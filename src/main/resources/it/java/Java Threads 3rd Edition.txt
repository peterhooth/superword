Threads are essential to Java programming, but learning to use them effectively is a.
This new edition of the classic Java Threads shows you how to take full.
O'Reilly books may be purchased for educational, business, or sales promotional use.
Java and all Java-based trademarks and logos are trademarks or registered.
Many of the designations used by manufacturers and sellers to distinguish their.
While every precaution has been taken in the preparation of this book, the publisher.
It turns out that Java's threading system is simple, at least relative to other threading.
This simplicity makes Java's threading system easy to learn so that even.
In early versions of Java, this simplicity came with tradeoffs; some of the advanced.
This book is intended for programmers of all levels who need to learn to use threads.
Therefore, even if you've written a threaded program in Java, this book.
The first few chapters of the book deal with the issues of threaded programming in.
Java, starting at a basic level; no assumption is made that the developer has had any.
This book is ideally suited to developers targeting the second wave of Java.
We make the assumption that readers of the book are familiar with Java's.
In a few areas, we present complex programs that depend on.
We've found that books that deal with these other APIs tend to give short shrift.
Though the material presented in this book does not assume any prior knowledge of.
Writing a book on Java in the age of Internet time is hard—the sand on which we're.
But we've drawn a line in that sand, and the line we've.
It's likely that versions of Java that postdate this version will contain some changes to.
A set of classes that provide threadsafe operations without synchronization.
Variables that can be the subject of a targeted notification when certain.
Classes that can manage a pool of threads to run certain tasks.
Classes that can execute tasks at a particular point in time.
The Java language has always had the capability to perform data.
These new implementations do not introduce new concepts for a developer.
At some point in time, virtually all developers who write threaded programs.
But given the importance of threading in the Java platform, adding these basic.
Java's new atomic classes provide a means by which developers can, when.
If you've read previous editions of this book, the concepts presented in the first two.
The information that falls into the third category is completely new to this edition.
This chapter forms a basic introduction to the topic of threads: why they are.
This chapter shows you how to create threads and runnable objects while.
This chapter discusses the basic level at which threads share data.
Sharing data between threads is the underlying topic of our next four.
This chapter discusses the basic technique threads use to communicate with.
This chapter discusses classes and programming methods that achieve data.
In this chapter, we complete our examination of data sharing and.
Java collection classes are written for a variety of circumstances.
Scheduling is the process whereby a single CPU selects a thread to run.
This chapter discusses thread pools—a collection of threads that can be used.
Task schedulers execute a task one or more times at some point in the future.
This set of classes includes timers (Java has had timer classes since JDK 1.3)
Dealing with I/O is one of the primary reasons why developers use threads in.
In this chapter, we use all of Java's threading features to show you how.
In this chapter, we complete our examination of thread-related features of.
Java by examining thread security, thread groups, thread stacks, and other.
In this chapter, we show a process for exploiting the power of multiprocessor.
Indicates URLs and filenames, and is used to introduce new terms.
Indicates user input, such as commands that you type on the command line.
All examples presented in the book are complete, running applications.
This book is here to help you get your job done.
Selling or distributing a CD-ROM of examples from O'Reilly books does.
Answering a question by citing this book and quoting example.
If you feel your use of code examples falls outside fair use or the permission given.
Please address comments and questions concerning this book to the publisher:
O'Reilly maintains a web page for this book, where we list errata, examples, and any.
To comment or ask technical questions about this book, send email to:
For more information about O'Reilly books, conferences, Resource Centers, and the.
As readers of prefaces are well aware, writing a book is never an effort undertaken.
Deb Cameron, for editing sometimes rambling text into coherency; Hong Zhang, for.
Steve Wilson, and Tim Cramer for supporting us in our work over the past six years.
Finally, we must thank the many readers of the earlier editions of this book who sent.
We have tried our best to answer every concern that they.
This is a book about using threads in the Java programming language and the Java.
The topic of threads is very important in Java—so important that.
The concept of threads is not a new one: for some time, many operating systems.
With Java, things are different: it is impossible to write any but the simplest Java.
Let's start by defining some terms used throughout this book.
Java, it's clear from the context that we're talking specifically about the.
While it's possible to take the Java programming language, directly compile it.
The Java virtual machine is the code that actually runs a Java program.
However, modern virtual machines usually compile the majority of the code.
This leads us to the terms that we use for things written in the Java language.
Like traditional programming models, Java supports the idea of a standalone.
As far as Java threads are concerned, the distinction between the different.
Concurrency also includes the ability to access data at the same time in two or.
These are issues of data synchronization, which is the term we.
We also need to be concerned with specific versions of Java itself.
Note the version number change or perhaps we should say leap.
In this book, we refer to earlier versions using the more commonly.
It's interesting to note the differences between this edition of Java Threads.
All that functionality and more is now included in the.
Full code to run all the examples in this book can be downloaded from.
Code is organized by packages in terms of chapter number and example number.
Within a chapter, certain classes apply to all examples and are in the chapter-related.
Examples within a chapter (and often between chapters) tend to be iterative, each.
Following the ellipses, we see that there is a new instance variable (stopButton) and.
For reference purposes, we list the examples and their main class at the end of each.
While the -source argument is not needed for a great many of our examples, we.
Running the examples requires using the entire package name for the main class:
It is always possible to run each example in this fashion: first compile all the files in.
To make this easier, we've also supplied an Ant build file that can be used to compile.
In theory, it is kind of like Make, but without Make's.
You don't need to know anything about how ant works in order to use it for.
The ant build file we supply has a target for each example that you can run; these.
The ant target for each example is also listed at the end of each chapter.
For example, to specify the number of threads for a particular example in.
The properties and their defaults are listed at the end of the chapter, like this:
The notion of threading is so ingrained in Java that it's almost impossible to write even.
Historically, threading was first exploited to make certain programs easier to write: if.
The popularity of threading increased when graphical interfaces became the standard.
In the 1990s, threaded programs began to exploit the growing number of computers.
Programs that require a lot of CPU processing are natural.
Although computers with multiple processors have been around for a long time, we're.
However, threading in Java often has nothing at all to do with multiprocessor.
One reason that threading is important in Java is that, until JDK 1.4, Java had no.
This is not to say there aren't other times when threads are a handy programming.
Many of these circumstances are due to the need for asynchronous behavior or the.
When the program executes the read() method, the program typically waits until the.
This type of I/O is called blocking I/O : the program blocks until some data is available.
Developers often take all input sources and use a system call like select() to.
Beginning with JDK 1.4, this feature is provided with the NIO library—a library.
Polling allows a developer to test if data is available from a particular source.
If data is available, the data can be read and processed: if it is not, the.
Polling is also supported by the NIO library of JDK 1.4
A file descriptor representing the input source can often be set so that an.
This signal interrupts the program, which processes the data and.
While the issue of blocking I/O can conceivably occur with any data source, it occurs.
Many developers, used to programming on a local area network (LAN), are.
As a result, writing a program that uses I/O means either using multiple threads to.
On the other hand, there are many times when the added complexity of the NIO.
Traditional operating systems typically provide some sort of timer or alarm call: the.
In early versions of Java, the programmer had to set up a separate thread to simulate.
That thread slept for the duration of a specified time interval and then notified.
A Java program is often called on to perform independent tasks.
In either case, while it is possible to write a.
The complete answer to the question "Why threads?" really lies in this category.
In a threaded word processor, the save operation would be in a.
With the advent of virtual machines that can use multiple CPUs simultaneously, Java.
But for many programs with CPU-intensive loops, parallelizing the loop.
Many languages have compilers that support automatic parallelization of loops, but as.
In this chapter, we've provided a basic overview of where we're going in our.
In the next few chapters, we look into the basics of thread programming.
In this chapter, we cover all the basics about threads: what a thread is, how threads.
Be aware, however, that we take some shortcuts with our examples in this.
The notion of a task should be familiar to you even if.
Suppose you have a Java program to compute the factorial of.
When your computer runs this application, it executes a sequence of commands.
If it is, multiply the value stored in fact by the value stored in n and.
If it isn't, print out the value stored in fact.
Behind the scenes, what happens is somewhat more complicated since the.
Don't get hung up on the strict sequential ordering of the list.
As a concept, thinking of a thread as an ordered.
Consequently, every computer program has at least one thread: the thread that.
For Java applications, execution begins with the main() method of the class.
In applets, servlets, and other J2EE programs, execution still begins with the.
In any case, the procedure is the same: execution of your code begins with.
In a Java program, it turns out that every program has more than one thread.
Your Java application is highly threaded, whether you program additional.
Returning to our example, let's suppose that we wrote a program that performed two.
These are two separate tasks, and so you could choose to write them as.
The answer to that depends on the conditions under which the application is run.
Java virtual machine now has two distinct lists of instructions to execute.
Although you may not have thought about it in these terms, this situation should also.
So too is the program that you use to listen to music.
In fact, what happens is that the computer executes a handful of instructions from the.
Quickly enough, in fact, that there are no gaps in the music.
If you happen to have more than one CPU on your computer, the lists of instructions.
CPUs aren't necessary to give the appearance of simultaneous execution or to exploit.
A single CPU can appear to execute both lists of instructions.
So threads are simply tasks that you want to execute at roughly the same time.
That allows you to double-click on an MP3 attachment in your.
In a multitasking environment, data in the programs is separated by default: each.
This type of data sharing is fine for dissimilar programs, but it is inadequate for other.
Consider a network server that sends stock quotes to multiple clients.
Sending a quote to a client is a discrete task and may be done in a separate thread.
In fact, if the client must acknowledge the quote, then sending the data in separate.
Here the data to be sent to the clients is the same; you don't.
Conceptually, the threads seem to be the same as programs.
A thread, then, is a discrete task that operates on data shared with other threads.
Threads can be created in two ways: using the Thread class and using the Runnable.
The Runnable interface (generally) requires an instance of a thread, so we.
Through the next few chapters, we add enough logic to score the user's.
For now, we are content to display a random character and display the character the.
Before we delve into the threading aspects of our code, let's look at a few utility.
We want to use the standard Java pattern of event listeners to handle these.
That requires the typical set of Java classes for a listener.
And finally, we need a helper class that fires the events when appropriate:
In our graphical display, one canvas registers to be notified when the user types a.
We've chosen this design pattern since, in later examples, multiple.
Here's a utility class that can display a given character:
Although this class has no references to threads, it still has thread-related issues:
In order to understand threaded programming fully, you must understand.
This is the essence of a race condition: two things.
Now we can program our first task (and our first thread): a thread that periodically.
They are created just like any other Java object, but they.
As you see, threads are created with four pieces of information:
The name of a thread is part of the information shown when a thread object is.
Otherwise, it has no significance, so give your threads names that.
Every thread has a stack where it stores temporary variables as it executes.
Everything related to the stack size of a thread is.
We can use these methods of the Thread class to create our first thread:
The first thing to note about this example is that it extends the Thread class.
In a sense, the run() method is similar to the main() method of a standalone Java.
Subsequent threads start executing with the run() method of the thread.
So when the run() method of this class is eventually called, it fires off a new.
The second task of our application is responsible for displaying the characters typed.
It is also responsible for creating and starting our second thread.
Other threads are involved in this example, even though you don't see references to.
The second thread of the application is the instance of the.
It is created the first time the Start button is.
A third thread in the application is the event-processing thread.
At this point, you can compile and run the application.
At this point, we can't do much about scoring what the user types.
However, we can clear up a few things in the display as we discuss how.
In our example, we gloss over some of the details of how the thread is actually started.
We'll discuss that in more depth now and also give details on other lifecycle events of.
In our example, we use the simplest constructor available to us.
All threads have names that serve to identify them in the virtual machine.
A thread exists once it has been constructed, but at that point it is not executing any.
In this waiting state, other threads can interact with the existing thread object.
Various attributes of the waiting thread can be set: its priority, its name, its daemon.
We'll see examples of these throughout the book, but each of these.
When you're ready for the thread to begin executing code, you call its start()
This method performs some internal housekeeping and calls the thread's.
When the start() method returns, two threads are now executing in.
After its start() method has been called, the new thread is said to be alive.
If the isAlive( ) method returns false, however, the thread may not.
Once started, a thread executes only one method: the run() method.
As a result, the only way to terminate a thread is to arrange for its run() method to.
If you look at the documentation of the Thread class, you notice that the.
There are many threads that you don't need to stop.
Often, however, you want a thread to continue to execute until some other condition.
We explore some basic ways to arrange for a thread to stop.
The run() method cannot throw a checked exception, but like all Java methods, it can.
Once a thread begins executing its run() method, it continues execution until the.
If you're familiar with other thread models, you may know.
Later, the thread is resumed, which is to say that it is told to continue its execution.
The Thread class contains suspend() and resume() methods, but they suffer from.
It is possible for a thread to suspend its own execution for a specific period of time by.
When a thread executes the sleep() method, it pauses for a given number of.
When the pause time has elapsed, the thread wakes up and continues execution with.
The Thread class provides a version of the sleep() method that allows the.
Ongoing projects within the Java Community Process are working on a.
Strictly speaking, sleeping is not the same thing as thread suspension.
A thread that has completed its run() method has terminated.
As long as some other active object holds a reference.
In general, then, you should not hold onto thread references so that they may be.
One reason to hold onto a thread reference is to determine when it has completed its.
You'll see that technique in use in the examples in.
The join() method blocks until the thread has completed its run() method.
This means that you may call the join() method any number of times.
The most common way of stopping a thread is to set some internal flag to signal that.
The thread can then periodically query that flag to determine.
Here we've created the boolean flag done to signal the thread that it should quit.
We've also introduced the use of the Java keyword volatile for that variable.
We must now modify our application to set this flag:
Now we have two buttons: a Start and a Stop button.
This process also reenables the Start button: we can start a new thread at any time.
It would be more natural simply to suspend and resume the thread, as we do in.
However, in a case like this, it actually does not matter.
If you're writing a program and it is easier to abandon a thread and.
We revisit this topic in more depth when we discuss thread pools in.
Calling the setDone() method is a simple way for threads to communicate with each.
The last example has a delay between when the actionPerformed() method called.
The delay in this case is minimal, but it's likely to be close to the amount of time that.
If we originally specify a 15-second delay, we probably won't want to wait.
In other cases, the delay can be worse: if the thread is executing a read() method to.
Methods like these are called blocking methods because they block execution.
When you arrange for a thread to terminate, you often want it to complete its blocking.
The second effect is to set a flag inside the thread object that indicates the thread has.
Here's how a thread uses this information to determine whether or not it should.
Note: the done instance variable and setDone( ) method are removed.
This example is almost exactly the same as the one in which we use a done flag to.
Note that this technique does not completely eliminate the possibility that we sleep.
When we talked about creating a thread, we mentioned the Runnable interface.
The Runnable interface allows you to separate the implementation of a task from the.
Now we must construct the thread directly and pass the runnable object (producer)
This leads to the question of whether you should use the Runnable interface or the.
The truth is that sometimes it makes sense to use the Runnable interface and.
If you extend the Thread class as we do in our first examples, then you inherit the.
In fact, we should point out that the full source code for example 5 is based on.
We have to use the setDone() method to signal that the.
A similar example can be used to show why it is sometimes preferable to use the.
Let's suppose that we want the character in our display canvas to.
We could develop a brand new class to do this, but it shares most of the logic of the.
This class demonstrates the canonical technique to handle animation in Java: a.
The thread that controls the animation in this canvas is created just as before: the.
The stop() method, on the other hand, calls the setDone() method.
We began this section by wondering whether it was preferable to program a task.
With Runnable, Java provides a number of classes that handle threading.
These classes handle thread pooling, task scheduling, or timing issues.
If you do a thorough program design and Unified Modeling Language (UML) model of.
But if your object hierarchy is silent on the parent class for your task, or if you.
This point is often confusing to developers who are new to threads; it can be.
In Java, an instance of the Thread class is just an.
Thread object is not the thread itself; it is instead a set of methods and data that.
The upshot of this is that you cannot look at any object source code and know which.
Sometimes, you need to find out what the current thread is.
In other circumstances, code within a thread object may want to see if.
You can retrieve a reference to the current thread by calling the currentThread()
Similarly, within an arbitrary object, you can use the currentThread() method to.
In fact, the Thread class includes a static method interrupted() that simply returns.
In this chapter, we've had our first taste of threads.
How can these tasks be separated to make the program logic easier, or benefit your.
At a programming level, we've learned how to construct, start, pause, and stop.
We've also learned about the Runnable interface and how that interface.
Tasks can be either Thread objects or Runnable objects associated with a.
Using the Runnable interface allows more flexibility in how you define your.
We've also touched on how threads interoperate by calling methods on the same.
The ability of threads to interoperate in this manner includes the ability for.
That data sharing is key to the benefits of a.
Here are the class names and Ant targets for the examples in this chapter:
The factorial program accepts a command-line argument to indicate the integer.
In the previous chapter, we covered a lot of ground: we examined how to create and.
In others, we needed to change a character variable that was used in.
We glossed over the details at the time, which may have given.
In this chapter, we look at the issue of sharing data between threads.
In this chapter, we examine the concept of a race condition and.
The most obvious is the one that we created and.
This constant adjustment and redrawing is what is seen as animation by the.
There is no race condition between these threads since no data in this object is shared.
However, as we mentioned at the end of the last chapter, other.
It is possible for the newCharacter() method to change the.
Or for the newCharacter() and paintComponent() methods to leave the.
The term atomic is related to the atom, once considered the smallest.
This can either be accomplished in hardware or simulated in.
In our case, we define atomic code as code that can't be found in an.
The Java specification provides certain mechanisms that deal specifically with this.
The Java language provides the synchronized keyword; in comparison with.
A mutex lock is also known as a mutually exclusive lock.
The other thread has to wait until the first thread releases.
If one thread wants to call one of these methods while.
Since only one thread gets to call either method at a time, only.
Under the covers, the concept of synchronization is simple: when a method is.
Once the method has acquired (or checked out or grabbed)
There is still one more threading issue in this example, and it has to do with the.
So, can't we just synchronize the two methods, just as we did previously? Yes and no.
Yes, Java's synchronized keyword allows this problem to be fixed.
If we synchronized both the run() and setDone() methods, how.
The scope of a lock is defined as the period of time between when the lock is.
Later in this chapter, we'll examine locks that apply to any block of code.
The problem at this point relates to the scope of the lock: the scope of the run()
By synchronizing the run() method, the lock is grabbed and.
There is a way to shrink the scope of a lock by synchronizing only the.
However, there is a more elegant solution in this case.
The setDone() method performs only one operation with the done flag: it stores a.
The run() method also performs one operation with the done flag:
The issue here is that we potentially have a race condition because one piece of data.
When only a single piece of data is involved, there is a different solution.
That means the value of the variable can't be found in an interim.
The setDone() method has only one store operation; therefore, it is.
This is particularly true in loops that are controlled by a variable.
One way to solve this problem is to provide setter and getter methods for the variable.
We can then simply synchronize access by using the synchronized keyword on these.
This works because acquiring a synchronization lock means that all.
Similarly, every time the variable is written, the value must be stored in main.
Since these operations are atomic, we can avoid the race condition in our.
In most releases of the virtual machine prior to JDK 1.2, the actual implementation of.
Java's memory model made using volatile variables a moot point: variables were.
So why is volatile necessary? Or even useful? Volatile variables solve only the.
As we mentioned, we could have solved this problem by using synchronized setter.
We must invoke another method, including setting up parameters and the return.
We must grab and release the lock necessary to invoke the method.
The concept of using a done flag is common enough that we can make a very.
While we can agree that you might not use these types of.
How does volatile work with arrays? Declaring an array volatile makes the array.
The elements within the array are not volatile; the virtual.
Consequently, if multiple threads are going to access array elements, they must use.
Let's examine a more complex example; so far, we have looked at simple data.
Our application has a display component that presents random numbers and letters.
To accomplish this, we will introduce a new component, one that displays the user's.
The heart of this class is the newCharacter() method, which is called from multiple.
It is called, at random times, by the source (and thread) that.
It is also called by a character source every time the.
Solving the race conditions means synchronizing this data at the.
In this case, synchronizing at the method level solves the problem, and making the.
The user types a character, which happens to be correct.
The random character source calls the newCharacter() method, which routes.
The random character thread stores the new character in the char2type.
This case is dependent on a scheduling change occurring at an unfortunate time.
Since the score is both incremented and decremented, the user is not given.
The new character from the random character generator is lost.
The character is lost only to the scoring component, not to the animation.
The user is correctly informed of the new character to be typed.
The resetScore() method also accesses the same common data and therefore also.
You may think this is not necessary since the method is.
In this case, they are being synchronized to make the class.
This is an important point in designing classes for use in a multithreaded environment.
Even if you believe that a race condition cannot occur based on the current use of the.
A race condition occurs when the order of execution of two or more threads.
Race conditions can be considered harmless (or benign) if you can prove that.
But in general, a race condition is a problem that is waiting to happen.
At this point, we may have introduced more questions than answers.
How can synchronizing two different methods prevent multiple threads calling those.
The implementation of this mechanism is done by a lock that is.
The point to remember here is that the lock is based on a specific instance of an object.
How does a synchronized method behave in conjunction with an unsynchronized.
This, in turn, provides the means of allowing only one.
Simply put, a synchronized method tries to grab the object.
What does synchronizing static methods do? And how does it work? Throughout this.
Just as there is an object lock that can be obtained for each instance of a.
In terms of implementation, there is no such thing as a class.
When a static synchronized method is called, the program obtains the class lock.
This mechanism is identical to the case in which the.
Apart from the functional relationship between the two locks, they are not.
As we mentioned, a class lock does not actually exist.
We have introduced the concept of "lock scope" but only touched on avoiding a scope.
The purpose of the synchronized keyword is to provide the ability to allow serialized.
For now, the two methods of this interface that are important to us are.
Using the Lock interface is similar to using the synchronized.
The difference is that the lock can now be more.
This new version of the ScoreLabel class is very similar to the previous version.
Instead of declaring methods as synchronized, those methods now call the lock()
Using locks, we need to call the unlock() method: by placing the unlock() method.
In terms of functionality, this example is exactly the same as the previous example.
Using a lock class, we can now grab and release a lock whenever desired.
It is also possible for one object to have multiple locks.
Since we now have t he lock-related classes available in our arsenal, many of our.
Since the lock() and unlock() method calls are explicit, we can move them.
And we can now lock at a scope that is specific to the program design instead.
It is possible for the synchronized keyword to lock a block of code within a method.
It is also possible for the synchronized keyword to specify the object whose lock is.
It is possible to lock at a scope that is smaller than a method, and it is.
We can implement our last example just by using the synchronized keyword:
This syntax of the synchronized keyword requires an object whose lock is obtained.
This is similar to our scoreLock object in the previous example.
Using this syntax, we can now lock individual lines of code instead of.
We can also share data across multiple objects by locking on other.
It is possible to use only the synchronized block mechanism even when we.
So, which technique should you use? That is up to you.
For more complex thread programming, however, relying solely on the.
How are the lock classes related to static methods? For static methods, the explicit.
As far as lock objects are concerned, it doesn't matter if the method being executed.
As long as the method has a reference to the lock object, it can acquire.
Synchronizing entire methods is the simplest technique, but as we have already.
It may also be inefficient to hold a lock for the section of code.
Using the synchronized block mechanism may also be a problem if too many objects.
As we shall see, it is also possible to have a deadlock condition if we.
Synchronized blocks also cannot establish a lock scope that spans.
In the end, which technique to use is often a matter of personal preference.
We tend to favor using explicit locks in the later.
What if we want to do other tasks if we can't obtain the lock? The Lock interface.
If the lock is obtained, the return value is a boolean value of true.
What if we want to wait only for a specific period of time for a lock? The tryLock()
This method takes two parameters: one that specifies the number of time units and a.
TimeUnit object that specifies how the first parameter should be interpreted.
This method is similar to the lock() method in that it waits for the lock, but only for.
It is similar to the tryLock() method in that it may return.
What are the other methods of the Lock interface used for? We address them later in.
By using explicit locks, the developer is free to address.
Our implementation of the newCharacter() method could be refactored into multiple.
This isolates the generator and typist logic into separate methods, making.
So, there is no reason for these methods to acquire the lock.
The reason this works is that Java does not blindly grab the lock when it enters.
If the current thread owns the lock, there is no reason to wait for.
Furthermore, the system is smart enough to not free the lock.
Nested locks are also supported by the ReentrantLock class—the class that.
This implementation allows these locks to behave exactly like the.
Note, however, that this is a specific property of the.
ReentrantLock class and not a general property of classes that implement the Lock.
Whyis Java's support of nested locks important? This was a simple example.
The deadlock occurs because the final method tries to grab a lock that the current.
This lock can't be freed until the original method unlocks.
Cross-calling methods are common and can be so complex that it may not be possible.
Cross-calling methods and callbacks are very prevalent in Java's core.
Is it possible to detect how many times a lock has been recursively acquired? It is not.
The getHoldCount() method returns the number of acquisitions that the current.
A return value of zero means that the current thread.
Two other methods of the ReentrantLock class are also important to this discussion.
We have mentioned deadlock a few times in this chapter, and we'll examine the.
Simplistically, deadlock occurs when two or more threads are waiting for two or more.
Interestingly, it is possible to deadlock even if no synchronization locks.
To do this, we revisit and break one of our.
Two threads are involved here: the thread created by this class and the.
It is a data variable that the run() method uses to determine.
In essence, the run() method is waiting for the done flag to be.
When the animation thread is started, the object lock is grabbed by the run() method.
The method does not release the object lock until it has completed—which is.
The object lock can't be acquired until the run() methods exits.
Since that lock is already held by the animation thread itself, the.
To fix this problem, we reduce the scope of the lock used by the run() method.
Now that the run() method is synchronized only while it is executing the getDone()
This is a simple example, but, as you can see, a deadlock can occur even with simple.
The reason that a deadlock is a problem is obvious — it prevents the.
Upon examining our ScoreLabel class, we got a very good idea.
In order to be more efficient, we create a lock just for these two.
In fact, it may not be detected at all, as the.
In our previous example, the problem manifested itself as soon as the.
In this example, the program can run correctly for millions of.
Since this deadlock is dependent on the timing of the threads, it may.
So, where is the deadlock? It is related to the differences in lock acquisition between.
It is now possible for one method to be called which grabs one lock, but, before.
Let's look at a possible run of this implementation as outlined in Figure 3-2
This method first grabs the score lock (L1) and then is about to grab the.
At the same time, the user presses the Start button, generating a call.
After thread 1 grabs the score lock, it then tries to grab the character.
Since the character lock is already held, it waits for it to be released.
Can the system somehow resolve this deadlock, just as it is able to avoid the potential.
Unlike the case of the nested locks, where a single thread is.
Since a thread owns one of the locks involved, it.
Either case is very complex and may be more complex.
As for the developer, we look at the design issues related to deadlock.
The last question we need to address is the question of lock fairness.
This means that fairness is based on the algorithm of the program and only.
How should locks be granted with explicit locks? One possibility is that locks should be.
A third view is that locks should be granted in a fashion that.
The behavior of synchronization (using the synchronized keyword or explicit locks)
The ReentrantLock class provides an option in its constructor to specify whether to.
This means that when many lock requests are made at the same time, they are.
One thread is executed only once every second or so while the other.
It is up to the developer to decide whether or not to use this.
What if your program has a different notion of fairness? In that case, it's up to you to.
In this chapter, we've introduced the synchronized keyword of the Java language.
This keyword allows us to synchronize methods and blocks of code.
They also provide features such as testing to see if the lock is available, placing.
We've also looked at a common way of handling synchronization of a single variable:
As you can tell, it is one of the most.
Here are the class names and Ant targets for the examples in this chapter:
Thread notification addresses a number of issues in our sample application.
In fact, the entire initialization process is repeated every time that the Start button is.
Fortunately, the mechanisms we explore in this chapter can solve all.
When another thread creates the condition, it notifies the first thread that has been.
With Solaris or POSIX threads, these are often referred to as condition variables; with Windows, they are.
Notifies a thread that is waiting that the condition has occurred.
The wait() and notify() mechanism works because these are methods of.
Since all objects in the Java system inherit directly or.
What is the purpose of the wait-and-notify mechanism, and how does it work? The.
Can the wait-and-notify mechanism be used to replace the synchronized mechanism?
Actually, the answer is no; wait-and-notify does not solve the race condition problem.
Let's use this technique to solve the efficiency problem in our animation component.
In this fixed version, the animation thread does not exit when the done flag is set.
Instead, it simply waits for the done flag to be reset.
In this new version, the done flag is no longer volatile.
Therefore, access to the done flag is now protected by a synchronized.
The run() method now no longer exits when the done flag is set to false.
Also notice that instead of calling the sleep() method, the animation is achieved by.
When the wait() method executes, the synchronization lock is released.
This technique is needed due to a race condition that would otherwise exist between.
In the online examples, the random character generator's restarting issue has also.
We'll leave it up to you to examine the code at your leisure.
As we just mentioned, the wait-and-notify mechanism has a race condition that needs.
The wait() method releases the lock prior to waiting and reacquires the lock prior to.
This integration of the wait-and-notify mechanism and the synchronization lock is.
In other systems, such as Solaris or POSIX threads, condition variables also.
In our example, both the run() and the setDone() methods are synchronized.
The wait() method releases the lock, which allows other threads to.
What happens when notify() is called and no thread is waiting? This cannot happen.
Since the run() method does not exit, it is not possible.
A thread that later executes the wait() method has to.
What are the details of the race condition that exists in the wait-and-notify.
The first thread tests the condition and confirms that it must wait.
How does this potential race condition get resolved? This race condition is resolved by.
This is mandatory; the methods do not work properly and generate an.
The developer must use this lock to ensure that checking the.
Is there a race condition during the period that the wait() method releases and.
The object lock is not actually freed until the waiting thread is already in a state in.
The system prevents any race conditions from occurring in this.
If a thread receives a notification, is it guaranteed that the condition is set correctly?
Prior to calling the wait() method, a thread should always test the.
This is because another thread can also test the condition and determine that.
A race condition exists when multiple threads are waiting for.
The race condition that is solved internally to the wait-and-notify.
Thread 1 calls a method that acquires the synchronization lock.
Thread 1 calls the wait() method, which frees the lock.
Thread 2 calls a method that acquires the same synchronization lock.
Thread 3 calls a method that blocks waiting for the lock.
Thread 2 sets the state flag and calls the notify() method.
This is a common case when multiple threads are involved in the notifications.
As such, when a consumer wakes up, it cannot assume that the state it.
It may have been valid in the past, but the state may have.
Waiting threads must provide the option to check the state and to return.
Remember too that the wait() method can return early if its thread is interrupted.
What happens when more than one thread is waiting for notification? Which threads.
There is no way to determine, even on a single.
Another method of the Object class assists us when multiple threads are waiting for.
Notifies all the threads waiting on the object that the condition has occurred.
This method must be called from within a synchronized method or block.
The notifyAll() method is similar to the notify() method except that all of the.
Just like the notify() method, the notifyAll() method does not allow us to decide.
Does the notifyAll() method really wake up all the threads? Yes and no.
Thus, only one thread can run at a time, and only after the thread that called the.
Why would you want to wake up all of the threads? There are a few reasons.
Later in this chapter, we discuss options to allow multiple condition variables to coexist.
Another option could be when producers generate data that can satisfy more than one.
Since it may be difficult to determine how many consumers can be.
In our example, we showed how the wait() and notify() methods are called within.
In that case, the lock that interacts with the wait() and.
It is possible to use the wait() and notify() methods with a synchronized block.
Therefore, you must invoke the wait() or notify() method on that same object, like.
In this example, we've separated the synchronization that protects the animation.
Now when the wait() and notify() methods are called, we're holding the object lock.
It may help to remind yourself how Java objects work in this regard.
So the wait() and notify() methods are consistent: they are always called with an.
Condition variables are a type of synchronization provided by many other threading.
A condition variable is very similar to Java's wait-and-notify mechanism—in.
The signal() function wakes up one thread whereas the broadcast() function.
The race conditions of a condition variable are solved in the same way.
To create a Condition object from the Lock object, you call a method available on the.
Using the Condition object is similar to using the wait-and-notify mechanism, with.
We'll modify our typing program to use the condition variable.
As we mentioned, a new Condition object is created by calling the newCondition()
Therefore, our new random character generator now uses a Lock object as its.
We instantiate a Condition object, cv, which is set to the value.
In this example, it doesn't look like we accomplished anything: all we do is use.
First, condition variables are needed when you use Lock objects.
In other words, the lock represented by the Lock object and the.
This condition variable mechanism is provided by the Condition object.
The second reason is the creation of the Condition object.
Java mechanism, all waiting threads that are synchronizing on the same object are.
Notifies a thread that is waiting using the Condition object that the condition.
Notifies all the threads waiting using the Condition object that the condition.
Basically, the methods of the Condition interface duplicate the functionality of the.
In this chapter, we introduced the methods of the wait-and-notify mechanism.
With these methods of the Object class and Condition interface, threads are able to.
In later chapters, we examine classes and techniques that provide even higher level.
Here are the class names and Ant targets for the examples in this chapter:
In this chapter, we complete our discussion of data synchronization and thread safety.
We then examine another approach to data synchronization: the use of atomic.
The code path in many virtual machine implementations is different for.
Before a contended lock can by acquired, its current holder must release it.
The terms contended and uncontended refer to how many threads are.
A lock that is not held by any thread is an.
When a thread attempts to acquire a lock that is already held by another.
In practical terms, the second point here is the most salient: if someone else holds the.
This situation leads programmers to attempt to limit synchronization in their.
This is a good idea; you certainly don't want to have unneeded.
But are there times when you can avoid synchronization altogether?
We've already seen that in one case the answer is yes: you can use the volatile.
But these are really the only cases in which you can avoid synchronization.
The reasons for this have to do with the way in which computers optimize programs.
Computers perform two primary optimizations: creating registers to hold data and.
Your computer has a certain amount of main memory in which it stores the data.
Most CPUs are able to operate directly on the data that's held in main memory.
CPUs can only read and write to main memory locations; these computers must read.
Yet even CPUs that can operate on data directly in main.
Consequently, register use is pervasive when the computer executes your code.
From a logical perspective, every thread has its own set of registers.
So, threads never share data that is held in registers.
This associates a particular memory location (e.g., 0xff12345) with the variable done.
The run() method is then compiled into a set of instructions:
You can see the problem: the run() method never reloads register r1 with the.
Using the volatile keyword ensures that the variable is never kept in a register.
The virtual machine can use registers for volatile variables as long as it obeys the semantics we've outlined.
Remember that we might have implemented this code by synchronizing around.
Developers often hope that they can avoid synchronization by depending on the order.
Suppose that we decide to keep track of the total score.
A race condition exists because we can have this order of execution by threads t1 and.
However, you cannot depend on the ordered execution of statements like this.
This decision is made at runtime based on the particular.
Now the race condition has caused a problem: we've returned the wrong final score.
Note that it doesn't make any difference whether the variables are defined as.
The only thing that can help us here is synchronization.
Note, however, that the converse is not true: a statement before a.
This design pattern gained a fair amount of attention when it was first proposed, but.
One case where developers are tempted to avoid synchronization deals with lazy.
In this paradigm, an object contains a reference that is time-consuming.
The developer's goal here is to prevent synchronization once the foo object has been.
Unfortunately, this pattern is broken because of the reasons we've just.
In particular, the value for foo can be stored before the constructor for foo.
For more information on the double-checked locking pattern as well as an extensive.
The purpose of synchronization is to prevent the race conditions that can cause data.
This is a subtle but important point: not all race conditions should be avoided.
We can fix the problem in one of two ways.
This means that there is a balance between synchronization and volatile variables.
Of course, the balance is very one sided; volatile variables can be safely.
Their first, and simpler, use is to provide classes that can perform atomic operations.
A volatile integer, for example, cannot be used with the ++
The second, and more complex, use of the atomic classes is to build complex code.
However, using the same sort of coding techniques as the atomic classes.
The other constructor creates the variable with an initial value that is.
The get() and set() methods also ensure that the data is read from or written.
Both of these methods take two arguments—the value the data is expected.
A boolean value of true is returned if the current value is equal to the.
The AtomicInteger and AtomicLong classes provide additional methods to support.
Using an atomic class allows you to treat the operations atomically.
The addAndGet() and getAndAdd() methods provide the pre- and post-operators for.
Does the atomic package support more complex variable types? Yes and no.
Some classes support arrays and variables that are already part of other objects.
However, no extra functionality is provided by these classes, so support of complex.
For arrays, only one indexed variable can be modified at a time;
Volatile variables (of certain types) that are already defined in other classes can be.
The basic methods of these classes are essentially the same, with slight modifications.
As we mentioned, it is possible (in theory) to implement every program or class that.
The atomic classes are not a direct replacement of the synchronization tools — using.
To understand this better, let's modify our ScoreLabel class[2] to use only atomic.
When you compare this class to previous implementations, you'll see that we've.
The point of each modification is to preserve the full semantics of the synchronized.
The simplest kind of modification you may have to make is simply substituting atomic.
Interestingly, changing both variables together is not done atomically: it is possible.
This may sound like a problem, but it actually isn't because we've preserved the.
Remember that the purpose of synchronization is not to prevent all race conditions; it.
The second type of change is embodied within our new implementation of the.
In fact, they don't even change variables that are shared with.
These problems arise because the state encapsulated by the resetGenerator()
Consider what would happen when two threads simultaneously call the.
In this code, the two threads simultaneously ask generatorA to remove the this.
Because our previous example was synchronized, these errors were prevented.
There is one side effect here that affects another method.
The newCharacter() method contains the most extensive changes in this example.
As we mentioned, the first change is to separate events based on the different.
This method can no longer assume that the source is the typist if.
The handling of the generator event has only minor changes.
We need to update the score to credit or penalize the.
It is not a problem if the user sees a very short delay before the score.
The score is updated only if char2type has been updated correctly.
What does it mean that the other thread was successful in processing another event?
It means that we must start our event processing over from the beginning.
That's why this section of code is wrapped in an endless loop: the program does not.
The purpose of atomic variables is to avoid synchronization for the sake of.
However, how can atomic variables be faster if we have to place the.
Extra iterations of the loop occur only if the atomic operation fails, which in turn.
As we can tell from this example, it's necessary to balance the usage of.
Is it possible to use atomic variables if we also need the functionality of condition.
In fact, code executed by unsynchronized threads may have to be placed.
This does not mean that you should avoid atomic variables if you need condition.
It is possible to implement all of a program with atomic.
Of course, in some situations, it is not a problem.
This last alternative is the case with our typing game.
Second, the waiting process occurs only when the game is stopped.
Here is an implementation of our animation component using only atomic variables;
As with our previous example, using atomic variables is not simply a matter of.
In our animation component, this is especially true for the code that.
We could have left the code in that method and used.
However, it's much easier to implement this functionality by creating and.
The paintComponent() method is also not completely atomic, but as with the.
The paintComponent() method loads into temporary variables data that it.
The run() method is similar to our previous versions in that it calls the repaint()
On the other hand, resuming the animation is no longer.
This could be solved by calling the repaint() method from the setDone()
The implementation of the setDone() method is now much simpler.
And it no longer needs to inform the animation thread that the done flag.
The major benefit of this implementation is that there is no longer any.
As we mentioned, developers do not just face a choice of.
In order to understand the balance, it is beneficial to use both.
These examples show a number of canonical uses of atomic variables; we've used.
What's happening in our examples with atomic variables is that there is no.
The atomic classes use this technique internally in their implementation, and.
Data exchange is the ability to set a value atomically while obtaining the previous.
What if the data exchange is more complex? What if the value to be set is dependent.
The get() method is used to get the previous value, which is used.
The variable is set to the new value using the.
If the compareAndSet() method fails, the entire operation can be.
Although the get() method call, the calculation of the new value, and the.
Comparing and setting is the ability to set a value atomically only if the current value.
What if the comparison is more complex? What if the comparison is dependent on the.
The complex comparison is used to see if the operation should proceed.
The compareAndSet() method is then used to set the value if the current value has.
Although the list of data types for which atomic classes are available is pretty.
While it does support generic object types, it doesn't support the.
As a result, it may not be possible to change a floating-point value atomically, but it.
As long as the floating-point values are read-only, this technique is threadsafe.
In our new AtomicDouble class, we use an atomic reference object to encapsulate a.
The get() method now has to use two method calls to get the double value—it must.
Getting the Double object type is obviously atomic because we are using an atomic.
As for the atomic reference itself, it is atomic because we are using an atomic.
In our previous examples, we have set only individual variables atomically; we.
Once again, this works only if the values are not directly changed in any way.
Here is an atomic class that protects two variables: a score and a character variable.
Using this class, we are able to develop a typing game that modifies both the score.
As in our AtomicDouble class, the getScore() and getCharacter() methods work.
The setScore() and setCharacter() methods are implemented using the advance.
The first method sets the new character to be typed while.
Once again, using atomic variables has to be balanced with using.
Is the creation of all the temporary objects acceptable? Is this.
As these techniques demonstrate, using atomic variables is sometimes complex.
In many cases, atomic variables are simple to use because you just want to.
In many cases, using this kind of minimal synchronization is not a good idea.
With a high volume of method calls where synchronization can.
Any thread can, at any time, define a thread local variable that is private to that.
Other threads that define the same variable create their own copy.
This means that thread local variables cannot be used to share state.
Thread local variables have other uses, of course, but their most.
In typical usage, you subclass the ThreadLocal class and override the.
One case where you might use a thread local variable to avoid synchronization is in a.
When the calculate() method in our example is called, the thread local hash map is.
Since access to the map is from only a single thread, we're able to use a.
This approach is worthwhile only if the calculation is very expensive since obtaining.
And in general, the performance of the ThreadLocal class has been fairly.
Another case where this technique is useful is dealing with thread-unsafe classes.
Values stored by threads in thread local variables are unrelated.
This class allows a child thread to inherit the value of the thread local variable from its.
If you like, you can use the childValue() method to further augment this behavior.
When the child thread calls the get() method of the thread local variable, the get()
In this chapter, we've examined some advanced techniques for synchronization.
We've learned about the Java memory model and why it inhibits some.
Here are the class names and Ant targets for the examples in this chapter:
The calculator test requires a command-line argument that sets the number of.
In the Ant script, it is defined by this property:
In this chapter, we look at some of the more advanced issues related to data.
Programmers with a background in a particular threading system generally tend to.
A barrier is a rendezvous point for multiple threads: all threads must arrive at.
A condition variable is not actually a lock; it is a variable associated with a lock.
Condition variables are often used in the context of data synchronization.
Condition variables generally have an API that achieves the same functionality.
This term refers to the access granted to a particular thread that has entered.
In some systems, a monitor is simply a lock; in others, a monitor is.
A lock that can be acquired by multiple threads simultaneously as long as the.
You probably noticed a strong pattern while reading this list of terms: beginning with.
In Java, a semaphore is basically a lock with an attached counter.
Lock interface as it can also be used to prevent access if the lock is granted; the.
In those terms, a semaphore with a counter of one is the.
The Semaphore class keeps tracks of the number of permits it can issue.
Therefore, a semaphore can be used to represent the number of locks.
It could also be used to throttle the number of threads working.
The Semaphore interface is very similar to the Lock interface.
If a semaphore is constructed with its fair flag set to true, the semaphore tries to.
The downside to this option is speed: it takes more.
Of all the different types of thread synchronization tools, the barrier is probably the.
This is generally used when an application operates in phases.
For example, many compilers make multiple passes between loading the source and.
Given its simplicity, why is the barrier not more commonly used? The functionality is.
We can solve the coordination problem in two ways, without using a barrier.
However, in some cases it is preferable to use barriers.
It may be easier to code all of the logic as one method, particularly if the.
When the barrier is constructed, the developer must specify the number of parties.
This number is used to trigger the barrier: the threads are.
There is also an option to specify an action—an object that.
Each thread that calls the await() method gets back a unique return value.
The first thread to arrive is one less than the number.
Upon arrival of the last thread, the action is executed, the.
The waiting threads can be interrupted, a thread may break through the.
In every exception condition, the barrier simply breaks, thus requiring that the.
Reinitialization of the barrier is complex enough that it may be safer to create a new.
Finally, the CyclicBarrier class provides a few operational support methods.
The countdown latch implements a synchronization tool that is very similar to a.
In fact, it can be used instead of a barrier.
Like the barrier class, methods are provided that allow threads to wait for a condition.
The difference is that the release condition is not the number of threads that are.
Instead, the threads are released when the specified count reaches zero.
The CountDownLatch class provides a method to decrement the count.
It can also be called by a thread that is not.
When the count reaches zero, all waiting threads are released.
It may be that more threads than the specified count are.
And any thread that attempts to wait after the latch has triggered is.
And a couple of methods are provided to control the count—one to decrement.
The boolean return value for the timeout variant of the.
The exchanger implements a synchronization tool that does not really have.
This class is closer to a collection class than a synchronization tool—it is mainly used.
It is also very specific in that threads have to be paired.
The exchange() method is called with the data object to be exchanged with another.
If another thread is already waiting, the exchange() method returns with the.
If no other thread is waiting, the exchange() method waits for.
A timeout option can control how long the calling thread waits.
Unlike the barrier class, this class is very safe to use: it will not break.
Timeouts and interrupts also do not break the exchanger as they do in the barrier.
Sometimes you need to read information from an object in an operation that may.
You need to lock the object so that the information you read is.
If the lock needs to be held for a long time, it makes sense to consider allowing.
You create a reader-writer lock by instantiating an object using the.
Both of these locks are objects of the Lock class—their.
These locks also nest, which means that owners of the lock can repeatedly acquire the.
This allows for callbacks or other complex algorithms to execute.
Furthermore, threads that own the write lock can also acquire the read lock.
Threads that own the read lock cannot acquire the write lock;
Later in this chapter, we examine the topic of lock starvation in depth.
In this section, we've examined higher-level synchronization tools provided by J2SE.
In a sense, they can be considered convenience classes; that is, they.
There is also a lot of overlap between these classes.
A countdown latch can be used as a barrier simply by having.
The major advantage in using these classes is that they offload threading and data.
Developers should design their programs at as high a level as.
Using these libraries, however, does not remove the responsibility for.
Deadlock between threads competing for the same set of locks is the hardest problem.
It's a hard enough problem, in fact, that it cannot.
To review, deadlock occurs if two threads execute the newCharacter() and.
As we mentioned at the time, this example is simple, but more complicated conditions.
Deadlock is difficult to detect because it can involve many classes that call each.
Nonetheless, a close examination of the source code is the only option presently.
In certain cases, the virtual machine can detect that two threads are.
It's possible to obtain a stack trace for all active threads in the.
If two or more threads are waiting for each other's locks, the virtual machine.
The virtual machine cannot detect other kinds of deadlock, such as the first.
The simplest way to avoid deadlock is to follow this rule.
It's impractical: many useful Java methods are synchronized, and you'll want.
To avoid the usage of collection classes from synchronized methods would.
It's overkill: if the synchronized method you're going to call does not in turn.
Furthermore, if the class or library is accessed only through its class.
Nonetheless, if you can manage to obey this rule, there will be no deadlocks in your.
Another frequently used technique to avoid deadlock is to lock some higher-order.
Of course, this is only a simple example: we don't need to lock everything.
The problem with this technique is that it often leads to situations where the lock.
By synchronizing with only one lock, we are preventing access.
The most practical rule to avoid deadlock is to make sure that the locks are always.
In our example, it means that either the score or.
This implies the need for a lock hierarchy—meaning that locks are not only.
Since the resetScore() method now also grabs the score lock first, it is not possible.
Understand which locks are assigned to which subsystems and understand the.
This allows us to form groups of locks and map out.
The relationship of the locks must be understood in order to be.
If you are developing a very complex Java program, it's a good idea to develop a lock.
However, what happens if the thread that calls the resetScore() method encounters.
Under those systems, another thread could wait forever when it tries.
But we are using the Lock interface instead of the synchronized keyword.
There is a simple way around this: we can use Java's finally clause to make sure.
By the way, this antideadlock behavior of the synchronized keyword is not.
When a thread encounters a runtime exception while it is.
Unfortunately, given Java's semantics, this problem is impossible to solve completely.
Since we cannot solve this problem completely, it may sometimes be better to use.
Since the Lock interface provides options for when a lock can't be grabbed; can we.
For example, if we need a resource but have an.
Alternatively, if we are unable to obtain the lock within a time limit, perhaps we can.
Unfortunately, using explicit locks in this fashion is more complex than using a lock.
To develop a lock hierarchy, we simply have to figure out the order in which.
To use timeouts, we need to design the application to.
We are actually designing multiple pathways to completion to avoid deadlock instead.
You must decide whether these types of benefits outweigh the added complexity of.
The problem with deadlock is that it causes the program to hang indefinitely.
Obviously, if a program hangs, deadlock may be the cause.
Figure 6-1 shows two cases of threads and locks waiting for each other.
This also means that if the thread deadlocks, it can.
The second case is of threads waiting to obtain a lock.
Furthermore, a lock can have many threads waiting for it to be free.
This means that if a lock deadlocks, it can block many waiting threads.
We have introduced many new terms here—we'll explain them before we move on.
We define a deadlocked lock as a lock that is owned by a thread that has deadlocked.
We define a deadlocked thread as a thread that is waiting for a deadlocked lock.
A deadlock occurs if the original thread needs to wait for any of.
We define a hard wait as a thread trying to acquire a lock by waiting indefinitely.
Assuming that we can keep track of all of the locks that are owned by a thread and.
Figure 6-2 shows a potential tree that is formed by.
In effect, each lock in the diagram is already waiting, whether.
Using this algorithm, here is an implementation of a deadlock-detecting lock:
Before we go into detail on this deadlock-detecting lock, it must be noted that this.
In terms of implementation, this class inherits from the Lock interface, so it may be.
It may not be possible to detect a loop if any of the locks are.
To use this class, replace all instances of ReentrantLock with.
This slows down your program, but when a deadlock is.
This list is not static; it holds all the thread.
The deadlock locks are added and removed from the registry by using the.
Since these methods are static—while the list is not—the list.
A deadlock is detected if the lock is already in the wait tree.
With the ability to detect deadlocks, we can now override the lock() method of the.
In that regard, our new lock() method is also minimally.
The first part of the lock() method is for nested locks.
There is no race condition for this case: only the owner.
And since there is no chance that the owner of the lock will change if the owner is the.
The second part of the lock() method is used to obtain new locks.
Otherwise, the thread is placed on the hard wait list for.
There is no reason to override the lock methods that accept a timeout since these are.
The interruptible lock request is disabled by routing it to the uninterruptible.
The reacquisition of the lock is a hard wait since the await() method can't.
If you've already examined the code, you'll notice that the implementation of the.
Instead, it simply performs a hard wait prior to waiting for the signal.
Furthermore, since it is not possible to cause a deadlock.
The condition variable just needs to allow the deadlock to be.
At this point, we are sure many readers have huge diagrams on their desk—or maybe.
We have tried to present it as simply as possible, but we are.
To help with this, the latest online copy of this.
To help further, here are answers to some possible questions.
As a warning, some of these questions are very obscure, so obscure that some.
The goal is to work out the scenarios to understand the questions, which can.
We have stated that a deadlock condition is detected when a loop in the wait tree is.
That's because a thread can't perform a hard wait on more than one lock.
Any owned lock node can have only one parent thread node.
Why are we using only the thread tree? What about the lock tree? These questions.
Fortunately, we don't have to traverse the lock tree because the thread tree is.
It is not possible for this thread to be currently waiting.
Isn't marking the hard wait prior to checking for the deadlock condition a problem?
Can it cause spurious deadlock exceptions? The answer is no.
We are connecting the lock node to the top thread node—the.
This connection is seen from the lock tree but is not a problem because that tree.
Traversals by other threads will be detected early as a deadlock.
Can marking the hard wait first cause an error condition in other threads? Will it cause.
The answer to this question is no, it can't cause an error condition.
If a loop is formed, only the thread represented by the top thread node can.
This answer assumes that a deadlock-detected exception has never been thrown; this.
A better way to envision it is to treat the operations as.
Since the reacquisition is mandatory (i.e., it will eventually occur), we mark the.
This is just an artifact of examining the wait tree from.
From that perspective, we can use either the ownership state or hard wait state for.
Why don't we have to check for potential deadlocks on the condition variable side? It.
Marking for the wait operation prior to unlocking works in a pseudo.
Another explanation is that there is no need to check because we already.
Isn't marking for the hard wait prior to performing the await() operation a problem?
Can it cause spurious deadlock exceptions? Can it cause an error condition in other.
The extra question here addresses the issue of interfering with the.
That question doesn't apply on the lock() method side because we.
However, the answers to the other questions are not exactly the same as before.
We are creating a temporary loop—a loop that is created even.
Second, the one thread node that is within this small loop is not performing.
And finally, any deadlock check does not traverse the lock tree.
This means that an error condition can't occur in another thread and that detecting a.
It is not possible for another thread to own the lock unless the condition.
To review, we are traversing the thread tree to check whether the lock tree is a.
Instead of recursively traversing from the thread tree, isn't it easier to.
Unfortunately, there are two bad points to traversing upward from the lock tree.
In comparison, moving downward from the lock node to the thread node is.
The second bad point stems from the techniques that we use to solve the race.
We just need to terminate the search if the top lock node is found.
Also note that finding the top lock node is not an indication of a deadlock condition.
To review, we are traversing the thread tree instead of the lock tree because the top.
The top lock node may not be the root node.
However, what if the top lock node is also the root node? Isn't this a shortcut in the.
It is not possible for the lock tree to be a subtree of the.
However, a race condition exists when a lock has no owner.
This race condition is not a problem since it is not possible for any lock in the wait tree.
This shortcut is mostly for locks that are infrequently used.
The modification with some deadlock checking removed is available online in our.
This change is also provided online in our alternate deadlock-detecting lock class.
The deadlock-detecting lock regards all lock requests with a timeout as soft locks.
What if we do not agree with this premise? This topic is open to debate.
When the timeout period is more than an hour? A day? A month? Obviously, these.
Here is an implementation of the tryLock() method that treats the request as a soft.
This change is also provided in the online examples as an alternative to the.
Its implementation is practically identical to that of the lock() method.
Again, the difference is that we now place all lock requests within a try-finally.
This allows the method to clean up after the request, regardless if it exits.
This example treats the operation as a soft wait for requests.
While the deadlock-detecting lock is well-designed for detecting the deadlock.
This class is not designed to be used in a.
The main purpose of this class is so that we can understand.
The class can be designed to fail fast—meaning that if a.
A third, and not recommended, option is to allow the class to continue.
The first and third options are provided as conditional code in the.
This topic of deadlock detection seems to be incredibly complex.
ReentrantLock class is implemented with minimal synchronization, making the class.
Whenever multiple threads compete for a scarce resource, there is the danger of.
Lock starvation is similar to CPU starvation in that the thread is unable to execute.
Lock starvation occurs when a particular thread attempts to acquire a lock and never.
Lock starvation is not something most threaded Java programs need to consider.
Lock starvation also involves the question of fairness: at certain.
Consider the case of two threads competing for a lock.
At time T0, both thread A and thread B are able to run, and thread A is the.
Thread A is still the currently running thread, and it acquires the object lock.
A timeslice occurs; this causes thread B to become the currently running.
Very soon after becoming the currently running thread, thread B attempts to.
Thread A once again enters the synchronized block and acquires the lock.
It's possible for this cycle to continue forever such that thread B can never acquire the.
Clearly, this example is a pathological case: CPU scheduling must occur only during.
With several threads, however, it's not out of the question.
At first glance, we might expect this not to be a problem; other threads can't starve.
When a thread attempts to acquire a lock, it does not check to see if another.
For threads of equal priority, there's nothing in this process that prevents a.
When a lock is released, any threads that were blocked waiting for that lock.
However, no actual scheduling occurs, so none of the threads that.
This lock becomes the scarce resource for which some threads may.
If, for example, we're calculating a big matrix, there's probably a point.
All of the properties of lock starvation stem from the fact that a thread attempting to.
Fortunately, this problem has already been solved by the ReentrantLock class.
ReentrantLock class with its fairness flag set grants the lock on very close to a.
Unfortunately, the downside to using the ReentrantLock class in this manner is that.
Programs that set thread priorities do so for a reason.
Lock starvation is a rare problem; it happens only under very distinct circumstances.
While it can be easily fixed with the ReentrantLock class, it may also change some of.
On the other hand, if priorities and scheduling are not a.
Generally, reader/writer locks are used when there are many more readers than.
This is why the reader/writer lock is needed—to share data.
To solve this, the reader/writer lock does not grant the read lock to a new thread if.
Instead it places the reader into a wait state until.
The strong integration of locks into the Java language and API is very useful for.
While it is not possible to have a program threaded.
Here are the class names and Ant targets for the examples in this chapter:
The second test uses three threads and three competing locks.
The Swing classes in Java are not threadsafe; if you access a Swing object from.
To deal with this situation, you must make sure that you access.
The general principles of this chapter apply to other thread-unsafe objects:
We'll start with a general discussion of the threads that Swing creates automatically.
In doing so, we'll (finally) explain the last pieces of our typing program.
If you're interested in the general case of how to deal with a set of classes that are not.
Access to all Swing objects must occur from this thread.
The reason for this is that Swing objects have complex inner state that Swing itself.
If the user is in the middle of changing the.
Therefore, the second thread must arrange for the event-dispatching thread to read.
Note that it's not enough for our second thread simply to synchronize access to the.
It may seem like this restriction is overkill: the value of a JSlider is a single variable.
Even the simplest of Swing components contain complex state; it's.
Consequently, all calls to Swing objects must be made on the event-dispatching.
That's the thread that Swing uses internally to change the state of its objects;
Swing objects that have not been displayed can be created and manipulated.
That means you can create your GUI objects in any thread but.
The invokeAndWait() method can be called from any thread other than the.
As we mentioned, all the event callbacks of your program occur on the.
This is good news since it means that most of the code that.
In our sample typing program, we access Swing components from these methods:
To write a threadsafe Swing program, we must make sure that the methods listed.
The Swing classes have already made sure that all callbacks occur on the.
Finally, the setScore() method accesses Swing components only within the.
This is due to historical reasons, and you can use.
The invokeLater() and invokeAndWait() methods allow you to define a task and.
It can also be called when the random character generator.
The invokeLater() method takes a Runnable object as its parameter.
Note that the run() method is in its own object.
For the most part, the invokeAndWait() method looks similar, but it has three.
On the other hand, the invokeAndWait() method is synchronous: it does not return.
As a rule of thumb, then, you should use the.
The second difference is that the invokeAndWait() method cannot itself be called.
The third difference is that the invokeAndWait() method can throw an.
If you have code that you want to take effect immediately and that might be called.
We could use that method in our ScoreLabel class like this:
There's another case when Swing programs and threads interact: a long-running.
While an event callback is executing, the rest of the GUI is.
If this happens for a long period of time, it can be very frustrating to.
If you're going to have a lot of tasks like this, though, the easiest thing to do is use a.
If you have a lot of tasks to execute in parallel, you.
Here's an example of how to take the first path and set up a thread in a long-running.
Suppose that in our type tester, the start method must log into a server in.
In fact, you want to give the user an option to cancel that operation in.
We've used all our Swing utilities and techniques in this example.
When the server gets an error or the user presses the Stop button, we need to tell the.
The Swing classes comprise one of the largest set of classes in the Java API.
This places a responsibility on the developer, who must make sure that she follows.
Swing's use of the invokeLater() method gives us a hint about how we might handle.
Here are the class names and Ant targets for the examples in this chapter:
In this chapter, we'll look at how threads interact with the collection classes provided.
We'll examine some synchronization issues and how they affect our choice.
Collection classes interact with Java threads in a few areas:
Collection classes may or may not be threadsafe, so threads that use those.
Not all collections have the same performance with regard to thread.
We begin this chapter with an overview of the collection classes; the overview.
In the beginning, Java provided only a few collection classes.
The controversial change introduced in JDK 1.2 is that most of the collection classes.
Two factors inform this decision: the performance of synchronization and the.
As we mentioned, the collection classes are based around a set of interfaces.
A list is an ordered set of data (e.g., an array)
A set is a collection of elements that are stored in no particular order.
A queue is an ordered set of data that is operated on in either last-in-first-out.
Here are some of the more common threadsafe collection classes:
A simple array, allowing index-based operations and random insertion and.
The Stack class extends the Vector class to provide the ability to treat the.
Objects can be pushed onto the stack or popped from the.
A simple array list that provides safe semantics for unsynchronized iterator.
A simple set that provides safe semantics for unsynchronized iterator access.
A bit set stores an array of boolean (1-bit) values.
A BitSet saves space compared to an array of booleans since the.
A class that implements a sorted (and ordered) set collection.
A class that implements a sorted (and ordered) map collection.
A class that implements a list and a queue collection, providing a doubly linked.
A set collection that sorts its items based on the order in which they are added.
A map collection that sorts its items based on the order in which they are.
Unlike all other maps, this class uses = for key comparison.
A specialized map collection that uses only Enum values as keys.
A FIFO queue that can be either bounded or unbounded.
A class that implements an unbounded queue with a time-based order.
Retrieval from the queue is based on the object whose getDelay() method.
When writing a multithreaded program, the most important question when using a.
In the simple case, you're going to use the collection.
In this case, using a vector is sufficient for our purposes.
A second option would be to use a thread-unsafe class (e.g., the ArrayList class)
In this example, it doesn't matter whether we synchronize on the collection object or.
Our third option is to use a synchronized version of the thread-unsafe collection class.
Most thread-unsafe collection classes have a synchronized counterpart that is.
The threadsafe collections are constructed by calling one of these static.
Any of these options protect access to the data held in the collection.
A more complex case arises when you need to perform multiple operations atomically.
In the previous section, we were able to use simple.
As a result, we could rely on the container to provide the synchronization.
We alluded to a race condition in the fireNewCharacter() method.
In other programs, that may not necessarily be the case.
Here we use thread-unsafe collections to hold the data and explicitly synchronize.
Hashtable collections in this code without also synchronizing as we did earlier.
Although retrieving a value from a hashtable is threadsafe, and replacing an element.
The moral of the story is that using a threadsafe collection does not guarantee the.
Many situations call for using each element of a collection.
We called the toArray() method, which returns an array containing every.
More generally, all collection classes implement one or more methods that return a.
That may or may not be a problem for your program; if it is a problem, the.
To use an enumeration of a collection that may also be used by multiple threads, you.
You could synchronize the method instead, as long as your collection is not used in.
The point is that the enumeration and all uses of the.
The safest way to use an iterator is to make sure its use is synchronized by its.
Modifying the collection while the iterator is active creates a.
This is an expensive operation, both in terms of time and memory usage.
These classes are designed for cases where modifications to the collection are rare.
With the copy-on-write classes, the copy is made whenever the.
Many collection classes are what we would term "thread-aware." They have many.
Some collections have an implementation that minimizes the need for.
Interfaces have been enhanced to handle issues related to threads better.
One of the more common patterns in threaded programming is the.
This pattern provides a clean separation that allows for better thread design and.
The producer/consumer pattern is common for threaded programs because it is easy.
We just need to provide a safe way to pass data from the.
Therefore, any threadsafe vector, list, or queue can be used.
The queue data type is perfect to use for this pattern since it has the.
The producer is implemented to run in a separate thread; it uses the queue to store.
We're using a blocking queue because we want the queue.
It blocks until a request is in the queue, at.
Notice that the producer and consumer threads are decoupled: the producer never.
More generally, we can vary the number of either based on performance.
The queue has also hidden all of the interesting thread code.
We chose to calculate a Fibonacci number in our test program because we used a.
If you have a multiprocessor machine, you can run the example with multiple.
So, which are the best collections to use? Obviously, no single answer fits all cases.
There is little performance benefit in using a nonsynchronized collection.
This may be surprising to many developers—for an understanding of the.
If there is contention, having race conditions is a more.
For algorithms with a lot of contention, consider using the concurrent.
If a program's algorithm fits into one of these interfaces, consider.
Queues are best for the producer/consumer model for many reasons.
When possible, try to minimize the use of explicit synchronization.
Iterators and other support methods that require tranversal of an entire.
This can be a problem when many threads are involved.
First, use these classes only when the number of elements in the collection is.
This is because of the time and size requirements of the copy-on-write.
Second, your program must not require that the collection have the.
Consider having an algorithm that uses segmented collections instead of a.
There is little difference between a set and a map.
Theoretically, a set and a map are different in a number of ways, but in terms.
In this chapter, we have examined how threads interact with Java's collection classes.
We've seen the synchronization requirements imposed by different classes and how.
Here are the class names and Ant targets for the examples in this chapter.
In the Ant script, the number of consumer threads is defined by this property:
In particular, the next few chapters discuss task scheduling and thread.
The key to understanding Java thread scheduling is to realize that a CPU is a scarce.
When two or more threads want to run on a single-processor machine, they.
Java virtual machine, or the operating system—to make sure that the CPU is shared.
The same is true whenever a program has more threads than.
In earlier examples, we didn't concern ourselves with this topic because, in those.
Most of the time, this thread isn't using a CPU because it's.
The topic of thread scheduling is a difficult one to address because the Java.
It provides guidelines that threads should be scheduled based on a thread's.
We'll start by looking at the basic principles of how threads are scheduled.
Let's start by looking at an example with some CPU-intensive threads.
We've made this class a Runnable object so that we can run multiple instances of it in.
Running this code with three threads produces this kind of output:
Notice that the last thread we created and started (Task 2)
Generally, we'd expect to see similar output on almost any Java virtual machine.
Certain virtual machines and operating systems, however, would produce this.
The total here takes about the same amount of time, but now they have run.
Another interesting fact about this output is that each individual task took less time.
In each of these examples, multiple threads compete for time on the CPU.
A Java virtual machine is required to implement a preemptive, priority-based.
The priority value is important because the contract between the Java virtual machine.
The contract with the operating system, however, is not absolute, which means.
Java's requirement for a priority-based, preemptive scheduling mechanism maps well.
Our first example, where the threads all complete at about the same time, is executed.
Let's examine how the scheduling process works in a little more detail.
A thread is in the runnable state once its start() method has been called.
A thread that is in the runnable state may not actually be running; it may be.
A thread that is running on a CPU is called a currently.
A thread that is blocked is one that cannot be run because it is waiting for.
We've seen APIs that also block, but internally those methods are all.
The basic process of thread scheduling is essentially the same whether it's performed.
We can conceive that a thread scheduler keeps track of all the threads on which it.
Let's see how this scheduling will occur with the example we show at the beginning of.
The threads that calculate a Fibonacci number never block: they move from the initial.
The second time that we run the program, the state of the threads follows the.
At that point, one of the task threads becomes the currently.
That explains the output that we see when we run the program for a second time:
The first time we run the example, we do so on a typical operating system.
That means when threads are waiting for the CPU, the operating system.
Java does not mandate that its threads be time-sliced, but most operating systems do.
There is often some confusion in terminology here: preemption is often confused.
In fact, preemption means only that a higher-priority thread runs.
They are typically subject to time-slicing, but that is not a.
When that thread changes to the exiting state, a second task thread changes to.
In the second case, the time transitions occur at a much shorter interval, on the order.
When an operating system schedules Java threads, it may choose to run a.
In a typical priority-based threading system, something unusual occurs when a.
Suppose that we have a thread with a priority of 8 that.
The goal of priority inheritance is to allow the high-priority thread to run as soon as.
It is a common feature of operating systems, and Java virtual machines.
The second case involves the priority assigned to threads by the operating system.
This type of formula accounts for the length of time that the thread has been waiting.
After a sufficient amount of time has passed, a thread with a Java priority.
This gives the priority 3 thread an opportunity to run, even though it has.
Complex priorities are advantageous because they help to prevent thread starvation.
Without such a model, a low-priority thread would have to wait for all other.
With complex priorities, it can still run much less often.
On the other hand, complex priorities mean that you cannot guarantee thread.
In particular, you cannot use thread priorities to try and prevent race.
The Thread class contains a number of methods and variables related to thread.
The setPriority() method changes the priority of a particular thread.
In the Java Thread class, three static final variables define the allowable range of.
The symbolic definition of priority constants is not necessarily useful.
Unfortunately, that logic doesn't apply in the case of thread priorities: if we have to.
Because of the way in which these values map to.
If you really want to work with Java's full range of priorities, the.
On the other hand, not all operating systems support 10 distinct levels of thread.
The best we can do for portable applications is to use the three symbolic.
What happens when we run this program is very dependent on the operating system.
We'll discuss that effect for several popular platforms in the.
The Thread class also includes a yield() method, which asks the host operating.
On the green thread model (see the next section), the yield( )
We'll now look at how all of this plays out in the implementation of the Java virtual.
But we stress that these details actually matter in very few cases.
The first model that we'll look at is the simplest.
Each thread in this model is an abstraction within the virtual machine: the virtual.
As far as the operating system is concerned, the virtual.
This model is known in Java as the green thread model.
In most operating systems, the operating system is logically divided into two.
When a program running at user level wants to read a file; for example, it.
Because of this separation, it is possible to have support for threads at the.
In the early days of Java, the green thread model was fairly common, particularly on.
The green thread model is completely deterministic with respect to scheduling.
Task 4 gets to run occasionally when the main thread is blocked, and it eventually.
In the native-threading model used on 32-bit Windows operating systems, the OS is.
This model is usually simple to understand because every thread can be thought of as.
The OS scheduler makes no real distinction in this case between a process.
Windows operating systems use a complex priority calculation to determine which.
This is very similar to the Java-level thread priority between.
Different implementations of the virtual machine do this differently, but one common.
On this implementation, a thread with a Java priority of 3 and one with a Java priority.
However, scheduling classes are not easy to change, so they do not.
Windows operating systems also use a complex priority calculation that includes the.
The actual priority of a thread is based on its programmed (or inverted)
This value is subject to continual adjustment: the more time passes, the closer.
On another level, a thread that has not run for a very long time is given a.
The value of this boost decays over time as the.
The effect of this priority boost depends on the original priority of the.
Threads running in a program that has keyboard and mouse focus are given a.
The upshot of all this is that it's very difficult to guarantee explicitly ordered thread.
On Windows operating systems, the output of our priority-based thread calculation.
On this platform, the complex priority calculation places a great deal of emphasis on.
In fact, the highest priority tasks finish before some of the.
Recent versions of the Solaris Operating Environment have had two different.
Much of the flexibility of this model is lost on the Java.
In Solaris 9, a new one-to-one threading model is used.
In Solaris 8, both models are available, and the user picks a model when the Java.
For Java programs, the one-to-one model is highly preferable, particularly when the.
On Solaris 8, you specify the new threading model by.
On Solaris 7, you can mimic some of the benefits of Solaris' new threading model by.
The complex priority of a Solaris thread is determined by the following:
Running our priority-based calculator on Solaris produces this sort of output:
The lower-priority threads tend to start later than the higher-priority threads, but.
Until JDK 1.3, Linux-based virtual machines tended to use a green thread model.
Some used Linux's native threads, but the kernel support for those threads did not.
However, the Linux kernel at the time was not optimal for threaded.
The complex priority calculation for those threads is similar to.
Thread scheduling is a gray area of Java programming because actual scheduling.
In a general sense, threads have a priority, and threads with a higher-priority tend to.
For the most part, this thread scheduling doesn't matter: the information we've.
Here is the class name and Ant target for the example in this chapter:
The Fibonacci test requires command-line arguments that specify the number of.
For various reasons, thread pools are a very common tool in a multithreaded.
Most programs that use a lot of threads benefit in some way from.
The idea behind a thread pool is to set up a number of threads that sit idle, waiting for.
One of the idle threads in the pool takes the task and.
Thread pools have a maximum number of threads available to run these tasks.
Consequently, when you add a task to a thread pool, it might have to wait for an.
That may not sound encouraging, but it's at the core of why.
The first reason thread pools are often recommended is because it's felt that the.
The second reason for using a thread pool is very important: it allows for better.
If your program has a lot of tasks to execute, you can perform all the.
A thread pool allows you to delegate all the thread.
The primary reason to use a thread pool is that they carry important performance.
If you read that last sentence carefully, in the back of your mind you're probably.
In this case, we have three threads and one CPU.
Imagine that we have written this program as a server where each.
In our second example, we run the threads sequentially and see this output:
In this case, the total time to complete the calculation is still about 8 seconds, but.
This is what we mean by the throughput of the program.
Now consider what happens if additional requests come in while the server is.
If we create a new thread for every client, the server could quickly become.
On the other hand, if we run the requests sequentially using only one thread, the.
If a user is watching the image on screen, you might.
The similarity to programs like this and servers is that the results of each thread are.
The result of a single calculation is interesting to the client that requested.
In these cases, throttling the number of threads provides a better.
Clearly, parts of this discussion are contrived; we've selected the numbers in the best.
In the real world, requests arrive at the server in random.
Those things complicate using a thread pool, but they do not.
The fact that threads may block means that we need to have more threads than CPUs.
So far, we've considered cases where there is one CPU and have seen that.
Of course, you're unlikely to be able to model your program in such detail.
In the end, you'll need to run some tests to determine an appropriate size for.
But if CPU resources are sometimes scarce, throttling the number of.
If your program is doing batch processing, or simply providing a single answer or.
That doesn't mean that you can expect to create thousands.
Still, if your program design nicely separates into multiple threads and.
Thread pools are also not necessary when available CPU resources are adequate to.
Obviously, if your system has eight CPUs and you have only.
With a thread pool, you want to throttle the total number of threads so that they.
Java's implementation of thread pools is based on an executor.
Executors are a useful design pattern for multithreaded programs because they allow.
It also provides a task scheduling executor, which we examine.
This interface provides a means for you to manage the executor and its tasks.
So there's a period of time between calling the shutdown() or shutdownNow()
You can check to see if the executor service is in the terminated.
An executor service also allows you to handle many tasks in ways that the simple.
The invokeAll( ) methods execute all the tasks in the given.
The invokeAny() methods execute the tasks in the given collection, but.
To use a thread pool, you must do two things: you must create the tasks that the pool.
ExecutorService interface, which tells us how to feed it tasks and how to shut it.
We'll look at the other aspects of that class in this section, beginning with how.
The core pool size, maximum pool size, keep alive times, and so on control how the.
For now, we can use a constructor to create the tasks and put them in the thread.
In this example, we're using the tasks to calculate Fibonacci numbers as we do in.
When we're done, we gracefully shut down the pool; the.
The two fundamental things that affect a thread pool are its size and the queue used.
These are set in the constructor of the thread pool; the size can change.
The first set of methods deal with the thread pool's size, and the remaining methods.
The size of the thread pool varies between a given minimum (or core) and.
If you specify different numbers for the minimum and maximum number of.
The queue is the data structure used to hold tasks that are awaiting execution.
The choice of queue affects how certain tasks are scheduled.
The getQueue() method returns the queue, but you should use.
These parameters allow considerable flexibility in the way the thread pool operates.
The basic principle is that the thread pool tries to keep its minimum number of.
There are some nuances in this, particularly in how the queue interacts with the.
The thread pool is constructed with M core threads and N maximum threads.
If no tasks are on the queue, one of two things happens:
If a new task is queued within the timeout period, the.
If not, the thread exits, reducing the total number of.
What are the implications of all this? It means that the choice of pool size and.
Note that you can prevent rejection of a task if.
In this case, adding a task to the queue always.
As tasks are added to the pool, it creates threads until it.
This is perhaps the most common configuration of thread pools: it.
If you use a thread pool, there is no magic formula that you can use to determine its.
Depending on the type of queue you use in the thread pool, a task may be rejected by.
Tasks are rejected if the queue is full or if the shutdown( )
When a task is rejected, the thread pool calls the rejected execution handler.
There is one rejected execution handler for the entire pool; it applies to all potential.
You can write your own rejected execution handler, or you can use one of four.
This handler does not allow the new task to be scheduled when the queue is.
This handler executes the new task independently of the thread pool if the.
That is, rather than queuing the task and executing it in another.
This handler silently discards the oldest task in the queue and then queues the.
When used with a SynchronousQueue, there are never waiting tasks and.
If the pool has been shut down, the task is silently discarded.
To create your own rejected task handler, create a class that implements the.
The thread pool dynamically creates threads according to the size policies in effect.
When the pool creates a thread, it uses the currently installed thread pool factory to.
Creating and installing your own thread factory allows you to set up a custom.
The default thread factory creates a thread with the following characteristics:
New threads belong to the same thread group as the thread that created the.
However, the security manager policy can override this and place.
The name of the thread reflects its pool number and its thread number within.
Within a pool, threads are numbered consecutively beginning with 1;
The daemon status of the thread is the same as the status of the thread that.
Executors in general operate on tasks, which are objects that implement the.
In order to provide more control over tasks, Java also defines a.
Unlike a runnable object, a callable object can return a result or throw a checked.
When you ask an executor service to run a callable object, the service returns a.
Callable and future objects have a one-to-one correspondence: every callable object.
If the call() method throws an exception, the get() method.
The future object keeps track of the state of an embedded Callable object.
When the cancel() method is called, the corresponding callable object may be in one.
It may be waiting for execution, in which case its state is set to.
The callable object must still pay attention to this, periodically.
When an object in a thread pool is cancelled, there is no immediate effect: the object.
So, cancelling an object on a thread pool queue does not.
One way to deal with this situation is to call the purge() method on the thread pool.
The purge() method looks over the entire queue and removes any cancelled objects.
A better way to cancel objects with thread pools is to use the remove() method of the.
You can associate a Runnable object with a future result using the FutureTask class:
This class is used internally by the executor service: the object returned from the.
Future interface to monitor the status of the run() method of the embedded.
The get() method of a future task that embeds a callable task returns whatever is.
Swing classes are not threadsafe, so they must always be called.
In the case of Swing, that means that they must be called from.
What if you have a different library that isn't threadsafe and want to use the library in.
The methods of this class function exactly like their counterparts in the.
SwingUtilities class: the invokeLater() method runs its task asynchronously and.
In this chapter, we began exploration of executors: utilities that process Runnable.
The thread pool executor is one of two key executors in Java.
The combination of individual tasks and a lack of CPU resources is key to when to use.
The key to effectively using Java's thread pool implementation is to select an.
A little bit of work is required to get the most out of a.
But the rewards—both in terms of the simplification of program logic and.
Here are the class names and Ant targets for the examples in this chapter:
In the previous chapter, we examined an interesting aspect of threads.
With a thread pool, we were concerned with the task that we.
Using an executor allowed us to focus on our program's logic.
In this chapter, we examine this idea in another context.
Once again, they free us from many of the low-level.
Interestingly, this is not the first time that we have been concerned with when a task.
Previously, we've just considered the timing as part of the task.
We've seen tools that allow threads to wait for specific periods of time.
In our discussion of the Thread class, we examined the concept of a thread.
Our discussion of this method of the Thread class represents the first time that.
The wait() method of the Object class allows a thread to wait for any event.
This method also provides the option to return if a specific time period passes.
This allows the program to execute a task at a later time if the event occurs or.
This functionality is also emulated with condition variables using the.
This class is used to define a time period, allowing methods to specify a time.
This class also provides convenience methods to support certain periodic.
In effect, the task to process the data is to be.
As these examples show, in some cases, a program needs to execute code only after.
We've used these methods in our examples when a program needs to execute code.
Tasks to be executed by the Timer class must inherit from the TimerTask class.
TimerTask object so that two methods can be attached to the task; these methods.
The downside of this technique is that the task can't inherit from other classes.
The cancel() method is used to stop the class from being executed.
If the task is not running, it is the time at which the.
Its purpose is a bit obscure but it will make.
The Timer class provides the means to execute tasks at a later time.
Four constructors are provided to create different versions of the Timer class.
The other parameter is used to name the thread; this is important if the threads are.
The first two overloaded versions of the schedule() method are used to schedule.
The first allows for the specification of a delay: a time period in.
The last two overloaded versions of the schedule() method are used to schedule.
The third parameter is used to specify the period in milliseconds.
There are a few important issues in the timer implementation, particularly for.
This means that if the Timer object is overwhelmed, a task.
This is not very useful if the task is used to maintain a clock or other time-critical task.
This method can be used by the task itself to determine when the task is.
Based on the comparison to the current time, the task can adjust its.
Since the tasks are not allowed to drift, more than one.
For example, a task that runs every five seconds can tell if it has missed an.
We're more than five seconds off; skip this because another.
Table 11-1 shows when tasks would be executed under different scheduling models of.
In this example, we're assuming that the task is to be run every.
Neither takes into account the time required to execute the.
The cancel() method is provided by the Timer class to destroy the timer.
The Timer object can no longer be used to schedule any more tasks.
The task is deleted from the queue by the timer when it is time for the task to execute:
The purge() method is important only when a large number of.
Web sites that are reachable are displayed in green; web.
We start with the timer task that contacts the web site:
The run() method periodically contacts the given URL and then updates the status.
The program that sets up the task looks like this:
Also note that since a task cannot be reused, the.
This application points out the basic shortcomings of the Timer class.
Although our task uses timeouts to talk to the web server, it's conceivable that a.
That's the reason we put logic into the run() method of the task to check to see.
The alternative is to create a new timer for each panel.
The downside is that we now have one thread for.
As we've discussed, Swing objects cannot be accessed from arbitrary threads—which.
SwingUtilities class to overcome this, but Java also provides a Timer class just for.
Most of the methods provided by this class are used to.
This provides an interface that Swing developers are accustomed to: all.
This value is used by the timer as both the initial time to wait to fire the.
This allows the developer to get specific types of listeners that are registered to the.
In most cases, this is probably not very useful, as the limitation of the timer as.
The getDelay() and setDelay() methods are used to retrieve and modify the time.
The isRepeats() and setRepeats() methods are used to control whether events are.
By default, the timer repeats events, as this Timer class was originally.
This is important for tasks such as blinking the cursor.
The getLogTimers() and setLogTimers() methods are used to control debugging of.
If debugging is activated, messages are sent to standard output to report.
Finally, the timer must be activated upon completion of the registration of the.
The restart() method resets the timer: the timer then waits.
The isRunning() method is used to determine whether the timer has been.
Note that this implementation is much simpler than our previous implementations.
Previously, we set up a thread in the setDone() method; now, we simply call the.
Using the timer has also allowed us to simplify the locking around the calls to the.
Knowing when the animation should run used to require a.
The Timer class itself has the waiting logic within it: operationally, we haven't.
But in terms of development, using a timer has saved us some effort.
This is a clear example of why using higher-level thread constructs makes things.
This is not necessary: it is possible for the timer itself to maintain this information.
It is much more flexible to allow any Runnable object to be used as the.
Finally, relying upon the run() method is too restrictive for tasks.
These parameters are basically the same parameters as the thread pool.
Note, however, that the constructors have no parameter to specify the maximum.
The schedule() method is used to schedule a one-time task.
ScheduledFuture object returned by this method to perform the usual tasks on the.
For instance, this model is better for animation since there is.
Table 11-2 shows when tasks would be executed under different scheduling models of.
It does not compensate for the .5-second delay, so it drifts over time.
The execute() and submit() methods are used to schedule a task to run.
Still, it may be useful for one task to add other tasks to be run in the.
The shutdown() and shutdownNow() methods are also part of the thread pool class.
The shutdown() method is used to shut down the executor but allows all pending.
The shutdownNow() method is used to try to cancel the tasks in the.
Therefore, setting both to false empties the queue but allows currently running tasks.
This is similar to how the Timer class is shut down.
With the support of thread pools, callable tasks, and fixed delay support, you might.
First, it provides the option to specify an absolute time.
Timer class is simpler to use: it may be preferable if only a few tasks or repeated.
Here's a modification of our URL monitor that uses a scheduled executor.
The main enhancement that this change has bought us is the ability to specify a.
In this case, it would have been even more ideal for the task executor to.
The other case when using a scheduled executor makes sense is when you want to.
We'll extend our example slightly to see how this works.
In the absence of a valid license, we can set up a callable task that runs after.
After that task has run, we know that the license period has.
We'll have to poll the license task periodically to see whether it has finished.
In a more complicated case, the license task might check with a license server and.
IOException, which is why we've declared that this task throws that exception.
If we got a result, we know that the license has expired.
The checkLicense() method is called every time status is reported; it polls the.
When the poll succeeds, the checkLicense() method sets a done flag.
If you look carefully, you'll notice that there's no synchronization for the.
That blocks the event-dispatching thread so we are already assured that only one.
In this chapter, we've looked at various ways in which tasks may be scheduled in the.
Each instance of a timer is a single thread; that.
Because it uses a thread pool, it can be more.
The key benefit of task executors and timers is that they free you from having to.
Here are the class names and Ant targets for the examples in this chapter:
If you're not interested in parallel processing, the area where you're most likely to.
In most programs, blocking for that amount of time makes little difference, but.
A database server reads commands from a user, but the.
Because early versions of Java did not have a way to handle nonblocking I/O, Java.
Java clients would typically start a new thread to send requests to the server so that.
In JDK 1.4, this situation changed: Java introduced the NIO package, which allowed.
In this chapter, we look at servers that employ each type of I/O and show common.
Let's start with the simplest case, which is based on Java's original (blocking) I/O.
In this model, a network server must start a new thread for every client that.
We already know that by reading data from a socket in a.
Threading on the server side has an additional benefit: by having a thread associated.
This simplifies our server-side programming: we can code our classes as if we.
Before we show the code for the server, let's review some networking basics.
ServerSocket class is used to listen on a port known to the client.
Once a data connection has been negotiated, the server and client communicate.
Since the setup is generic, we can develop a generic TCPServer class that handles the.
Here's the implementation of this class, which serves as the.
The TCPServer class implements the Runnable interface; it creates multiple threads.
The logic to handle the clients is contained within the run() method.
When we first enter the run( ) method, the server variable is.
When a new connection has been accepted, we clone the TCPServer.
To start the server, you must call the startServer() method.
The stopServer() method is used to stop the server: it.
One more point about this implementation: you'll notice that the startServer() and.
If the client threads need to share data, they are.
For our first example, we'll subclass the TCPServer class to perform I/O within the.
We'll develop only the first part of that server, the part that sends a.
Developing a server like this depends on establishing a protocol between the client.
For our example, we use a simple protocol where messages are a single.
The WELCOME message must be sent by the server when it accepts a new client into.
Remember that the run() method in this class is called after a new connection has.
Each time it executes the readByte() method, it blocks until the client.
This class is also responsible for starting the server, which is a simple case of.
We've not provided any way to stop the server other.
Now we must develop the client side of our first example.
Put up a dialog box to alert user of error.
The only thread here is the one we've always had, which sends out the next character.
The primary issue when using the server we've just implemented is that it can handle.
Two factors limit the number of clients the server can.
First, the server can start only a certain number of threads.
To address these concerns, let's look at how to limit the number of threads that.
Using traditional I/O, we can set up a pool of threads to.
Our second example shows the server and client code to.
This approach works only for applications in which the client connections are.
It depends on the fact that the threads in the server do not block because.
Otherwise, if the scaling issues of traditional I/O are a problem for your.
The design pattern of this example is known as the leader-follower pattern.
It can then release the lock, and the next thread in line then obtains the.
To use this pattern, we must extend our TCPServer class:
Notice that our implementation is now much simpler because we no longer need to.
We establish a fixed number of threads in the startServer()
Each thread executes the run() method, where each in turn gets a client.
Because the thread itself operates on the socket, the server object no.
Handling only a single request has simplified this implementation as well.
Continually making new connections to the server can be a nuisance, as well as.
If the protocol of your application is such that messages flow.
When you need to handle a large number of clients making an arbitrary number of.
Because of this situation, Java introduced a new I/O package (java.nio) in JDK 1.4
The I/O classes in this package allow you to use nonblocking I/O.
Depending on the operations the server has to perform, it may need (or want) to.
Given this efficiency, why would you ever use the traditional I/O patterns we looked.
In other cases, however, the runtime efficiencies of the new I/O classes.
To understand the complexities we're facing, let's compare blocking and nonblocking.
The first four bytes make up an integer that indicates how much data the.
The remaining data is character data, the representation of which.
An application that wants to read this string first requests 2 bytes, calculates the.
As this data travels over the network, it may become fragmented.
Therefore, when the application requests the 17 bytes, it may get back only the few.
The difference between blocking and nonblocking I/O is in how this situation is.
With blocking I/O, the readUTF() method can just request the additional.
You can't immediately retry reading the data because it still may.
Worse, you'd lose any benefit of nonblocking I/O: if you're.
When you use nonblocking I/O, then, it's your responsibility to be prepared for this.
As a result, some of the data may be available immediately while the.
The situations we've described here are very similar to a race condition; they depend.
It's possible to write a server or other program using nonblocking I/O.
Now we'll develop our third example: a single-threaded network server that uses the.
As before, we'll develop a generic NIO server and the example server.
As a result, we can use the client from example 1 to connect to.
Our intent here is not to explain in great detail the NIO classes themselves; for a good.
The reason we can do this all in a single thread is that the I/O that occurs in the.
As before, we need to provide a subclass of this framework that handles the actual.
Here's how we'd write a subclass based on our typing server protocol:
Note the greatly increased complexity in this example from our multithreaded.
In the recv() method, we're reading all the data available from a client.
Our requests are a single byte long, so when I/O is available, we know that there's at.
Notice how we read this from a temporary buffer in.
In the send() method, we also check to make sure that we've written all the data.
Our new I/O server is very efficient at handling a large number of clients, but it may.
In other cases, we might have a handleClient() method that.
This situation is handled with a thread pool: as requests come into the server, the.
From a threading perspective, the interesting thing to note here is that the handling.
One point about using multiple threads and the new I/O classes: the buffers and.
Traditional I/O methods in Java can also block: we've seen how reading from a socket.
What is the effect of calling interrupt() on a thread that is blocked in I/O? The.
Linux, the interrupt() method causes the blocked I/O method to throw an.
So what's a programmer to do? The safest answer is not to rely on the interrupt()
If interruptible I/O as a generic feature is added to Java in the future, it will.
If you do rely on interruptible I/O, be aware that the I/O in question is not restartable:
The difficulty of dealing with the issue of restarting I/O that has been.
Under certain circumstances, you can still use the interrupt() method to close down.
What we've done in this class is to start two threads: one that is reading the data and.
Do other things until we need to shut down the reader ...
A concrete implementation of the interruptible reader might look like this:
Rather than going to all this effort, we might simply have closed the input stream.
Similarly, we might have written a shutdown() method in the.
The reason you might select this approach is that it keeps things consistent.
Using multiple threads well is very important in any Java program that performs a lot.
In the simplest case, I/O (and particularly socket I/O) may block at any point.
That model does not scale completely as the number of I/O sources grows.
In most other cases, you'll need to use the nonblocking features of Java's NIO classes.
Although these classes increase the complexity of your applications, they allow you to.
I/O can be mitigated somewhat by using multiple threads with nonblocking I/O; that.
Used judiciously, Java's threading and I/O models allow you great flexibility in.
Here are the class names and Ant targets for the examples in this chapter:
The single-threaded client (example 1) can be used with either single-threaded.
The interruptible client can be used with any type of.
To change ports and hostnames for the Ant targets, use these properties:
Some of these topics are interrelated: in particular, the thread group class is used by.
All threads belong to a thread group, which, as its name implies, is a group of threads.
Every thread we've looked at so far belongs to this.
Thread groups are more than just arbitrary groupings of threads; they are related to.
Every thread group has a parent thread group, so thread groups exist in.
The obvious exception to this, of course, is the root of the tree, which.
Figure 13-1 shows a sample thread hierarchy from a system running the.
In this figure, each applet is given its own thread which is started in its.
Some of the applets have created additional thread groups to.
Not all virtual machine-level threads have a corresponding Java thread object, so the system group does not.
You can create your own thread groups as well and make this hierarchy arbitrarily.
Thread groups are created just like any Java object; when you instantiate a.
If a security manager has been installed, the getThreadGroup() method of.
The interrupt() method is really the only method of the ThreadGroup class.
The second advantage of thread groups relates to thread security.
To make security decisions in this way, however, requires that you write a custom.
One of Java's hallmarks is that it is designed from the ground up with security in mind.
It's no surprise, then, that threads have a number of interesting security-related.
In its default configuration, security in a Java program is enforced by the security.
There is one method in the SecurityManager class that handles security policies for.
Checks if the current thread is allowed to modify the state of the thread t.
Checks if the current thread is allowed to modify the state of the thread group.
Like all methods in the SecurityManager class, these methods throw a.
SecurityException if they determine that performing the operation would violate.
As an example, here's a conflation of the code that the.
Assuming that no exception is thrown, an internal method is called that actually.
Both the Thread and ThreadGroup classes have an internal method called.
The checkAccess() method within the Thread and ThreadGroup classes is.
The checkAccess() method within the ThreadGroup class is final; it may not.
Because only one method in the SecurityManager class is used to check for security.
The checkAccess() method itself looks to see which thread group the target thread.
If the thread is not a member of the root thread group, the checkAccess()
Java security is normally determined via a series of policy files, including the files.
For thread access, code must be granted one of these two permissions:
When the checkAccess() method is called and each method presently on the stack.
By default, this permission is granted to all code, and the other thread permissions.
By default, then, threads can modify the state of any other thread (including itself)
However, the security policy of the Java virtual machine is quite flexible and can be.
For more details on how Java security works, including how you can override the.
A daemon thread is identical to a user thread in almost every way.
If we don't have any other threads running, however, there's nothing for the garbage.
So if the garbage collector is the only thread left running in the Java.
The daemon mode of a thread is set by calling the setDaemon() method with either.
By default, a thread is a user thread if it is created by a user thread; it is a daemon.
Classes in Java are loaded by a classloader object, which consults the directories and.
Despite the similarity of this hierarchy to the thread group hierarchy, the two are.
Threads can freely share classes that are loaded in other threads, no.
The context classloader is used to load classes (and resources) only in certain specific.
Developers often assume that the context classloader can be used to affect.
B, it attempts to load the code for class B from the same classloader that loaded class.
A (or one of that classloader's ancestors in the classloading hierarchy)
A classloader knows only about its ancestors, not its descendants.
The context classloader only comes into play with certain internal classes in the.
For example, when you pass serialized objects over IIOP, the ORB.
The reason a context classloader is needed in these circumstances is that the ORB.
Clearly, the application classes it needs to deserialize the object won't be.
This hook is unrelated to threading issues: the context classloader can be set and.
The default context classloader for a thread is the classloader that loaded the class.
The run() method is executed inside a context that allows the virtual.
All uncaught exceptions are handled by code outside of the run() method before the.
The default exception handler is a Java method; it can be.
This means that it is possible for a program to write a new default.
It is called only when an exception is thrown from the run()
The thread is technically completed when the run() method returns, even.
By the time the run() method has returned, it's too late to.
Here's an example that does that when its thread eventually encounters an.
Use Java Mail to send the administrator's pager an email.
When the out of memory error occurs, the application prints a message alerting the.
The static methods of the Thread class set or retrieve a default thread handler used.
When a thread is constructed, its exception handler is set to the.
By default, the exception handler for a thread is its thread group: the ThreadGroup.
The ThreadDeath class is a special Throwable class that was formerly used to stop a.
When the stop() method is called on a thread, that thread immediately.
After all, if we didn't want the thread to die, why was the stop()
The ThreadDeath class is what caused the stop() method to become deprecated.
Because it's thrown immediately upon receipt of the stop() method, it has the.
This leads us to one limited circumstance in which the ThreadDeath class is useful as.
The normal way to do this is to return from the run() method, but it.
Even so, a thread that wants to terminate itself cannot simply throw a ThreadDeath.
Still, you have to be very careful only to do this when it's.
Using this particular constructor can lead to unportable Java programs.
The stack is where a thread keeps track of information about the methods it's.
Let's look again at our class that calculates Fibonacci numbers:
When a thread executes the run() method of this class, it creates a stack frame.
When the run() method calls the fib() method, a new.
At some point, then, the stack resembles Figure 13-4: the run() method.
At this point, as the fib() method returns, frames are popped off the.
Stack frames contain more information than the local variables of a method: they.
In addition, the bookkeeping information for a stack is dependent on the Java.
The size of the stack (and the frames it holds) impacts Java's memory usage in two.
If we attempt to calculate fib(65536), we'll get a stack overflow error:
This is one case where you might want to use the stack-size argument to the.
The problem here is what value to pick for the stack size.
You may be able to figure out the first value in advance, but.
Allowing the user to specify the stack size for the thread through a.
In a number of cases, Java programs may throw an OutOfMemoryError.
It is also possible to get an out of memory error when you construct a thread.
But it's far more likely that the system cannot allocate space for the.
Java stacks are not stored in the Java heap; they are stored in the general memory of.
This effectively limits the number of threads that an application.
Suppose again that a default Java stack is 1024 KB.
On SPARC systems running Solaris, the maximum size of a process is 4 GB, leaving us.
So depending on the number of threads you need to create and the platform you're.
We've already mentioned that the stack size for a thread can be specified when the.
On many Java implementations, you can also specify the stack size for all threads.
This is a good technique to use when your application throws an out of memory error.
However, this argument is nonstandard, so it is not available in all Java.
The Thread class has four miscellaneous methods that provide information about a.
The countStackFrames() method can only be called on a thread that is suspended;
In this chapter, we've filled in a lot of the details about how threads work.
We've also looked at how threads handle uncaught exceptions: though they normally.
Here are the class names and Ant targets for the examples in this chapter:
In a few places in this book, we've referred to performance characteristics of.
We've glossed over a lot of that information; in this.
Most developers are concerned about the performance of their program.
Performance, however, is not the most important aspect in developing good.
Without any prior knowledge of a program's behavior, this is counterproductive.
Tony Hoare is credited with originating the quote "Premature optimization is the root of all evil," and Donald.
Make performance testing a regular part of the development cycle.
In an ideal situation, coding would go through a cycle shown in Figure 14-1
Measuring performance of a Java program presents certain difficulties, particularly.
If you're interested in measuring the performance of a long-running Java program.
Measuring performance in this situation requires a ramp-up time that allows the.
If you're writing a benchmark to test performance of a particular operation, you must.
In our tests (available in the online source), we execute certain methods a large.
We warm up the compiler by executing the method 10,000 times.
All of this is to say that the conclusions we draw here are based on the.
Differences in heap size reflect the underlying support of the operating system for the.
Let's look into some synchronization issues, starting with a question.
To reach this conclusion, we looked at the performance of adding objects to four kinds.
For a sufficiently large value of nLoops, taking the time to execute this method when.
Although the Vector and ArrayList classes are conceptually similar, their.
But if you're planning to use an unsynchronized collection class, access to.
If you really know that a particular data structure won't be accessed by more than one.
Next, let's look at the difference between using classes in the.
We'll see the benefits of doing that in this section.
Atomic variables offer advantages other than performance: they neatly encapsulate.
So quite apart from any performance benefit that they may or may not offer, their use.
For this test, we gauge the performance of incrementing an integer variable.
When there is only one thread running, the locks are uncontended, and we get similar.
When there are two threads, contention for the lock is introduced.
Much more interesting is what happens when many threads are contending for the.
Now the difference has been cut in half on Unix systems.
This is because the atomic variable methods loop until they achieve the desired result.
It's also interesting to note that this behavior is not observed on Windows Server.
In both tests, the Windows Server 2003 platform spends a great deal more.
An interesting case arises with the ConcurrentHashMap class, which allows threads to.
In fact, as CPUs get faster, the simpler implementation of the.
As we add contention, the Hashtable class pays the predictable penalty, and now the.
Because of the "optimistic" nature of the concurrent hashmap, the.
Server 2003 again, where the added lock contention in the operating system.
The final performance aspect we'll discuss is thread creation and the use of thread.
A common assumption is that creating a thread is an expensive operation and.
And the perceived performance of a program can often be improved.
That said, is it really more efficient to use a thread pool than to spawn a new thread?
The answer is yes, but not always to an extent that it affects your program.
We run this method three different ways: in a simple loop, in a Runnable.
Subtracting the time required to execute the method in a loop from the time.
Test platform Time difference between thread creation and thread pool.
A few hundred microseconds is nothing to sneeze at in computer time.
In many programs this additional overhead does not make a big difference.
On the other hand, our program doesn't do anything interesting at all.
At some point, the added time to create the threads becomes lost in.
The moral of the story is if you need to spawn a few threads, don't sweat it.
Performance is an overriding concern for many developers, and performance of.
It's important to measure your particular program to see if these issues affect it.
The online examples have our test code and can be run with the following classes or.
In previous chapters, we examined threading as a technique that allows us to simplify.
Since the operating system can place different threads on different.
In this chapter, we'll look at how to parallelize Java programs so that they run faster.
How does the Java threading system behave in a multiprocessor system? There are.
The real difference is that the threads actually do execute.
For Java developers, threaded code running on multiple processors means that race.
Testing those programs on a multiprocessor machine is one good way to.
Without redesigning a program, the best area to parallelize—that is, the area in which.
After all, it doesn't make sense to bring in more processors if.
CPU-bound—that is, the process is using all of the computer processors' cycles while.
Furthermore, these calculations probably involve a large control loop or.
This code is the basis of our examples in the rest of this chapter.
Considering the cost of a 12-processor machine, this is not acceptable.
Obviously, it exists only for the duration of the loop.
The terminology used in this chapter is based on the terminology used by the.
Automatic parallelization is the same technique that we are describing in this.
This is due to the aliasing problems with the C language:
In this regard, Java is closer to FORTRAN than to C.
Furthermore, we can state that the index variable i is also a loop-private variable: it.
Since it is never changed during an iteration and is directly.
However, for now, simply considering it as a loop-private variable is good.
We may try to break the parts of this loop among many threads as follows:
The code in this new version is functionally the same as the previous version, albeit.
The original mathematical calculation is moved to a new method, loopDoRange()
Second, although the lookupTable array is not loop private, the individual members.
The only synchronization we need is in the assignment of the different ranges.
The code for this new version is more complicated than our first version.
Given the complexity we introduced to handle this simple loop, it may become too.
In our new LoopHandler class, we have implemented the logic that we applied in our.
The logic of creating, tracking, and joining back with the original.
Just as in our earlier example, the algorithm calls the loopDoRange()
Now our implementation of the SinTable class is much simpler:
In this case, we simply configure the ranges needed by the loop handler, provide the.
We define the process of distributing the iterations of the loop to the individual.
Under static scheduling, each thread is assigned an equal number of iterations that.
This is the algorithm that is used by the LoopHandler class.
Otherwise, there might be an iteration left over and a worker thread would have to.
The problem with this algorithm is that it assumes that each iteration of the loop takes.
If this is not true, one of the threads takes more time than.
Since all the work is divided up at the beginning of the.
In self-scheduling, each worker thread grabs a small chunk of the iterations to.
After completion of its assigned range, it grabs another small chunk.
As with static scheduling, the different worker threads may not complete at the same.
However, since the chunks are small in the self-scheduling model, the idle time.
LoopHandler class already has the logic of working until the loop completes.
Note that we've started extending the PoolLoopHandler class, which is functionally equivalent to the.
Guided self-scheduling is a compromise between the static scheduler and the.
In the beginning, the guided scheduler grabs a large number of.
Implementation of a guided self-scheduling loop handler is also straightforward.
The implementation of the self-scheduler and the guided self-scheduler is simple for.
To use any of these other algorithms in our SinTable class, we simply subclass from.
In the implementation of the SinTable class, we classify the variables used in the.
The reason for classifying variables at all is that different types of variables.
A loop-private variable is a variable that does not pass its value from one iteration of.
It can actually be a variable that is declared in the loop itself, and.
This is the case with the lookupValues array variable, where.
As shown with the SinTable class, loop-private variables are often handled with a.
Read-only variables are variables where values do not change during the execution of.
They can be true constants or simply variables that are initialized and do not.
Storeback variables are basically loop-private variables that are needed after the loop.
In this slightly modified version of the SinTable loop, both the sinValue variable and.
These two variables have no data dependency in different iterations of the loop.
However, in this case the sinValue variable is also a storeback variable.
The sinValue variable is still treated as a loop-private variable.
Since the algorithm is now executed in a multithreaded manner, the last iteration is.
A thread must check that it has executed the last chunk of the loop before copying the.
Since only the last iteration is copied, only one thread is executing the.
Obviously, it is not possible to make every variable a loop-private variable since there.
Because of these data dependencies, different threads executing different iterations.
However, what if the order does not matter? We will be able to process the loop in any.
In this case, the sumValue variable is clearly not a loop-private variable.
However, the sumValue variable is useful only after the loop.
The iterations simply add to the running total—subtotals or other.
In the examples of this section, we assume that we can perform the addition.
If you're performing sensitive numerical analysis, be aware that the tricks of.
Race conditions in this example are prevented by using the synchronization lock of.
If we have many reduction variables that are not dependent.
Furthermore, we are synchronizing with each iteration of the loop.
It is better to assign the value to loop-private variables and only synchronize.
In this new example, we are doing a two-stage reduction of the values.
Synchronization is still necessary when adding to the reduction variable.
A reduction variable is a good candidate for an atomic variable.
We'll test this later in the chapter, and you can consult the online source.
Originally, all variables in the loop are shared variables since all variables can be.
Unfortunately, in some cases a shared variable cannot be classified as anything but a.
The other problem with shared variables is the side effect.
When variable classification is not enough for parallelization, we have other.
They may not solve every case, but with experience, more.
To assist our parallelizing techniques, we can analyze the algorithms of the loop itself.
In many cases, only a small portion of a large complex loop contains code that must.
It may be possible to separate the large complex loop into.
Once the complex loop is separated into two loops—one loop.
Returning to our SinTable example, let's assume that we need to generate a running.
While it is not possible to parallelize the running subtotal without drastically changing.
This separate loop runs on a single thread, only after the first loop is processed.
In most cases, calculations of the subtotal are small considering the.
Although the many loops may be very complex, with large data dependencies.
It may be possible to isolate the individual loops themselves and run them each in a.
Multilayered loops are a prime cause of CPU-bound applications that run for a long.
This could be loops that are directly inside of other loops or, more.
For multilayered loops, it is generally more profitable to thread the outer loop instead.
It is not necessary to thread both the inner and outer loop because.
In this new version of the table calculation, we are now working on a two-dimensional.
The problem in this case is a data dependency between the rows themselves.
The inner loop can be parallelized with no problem since there.
However, we could also rewrite our original code as follows:
The inner loop can then process the data from row.
By interchanging the loops, the inner loop is no longer threadable because of.
Unfortunately, although loops within loops are common, this example may not be.
There is generally setup code for an inner loop, and there may be multiple loops that.
Having an inner loop that is threadable in an outer loop that is not threadable is.
We examine inner-loop threading in more detail later in this chapter.
As you may have noticed, the loop handler that we have developed is fairly restrictive.
While some of these restrictions are because we have not implemented.
If all else fails during loop transformation, programming experience is still very useful.
A while or a do loop may be converted to a for loop.
The issues that we have discussed so far do not change when the loops are nested: if.
As mentioned, a loop interchange should allow the outer loop to be.
However, instead of the loop transformation, let's try to thread the inner.
The first variable to classify is the outer-loop-index variable, j.
At first glance, this does not make sense: how could an index variable be.
While the lookupValues array variable is a shared variable, the elements can be.
Since each iteration of the loop accesses a different member.
Since we are not creating a local copy of these.
The last two variables—sinValue and i—are simply classified as loop-private.
The loop scheduler is chosen by examining the algorithm inside the inner loop itself.
In this case, there is nothing that should cause any iteration to execute longer than.
However, there should be no harm in choosing either the self- or guided.
Once these tasks are completed, the loop is threaded by using the loop handler as.
However, a slight complication arises: compared with the outer loop, the inner.
Furthermore, the loop handler is designed as a "one use"
A new loop handler must be created for each iteration of the outer loop.
Although using the loop handler works without any problems, the overhead may be.
The fact that our original LoopHandler class can be used only once is merely a design.
The loop index can never be set back to the start of the loop nor can the range.
To fix this, we simply add two new methods, reset() and.
To avoid creating a lot of threads, we use the thread pool executor we.
Prior to threading any loop, we should always examine that loop.
When moving from the outer loop to the inner loop, we must examine the.
Just because the outer loop is a candidate for threading does not.
We can implement other scheduling models in the pool handler quite easily:
What's interesting here is the similarity to our original SelfLoopHandler class.
However, to be more configurable, we have modified the handler to allow the extra.
To implement the SinTable class, we place the code from the inner loop in the.
Since the j index variable is a read-only shared variable, it is now an.
Having a loop handler that can be used more than once is also very important.
The task of sending a string to a file or the display is an I/O-bound task.
However, what if the printing portion of the loop is small when compared with the.
The only problem that needs to be solved is the ordering of the output.
In this new version of the getValues() method, we are also printing the table to.
Obviously, this simple example can be transformed with a loop.
This output index could be related to the index of the.
In any case, an output index should not be assigned to more than one.
Technically, we could have done the same thing with a single-dimensional array of string buffers.
Printing an object to the virtual display is done with the print() and println()
Along with the object to be printed, the program must supply an index as a.
The loop printer is created prior to the loop, all printing that was previously sent to a.
Since the loop printer sends all the information to one.
Also note that we constructed the loop printer with the index size as its initial size.
We want to avoid expanding the size because this operation not only requires the.
Second, it allows the methods to work—although the print order is no.
When the output cannot be increased no matter how many.
If the oven cannot produce more bagels per hour, it does not matter how.
The scaling limit can also be controlled by many other.
In this chapter, when we refer to the scalability of a multithreaded program, we are.
Adding more than this limit does not make the program run faster.
The best a program can scale is based on the scalability limits of.
For perfect CPU-bound programs in a perfect world, we could expect perfect scaling:
A certain amount of time is required to execute the code outside of the loop.
This amount of time is independent of the number of.
In parallelizing the loops of this chapter, we've introduced some additional.
Some methods in our parallelized code must run sequentially because they are.
One of the factors that can affect the scalability of a particular program is the.
If we view the setup time, synchronization time, and time required to execute the.
Here, S is the scaling we'll see, assuming that F% of code is parallelized over N.
What sort of scaling can we expect from the techniques of this chapter? To answer.
To make testing easier, we use the following class and interface to build a system by.
When we use the ScaleTest class, we get two numbers: the number of milliseconds.
In the remainder of this section, we'll develop examples that use this class to see the.
In this example, we'll explore how various loop handlers affect parallelization.
This class contains no threading; it is the way that we would normally implement the.
This class uses our simple loop handler to process the loop; notice, however, that.
Table 15-1 lists the results of the ScaleTest program when run with different.
The overhead of setting up the thread and loop handling class itself is.
We would not want to use this technique on a.
Going past eight threads—that is, the number of CPUs available—yields a.
The guided self-scheduler is the best choice in this example.
What effect does a reduction variable have in our testing? In our next series of tests.
Because there's only one reduction variable, the effect on scaling is minor.
However, the effect of many reduction variables could potentially aggregate into.
We did no better—in fact, slightly worse—by replacing the synchronized call to the.
What if we had threaded only the inner loop? This question is interesting since it.
As shown in example 12 in the online archive, we.
In this test, we start out with some scaling, through about four CPUs.
CPUs, however, we're not seeing the same scaling as in our previous tests.
This effect becomes even more pronounced if we run with a smaller inner loop size.
As we mentioned, threading of small loops—and particularly of small inner loops—is.
What if we add code to the loop that prints out the result of some calculations? We can.
However, remember that we ended our section on the LoopPrinter class with a.
This version of the loop printer eliminates the synchronization of our first.
There is still some synchronization when adding the string to the.
However, the difference between our threadsafe and thread-unsafe versions of this.
Table 15-4 lists the results that we obtained for both cases cases.
The numbers in this table are obtained from printing out the result of every 20th.
Even when the loop printer class is not synchronized, the extra overhead.
It's interesting to compare these results to a case in which we print out only every.
We get better scalability here, though still clearly worse than when we had no printing.
The lesson here is clear: when you want to get the most benefit out of running.
In this chapter, we examined techniques that allow us to utilize multiprocessor.
The goals here are to write fast programs from the start, to increase the performance.
The first nine SinTable classes we showed should mainly be used as a reference.
They contain testing code, but the printed output isn't as interesting as the code itself.
Examples 10-13 are somewhat different from the examples from earlier chapters.
These examples are used for the tests that produced the tables in this chapter.
For the ScaleTest class, the class name argument appears in table listings earlier in.
Readers of previous editions of this book will have noticed that many of the classes we.
While these libraries can still be used, it is recommended that.
While the examples in the previous edition of this book are now obsolete, there are a.
Still, for research purposes, there is advantage in examining them.
So for those who may be interested, here is a quick review of our obsolete classes.
The BusyFlag class implements a basic, no-frills, mutually exclusive lock.
Simplistically, the purpose of this class is to use Java's basic synchronization.
It grabs the busy flag if it is available while.
The getBusyFlag() method uses the tryGetBusyFlag() method to repeatedly try.
And if the counter is zero, this method declares that.
The getBusyFlagOwner() method is merely an administration method that allows a.
You must own the lock in order to use this method.
You must own the lock in order to use this method.
You must own the lock in order to use this method.
The CondVar class implements a basic condition variable for use with the BusyFlag.
The purpose of this class is to allow Java's wait-and-notify mechanism to work with.
It also allows a single lock to have more than.
The CondVar class provides four methods for waiting for notification; three of these.
This method frees the ownership of the busy flag completely.
Also note that it may still wait upon receiving notification as it can still block while.
Two of the convenience methods allow the program to specify a timeout or wait.
The last one allows you to specify an alternate busy flag class—a flag that.
Condition class, a common Lock object could be created just for notification between.
The cvSignal() method is used to send a single notification—using the notify()
As with the wait methods, it is overloaded to allow the program to specify an.
The cvBroadcast() method is used to send notifications to all the.
The Barrier class is a basic, no-frills implementation of a barrier.
The last thread to reach the barrier is assigned the value of zero, and.
Here is an implementation of the RWLock (reader/writer lock) class:
The interface to the reader-writer lock is very simple: there's a lockRead() method.
This is to allow the RWLock class to order the requests for.
Because we need to keep track of how each thread wants to acquire the.
This is the RWNode class; our waiters vector holds elements.
Acquisition of the read lock is done in an orderly manner—the RWLock class doesn't.
If the nodes that are ahead of the current thread in the waiters queue want.
Acquisition of the write lock is stricter: we must be in position zero in the vector.
Both acquisition methods must check to see if there is already a node.
Finally, the reader-writer lock class contains some methods to search the waiters.
The ThreadPool class implements a thread pool—similar to the thread pool executor.
Each thread waits for work; when it is signaled, it simply pulls the first.
As a result, this code has three waiting points :
A CondVar object (i.e., a condition variable), cvAvailable, is associated with.
This condition is used to signal that work is available to be.
A CondVar object, cvEmpty, is also associated with the same cvBusyFlag.
We use condition variables for the last two cases because they share the same lock.
Note that objects that are to be run by the thread pool are expected to implement the.
Interestingly enough, there is no way to shut down a thread pool automatically.
And because they have a reference to the thread pool itself, the thread pool cannot be.
Then, when the thread pool has run all of its.
Here is an implementation of the JobScheduler class to execute a task:
The JobScheduler class implements a time-based execution system—similar to the.
This option is useful if the job is a long-term task or for a job.
The class is designed to be as simple—and as basic—as possible: the class just.
In addition, we need to find the time for the job that is due to run.
For completeness, we've added a little complexity in our JobScheduler class.
In our JobScheduler class, this is all handled by a single thread that calls the.
The task of deciding whether the job needs to be executed again.
Most of the logic for the JobScheduler class is actually the.
Used for a job that is to be executed once; simply runs the job.
Used for a job that is to be executed once; runs the job after the specified.
Used for a job that is to be executed once; runs the job at the time specified.
No error is generated if the job is not in the.
As rich as the set of methods provided by this class, it can be considered weak in.
In those systems, developers can specify criteria such as day of the week, day of the.
DaemonLock class is to allow the job scheduler to shut down gracefully.
We accomplish this by making the threads in the job scheduler daemon threads; that.
In a way, this appendix is like a history lesson: we have just reviewed the major.
Our look is the result of reader comments, our own experimentation, and feedback.
The animal on the cover of Java Threads, Third Edition is a marine invertebrate.
Invertebrates, or animals without backbones, make up over 97 percent of all animal.
One of the most intelligent animals in the sea, the octopus, is also an.
Many invertebrates have protective shells to shield them from hungry, razor-toothed.
You may think that invertebrates without shells would be particularly.
Though you may not realize it, marine invertebrates are quite beneficial to humans.
Emma Colby designed the cover of this book, based on a series design by Edie.
The cover image is a 19th-century engraving from the Dover Pictorial.
Emma Colby produced the cover layout with QuarkXPress 4.1 using Adobe's.
Linotype Birka; the heading font is Adobe Myriad Condensed; and the code font is.
