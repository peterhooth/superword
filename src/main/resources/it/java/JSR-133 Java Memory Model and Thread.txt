This document is the public review version of the JSR-133 specification, the Java Memory Model (JMM) and Thread Specification.
The current document has been written generically to apply to both, the final version will include two different versions, essentially identical in semantics but using the appropriate terminology for each.
The discussion and development of this specification has been unusually detailed and technical, involving insights and advances in a number of academic topics.
This discussion is archived (and continues) at the JMM web site.
The web site provides additional information that may help in understanding how this specification was arrived at; it is located at http://www.cs.umd.edu/~pugh/java/memoryModel.
The existing chapters of the JLS and JVMS specify semantics that are at odds with optimizations performed by many existing JVMs.
The proposed core semantics should not cause issues for existing JVM implementations, although they could conceivably limit potential future optimizations and implementations.
Since the community review period, several changes have been implemented.
Issues involving the interaction of wait, notify and interrupt have been resolved.
In addition, implementations are now permitted to reject classfiles based on some of the behaviors of final fields.
This is the one place most likely to require JVM implementors to change their implementation to be compliant with JSR-133
In particular, memory barriers or other techniques may be required to ensure that other threads see the correct values for final fields of immutable objects, even in the presence of data races.
When is Thread 3 guaranteed to see the correct value for final field b.f?
Final field example where Reference to object is read twice.
Bytes must not be overwritten by writes to adjacent bytes.
The only way for a user to create a thread is to create an object of this class; each Java thread is associated with such an object.
A thread will start when the start() method is invoked on the corresponding Thread object.
The behavior of threads, particularly when not correctly synchronized, can be confusing and counterintuitive.
This specification describes the semantics of multithreaded Java programs, including rules for which values may be seen by a read of shared memory that is updated by multiple threads.
As the specification is similar to the memory models for different hardware architectures, these semantics are referred to as the Java memory model.
These semantics do not describe how a multithreaded program should be executed.
Rather, they describe only the behaviors that are allowed by multithreaded programs.
Any execution strategy that generates only allowed behaviors is an acceptable execution strategy.
The most basic of these methods is synchronization, which is implemented using monitors.
Each object in Java is associated with a monitor, which a thread can lock or unlock.
Only one thread at a time may hold a lock on a monitor.
Any other threads attempting to lock that monitor are blocked until they can obtain a lock on that monitor.
A thread t may lock a particular monitor multiple times; each unlock reverses the effect of one lock operation.
The Java programming language does not provide a way to perform separate lock and unlock actions; instead, they are implicitly performed by high-level constructs that always arrange to pair such actions correctly.
Note, however, that the Java virtual machine provides separate monitorenter and monitorexit instructions that implement the lock and unlock actions.
The synchronized statement computes a reference to an object; it then attempts to perform a lock action on that object’s monitor and does not proceed further until the lock action has successfully completed.
After the lock action has been performed, the body of the synchronized statement is executed.
If execution of the body is ever completed, either normally or abruptly, an unlock action is automatically performed on that same monitor.
A synchronized method automatically performs a lock action when it is invoked; its body is not executed until the lock action has successfully completed.
If the method is an instance method, it locks the monitor associated with the instance for which it was invoked (that is, the object that will be known as this during execution of the body of the method)
If the method is static, it locks the monitor associated with the Class object that represents the class in which the method is defined.
If execution of the method’s body is ever completed, either normally or abruptly, an unlock action is automatically performed on that same monitor.
The Java programming language neither prevents nor requires detection of deadlock conditions.
Programs where threads hold (directly or indirectly) locks on multiple objects should use conventional techniques for deadlock avoidance, creating higher-level locking primitives that don’t deadlock, if necessary.
There is a total order over all lock and unlock actions performed by an execution of a program.
The Java memory model is not fundamentally based in the Object-Oriented nature of the Java programming language.
For concision and simplicity in our examples, we often exhibit code fragments that could as easily be C or Pascal code fragments, without class or method definitions, or explicit dereferencing.
Most examples consist of two or more threads containing statements with access to local variables, shared global variables or instance fields of an object.
The semantics of the Java programming language allow compilers and microprocessors to perform optimizations that can interact with incorrectly synchronized code in ways that can produce behaviors that seem paradoxical.
However, compilers are allowed to reorder the instructions in each thread, when this does not affect the execeution of that thread in isolation.
To some programmers, this behavior may make it seem as if their code is being “broken” by Java.
However, it should be noted that this code is improperly synchronized:
When code contains a data race, counterintuitive results are often possible.
Several mechanisms can produce this reordering: the just-in-time compiler and the processor may rearrange code.
In addition, the memory hierarchy of the architecture on which a virtual machine is run may make it appear as if code is being reordered.
For the purposes of simplicity, we shall simply refer to anything that can reorder code as being a compiler.
Source code to bytecode transformation can reorder and transform programs, but must do so only in the ways allowed by this specification.
This program is incorrectly synchronized; it accesses shared memory without enforcing any ordering between those accesses.
One common compiler optimization involves having the value read for m reused for o: they are both reads of p.x with no intervening write.
Although this behavior is surprising, it is allowed by most JVMs.
However, it is forbidden by the original Java memory model in the JLS and JVMS: this was one of the first indications that the original JMM needed to be replaced.
A program must be correctly synchronized to avoid the kinds of counterintuitive behaviors that can be observed when code is reordered.
The use of correct synchronization does not ensure that the overall behavior of a program is correct.
However, its use does allow a programmer to reason about the possible behaviors of a program in a simple way; the behavior of a correctly synchronized program is much less dependent on possible reorderings.
Without correct synchronization, very strange, confusing and counterintuitive behaviors are possible.
There are two key ideas to understanding whether a program is correctly synchronized:
Conflicting Accesses Two accesses (reads of or writes to) the same shared field or array element are said to be conflicting if at least one of the accesses is a write.
Happens-Before Relationship Two actions can be ordered by a happens-before relationship.
If one action happens before another, then the first is visible to and ordered before the second.
There are a number of ways to induce a happens-before ordering in a Java program, including:
Each action in a thread happens before every subsequent action in that thread.
An unlock on a monitor happens before every subsequent lock on that monitor.
A write to a volatile field happens before every subsequent read of that volatile.
A call to start() on a thread happens before any actions in the started thread.
All actions in a thread happen before any other thread successfully returns from a join() on that thread.
If an action a happens before an action b, and b happens before an action c, then a happens before c.
When a program contains two conflicting accesses that are not ordered by a happensbefore relationship, it is said to contain a data race.
A correctly synchronized program is one that has no data races (Section 3.4 contains a subtle but important clarification)
An example of incorrectly synchronized code can be seen in Figure 3, which shows two different executions of the same program, both of which contain conflicting accesses to shared variables X and Y.
However, a different execution, shown in Figure 3b, shows why this program is incorrectly synchronized; there is no happens-before ordering between the conflicting accesses to X.
If a program is not correctly synchronized, then three types of problems can appear: visibility, ordering and atomicity.
If an action in one thread is visible to another thread, then the result of that action can be observed by the second thread.
In order to guarantee that the results of one action are observable to a second action, then the first must happen before the second.
Now imagine that two threads are created, and that one thread calls work(), and at some point, the other thread calls stopWork()
Because there is no happens-before relationship between the two threads, the thread in the loop may never see the update to done performed by the other thread.
In practice, this may happen if the compiler detects that no writes are performed to done in the first thread; the compiler may hoist the read of done out of the loop, transforming it into an infinite loop.
To ensure that this does not happen, there must be a happens-before relationship between the two threads.
In LoopMayNeverEnd, this can be achieved by declaring done to be volatile.
Conceptually, all actions on volatiles happen in a single order, and each write to a volatile field happens before any read of that volatile that occurs later in that order.
Ordering constraints govern the order in which multiple actions are seen to have happened.
The ability to perceive ordering constraints among actions is only guaranteed to actions that share a happens-before relationship with them.
The code in Figure 5 shows an example of where the lack of ordering constraints can produce surprising results.
Consider what happens if threadOne() gets executed in one thread and threadTwo() gets executed in another.
Would it be possible for threadTwo() to return the value true?
The Java memory model allows this result, illustrating a violation of the ordering that a.
This code fragment is not correctly synchronized (the conflicting accesses are not ordered by a happens-before ordering)
If ordering is not guaranteed, then the assignments to a and b in threadOne() can be performed out of order.
Compilers have substantial freedom to reorder code in the absence of synchronization.
This might result in threadTwo() being executed after the assignment to b, but before the assignment to a.
To avoid this behavior, programmers must ensure that their code is correctly synchronized.
If an action is (or a set of actions are) atomic, its result must be seen to happen “all at once”, or indivisibly.
Section 11 discusses some atomicity issues for Java; other than the exceptions mentioned there, all individual read and write actions take place atomically.
Atomicity can also be enforced on a sequence of actions.
A program can be free from data races without having this form of atomicity.
However, enforcing this kind of atomicity is frequently as important to program correctness as enforcing freedom from data races.
Since all access to the shared variable balance is guarded by synchronization, the code is free of data races.
The deposit() method sees a value of 10 for the balance, then.
The deposit() method uses the balance it originally saw to calculate the new balance.
A programmer writing multi-threaded code must use synchronization carefully to avoid this sort of error.
For this example, making the deposit() and withdraw() methods synchronized will ensure that the actions of those methods take place atomically.
If a program has no data races, then executions of the program are sequentially consistent: very strong guarantees are made about visibility and ordering.
Within a sequentially consistent execution, there is a total order over all individual actions (such as a read or a write) which is consistent with program order.
Each individual action is atomic and is immediately visible to every thread.
Having discussed sequential consistency, we can use it to provide an important clarification regarding data races and correctly synchronized programs.
A data race occurs in an execution of a program if there are conflicting actions in that execution that are not ordered by synchronization.
A program is correctly synchronized if and only if all sequentially consistent executions are free of data races.
Programmers therefore only need to reason about sequentially consistent executions to determine if their programs are correctly synchronized.
A more full and formal treatment of memory model issues for normal fields is given in Sections 4–7
Fields declared final can be initialized once, but never changed.
The detailed semantics of final fields are somewhat different from those of normal fields.
In particular, compilers have a great deal of freedom to move reads of final fields across synchronization barriers and calls to arbitrary or unknown methods.
Correspondingly, compilers are allowed to keep the value of a final field cached in a register and not reload it from memory in situations where a non-final field would have to be reloaded.
Final fields also allow programmers to implement thread-safe immutable objects without synchronization.
A thread-safe immutable object is seen as immutable by all threads, even if a data race is used to pass references to the immutable object between threads.
This can provide safety guarantees against misuse of the immutable class by incorrect or malicious code.
Final fields must be used correctly to provide a guarantee of immutability.
An object is considered to be completely initialized when its constructor finishes.
The usage model for final fields is a simple one.
Set the final fields for an object in that object’s constructor.
Do not write a reference to the object being constructed in a place where another thread can see it before the object’s constructor is finished.
If this is followed, then when the object is seen by another thread, that thread will always see the correctly constructed version of that object’s final fields.
It will also see versions of any object or array referenced by those final fields that are at least as up-to-date as the final fields are.
Figure 7 gives an example that demonstrates how final fields compare to normal fields.
The class FinalFieldExample has a final int field x and a non-final int field y.
One thread might execute the method writer(), and another might execute the method reader()
However, f.y is not final; the reader() method is therefore not guaranteed to see the value 4 for it.
Final fields are designed to allow for necessary security guarantees.
String objects are intended to be immutable and string operations do not perform synchronization.
While the String implementation does not have any data races, other code could have data races involving the use of Strings, and the JLS makes weak.
Figure 8: Without final fields or synchronization, it is possible for this code to print /usr.
A later operation on the String object might see the correct offset of 4, so that the String object is perceived as being "/usr"
Many security features of the Java programming language depend upon Strings being perceived as truly immutable, even if malicious code is using data races to pass String references between threads.
This is only an overview of the semantics of final fields.
A memory model describes, given a program and an execution trace of that program, whether the execution trace is a legal execution of the program.
Java’s memory model works by examining each read in an execution trace and checking that the write observed by that read is valid.
When we use the term “read” in this memory model, we are only referring to values returned from fields or array elements.
There are other actions performed by a virtual machine, including reads of array lengths, executions of checked casts, and invocations of virtual methods, that are not affected directly by the memory model or data races.
Although these may be implemented with reads at the machine level, these actions cannot throw an exception or otherwise cause the VM to misbehave (e.g., crash the VM, allow access outside an array or report the wrong array length)
The memory semantics determine what values can be read at every point in the program.
The actions of each thread in isolation must behave as governed by the semantics of that thread, with the exception that the values seen by each read are determined by the memory model.
When we refer to this, we say that the program obeys intra-thread semantics.
However, when threads interact, reads can return values written by writes from different threads.
Shared variables/Heap memory Memory that can be shared between threads is called shared or heap memory.
All instance fields, static fields and array elements are stored in heap memory.
We use the term variable to refer to both fields and array elements.
Variables local to a method are never shared between threads.
Inter-thread Actions An inter-thread action is an action performed by a thread that could be detected by or be directly influenced by another thread.
Inter-thread actions include reads and writes of shared variables and synchronization actions, such as locking or unlocking a monitor, reading or writing a shared variable, or starting a thread.
We do not need to concern ourselves with intra-thread actions (e.g., adding two local variables and storing the result in a third local variable)
As previously mentioned, all threads need to obey the correct intra-thread semantics for Java programs.
Every inter-thread action is associated with information about the execution of that action; we refer to that information as annotation.
All actions are annotated with the thread in which they occur and the program order in which they occur within that thread.
For brevity’s sake, we usually refer to inter-thread actions as simply actions.
Program Order Among all the inter-thread actions performed by each thread t, the program order of t is a total order that reflects the order in which these actions would be performed according to the intra-thread semantics of t.
Intra-thread semantics Intra-thread semantics are the standard semantics for single threaded programs, and allow the complete prediction of the behavior of a thread based on the values seen by read actions within the thread.
To determine if the actions of thread t in an execution are legal, we simply evaluate the implementation of thread t as it would be performed in a single threaded context, as defined in the remainder of the Java Language Specification.
Each time the evaluation of thread t generates an inter-thread action, it must match the inter-thread action a of t that comes next in program order.
If a is a read, then further evaluation of t uses the value seen by a.
Simply put, intra-thread semantics are what result from the execution of a thread in isolation; when values are read from the heap, they are determined by the memory model.
Synchronization Actions All inter-thread actions other than reads and writes of normal and final variables are synchronization actions.
These include locks, unlocks, reads of and writes to volatile variables, actions that start a thread, and actions that detect that a thread is done.
Synchronization Order In any execution, there is a synchronization order which is a total order over all of the synchronization actions of that execution.
For each thread t, the synchronization order of the synchronization actions in t is consistent with the program order of t.
If x and y are actions of the same thread and x comes before y in program.
There is a happens-before edge from an unlock action on monitor m to all subsequent lock actions onm (where subsequent is defined according to the synchronization order)
There is a happens-before edge from a write to a volatile variable v to all subsequent reads of v by any thread (where subsequent is defined according to the synchronization order)
There is a happens-before edge from an action that starts a thread to the first action in the thread it starts.
In addition, we have two other rules for generating happens-before edges.
There is a happens-before edge from the write of the default value (zero, false or null) of each variable to the first action in every thread.
However, the fact that they took place out of order should not be detectable.
For example, the write of a default value to every field of an object constructed by a thread need not occur before the beginning of that thread, as long as no read ever observes that fact.
The wait methods of class Object have lock and unlock actions associated with them; their happens-before relationships are defined by these associated actions.
Before going into details about the properties of the Java Memory Model, it is first useful to detail the requirements and goals for the Java memory model.
It is important to understand that this is not the specification of the Java Memory Model, but merely properties that the Java Memory Model will have.
These are the standard semantics for a single thread’s execution.
It is important for most programs in Java to have relatively straightforward semantics.
As discussed in Section 3.4, if code is written so that it has no data races, it will behave as if it is sequentially consistent; most of the unusual and counterintuitive behaviors discussed in this document will not appear if programmers adhere to this model.
This behavior when programs are correctly synchronized is a property that has long been advocated and accepted for memory models.
Many compiler transformations have been developed over the years; these include the reordering of non-conflicting memory accesses and the storage of values in registers.
It is a goal of the Java memory model for all such transformations to be legal.
Of course, this blanket proclamation is true only for transformations that do not interact with thread semantics.
For example, the reordering of a normal memory access and a volatile memory access is not legal in general, although it is legal in a number of more specific cases.
Similarly, transformations may not be universally allowable if they depend upon analyzing what values can be seen by reads of variables shared with other threads.
One important exception is that it is not legal, in general, to introduce additional reads and writes into the program in a way that is detectable.
The code fragment should always return a value that is twice that of a value read for x.
The transformed fragment return x+x could return an odd value.
Some operations (e.g., writing a volatile variable, unlocking a monitor, starting a thread) have release semantics: they allow the actions that happen before the release to be visible to and ordered before following actions.
It is generally legal to reorder a normal memory access and a following acquire action, or a release action and a following normal memory access.
This has been referred to as “roach motel” semantics: variable accesses can be moved into a synchronized block, but cannot, in general, move out.
Note, however, that some processor architectures (specifically, Alpha and DSM architectures) may have more implementation issues for correct handling of accesses to final fields.
A synchronization action is useless in a number of situations, including lock acquisition on thread-local objects or the reacquisition of a lock on an object on which a thread already has a lock.
A number of papers have been published showing compiler analyses that can detect and remove useless synchronization.
The old JMM did not allow useless synchronization to be completely removed; the new JMM does.
As mentioned, a number of academic papers on memory models have noted that a memory model should guarantee sequentially consistent semantics for correctly synchronized programs.
However, those papers did not provide any semantics or guarantees for incorrectly synchronized programs.
The Java memory model needs to provide such guarantees for two reasons:
In Java is that you should be able to load and run untrusted code inside a trusted process.
Thus it must be possible to limit the effect of malicious code, even if it is badly synchronized.
Hence any program that passes the verifier must have defined semantics.
This is in constrast to languages such as C and C++ that, for example, do not define the semantics of programs that write outside the bounds of an array.
As a result, programs written in those languages are subject to attacks that can violate important security guarantees.
Errors in general, and synchronization errors in particular, occur all too often in real programs.
While it is preferable to avoid errors altogether, if one occurs, its effects should be as limited and localized as possible.
Although there is no complete list of the safety guarantees needed by incorrectly synchronized programs, we can still provide those that we discuss here:
No out-of-thin-air reads Each read of a variable must see a value written by a write to that variable.
Type Safety Incorrectly synchronized programs are still bound by Java’s type safety guarantees.
This is guaranteed by the fact that the programs must obey intra-thread semantics (as described in Section 5) and that there cannot be any out-of-thin-air reads.
Non-intrusive reads If you are given a correctly synchronized program, and then add additional incorrectly synchronized reads to program in a way that does not affect the behavior of the program, the program is no longer correctly synchronized.
This can happen, for example, if the reads are for the purposes of debugging.
Regardless of this, the program should still have sequentially consistent semantics, other than for the values seen by the added reads.
While this case is a special case of limited applicability, it captures an important property that pushes the Java memory model in a desirable direction.
Note that the semantics of final fields do not have the non-intrusive reads property.
Causality This is, without a doubt, the hardest concept to understand and formalize.
While we prohibit this example, there are a number of other examples that seem to be violations of causality, but can, in fact, arise through combinations of standard and desirable compiler optimizations.
We previously described sequential consistency (Section 3.4), and showed that it is too strict for use as the Java memory model since it forbids standard compiler and processor optimizations.
We will now present a description of the Java memory model.
This description captures many of the important features of the Java memory model.
One part of the description is incomplete and informal (Section 7.2, having to do with causality)
The expert group continues to work on the best way to describe and present this material formally, and this additional work is described on the Java Memory Model web page (http://www.cs.umd.edu/~pugh/java/memoryModel) and mailing list (accessible from that web page)
The expert group felt that it was unreasonable to expect most people examining the Java memory model for the first time during the JSR-133 public review to invest the time to understand fully the formal specifications of causality.
Instead, in this document, the issues related to causality are explained informally, and through requirements and test cases.
Those familiar with formal specifications of memory models are encouraged to also examine additional information on the Java memory model web page and mailing list.
A formal specification will be part of the final specification.
In sequential consistency, all actions occur in a total order (the execution order) that is consistent with program order, and each read r of a variable v sees the value written by the write w to v such that:
We now relax the rules by which writes can be seen by a read.
We retain the idea that there is a total order over all actions that is consistent with the program order.
We say that a read r of a variable v is allowed to observe a write w to v if, in the happens-before partial order of the execution trace:
Figure 10: Behavior allowed by happens-before consistency, but not sequential consistency.
Informally, a read r is allowed to see the result of a write w if there is no happens-before ordering to prevent that read.
An execution trace is happens-before consistent if all of the reads in the execution trace are allowed.
An execution is happens-before consistent if each read sees a write that it is allowed to see by the happens-before ordering.
For example, the behavior shown in Figure 10 is happens-before consistent, since there is an execution order that allows each read to see the appropriate write.
In this case, since there is no synchronization, each read can see either the write of the initial value or the write by the other thread.
Similarly, the behavior shown in Figure 1 is happens-before consistent, since there is an execution order that allows each read to see the appropriate write.
In this execution, the reads see writes that occur later in the execution order.
This may seem counterintuitive, but is allowed by happens-before consistency.
It turns out that allowing reads to see later writes can sometimes produce unacceptable behaviors.
Happens-Before Consistency is a necessary, but not sufficient, set of constraints.
Merely enforcing Happens-Before Consistency would allow for unacceptable behaviors – those that violate common, established properties of Java programs, for example, that values never appear “out of thin air”
For example, the code shown in Figure 11 is correctly synchronized.
This may seem surprising, since it doesn’t perform any synchronization actions.
Remember, however, that a program is correctly synchronized if, when it is executed in a sequentially consistent manner, there are no data races among its non-volatile variables.
Since no writes occur, there can be no data races: the program is correctly synchronized.
Since this program is correctly synchronized, the only behaviors we can allow are sequentially consistent behaviors.
However, there is an execution of this program that is happens-before consistent, but not sequentially consistent:
This result is happens-before consistent: there is no happens-before relationship that prevents it from occurring.
However, it is clearly not acceptable: there is no sequentially consistent execution that would result in this behavior.
The fact that we allow a read to see a write that comes later in the execution order can sometimes thus result in unacceptable behaviors.
Although allowing reads to see writes that come later in the execution order is sometimes undesirable in this model, it is also sometimes necessary.
Since the reads come first in each thread, the very first action in the execution order must be a read.
If that read can’t see a write that occurs later, then it can’t see any value other than the initial value for the variable it reads.
We refer to the issue of when reads can see future writes as causality.
Read operations do not actually use crystal balls or time machines to foretell the future to determine which value they can see.
This issue actually arises because programs are often not actually executed in the order they are written.
Compilers, JVMs and architectures often reorder operations or perform them in parallel.
For purposes of this document, however, we will talk about the problem in terms of reads seeing writes that occur later in the execution order.
Even when a program is incorrectly synchronized, there are certain behaviors that violate causality in a way that is considered unacceptable.
However, the details are complicated and can be controversial, in part because they rely on judgments about acceptability that are not covered by traditional program semantics.
There are, however, two uncontroversial properties that are easy to specify:
If a write is absolutely certain to be performed in all executions, it may be seen early (thus, the behavior in Figure 1 is legal)
In this section, we give a number of examples of behaviors that are either allowed or prohibited by the Java memory model.
Most of these are either examples that show violations of our informal notion of causality, and thus are prohibited, or examples that seem to be a violation of causality but can result from standard compiler optimizations, and are in fact allowed.
The example in Figure 12 provides an example of a result that is clearly unacceptable.
If, for example, the value that was being produced “out of thin air” was a reference to an object which the thread was not supposed to have, then such a transformation could be a serious security violation.
There are no reasonable compiler transformations that produce this result.
This behavior, while surprising, is a common optimization that is allowed by the Java memory model.
Without this information, the assignment seems to cause itself to happen.
Thus, simple compiler optimizations can lead to an apparent causal loop.
This behavior would seem impossible, because thread 2 should not be able to decide which assignment statement it will execute until after it has read b.
Thus, the action may be performed early, even though we don’t know in advance which statement would have caused the action to occur.
The write to y is therefore not dependent on the value seen for x.
In either case, it would be legal for a read of x to see the value.
This sort of behavior is not known to result from any combination of known reasonable and desirable optimizations.
However, there is also some question as to whether this reflects a real and serious security requirement.
However, additional feedback on this kind of behavior, and whether it should be allowed or prohibited, is solicited as part of the JSR-133 public review.
This annotation can be used to pass immutable objects between threads without synchronization.
The value of a final field is not intended to change.
The compiler should not have to reload a final field because a lock was obtained, a volatile variable was read, or an unknown method was invoked.
In fact, the compiler is allowed to hoist reads within thread t of a final field f of an object X to immediately after the very first read of a reference to X by t; the thread need never reload that field.
Objects that have only final fields and are not made visible to other threads during construction should be perceived as immutable even if references to those objects are passed between threads via data races.
Storing a reference to an object X into the heap during construction of X does not necessarily violate this requirement.
For example, synchronization could ensure that no other thread could load the reference to X during construction.
Alternatively, during construction of X a reference to X could be stored into another object Y ; if no references to Y are made visible to other threads until after construction of X is complete, then final field guarantees still hold.
The use of final fields adds constraints on which writes are considered ordered before which reads, for the purposes of determining if an execution is consistent.
Assume a freeze action on a final field f of an object X takes place when the constructor for X in which f is written exits.
When is R guaranteed to see the correctly initialized value of X.f?
For the moment, assume each thread only reads a single reference to each object.
For any object X, thread t2 must have obtained its address via a chain of the following reference links:
Thread ti wrote a reference to an object Y which was read by another thread tj.
Thread ti read a reference to an object Y , and then read a field of Y to see a reference to another object Z.
Thread ti read a reference to an object Y , and later wrote a reference to Y.
If there is no such action, then R does not get that guarantee.
An execution of this code is shown in Figure 21, with the reference links shown and labeled.
In order for the read of b.f to be correctly ordered with respect to the construction of the object.
Bar b = new Bar() Bar b = f.b; int i = b.f;
We assume r and s do not see the value null.
Figure 22: Final field example where Reference to object is read twice.
In the more general case, thread ti may read multiple references to an object Y from different locations.
To make the guarantees associated with final fields, it must be possible.
On the chain that goes through the global variable b, there is no action that is ordered after the freeze operation, so the read of t.f is not correctly ordered with regards to the freeze operation.
Therefore, k is not guaranteed to see the correctly constructed value for the final field.
The fact that k does not receive this guarantee reflects legal transformations by the compiler.
A compiler can analyze this code and determine that r.f and t.f are reads of the same final field of the same object.
The read is therefore correctly ordered with respect to the freeze operation, and guaranteed to see the correct value.
A final field may only be written by bytecode once.
A classfile may be rejected in any one of the following situations:
It consists of only the freezes seen at every read in the thread in isolation.
It consists of only the writes seen at every read in the thread in isolation.
Figure 23: Sets used in the formalization of final fields.
Other techniques, such as deserialization, may cause a final field to be modified after the end of the enclosing object’s constructor.
There must be a freeze of the final field after each such write.
If a reference to an object is shared with other threads between the initial construction of an object and when deserialization changes the final fields of the object, most of the guarantees for final fields of that object can go kerflooey.
The following is a discussion of the formal semantics of final fields.
Figure 23 contains a table of all of the sets mentioned below, and their definition.
Each field o.x has an enclosing object o, and a set of objects that are reachable by following a chain of dereferences from it.
A final field may be written to multiple times: once by bytecode in a constructor, and otherwise by VM actions.
After the constructor for the enclosing object, a final field is explicitly frozen.
After the other writes, the VM may optionally choose to freeze the final field.
For the purposes of this discussion, freeze can be considered a noun: a freeze can be copied from thread to thread, and the set of freezes visible to a given thread for a field are the ones that provide the guarantees for that field.
The set G of freezes that are written at every write w of an enclosing object at address a include:
Each reference a to an object may be stored in fields of several different objects.
The set G (defined above) that was associated with the write of a, and.
However System.in, System.out, and System.err are final static fields that, for legacy reasons, must be allowed to be changed by the methods System.setIn(), System.setOut() and System.setErr()
We refer to these fields as being write-protected to distinguish them from ordinary final fields.
Figure 24: Bytes must not be overwritten by writes to adjacent bytes.
The compiler needs to treat these fields differently from other final fields.
For example, a read of an ordinary final field is “immune” to synchronization: the barrier involved in a lock or volatile read does not have to affect what value is read from a final field.
Since the value of write-protected fields may be seen to change, synchronization events should have an effect on them.
Therefore, the semantics dictate that these fields be treated as normal fields that cannot be changed by user code, unless that user code is in the System class.
One implementation consideration for Java virtual machines is that every field and array element is considered distinct; updates to one field or element do not interact with reads or updates of any other field or element.
In particular, two threads that update adjacent elements of a byte array must not interfere or interact and do not need synchronization to.
Some processors (notably early Alphas) do not provide the ability to write to a single.
It would be illegal to implement byte array updates on such a processor by simply reading an entire word, updating the appropriate byte, and then writing the entire word back to memory.
This problem is sometimes known as word tearing, and on processors that cannot easily update a single byte in isolation some other approach will be required.
Figure 24 shows a test case to detect word tearing.
For efficiency’s sake, this behavior is implementation specific; Java virtual machines are free to perform writes to long and double values atomically or in two parts.
For the purposes of this memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half.
Write and reads of volatile long and double values are always atomic.
Programmers are encouraged to declare shared 64-bit values as volatile or synchronize their programs correctly to avoid this.
Without a fairness guarantee for virtual machines, it is possible for a thread that is capable of making progress never to do so.
One example of a such a guarantee would state that if a thread is infinitely often allowed to make progress, it will eventually do so.
Java has no official fairness guarantee, although, in practice, most JVMs do provide it to some extent.
Without a fairness guarantee, it is perfectly legal for a compiler to move the synchronized block outside the while loop; Thread 2 will be blocked forever.
Any potential fairness guarantee would be inextricably linked to the threading model for a given virtual machine.
A threading model that only switches threads when Thread.yield() is called will, in fact, never allow Thread 2 to execute.
A fairness guarantee makes this sort of implementation illegal; it would force Thread 2 to be scheduled.
Because this kind of implementation is often desirable, this specification does not include a fairness guarantee.
In particular, for any execution shown to be legal by the semantics for consistency and causality, it would also be legal to execute just the instructions in any prefix of the causal order of that execution.
Every object, in addition to having an associated lock, has an associated wait set.
When an object is first created, its wait set is empty.
Elementary actions that add threads to and remove threads from wait sets are atomic.
Wait sets are manipulated in Java solely through the methods Object.wait, Object.notify , and Object.notifyAll.
Wait set manipulations can also be affected by the interruption status of a thread, and by the Thread class methods dealing with interruption.
Additionally, Thread class methods for sleeping and joining other threads have properties derived from those of wait and notification actions.
Wait actions occur upon invocation of wait(), or the timed forms wait(long millisecs) and wait(long millisecs, int nanosecs)
A call of wait(long millisecs) with a parameter of zero, or a call of wait(long millisecs, int nanosecs) with two zero parameters, is equivalent to an invocation of wait()
Let thread t be the thread executing the wait method on Object m, and let n be the number of lock actions by t on m that have not been matched by unlock actions.
Thread T is added to the wait set of object m, and performs n unlock actions on m.
Thread t does not execute any further Java instructions until it has been removed from m’s wait set.
The thread may be removed from the wait set due to any one of the following actions, and will resume sometime afterward.
A notify action being performed on m in which t is selected for removal from the wait set.
If this is a timed wait, an internal action removing t fromm’s wait set that occurs after at least millisecs milliseconds plus nanosecs nanoseconds elapse since the beginning of this wait action.
Implementations are permitted, although not encouraged, to perform “spurious wake-ups” – to remove threads from wait sets and thus enable resumption without explicit Java instructions to do so.
Notice that this provision necessitates the Java coding practice of using wait() only within loops that terminate only when some logical condition that the thread is waiting for holds.
Each thread must determine an order over the events that could cause it to be removed from a wait set.
That order does not have to be consistent with other orderings, but the thread must behave as though those events occurred in that order.
For example, if a thread t is in the wait set for m, and then both an interrupt of t and a notification of m occur, there must be an order over these events.
If the notification is deemed to have occurred first, then t will eventually return normally from wait with an interrupt still pending.
Notification actions occur upon invocation of methods notify and notifyAll()
Let thread t be the thread executing either of these methods on Object m, and let n be the number of.
This is the case where thread t does not already possess the lock for target m.
If n is greater than zero and this is a notify action, then, if m’s wait set is not empty, a thread u that is a member of m’s current wait set is selected and removed from the wait set.
There is no guarantee about which thread in the wait set is selected.
This removal from the wait set enables u’s resumption in a wait action.
Notice however, that u’s lock actions upon resumption cannot succeed until some time after t fully unlocks the monitor for m.
If n is greater than zero and this is a notifyAll action, then all threads are removed from m’s wait set, and thus resume.
Notice however, that only one of them at a time will lock the monitor required during the resumption of wait.
Let t be the thread invoking U.interrupt(), for some thread u, where t and u may be the same.
This action causes u’s interruption status to be set to true.
Additionally, if there exists some object m whose wait set contains u, u is removed from m’s wait set.
The above specifications allow us to determine several properties having to do with the interaction of waits, notification and interruption.
If a thread is both notified and interrupted while waiting, it may either:
The thread may not reset its interrupt status and return normally from the call to wait()
Causes the currently executing thread to sleep (temporarily cease execution) for the specified duration, subject to the precision and accuracy of system timers and schedulers.
The thread does not lose ownership of any monitors, and resumption of execution will depend on scheduling and the availability of processors on which to execute the thread.
A sleep for a period of zero time and yield operations need not have obversable effects.
It is important to note that neither Thread.sleep nor Thread.yield have any synchronization semantics.
In particular, the compiler does not have to flush writes cached in registers out to shared memory before a call to sleep or yield, nor does the compiler have to reload values cached in registers after a call to sleep or yield.
For example, in the following (broken) code fragment, assume that this.done is a non-volatile boolean field:
The compiler is free to read the field this.done just once, and reuse the cached value in each execution of the loop.
This would mean that the loop would never terminate, even if another thread changed the value of this.done.
Let sawAddress(t, a) be the set of reads in thread t that returned the address a.
These ordering constraints are taken into account in determining which writes are visible to the read r.
However, these ordering constraints do not otherwise compose with the standard happens-before ordering constraints.
Like the equations for freezes, these equations are recursive; the solution is defined to be the least fixed point solution.
Result set for non-final fields or array elements Consider a read r in thread t of non-final field or element x of the object at address c.
Result set for final fields Consider a read r in thread t of final field x of the object at address c.
If a.x is a final field, these are the only writes considered to be ordered before r.
In addition, if a.x is a final static field, then r will always return a.x’s correctly constructed value, unless r happens in the thread that performed the class initialization, before the field was written.
We have discussed in detail what guarantees are made for final fields seen in multiple threads.
However, compiler transformations can cause a read of a final field to return a default value even if it is only accessed in a single thread.
In this section, we discuss what guarantees are made if a final field is seen to change in a single thread.
For cases where a final field is set once in the constructor, the rules are simple: the reads and writes of the final field in the constructing thread are ordered according to program order.
We must treat cases such as deserialization, where a final field can be modified after the constructor is completed, a little differently.
Because reads of final fields can be reordered around method boundaries, the compiler may reuse the value of the first read for the second read.
The limitation we place on this is that if the method returns a “new” reference to the final field’s enclosing object, and the final field is read via that reference, then the program will see the rewritten value of the final field.
If it uses the “old” reference to the final field’s enclosing object, then the program may see either the original value or the new one.
Conceptually, before a program modifies a frozen final field, the system must call a realloc() function, passing in a reference to the object, and getting out a reference to the object through which the final fields can be reassigned.
The only appropriate way to use this realloc() function is to pass the only live reference to the object to the realloc() function, and only to use that value realloc() returns to refer to the object after that call.
After getting back a “fresh” copy from realloc(), the final fields can be modified and refrozen.
The realloc() function need not actually be implemented at all; the details are hidden inside the implementation.
However, it can be thought of as a function that might decide to perform a shallow copy.
In more detail, each reference within a thread essentially has a version number.
A read of a final field is ordered according to program order with all writes to that field using the same or smaller version number.
Two references to the same object but with different version numbers should not be compared for equality.
If one reference is ever compared to a reference with a lower version number, then that read and all reads of final fields from that reference are treated as if they have the lower version number.
This appendix details changes to Section 12.6 of the Java language specification, which deals with finalization.
The class Object has a protected method called finalize; this method can be overridden by other classes.
The particular definition of finalize that can be invoked for an object is called the finalizer of that object.
Before the storage for an object is reclaimed by the garbage collector, the Java virtual machine will invoke the finalizer of that object.
Finalizers provide a chance to free up resources that cannot be freed automatically by an automatic storage manager.
In such situations, simply reclaiming the memory used by an object would not guarantee that the resources it held would be reclaimed.
The Java programming language does not specify how soon a finalizer will be invoked, except to say that it will happen before the storage for the object is reused.
Also, the language does not specify which thread will invoke the finalizer for any given object.
It is guaranteed, however, that the thread that invokes the finalizer will not be holding any user-visible synchronization locks when the finalizer is invoked.
It is important to note that many finalizer threads may be active (this is sometimes needed on large SMPs), and that if a large connected data structure becomes garbage, all of the finalize methods for every object in that data structure could be invoked at the same time, each finalizer invocation running in a different thread.
The finalize method declared in class Object takes no action.
The fact that class Object declares a finalizemethod means that the finalizemethod.
This should always be done, unless it is the programmer’s intent to nullify the actions of the finalizer in the superclass.
Unlike constructors, finalizers do not automatically invoke the finalizer for the superclass; such an invocation must be coded explicitly.
For efficiency, an implementation may keep track of classes that do not override the finalize method of class Object, or override it in a trivial way, such as:
We encourage implementations to treat such objects as having a finalizer that is not overridden, and to finalize them more efficiently, as described in Section B.1
A finalizer may be invoked explicitly, just like any other method.
The package java.lang.ref describes weak references, which interact with garbage collection and finalization.
As with any API that has special interactions with the language, implementors must be cognizant of any requirements imposed by the java.lang.ref API.
This specification does not discuss weak references in any way.
A reachable object is any object that can be accessed in any potential continuing computation from any live thread.
Any object that may be referenced from a field or array element of a reachable object is reachable.
Finally, if a reference to an object is passed to a JNI method, then the object must be considered reachable until that method completes.
A class loader is considered reachable if any instance of a class loaded by that loader is reachable.
A class object is considered reachable if the class loader that loaded it is reachable.
Another example of this occurs if the values in an object’s fields are stored in registers.
The program then may access the registers instead of the object, and never access the object again.
Note that this sort of optimization is only allowed if references are on the stack, not stored in the heap.
The finalizer guardian forces a super.finalize() to be called if a subclass overrides finalize and does not explicitly call super.finalize()
If these optimizations are allowed for references that are stored on the heap, then the compiler can detect that the finalizerGuardian field is never read, null it out, collect the object immediately, and call the finalizer early.
This runs counter to the intent: the programmer probably wanted to call the Foo finalizer when the Foo instance became unreachable.
This sort of transformation is therefore not legal: the inner class object should be reachable for as long as the outer class object is reachable.
Transformations of this sort may result in invocations of the finalize method occurring earlier than might be otherwise expected.
In order to allow the user to prevent this, we enforce the notion that synchronization may keep the object alive.
If an object’s finalizer can result in synchronization on that object, then that object must be alive and considered reachable whenever a lock is held on it.
Note that this does not prevent synchronization elimination: synchronization only keeps an object alive if a finalizer might synchronize on it.
Since the finalizer occurs in another thread, in many cases the synchronization could not be removed anyway.
An unfinalized object has never had its finalizer automatically invoked; a finalized object has had its finalizer automatically invoked.
A finalizable object has never had its finalizer automatically invoked, but the Java virtual machine may eventually automatically invoke its finalizer.
An object cannot be considered finalizable until its constructor has finished.
Every pre-finalization write to a field of an object must be visible to the finalization of that object.
Furthermore, none of the pre-finalization reads of fields of that object may see writes that occur after finalization of that object is initiated.
