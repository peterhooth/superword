O’Reilly books may be purchased for educational, business, or sales promotional use.
Java Network Programming, the image of a North American river otter, and related trade dress are trademarks of O’Reilly Media, Inc.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in this book, and O’Reilly Media, Inc., was aware of a trademark claim, the designations have been printed in caps or initial caps.
While every precaution has been taken in the preparation of this book, the publisher and author assume no responsibility for errors or omissions, or for damages resulting from the use of the information contained herein.
Java’s growth over the past 20 years has been nothing short of phenomenal.
Given Java’s rapid rise to prominence and the even more spectacular growth of the Internet, it’s a little surprising that network programming in Java remains so mysterious to so many.
In fact, writing network programs in Java is quite simple, as this book will show.
Readers with previous experience in network programming in a Unix, Windows, or Macintosh environment will be pleasantly surprised at how much easier it is to write equivalent programs in Java.
The Java core API includes well-designed interfaces to most network features.
Indeed, there is very little application layer network software you can write in C or C++ that you can’t write more easily in Java.
Java Network Programming, Fourth Edition, endeavors to show you how to take advantage of Java’s network class library to quickly and easily write programs that accomplish many common networking tasks.
Java is the first (though no longer the only) language to provide such a powerful crossplatform network library for handling all these diverse tasks.
Java Network Programming exposes the power and sophistication of this library.
To do so, this book provides a general background in network fundamentals, as well as detailed discussions of Java’s facilities for writing network programs.
You’ll learn how to write Java programs that share data across the Internet for games, collaboration, software updates, file transfer, and more.
You’ll also get a behind-the-scenes look at HTTP, SMTP, TCP/IP, and the other protocols that support the Internet and the Web.
When you finish this book, you’ll have the knowledge and the tools to create the next generation of software that takes full advantage of the Internet.
About the Fourth Edition In 1996, in the first edition of this book’s opening chapter, I wrote extensively about the sort of dynamic, distributed network applications I thought Java would make possible.
One of the most exciting parts of writing subsequent editions has been seeing virtually all of the applications I foretold come to pass.
Programmers are using Java to query database servers, monitor web pages, control telescopes, manage multiplayer games, and more, all by using Java’s native ability to access the Internet.
Java in general and network programming in Java in particular has moved well beyond the hype stage and into the realm of real, working applications.
The fourth edition focuses even more heavily on HTTP and REST.
As you’ll see, it is often the protocol on which other protocols are built, forming its own layer in the network stack.
Many other methods have been added to existing classes in the last three releases of Java, and these are discussed in the relevant chapters.
I’ve also rewritten large parts of the book to reflect the ever-changing fashions in Java programming in general and network programming in particular.
I hope you’ll find this fourth edition an even stronger, longer-lived, more accurate, and more enjoyable tutorial and reference to network programming in Java than the previous one.
Organization of the Book Chapter 1, Basic Network Concepts, explains in detail what a programmer needs to know about how the networks and the Internet work.
It covers the protocols that underlie the Internet, such as TCP/IP and UDP/IP.
The next two chapters throw some light on two parts of Java programming that are critical to almost all network programs but are often misunderstood and misused: I/O and threading.
Chapter 2, Streams, explores Java’s classic I/O which—despite the new I/O APIs—isn’t going away any time soon and is still the preferred means of handling input and output in most client applications.
Understanding how Java handles I/O in the general case is a prerequisite for understanding the special case of how Java handles network I/O.
Chapter 3, Threads, explores multithreading and synchronization, with a special emphasis on how they can be used for asynchronous I/O and network servers.
Experienced Java programmers may be able to skim or skip these two chapters.
However, Chapter 4, Internet Addresses, is essential reading for everyone.
It shows how Java programs interact with the Domain Name System through the InetAddress class, the one class that’s needed by essentially all network programs.
Once you’ve finished this chapter, it’s possible to jump around in the book as your interests and needs dictate.
Chapter 5, URLs and URIs, explores Java’s URL class, a powerful abstraction for downloading information and files from network servers of many kinds.
The URL class enables you to connect to and download files and documents from a network server without concerning yourself with the details of the protocol the server speaks.
It lets you connect to an FTP server using the same code you use to talk to an HTTP server or to read a file on the local hard disk.
Chapter 6, HTTP, delves deeper into the HTTP protocol specifically.
Chapter 7, URLConnections, shows you how to use the URLConnection and HttpURLConnection classes not just to download data from web servers, but to upload documents and configure connections.
Chapter 8, Sockets for Clients, introduces the Java sockets API and the Socket class in particular.
It shows you how to write network clients that interact with TCP servers of all kinds including whois, dict, and HTTP.
Chapter 9, Sockets for Servers, shows you how to use the ServerSocket class to write servers for these and other protocols.
Chapter 11, Nonblocking I/O, introduces the new I/O APIs specifically designed for network servers.
These APIs enable a program to figure out whether a connection is ready before it tries to read from or write to the socket.
This allows a single thread to manage many different connections simultaneously, thereby placing much less load on the virtual machine.
The new I/O APIs don’t help much for small servers or clients that don’t open many simultaneous connections, but they may provide performance boosts for high-volume servers that want to transmit as much data as the network can handle as fast as the network can deliver it.
Chapter 12, UDP, introduces the User Datagram Protocol (UDP) and the associated DatagramPacket and DatagramSocket classes that provide fast, unreliable communication.
Finally, Chapter 13, IP Multicast, shows you how to use UDP to communicate with multiple hosts at the same time.
Who You Are This book assumes you are comfortable with the Java language and programming environment, in addition to object-oriented programming in general.
This book does not attempt to be a basic language tutorial.
You should be thoroughly familiar with the syntax of Java.
It also wouldn’t hurt if you’re familiar with basic Swing programming, though that’s not required aside from a few examples.
When you encounter a topic that requires a deeper understanding for network programming than is customary—for instance, threads and streams—I’ll cover that topic as well, at least briefly.
However, this book doesn’t assume that you have prior experience with network programming.
You should find it a complete introduction to networking concepts and network application development.
You’ll learn what you need to know about these here.
Java Versions Java’s network classes have changed a lot more slowly since Java 1.0 than other parts of the core API.
In comparison to the AWT or I/O, there have been almost no changes and only a few additions.
Of course, all network programs make extensive use of the I/O classes and some make heavy use of GUIs.
This book is written with the assumption that you are coding with at least Java 5.0
In general, I use Java 5 features like generics and the enhanced for loop freely without further explanation.
I have not shied away from using features introduced in Java 7 where they seemed especially useful or convenient—for instance, try-withresources and multicatch are both very helpful when trying to fit examples into the limited space available in a printed book—but I have been careful to point out my use of such features.
Overall, though, Java’s networking API has been relatively stable since Java 1.0
Very little of the post-1.0 networking API has ever been deprecated, and additions have been.
You shouldn’t have any trouble using this book after Java 8 is released.
New APIs, however, have been somewhat more frequent in the supporting classes, particularly I/O, which has undergone three major revisions since Java 1.0
About the Examples Most methods and classes described in this book are illustrated with at least one complete working program, simple though it may be.
In my experience, a complete working program is essential to showing the proper use of a method.
Without a program, it is too easy to drop into jargon or to gloss over points about which the author may be unclear in his own mind.
The Java API documentation itself often suffers from excessively terse descriptions of the method calls.
In this book, I have tried to err on the side of providing too much explication rather than too little.
If a point is obvious to you, feel free to skip over it.
You do not need to type in and run every example in this book; but if a particular method does give you trouble, you should have at least one working example.
Each chapter includes at least one (and often several) more complex programs that demonstrate the classes and methods of that chapter in a more realistic setting.
These often rely on Java features not discussed in this book.
Indeed, in many of the programs, the networking components are only a small fraction of the source code and often the least difficult parts.
Nonetheless, none of these programs could be written as easily in languages that didn’t give networking the central position it occupies in Java.
The apparent simplicity of the networked sections of the code reflects the extent to which networking has been made a core feature of Java, and not any triviality of the program itself.
All example programs presented in this book are available online, often with corrections and additions.
I have tested all the examples on Linux and many on Windows and Mac OS X.
Most of the examples given here should work on other platforms and with other compilers and virtual machines that support Java 5 or later.
These examples can easily be rewritten to support earlier Java versions at the cost of increased verbosity.
I do feel a little guilty about a couple of compromises necessitated by the needs of space in a printed book.
Most methods assume they are passed good data, and dispense with null checks and similar principles of good code hygiene.
Furthermore, I have reduced the indentation to two characters per block and four characters per continuation line, as opposed to the Java standard of four and eight, respectively.
On the positive side, these compromises have aided me in making this edition considerably shorter (by several hundred pages) than the previous edition.
Anything that might appear in a Java program, including keywords, operators, data.
Command lines and options that should be typed verbatim on the screen.
Significant code fragments and complete programs are generally placed into a separate paragraph, like this:
When code is presented as fragments rather than complete programs, the existence of the appropriate import statements should be inferred.
In these cases, the user input will be displayed in bold, as in this example from Chapter 9:
Finally, although many of the examples used here are toy examples unlikely to be reused, a few of the classes I develop have real value.
Please feel free to reuse them or any parts of them in your own code.
Request for Comments I enjoy hearing from readers, whether with general comments about this book, specific corrections, other topics they would like to see covered, or just war stories about their own network programming travails.
Please realize, however, that I receive several hundred pieces of email a day and cannot personally respond to each one.
For the best chance of getting a personal response, please identify yourself as a reader of this book.
If you have a question about a particular program that isn’t working as you expect, try to reduce it to the simplest case that reproduces the bug, preferably a single class, and paste the text of the entire program into the body of your email.
And please, please send the message from the account you want me to reply to and make sure that your Reply-to address is properly set! There’s nothing quite so frustrating as spending an hour or more carefully researching the answer to an interesting question and composing a detailed response, only to have it bounce because my correspondent sent her feedback from a public terminal and neglected to set the browser preferences to include her actual email address.
I’ve yet to make it perfect, but I keep trying.
And I’m sure that at least one of them is a really embarrassing whopper of a problem.
If you find a mistake or a typo, please let me know so I can correct it.
Before reporting errors, please check one of those pages to see if I already know about it and have posted a fix.
Any errors that are reported will be fixed in future printings.
Using Code Examples This book is here to help you get your job done.
In general, if this book includes code examples, you may use the code in this book in your programs and documentation.
You do not need to contact us for permission unless you’re reproducing a significant portion of the code.
For example, writing a program that uses several chunks of code from this book does not require permission.
Selling or distributing a CD-ROM of examples from O’Reilly books does require permission.
Answering a question by citing this book and quoting example code does not require permission.
Incorporating a significant amount of example code from this book into your product’s documentation does require permission.
An attribution usually includes the title, author, publisher, and ISBN.
Technology professionals, software developers, web designers, and business and creative professionals use Safari Books Online as their primary resource for research, problem solving, learning, and certification training.
Safari Books Online offers a range of product mixes and pricing programs for organizations, government agencies, and individuals.
For more information about Safari Books Online, please visit us online.
How to Contact Us Please address comments and questions concerning this book to the publisher:
We have a web page for this book, where we list errata, examples, and any additional information.
For more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.
Acknowledgments Many people were involved in the production of this book.
My editor, Mike Loukides, got things rolling, and provided many helpful comments along the way that substantially improved the book.
The technical editors all provided invaluable assistance in hunting down errors and omissions.
Laurent provided crucial advice on which topics deserved more coverage.
Scott Oaks lent his thread expertise to Chapter 3, proving once again by the many subtle bugs he hunted down that multithreading still requires the attention of an expert.
Ron Hitchens shone light into many of the darker areas of the new I/O APIs.
Marc Loy and Jim Elliott reviewed some of the most bleeding edge material in the book.
Rohaly was unswerving in his commitment to making sure I closed all my sockets and caught all possible exceptions, and in general wrote the cleanest, safest, most exemplary code I could write.
John Zukowski found numerous errors of omission, all now filled thanks to him.
And the eagle-eyed Avner Gelb displayed an astonishing ability to spot mistakes that had somehow managed to go unnoticed by myself, all the other.
Alex Stangl and Ryan Cuprak provided further assistance with spotting both new and lingering mistakes in this latest edition.
It isn’t customary to thank the publisher, but the publisher does set the tone for the rest of the company, authors, editors, and production staff alike; and I think Tim O’Reilly deserves special credit for making O’Reilly Media absolutely one of the best houses an author can write for.
If there’s one person without whom this book would never have been written, it’s him.
If you, the reader, find O’Reilly books to be consistently better than most of the dreck on the market, the reason really can be traced straight back to Tim.
My agent, David Rogelberg, convinced me it was possible to make a living writing books like this rather than working in an office.
The entire crew at ibiblio.org over the last several years has really helped me to communicate better with my readers in a variety of ways.
Every reader who sent in bouquets and brickbats for previous editions has been instrumental in helping me write this much-improved edition.
Finally, as always, I’d like to offer my largest thanks to my wife, Beth, without whose love and support this book would never have happened.
Network programming is no longer the province of a few specialists.
It has become a core part of every developer’s toolbox.
Besides classic applications like email, web browsers, and remote login, most major applications have some level of networking built in.
Text editors like BBEdit save and open files directly from FTP servers.
IDEs like Eclipse and IntelliJ IDEA communicate with source code repositories like.
Antivirus programs like Norton AntiVirus check for new virus definitions by connecting to the vendor’s website every time the computer is started.
Music players like Winamp and iTunes upload CD track lengths to CDDB and.
Gamers playing multiplayer first-person shooters like Halo gleefully frag each other.
Supermarket cash registers running IBM SurePOS ACE communicate with their.
The server uploads its daily receipts to the chain’s central computers each night.
Schedule applications like Microsoft Outlook automatically synchronize calendars among employees in a company.
Java was the first programming language designed from the ground up for network applications.
Java was originally aimed at proprietary cable television networks rather than the Internet, but it’s always had the network foremost in mind.
One of the first two real Java applications was a web browser.
As the Internet continues to grow, Java is uniquely suited to build the next generation of network applications.
One of the biggest secrets about Java is that it makes writing network programs easy.
In fact, it is far easier to write network programs in Java than in almost any other language.
This book shows you dozens of complete programs that take advantage of the Internet.
Some are simple textbook examples, while others are completely functional applications.
One thing you’ll notice in the fully functional applications is just how little code is devoted to networking.
Even in network-intensive programs like web servers and clients, almost all the code handles data manipulation or the user interface.
The part of the program that deals with the network is almost always the shortest and simplest.
In brief, it is easy for Java applications to send and receive data across the Internet.
This chapter covers the background networking concepts you need to understand before writing networked programs in Java (or, for that matter, in any language)
Moving from the most general to the most specific, it explains what you need to know about networks in general, IP and TCP/IP-based networks in particular, and the Internet.
This chapter doesn’t try to teach you how to wire a network or configure a router, but you will learn what you need to know to write applications that communicate across the Internet.
Topics covered in this chapter include the nature of networks; the TCP/IP layer model; the IP, TCP, and UDP protocols; firewalls and proxy servers; the Internet; and the Internet standardization process.
Experienced network gurus may safely skip this chapter, and move on to the next chapter where you begin developing the tools needed to write your own network programs in Java.
Networks A network is a collection of computers and other devices that can send data to and receive data from one another, more or less in real time.
A network is often connected by wires, and the bits of data are turned into electromagnetic waves that move through the wires.
However, wireless networks transmit data using radio waves; and most longdistance transmissions are now carried over fiber-optic cables that send light waves through glass filaments.
There’s nothing sacred about any particular physical medium for the transmission of data.
Theoretically, data could be transmitted by coal-powered computers that send smoke signals to one another.
The response time (and environmental impact) of such a network would be rather poor.
Every network node has an address, a sequence of bytes that uniquely identifies it.
You can think of this group of bytes as a number, but in general the number of bytes in an address or the ordering of those bytes (big endian or little endian) is not guaranteed to.
The more bytes there are in each address, the more addresses there are available and the more devices that can be connected to the network simultaneously.
Manufacturers of Ethernet hardware use preassigned manufacturer codes to make sure there are no conflicts between the addresses in their hardware and the addresses of other manufacturers’ hardware.
Each manufacturer is responsible for making sure it doesn’t ship two Ethernet cards with the same address.
Internet addresses are normally assigned to a computer by the organization that is responsible for it.
However, the addresses that an organization is allowed to choose for its computers are assigned by the organization’s Internet service provider (ISP)
ISPs get their IP addresses from one of four regional Internet registries (the registry for North America is ARIN, the American Registry for Internet Numbers), which are in turn assigned IP addresses by the Internet Corporation for Assigned Names and Numbers (ICANN)
Names can change while addresses stay the same; likewise, addresses can change while the names stay the same.
One address can have several names and one name can refer to several different addresses.
All modern computer networks are packet-switched networks: data traveling on the network is broken into chunks called packets and each packet is handled separately.
Each packet contains information about who sent it and where it’s going.
The most important advantage of breaking data into individually addressed packets is that packets from many ongoing exchanges can travel on one wire, which makes it much cheaper to build a network: many computers can share the same wire without interfering.
In contrast, when you make a local telephone call within the same exchange on a traditional phone line, you have essentially reserved a wire from your phone to the phone of the person you’re calling.
When all the wires are in use, as sometimes happens during a major emergency or holiday, not everyone who picks up a phone will get a dial tone.
If you stay on the line, you’ll eventually get a dial tone when a line becomes free.
In some countries with worse phone service than the United States, it’s not uncommon to have to wait half an hour or more for a dial tone.
Another advantage of packets is that checksums can be used to detect whether a packet was damaged in transit.
We’re still missing one important piece: some notion of what computers need to say to pass data back and forth.
A protocol is a precise set of rules defining how computers communicate: the format of addresses, how data is split into packets, and so on.
There are many different protocols defining different aspects of network communication.
For example, the Hypertext Transfer Protocol (HTTP) defines how web browsers and.
Open, published protocol standards allow software and equipment from different vendors to communicate with one another.
A web server doesn’t care whether the client is a Unix workstation, an Android phone, or an iPad, because all clients speak the same HTTP protocol regardless of platform.
The Layers of a Network Sending data across a network is a complex operation that must be carefully tuned to the physical characteristics of the network as well as the logical character of the data being sent.
Software that sends data across a network must understand how to avoid collisions between packets, convert digital data to analog signals, detect and correct errors, route packets from one host to another, and more.
The process is further complicated when the requirement to support multiple operating systems and heterogeneous network cabling is added.
To hide most of this complexity from the application developer and end user, the different aspects of network communication are separated into multiple layers.
Each layer represents a different level of abstraction between the physical hardware (i.e., the wires and electricity) and the information being transmitted.
In theory, each layer only talks to the layers immediately above and immediately below it.
Separating the network into layers lets you modify or even replace the software in one layer without affecting the others, as long as the interfaces between the layers stay the same.
Figure 1-1 shows a stack of possible protocols that may exist in your network.
While the middle layer protocols are fairly consistent across most of the Internet today, the top and the bottom vary a lot.
Some hosts use Ethernet; some use WiFi; some use PPP; some use something else.
Similarly, what’s on the top of the stack will depend completely on which programs a host is running.
The key is that from the top of the stack, it doesn’t really matter what’s on the bottom and vice versa.
The layer model decouples the application protocols (the main subject of this book) from the physics of the network hardware and the topology of the network connections.
There are several different layer models, each organized to fit the needs of a particular kind of network.
This book uses the standard TCP/IP four-layer model appropriate for the Internet, shown in Figure 1-2
In this model, applications like Firefox and Warcraft run in the application layer and talk only to the transport layer.
The transport layer talks only to the application layer and the Internet layer.
The Internet layer in turn talks only to the host-to-network layer and the transport layer, never directly to the application layer.
The host-to-network layer moves the data across the wires, fiber-optic cables, or other medium to the host-to-network layer on the remote system, which then moves the data up the layers to the application on the remote system.
For example, when a web browser sends a request to a web server to retrieve a page, the browser is actually talking to the transport layer on the local client machine.
The internet layer fragments the segments into IP datagrams of the necessary size for the local network and passes them to the host-to-network layer for transmission onto the wire.
The host-to-network layer encodes the digital data as analog signals appropriate for the particular physical medium and sends the request out the wire where it will be read by the host-to-network layer of the remote system to which it’s addressed.
The host-to-network layer on the remote system decodes the analog signals into digital data, then passes the resulting IP datagrams to the server’s internet layer.
The internet layer does some simple checks to see that the IP datagrams aren’t corrupt, reassembles them if they’ve been fragmented, and passes them to the server’s transport layer.
The server’s transport layer checks to see that all the data arrived and requests retransmission of any missing or corrupt pieces.
This request actually goes back down through the server’s internet layer, through the server’s host-to-network layer, and back to the client system, where it bubbles back up to the client’s transport layer, which retransmits the missing data back down through the layers.
Once the server’s transport layer has received enough contiguous, sequential datagrams, it reassembles them and writes them onto a stream read by the web server running in the server application layer.
The server responds to the request and sends its response back down through the layers on the server system for transmission back across the Internet and delivery to the web client.
As you can guess, the real process is much more elaborate.
The host-to-network layer is by far the most complex, and a lot has been deliberately hidden.
For example, it’s entirely possible that data sent across the Internet will pass through several routers and their layers before reaching its final destination.
It may need to be converted from radio waves in the air to electrical signals in copper wire to light pulses in fiber-optic cables and back again, possibly more than once.
However, 90% of the time your Java code will work in the application layer and only need to talk to the transport layer.
The other 10% of the time, you’ll be in the transport layer and talking to the application layer or the internet layer.
The complexity of the host-to-network layer is hidden from you; that’s the point of the layer model.
If you read the network literature, you’re likely to encounter an alternative seven-layer model called the Open Systems Interconnection (OSI) Reference Model.
For network programs in Java, the OSI model is overkill.
The biggest difference between the OSI model and the TCP/IP model used in this book is that the OSI model splits the hostto-network layer into data link and physical layers and inserts presentation and session layers in between the application and transport layers.
The OSI model is more general and better suited for non-TCP/ IP networks, although most of the time it’s still overly complex.
In any case, Java’s network classes only work on TCP/IP networks and always in the application or transport layers, so for the purposes of this book, absolutely nothing is gained by using the more complicated OSI model.
To the application layer, it seems as if it is talking directly to the application layer on the other system; the network creates a logical path between the two application layers.
It’s easy to understand the logical path if you think about an IRC chat session.
Most participants in an IRC chat would say that they’re talking to another person.
If you really push them, they might say that they’re talking to their computer (really the application layer), which is talking to the other person’s computer, which is talking to the other person.
Everything more than one layer deep is effectively invisible, and that is exactly the way it should be.
The Host-to-Network Layer As a Java programmer, you’re fairly high up in the network food chain.
In the standard reference model for IP-based Internets (the only kind of network Java really understands), the hidden parts of the network belong to the hostto-network layer (also known as the link layer, data link layer, or network interface layer)
The host-to-network layer defines how a particular network interface—such as an Ethernet card or a WiFi antenna—sends IP datagrams over its physical connection to the local network and the world.
The part of the host-to-network layer made up of the hardware that connects different computers (wires, fiber-optic cables, radio waves, or smoke signals) is sometimes called the physical layer of the network.
As a Java programmer, you don’t need to worry about this layer unless something goes wrong—the plug falls out of the back of your computer, or someone drops a backhoe through the T–1 line between you and the rest of the world.
The primary reason you’ll need to think about the host-to-network layer and the physical layer, if you need to think about them at all, is performance.
For instance, if your clients reside on fast, reliable fiber-optic connections, you will design your protocol and applications differently than if they’re on high-latency satellite connections on an oil rig.
You’ll make still different choices if your clients are on a 3G data plan where they’re charged by the byte for relatively low bandwidth.
And if you’re writing a general consumer application that could be used by any of these clients, you’ll try to hit a sweet spot somewhere in the middle, or perhaps even detect and dynamically adapt to individual client capabilities.
However, whichever physical links you encounter, the APIs you use to communicate across those networks are the same.
The Internet Layer The next layer of the network, and the first that you need to concern yourself with, is the internet layer.
In the OSI model, the internet layer goes by the more generic name network layer.
A network layer protocol defines how bits and bytes of data are organized into the larger groups called packets, and the addressing scheme by which different machines find one another.
The Internet Protocol (IP) is the most widely used network layer protocol in the world and the only network layer protocol Java understands.
Although these are two very different network protocols that do not interoperate on the same network without special gateways and/or tunneling protocols, Java hides almost all of the differences from you.
In practice, most IPv4 datagrams are much smaller, ranging from a few dozen bytes to a little more than eight kilobytes.
An IPv6 datagram contains a larger header and up to four gigabytes of data.
All bits and bytes are big endian; most significant to least significant runs left to right.
Besides routing and addressing, the second purpose of the Internet layer is to enable different types of Host-to-Network layers to talk to each other.
Internet routers translate between WiFi and Ethernet, Ethernet and DSL, DSL and fiber-optic backhaul protocols, and so forth.
Without the internet layer or something like it, each computer could only talk to other computers that shared its particular type of network.
The internet layer is responsible for connecting heterogenous networks to each other using homogeneous protocols.
Most notably, there’s no guarantee that they will be delivered.
Even if they are delivered, they may have been corrupted in transit.
The header checksum can only detect corruption in the header, not in the data portion of a datagram.
Finally, even if the datagrams arrive uncorrupted, they do not necessarily arrive in the order in which they were sent.
Individual datagrams may follow different routes from source to destination.
Just because datagram A is sent before datagram B does not mean that datagram A will arrive before datagram B.
The transport layer is responsible for ensuring that packets are received in the order they were sent and that no data is lost or corrupted.
If a packet is lost, the transport layer can ask the sender to retransmit the packet.
The first, the Transmission Control Protocol (TCP), is a high-overhead protocol that allows for retransmission of lost or corrupted data and delivery of bytes in the order they were sent.
The second protocol, the User Datagram Protocol (UDP), allows the receiver to detect corrupted packets but does not guarantee.
Later, you’ll see that unreliable protocols are much more useful than they sound.
The Application Layer The layer that delivers data to the user is called the application layer.
The three lower layers all work together to define how data is transferred from one computer to another.
The application layer decides what to do with the data after it’s transferred.
For example, an application protocol like HTTP (for the World Wide Web) makes sure that your web browser displays a graphic image as a picture, not a long stream of numbers.
The application layer is where most of the network parts of your programs spend their time.
There is an entire alphabet soup of application layer protocols: in addition to HTTP for the Web, there are SMTP, POP, and IMAP for email; FTP, FSP, and TFTP for file transfer; NFS for file access; Gnutella and BitTorrent for file sharing; the Session Initiation Protocol (SIP) and Skype for voice communication; and many, many more.
In addition, your programs can define their own application layer protocols as necessary.
IP, TCP, and UDP IP, the Internet protocol, was developed with military sponsorship during the Cold War, and ended up with a lot of features that the military was interested in.
The entire network couldn’t stop functioning if the Soviets nuked a router in Cleveland; all messages still had to get through to their intended destinations (except those going to Cleveland, of course)
Therefore, IP was designed to allow multiple routes between any two points and to route packets of data around damaged routers.
Second, the military had many different kinds of computers, and all of them had to be able to talk to one another.
The IBM mainframes needed to talk to the PDP-11s and any other strange computers that might be lying around.
Because there are multiple routes between two points, and because the quickest path between two points may change over time as a function of network traffic and other factors (such as the existence of Cleveland), the packets that make up a particular data stream may not all take the same route.
Furthermore, they may not arrive in the order they were sent, if they even arrive at all.
To improve on the basic scheme, TCP was layered on top of IP to give each end of a connection the ability to acknowledge receipt of IP packets and request retransmission of lost or corrupted packets.
Furthermore, TCP allows the packets to be put back together on the receiving end in the same order they were sent.
Therefore, if the order of the data isn’t particularly important and if the loss of individual packets won’t completely corrupt the data stream, packets are sometimes sent without the guarantees that TCP provides using the UDP protocol.
Although this would be a problem for uses such as file transfer, it is perfectly acceptable for applications where the loss of some data would go unnoticed by the end user.
For example, losing a few bits from a video or audio signal won’t cause much degradation; it would be a bigger problem if you had to wait for a protocol like TCP to request a retransmission of missing data.
Furthermore, error-correcting codes can be built into UDP data streams at the application level to account for missing data.
A number of other protocols can run on top of IP.
The most commonly requested is ICMP, the Internet Control Message Protocol, which uses raw IP datagrams to relay error messages between hosts.
The best-known use of this protocol is in the ping program.
Java does not support ICMP, nor does it allow the sending of raw IP datagrams (as opposed to TCP segments or UDP datagrams)
The only protocols Java supports are TCP and UDP, and application layer protocols built on top of these.
All other transport layer, internet layer, and lower layer protocols such as ICMP, IGMP, ARP, RARP, RSVP, and others can only be implemented in Java programs by linking to native code.
Every computer on an IPv4 network is identified by a four-byte number.
Every computer attached to an IPv4 network has a unique four-byte address.
When data is transmitted across the network, the packet’s header includes the address of the machine for which the packet is intended (the destination address) and the address of the machine that sent the packet (the source address)
Routers along the way choose the best route on which to send the packet by inspecting the destination address.
The source address is included so the recipient will know who to reply to.
There are a little more than four billion possible IP addresses, not even one for every person on the planet, much less for every computer.
To make matters worse, the addresses aren’t allocated very efficiently.
No more IPv4 addresses were available to be allocated to these regions; and they have since had to make do by recycling and reallocating from their existing supply.
North America, Latin America, and Africa still have a few IP address blocks left to parcel out, but they’re not going to last much longer.
This provides enough IP addresses to identify every person, every computer, and indeed every device.
A double colon, at most one of which may appear in any address, indicates multiple zero blocks.
Although computers are very comfortable with numbers, human beings aren’t very good at remembering them.
When Java programs access the network, they need to process both these numeric addresses and their corresponding hostnames.
Others, especially clients on local area networks and wireless connections, receive a different address every time they boot up, often provided by a DHCP server.
Mostly you just need to remember that IP addresses may change over time, and not write any code that relies on a system having the same IP address.
For instance, don’t store the local IP address when saving application state.
Instead, look it up fresh each time your program starts.
It’s also possible, although less likely, for an IP address to change while the program is running (e.g., if a DHCP lease expires), so you may want to check the current IP address every time you need it rather than caching it.
Otherwise, the difference between a dynamically and manually assigned address is not significant to Java programs.
They can be used on internal networks, but no host using addresses in these blocks is allowed onto the global Internet.
These non-routable addresses are useful for building private networks that can’t be seen on the Internet.
That is, these addresses always point to the local computer, no matter which computer you’re running on.
The address 0.0.0.0 always refers to the originating host, but may only be used as a source address, not a destination.
Packets sent to this address are received by all nodes on the local network, though they are not routed beyond the local network.
All nodes on the network receive the packet, but only the DHCP server responds.
In particular, it sends the laptop information about the local network configuration, including the IP address that laptop should use for the remainder of its session and the address of a DNS server it can use to resolve hostnames.
Ports Addresses would be all you needed if each computer did no more than one thing at a time.
Email needs to be separated from FTP requests, which need to be separated from web traffic.
Each computer with an IP address has several thousand logical ports (65,535 per transport layer protocol, to be precise)
These are purely abstractions in the computer’s memory and do not represent anything physical, like a USB port.
We say that a web server listens on port 80 for incoming connections.
When data is sent to a web server on a particular machine at a particular IP address, it is also sent to a particular port (usually port 80) on that machine.
The receiver checks each packet it sees for the port and sends the data to any program that is listening to that port.
This is how different types of traffic are sorted out.
On Unix systems, including Linux and Mac OS X, only programs running as root can receive data from these ports, but all programs may send data to them.
On Windows, any program may use these ports without special privileges.
Table 1-1 shows the well-known ports for the protocols that are discussed in this book.
On Unix systems, a fairly complete listing of assigned ports is stored in the file /etc/services.
It is an amorphous group of computers in many different countries on all seven continents (Antarctica included) that talk to one another using IP protocols.
Each computer on the Internet has at least one IP address by which it can be identified.
Many of them also have at least one name that maps to that IP address.
The Internet is not owned by anyone, although pieces of it are.
It is not governed by anyone, which is not to say that some governments don’t try.
It is simply a very large collection of computers that have agreed to talk to one another in a standard way.
The Internet is not the only IP-based network, but it is the largest one.
Other IP networks are called internets with a little i: for example, a high-security internal network that is not connected to the global Internet.
Intranet loosely describes corporate practices of putting lots of data on internal web servers that are not visible to users outside the local network.
Unless you’re working in a high-security environment that’s physically disconnected from the broader network, it’s likely that the internet you’ll be using is the Internet.
To make sure that hosts on different networks on the Internet can communicate with each other, a few rules need to be followed that don’t apply to purely internal internets.
The most important rules deal with the assignment of addresses to different organizations, companies, and individuals.
If everyone picked the Internet addresses they wanted at random, conflicts would arise almost immediately when different computers showed up on the Internet with the same address.
Internet Address Blocks To avoid this problem, blocks of IPv4 addresses are assigned to Internet service providers (ISPs) by their regional Internet registry.
When a company or an organization wants to set up an IP-based network connected to the Internet, their ISP assigns them a block of addresses.
However, the lowest address in all block used to identify the network itself, and the largest address is a broadcast address for the network, so you have two fewer available addresses than you might first expect.
Network Address Translation Because of the increasing scarcity of and demand for raw IP addresses, most networks today use Network Address Translation (NAT)
The routers that connect the local networks to the ISP translate these local addresses to a much smaller set of routable addresses.
For instance, the dozen or so IP nodes in my apartment all share a single externally visible IP address.
The computer on which I’m typing this has the IP address 192.168.1.5, but on your network that address may refer to a completely different host, if it exists at all.
Nor could you reach my computer by sending data to 192.168.1.5
The router watches my outgoing and incoming connections and adjusts the addresses in the IP packets.
For an incoming packet, it changes the destination address to one of the local addresses, such as 192.168.1.12
Exactly how it keeps track of which connections come from and are aimed at which internal computers is not particularly important to a Java programmer.
As long as your machines are configured properly, this process is mostly transparent.
You just need to remember that the external and internal addresses may not be the same.
Subnets will still exist for routing, but they’ll be much larger.
To keep them out, it’s often helpful to set up one point of access to a local network and check all traffic into or out of that access.
The hardware and software that sit between the Internet and the local network, checking all the data that comes in or out to make sure it’s kosher, is called a firewall.
The firewall is often part of the router that connects the local network to the broader Internet and may perform other tasks, such as network address translation.
Modern operating systems like Mac OS X and Red Hat Linux often have built-in personal firewalls that monitor just the traffic sent to that one machine.
Either way, the firewall is responsible for inspecting each packet that passes into or out of its network interface and accepting it or rejecting it according to a set of rules.
For example, all traffic coming from the Class C network 193.28.25.x may be rejected because you had bad experiences with hackers from that network in the past.
Outgoing SSH connections may be allowed, but incoming SSH connections may not.
Incoming connections on port 80 (web) may be allowed, but only to the corporate web server.
More intelligent firewalls look at the contents of the packets to determine whether to accept or reject them.
The exact configuration of a firewall—which packets of data are and to pass through and which are not—depends on the security needs of an individual site.
Java doesn’t have much to do with firewalls—except insofar as they often get in your way.
If a firewall prevents hosts on a network from making direct connections to the outside world, a proxy server can act as a go-between.
Thus, a machine that is prevented from connecting to the external network by a firewall would make a request for a web page from the local proxy server instead of requesting the web page directly from the remote web server.
The proxy server would then request the page from the web server and forward the response back to the original requester.
Proxies can also be used for FTP services and other connections.
One of the security advantages of using a proxy server is that external hosts only find out about the proxy server.
They do not learn the names and IP addresses of the internal machines, making it more difficult to hack into internal systems.
Whereas firewalls generally operate at the level of the transport or internet layer, proxy servers normally operate at the application layer.
A proxy server has a detailed understanding of some application-level protocols, such as HTTP and FTP.
The notable exception are SOCKS proxy servers that operate at the transport layer, and can proxy for all TCP and UDP connections regardless of application layer protocol.
Packets that pass through the proxy server can be examined to ensure that they contain data appropriate for their type.
For instance, FTP packets that seem to contain Telnet data can be rejected.
Figure 1-4 shows how proxy servers fit into the layer model.
As long as all access to the Internet is forwarded through the proxy server, access can be tightly controlled.
Some companies allow incoming FTP but disallow outgoing FTP so confidential data cannot be as easily smuggled out of the company.
Other companies use proxy servers to track their employees’ web usage so they can see who’s using the Internet to get tech support and who’s using it to check out the Playmate of the Month.
Proxy servers can also be used to implement local caching.
When a file is requested from a web server, the proxy server first checks to see if the file is in its cache.
If the file is in the cache, the proxy serves the file from the cache rather than from the Internet.
If the file is not in the cache, the proxy server retrieves the file, forwards it to the requester, and stores it in the cache for the next time it is requested.
This scheme can significantly reduce load on an Internet connection and greatly improve response time.
America Online runs one of the largest farms of proxy servers in the world to speed the transfer of data to its users.
If you look at a web server logfile, you’ll probably find some hits from clients in the aol.com domain, but not as many as you’d expect given the more than three million AOL subscribers.
That’s because AOL proxy servers supply many pages out of their cache rather than re-requesting them for one another.
The biggest problem with proxy servers is their inability to cope with all but a few protocols.
Generally established protocols like HTTP, FTP, and SMTP are allowed to pass through, while newer protocols like BitTorrent are not.
In the rapidly changing world of the Internet, this is a significant disadvantage.
It’s a particular disadvantage for Java programmers because it limits the effectiveness of custom protocols.
In Java, it’s easy and often useful to create a new protocol that is optimized for your application.
Consequently, some developers have taken to tunneling their protocols through HTTP, most notably with SOAP.
The firewall is normally there for a reason, not just to annoy Java programmers.
Applets that run in web browsers normally use the proxy server settings of the web browser itself, though these can be overridden in the Java Control Panel.
Standalone Java applications can indicate the proxy server to use by setting the socksProxyHost and socksProxyPort properties (if you’re using a SOCKS proxy server), or http.proxySet, http.proxyHost, http.proxyPort, https.proxySet, https.proxy Host, https.proxyPort, ftpProxySet, ftpProxyHost, ftpProxyPort, gopherProxy Set, gopherProxyHost, and gopherProxyPort system properties (if you’re using protocol-specific proxies)
You can set system properties from the command line using the -D flag, like this:
The Client/Server Model Most modern network programming is based on a client/server model.
A client/server application typically stores large quantities of data on an expensive, high-powered server or cloud of servers while most of the program logic and the user interface is handled by client software running on relatively cheap personal computers.
In most cases, a server primarily sends data while a client primarily receives it; but it is rare for one program to send or receive exclusively.
A more reliable distinction is that a client initiates a conversation while a server waits for clients to start conversations with it.
In some cases, the same program may be both a client and a server.
You are already familiar with many examples of client/server systems.
In 2013, the most popular client/server system on the Internet is the Web.
Web servers like Apache respond to requests from web clients like Firefox.
Data is stored on the web server and is sent out to the clients that request it.
Aside from the initial request for a page, almost all data is transferred from the server to the client, not from the client to the server.
People often use FTP to upload files from the client to the server, so it’s harder to say that the data transfer is primarily in one direction, but it is still true that an FTP client initiates the connection and the FTP server responds.
For instance, in networked games, it seems likely that both players will send data back and forth roughly equally (at least in a fair game)
The telephone system is the classic example of a peer-to-peer network.
Each phone can either call another phone or be called by another phone.
You don’t have to buy one phone to send calls and another to receive them.
Java does not have explicit peer-to-peer communication in its core networking API.
However, applications can easily offer peer-to-peer communications in several ways, most commonly by acting as both a server and a client.
Alternatively, the peers can communicate with each other through an intermediate server program that forwards data from one peer to the other peers.
This neatly solves the discovery problem of how two peers find each other.
Internet Standards This book discusses several application layer Internet protocols, most notably HTTP.
If you need detailed information about any protocol, the definitive source is the standards document for the protocol.
Although there are many standards organizations in the world, the two that produce most of the standards relevant to application layer network programming and protocols are the Internet Engineering Task Force (IETF) and the World Wide Web Consortium (W3C)
The IETF is a relatively informal, democratic body open to participation by any interested party.
Its standards are based on “rough consensus and running code” and.
The W3C, by contrast, is a vendor organization, controlled by duespaying member corporations, that explicitly excludes participation by individuals.
For the most part, the W3C tries to define standards in advance of implementation.
Despite the name, a published RFC is a finished work.
It may be obsoleted or replaced by a new RFC, but it will not be changed.
RFCs range from informational documents of general interest to detailed specifications of standard Internet protocols such as FTP.
RFCs are available from many locations on the Internet, including http://www.faqs.org/rfc/ and http://www.ietf.org/rfc.html.
For the most part, RFCs, (particularly standards-oriented RFCs), are very technical, turgid, and nearly incomprehensible.
Nonetheless, they are often the only complete and reliable source of information about a particular protocol.
Most proposals for an RFC begin when a person or group gets an idea and builds a prototype.
Before something can become an IETF standard, it must actually exist and work.
This requirement ensures that IETF standards are at least feasible, unlike the standards promulgated by some other organizations.
Table 1-2 lists the RFCs that provide formal documentation for the protocols discussed in this book.
Describes the standardization process and the current status of the different Internet protocols.
Host Requirements Documents the protocols that must be supported by all Internet hosts at different layers (data link layer, IP layer, transport layer, and application layer)
An internet layer protocol that uses raw IP datagrams but is not supported by Java.
The application layer protocol by which one host transfers email to another host.
This standard doesn’t say anything about email user interfaces; it covers the mechanism for passing email from one computer to another.
Telnet Protocol An application layer remote login service for command-line environments based around an abstract network virtual terminal (NVT) and TCP.
An application layer protocol that sends an indefinite sequence of ASCII characters to any client that connects over either TCP or UDP; also useful as a debugging tool.
This contrasts with the various NTP and Time Server protocols, which do not return data that can be easily read by humans.
The time is sent as a machinereadable, 32-bit unsigned integer.
The standard is incomplete in that it does not specify how the integer is encoded in 32 bits, but in practice a big-endian integer is used.
The application layer protocol by which Usenet news is transferred from machine to machine over TCP; used by both news clients talking to news servers and news servers talking to each other.
This RFC defines how domain name servers on different hosts communicate with each other using UDP.
The internet layer methods by which conforming systems can direct a single packet of data to multiple hosts.
A more precise application layer protocol for synchronizing clocks between systems that attempts to account for network latency.
An application layer protocol used by sporadically connected email clients such as Eudora to retrieve mail from a server over TCP.
A means of encoding binary data and non-ASCII text for transmission through Internet email and other ASCII-oriented protocols.
Similar to URLs but intended to refer to actual resources in a persistent fashion rather than the transient location of those resources.
Version 1.1 of the application layer protocol used by web browsers talking to web servers over TCP.
A protocol for remotely accessing a mailbox stored on a server including downloading messages, deleting messages, and moving messages into and out of different folders.
For instance, ISBN numbers may be URIs even if the book cannot be retrieved over the Internet.
The IETF has traditionally worked behind the scenes to codify and standardize existing practice.
Although its activities are completely open to the public, it’s been very low profile.
There simply aren’t that many people who get excited about network arcana like the Internet Gateway Message Protocol (IGMP)
The participants in the process have mostly been engineers and computer scientists, including many from academia as well as the corporate world.
Consequently, despite often vociferous debates about ideal implementations, most serious IETF efforts have produced reasonable standards.
Unfortunately, that can’t be said of the IETF’s efforts to produce web (as opposed to Internet) standards.
In particular, the IETF’s early effort to standardize HTML was a colossal failure.
The refusal of Netscape and other key vendors to participate or even acknowledge the process was a crucial problem.
That HTML was simple enough and high profile enough to attract the attention of assorted market droids and random flamers didn’t help matters either.
Thus, in October 1994, the World Wide Web Consortium was formed as a vendor-controlled body that might be able to avoid the pitfalls that plagued the IETF’s efforts to standardize HTML and HTTP.
Whereas the IETF is open to participation by anyone, only corporations and other organizations may become members of.
Individuals are specifically excluded, though they may become invited experts on particular working groups.
However, the number of such individuals is quite small relative to the number of interested experts in the broader community.
Membership in the IETF costs $0 a year with no commitment beyond a willingness to participate.
Clearly, the IETF is a much more democratic (some would say anarchic) and open organization than the W3C.
Despite the W3C’s strong bias toward the corporate members that pay its bills, it has so far managed to do a better job of navigating the politically tricky waters of web standardization than the IETF.
It has produced several HTML standards, as well as a variety of others such as HTTP, PICS, XML, CSS, MathML, and more.
The W3C has had considerably less success in convincing vendors like Mozilla and Microsoft to fully and consistently implement its standards.
Notes will not necessarily lead to the formation of a working group or a W3C recommendation.
Working drafts A working draft is a reflection of the current thinking of some (not necessarily all) members of a working group.
It should eventually lead to a proposed recommendation, but by the time it does so it may have changed substantially.
Candidate recommendation A candidate recommendation indicates that the working group has reached consensus on all major issues and is ready for third-party comment and implementations.
If the implementations do not uncover any obstructions, the spec can be promoted to a candidate recommendation.
Proposed recommendation A proposed recommendation is mostly complete and unlikely to undergo more than minor editorial changes.
The main purpose of a proposed recommendation is to work out bugs in the specification document rather than in the underlying technology being documented.
Recommendation A recommendation is the highest level of W3C standard.
However, the W3C is very careful not to actually call this a “standard” for fear of running afoul of antitrust statutes.
The IETF calls these submissions “Internet drafts” and publishes them for six months before deleting them.
The W3C refers to such submissions as “acknowledged submissions” and publishes them indefinitely.
However, neither organization actually promises to do more than acknowledge receipt of these documents.
In particular, they do not promise to form a working group or begin the standardization process.
Nonetheless, press releases invariably misrepresent the submission of such a document as a far more significant event than it actually is.
However, you should recognize these ploys for what they are.
A large part of what network programs do is simple input and output: moving bytes from one system to another.
Bytes are bytes; to a large extent, reading data a server sends you is not all that different from reading a file.
Sending text to a client is not that different from writing a file.
However, input and output (I/O) in Java is organized differently than it is in most other languages, such as Fortran, C, and C++
Consequently, I’ll take a few pages to summarize Java’s unique approach to I/O.
However, all output streams have the same basic methods to write data and all input streams use the same basic methods to read data.
After a stream is created, you can often ignore the details of exactly what it is you’re reading or writing.
Filter streams can be chained to either an input stream or an output stream.
Filters can modify the data as it’s read or written—for instance, by encrypting or compressing itor they can simply provide additional methods for converting the data that’s read or written into other formats.
Readers and writers can be chained to input and output streams to allow programs to read and write text (i.e., characters) rather than bytes.
Used properly, readers and writers can handle a wide variety of character encodings, including multibyte character sets such as SJIS and UTF-8
Streams are synchronous; that is, when a program (really a thread) asks a stream to read or write a piece of data, it waits for the data to be read or written before it does anything else.
Nonblocking I/O is a little more complicated, but can be much faster in some high-volume applications, such.
Normally, the basic stream model is all you need and all you should use for clients.
This class provides the fundamental methods needed to write data.
Subclasses of OutputStream use these methods to write data onto particular media.
For instance, a FileOutputStream uses these methods to write data into a file.
A TelnetOutputStream uses these methods to write data onto a network connection.
But whichever medium you’re writing to, you mostly use only these same five methods.
Sometimes you may not even know exactly what kind of stream you’re writing onto.
For instance, you won’t find TelnetOutputStream in the Java class library documentation.
It’s returned by various methods in various classes in java.net, like the getOutputStream() method of java.net.Sock et.
However, these methods are declared to return only OutputStream, not the more specific subclass TelnetOutputStream.
If you know how to use the superclass, you know how to use all the subclasses, too.
This method is declared abstract because subclasses need to change it to handle their particular medium.
However, a FileOutput Stream will need to use native code that understands how to write data in files on the host platform.
Take note that although this method takes an int as an argument, it actually writes an unsigned byte.
Java doesn’t have an unsigned byte data type, so an int has to be used here instead.
The only real difference between an unsigned byte and a signed byte is the interpretation.
They’re both made up of eight bits, and when you write an int onto a network connection using write(int b), only eight bits are placed on the wire.
If an int outside the range 0–255 is passed to write(int b), the least significant byte of the.
This is the effect of casting an int to a byte.
The most popular variation of this protocol sends 72-character lines containing printable ASCII characters.
Because ASCII is a 7-bit character set, each character is sent as a single byte.
Consequently, this protocol is straightforward to implement using the basic write() methods, as the next code fragment demonstrates:
Most of the arithmetic here is to make the loop rotate in that range.
After each 72-character chunk is written, a carriage return and a linefeed are written onto the output stream.
The next start character is calculated and the loop repeats.
Writing a single byte at a time is often inefficient.
For example, every TCP segment contains at least 40 bytes of overhead for routing and error correction.
If each byte is sent by itself, you may be stuffing the network with 41 times more data than you think you are! Add overhead of the host-to-network layer protocol, and this can be even worse.
That is, they accumulate bytes in memory and send them to their eventual destination only when a certain number have accumulated or a certain amount of time has passed.
However, if you have more than one byte ready to go, it’s not a bad idea to send them all at once.
Using write(byte[] data) or write(byte[] data, int offset, int length) is normally much faster than writing all the components of the data array one at a time.
The algorithm for calculating which bytes to write when is the same as for the previous implementation.
The crucial difference is that the bytes are packed into a byte array before being written onto the network.
Also, notice that the int result of the calculation must be cast to a byte before being stored in the array.
This wasn’t necessary in the previous implementation because the single-byte write() method is declared to take an int as an argument.
Streams can also be buffered in software, directly in the Java code as well as in the network hardware.
Typically, this is accomplished by chaining a BufferedOutput Stream or a BufferedWriter to the underlying stream, a technique we’ll explore shortly.
Consequently, if you are done writing data, it’s important to flush the output stream.
You generally want to wait for a response before sending any more data.
However, if the output stream has a 1,024-byte buffer, the stream may be waiting for more data to arrive before it sends the data out of its buffer.
The flush() method breaks the deadlock by forcing the buffered stream to send its data even if the buffer isn’t yet full.
Data can get lost if you don’t flush your streams.
It’s important to flush your streams whether you think you need to or not.
Depending on how you got hold of a reference to the stream, you may or may not know whether it’s buffered.
For instance, System.out is buffered whether you want it to be or not.
Failing to flush when you need to can lead to unpredictable, unrepeatable program hangs that are extremely hard to diagnose if you don’t have a good idea of what the problem is in the first place.
As a corollary to all this, you should flush all streams immediately before you close them.
Otherwise, data left in the buffer when the stream is closed may get lost.
Finally, when you’re done with a stream, close it by invoking its close() method.
This releases any resources associated with the stream, such as file handles or ports.
If the stream derives from a network connection, then closing the stream terminates the connection.
Once an output stream has been closed, further writes to it throw IOExcep tions.
However, some kinds of streams may still allow you to do things with the object.
Failure to close a stream in a long-running program can leak file handles, network ports, and other resources.
Consequently, in Java 6 and earlier, it’s wise to close the stream in a finally block.
To get the right variable scope, you have to declare the stream variable outside the try block but initialize it inside the try block.
Furthermore, to avoid Null PointerExceptions you need to check whether the stream variable is null before closing it.
Finally, you usually want to ignore or at most log any exceptions that occur while closing the stream.
This technique is sometimes called the dispose pattern; and it’s common for any object that needs to be cleaned up before it’s garbage collected.
You’ll see it used not just for streams, but also for sockets, channels, JDBC connections and statements, and more.
Java 7 introduces the try with resources construct to make this cleanup neater.
Instead of declaring the stream variable outside the try block, you declare it inside an argument list of the try block.
For instance, the preceding fragment now becomes the much simpler:
Java automatically invokes close() on any AutoCloseable objects declared inside the argument list of the try block.
So far, JavaMail Transport objects are only exceptions I’ve encountered.
This class provides the fundamental methods needed to read data as raw bytes.
Concrete subclasses of InputStream use these methods to read data from particular media.
But whichever source you’re reading, you mostly use only these same six methods.
Sometimes you don’t know exactly what kind of stream you’re reading from.
For instance, TelnetInputStream is an undocumented class hidden inside the sun.net package.
Instances of it are returned by various methods in the java.net package (e.g., the openStream() method of java.net.URL)
However, these methods are declared to return only InputStream, not the more specific subclass TelnetInputStream.
The instance of the subclass can be used transparently as an instance of its superclass.
The basic method of InputStream is the noargs read() method.
The read() method waits and blocks execution of any code that follows it until a byte of data is available and ready to be read.
Input and output can be slow, so if your program is doing anything else of importance, try to put I/O in its own thread.
The read() method is declared abstract because subclasses need to change it to handle their particular medium.
However, a TelnetInputStream needs to use a native library that understands how to read data from the network interface on the host platform.
The following code fragment reads 10 bytes from the InputStream in and stores them in the byte array input.
However, if end of stream is detected, the loop is terminated early:
Although read() only reads a byte, it returns an int.
Thus, a cast is necessary before storing the result in the byte array.
However, as long as you’re clear about which one you’re working with, this is not a major problem.
You can convert a signed byte to an unsigned byte like this:
Reading a byte at a time is as inefficient as writing data one byte at a time.
Consequently, there are two overloaded read() methods that fill a specified array with multiple bytes of data read from the stream read(byte[] input) and read(byte[] input, int offset, int length)
The first method attempts to fill the specified array input.
The second attempts to fill the specified subarray of input, starting at offset and continuing for length bytes.
Notice I said these methods attempt to fill the array, not that they necessarily succeed.
For instance, it’s not unheard of that while your program is reading data from a remote web server over DSL, a bug in a switch at a phone company central office will disconnect you and several hundred of your neighbors from the rest of the world.
More commonly, however, a read attempt won’t completely fail but won’t completely succeed either.
Some of the requested bytes may be read, but not all of them.
They’ll arrive eventually, but they aren’t available at this moment.
To account for this, the multibyte read methods return the number of bytes actually read.
It attempts to read 1,024 bytes from the InputStream in into the array input.
To guarantee that all the bytes you want are actually read, place the read in a loop that reads repeatedly until the array is filled.
Chances are that if a file is available at all, all the bytes of a file are also available.
However, because networks move much more slowly than CPUs, it is very easy for a program to empty a network buffer before all the data has arrived.
In fact, if one of these two methods tries to read from a temporarily empty but open network buffer, it will generally return 0, indicating that no data is available but the stream is not yet closed.
This is often preferable to the behavior of the single-byte read() method, which blocks the running thread in the same circumstances.
All three read() methods return –1 to signal the end of the stream.
If the stream ends while there’s still data that hasn’t been read, the multibyte read() methods return the data until the buffer has been emptied.
The next call to any of the read() methods will return –1
The previous code fragment had a bug because it didn’t consider the possibility that all 1,024 bytes might never arrive (as opposed to not being immediately available)
Fixing that bug requires testing the return value of read() before adding it to bytesRead.
If you do not want to wait until all the bytes you need are immediately available, you can use the available() method to determine how many bytes can be read without blocking.
This returns the minimum number of bytes you can read.
You may in fact be able to read more, but you will be able to read at least as many bytes as available() suggests.
In this case, you can expect that bytesRead is exactly equal to bytesAvailable.
You cannot, however, expect that bytesRead is greater than zero.
On rare occasions, you may want to skip over data without reading it.
It’s less useful on network connections than when reading from files.
Network connections are sequential and normally quite slow, so it’s not significantly more time consuming to read data than to skip over it.
Files are random access so that skipping can be implemented simply by repositioning a file pointer rather than processing each byte to be skipped.
As with output streams, once your program has finished with an input stream, it should close it by invoking its close() method.
This releases any resources associated with the stream, such as file handles or ports.
Once an input stream has been closed, further reads from it throw IOExceptions.
However, some kinds of streams may still allow you to do things with the object.
Marking and Resetting The InputStream class also has three less commonly used methods that allow programs to back up and reread data they’ve already read.
In order to reread data, mark the current position in the stream with the mark() method.
At a later point, you can reset the stream to the marked position using the reset() method.
Subsequent reads then return data starting from the marked position.
However, you may not be able to reset as far back as you like.
The number of bytes you can read from the mark and still reset is determined by the readAheadLimit argument to mark()
If you try to reset too far back, an IOException is thrown.
Furthermore, there can be only one mark in a stream at any given time.
Marking and resetting are usually implemented by storing every byte read from the marked position on in an internal buffer.
Before trying to use marking and resetting, check whether the markSupported() method returns true.
Otherwise, mark() will do nothing and reset() will throw an IOException.
In practice, more streams don’t support marking and resetting than do.
Attaching functionality to an abstract superclass that is not available to many, probably most, subclasses is a very poor idea.
It would be better to place these three methods in a separate interface that could be implemented by those classes that provided this functionality.
The disadvantage of this approach is that you couldn’t then invoke these methods on an arbitrary input stream of unknown type; but in practice, you can’t do that anyway because not all streams support marking and resetting.
An object-oriented approach would embed this in the type system through interfaces and classes so that it could all be checked at compile time.
However, other input streams such as Telne tInputStream may support marking if they’re chained to a buffered input stream first.
They read and write bytes singly or in groups, but that’s all.
Deciding what those bytes mean—whether they’re integers or IEEE 754 floating-point numbers or Unicode text—is completely up to the programmer and the code.
However, there are certain extremely common data formats that can benefit from a solid implementation in the class library.
For example, many integers passed as parts of network protocols are 32-bit big-endian integers.
Many files transferred by FTP are stored in the ZIP format.
Java provides a number of filter classes you can attach to raw streams to translate the raw bytes to and from these and other formats.
The filters come in two versions: the filter streams, and the readers and writers.
The filter streams still work primarily with raw data as bytes: for instance, by compressing the data or interpreting it as binary numbers.
Filters are organized in a chain, as shown in Figure 2-2
Each link in the chain receives data from the previous filter or stream and passes the data along to the next link in the.
In this example, a compressed, encrypted text file arrives from the local network interface, where native code presents it to the undocumented TelnetInputStream.
Finally, the text is read into the application and processed.
Every filter input stream has the same read(), close(), and.
The filtering is purely internal and does not expose any new public interface.
However, in most cases, the filter stream adds public methods with additional purposes.
At other times, they almost completely replace the original interface.
For example, it’s relatively rare to use the write() method of PrintStream instead of one of its print() and println() methods.
Chaining Filters Together Filters are connected to streams by their constructors.
For example, the following code fragment buffers input from the file data.txt.
First, a FileInputStream object fin is created by passing the name of the file as an argument to the FileInputStream constructor.
From this point forward, it’s possible to use the read() methods of both fin and bin to read data from the file data.txt.
However, intermixing calls to different streams connected to the same source may violate several implicit contracts of the filter streams.
Most of the time, you should only use the last filter in the chain to do the actual reading or writing.
One way to write your code so that it’s at least harder to introduce this sort of bug is to deliberately overwrite the reference to the underlying input stream.
After these two lines execute, there’s no longer any way to access the underlying file input stream, so you can’t accidentally read from it and corrupt the buffer.
In cases where it is necessary to use the additional methods of the filter stream not declared in the superclass, you may be able to construct one stream directly inside another.
Although these statements can get a little long, it’s easy to split the statement across several lines, like this:
There are times when you may need to use the methods of multiple filters in a chain.
Or, if you’re connecting to a web server, you may want to read the header the server sends to find the Content-encoding and then use that content encoding to pick the right Reader filter to read the body of the response.
Or perhaps you want to send floating-point numbers across a network connection using a DataOutputStream and then retrieve a MessageDigest from the DigestOutputStream that the DataOut putStream is chained to.
In all these cases, you need to save and use references to each of the underlying streams.
However, under no circumstances should you ever read from or write to anything other than the last filter in the chain.
Then it writes the data onto the underlying output stream all at once.
A single write of many bytes is almost always much faster than many small writes that add up to the same thing.
This is especially true of network connections because each TCP segment or UDP packet carries a finite amount of overhead, generally about 40 bytes’ worth.
Most network cards and TCP implementations provide some level of buffering themselves, so the real numbers aren’t quite this dramatic.
Nonetheless, buffering network output is generally a huge performance win.
When one of the stream’s read() methods is called, it first tries to get the requested data from the buffer.
Only when the buffer runs out of data does the stream read from the underlying source.
At this point, it reads as much data as it can from the source into the buffer, whether it needs all the data immediately or not.
Data that isn’t used immediately will be available for later invocations of read()
When reading files from a local disk, it’s almost as fast to read several hundred bytes of data from the underlying stream as it is to read one byte of data.
The gain is less obvious on network connections where the bottleneck is often the speed at which the network can deliver data rather than the speed at which the network interface delivers data to the program or the speed at which the.
Nonetheless, buffering input rarely hurts and will become more important over time as network speeds increase.
The first argument is the underlying stream from which unbuffered data will be read or to which buffered data will be written.
The second argument, if present, specifies the number of bytes in the buffer.
The ideal size for a buffer depends on what sort of stream you’re buffering.
For network connections, you want something a little larger than the typical packet size.
However, this can be hard to predict and varies depending on local network connections and protocols.
Faster, higher-bandwidth networks tend to use larger packets, although TCP segments are often no larger than a kilobyte.
The two multibyte read() methods attempt to completely fill the specified array or subarray of data by reading from the underlying input stream as many times as necessary.
They return only when the array or subarray has been completely filled, the end of stream is reached, or the underlying stream would block on further reads.
They read from the underlying stream or data source only once before returning.
You invoke its methods exactly as you would in any output stream.
The difference is that each write places data in the buffer rather than directly on the underlying output stream.
Consequently, it is essential to flush the stream when you reach a point at which the data needs to be sent.
PrintStream The PrintStream class is the first filter output stream most programmers encounter because System.out is a PrintStream.
However, other output streams can also be chained to print streams, using these two constructors:
However, if the autoFlush argument is true, the stream will be flushed every time a byte array or linefeed is written or a println() method is invoked.
Each print() method converts its argument to a string in a predictable fashion and writes the string onto the underlying output stream using the default encoding.
The println() methods do the same thing, but they also append a platform-dependent line separator to the end of the line they write.
PrintStream is evil and network programmers should avoid it like the plague!
The first problem is that the output from println() is platform dependent.
Depending on what system runs your code, lines may sometimes be broken with a linefeed, a carriage return, or a carriage return/linefeed pair.
This doesn’t cause problems when writing to the console, but it’s a disaster for writing network clients and servers that must follow a precise protocol.
Most network protocols such as HTTP and Gnutella specify that lines should be terminated with a carriage return/linefeed pair.
Using println() makes it easy to write a program that works on Windows but fails on Unix and the Mac.
Although many servers and clients are liberal in what they accept and can handle incorrect line terminators, there are occasional exceptions.
The second problem is that PrintStream assumes the default encoding of the platform on which it’s running.
However, this encoding may not be what the server or client expects.
For example, a web browser receiving XML files will expect them to be encoded.
However, a web server that uses PrintStream may well send the files encoded in CP1252 from a U.S.-localized Windows system or SJIS from a Japanese-localized system, whether the client expects or understands those encodings or not.
PrintStream doesn’t provide any mechanism for changing the default encoding.
This problem can be patched over by using the related Print Writer class instead.
This makes PrintStream suitable for textbook programs such as HelloWorld, because simple console output can be taught without burdening students with first learning about exception handling and all that implies.
However, network connections are much less reliable than the console.
Connections routinely fail because of network congestion, phone company misfeasance, remote systems crashing, and many other reasons.
Network programs must be prepared to deal with unexpected interruptions in the flow of data.
However, PrintStream catches any exceptions thrown by the underlying output stream.
Notice that the declaration of the standard five Output Stream methods in PrintStream does not have the usual throws IOException declaration:
Instead, PrintStream relies on an outdated and inadequate error flag.
If the underlying stream throws an exception, this internal error flag is set.
The programmer is relied upon to check the value of the flag using the checkError() method:
To do any error checking at all on a PrintStream, the code must explicitly check every call.
Furthermore, once an error has occurred, there is no way to unset the flag so further errors can be detected.
In short, the error notification provided by PrintStream is wholly inadequate for unreliable network connections.
Data Streams The DataInputStream and DataOutputStream classes provide methods for reading and writing Java’s primitive data types and strings in a binary format.
The binary formats used are primarily intended for exchanging data between two different Java programs through a network connection, a datafile, a pipe, or some other intermediary.
What a data output stream writes, a data input stream can read.
However, it happens that the formats are the same ones used for most Internet protocols that exchange binary numbers.
For instance, the time protocol uses 32-bit big-endian integers, just like Java’s int.
Both Java and most network protocols were designed by Unix programmers, and consequently both tend to use the formats common to most Unix systems.
However, this isn’t true for all network protocols, so check the details of any protocol you use.
The DataOutputStream class offers these 11 methods for writing particular Java data types:
Integers are written in two’s complement in the minimum number of bytes possible.
Thus, a byte is written as one byte, a short as two bytes, an int as four bytes, and a long as eight bytes.
Floats and doubles are written in IEEE 754 form in four and eight bytes, respectively.
The writeChars() method simply iterates through the String argument, writing each character in turn as a two-byte, big-endian Unicode character (a UTF-16 code point, to be absolutely precise)
The write Bytes() method iterates through the String argument but writes only the least significant byte of each character.
Thus, information will be lost for any string with characters from outside the Latin-1 character set.
This method may be useful on some network protocols that specify the ASCII encoding, but it should be avoided most of the time.
Neither writeChars() nor writeBytes() encodes the length of the string in the output stream.
As a result, you can’t really distinguish between raw characters and characters that make up part of a string.
The writeUTF() method does include the length of the string.
It encodes the string itself in a variant of the UTF-8 encoding of Unicode.
Because this variant is subtly incompatible with most non-Java software, it should be used only for exchanging data with other Java programs that use a DataInputStream to read.
For exchanging UTF-8 text with all other software, you should use an Input StreamReader with the appropriate encoding.
There wouldn’t be any confusion if Sun had just called this method and its partner writeString() and readString() rather than writeUTF() and readUTF()
Along with these methods for writing binary numbers and strings, DataOutput Stream of course has the usual write(), flush(), and close() methods any Output Stream class has.
In addition, DataInputStream has the usual read(), available(), skip(), and close() methods, as well as methods for reading complete arrays of bytes and lines of text.
In addition, DataInputStream provides two methods to read unsigned bytes and unsigned shorts and return the equivalent int.
Java doesn’t have either of these data types, but you may encounter them when reading binary data written by a C program:
DataInputStream has the usual two multibyte read() methods that read data into an array or subarray and return the number of bytes read.
It also has two readFully() methods that repeatedly read data from the underlying input stream into an array until the requested number of bytes have been read.
If enough data cannot be read, then an IOException is thrown.
These methods are especially useful when you know in advance exactly how many bytes you have to read.
This might be the case when you’ve read the Content-length field out of an HTTP header and thus know how many bytes of data there are:
Finally, DataInputStream provides the popular readLine() method that reads a line of text as delimited by a line terminator and returns a string:
However, this method should not be used under any circumstances, both because it is deprecated and because it is buggy.
It’s deprecated because it doesn’t properly convert non-ASCII characters to bytes in most circumstances.
That task is now handled by the readLine() method of the BufferedReader class.
However, that method and this one share the same insidious bug: they do not always recognize a single carriage return as ending a line.
Rather, readLine() recognizes only a linefeed or a carriage return/linefeed pair.
When a carriage return is detected in the stream, readLine() waits to see whether the next character is a linefeed before continuing.
If it is a linefeed, the carriage return and the linefeed are thrown away and the line is returned as a String.
If it isn’t a linefeed, the carriage return is thrown away, the line is returned as a String, and the extra character that was read becomes part of the next line.
However, if the carriage return is the last character in the stream, then readLine() hangs, waiting for the last character, which isn’t forthcoming.
This problem isn’t obvious when reading files because there will almost certainly be a next character: –1 for end of stream, if nothing else.
However, on persistent network connections such as those used for FTP and late-model HTTP, a server or client may simply stop sending data after the last character and wait for a response without actually closing the connection.
If you’re lucky, the connection may eventually time out on one end or the other and you’ll get an IOException, although this will probably take at least a couple of minutes, and cause you to lose the last line of data from the stream.
Readers and Writers Many programmers have a bad habit of writing code as if all text were ASCII or at least in the native encoding of the platform.
Java’s native character set is the UTF-16 encoding of Unicode.
When the encoding is no longer ASCII, the assumption that bytes and chars are essentially the same things also breaks down.
Consequently, Java provides an almost complete mirror of the input and output stream class hierarchy designed for working with characters instead of bytes.
In this mirror image hierarchy, two abstract superclasses define the basic API for reading and writing characters.
The java.io.Reader class specifies the API by which characters are read.
The java.io.Writer class specifies the API by which characters are written.
Wherever input and output streams use bytes, readers and writers use Unicode characters.
Concrete subclasses of Reader and Writer allow particular sources to be read and targets to be written.
Filter readers and writers can be attached to other readers and writers to provide additional services or interfaces.
The most important concrete subclasses of Reader and Writer are the InputStream Reader and the OutputStreamWriter classes.
An InputStreamReader contains an underlying input stream from which it reads raw bytes.
It translates these bytes into Unicode characters according to a specified encoding.
It then translates those characters into bytes using a specified encoding and writes the bytes onto an underlying output stream.
In addition to these two classes, the java.io package provides several raw reader and writer classes that read characters without directly requiring an underlying input stream, including:
The first two classes in this list work with files and the last four work inside Java, so they aren’t of great use for network programming.
However, aside from different constructors, these classes have pretty much the same public interface as all other reader and writer classes.
Like OutputStream, the Writer class is never used directly; instead, it is used polymorphically, through one of its subclasses.
It has five write() methods as well as a flush() and a close() method:
The write(char[] text, int offset, int length) method is the base method in terms of which the other four write() methods are implemented.
A subclass must override at least this method as well as flush() and close(), although most override some of the other write() methods as well in order to provide more efficient implementations.
For example, given a Writer object w, you can write the string “Network” like this:
The same task can be accomplished with these other methods, as well:
All of these examples are different ways of expressing the same thing.
The one you choose to use in any given situation is mostly a matter of convenience and taste.
However, how many and which bytes are written by these lines depends on the encoding w uses.
Writers may be buffered, either directly by being chained to a BufferedWriter or indirectly because their underlying output stream is buffered.
To force a write to be committed to the output medium, invoke the flush() method:
The close() method behaves similarly to the close() method of OutputStream.
After a writer has been closed, further writes throw IOExceptions.
OutputStreamWriter OutputStreamWriter is the most important concrete subclass of Writer.
It converts these into bytes according to a specified encoding and writes them onto an underlying output stream.
Its constructor specifies the output stream to write to and the encoding to use:
Valid encodings are listed in the documentation for Sun’s native2ascii tool included with the JDK.
If no encoding is specified, the default encoding for the platform is used.
However, on Linux it can vary if the local operating system is configured to use some other character set by default.
Default character sets can cause unexpected problems at unexpected times.
You’re generally almost always better off explicitly specifying the character set rather than letting Java pick one for you.
For example, this code fragment writes the first few words of Homer’s Odyssey in the CP1253 Windows Greek encoding:
Other than the constructors, OutputStreamWriter has only the usual Writer methods (which are used exactly as they are for any Writer class) and one method to return the encoding of the object:
Like InputStream and Writer, the Reader class is never used directly, only through one of its subclasses.
It has three read() methods, as well as skip(), close(), ready(), mark(), reset(), and markSupported() methods:
The read(char[] text, int offset, int length) method is the fundamental method through which the other two read() methods are implemented.
A subclass must override at least this method as well as close(), although most will override some of the other methods as well in order to provide more efficient implementations.
Most of these methods are easily understood by analogy with their InputStream counterparts.
Technically it returns a UTF-16 code point, though almost always that’s the same as a Unicode character.
The read(char[] text) method tries to fill the array text with characters and returns the actual number of characters read or –1 on end of stream.
The read(char[] text, int offset, int length) method attempts to read length characters into the subarray of text beginning at offset and continuing for length characters.
It also returns the actual number of characters read or –1 on end of stream.
The mark() and reset() methods allow some readers to reset back to a marked position in the character sequence.
The markSupported() method tells you whether the reader supports marking and resetting.
The close() method closes the reader and any underlying input stream so that further attempts to read from it throw IOExceptions.
The exception to the rule of similarity is ready(), which has the same general purpose as available() but not quite the same semantics, even modulo the byte-to-char conversion.
Whereas available() returns an int specifying a minimum number of bytes that may be read without blocking, ready() only returns a boolean indicating whether the reader may be read without blocking.
The problem is that some character encodings, such as UTF-8, use different numbers of bytes for different characters.
Thus, it’s hard to tell how many characters are waiting in the network or filesystem buffer without actually reading them out of the buffer.
An Input StreamReader reads bytes from an underlying input stream such as a FileInput Stream or TelnetInputStream.
It converts these into characters according to a specified encoding and returns them.
The constructor specifies the input stream to read from and the encoding to use:
If no encoding is specified, the default encoding for the platform is used.
For example, this method reads an input stream and converts it all to one Unicode string using the MacCyrillic encoding:
Filter Readers and Writers The InputStreamReader and OutputStreamWriter classes act as decorators on top of input and output streams that change the interface from a byte-oriented interface to a character-oriented interface.
As with filter streams, there are a variety of subclasses that perform specific filtering, including:
When a program reads from a BufferedReader, text is taken from the buffer rather than directly from the underlying input stream or other text source.
When the buffer empties, it is filled again with as much text as possible, even if not all of it is immediately needed, making future reads much faster.
When a program writes to a BufferedWriter, the text is placed in the buffer.
The text is moved to the underlying output stream or other target only when the buffer fills up or when the writer is explicitly flushed, which can make writes much faster than would otherwise be the case.
BufferedReader and BufferedWriter have the usual methods associated with readers and writers, like read(), ready(), write(), and close()
They each have two constructors that chain the BufferedReader or BufferedWriter to an underlying reader.
If the size is not set, the default size of 8,192 characters is used:
Because MacCyrillic is a 1-byte character set, it also read bytes one at a time.
However, it’s straightforward to make it run faster by chaining a BufferedReader to the InputStreamReader, like this:
All that was needed to buffer this method was one additional line of code.
None of the rest of the algorithm had to change, because the only InputStreamReader methods used were the read() and close() methods declared in the Reader superclass and shared by all Reader subclasses, including BufferedReader.
The BufferedReader class also has a readLine() method that reads a single line of text and returns it as a string:
This method replaces the deprecated readLine() method in DataInputStream, and it has mostly the same behavior as that method.
The big difference is that by chaining a BufferedReader to an InputStreamReader, you can correctly read lines in character sets other than the default encoding for the platform.
The BufferedWriter() class adds one new method not included in its superclass, called newLine(), also geared toward writing lines:
This method inserts a platform-dependent line-separator string into the output.
The line.separator system property determines exactly what the string is: probably a linefeed on Unix and Mac OS X, and a carriage return/linefeed pair on Windows.
Because network protocols generally specify the required line terminator, you should not use this method for network programming.
More often than not, the required terminator is a carriage return/ linefeed pair.
PrintWriter The PrintWriter class is a replacement for Java 1.0’s PrintStream class that properly handles multibyte character sets and international text.
Sun originally planned to deprecate PrintStream in favor of PrintWriter but backed off when it realized this step would invalidate too much existing code, especially code that depended on Sys tem.out.
Aside from the constructors, the PrintWriter class has an almost identical collection of methods to PrintStream.
Most of these methods behave the same for PrintWriter as they do for PrintStream.
The exceptions are the four write() methods, which write characters rather than bytes; also, if the underlying writer properly handles character set conversion, so do all the methods of the PrintWriter.
PrintStream class, but it’s still not good enough for network programming.
Unfortunately, PrintWriter still has the problems of platform dependency and minimal error reporting that plague PrintStream.
This chapter has been a whirlwind tour of the java.io package, covering the bare minimum you need to know to write network programs.
For a more detailed and comprehensive look with many more examples, check out my other book in this series, Java I/O (O’Reilly)
Back in the good old days of the Net, circa the early 1990s, we didn’t have the Web and HTTP and graphical browsers.
Instead, we had Usenet news and FTP and commandline interfaces, and we liked it that way! But as good as the good old days were, there were some problems.
For instance, when we were downloading kilobytes of free software from a popular FTP site over our 2,400 bps modems using Kermit, we would often encounter error messages like this one:
In fact, in the days when the Internet had only a few million users instead of a few billion, we were far more likely to come across an overloaded and congested site than we are today.
Because processes are fairly heavyweight items, too many could rapidly bring a server to its knees.
The problem wasn’t that the machines weren’t powerful enough or the network fast enough; it was that the FTP servers were poorly implemented.
Many more simultaneous users could be served if a new process wasn’t needed for each connection.
Early web servers suffered from this problem as well, although the problem was masked a little by the transitory nature of HTTP connections.
Because web pages and their embedded images tend to be small (at least compared to the software archives commonly retrieved by FTP) and because web browsers “hang up” the connection after each.
The fundamental problem is that while it’s easy to write code that handles each incoming connection and each new task as a separate process (at least on Unix), this solution doesn’t scale.
By the time a server is attempting to handle a thousand or more simultaneous connections, performance slows to a crawl.
The first is to reuse processes rather than spawning new ones.
When the server starts up, a fixed number of processes (say, 300) are spawned to handle requests.
Each process removes one request from the queue, services the request, then returns to the queue to get the next request.
Your exact mileage may vary, especially if your server hasn’t yet reached the volume where scalability issues come into play.
Still, whatever mileage you get out of spawning new processes, you should be able to do much better by reusing old processes.
The second solution to this problem is to use lightweight threads instead of heavyweight processes to handle connections.
Whereas each separate process has its own block of memory, threads are easier on resources because they share memory.
Using threads instead of processes can buy you another factor of three in server performance.
By combining this with a pool of reusable threads (as opposed to a pool of reusable processes), your server can run nine times faster, all on the same hardware and network connection! The impact of running many different threads on the server hardware is relatively minimal because they all run within one process.
However, by using a thread pool instead of spawning new threads for each connection, fewer than a hundred threads can handle thousands of short connections per minute.
Alternatives to Threading If an application needs thousands of simultaneous long-lived connections (and that’s a pretty rare application) it’s time to start thinking about asynchronous I/O instead of threads.
Selectors enable one thread to query a group of sockets to find out which ones are ready to be read from or written to, and then process the ready sockets sequentially.
In this case, the I/O has to be designed around channels and buffers rather than streams.
Given the high performance of threads in modern virtual machines and operating systems, as well as the relative simplicity of a building a thread-based server, a thread-based design is usually where you should start until you can prove you’re hitting a wall.
If you do hit a wall, you should seriously consider sharding the application across multiple.
Of course, sharding introduces design issues of its own, particularly around consistency, that aren’t present in a single system.
But it does offer you more scalability and redundancy than you’ll ever get out of a single system, no matter how efficiently implemented.
In particular, multithreaded servers (and other multithreaded programs) require developers to address concerns that aren’t issues for single-threaded programs, particularly issues of safety and liveness.
Because different threads share the same memory, it’s entirely possible for one thread to stomp all over the variables and data structures used by another thread.
Consequently, different threads have to be extremely careful about which resources they use when.
Generally, each thread must agree to use certain resources only when it’s sure those resources can’t change or that it has exclusive access to them.
However, it’s also possible for two threads to be too careful, each waiting for exclusive access to resources it will never get.
This can lead to deadlock, in which two threads are each waiting for resources the other possesses.
Neither thread can proceed without the resources that the other thread has reserved, but neither is willing to give up the resources it has already.
Running Threads A thread with a little t is a separate, independent path of execution in the virtual machine.
There is a oneto-one relationship between threads executing in the virtual machine and Thread objects constructed by the virtual machine.
Most of the time it’s obvious from the context which one is meant if the difference is really important.
To start a new thread running in the virtual machine, you construct an instance of the Thread class and invoke its start() method, like this:
Of course, this thread isn’t very interesting because it doesn’t have anything to do.
To give a thread something to do, you either subclass the Thread class and override its run() method, or implement the Runnable interface and pass the Runnable object to the Thread constructor.
I generally prefer the second option because it separates the task that the thread performs from the thread itself more cleanly, but you will see both techniques used in this book and elsewhere.
In both cases, the key is the run() method, which has this signature:
You’re going to put all the work the thread does in this one method.
This method may invoke other methods; it may construct other objects; it may even spawn other threads.
In essence, the run() method is to a thread what the main() method is to a traditional nonthreaded program.
A multithreaded program exits when both the main() method and the run() methods of all nondaemon threads return.
Daemon threads perform background tasks such as garbage collection and don’t prevent the virtual machine from exiting.
Subclassing Thread Consider a program that calculates the Secure Hash Algorithm (SHA) digest for many files.
To a large extent, this is an I/O-bound program (i.e., its speed is limited by the amount of time it takes to read the files from the disk)
If you write it as a standard program that processes the files in series, the program is going to spend a lot of time waiting for the hard drive to return the data.
This limit is even more characteristic of network programs: they execute faster than the network can supply input.
This is time that other threads could use, either to process other input sources or to do something that doesn’t rely on slow input.
Sometimes, even if none of the threads have a lot of spare time to allot to other threads, it’s simply easier to design a program by breaking it into multiple threads that perform independent operations.
It does this by reading the file with a DigestInput Stream.
This filter stream calculates a cryptographic hash function as it reads the file.
When it’s finished reading, the hash function is available from the digest() method.
The main() method reads filenames from the command line and starts a new DigestTh read for each one.
The work of the thread is actually performed in the run() method.
Then the resulting digest is printed on System.out in hexadecimal encoding.
Notice that the entire output from this thread is first built in a local StringBuilder variable result.
This is then printed on the console with one method invocation.
Because the signature of the run() method is fixed, you can’t pass arguments to it or return values from it.
Consequently, you need different ways to pass information into the thread and get information out of it.
The simplest way to pass information in is to pass arguments to the constructor, which sets fields in the Thread subclass, as done here.
Getting information out of a thread back into the original calling thread is trickier because of the asynchronous nature of threads.
Example 3-1 sidesteps that problem by never passing any information back to the calling thread and simply printing the results on System.out.
Most of the time, however, you’ll want to pass the information to other parts of the program.
You can store the result of the calculation in a field and provide a getter method to return the value of that field.
However, how do you know when the calculation of that value is complete? What do you return if somebody calls the getter.
If you subclass Thread, you should override run() and nothing else! The various other methods of the Thread class—for example, start(), interrupt(), join(), sleep(), and so on—all have very specific semantics and interactions with the virtual machine that are difficult to reproduce in your own code.
You should override run() and provide additional constructors and other methods as necessary, but you should not replace any of the other standard Thread methods.
Implementing the Runnable Interface One way to avoid overriding the standard Thread methods is not to subclass Thread.
Instead, write the task you want the thread to perform as an instance of the Runnable interface.
This interface declares the run() method, exactly the same as the Thread class:
Other than this method, which any class implementing this interface must provide, you are completely free to create any other methods with any other names you choose, all without any possibility of unintentionally interfering with the behavior of the thread.
This also allows you to place the thread’s task in a subclass of some other class, such as Applet or HTTPServlet.
To start a thread that performs the Runnable’s task, pass the Runnable object to the Thread constructor.
It’s easy to recast most problems that subclass Thread into Runnable forms.
Aside from the name change, the only modifications that are necessary are changing extends Thread to implements Runnable and passing a DigestRunnable object to the Thread constructor in the main() method.
There’s no strong reason to prefer implementing Runnable to extending Thread or vice versa in the general case.
In a few special cases, such as Example 3-14 later in this chapter, it may be useful to invoke some instance methods of the Thread class from within the constructor for each Thread object.
In other specific cases, it may be necessary to place the run() method in a class that extends another class, such as HTTPServlet, in which case the Runnable interface is essential.
Finally, some object-oriented purists argue that the task that a thread undertakes is not really a kind of Thread, and therefore should be placed in a separate class or interface such as Runnable rather than in a subclass of Thread.
I half agree with them, although I don’t think the argument is as strong as it’s sometimes made out to be.
Consequently, I’ll mostly use the Runnable interface in this book, but you should feel free to do whatever seems most convenient.
Returning Information from a Thread One of the hardest things for programmers accustomed to traditional, single-threaded procedural models to grasp when moving to a multithreaded environment is how to return information from a thread.
Getting information out of a finished thread is one of the most commonly misunderstood aspects of multithreaded programming.
The run() method and the start() method don’t return any values.
Example 3-3 is a Thread subclass that calculates a digest for a specified file.
Example 3-4 is a simple command-line user interface that receives filenames and spawns threads to calculate digests for them.
The ReturnDigest class stores the result of the calculation in the private field digest, which is accessed via getDigest()
It starts a new ReturnDi gest thread for each file and then tries to retrieve the result using getDigest()
However, when you run this program, the result may not be what you expect:
The problem is that the main program gets the digest and uses it before the thread has had a chance to initialize it.
Although this flow of control would work in a singlethreaded program in which dr.start() simply invoked the run() method in the same thread, that’s not what happens here.
The calculations that dr.start() kicks off may or may not finish before the main() method reaches the call to dr.getDigest()
Race Conditions One possibility is to move the call to dr.getDigest() later in the main() method, like this:
If you’re lucky, this will work and you’ll get the expected output, like this:
Whether this code works is completely dependent on whether every one of the ReturnDigest threads finishes before its getDigest() method is called.
If the first for loop is too fast and the second for loop is entered before the threads spawned by the first loop start finishing, you’re back where you started.
Worse yet, the program may appear to hang with no output at all, not even a stack trace.
Whether you get the correct results, an exception, or a hung program depends on many factors, including how many threads the program spawns, the speed of the CPU and disk on the system where this is run, how many CPUs the system uses, and the algorithm the Java virtual machine uses to allot time to different threads.
Getting the correct result depends on the relative speeds of different threads, and you can’t control those! You need a better way to guarantee that the getDigest() method isn’t called until the digest is ready.
Polling The solution most novices adopt is to make the getter method return a flag value (or perhaps throw an exception) until the result field is set.
Then the main thread periodically polls the getter method to see whether it’s returning something other than the flag value.
In this example, that would mean repeatedly testing whether the digest is null and using it only if it isn’t.
If it works at all, it gives the correct answers in the correct order irrespective of how fast the individual threads run relative to each other.
However, it’s doing a lot more work than it needs to.
On some virtual machines, the main thread takes all the time available and leaves no time for the actual worker threads.
The main thread is so busy checking for job completion that there’s no time left to actually complete the job! Clearly this isn’t a good approach.
Callbacks In fact, there’s a much simpler, more efficient way to handle the problem.
The infinite loop that repeatedly polls each ReturnDigest object to see whether it’s finished can be eliminated.
The trick is that rather than having the main program repeatedly ask each ReturnDigest thread whether it’s finished (like a five-year-old repeatedly asking, “Are we there yet?” on a long car trip, and almost as annoying), you let the thread tell the.
It does this by invoking a method in the main class that started it.
This is called a callback because the thread calls its creator back when it’s done.
This way, the main program can go to sleep while waiting for the threads to finish and not steal time from the running threads.
When the thread’s run() method is nearly done, the last thing it does is invoke a known method in the main program with the result.
Rather than the main program asking each thread for the answer, each thread tells the main program the answer.
For instance, Example 3-5 shows a CallbackDigest class that is much the same as before.
However, unlike the main() methods in the other variations of this program, this one only starts the threads for the files named on the command line.
It does not attempt to actually read, print out, or in any other way work with the results of the calculation.
Those functions are handled by a separate method, receiveDigest(), which is not invoked by the main() method or by any method that can be reached by.
That is, receiveDigest() runs inside the digesting threads rather than inside the main thread of execution.
However, it’s not much harder (and it’s considerably more common) to call back to an instance method.
In this case, the class making the callback must have a reference to the object it’s calling back.
Generally, this reference is provided as an argument to the thread’s constructor.
When the run() method is nearly done, the last thing it does is invoke the instance method on the callback object to pass along the result.
For instance, Example 3-7 shows a CallbackDigest class that is much the same as before.
At the end of the run() method, the digest is passed to callback’s receiveDigest() method.
Example 3-8 just prints out the digest, but a more expansive class could do other things as well, such as storing the digest in a field, using it to start another thread, or performing further calculations on it.
Using instance methods instead of static methods for callbacks is a little more complicated but has a number of advantages.
Furthermore, the instance can easily recalculate the digest for a particular file, if necessary.
Notice the addition of the calculateDigest() method to start the thread.
You might logically think that this belongs in a constructor.
However, starting threads in a constructor is dangerous, especially threads that will call back to the originating object.
There’s a race condition here that may allow the new thread to call back before the constructor is finished and the object is fully initialized.
It’s unlikely in this case, because starting the new thread is the last thing this constructor does.
Therefore, it’s good form to avoid launching threads from constructors.
The first advantage of the callback scheme over the polling scheme is that it doesn’t waste so many CPU cycles.
However, a much more important advantage is that callbacks are more flexible and can handle more complicated situations involving many more threads, objects, and classes.
For instance, if more than one object is interested in the result of the thread’s calculation, the thread can keep a list of objects to call back.
Particular objects can register their interest by invoking a method in the Thread or Runna ble class to add themselves to the list.
If instances of more than one class are interested in the result, a new interface can be defined that all these classes implement.
Futures, Callables, and Executors Java 5 introduced a new approach to multithreaded programming that makes it somewhat easier to handle callbacks by hiding the details.
Instead of directly creating a thread, you create an ExecutorService that will create threads for you as needed.
You submit Callable jobs to the ExecutorService and for each one you get back a Future.
At a later point, you can ask the Future for the result of the job.
If it’s not ready, the polling thread blocks until it is ready.
The advantage is that you can spawn off many different threads, then get the answers you need in the order you need them.
For example, suppose you need to find the maximum value in a large array of numbers.
Implemented naively, this takes O(n) time where n is the number of elements in the array.
However, you can go faster than that if you split the work into multiple threads, each running on a separate core.
For purposes of illustration, let’s assume two threads are desired.
The Callable interface defines a single call() method that can generically return any type.
Example 3-9 is a Callable that finds the maximum value in a subsection of an array in the most obvious way possible.
Although you could invoke the call() method directly, that is not its purpose.
Instead, you submit Callable objects to an Executor that spins up a thread for each one.
There are other strategies an Executor could use—for instance, it could use a single thread to invoke the callables in order—but one thread per callable is a good strategy for this problem.
Each subarray is searched at the same time, so on suitable hardware and a large input this program can run almost twice as fast.
Nonetheless, the code is almost as simple and straightforward as finding the maximum in the first half of the array and then finding the maximum in the second half of the array, without ever worrying about threads or asynchronicity.
It’s possible that the second thread has already finished, in which case the value is immediately returned; but if not, execution waits for that thread to finish too.
Once both threads have finished, their results are compared and the maximum is returned.
Futures are a very convenient means of launching multiple threads to work on different pieces of a problem, and then waiting for them all to finish before proceeding.
Executors and executor services let you assign jobs to different threads with different strategies.
This example used just two threads once each, but it’s possible to use many more threads, and to reuse threads for multiple tasks.
Executors hide a lot of the nitty-gritty details of asynchronicity as long as you can divide your job up into reasonably independent parts.
Synchronization My shelves are overflowing with books, including many duplicate books, out-of-date books, and books I haven’t looked at for 10 years and probably never will again.
Over the years, these books have cost me tens of thousands of dollars, maybe more, to acquire.
By contrast, two blocks down the street from my apartment, you’ll find the Central Brooklyn Public Library.
Its shelves are also overflowing with books, and over its 100 years, it’s spent millions on its collection.
But the difference is that its books are shared among all the residents of Brooklyn, and consequently the books have very high turnover.
Most books in the collection are used several times a year.
Although the public library spends a lot more money buying and storing books than I do, the cost per page read is much lower at the library than for my personal shelves.
If I need a book from the library, I have to walk over there.
I have to find the book I’m looking for on the shelves.
I have to stand in line to check the book out, or else I have to use it right there in the library rather than bringing it home with me.
Sometimes somebody else has checked the book out, and I have to fill out a form requesting that the book be saved for me when it’s returned.
And I can’t write notes in the margins, highlight paragraphs, or tear pages out to paste on my bulletin board.
Well, I can, but if I do, it significantly reduces the usefulness of the book for future borrowers, and if the library catches me, I may lose my borrowing privileges.
There’s a significant time and convenience penalty associated with borrowing a book from the library rather than purchasing my own copy, but it does save me money and storage space.
A thread is like a borrower at a library; the thread borrows from a central pool of resources.
Threads make programs more efficient by sharing memory, file handles, sockets, and other resources.
As long as two threads don’t want to use the same resource at the same time, a multithreaded program is much more efficient than the multiprocess alternative, in which each process has to keep its own copy of every resource.
The downside of a multithreaded program is that if two threads want the same resource at.
If one of them doesn’t wait, the resource may get corrupted.
The order in which the lines are written is unpredictable because thread scheduling is unpredictable, but each line is written as a unified whole.
Suppose, however, you used this variation of the run() method, which, rather than storing intermediate parts of the result in the String variable result, simply prints them on the console as they become available:
When you run the program on the same input, the output looks something like this:
The digests of the different files are all mixed up! There’s no telling which number belongs to which digest.
The reason this mix-up occurs is that System.out is shared between the four different threads.
The exact order in which one thread preempts the other threads is indeterminate.
You’ll probably see slightly different output every time you run this program.
You need a way to assign exclusive access to a shared resource to one thread for a specific series of statements.
In this example, that shared resource is System.out, and the statements that need exclusive access are:
Synchronized Blocks To indicate that these five lines of code should be executed together, wrap them in a synchronized block that synchronizes on the System.out object, like this:
Once one thread starts printing out the values, all other threads will have to stop and wait for it to finish before they can print out their values.
Synchronization forces all code that synchronizes on the same object to run in series, never in parallel.
For instance, if some other code in a different class and different thread also happened to synchronize on System.out, it too would not be able to run in parallel with this block.
However, other code that synchronizes on a different object or doesn’t synchronize at all can still run in parallel with this code.
It can do so even if it also uses System.out.
Java provides no means to stop all other threads from using a shared resource.
It can only prevent other threads that synchronize on the same object from using the shared resource.
In fact, the PrintStream class internally synchronizes most methods on the PrintStream object (System.out, in this example)
Synchronization must be considered any time multiple threads share resources.
These threads may be instances of the same Thread subclass or use the same Runnable class, or they may be instances of completely different classes.
The key is the resources they share, not what classes they are.
Synchronization becomes an issue only when two threads both possess references to the same object.
In this case, it was a static class variable that led to the conflict.
The logfile may be represented by a class like the one shown in Example 3-11
However, if the web server uses multiple threads to handle incoming connections, then each of those threads will need access to the same logfile and consequently to the same LogFile object.
In this class, the writeEntry() method finds the current date and time, then writes into the underlying file using four separate invocations of out.write()
A problem occurs if two or more threads each have a reference to the same LogFile object and one of those threads interrupts another in the process of writing the data.
One thread may write the date and a tab, then the next thread might write three complete entries; then, the first thread could write the message, a carriage return, and a linefeed.
However, here there are two good choices for which object to synchronize on.
The first choice is to synchronize on the Writer object out.
This works because all the threads that use this LogFile object also use the same out object that’s part of that LogFile.
Although it is used by the other threads and objects, it’s referenced only within the LogFile class.
Furthermore, although you’re synchronizing here on the out object, it’s the writeEntry() method that needs to be protected from interruption.
The Writer classes all have their own internal synchronization, which protects one thread from interfering with a write() method in another thread.
This is not true of input and output streams, with the exception of PrintStream.
It is possible for a write to an output stream to be interrupted by another thread.
Each Writer class has a lock field that specifies the object on which writes to that writer synchronize.
The second possibility is to synchronize on the LogFile object itself.
This is simple enough to arrange with the this keyword.
Synchronized Methods Because synchronizing the entire method body on the object itself is such a common thing to do, Java provides a shortcut.
You can synchronize an entire method on the current object (the this reference) by adding the synchronized modifier to the method declaration.
Simply adding the synchronized modifier to all methods is not a catchall solution for synchronization problems.
For one thing, it exacts a severe performance penalty in many VMs (though more recent VMs have improved greatly in this respect), potentially slowing down your code by a factor of three or more.
Third, and most importantly, it’s not always the object itself you need to protect from simultaneous modification or access, and synchronizing on the instance of the method’s class may not protect the object you really need to protect.
For instance, in this example, what you’re really trying to prevent is two threads simultaneously writing onto out.
If some other class had a reference to out completely unrelated to the LogFile, this attempt would fail.
However, in this example, synchronizing on the LogFile object is sufficient because out is a private instance variable.
Because you never expose a reference to this object, there’s no way for any other object to invoke its methods except through the LogFile class.
Therefore, synchronizing on the Log File object has the same effect as synchronizing on out.
Alternatives to Synchronization Synchronization is not always the best solution to the problem of inconsistent behavior caused by thread scheduling.
There are a number of techniques that avoid the need for synchronization entirely.
The first is to use local variables instead of fields wherever possible.
Every time a method is entered, the virtual machine creates a completely new set of local variables for the method.
These variables are invisible from outside the method and are destroyed when the method exits.
As a result, it’s impossible for one local variable to be shared by two different threads.
Every thread has its own separate set of local variables.
Method arguments of primitive types are also safe from modification in separate threads because Java passes arguments by value rather than by reference.
A corollary of this is that pure functions such as Math.sqrt() that take zero or more primitive data type arguments, perform some calculation, and return a value without ever interacting with the fields of any class are inherently thread safe.
These methods often either are or should be declared static.
Method arguments of object types are a little trickier because the actual argument passed by value is a reference to the object.
Suppose, for example, you pass a reference to an array into a sort() method.
While the method is sorting the array, there’s nothing to stop some other thread that also has a reference to the array from changing the values in the array.
String arguments are safe because they’re immutable (i.e., once a String object has been created, it cannot be changed by any thread)
The values of its fields are set once when the constructor runs and never altered thereafter.
StringBuilder arguments are not safe because they’re not immutable; they can be changed after they’re created.
A constructor normally does not have to worry about issues of thread safety.
Until the constructor returns, no thread has a reference to the object, so it’s impossible for two threads to have a reference to the object.
The most likely issue is if a constructor depends on another object in another thread that may change while the constructor runs, but that’s uncommon.
There’s also a potential problem if a constructor somehow passes a reference to the object it’s creating into a different thread, but this is also uncommon.
You can take advantage of immutability in your own classes.
It’s usually the easiest way to make a class thread safe, often much easier than determining exactly which methods or code blocks to synchronize.
To make an object immutable, simply declare all its fields private and final and don’t write any methods that can change them.
This makes these classes less useful for some purposes, but it does make them a lot more thread safe.
A third technique is to use a thread-unsafe class but only as a private field of a class that is thread safe.
As long as the containing class accesses the unsafe class only in a threadsafe fashion and as long as it never lets a reference to the private field leak out into another object, the class is safe.
An example of this technique might be a web server that uses an unsynchronized LogFile class but gives each separate thread its own separate log so no resources are shared between the individual threads.
In particular, rather than using an int, you can use an AtomicInteger.
Rather than using a long, you can use an AtomicLong.
Rather than using a boolean, you can use an AtomicBoolean.
Rather than using an int[], you can use an AtomicIntegerArray.
Rather than a reference variable, you can store an object inside an AtomicReference, though note well that this doesn’t make the object itself thread safe, just the getting and setting of the reference variable.
These classes may be faster than synchronized access to their respective primitive types if they can take advantage of fast machine-level thread-safe instructions on modern CPUs.
If at any point you access the original, underlying data structure, neither the original nor the synchronized view will be thread safe.
In all cases, realize that it’s just a single method invocation that is atomic.
If you need to perform two operations on the atomic value in succession without possible interruption, you’ll still need to synchronize.
Thus, for instance, even if a list is synchronized via.
Although each method call is safely atomic, the sequence of operations is not without explicit synchronization.
Deadlock occurs when two threads need exclusive access to the same set of resources and each thread holds the lock on a different subset of those resources.
If neither thread is willing to give up the resources it has, both threads come to an indefinite halt.
This isn’t quite a hang in the classical sense because the program is still active and behaving normally from the perspective of the OS, but to a user the difference is insignificant.
If Jill has checked out the first book and Jack has checked out the second, and neither is willing to give up the book they have, neither can finish the paper.
Eventually, the deadline expires and they both get an F.
Most of the time, either Jack or Jill will get to the library first and check out both books.
In this case, the one who gets the books first writes a paper and returns the books; then the other one gets the books and writes his or her paper.
Only rarely will they arrive at the same time and each get one of the two books.
Of course, if a multithreaded server is handling hundreds of requests per second, even a problem that occurs only once every million requests can hang the server in short order.
The most important technique for preventing deadlock is to avoid unnecessary synchronization.
If there’s an alternative approach for ensuring thread safety, such as making objects immutable or keeping a local copy of an object, use it.
Synchronization should be a last resort for ensuring thread safety.
If you do need to synchronize, keep the synchronized blocks small and try not to synchronize on more than one object at a time.
This can be tricky, though, because many of the methods from the Java class library that your code may invoke synchronize on objects you aren’t aware of.
Consequently, you may in fact be synchronizing on many more objects than you expect.
The best you can do in the general case is carefully consider whether deadlock is likely to be a problem and design your code around it.
If multiple objects need the same set of shared resources to operate, make sure they request them in the same order.
If neither requests Y unless it already possesses X, deadlock is not a problem.
Thread Scheduling When multiple threads are running at the same time (more properly, when multiple threads are available to be run at the same time), you have to consider issues of thread scheduling.
You need to make sure that all important threads get at least some time to run and that the more important threads get more time.
Furthermore, you want to ensure that the threads execute in a reasonable order.
By that point, the user has likely gone to another page.
The reason this strategy works is that there’s a lot of dead time in servicing a typical web request, time in which the thread is simply waiting for the network to catch up with the CPU—time the VM’s thread scheduler can put to good use by other threads.
However, CPU-bound threads (as opposed to the I/O-bound threads more common in network programs) may never reach a point where they have to wait for more input.
It is possible for such a thread to starve all other threads by taking all the available CPU resources.
When multiple threads are ready to run, the VM will generally run only the highest-priority thread, although that’s not a hard-and-fast rule.
The default priority is 5, and this is the priority that your threads will have unless you deliberately set them otherwise.
This is the exact opposite of the normal Unix way of prioritizing processes, in which the higher the priority number of a process, the less CPU time the process gets.
Sometimes you want to give one thread more time than another.
Threads that interact with the user should get very high priorities so that perceived responsiveness will be very quick.
On the other hand, threads that calculate in the background should get low priorities.
Tasks that take a long time should have low priorities so that they won’t get in the way of other tasks.
You can change the priority of the thread using the setPriority() method:
For instance, in Example 3-11, you might want to give higher priorities to the threads that do the calculating than the main program that spawns the threads.
This is easily achieved by changing the calculateDigest() method to set the priority of each spawned thread to 8:
In general, though, try to avoid using too high a priority for threads, because you run the risk of starving other, lower-priority threads.
Preemption Every virtual machine has a thread scheduler that determines which thread to run at any given time.
There are two main kinds of thread scheduling: preemptive and cooperative.
A preemptive thread scheduler determines when a thread has had its fair share of CPU time, pauses that thread, and then hands off control of the CPU to a different thread.
A cooperative thread scheduler waits for the running thread to pause itself before handing off control of the CPU to a different thread.
A virtual machine that uses cooperative thread scheduling is much more susceptible to thread starvation than a virtual machine that uses preemptive thread scheduling, because one high-priority, uncooperative thread can hog an entire CPU.
All Java virtual machines are guaranteed to use preemptive thread scheduling between priorities.
That is, if a lower-priority thread is running when a higher-priority thread.
The situation when multiple threads of the same priority are ready to run is trickier.
A preemptive thread scheduler will occasionally pause one of the threads to allow the next one in line to get some CPU time.
It will wait for the running thread to explicitly give up control or come to a stopping point.
If the running thread never gives up control and never comes to a stopping point and if no higher-priority threads preempt the running thread, all other threads will starve.
It’s important to make sure all your threads periodically pause themselves so that other threads have an opportunity to run.
A starvation problem can be hard to spot if you’re developing on a VM that uses preemptive thread scheduling.
Just because the problem doesn’t arise on your machine doesn’t mean it won’t arise on your customers’ machines if their VMs use cooperative thread scheduling.
Most current virtual machines use preemptive thread scheduling, but some older virtual machines are cooperatively scheduled, and you may also encounter cooperative scheduling in special-purpose Java virtual machines such as for embedded environments.
There are 10 ways a thread can pause in favor of other threads or indicate that it is ready to pause.
Inspect every run() method you write to make sure that one of these conditions will occur with reasonable frequency.
The last two possibilities are deprecated because they have the potential to leave objects in inconsistent states, so let’s look at the other eight ways a thread can be a cooperative citizen of the virtual machine.
Blocking Blocking occurs any time a thread has to stop and wait for a resource it doesn’t have.
The most common way a thread in a network program will voluntarily give up control of the CPU is by blocking on I/O.
Because CPUs are much faster than networks and disks, a network program will often block while waiting for data to arrive from the network or be sent out to the network.
Even though it may block for only a few milliseconds, this is enough time for other threads to do significant work.
Threads can also block when they enter a synchronized method or block.
If the thread does not already possess the lock for the object being synchronized on and some other thread does possess that lock, the thread will pause until the lock is released.
If the lock is never released, the thread is permanently stopped.
Neither blocking on I/O nor blocking on a lock will release any locks the thread already possesses.
For I/O blocks, this is not such a big deal, because eventually the I/O will either unblock and the thread will continue or an IOException will be thrown and the thread will then exit the synchronized block or method and release its locks.
However, a thread blocking on a lock that it doesn’t possess will never give up its own locks.
If one thread is waiting for a lock that a second thread owns and the second thread is waiting for a lock that the first thread owns, deadlock results.
Yielding The second way for a thread to give up control is to explicitly yield.
A thread does this by invoking the static Thread.yield() method.
This signals to the virtual machine that it can run another thread if one is ready to run.
Some virtual machines, particularly on real-time operating systems, may ignore this hint.
Before yielding, a thread should make sure that it or its associated Runnable object is in a consistent state that can be used by other objects.
Therefore, ideally, a thread should not be synchronized on anything when it yields.
If the only other threads waiting to run when a thread yields are blocked because they need the synchronized resources that the yielding thread possesses, then the other threads won’t be able to run.
Instead, control will return to the only thread that can run, the one that just yielded, which pretty much defeats the purpose of yielding.
If the thread’s run() method simply consists of an infinite loop, just put a call to Thread.yield() at the end of the loop.
This gives other threads of the same priority the opportunity to run.
If each iteration of the loop takes a significant amount of time, you may want to intersperse more calls to Thread.yield() in the rest of the code.
This precaution should have minimal effect in the event that yielding isn’t necessary.
Whereas yielding indicates only that a thread is willing to pause and let other equal-priority threads have a turn, a thread that goes to sleep will pause whether any other thread is ready to run or not.
This gives an opportunity to run not only to other threads of the same priority, but also to threads of lower priorities.
However, a thread that goes to sleep does hold onto all the locks it’s grabbed.
Consequently, other threads that need the same locks will be blocked even if the CPU is available.
Therefore, try to avoid sleeping threads inside a synchronized method or block.
A thread goes to sleep by invoking one of two overloaded static Thread.sleep() methods.
The first takes the number of milliseconds to sleep as an argument.
The second takes both the number of milliseconds and the number of nanoseconds:
There’s no guarantee that you can actually time the sleep to within a nanosecond or even within a millisecond on any particular virtual machine.
If the local hardware can’t support that level of accuracy, the sleep time is simply rounded to the nearest value that can be measured.
For example, this run() method attempts to load a certain page every five minutes and, if it fails, emails the webmaster to alert him of the problem:
The thread is not guaranteed to sleep as long as it wants to.
On occasion, the thread may not wake up until some time after its requested wake-up call, simply because the VM is busy doing other things.
It is also possible that some other thread will do something to.
Generally, this is accomplished by invoking the sleeping thread’s interrupt() method.
This is one of those cases where the distinction between the thread and the Thread object is important.
Just because the thread is sleeping doesn’t mean that other threads that are awake can’t work with the corresponding Thread object through its methods and fields.
From that point forward, the thread is awake and executes as normal, at least until it goes to sleep again.
The userinterface thread can invoke this thread’s interrupt() method when the user selects Exit from a menu or otherwise indicates that he wants the program to quit.
If a thread is blocked on an I/O operation such as a read or write, the effect of interrupting the thread is highly platform dependent.
On Solaris, the read() or write() method may throw an Interrupte dIOException, a subclass of IOException instead.
However, this is unlikely to happen on other platforms, and may not work with all stream classes on Solaris.
If your program architecture requires interruptible I/O, you should seriously consider using the nonblocking I/O discussed in Chapter 11 rather than streams.
Unlike streams, buffers and channels are explicitly designed to support interruption while blocked on a read or write.
Joining threads It’s not uncommon for one thread to need the result of another thread.
For example, a web browser loading an HTML page in one thread might spawn a separate thread to retrieve every image embedded in the page.
If the IMG elements don’t have HEIGHT and WIDTH attributes, the main thread might have to wait for all the images to load before it can finish by displaying the page.
Java provides three join() methods to allow one thread to wait for another thread to finish before continuing.
The first variant waits indefinitely for the joined thread to finish.
The second two variants wait for the specified amount of time, after which they continue even if the joined.
As with the sleep() method, nanosecond accuracy is not guaranteed.
The joining thread (i.e., the one that invokes the join() method) waits for the joined thread (i.e, the one whose join() method is invoked) to finish.
You want to find the minimum, maximum, and median of a random array of doubles.
You spawn a new thread to sort the array, then join to that thread to await its results.
Only when it’s done do you read out the desired values.
Line 6 starts the thread that will sort the array.
Before you can find the minimum, median, and maximum of the array, you need to wait for the sorting thread to finish.
Therefore, line 8 joins the current thread to the sorting thread.
At this point, the thread executing these lines of code stops in its tracks.
Notice that at no point is there a reference to the thread that pauses.
It’s not the Thread object on which the join() method is invoked; it’s not passed as an argument to that method.
If this is within the normal flow of control of the main() method of the program, there may not be any Thread variable anywhere that points to this thread.
A thread that’s joined to another thread can be interrupted just like a sleeping thread if some other thread invokes its interrupt() method.
From that point forward, it executes as normal, starting from the catch block that caught the exception.
In the preceding example, if the thread is interrupted, it skips over the calculation of the minimum, median, and maximum because they won’t be available if the sorting thread was interrupted before it could finish.
Its problem was that the main() method tended to outpace the threads whose results the main() method was using.
Because Example 3-12 joins to threads in the same order as the threads are started, this fix also has the side effect of printing the output in the same order as the arguments used to construct the threads, rather than in the order the threads finish.
This modification doesn’t make the program any slower, but it may occasionally be an issue if you want to get the output of a thread as soon as it’s done, without waiting for other unrelated threads to finish first.
In particular, many designs that used to require join() can now more easily be implemented using an Executor and a Future instead.
Waiting on an object A thread can wait on an object it has locked.
While waiting, it releases the lock on the object and pauses until it is notified by some other thread.
Another thread changes the object in some way, notifies the thread waiting on that object, and then continues.
This differs from joining in that neither the waiting nor the notifying thread has to finish before the other thread can continue.
Waiting pauses execution until an object or resource reaches a certain state.
Waiting on an object is one of the lesser-known ways a thread can pause.
That’s because it doesn’t involve any methods in the Thread class.
Instead, to wait on a particular object, the thread that wants to pause must first obtain the lock on the object using synchronized and then invoke one of the object’s three overloaded wait() methods:
Consequently, they can be invoked on any object of any class.
When one of these methods is invoked, the thread that invoked it releases the lock on the object it’s waiting on (though not any locks it possesses on other objects) and goes to sleep.
The timeout is the same as for the sleep() and join() methods; that is, the thread wakes up after the specified amount of time has passed (within the limits of the local hardware clock accuracy)
When the timeout expires, execution of the thread resumes with the statement immediately following the invocation of wait()
However, if the thread can’t immediately regain the lock on the object it was waiting on, it may still be blocked for some time.
Interruption works the same way as sleep() and join(): some other thread invokes the thread’s interrupt() method.
The thread regains the lock on the object it was waiting on before the exception is thrown, however, so the thread may still be blocked for some time after the interrupt() method is invoked.
Notification occurs when some other thread invokes the notify() or notifyAll() method on the object on which the thread is waiting.
These must be invoked on the object the thread was waiting on, not generally on the Thread itself.
Before notifying an object, a thread must first obtain the lock on the object using a synchronized method or block.
The notify() method selects one thread more or less at random from the list of threads waiting on the object and wakes it up.
The notifyAll() method wakes up every thread waiting on the given object.
Once a waiting thread is notified, it attempts to regain the lock of the object it was waiting on.
If it succeeds, execution resumes with the statement immediately following the invocation of wait()
If it fails, it blocks on the object until its lock becomes available; then execution resumes with the statement immediately following the invocation of wait()
For example, suppose one thread is reading a JAR archive from a network connection.
The first entry in the archive is the manifest file.
Another thread might be interested in the contents of the manifest file even before the rest of the archive is available.
The interested thread could create a custom ManifestFile object, pass a reference to this object to the thread that would read the JAR archive, and wait on it.
The thread reading the archive would first fill the ManifestFile with entries from the stream, then notify the ManifestFile, then continue reading the rest of the JAR archive.
When the reader thread notified the ManifestFile, the original thread would wake up and do whatever it planned to do with the now fully prepared ManifestFile object.
Waiting and notification are more commonly used when multiple threads want to wait on the same object.
For example, one thread may be reading a web server logfile in which each line contains one entry to be processed.
Each line is placed in a java.util.List as it’s read.
Several threads wait on the List to process entries as they’re added.
Every time an entry is added, the waiting threads are notified using the notifyAll() method.
If more than one thread is waiting on an object, notifyAll() is preferred, because there’s no way to select which thread to notify.
When all threads waiting on one object are notified, all will wake up and try to get the lock on the object.
That one continues; the rest are blocked until the first one releases the lock.
If several threads are all waiting on the same object, a significant amount of time may pass before the last one gets its turn at the lock on the object and continues.
It’s entirely possible that the object on which the thread was waiting will once again have been placed in an unacceptable state during this time.
Thus, you’ll generally put the call to wait() in a loop that checks the current state of the object.
Do not assume that just because the thread was notified, the object is now in the correct state.
Check it explicitly if you can’t guarantee that once the object reaches a correct state it will never again reach an incorrect state.
For example, this is how the client threads waiting on the logfile entries might look:
The code reading the logfile and adding entries to the list might look something like this:
Finish The final way a thread can give up control of the CPU in an orderly fashion is by finishing.
When the run() method returns, the thread dies and other threads can take over.
In network applications, this tends to occur with threads that wrap a single blocking operation, such as downloading a file from a server, so that the rest of the application won’t be blocked.
Otherwise, if your run() method is so simple that it always finishes quickly enough without blocking, there’s a very real question of whether you should spawn a thread at all.
There’s a nontrivial amount of overhead for the virtual machine in setting up and tearing down threads.
If a thread is finishing in a small fraction of a second anyway, chances are it would finish even faster if you used a simple method call rather than a separate thread.
Thread Pools and Executors Adding multiple threads to a program dramatically improves performance, especially for I/O-bound programs such as most network programs.
Starting a thread and cleaning up after a thread that has died takes a noticeable amount of work from the virtual machine, especially if a program spawns hundreds of threads—not an unusual occurrence for even a low- to mediumvolume network server.
Even if the threads finish quickly, this can overload the garbage collector or other parts of the VM and hurt performance, just like allocating thousands of any other kind of object every minute.
If the threads are blocking naturally—for instance, by waiting for data from the network—there’s no real penalty to this; but if the threads.
Finally, and most importantly, although threads help make more efficient use of a computer’s limited CPU resources, there is still only a finite amount of resources to go around.
Once you’ve spawned enough threads to use all the computer’s available idle time, spawning more threads just wastes MIPS and memory on thread management.
You simply submit each task as a Runnable object to the pool.
You get back a Future object you can use to check on the progress of the task.
This is a filter stream that compresses all the data it writes.
On the one hand, this is an I/O-heavy operation because all the files have to be read and written.
On the other hand, data compression is a very CPU-intensive operation, so you don’t want too many threads running at once.
This is a good opportunity to use a thread pool.
Each client thread will compress files while the main program will determine which files to compress.
In this example, the main program is likely to significantly outpace the compressing threads because all it has to do is list the files in a directory.
Therefore, it’s not out of the question to fill the pool first, then start the threads that compress the files in the pool.
However, to make this example as general as possible, you’ll allow the main program to run in parallel with the zipping threads.
It has a single field that identifies the file to compress.
Notice the use of Java 7’s try-with-resources statement in GZipRunnable.
Both the input and output stream are declared at the beginning of the try block and automatically closed at the end of the try block.
This is very important for performance in I/O-limited applications, and especially important in network programs.
At worst, buffering has no impact on performance, while at best it can give you an order of magnitude speedup or more.
It constructs the pool with a fixed thread count of four, and iterates through all the files and directories listed on the command line.
Each of those files and files in those directories is used to construct a GZipRunnable.
This runnable is submitted to the pool for eventual processing by one of the four threads.
Once you have added all the files to the pool, you call pool.shutdown()
Chances are this happens while there’s still work to be done.
It simply notifies the pool that no further tasks will be added to its internal queue and that it should shut down once it has finished all pending work.
Shutting down like this is mostly atypical of the heavily threaded network programs you’ll write because it does have such a definite ending point: the point at which all files are processed.
Most network servers continue indefinitely until shut down through an administration interface.
In those cases, you may want to invoke shutdownNow() instead to abort currently processing tasks and skip any pending tasks.
Each node or host is identified by at least one unique number called an Internet address or an IP address.
They aren’t numbers, and they aren’t ordered in any predictable or useful sense.
Bytes are separated by periods for the convenience of human eyes.
An IPv6 address is normally written as eight blocks of four hexadecimal digits separated by colons.
A double colon, at most one of which may appear in any address, indicates multiple zero blocks.
Miller discovered that most people could remember about seven digits per number; some can remember as many as nine, while others remember as few as five.
This is why phone numbers are broken into three- and four-digit pieces with three-digit area codes.
Obviously, an IP address, which can have as many as 12 decimal digits, is beyond the capacity of most humans to remember.
I can remember about two IP addresses, and then only if I use both daily and the second is on the same subnet as the first.
To avoid the need to carry around Rolodexes full of IP addresses, the Internet’s designers invented the Domain Name System (DNS)
Clients often have a hostname, but often don’t, especially if their IP address is dynamically assigned at startup.
Colloquially, people often use “Internet address” to mean a hostname (or even an email address, or full URL)
In a book about network programming, it is crucial to be precise about addresses and hostnames.
In this book, an address is always a numeric IP address, never a human-readable hostname.
For instance, www.beand.com and xom.nu are really the same Linux box.
The name www.beand.com really refers to a website rather than a particular machine.
In the past, when this website moved from one machine to another, the name was reassigned to the new machine so it always pointed to the site’s current server.
This way, URLs around the Web don’t need to be updated just because the site has moved to a new host.
Some common names like www and news are often aliases for the machines providing those services.
Because the server may change over time, the alias can move with the service.
It is then the responsibility of the DNS server to randomly choose machines to respond to each request.
This feature is most frequently used for very high-traffic websites, where it splits the load across multiple systems.
Every computer connected to the Internet should have access to a machine called a domain name server, generally a Unix box running special DNS software that knows the mappings between different hostnames and IP addresses.
Most domain name servers only know the addresses of the hosts on their local network, plus the addresses of a few domain name servers at other sites.
If a client asks for the address of a machine outside the local domain, the local domain name server asks a domain name server at the remote location and relays the answer to the requester.
Most of the time, you can use hostnames and let DNS handle the translation to IP addresses.
As long as you can connect to a domain name server, you don’t need to worry about the details of how names and addresses are passed between your machine, the local domain name server, and the rest of the Internet.
However, you will need access to at least one domain name server to use the examples in this chapter and most of the rest of this book.
It is used by most of the other networking classes, including Socket, ServerSocket, URL, DatagramSocket, DatagramPacket, and more.
Usually, it includes both a hostname and an IP address.
Instead, InetAddress has static factory methods that connect to a DNS server to resolve a hostname.
This method does not merely set a private String field in the InetAddress class.
It actually makes a connection to the local DNS server to look up the name and the numeric address.
If you’ve looked up this host previously, the information may be cached locally, in which case a network connection is not required.
You can also do a reverse lookup by IP address.
If the address you look up does not have a hostname, getHostName() simply returns the dotted quad address you supplied.
If, for some reason, you need all the addresses of a host, call getAllByName() instead, which returns an array:
Finally, the getLocalHost() method returns an InetAddress object for the host on which your code is running:
This is the hostname “localhost” and the dotted quad address “127.0.0.1”
Example 4-2 prints the address of the machine it’s run on.
If you’re not connected to the Internet, and the system does not have a fixed IP address or domain name, you’ll probably see localhost as the domain name and 127.0.0.1 as the IP address.
This method can create addresses for hosts that do not exist or cannot be resolved:
Note that it had to cast the two large values to bytes.
Unlike the other factory methods, these two methods make no guarantees that such a host exists or that the hostname is correctly mapped to the IP address.
This could be useful if a domain name server is not available or might have inaccurate information.
For example, none of the computers, printers, or routers in my basement area network are registered with any DNS server.
Because I can never remember which addresses I’ve assigned to which systems, I wrote a simple program that attempts to connect to all 254 possible local addresses in turn to see which ones are active.
This only took me about 10 times as long as writing down all the addresses on a piece of paper.
Caching Because DNS lookups can be relatively expensive (on the order of several seconds for a request that has to go through several intermediate servers, or one that’s trying to resolve an unreachable host) the InetAddress class caches the results of lookups.
Once it has the address of a given host, it won’t look it up again, even if you create a new InetAddress object for the same host.
As long as IP addresses don’t change while your program is running, this is not a problem.
Negative results (host not found errors) are slightly more problematic.
It’s not uncommon for an initial attempt to resolve a host to fail, but the immediately following one to succeed.
The first attempt timed out while the information was still in transit from the remote DNS server.
Then the address arrived at the local server and was immediately available for the next request.
For this reason, Java only caches unsuccessful DNS queries for 10 seconds.
Attempting to look up the same host again within these limits will only return the same value.
Besides local caching inside the InetAddress class, the local host, the local domain name server, and other DNS servers elsewhere on the Internet also cache the results of various queries.
As a result, it may take several hours for the information about an IP address change to propagate across the Internet.
When you call getByName() with an IP address string as an argument, it creates an InetAddress object for the requested IP address without checking with DNS.
This means it’s possible to create InetAddress objects for hosts that don’t really exist and that you can’t connect to.
The hostname of an InetAddress object created from a string containing an IP address is initially set to that string.
A DNS lookup for the actual hostname is only performed when the hostname is requested, either explicitly via a getHostName()
If, at the time the hostname is requested and a DNS lookup is finally performed, the host with the specified IP address can’t be found, the hostname remains the original dotted quad string.
Some services have lived at the same hostname for years, but have switched IP addresses several times.
Use an IP address only when a hostname is not available.
Creating a new InetAddress object from a hostname is considered a potentially insecure operation because it requires a DNS lookup.
An untrusted applet under the control of the default security manager will only be allowed to get the IP address of the host it came from (its codebase) and possibly the local host.
Untrusted code is not allowed to create an InetAddress object from any other hostname.
Untrusted code can construct an InetAddress object from the string form of the IP address, though it will not perform DNS lookups for such addresses.
Untrusted code is not allowed to perform arbitrary DNS lookups for third-party hosts because of the prohibition against making network connections to hosts other than the codebase.
Arbitrary DNS lookups would open a covert channel by which a program could talk to third-party hosts.
To resolve that hostname, the applet would contact the local DNS server.
The local DNS server would contact the DNS server at crackersinc.com.
Even though these hosts don’t exist, the cracker can inspect the DNS error log for crackersinc.com to retrieve the message.
This scheme could be considerably more sophisticated with compression, error correction, encryption, custom DNS servers that email the messages to a fourth site, and more, but this version is good enough for a proof of concept.
Arbitrary DNS lookups are prohibited because arbitrary DNS lookups leak information.
The reason for prohibiting the applet from finding out the true hostname and address is that the computer on which the applet is running may be deliberately hidden behind a firewall.
In this case, an applet should not be a channel for information the web server doesn’t already have.
Like all security checks, prohibitions against DNS resolutions can be relaxed for trusted code.
The specific SecurityManager method used to test whether a host can be resolved is checkConnect():
When the port argument is –1, this method checks whether DNS may be invoked to resolve the specified host.
If the port argument is greater than –1, this method checks.
Getter Methods The InetAddress class contains four getter methods that return the hostname as a string and the IP address as both a string and a byte array:
There are no corresponding setHostName() and setAddress() methods, which means that packages outside of java.net can’t change an InetAddress object’s fields behind its back.
The getHostName() method returns a String that contains the name of the host with the IP address represented by this InetAddress object.
If the machine in question doesn’t have a hostname or if the security manager prevents the name from being determined, a dotted quad format of the numeric IP address is returned.
The getHostAddress() method returns a string containing the dotted quad format of the IP address.
Example 4-4 uses this method to print the IP address of the local machine in the customary format.
Find the IP address of the local machine import java.net.*;
Of course, the exact output depends on where the program is run.
If you want to know the IP address of a machine (and you rarely do), then use the getAddress() method, which returns an IP address as an array of bytes in network byte order.
The most significant byte (i.e., the first byte in the address’s dotted quad form) is the first byte in the array, or element zero.
To be ready for IPv6 addresses, try not to assume anything about the length of this array.
If you need to know the length of the array, use the array’s length field:
Unlike C, Java doesn’t have an unsigned byte primitive data type.
Bytes with values higher than 127 are treated as negative numbers.
Therefore, if you want to do anything with the bytes returned by getAddress(), you need to promote the bytes to ints and make appropriate adjustments.
If it is, 256 is added to signedByte to make it positive.
One reason to look at the raw bytes of an IP address is to determine the type of the address.
Address Types Some IP addresses and some patterns of addresses have special meanings.
For instance, I’ve already mentioned that 127.0.0.1 is the local loopback address.
Java includes 10 methods for testing whether an InetAddress object meets any of these criteria:
A wildcard address matches any address of the local system.
This is important if the system has multiple network interfaces, as might be the case on a system with multiple Ethernet cards or an Ethernet card and an 802.11 WiFi interface.
The loopback address connects to the same computer directly in the IP layer without using any physical hardware.
Thus, connecting to the loopback address enables tests to bypass potentially buggy or nonexistent Ethernet, PPP, and other drivers, helping to isolate problems.
Connecting to the loopback address is not the same as connecting to the system’s normal IP address from the same system.
Routers do not forward packets addressed to a link-local address beyond the local subnet.
The next eight bytes are filled with a local address, often copied from the Ethernet MAC address assigned by the Ethernet card manufacturer.
Site-local addresses are similar to link-local addresses except that they may be forwarded by routers within a site or campus but should not be forwarded beyond that site.
The next eight bytes are filled with a local address, often copied from the Ethernet MAC address assigned by the Ethernet card manufacturer.
Multicasting broadcasts content to all subscribed computers rather than to one particular computer.
The isMCGlobal() method returns true if the address is a global multicast address, false otherwise.
A global multicast address may have subscribers around the world.
In IPv4, all multicast addresses have global scope, at least as far as this method is concerned.
The isMCOrgLocal() method returns true if the address is an organization-wide multicast address, false otherwise.
An organization-wide multicast address may have subscribers within all the sites of a company or organization, but not outside that organization.
The isMCSiteLocal() method returns true if the address is a site-wide multicast address, false otherwise.
Packets addressed to a site-wide address will only be transmitted within their local site.
The isMCLinkLocal() method returns true if the address is a subnet-wide multicast address, false otherwise.
Packets addressed to a link-local address will only be transmitted within their own subnet.
The isMCNodeLocal() method returns true if the address is an interface-local multicast address, false otherwise.
Packets addressed to an interface-local address are not sent beyond the network interface from which they originate, not even to a different network interface on the same node.
The method name is out of sync with current terminology.
Earlier drafts of the IPv6 protocol called this type of address “node-local,” hence the name “isMCNodeLocal.” The IPNG working group actually changed the name before this method was added to the JDK, but Sun didn’t get the memo in time.
Testing Reachability The InetAddress class has two isReachable() methods that test whether a particular node is reachable from the current host (i.e., whether a network connection can be made)
Connections can be blocked for many reasons, including firewalls, proxy servers, misbehaving routers, and broken cables, or simply because the remote host is not turned on when you try to connect.
These methods attempt to use traceroute (more specifically, ICMP echo requests) to find out if the specified address is reachable.
If the host responds within timeout milliseconds, the methods return true; otherwise, they return false.
An IOException will be thrown if there’s a network error.
The second variant also lets you specify the local network interface the connection is made from and the “time-to-live” (the maximum number of network hops the connection will attempt before being discarded)
Thus, it has access to all the methods of that class.
An object is equal to an InetAddress object only if it is itself an instance of the InetAd dress class and it has the same IP address.
The int that hash Code() returns is calculated solely from the IP address.
If two InetAddress objects have the same address, then they have the same hash code, even if their hostnames are different.
As you saw, the string produced by toString() has the form:
If one doesn’t, the dotted quad address is substituted in Java 1.3 and earlier.
In Java 1.4 and later, the hostname is set to the empty string.
In the application layer where Java programs reside, you simply don’t need to know this (and even if you do need to know, it’s quicker to check the size of the byte array returned by getAddress() than to use instanceof to test which subclass you have)
Inet4Address overrides several of the methods in InetAddress but doesn’t change their behavior in any public way.
If this is the case, you can pull off the last four bytes from the array returned by getBytes() and use this data to create an Inet4Ad dress instead.
This can either be a physical interface such as an additional Ethernet card (common on firewalls and routers) or it can be a virtual interface bound to the same physical hardware as the machine’s other IP addresses.
The NetworkInterface class provides methods to enumerate all the local addresses, regardless of interface, and to create InetAddress objects from them.
These InetAddress objects can then be used to create sockets, server sockets, and so forth.
Factory Methods Because NetworkInterface objects represent physical hardware and virtual addresses, they cannot be constructed arbitrarily.
As with the InetAddress class, there are static factory methods that return the NetworkInterface object associated with a particular network interface.
You can ask for a NetworkInterface by IP address, by name, or by enumeration.
The getByName() method returns a NetworkInterface object representing the network interface with the particular name.
If there’s no interface with that name, it returns null.
If the underlying network stack encounters a problem while locating the relevant network interface, a SocketException is thrown, but this isn’t too likely to happen.
The local loopback address is probably named something like “lo”
For example, this code fragment attempts to find the primary Ethernet interface on a Unix system:
The getByInetAddress() method returns a NetworkInterface object representing the network interface bound to the specified IP address.
If no network interface is bound to that IP address on the local host, it returns null.
For example, this code fragment finds the network interface for the local loopback address:
Example 4-8 is a simple program to list all network interfaces on the local host:
Here’s the result of running this on the IBiblio login server:
You can see that this host has two separate Ethernet cards plus the local loopback address.
Getter Methods Once you have a NetworkInterface object, you can inquire about its IP address and name.
This is pretty much the only thing you can do with these objects.
The getName() method returns the name of a particular NetworkInterface object, such as eth0 or lo.
On Windows, you may see slightly friendlier names such as “Local Area Connection” or “Local Area Connection 2.”
The tools in this class alone let you write some genuinely useful programs.
Here you’ll look at two examples: one that queries your domain name server interactively and another that can improve the performance of your web server by processing logfiles offline.
SpamCheck A number of services monitor spammers, and inform clients whether a host attempting to connect to them is a known spammer or not.
These real-time blackhole lists need to respond to queries extremely quickly, and process a very high load.
Thousands, maybe millions, of hosts query them repeatedly to find out whether an IP address attempting a connection is or is not a known spammer.
The nature of the problem requires that the response be fast, and ideally it should be cacheable.
Furthermore, the load should be distributed across many servers, ideally ones located around the world.
Although this could conceivably be done using a web server, SOAP, UDP, a custom protocol, or some other mechanism, this service is in fact cleverly implemented using DNS and DNS alone.
To find out if a certain IP address is a known spammer, reverse the bytes of the address, add the domain of the blackhole service, and look it up.
Note that despite the numeric component, this is a hostname ASCII string, not a dotted quad IP address.
If the DNS query succeeds (and, more specifically, if it returns the address 127.0.0.2), then the host is known to be a spammer.
If you use this technique, be careful to stay on top of changes to blackhole list policies and addresses.
For obvious reasons, blackhole servers are frequent targets of DDOS and other attacks, so you want to be careful that if the blackhole server changes its address or simply stops responding to any queries, you don’t begin blocking all traffic.
Further note that different blackhole lists can follow slightly different protocols.
Processing Web Server Logfiles Web server logs track the hosts that access a website.
By default, the log reports the IP addresses of the sites that connect to the server.
However, you can often get more information from the names of those sites than from their IP addresses.
Most web servers have an option to store hostnames instead of IP addresses, but this can hurt performance because the server needs to make a DNS request for each hit.
It is much more efficient to log the IP addresses and convert them to hostnames at a later time, when the server isn’t busy or even on another machine completely.
Example 4-10 is a program called Weblog that reads a web server logfile and prints each line with IP addresses converted to hostnames.
Most web servers have standardized on the common logfile format.
A typical line in the common logfile format looks like this:
The first field is the IP address or, if DNS resolution is turned on, the hostname from which the connection was made.
Therefore, for our purposes, parsing the logfile is easy: everything before the first space is the IP address, and everything after it does not need to be changed.
The name of the file to be processed is passed to Weblog as the first argument on the command line.
A FileInputStream fin is opened from this file and an InputStream Reader is chained to fin.
This InputStreamReader is buffered by chaining it to an instance of the BufferedReader class.
The file is processed line by line in a for loop.
Each pass through the loop places one line in the String variable entry.
The position of the first space is determined by entry.indexOf(" ")
The substring ip is converted to an InetAddress object using getByName()
Finally, the hostname and everything else on the line (theRest) are printed on System.out.
Output can be sent to a new file through the standard means for redirecting output.
Most web browsers generate multiple logfile entries per page served, because there’s an entry in the log not just for the page itself but for each graphic on the page.
And many visitors request multiple pages while visiting a site.
If the same address is requested again, it can be retrieved from the cache much more quickly than from DNS.
In my initial tests, it took more than a second per log entry.
Exact numbers depend on the speed of your network connection, the speed of the local and remote DNS servers, and network congestion when the program is run.
The program spends a huge amount of time sitting and waiting for DNS requests to return.
Of course, this is exactly the problem multithreading is designed to solve.
One main thread can read the logfile and pass off individual entries to other threads for processing.
Over the space of a few days, even lowvolume web servers can generate a logfile with hundreds of thousands of lines.
Trying to process such a logfile by spawning a new thread for each entry would rapidly bring even the strongest virtual machine to its knees, especially because the main thread can read logfile entries much faster than individual threads can resolve domain names and die.
The number of threads is stored in a tunable parameter, numberOfThreads, so that it can be adjusted to fit the VM and network stack.
Launching too many simultaneous DNS requests can also cause problems.
The first class, LookupTask, shown in Example 4-11, is a Callable that parses a logfile entry, looks up a single address, and replaces that address with the corresponding hostname.
This doesn’t seem like a lot of work and CPU-wise, it isn’t.
The second class, PooledWeblog, shown in Example 4-12, contains the main() method that reads the file and creates one LookupTask per line.
Each task is submitted to an executor that can run multiple (though not all) tasks in parallel and in sequence.
The Future that is returned from the submit() method is stored in a queue, along with the original line (in case something goes wrong in the asynchronous thread)
A loop reads values out of the queue and prints them.
Using threads like this lets the same logfiles be processed in parallel—a huge time savings.
The tech editor ran the same test on a different system and only saw a factor of four improvement, but either way it’s still a significant gain.
Although the queue of Callable tasks is much more efficient than spawning a thread for each logfile entry, logfiles can be huge and this program can still burn a lot of memory.
To avoid this, you could put the output into a separate thread that shared the queue with the input thread.
Because early entries could be processed and output while the input was still being parsed, the queue would not grow so large.
You’d need a separate signal to tell you when the output was complete because an empty queue is no longer sufficient to prove the job is complete.
The easiest way is simply to count the number of input lines and make sure it matches up to the number of output lines.
In the last chapter, you learned how to address hosts on the Internet via host names and IP addresses.
In this chapter, we increase the granularity by addressing resources, any number of which may reside on any given host.
A URL unambiguously identifies the location of a resource on the Internet.
A URI can identify a resource by its network location, as in a URL, or by its name, number, or other characteristics.
The URL class is the simplest way for a Java program to locate and retrieve data from the network.
You do not need to worry about the details of the protocol being used, or how to communicate with the server; you simply tell Java the URL and it gets the data for you.
URIs A Uniform Resource Identifier (URI) is a string of characters in a particular syntax that identifies a resource.
The resource identified may be a file on a server; but it may also be an email address, a news message, a book, a person’s name, an Internet host, the current stock price of Oracle, or something else.
A resource is a thing that is identified by a URI.
Don’t spend too much time worrying about what a resource is or isn’t, because you’ll never see one anyway.
All you ever receive from a server is a representation of a resource which comes in the form of bytes.
There are also representations of this resource in English, French, Arabic, and many other languages.
One of the key principles of good web architecture is to be profligate with URIs.
If anyone might want to address something or refer to something, give it a URI (and in practice a URL)
Just because a resource is a part of another resource, or a collection of other resources, or a state of another resource at a particular time, doesn’t mean it can’t have its own URI.
For instance, in an email service, every user, every message received, every message sent, every filtered view of the inbox, every contact, every filter rule, and every single page a user might ever look at should have a unique URI.
Although architecturally URIs are opaque strings, in practice it’s useful to design them with human-readable substructure.
The syntax of a URI is composed of a scheme and a scheme-specific part, separated by a colon, like this:
The syntax of the scheme-specific part depends on the scheme being used.
In addition, Java makes heavy use of nonstandard custom schemes such as rmi, jar, jndi, and doc for various purposes.
There is no specific syntax that applies to the scheme-specific parts of all URIs.
The authority part of the URI names the authority responsible for resolving the rest of the URI.
This means the server at www.ietf.org is responsible for mapping the path /rfc/rfc3986.txt to a resource.
The URI urn:isbn:156592870 has the scheme urn but doesn’t follow the hierarchical //authority/ path?query form for scheme-specific parts.
Although most current examples of URIs use an Internet host as an authority, future schemes may not.
However, if the authority is an Internet host, optional usernames and ports may also be provided to make the authority more specific.
In most cases, including the password in the URI is a big security hole unless, as here, you really do want everyone in the universe to know the password.
The path is a string that the authority can use to determine which resource is identified.
Different authorities may interpret the same path to refer to different resources.
The path may be hierarchical, in which case the individual parts are separated by forward slashes, and the.
These are derived from the pathname syntax on the Unix operating systems where the Web and URLs were invented.
They conveniently map to a filesystem stored on a Unix web server.
However, there is no guarantee that the components of any particular path actually correspond to files or directories on any particular filesystem.
Some URIs aren’t at all hierarchical, at least in the filesystem sense.
Although there’s some hierarchy to the newsgroup names indicated by the period between netscape and devs-java, it’s not encoded as part of the URI.
If you don’t hexadecimally encode non-ASCII characters like this, but just include them directly, then instead of a URI you have an IRI (an Internationalized Resource Identifier)
IRIs are easier to type and much easier to read, but a lot of software and protocols expect and support only ASCII URIs.
Punctuation characters such as / and @ must also be encoded with percent escapes if they are used in any role other than what’s specified for them in the scheme-specific part of a particular URL.
This is not as far-fetched as it might sound to Unix or Windows users.
And of course URLs are, more often than not, not derived from filenames at all.
URLs A URL is a URI that, as well as identifying a resource, provides a specific network location for the resource that a client can use to retrieve a representation of that resource.
By contrast, a generic URI may tell you what a resource is, but not actually tell you where.
In Java, it’s the difference between the java.net.URI class that only identifies resources and the java.net.URL class that can both identify and retrieve resources.
The network location in a URL usually includes the protocol used to access a server (e.g., FTP, HTTP), the hostname or IP address of the server, and the path to the resource on that server.
Here the protocol is another word for what was called the scheme of the URI.
In a URL, the protocol part can be file, ftp, http, https, magnet, telnet, or various other strings (though not urn)
The host part of a URL is the name of the server that provides the resource you want.
If present, it contains a username and, rarely, a password.
It’s not necessary if the service is running on its default port (port 80 for HTTP servers)
The path points to a particular resource on the specified server.
It often looks like a filesystem path such as /forum/index.php.
However, it may or may not actually map to a filesystem on the server.
If it does map to a filesystem, the path is relative to the document root of the server, not necessarily to the root of the filesystem on the server.
As a rule, servers that are open to the public do not show their entire filesystem to clients.
Rather, they show only the contents of a specified directory.
This directory is called the document root, and all paths and filenames are relative to it.
Thus, on a Unix server, all files that are available to the public might be in /var/public/html, but to somebody connecting from a remote machine, this directory looks like the root of the filesystem.
It’s commonly used only in http URLs, where it contains form data for input to programs running on the server.
Finally, the fragment references a particular part of the remote resource.
If the remote resource is HTML, the fragment identifier names an anchor in the HTML document.
If the remote resource is XML, the fragment identifier is an XPointer.
Some sources refer to the fragment part of the URL as a “section”
Java rather unaccountably refers to the fragment identifier as a “Ref ”
Fragment identifier targets are created in an HTML document with an id attribute, like this:
To refer to this point, a URL includes not only the document’s filename but the fragment identifier separated from the rest of the URL by a #:
Technically, a string that contains a fragment identifier is a URL reference, not a URL.
Java, however, does not distinguish between URLs and URL references.
Relative URLs A URL tells a web browser a lot about a document: the protocol used to retrieve the document, the host where the document lives, and the path to the document on that host.
Most of this information is likely to be the same for other URLs that are referenced in the document.
Therefore, rather than requiring each URL to be specified in its entirety, a URL may inherit the protocol, hostname, and path of its parent document (i.e., the document in which it appears)
URLs that aren’t complete but inherit pieces from their parent are called relative URLs.
In contrast, a completely specified URL is called an absolute URL.
In a relative URL, any pieces that are missing are assumed to be the same as the corresponding pieces from the URL of the document in which the URL is found.
For example, suppose that while browsing http://www.ibiblio.org/javafaq/javatutorial.html you click on this hyperlink:
Then it attaches javafaq.html onto the end of http://www.ibiblio.org/javafaq/ to get http://www.ibiblio.org/javafaq/javafaq.html.
If the relative link begins with a /, then it is relative to the document root instead of relative to the current file.
More importantly, relative URLs allow a single document tree to be served by multiple protocols: for instance, both HTTP and FTP.
Most importantly of all, relative URLs allow entire trees of documents to be moved or copied from one site to another without breaking all the internal links.
Rather than relying on inheritance to configure instances for different kinds of URLs, it uses the strategy design pattern.
Protocol handlers are the strategies, and the URL class itself forms the context through which the different strategies are selected.
Indeed, this is almost exactly how the java.net.URL class is organized, though the details vary a little between different versions of Java.
After a URL object has been constructed, its fields do not change.
This has the side effect of making them thread safe.
Creating New URLs Unlike the InetAddress objects in Chapter 4, you can construct instances of java.net.URL.
Which constructor you use depends on the information you have and the form it’s in.
The only protocols that have been available in all virtual machines are http and file, and the latter is notoriously flaky.
Today, Java also supports the https, jar, and ftp protocols.
Some virtual machines support mailto and gopher as well as some custom protocols like doc, netdoc, systemresource, and verbatim used internally by Java.
If the protocol you need isn’t supported by a particular VM, you may be able to install a protocol handler for that scheme to enable the URL class to speak that protocol.
In practice, this is way more trouble than it’s worth.
You’re better off using a library that exposes a custom API just for that protocol.
Other than verifying that it recognizes the URL scheme, Java does not check the correctness of the URLs it constructs.
The programmer is responsible for making sure that URLs created are valid.
It does not check that a mailto URL actually contains an email address.
You can create URLs for hosts that don’t exist and for hosts that do exist but that you won’t be allowed to connect to.
The simplest URL constructor just takes an absolute URL in string form as its single argument:
The following code constructs a URL object from a String, catching the exception that might be thrown:
Example 5-1 is a simple program for determining which protocols a virtual machine supports.
If the constructor succeeds, you know the protocol is supported.
The results of this program depend on which virtual machine runs it.
The nonsupport of RMI and JDBC is actually a little deceptive; in fact, the JDK does support these protocols.
However, that support is through various parts of the java.rmi and java.sql packages, respectively.
These protocols are not accessible through the URL class like the other supported protocols (although I have no idea why Sun chose to wrap up RMI and JDBC parameters in URL clothing if it wasn’t intending to interface with these via Java’s quite sophisticated mechanism for handling URLs)
VMs that are not derived from the Oracle codebase may vary somewhat in which protocols they support.
For example, Android’s Dalvik VM only supports the required http, https, file, ftp, and jar protocols.
You can also build a URL by specifying the protocol, the hostname, and the file:
This constructor sets the port to -1 so the default port for the protocol will be used.
The file argument should begin with a slash and include a path, a filename, and optionally a fragment identifier.
Forgetting the initial slash is a common mistake, and one that is not easy to spot.
The file specification includes a reference to a named anchor.
The code catches the exception that would be thrown if the virtual machine did not support the HTTP protocol.
For the rare occasions when the default port isn’t correct, the next constructor lets you specify the port explicitly as an int.
This constructor builds an absolute URL from a relative URL and a base URL:
In this case, you use the URL to the document that contains the link to provide the missing information.
This constructor is particularly useful when you want to loop through a list of files that are all in the same directory.
You can create a URL for the first file and then use this initial URL to create URL objects for the other files by substituting their filenames.
Other sources of URL objects Besides the constructors discussed here, a number of other methods in the Java class library return URL objects.
In applets, getDocumentBase() returns the URL of the page that contains the applet and getCodeBase() returns the URL of the applet .class file.
The java.io.File class has a toURL() method that returns a file URL matching the given file.
The exact format of the URL returned by this method is platform dependent.
In practice, file URLs are heavily platform and program dependent.
Java file URLs often cannot be interchanged with the URLs used by web browsers and other programs, or even with Java programs running on different platforms.
Class loaders are used not only to load classes but also to load resources such as images and audio files.
And finally, the instance method getRe source(String name) searches the path used by the referenced class loader for a URL to the named resource.
The URLs returned by these methods may be file URLs, HTTP URLs, or some other scheme.
The Java virtual machine will attempt to find the requested resource in the classpath, potentially inside a JAR archive.
What’s interesting is the data contained in the documents they point to.
The URL class has several methods that retrieve data from a URL:
The most basic and most commonly used of these methods is openStream(), which returns an InputStream from which you can read the data.
If you need more control over the download process, call openConnection() instead, which gives you a URLCon nection which you can configure, and then get an InputStream from it.
Finally, you can ask the URL for its content with getContent() which may give you a more complete object such as String or an Image.
Then again, it may just give you an InputStream anyway.
The openStream() method connects to the resource referenced by the URL, performs any necessary handshaking between the client and the server, and returns an Input Stream from which data can be read.
The data you get from this InputStream is the raw (i.e., uninterpreted) content the URL references: ASCII if you’re reading an ASCII text file, raw HTML if you’re reading an HTML file, binary image data if you’re reading an image file, and so forth.
It does not include any of the HTTP headers or any other protocol-related information.
You can read from this InputStream as you would read from any other InputStream.
As with most network streams, reliably closing the stream takes a bit of effort.
In Java 6 and earlier, we use the dispose pattern: declare the stream variable outside the try block, set it to null, and then close it in the finally block if it’s not null.
Java 7 makes this somewhat cleaner by using a nested try-with-resources statement:
That is, it prints the raw data located at the URL if the URL references an HTML file; the program’s output is raw HTML.
There are quite a few more lines in that web page; if you want to see them, you can fire up your web browser.
The shakiest part of this program is that it blithely assumes that the URL points to text, which is not necessarily true.
It could well be pointing to a GIF or JPEG image, an MP3 sound file, or something else entirely.
Even if does resolve to text, the document encoding may not be the same as the default encoding of the client system.
The remote host and local client may not have the same default character set.
As a general rule, for pages that use a character set radically different from ASCII, the HTML will include a META tag in the header specifying the character set in use.
For instance, this META tag specifies the Big-5 encoding for Chinese:
An XML document will likely have an XML declaration instead:
In practice, there’s no easy way to get at this information other than by parsing the file and looking for a header like this one, and even that approach is limited.
And as if this isn’t confusing enough, the HTTP header that precedes the actual document is likely to have its own encoding information, which may completely contradict what the document itself says.
You can’t read this header using the URL class, but you can with the URLConnection object returned by the openConnection() method.
Encoding detection and declaration is one of the thornier parts of the architecture of the Web.
The openConnection() method opens a socket to the specified URL and returns a URLConnection object.
A URLConnection represents an open connection to a network resource.
You should use this method when you want to communicate directly with the server.
The URLConnection gives you access to everything sent by the server: in addition to the document itself in its raw form (e.g., HTML, plain text, binary image data), you can access all the metadata specified by the protocol.
For example, if the scheme is HTTP or HTTPS, the URLConnection lets you access the HTTP headers as well as the raw HTML.
The URLConnection class also lets you write data to as well as read from a URL —for instance, in order to send email to a mailto URL or post form data.
An overloaded variant of this method specifies the proxy server to pass the connection through:
If the protocol handler does not support proxies, the argument is ignored and the connection is made directly if possible.
The getContent() method is the third way to download data referenced by a URL.
The getContent() method retrieves the data referenced by the URL and tries to make it into some type of object.
If the URL refers to some kind of text such as an ASCII or HTML file, the object returned is usually some sort of InputStream.
If the URL refers to an image such as a GIF or a JPEG file, getContent() usually returns a java.awt.Image Producer.
What unifies these two disparate classes is that they are not the thing itself but a means by which a program can construct the thing:
If the server does not use MIME headers or sends an unfamiliar Content-type, getContent() returns some sort of InputStream with which the data can be read.
An IOException is thrown if the object can’t be retrieved.
Here’s what you get when you try to load a header image from that page:
Here’s what happens when you try to load a Java applet using getContent():
Here’s what happens when you try to load an audio file using getContent():
The last result is the most unusual because it is as close as the Java core API gets to a class that represents a sound file.
It’s not just an interface through which you can load the sound data.
This example demonstrates the biggest problems with using getContent(): it’s hard to predict what kind of object you’ll get.
You could get some kind of InputStream or an ImageProducer or perhaps an AudioClip; it’s easy to check using the instanceof operator.
This information should be enough to let you read a text file or display an image.
If the content handler knows how to return a string representation of the resource, then it returns a String.
If it doesn’t know how to return a string representation of the resource, then it returns a Reader.
And if it doesn’t know how to present the resource as a reader, then it returns an InputStream.
You have to test for the type of the returned object using instanceof.
Splitting a URL into Pieces URLs are composed of five pieces:
The fragment identifier, also known as the section or ref.
For instance, the URL http://www.faqs.org/rfcs/rfc3986.html has a scheme, an authority, and a path, but no fragment identifier or query string.
The authority may further be divided into the user info, the host, and the port.
Read-only access to these parts of a URL is provided by nine public methods: get File(), getHost(), getPort(), getProtocol(), getRef(), getQuery(), getPath(), getUserInfo(), and getAuthority()
The getProtocol() method returns a String containing the scheme of the URL (e.g., “http”, “https”, or “file”)
The getHost() method returns a String containing the hostname of the URL.
The getPort() method returns the port number specified in the URL as an int.
If no port was specified in the URL, getPort() returns -1 to signify that the URL does not specify the port explicitly, and will use the default port for the protocol.
The following code prints -1 for the port number because it isn’t specified in the URL:
The getDefaultPort() method returns the default port used for this URL’s protocol when none is specified in the URL.
If no default port is defined for the protocol, then getDefaultPort() returns -1
The getFile() method returns a String that contains the path portion of a URL; remember that Java does not break a URL into separate path and file parts.
Everything from the first slash (/) after the hostname until the character preceding the # sign that begins a fragment identifier is considered to be part of the file.
If the URL does not have a file part, Java sets the file to the empty string.
Note that the getPath() method does not return only the directory path and getFile() does not return only the filename, as you might expect.
Both getPath() and getFile() return the full path and filename.
The only difference is that getFile() also returns the query string and getPath() does not.
The getRef() method returns the fragment identifier part of the URL.
If the URL doesn’t have a fragment identifier, the method returns null.
The getQuery() method returns the query string of the URL.
If the URL doesn’t have a query string, the method returns null.
That’s because the URL specifies the remote recipient of the message rather than the username and host that’s sending the message.
Example 5-4 uses these methods to split URLs entered on the command line into their component parts.
Here’s the result of running this against several of the URL examples in this chapter:
Equality and Comparison The URL class contains the usual equals() and hashCode() methods.
Two URLs are considered equal if and only if both URLs point to the same resource on the same host, port, and path, with the same fragment identifier and query string.
Prefer java.net.URI for this, and convert back and forth from URIs to URLs when necessary.
On the other hand, equals() does not go so far as to actually compare the resources identified by two URLs.
Example 5-5 creates URL objects for http://www.ibiblio.org/ and http://ibiblio.org/ and tells you if they’re the same using the equals() method.
The URL class also has a sameFile() method that checks whether two URLs point to the same resource:
The comparison is essentially the same as with equals(), DNS queries included, except that sameFile() does not consider the fragment identifier.
Here’s a fragment of code that uses sameFile() to compare two URLs:
Conversion URL has three methods that convert an instance to another form: toString(), toExternalForm(), and toURI()
The String produced by toString() is always an absolute URL, such as http://www.cafeaulait.org/javatutorial.html.
Outside of print statements, it’s more proper to use toExternal Form() instead:
The toExternalForm() method converts a URL object to a string that can be used in an HTML link or a web browser’s Open URL dialog.
The toExternalForm() method returns a human-readable String representing the URL.
In fact, all the toString() method does is return toExternalForm()
Finally, the toURI() method converts a URL object to an equivalent URI object:
For operations like absolutization and encoding, you should prefer the URI class where you have the option.
You should also prefer the URI class if you need to store URLs in a hashtable or other data structure, since its equals() method is not blocking.
The URL class should be used primarily when you want to download content from a server.
Most URIs used in practice are URLs, but most specifications and standards such as XML are defined in terms of URIs.
This class differs from the java.net.URL class in three important ways:
The URI class is purely about identification of resources and parsing of URIs.
It provides no methods to retrieve a representation of the resource identified by its URI.
The URI class is more conformant to the relevant specifications than the URL class.
In brief, a URL object is a representation of an application layer protocol for network retrieval, whereas a URI object is purely for string parsing and manipulation.
The URL class has some string parsing methods, such as getFile() and getRef(), but many of these are broken and don’t always behave exactly as the relevant specifications say they should.
Normally, you should use the URL class when you want to download the content at a URL and the URI class when you want to use the URL for identification rather than retrieval, for instance, to represent an XML namespace.
When you need to do both, you may convert from a URI to a URL with the toURL() method, and from a URL to a URI using the toURI() method.
You can either pass the entire URI to the constructor in a single string, or the individual pieces:
Unlike the URL class, the URI class does not depend on an underlying protocol handler.
As long as the URI is syntactically correct, Java does not need to understand its protocol in order to create a representative URI object.
Thus, unlike the URL class, the URI class can be used for new and experimental URI schemes.
The first constructor creates a new URI object from any convenient string.
If the string argument does not follow URI syntax rules—for example, if the URI begins with a colon—this constructor throws a URISyntaxException.
This is a checked exception, so either catch it or declare that the method where the constructor is invoked.
The second constructor that takes a scheme specific part is mostly used for nonhierarchical URIs.
The scheme is the URI’s protocol, such as http, urn, tel, and so forth.
It must be composed exclusively of ASCII letters and digits and the three punctuation characters +, -, and ..
Passing null for this argument omits the scheme, thus creating a relative URI.
The scheme-specific part depends on the syntax of the URI scheme; it’s one thing for an http URL, another for a mailto URL, and something else again for a tel URI.
Because the URI class encodes illegal characters with percent escapes, there’s effectively no syntax error you can make in this part.
Finally, the third argument contains the fragment identifier, if any.
Again, characters that are forbidden in a fragment identifier are escaped automatically.
Passing null for this argument simply omits the fragment identifier.
The third constructor is used for hierarchical URIs such as http and ftp URLs.
The host and path together (separated by a /) form the scheme-specific part for this URI.
If the constructor cannot form a legal hierarchical URI from the supplied pieces—for instance, if there is a scheme so the URI has to be absolute but the path doesn’t start with /—then it throws a URISyntaxException.
The fourth constructor is basically the same as the third, with the addition of a query string.
As usual, any unescapable syntax errors cause a URISyntaxException to be thrown and null can be passed to omit any of the arguments.
The fifth constructor is the master hierarchical URI constructor that the previous two invoke.
It divides the authority into separate user info, host, and port parts, each of which has its own syntax rules.
However, the resulting URI still has to follow all the usual rules for URIs; and again null can be passed for any argument to omit it from the result.
If you’re sure your URIs are legal and do not violate any of the rules, you can use the static factory URI.create() method instead.
For example, this invocation creates a URI for anonymous FTP access using an email address as password:
This is a runtime exception, so you don’t have to explicitly declare it or catch it.
The Parts of the URI A URI reference has up to three parts: a scheme, a scheme-specific part, and a fragment identifier.
If the scheme is omitted, the URI reference is relative.
If the fragment identifier is omitted, the URI reference is a pure URI.
The URI class has getter methods that return these three parts of each URI object.
The getRawFoo() methods return the encoded forms of the parts of the URI, while the equivalent getFoo() methods first decode any percentescaped characters and then return the decoded part:
There’s no getRawScheme() method because the URI specification requires that all scheme names be composed exclusively of URI-legal ASCII characters and does not allow percent escapes in scheme names.
These methods all return null if the particular URI object does not have the relevant component: for example, a relative URI without a scheme or an http URI without a fragment identifier.
A URI that has a scheme is an absolute URI.
The isAbsolute() method returns true if the URI is absolute, false if it’s relative:
The details of the scheme-specific part vary depending on the type of the scheme.
For example, in a tel URL, the scheme-specific part has the syntax of a telephone number.
However, in many useful URIs, including the very common file and http URLs, the scheme-specific part has a particular hierarchical format divided into an authority, a path, and a query string.
The authority is further divided into user info, host, and port.
The isOpaque() method returns false if the URI is hierarchical, true if it’s not hierarchical—that is, if it’s opaque:
If the URI is opaque, all you can get is the scheme, scheme-specific part, and fragment identifier.
However, if the URI is hierarchical, there are getter methods for all the different parts of a hierarchical URI:
If you want the raw, encoded parts of the URI, there are five parallel getRaw_Foo_() methods:
There are no getRawPort() and getRawHost() methods because these components are always guaranteed to be made up of ASCII characters.
In the event that the specific URI does not contain this information—for instance, the URI http://www.example.com has no user info, path, port, or query string—the relevant methods return null.
Since it’s declared to return an int, it can’t return null.
For various technical reasons that don’t have a lot of practical impact, Java can’t always initially detect syntax errors in the authority component.
The immediate symptom of this failing is normally an inability to return the individual parts of the authority, port, host, and user info.
The original URI does not change (URI objects are immutable), but the URI returned will have separate authority parts for user info, host, and port.
If the authority cannot be parsed, a URISyntaxException is thrown.
Example 5-6 uses these methods to split URIs entered on the command line into their component parts.
It’s similar to Example 5-4 but works with any syntactically correct URI, not just the ones Java has a protocol handler for.
Here’s the result of running this against three of the URI examples in this section:
The scheme is tel The scheme specific part is +1-800-9988-9938 The fragment ID is null.
Resolving Relative URIs The URI class has three methods for converting back and forth between relative and absolute URIs:
The resolve() methods compare the uri argument to this URI and use it to construct a new URI object that wraps an absolute URI.
After they’ve executed, resolved contains the absolute URI http://www.example.com/ images/logo.png.
If the invoking URI does not contain an absolute URI itself, the resolve() method resolves as much of the URI as it can and returns a new relative URI object as a result.
It’s also possible to reverse this procedure; that is, to go from an absolute URI to a relative one.
The relativize() method creates a new URI object from the uri argument that is relative to the invoking URI.
The URI object relative now contains the relative URI images/logo.png.
Equality and Comparison URIs are tested for equality pretty much as you’d expect.
The scheme and authority parts are compared without considering case.
The rest of the URI is case sensitive, except for hexadecimal digits used to escape illegal characters.
Equal URIs do have the same hash code and unequal URIs are fairly unlikely to share the same hash code.
The ordering is based on string comparison of the individual parts, in this sequence:
If the schemes are different, the schemes are compared, without considering case.
If both URIs are hierarchical, they’re ordered according to their authority components, which are themselves ordered according to user info, host, and port, in that order.
If the schemes and the authorities are equal, the path is used to distinguish them.
If the paths are also equal, the query strings are compared.
If the query strings are equal, the fragments are compared.
Comparing a URI to anything except another URI causes a ClassCastException.
String Representations Two methods convert URI objects to strings, toString() and toASCIIString():
If these characters occur as part of a path or query string, they and all other characters should be encoded.
Any characters that are not ASCII numerals, letters, or the punctuation marks specified earlier are converted into bytes and each byte is written as a percent sign followed by two hexadecimal digits.
Besides being encoded as %20, they can be encoded as a plus sign (+)
You can construct URL objects that use illegal ASCII and non-ASCII characters and/or percent escapes.
Such characters and escapes are not automatically encoded or decoded when output by methods such as getPath() and toExternalForm()
You are responsible for making sure all such characters are properly encoded in the strings used to construct a URL object.
Luckily, Java provides URLEncoder and URLDecoder classes to cipher strings in this format.
URLEncoder To URL encode a string, pass the string and the character set name to the URLEncod er.encode() method.
Any nonalphanumeric characters are converted into % sequences (except the space, underscore, hyphen, period, and asterisk characters)
This method is a little overaggressive; it also converts tildes, single quotes, exclamation points, and parentheses to percent escapes, even though they don’t absolutely have to be.
However, this change isn’t forbidden by the URL specification, so web browsers deal reasonably with these excessively encoded URLs.
Although this method allows you to specify the character set, the only such character set you should ever pick is UTF-8
UTF-8 is compatible with the IRI specification, the URI class, modern web browsers, and more additional software than any other encoding you could choose.
Here is the output (note that the code needs to be saved in something other than ASCII, and the encoding chosen should be passed as an argument to the compiler to account for the non-ASCII characters in the source code):
Notice in particular that this method encodes the forward slash, the ampersand, the equals sign, and the colon.
It does not attempt to determine how these characters are being used in a URL.
Consequently, you have to encode URLs piece by piece rather than encoding an entire URL in one method call.
This is an important point, because the most common use of URLEncoder is preparing query strings for communicating with server-side programs that use GET.
For example, suppose you want to encode this URL for a Google search:
It can’t distinguish between special characters used as part of the URL or query string, like / and =, and characters that need to be encoded.
Consequently, URLs need to be encoded a piece at a time like this:
In this case, you could have skipped encoding several of the constant strings such as “Java” because you know from inspection that they don’t contain any characters that need to be encoded.
However, in general, these values will be variables, not constants; and you’ll need to encode each piece to be safe.
Example 5-8 is a QueryString class that uses URLEncoder to encode successive name and value pairs in a Java object, which will be used for sending data to server-side programs.
To add name-value pairs, call the add() method, which takes two strings as arguments and encodes them.
The getQuery() method returns the accumulated list of encoded name-value pairs.
Using this class, we can now encode the previous example:
That is, it converts all plus signs to spaces and all percent escapes to their corresponding character:
If you have any doubt about which encoding to use, pick UTF-8
Since URLDecoder does not touch non-escaped characters, you can pass an entire URL to it rather than splitting it into pieces first.
Proxies Many systems access the Web and sometimes other non-HTTP parts of the Internet through proxy servers.
A proxy server receives a request for a remote server from a local client.
The proxy server makes the request to the remote server and forwards the result back to the local client.
Sometimes this is done for security reasons, such as to prevent remote hosts from learning private details about the local network configuration.
Other times it’s done to prevent users from accessing forbidden sites by filtering outgoing requests and limiting which sites can be viewed.
For instance, an elementary school might want to block access to http://www.playboy.com.
And still other times it’s done purely for performance, to allow multiple users to retrieve the same popular documents from a local cache rather than making repeated downloads from the remote server.
Java programs based on the URL class can work through most common proxy servers and protocols.
Indeed, this is one reason you might want to choose to use the URL class rather than rolling your own HTTP or other client on top of raw sockets.
System Properties For basic operations, all you have to do is set a few system properties to point to the addresses of your local proxy servers.
If you are using a pure HTTP proxy, set http.proxyHost to the domain name or the IP address of your proxy server and http.proxyPort to the port of the proxy server (the default is 80)
To exclude multiple hosts, separate their names by vertical bars.
You can also use an asterisk as a wildcard to indicate that all the hosts within a particular domain or subdomain should not be proxied.
For example, to proxy everything except hosts in the oreilly.com domain:
Java does not support any other application layer proxies, but if you’re using a transport layer SOCKS proxy for all TCP connections, you can identify it with the socksProxy Host and socksProxyPort system properties.
Java does not provide an option for nonproxying with SOCKS.
The Proxy Class The Proxy class allows more fine-grained control of proxy servers from within a Java program.
Specifically, it allows you to choose different proxy servers for different remote hosts.
The proxies themselves are represented by instances of the java.net.Proxy class.
There are still only three kinds of proxies, HTTP, SOCKS, and direct connections (no proxy at all), represented by three constants in the Proxy.Type enum:
Besides its type, the other important piece of information about a proxy is its address and port, given as a SocketAddress object.
Although there are only three kinds of proxy objects, there can be many proxies of the same type for different proxy servers on different hosts.
The default ProxySelector merely inspects the various system properties and the URL’s protocol to decide how to connect to different hosts.
However, you can install your own subclass of ProxySelector in place of the default selector and use it to choose different proxies based on protocol, host, path, time of day, or other criteria.
The key to this class is the abstract select() method:
Java passes this method a URI object (not a URL object) representing the host to which a connection is needed.
The ProxySelector object then chooses the right proxies for this type of object and returns them in a List<Proxy>
The second abstract method in this class you must implement is connectFailed():
This is a callback method used to warn a program that the proxy server isn’t actually making the connection.
As I said, each virtual machine has exactly one ProxySelector.
From this point forward, all connections opened by that virtual machine will ask the ProxySelector for the right proxy to use.
You normally shouldn’t use this in code running in a shared environment.
For instance, you wouldn’t change the ProxySelector in a servlet because that would change the ProxySelector for all servlets running in the same container.
Communicating with Server-Side Programs Through GET The URL class makes it easy for Java applets and applications to communicate with serverside programs such as CGIs, servlets, PHP pages, and others that use the GET method.
Server-side programs that use the POST method require the URLConnection class and.
All you need to know is what combination of names and values the program expects to receive.
Then you can construct a URL with a query string that provides the requisite names and values.
There are a number of ways to determine the exact syntax for a query string that talks to a particular program.
If you’ve written the server-side program yourself, you already know the name-value pairs it expects.
If you’ve installed a third-party program on your own server, the documentation for that program should tell you what it expects.
If you’re talking to a documented external network API such as the eBay Shopping API, then the service usually provides fairly detailed documentation to tell you exactly what data to send for which purposes.
If this is the case, it’s straightforward to figure out what input the program expects.
The method the form uses should be the value of the METHOD attribute of the FORM element.
The part of the URL that precedes the query string is given by the value of the ACTION attribute of the FORM element.
Note that this may be a relative URL, in which case you’ll need to determine the corresponding absolute URL.
Finally, the names in the name-value pairs are simply the values of the NAME attributes of the INPUT elements.
The values of the pairs are whatever the user types into the form.
For example, consider this HTML form for the local search engine on my Cafe con Leche site.
The program that processes the form is accessed via the URL http://www.google.com/search.
It has four separate name-value pairs, three of which have default values:
For instance, it doesn’t matter if it’s a set of checkboxes, a pop-up list, or a text field.
Only the name of each INPUT field and the value you give it is significant.
The submit input tells the web browser when to send the data but does not give the server any extra information.
Sometimes you find hidden INPUT fields that must have particular required default values.
There are many different form tags in HTML that produce pop-up.
However, although these input widgets appear different to the user, the format of data they send to the server is the same.
Each form element provides a name and an encoded string value.
In some cases, the program you’re talking to may not be able to handle arbitrary text strings for values of particular inputs.
However, since the form is meant to be read and filled in by human beings, it should provide sufficient clues to figure out what input is expected; for instance, that a particular field is supposed to be a two-letter state abbreviation or a phone number.
There may not even be a form, just links to follow.
In this case, you have to do some experimenting, first copying some existing values and then tweaking them to see what values are and aren’t accepted.
You don’t need to do this in a Java program.
You can simply edit the URL in the address or location bar of your web browser window.
The likelihood that other hackers may experiment with your own server-side programs in such a fashion is a good reason to make them extremely robust against unexpected input.
Regardless of how you determine the set of name-value pairs the server expects, communicating with it once you know them is simple.
All you have to do is create a query string that includes the necessary name-value pairs, then form a URL that includes that query string.
Send the query string to the server and read its response using the same methods you use to connect to a server and retrieve a static HTML page.
There’s no special protocol to follow once the URL is constructed.
To demonstrate this procedure, let’s write a very simple command-line program to look up topics in the Open Directory.
This site is shown in Figure 5-1 and it has the advantage of being really simple.
The Open Directory interface is a simple form with one input field named search; input typed in this field is sent to a program at http://search.dmoz.org/cgi-bin/search, which does the actual search.
There are only two input fields in this form: the Submit button and a text field named q.
Thus, to submit a search request to the Open Directory, you just need to append q=searchTerm to http://www.dmoz.org/search.
Of course, a lot more effort could be expended on parsing and displaying the results.
But notice how simple the code was to talk to this server.
Accessing Password-Protected Sites Many popular sites require a username and password for access.
Some sites, such as the W3C member pages, implement this through HTTP authentication.
Others, such as the New York Times website, implement it through cookies and HTML forms.
Supporting sites that use nonstandard, cookie-based authentication is more challenging, not least because this varies a lot from one site to another.
Accessing sites protected by standard HTTP authentication is much easier.
The Authenticator Class The java.net package includes an Authenticator class you can use to provide a username and password for sites that protect themselves using HTTP authentication:
Since Authenticator is an abstract class, you must subclass it.
For example, a character mode program might just ask the user to type the username and password on System.in.
A GUI program would likely put up a dialog box like the one shown in Figure 5-2
An automated robot might read the username out of an encrypted file.
For example, if you’ve written an Authenticator subclass named DialogAuthentica tor, you’d install it like this:
The address argument is the host for which authentication is required.
The port argument is the port on that host, and the protocol argument is the application layer protocol by which the site is being accessed.
It’s typically the name of the realm for which authentication is required.
Here the word scheme is not being used as a synonym for protocol.
Untrusted applets are not allowed to ask the user for a name and password.
If you don’t want to authenticate this request, return null, and Java will tell the server it doesn’t know how to authenticate the connection.
You normally have five tries to get the username and password correct; after that, openStream() throws a ProtocolException.
Usernames and passwords are cached within the same virtual machine session.
Once you set the correct password for a realm, you shouldn’t be asked for it again unless you’ve explicitly deleted the password by zeroing out the char array that contains it.
You can get more details about the request by invoking any of these methods inherited from the Authenticator superclass:
The getRequestingURL() method returns the complete URL for which authentication has been requested—an important detail if a site uses different names and passwords for different files.
The password is a char array so that the password can be erased when it’s no longer needed.
A String would have to wait to be garbage collected before it could be erased, and even then it might still exist somewhere in memory on the local system, possibly even on disk if the block of memory that contained it had been swapped out to virtual memory at one point.
The JPasswordField Class One useful tool for asking users for their passwords in a more or less secure fashion is the JPasswordField component from Swing:
This lightweight component behaves almost exactly like a text field.
However, anything the user types into it is echoed as an asterisk.
This way, the password is safe from anyone looking over the user’s shoulder at what’s being typed on the screen.
JPasswordField also stores the passwords as a char array so that when you’re done with the password you can overwrite it with zeros.
Otherwise, you mostly use the methods it inherits from the JTextField superclass.
Example 5-11 demonstrates a Swing-based Authenticator subclass that brings up a dialog to ask the user for his username and password.
A JPasswordField collects the password and a simple JTextField retrieves the username.
Flip back to Figure 5-2 to see the rather simple dialog box this produces.
The Hypertext Transfer Protocol (HTTP) is a standard that defines how a web client talks to a server and how data is transferred from the server back to the client.
Although HTTP is usually thought of as a means of transferring HTML files and the pictures embedded in them, HTTP is data format agnostic.
It can be used to transfer TIFF pictures, Microsoft Word documents, Windows .exe files, or anything else that can be represented in bytes.
To write programs that use HTTP, you’ll need to understand HTTP at a deeper level than the average web page designer.
This chapter goes behind the scenes to show you what actually happens when you type http://www.google.com into the browser’s address bar and press Return.
The Protocol HTTP is the standard protocol for communication between web browsers and web servers.
For each request from client to server, there is a sequence of four steps:
The client opens a TCP connection to the server on port 80, by default; other ports may be specified in the URL.
The client sends a message to the server requesting the resource at a specified path.
The request includes a header, and optionally (depending on the nature of the request) a blank line followed by data for the request.
The response begins with a response code, followed by a header full of metadata, a blank line, and the requested document or an error message.
In HTTP 1.1 and later, multiple requests and responses can be sent in series over a single TCP connection.
Furthermore, in HTTP 1.1, requests and responses can be sent in multiple chunks.
Each request and response has the same basic form: a header line, an HTTP header containing metadata, a blank line, and then a message body.
The first line is called the request line, and includes a method, a path to a resource, and the version of HTTP.
The GET method asks the server to return a representation of a resource.
HTTP/1.1 is the version of the protocol that the client understands.
Although the request line is all that is required, a client request usually includes other information as well in a header.
If a value is too long, you can add a space or tab to the beginning of the next line and continue it.
Lines in the header are terminated by a carriage-return linefeed pair.
The first keyword in this example is User-Agent, which lets the server know what browser is being used and allows it to send files optimized for the particular browser type.
The following line says that the request comes from version 2.4 of the Lynx browser:
All but the oldest first-generation browsers also include a Host field specifying the server’s name, which allows web servers to distinguish between different named hosts served from the same IP address:
The last keyword in this example is Accept, which tells the server the types of data the client can handle (though servers often ignore this)
For example, the following line says that the client can handle four MIME media types, corresponding to HTML documents, plain text, and JPEG and GIF images:
The type shows very generally what kind of data is contained: is it a picture, text, or movie? The subtype identifies the specific type of data: GIF image, JPEG image, TIFF image.
For example, HTML’s content type is text/html; the type is text, and the subtype is html.
The content type for a JPEG image is image/jpeg; the type is image, and the subtype is jpeg.
In addition, nonstandard custom types and subtypes can be freely defined as long as they begin with x-
Finally, the request is terminated with a blank line—that is, two carriage return/linefeed pairs, \r\n\r\n.
Once the server sees that blank line, it begins sending its response to the client over the same connection.
The response begins with a status line, followed by a header describing the response using the same “name: value” syntax as the request header, a blank line, and the requested resource.
The first line indicates the protocol the server is using (HTTP/1.1), followed by a response code.
The other header lines identify the date the request was made in the server’s time frame, the server software (Apache), a promise that the server will close the connection when it’s finished sending, the MIME media type, and the length of the document delivered (not counting this header)—in this case, 107 bytes.
Table 6-1 lists the standard and experimental response codes you’re most likely to encounter, minus a few used by WebDAV.
Continue The server is prepared to accept the request body and the client should send it; allows clients to ask whether the server will accept a request before they send a large amount of data as part of the request.
POST, the requested data is contained in the response along with the usual headers.
If the request method was HEAD, only the header information is included.
Created The server has created a resource at the URL specified in the body of the response.
This code is only sent in response to POST requests.
Accepted This rather uncommon response indicates that a request (generally from POST) is being processed, but the processing is not yet complete, so no response can be returned.
However, the server should return an HTML page that explains the situation to the user and provide an estimate of when the request is likely to be completed, and, ideally, a link to a status monitor of some kind.
The resource representation was returned from a caching proxy or other local source and is not guaranteed to be up to date.
No Content The server has successfully processed the request but has no information to send back to the client.
This is normally the result of a poorly written form-processing program on the server that accepts data but does not return a response to the user.
Reset Content The server has successfully processed the request but has no information to send back to the client.
Furthermore, the client should clear the form to which the request is sent.
Partial Content The server has returned the part of the resource the client requested using the byte range extension to HTTP, rather than the whole document.
Multiple Choices The server is providing a list of different representations (e.g., PostScript and PDF) for the requested document.
The client should automatically load the resource at this URL and update any bookmarks that point to the old URL.
The resource is at a new URL temporarily, but its location will change again in the foreseeable future; therefore, bookmarks should not be updated.
Sometimes used by proxies that require the user to log in locally before accessing the Web.
See Other Generally used in response to a POST form request, this code indicates that the user should retrieve a resource from a different URL using GET.
Not Modified The If-Modified-Since header indicates that the client wants the document only if it has been recently updated.
This status code is returned if the document has not been updated.
In this case, the client should load the document from its cache.
Use Proxy The Location header field contains the address of a proxy that will serve the response.
Similar to 302 but without allowing the HTTP method to change.
Similar to 301 but without allowing the HTTP method to change.
Bad Request The client request to the server used improper syntax.
This is rather unusual in normal web browsing but more common when debugging custom clients.
Unauthorized Authorization, generally a username and password, is required to access this page.
Either a username and password have not yet been presented or the username and password are invalid.
Payment Required Not used today, but may be used in the future to indicate that some sort of payment is required to access the resource.
Forbidden The server understood the request, but is deliberately refusing to process it.
This is sometimes used when a client has exceeded its quota.
Not Found This most common error response indicates that the server cannot find the requested resource.
It may indicate a bad link, a document that has moved with no forwarding address, a mistyped URL, or something similar.
The request method is not allowed for the specified resource; for instance, you tried to PUT a file on a web server that doesn’t support PUT or tried to POST to a URI that only allows GET.
Not Acceptable The requested resource cannot be provided in a format the client is willing to accept, as indicated by the Accept field of the request HTTP header.
An intermediate proxy server requires authentication from the client, probably in the form of a username and password, before it will retrieve the requested resource.
Request Timeout The client took too long to send the request, perhaps because of network congestion.
Conflict A temporary conflict prevents the request from being fulfilled; for instance, two clients are trying to PUT the same file at the same time.
Gone Like a 404, but makes a stronger assertion about the existence of the resource.
The resource has been deliberately deleted (not moved) and will not be restored.
Length Required The client must but did not send a Content-length field in the client request HTTP header.
A condition for the request that the client specified in the request HTTP header is not satisfied.
The body of the client request is larger than the server is able to process at this time.
The server does not understand or accept the MIME content type of the request body.
The server cannot send the byte range the client requested.
Expectation Failed The server cannot meet the client’s expectation given in an Expectrequest header field.
The content type of the request body is recognized, and the body is syntactically correct, but nonetheless the server can’t process it.
Either the header as a whole is too large, or one particular header field is too large.
Experimental; the server is prohibited by law from servicing the request.
An unexpected condition occurred that the server does not know how to handle.
Not Implemented The server does not have a feature that is needed to fulfill this request.
A server that cannot handle PUT requests might send this response to a client that tried to PUT form data to it.
Bad Gateway This code is applicable only to servers that act as proxies or gateways.
It indicates that the proxy received an invalid response from a server it was connecting to in an effort to fulfill the request.
The server is temporarily unable to handle the request, perhaps due to overloading or maintenance.
Gateway Timeout The proxy server did not receive a response from the upstream server within a reasonable amount of time, so it can’t send the desired response to the client.
The server does not support the version of HTTP the client is using (e.g., the as-yet-nonexistent HTTP 2.0)
Server does not have enough space to store the supplied request entity; typically used for POST or PUT.
The client needs to authenticate to gain network access (e.g., on a hotel wireless network)
Keep-Alive HTTP 1.0 opens a new connection for each request.
In practice, the time taken to open and close all the connections in a typical web session can outweigh the time taken to transmit the data, especially for sessions with many small documents.
In HTTP 1.1 and later, the server doesn’t have to close the socket after it sends its response.
It can leave it open and wait for a new request from the client on the same socket.
Multiple requests and responses can be sent in series over a single TCP connection.
However, the lockstep pattern of a client request followed by a server response remains the same.
A client indicates that it’s willing to reuse a socket by including a Connection field in the HTTP request header with the value Keep-Alive:
The URL class transparently supports HTTP Keep-Alive unless explicitly turned off.
That is, it will reuse a socket if you connect to the same server again before the server has closed the connection.
You can control Java’s use of HTTP Keep-Alive with several system properties:
Set http.keepAlive to “true or false” to enable/disable HTTP Keep-Alive.
However, these optimizations are usually performed in a translation layer that shields application programmers from the details, so the code you write will still mostly follow the preceding steps 1–4
Java does not yet support HTTP 2.0; but when the capability is added, your programs shouldn’t need to change to take advantage of it, as long as you access HTTP servers via the URL and URLConnection classes.
A start line containing the HTTP method and a path to the resource on which the method should be executed.
A header of name-value fields that provide meta-information such as authentication credentials and preferred formats to be used in the request.
A request body containing a representation of a resource (POST and PUT only)
There are four main HTTP methods, four verbs if you will, that identify the operations that can be performed:
If that seems like too few, especially compared to the infinite number of object-oriented methods you may be accustomed to designing programs around, that’s because HTTP puts most of the emphasis on the nouns: the resources identified by URIs.
The uniform interface provided by these four methods is sufficient for nearly all practical purposes.
Furthermore, its output is often cached, though that can be controlled with the right headers, as you’ll see shortly.
In a properly architected system, GET requests can be bookmarked and prefetched without concern.
By contrast, a well-behaved browser or web spider will not POST to a link without explicit user action.
The PUT method uploads a representation of a resource to the server at a known URL.
That is, it can be repeated without concern if it fails.
Putting the same document in the same place on the same server twice in a row leaves the server in the same state as only putting it once.
The DELETE method removes a resource from a specified URL.
If you aren’t sure whether a delete request succeeded—for instance, because the socket disconnected after you sent the request but before you received a response—just send the request again.
It too uploads a representation of a resource to a server at a known URL, but it does not specify what the server is to do with the newly supplied resource.
For instance, the server does not necessarily have to make that resource available at the target URL, but may instead move it to a different URL.
Or the server might use the data to update the state of one or more completely different resources.
Because GET requests include all necessary information in the URL, they can be bookmarked, linked to, spidered, and so forth.
The other methods, especially POST, are intended for actions that commit to something.
For example, adding an item to a shopping cart should send a GET, because this action doesn’t commit; the user can still abandon the cart.
However, placing the order should send a POST because that action makes a commitment.
This is why browsers ask you if you’re sure when you go back to a page that uses POST (as shown in Figure 6-1)
Reposting data may buy two copies of a book and charge your credit card twice.
In practice, POST is vastly overused on the Web today.
Any safe operation that does not commit the user to anything should use GET rather than POST.
One sometimes mistaken reason for preferring POST over GET is when forms require large amounts of input.
There’s an outdated misconception that browsers can only work with query strings of a few hundred bytes.
If you have more form data to submit than that, you may indeed need to support POST; but safe operations should still prefer GET for nonbrowser clients.
You usually only exceed those limits if you’re uploading data to the server to create a new resource, rather than merely locating an existing resource on the server; and in these cases POST or PUT is usually the right answer anyway.
In addition to these four main HTTP methods, a few others are used in special circumstances.
The most common such method is HEAD, which acts like a GET except it only returns the header for the resource, not the actual data.
This is commonly used to check the modification date of a file, to see whether a copy stored in the local cache is still valid.
The other two that Java supports are OPTIONS, which lets the client ask the server what it can do with a specified resource; and TRACE, which echoes back the client request for debugging purposes, especially when proxy servers are misbehaving.
Different servers recognize other nonstandard methods including COPY and MOVE, but Java does not send these.
The URL class described in the previous chapter uses GET to communicate with HTTP servers.
The URLConnection class (coming up in the Chapter 7) can use all four of these methods.
The Request Body The GET method retrieves a representation of a resource identified by a URL.
The exact location of the resource you want to GET from a server is specified by the various parts of the path and query string.
How different paths and query strings map to different resources is determined by the server.
As long as it knows the URL, it can download from it.
In these cases, the client supplies the representation of the resource, in addition to the path and the query string.
The representation of the resource is sent in the body of the request, after the header.
For example, this POST request sends form data to a server:
However, the HTTP header should include two fields that specify the nature of the body:
A Content-length field that specifies how many bytes are in the body (54 in the preceding example)
Thus it’s used by a lot of server-side programs that talk to browsers.
However, it’s hardly the only possible type you can send in the body.
For example, a camera uploading a picture to a photo sharing site can send image/jpeg.
For example, here’s a PUT request that uploads an Atom document:
Cookies Many websites use small strings of text known as cookies to store persistent client-side state between connections.
Cookies are passed from server to client and back again in the HTTP headers of requests and responses.
Cookies can be used by a server to indicate session IDs, shopping cart contents, login credentials, user preferences, and more.
However, more likely, the value is a meaningless string such as ATVPDKIKX0DER, which identifies a particular record in a database of some kind where the real information is kept.
Usually the cookie values do not contain the data but merely point to it on the server.
Cookies are limited to nonwhitespace ASCII text, and may not contain commas or semicolons.
To set a cookie in a browser, the server includes a Set-Cookie header line in the HTTP header.
For example, this HTTP header sets the cookie “cart” to the value “ATVPDKIKX0DER”:
If a browser makes a second request to the same server, it will send the cookie back in a Cookie line in the HTTP request header like so:
As long as the server doesn’t reuse cookies, this enables it to track individual users and sessions across multiple, otherwise stateless, HTTP connections.
For example, a request I just made to Amazon fed my browser five cookies:
In addition to a simple name=value pair, cookies can have several attributes that control their scope including expiration date, path, domain, port, version, and security options.
For example, by default, a cookie applies to the server it came from.
However, a site can also indicate that a cookie applies within an.
However, a server can only set cookies for domains it immediately belongs to.
Websites work around this restriction by embedding an image or other content hosted on one domain in a page hosted at a second domain.
The cookies set by the embedded content, not the page itself, are called third-party cookies.
Many users block all third-party cookies, and some web browsers are starting to block them by default for privacy reasons.
Cookies are also scoped by path, so they’re returned for some directories on the server, but not all.
The default scope is the original URL and any subdirectories.
For instance, if a cookie is set for the URL http://www.cafeconleche.org/XOM/, the cookie also applies in http://www.cafeconleche.org/XOM/apidocs/, but not in http://www.cafeconleche.org/ slides/ or http://www.cafeconleche.org/
However, the default scope can be changed using a Path attribute in the cookie.
For example, this next response sends the browser a cookie with the name “user” and the value “elharo” that applies only within the server’s /restricted subtree, not on the rest of the site:
When requesting a document in the subtree /restricted from the same server, the client echoes that cookie back.
However, it does not use the cookie in other directories on the site.
A cookie can include both a domain and a path.
For instance, this cookie applies in the /restricted path on any servers within the example.com domain:
The order of the different cookie attributes doesn’t matter, as long as they’re all separated by semicolons and the cookie’s own name and value come first.
However, this isn’t true when the client is sending the cookie back to the server.
In this case, the path must precede the domain, like so:
A cookie can be set to expire at a certain point in time by setting the expires attribute to a date in the form Wdy, DD-Mon-YYYY HH:MM:SS GMT.
The rest are numeric, padded with initial zeros if necessary.
The browser should remove this cookie from its cache after that date has passed.
The Max-Age attribute that sets the cookie to expire after a certain number of seconds have passed instead of at a specific moment.
For instance, this cookie expires one hour (3,600 seconds) after it’s first set:
The browser should delete this cookie after this amount of time has elapsed.
Because cookies can contain sensitive information such as passwords and session keys, some cookie transactions should be secure.
Most of the time this means using HTTPS instead of HTTP; but whatever it means, each cookie can have a secure attribute with no value, like so:
Browsers are supposed to refuse to send such cookies over insecure channels.
For additional security against cookie-stealing attacks like XSRF, cookies can set the HttpOnly attribute.
This tells the browser to only return the cookie via HTTP and HTTPS and specifically not by JavaScript:
Amazon wants my browser to send these cookie with the request for any page in the amazon.com domain, for the next 30–33 years.
Of course, browsers are free to ignore all these requests, and users can delete or block cookies at any time.
However, it does not include an implementation of that abstract class, so it requires a lot of grunt work.
Before Java will store and return cookies, you need to enable it:
If all you want is to receive cookies from sites and send them back to those sites, you’re done.
After installing a CookieManager with those two lines of code, Java will store any cookies sent by HTTP servers you connect to with the URL class, and will send the stored cookies back to those same servers in subsequent requests.
However, you may wish to be a bit more careful about whose cookies you accept.
For example, this code fragment tells Java to block third-party cookies but accept firstparty cookies:
That is, it will only accept cookies for the server that you’re talking to, not for any server on the Internet.
If you want more fine-grained control, for instance to allow cookies from some known domains but not others, you can implement the CookiePolicy interface yourself and override the shouldAccept() method:
Example 6-1 shows a simple CookiePolicy that blocks cookies from .gov domains, but allows others.
A cookie policy that blocks all .gov cookies but allows others import java.net.*;
CookieStore It is sometimes necessary to put and get cookies locally.
For instance, when an application quits, it can save the cookie store to disk and load those cookies again when it next starts up.
You can retrieve the store in which the CookieManager saves its cookies with the getCookieStore() method:
The CookieStore class allows you to add, remove, and list cookies so you can control the cookies that are sent outside the normal flow of HTTP requests and responses:
Each cookie in the store is encapsulated in an HttpCookie object that provides methods for inspecting the attributes of the cookie summarized in Example 6-2
Several of these attributes are not actually used any more.
In particular comment, comment URL, discard, and version are only used by the now obsolete Cookie 2 specification that never caught on.
URLConnection is an abstract class that represents an active connection to a resource specified by a URL.
First, it provides more control over the interaction with a server (especially an HTTP server) than the URL class.
A URLConnection can inspect the header sent by the server and respond accordingly.
It can set the header fields used in the client request.
Finally, a URLConnection can send data back to a web server with POST, PUT, and other HTTP request methods.
We will explore all of these techniques in this chapter.
Second, the URLConnection class is part of Java’s protocol handler mechanism, which also includes the URLStreamHandler class.
The idea behind protocol handlers is simple: they separate the details of processing a protocol from processing particular data types, providing user interfaces, and doing the other work that a monolithic web browser performs.
For example, if the browser runs across a URL with a strange scheme, such as compress, rather than throwing up its hands and issuing an error message, it can download a protocol handler for this unknown protocol and use it to communicate with the server.
Only abstract URLConnection classes are present in the java.net package.
The concrete subclasses are hidden inside the sun.net package hierarchy.
Many of the methods and fields as well as the single constructor in the URLConnection class are protected.
In other words, they can only be accessed by instances of the URLConnection class or its subclasses.
It is rare to instantiate URLConnection objects directly in your source code; instead, the runtime environment creates these objects as needed, depending on the protocol in use.
URLConnection does not have the best-designed API in the Java class library.
One of several problems is that the URLConnection class is too closely tied to the HTTP protocol.
For instance, it assumes that each file transferred is preceded by a MIME header or something very much like one.
However, most classic protocols such as FTP and SMTP don’t use MIME headers.
Opening URLConnections A program that uses the URLConnection class directly follows this basic sequence of steps:
Consequently, unless you’re subclassing URLConnection to handle a new kind of URL (i.e., writing a protocol handler), you create one of these objects by invoking the open Connection() method of the URL class.
You may find it convenient or necessary to override other methods in the class; but the single method that subclasses must implement is connect(), which makes a connection to a server and thus depends on the type of service (HTTP, FTP, and so on)
When a URLConnection is first constructed, it is unconnected; that is, the local and remote host cannot send and receive data.
However, getInputStream(), getContent(), getHeader Field(), and other methods that require an open connection will call connect() if the connection isn’t yet open.
Reading Data from a Server The following is the minimal set of steps needed to retrieve data from a URL using a URLConnection object:
Read from the input stream using the usual stream API.
The getInputStream() method returns a generic InputStream that lets you read and parse the data that the server sends.
Example 7-1 uses the getInputStream() method to download a web page.
It is no accident that this program is almost the same as Example 5-2
The open Stream() method of the URL class just returns an InputStream from its own URLCon nection object.
The output is identical as well, so I won’t repeat it here.
The differences between URL and URLConnection aren’t apparent with just a simple input stream as in this example.
URLConnection can configure the request parameters sent to the server.
URLConnection can write data to the server as well as read data from the server.
Reading the Header HTTP servers provide a substantial amount of information in the header that precedes each response.
For example, here’s a typical HTTP header returned by an Apache web server:
In general, an HTTP header may include the content type of the requested document, the length of the document in bytes, the character set in which the content is encoded, the date and time, the date the content expires, and the date the content was last modified.
However, the information depends on the server; some servers send all this information for each request, others send some information, and a few don’t send anything.
The methods of this section allow you to query a URL Connection to find out what metadata the server has provided.
Aside from HTTP, very few protocols use MIME headers (and technically speaking, even the HTTP header isn’t actually a MIME header; it just looks a lot like one)
When writing your own subclass of URLConnection, it is often necessary to override these methods so that they return sensible values.
The most important piece of information you may be lacking is the content type.
URLConnection provides some utility methods that guess the data’s content type based on its filename or the first few bytes of the data itself.
Retrieving Specific Header Fields The first six methods request specific, particularly common fields from the header.
The getContentType() method returns the MIME media type of the response body.
It relies on the web server to send a valid content type.
It throws no exceptions and returns null if the content type isn’t available.
Other commonly used types include text/plain, image/gif, application/xml, and image/jpeg.
If the content type is some form of text, this header may also contain a character set part identifying the document’s character encoding.
In this case, getContentType() returns the full value of the Content-type field, including the character encoding.
If a nontext type is encountered, an exception is thrown.
The getContentLength() method tells you how many bytes there are in the content.
It is used when you need to know exactly how many bytes to read or when you need to create a buffer large enough to hold the data in advance.
As networks get faster and files get bigger, it is actually possible to find resources whose size exceeds the maximum int value (about 2.1 billion bytes)
Chapter 5 showed how to use the openStream() method of the URL class to download text files from an HTTP server.
Although in theory you should be able to use the same method to download a binary file, such as a GIF image or a .class byte code file, in practice this procedure presents a problem.
To download a binary file, it is more reliable to use a URLConnection’s getConten tLength() method to find the file’s length, then read exactly the number of bytes indicated.
Example 7-3 is a program that uses this technique to save a binary file on a disk.
As usual, the main() method loops over the URLs entered on the command line, passing each URL to the saveBinaryFile() method.
It puts the type into the variable contentType and the content length into the variable contentLength.
Next, an if statement checks whether the content type is text or the Content-length field is missing or invalid (contentLength == -1)
If either of these is true, an IOException is thrown.
If these checks are both false, you have a binary file of known length: that’s what you want.
Now that you have a genuine binary file on your hands, you prepare to read it into an array of bytes called data.
Ideally, you would like to fill data with a single call to read() but you probably won’t get all the bytes at once, so the read is placed in a loop.
The number of bytes read up to this point is accumulated into the offset variable, which also keeps track of the location in the data array at which to start placing the data retrieved by the next call to read()
The loop continues until offset equals or exceeds contentLength; that is, the array has been filled with the expected number of bytes.
You also break out of the while loop if read() returns –1, indicating an unexpected end of stream.
The offset variable now contains the total number of bytes read, which should be equal to the content length.
If they are not equal, an error has occurred, so saveBi naryFile() throws an IOException.
This is the general procedure for reading binary files from HTTP connections.
Now you’re ready to save the data in a file.
If the content is sent unencoded (as is commonly the case with HTTP servers), this method returns null.
The content encoding is not the same as the character encoding.
The character encoding is determined by the Content-type header or information internal to the document, and specifies how characters are encoded in bytes.
Content encoding specifies how the bytes are encoded in other bytes.
This is the time the document was sent as seen from the server; it may not agree with the time on your local machine.
The final date method, getLastModified(), returns the date on which the document was last modified.
Example 7-4 reads URLs from the command line and uses these six methods to print their content type, content length, content encoding, date of last modification, expiration date, and current date.
The content type of the file at http://www.oreilly.com is text/html.
It was last modified on the same day at 5:04 P.M.
Many servers don’t bother to provide a Contentlength header for text files.
However, a Content-length header should always be sent for a binary file.
Now the server sends a Content-length header with a value of 2294:
Retrieving Arbitrary Header Fields The last six methods requested specific fields from the header, but there’s no theoretical limit to the number of header fields a message can contain.
The next five methods inspect arbitrary fields in a header.
Indeed, the methods of the preceding section are just thin wrappers over the methods discussed here; you can use these methods to get header fields that Java’s designers did not plan for.
The getHeaderField() method returns the value of a named header field.
The name of the header is not case sensitive and does not include a closing colon.
For example, to get the value of the Content-type and Content-encoding header fields of a URLConnec tion object uc, you could write:
To get the Date, Content-length, or Expires headers, you’d do the same:
If you’re interested in a numeric value, convert the String to a long or an int.
Do not assume the value returned by getHeaderField() is valid.
This method returns the key (i.e., the field name) of the nth header field (e.g., Contentlength or Server)
The request method is header zero and has a null key.
For example, in order to get the sixth key of the header of the URLConnec tion uc, you would write:
Besides the headers with named getter methods, this server also provides Server, AcceptRanges, Cache-control, Vary, Keep-Alive, and Connection headers.
The parseDate() method does a decent job of understanding and converting most common date formats, but it can be stumped—for instance, if you ask for a header field that contains something other than a date.
You can use the methods of the java.util.Date class to convert the long to a String.
This method retrieves the value of the header field name and tries to convert it to an int.
This method is often used to retrieve the Content-length field.
For example, to get the content length from a URLConnection uc, you would write:
Caches Web browsers have been caching pages and images for years.
Several HTTP headers, including Expires and Cache-control, can control caching.
By default, the assumption is that a page accessed with GET over HTTP can and should be cached.
A page accessed with HTTPS or POST usually shouldn’t be.
An Expires header (primarily for HTTP 1.0) indicates that it’s OK to cache this representation until the specified time.
The Cache-control header (HTTP 1.1) offers fine-grained cache policies: — max-age=[seconds]: Number of seconds from now before the cached entry.
A server can send multiple Cache-control headers in a single header as long as they don’t conflict.
The Last-modified header is the date when the resource was last changed.
A client can use a HEAD request to check this and only come back for a full GET if its local cached copy is older than the Last-modified date.
The ETag header (HTTP 1.1) is a unique identifier for the resource that changes when the resource does.
A client can use a HEAD request to check this and only come back for a full GET if its local cached copy has a different ETag.
It also says it was last modified on April 20 and has an ETag, so if the local cache already has a copy more recent than that, there’s no need to load the whole document now:
Example 7-6 is a simple Java class for parsing and querying Cache-control headers.
If a representation of the resource is available in the local cache, and its expiry date has not arrived, just use it.
If a representation of the resource is available in the local cache, but the expiry date has arrived, check the server with HEAD to see if the resource has changed before performing a full GET.
To install a system-wide cache of the URL class will use, you need the following:
A Java virtual machine can only support a single shared cache.
Once a cache is installed whenever the system tries to load a new URL, it will first look for it in the cache.
If the cache returns the desired content, the URLConnection won’t need to connect to the remote server.
However, if the requested data is not in the cache, the protocol handler will download it.
After it’s done so, it will put its response into the cache so the content is more quickly available the next time that URL is loaded.
Two abstract methods in the ResponseCache class store and retrieve data from the system’s single cache:
The put() method returns a CacheRequest object that wraps an OutputStream into which the URL will write cacheable data it reads.
CacheRequest is an abstract class with two methods, as shown in Example 7-7
The getOutputStream() method in the subclass should return an OutputStream that points into the cache’s data store for the URI passed to the put() method at the same time.
For instance, if you’re storing the data in a file, you’d return a FileOutput Stream connected to that file.
The protocol handler will copy the data it reads onto this OutputStream.
This method should then remove any data from the cache that has been stored for this request.
Later, the data can be retrieved using the getData() method, a custom method in this subclass just retrieving the data Java wrote onto the Output Stream this class supplied.
An obvious alternative strategy would be to store results in files and use a FileOutputStream instead.
The get() method in ResponseCache retrieves the data and headers from the cache and returns them wrapped in a CacheResponse object.
It returns null if the desired URI is not in the cache, in which case the protocol handler loads the URI from the remote server as normal.
Again, this is an abstract class that you have to implement in a subclass.
It has two methods: one to return the data of the request and one to return the headers.
When caching the original response, you need to store both.
The headers should be returned in an unmodifiable map with keys that are the HTTP header field names and values that are lists of values for each named HTTP header.
Example 7-10 shows a simple CacheResponse subclass that is tied to a SimpleCacheRe quest and a CacheControl.
In this example, shared references pass data from the request class to the response class.
If you were storing responses in files, you’d just need to share the filenames instead.
Along with the SimpleCacheRequest object from which it will read the data, you must also pass the original URLConnection object into the constructor.
This is used to read the HTTP header so it can be stored for later retrieval.
The object also keeps track of the expiration date and cache-control (if any) provided by the server for the cached representation of the resource.
Finally, you need a simple ResponseCache subclass that stores and retrieves the cached values as requested while paying attention to the original Cache-control header.
Example 7-11 demonstrates such a simple class that stores a finite number of responses in memory in one big thread-safe HashMap.
This class is suitable for a single-user, private cache (because it ignores the private and public attributes of Cache-control)
These set the single cache used by all programs running within the same Java virtual machine.
For example, this one line of code installs Example 7-11 in an application:
Once a ResponseCache like Example 7-11 is installed, HTTP URLConnections always use it.
Each retrieved resource stays in the HashMap until it expires.
This example waits for an expired document to be requested again before it deletes it from the cache.
A more sophisticated implementation could use a low-priority thread to scan for expired documents and remove them to make way for others.
Instead of or in addition to this, an implementation might cache the representations in a queue and remove the oldest documents or those closest to their expiration date as necessary to make room for new ones.
An even more sophisticated implementation could track how often each document in the store was accessed and expunge only the oldest and least-used documents.
I’ve already mentioned that you could implement a cache on top of the filesystem instead of on top of the Java Collections API.
You could also store the cache in a database, and you could do a lot of less-common things as well.
For instance, you could redirect requests for certain URLs to a local server rather than a remote server halfway around the world, in essence using a local web server as the cache.
This might be useful for a server that processes many different SOAP requests, all of which adhere to a few common schemas that can be stored in the cache.
The abstract ResponseCache class is flexible enough to support all of these and other usage patterns.
Configuring the Connection The URLConnection class has seven protected instance fields that define exactly how the client makes the request to the server.
For instance, if doOutput is true, you’ll be able to write data to the server over this URLConnection as well as read data from it.
If useCaches is false, the connection bypasses any local caching and downloads the file from the server afresh.
Because these fields are all protected, their values are accessed and modified via obviously named setter and getter methods:
You can modify these fields only before the URLConnection is connected (before you try to read content or headers from the connection)
In general, you can set the properties of a URLConnection object only before the connection is opened.
There are also some getter and setter methods that define the default behavior for all instances of URLConnection.
Unlike the instance methods, these methods can be invoked at any time.
The new defaults will apply only to URLConnection objects constructed after the new default values are set.
The constructor sets it when the URLConnection is created and it should not change thereafter.
You can retrieve the value by calling the getURL() method.
Example 7-12 opens a URLConnec tion to http://www.oreilly.com/, gets the URL of that connection, and prints it.
The URL that is printed is the one used to create the URLConnection.
Because the connection has not yet been opened when a new URLConnection object is created, its initial value is false.
There are no methods that directly read or change the value of connected.
However, any method that causes the URLConnection to connect should set this variable to true, including connect(), getInputStream(), and getOutputStream()
If you subclass URLConnection to write a protocol handler, you are responsible for setting connected to true when you are connected and resetting it to false when the connection closes.
If it’s set incorrectly, your program will have severe bugs that are not easy to diagnose.
For example, a web browser may need to ask for a username and password.
However, many applications cannot assume that a user is present to interact with it.
For instance, a search engine robot is probably running in the background without any user to provide a username and password.
The value true indicates that user interaction is allowed; false indicates that there is no user interaction.
The value may be read at any time but may be set only before the URLConnection is connected.
For example, this code fragment opens a connection that could ask the user for authentication if it’s required:
Java does not include a default GUI for asking the user for a username and password.
If the request is made from an applet, the browser’s usual authentication dialog can be relied on.
Figure 7-1 shows the dialog box that pops up when you try to access a passwordprotected page.
If you cancel this dialog, you’ll get a 401 Authorization Required error and whatever text the server sends to unauthorized users.
However, if you refuse to send authorization at all—which you can do by clicking OK, then answering No when asked.
The protected boolean field doInput is true if the URLConnection can be used for reading, false if it cannot be.
To access this protected variable, use the public getDoInput() and setDoInput() methods:
For example, a program that needs to send data to the server using the POST method could do so by getting an output stream from a URLConnection.
The protected boolean field doOutput is true if the URLConnection can be used for writing, false if it cannot be; it is false by default.
To access this protected variable, use the getDoOutput() and setDoOut put() methods:
When you set doOutput to true for an http URL, the request method is changed from GET to POST.
If the user asks for the same document again, it can be retrieved from the cache.
However, it may have changed on the server since it was last retrieved.
The only way to tell is to ask the server.
Clients can include an If-Modified-Since in the client request HTTP header.
If the document has changed since that time, the server should send it.
Typically, this time is the last time the client fetched the document.
If the document has changed since that time, the server will send it as usual.
Otherwise, it replies with a 304 Not Modified message, like this:
Some will send the document whether it’s changed or not.
It then downloads and displays the document—but only if it’s been modified in the last 24 hours.
Next, you see the new time, which you set to 24 hours prior to the current time:
Because this document hasn’t changed in the last 24 hours, it is not reprinted.
The useCaches variable determines whether a cache will be used if it’s available.
The default value is true, meaning that the cache will be used; false means the cache won’t be used.Because useCaches is protected, programs access it using the getUseCaches() and setUseCaches() methods:
This code fragment disables caching to ensure that the most recent version of the document is retrieved by setting useCaches to false:
Although nonstatic, these methods do set and get a static field that determines the default behavior for all instances of the URLConnection class created after the change.
Configuring the Client Request HTTP Header An HTTP client (e.g., a browser) sends the server a request line and a header.
A web server can use this information to serve different pages to different clients, to get and set cookies, to authenticate users through passwords, and more.
Placing different fields in the header that the client sends and the server responds with does all of this.
This is the HTTP header that the client sends to the server.
Each URLConnection sets a number of different name-value pairs in the header by default.
As you can see, it’s a little simpler than the one Chrome sends, and it has a different user agent and accepts different kinds of files.
However, you can modify these and add new fields before connecting.
This method can be used only before the connection is opened.
In this case, the separate values will be separated by commas.
These methods only really have meaning when the URL being connected to is an HTTP URL, because only the HTTP protocol makes use of headers like this.
Though they could possibly have other meanings in other protocols, such as NNTP, this is really just an example of poor API design.
These methods should be part of the more specific HttpURLConnection class, not the generic URLConnection class.
For instance, web servers and clients store some limited persistent information with cookies.
The server sends a cookie to a client using the response HTTP header.
From that point forward, whenever the client requests a URL from that server, it includes a Cookie field in the HTTP request header that looks like this:
This particular Cookie field sends three name-value pairs to the server.
There’s no limit to the number of name-value pairs that can be included in any one cookie.
Given a URLConnection object uc, you could add this cookie to the connection, like this:
You can set the same property to a new value, but this changes the existing property value.
For instance, the names can’t contain whitespace and the values can’t contain any line breaks.
Java enforces the restrictions on fields containing line breaks, but not much else.
Otherwise, it’s quite easy to make a URLConnection send malformed headers to the server, so be careful.
Some will ignore the bad header and return the requested document anyway, but some will reply with an HTTP 400, Bad Request error.
If, for some reason, you need to inspect the headers in a URLConnection, there’s a standard getter method:
Java also includes a method to get all the request properties for a connection as a Map:
Writing Data to a Server Sometimes you need to write data to a URLConnection, for example, when you submit a form to a web server using POST or upload a file using PUT.
The getOutputStream() method returns an OutputStream on which you can write data for transmission to a server:
A URLConnection doesn’t allow output by default, so you have to call setDoOut put(true) before asking for an output stream.
When you set doOutput to true for an http URL, the request method is changed from GET to POST.
In Chapter 5, you saw how to send data to server-side programs with GET.
However, GET should be limited to safe operations, such as search requests or page navigation, and not used for unsafe operations that create or modify a resource, such as posting a comment on a web page or ordering a pizza.
Safe operations can be bookmarked, cached, spidered, prefetched, and so on.
You may also chain it to a DataOutputStream, an OutputStream Writer, or some other class that’s more convenient to use than a raw OutputStream.
Sending data with POST is almost as easy as with GET.
Invoke setDoOutput(true) and use the URLConnection’s getOutputStream() method to write the query string rather than attaching it to the URL.
Java buffers all the data written onto the output stream until the stream is closed.
This enables it to calculate the value for the Content-length.
The complete transaction, including client request and server response, looks something like this:
For that matter, as long as you control both the client and the server, you can use any other sort of data encoding you like.
The post() method actually sends the data to the server by opening a URLConnection to the specified URL, setting its doOutput field to true, and writing the query string on the output stream.
It then returns the input stream containing the server’s response.
This resource is a simple form tester that accepts any input using either the POST or GET method and returns an HTML page showing the names and values that were submitted.
The data returned is HTML; this example simply displays the HTML rather than attempting to parse it.
It would be easy to extend this program by adding a user interface that lets you enter the name and email address to be posted—but because doing that triples the size of the program while showing nothing more of network programming, it is left as an exercise for the reader.
Once you understand this example, it should be easy to write Java programs that communicate with other server-side scripts.
The main() method tries to read the first command-line argument from args[0]
The argument is optional; if there is an argument, it is assumed to be a URL that can be POSTed to.
Next, the post() method is invoked and its response read and printed on System.out.
It first opens a connection to the URL stored in the url field.
It sets the doOutput field of this connection to true because this URL Connection needs to send output and chains the OutputStream for this URL to an ASCII OutputStreamWriter that sends the data, then flushes and closes the stream.
Do not forget to close the stream! If the stream isn’t closed, no data will be sent.
To summarize, posting data to a form requires these steps:
Decide what name-value pairs you’ll send to the server-side program.
Open a URLConnection to the URL of the program that will accept the data.
The getOutputStream() method is also used for the PUT request method, a means of storing files on a web server.
The data to be stored is written onto the OutputStream that getOutputStream() returns.
However, this can be done only from within the HttpURLConnection subclass of URLConnection, so discussion of PUT will have to wait a little while.
Security Considerations for URLConnections URLConnection objects are subject to all the usual security restrictions about making network connections, reading or writing files, and so forth.
For instance, a URLConnec tion can be created by an untrusted applet only if the URLConnection is pointing to the host that the applet came from.
However, the details can be a little tricky because different URL schemes and their corresponding connections can have different security implications.
For example, a jar URL that points into the applet’s own jar file should be fine.
However, a file URL that points to a local hard drive should not be.
Before attempting to connect a URL, you may want to know whether the connection will be allowed.
For this purpose, the URLConnection class has a getPermission() method:
It returns null if no permission is needed (e.g., there’s no security manager in place)
Guessing MIME Media Types If this were the best of all possible worlds, every protocol and every server would use standard MIME types to correctly specify the type of file being transferred.
Not only do we have to deal with older protocols such as FTP that predate MIME, but many HTTP servers that should use MIME don’t provide MIME headers at all or lie and provide headers that are incorrect (usually because the server has been misconfigured)
The URLConnection class provides two static methods to help programs figure out the MIME type of some data; you can use these if the content type just isn’t available or if you have reason to believe that the content type you’re given isn’t correct.
This method tries to guess the content type of an object based upon the extension in the filename portion of the object’s URL.
It returns its best guess about the content type as a String.
This guess is likely to be correct; people follow some fairly regular conventions when thinking up filenames.
On Unix, Java may also look at the mailcap file to help it guess.
For instance, it omits various XML applications such as RDF (.rdf), XSL (.xsl), and so on that should have the MIME type application/xml.
It also doesn’t provide a MIME type for CSS stylesheets (.css)
This method tries to guess the content type by looking at the first few bytes of data in the stream.
For this method to work, the InputStream must support marking so that you can return to the beginning of the stream after the first bytes have been read.
Java inspects the first 16 bytes of the InputStream, although sometimes fewer bytes are needed to make an identification.
For example, an XML document that begins with a comment rather than an XML declaration would be mislabeled as an HTML file.
This method should be used only as a last resort.
In particular, it contains methods to get and set the request method, decide.
It also includes several dozen mnemonic constants matching the various HTTP response codes.
Finally, it overrides the getPermission() method from the URLConnection superclass, although it doesn’t change the semantics of this method at all.
Because this class is abstract and its only constructor is protected, you can’t directly create instances of HttpURLConnection.
However, if you construct a URL object using an http URL and invoke its openConnection() method, the URLConnection object returned will be an instance of HttpURLConnection.
The Request Method When a web client contacts a web server, the first thing it sends is a request line.
Typically, this line begins with GET and is followed by the path of the resource that the client wants to retrieve and the version of the HTTP protocol that the client understands.
However, web clients can do more than simply GET files from web servers.
They can PUT a file on a web server or DELETE a file from a server.
And they can ask for just the HEAD of a document.
They can ask the web server for a list of the OPTIONS supported at a given URL.
All of these are accomplished by changing the request method from GET to a different keyword.
For example, here’s how a browser asks for just the header of a document using HEAD:
The method argument should be one of these seven case-sensitive strings:
However, it’s generally not enough to simply set the request method.
Depending on what you’re trying to do, you may need to adjust the HTTP header and provide a message body as well.
For instance, POSTing a form requires you to provide a Content-length header.
The HEAD function is possibly the simplest of all the request methods.
However, it tells the server only to return the HTTP header, not to actually send the file.
The most common use of this method is to check whether a file has been modified since the last time it was cached.
Example 7-15 is a simple program that uses the HEAD request method and prints the last time a file on a server was modified.
It wasn’t absolutely necessary to use the HEAD method here.
But if you used GET, the entire file at http://www.ibiblio.org/xml/ would have been sent across the network, whereas all you cared about was one line in the header.
When you can use HEAD, it’s much more efficient to do so.
The DELETE method removes a file at a specified URL from a web server.
Because this request is an obvious security risk, not all servers will be configured to support it, and those that are will generally demand some sort of authentication.
The server is free to refuse this request or ask for authorization.
Even if the server accepts this request, its response is implementation dependent.
Some servers may delete the file; others simply move it to a trash directory.
It allows clients to place documents in the abstract hierarchy of the site without necessarily knowing how the site maps to the actual local filesystem.
This contrasts with FTP, where the user has to know the actual directory structure as opposed to the server’s virtual directory structure.
Here’s a how an editor might PUT a file on a web server:
As with deleting files, some sort of authentication is usually required and the server must be specially configured to support PUT.
Most web servers do not support PUT out of the box.
The OPTIONS request method asks what options are supported for a particular URL.
If the request URL is an asterisk (*), the request applies to the server as a whole rather than to one particular URL on the server.
The server responds to an OPTIONS request by sending an HTTP header with a list of the commands allowed on that URL.
For example, when the previous command was sent, here’s what Apache responded with:
The list of legal commands is found in the Allow field.
However, in practice these are just the commands the server understands, not necessarily the ones it will actually perform on that URL.
The TRACE request method sends the HTTP header that the server received from the client.
The main reason for this information is to see what any proxy servers between the server and client might be changing.
The first five lines are the server’s normal response HTTP header.
The lines from TRACE /xml/ HTTP/1.1 on are the echo of the original client request.
However, if there were a proxy server between the client and server, it might not be.
Disconnecting from the Server HTTP 1.1 supports persistent connections that allow multiple requests and responses to be sent over a single TCP socket.
However, when Keep-Alive is used, the server won’t immediately close a connection simply because it has sent the last byte of data to the client.
Servers will time out and close the connection in as little as 5 seconds of inactivity.
However, it’s still preferred for the client to close the connection as soon as it knows it’s done.
The HttpURLConnection class transparently supports HTTP Keep-Alive unless you explicitly turn it off.
That is, it will reuse sockets if you connect to the same server again before the server has closed the connection.
Once you know you’re done talking to a particular host, the disconnect() method enables a client to break the connection:
If any streams are still open on this connection, disconnect() closes them.
Closing a stream on a persistent connection does not close the socket and disconnect.
Handling Server Responses The first line of an HTTP server’s response includes a numeric code and a message indicating what sort of response is made.
For instance, the most common response is 200 OK, indicating that the requested document was found.
Another response that you’re undoubtedly all too familiar with is 404 Not Found, indicating that the URL you requested no longer points to a document.
For instance, code 301 indicates that the resource has permanently moved to a new location and the browser should redirect itself to the new location and update any bookmarks that point to the old location.
Often all you need from the response message is the numeric response code.
HttpURL Connection also has a getResponseCode() method to return this as an int:
Although some numbers, notably 404, have become slang almost synonymous with their semantic meaning, most of them are less familiar.
Example 7-16 is a revised source viewer program that now includes the response message.
The only thing this program doesn’t read that the server sends is the version of HTTP the server is using.
In this example, you just fake it as “HTTP/1.x,” like this:
Error conditions On occasion, the server encounters an error but returns useful information in the message body nonetheless.
The getErrorStream() method returns an InputStream containing this page or null if no error was encountered or no data returned:
Generally, you’ll invoke getErrorStream() inside a catch block after getInput Stream() has failed.
Example 7-17 demonstrates with a program that reads form the input stream if possible.
However, if that fails for any reason, it then reads from the error stream instead.
Redirects The 300-level response codes all indicate some sort of redirect; that is, the requested resource is no longer available at the expected location but it may be found at some other location.
When encountering such a response, most browsers automatically load the document from its new location.
However, this can be a security risk, because it has the potential to move the user from a trusted site to an untrusted one, perhaps without the user even noticing.
However, the HttpURLConnec tion class has two static methods that let you decide whether to follow redirects:
With an argument of false, it prevents them from following redirects.
Because these are static methods, they change the behavior of all HttpURLConnection objects constructed after the method is invoked.
Proxies Many users behind firewalls or using AOL or other high-volume ISPs access the Web through proxy servers.
The usingProxy() method tells you whether the particular HttpURLConnection is going through a proxy server:
It returns true if a proxy is being used, false if not.
In some contexts, the use of a proxy server may have security implications.
Streaming Mode Every request sent to an HTTP server has an HTTP header.
One field in this header is the Content-length (i.e., the number of bytes in the body of the request)
However, to write the header you need to know the length of the body, which you may not have yet.
Normally, the way Java solves this catch-22 is by caching everything you write onto the OutputStream retrieved from the HttpURLCon nection until the stream is closed.
At that point, it knows how many bytes are in the body so it has enough information to write the Content-length header.
This scheme is fine for small requests sent in response to typical web forms.
However, it’s burdensome for responses to very long forms or some SOAP messages.
It’s very wasteful and slow for medium or large documents sent with HTTP PUT.
It’s much more efficient if Java doesn’t have to wait for the last byte of data to be written before sending the first byte of data over the network.
If you know the size of your data—for instance, you’re uploading a file of known size using HTTP PUT—you can tell the HttpURLConnection object the size of that data.
If you don’t know the size of the data in advance, you can use chunked transfer encoding instead.
In chunked transfer encoding, the body of the request is sent in multiple pieces, each with its own separate content length.
Java will then use a slightly different form of HTTP than the examples in this book.
As long as you’re using the URLConnection class instead of raw sockets and as long as the server supports chunked transfer encoding, it should all just work without any further changes to your code.
However, chunked transfer encoding does get in the way of authentication and redirection.
If you’re trying to send chunked files to a redirected URL or one that requires password authentication, an HttpRetryException will be thrown.
You’ll then need to retry the request at the new URL or at the old URL with the appropriate credentials; and this all needs to be done manually without the full support of the HTTP protocol handler you normally have.
Therefore, don’t use chunked transfer encoding unless you really need it.
As with most performance advice, this means you shouldn’t implement this optimization until measurements prove the nonstreaming default is a bottleneck.
If you do happen to know the size of the request data in advance, you can optimize the connection by providing this information to the HttpURLConnection object.
If you do this, Java can start streaming the data over the network immediately.
Otherwise, it has to cache everything you write in order to determine the content length, and only send it over the network after you’ve closed the stream.
Because this number can actually be larger than the maximum size of an int, in Java 7 and later you can use a long instead.
Java will use this number in the Content-length HTTP header field.
However, if you then try to write more or less than the number of bytes given here, Java will throw an IOException.
Of course, that happens later, when you’re writing data, not when you first call this method.
You can’t use both chunked transfer encoding and fixed-length streaming mode on the same request.
Servers neither know nor care how the Content-length was set, as long as it’s correct.
However, like chunked transfer encoding, streaming mode does interfere with authentication and redirection.
If either of these is required for a given URL, an HttpRetryException will be thrown; you have to manually retry.
Therefore, don’t use this mode unless you really need it.
Data is transmitted across the Internet in packets of finite size called datagrams.
The header contains the address and port to which the packet is going, the address and port from which the packet came, a checksum to detect data corruption, and various other housekeeping information used to ensure reliable transmission.
However, because datagrams have a finite length, it’s often necessary to split the data across multiple packets and reassemble it at the destination.
It’s also possible that one or more packets may be lost or corrupted in transit and need to be retransmitted or that packets arrive out of order and need to be reordered.
Keeping track of this—splitting the data into packets, generating headers, parsing the headers of incoming packets, keeping track of what packets have and haven’t been received, and so on—is a lot of work and requires a lot of intricate code.
Sockets allow the programmer to treat a network connection as just another stream onto which bytes can be written and from which bytes can be read.
Sockets shield the programmer from low-level details of the network, such as error detection, packet sizes, packet splitting, packet retransmission, network addresses, and more.
Using Sockets A socket is a connection between two hosts.
Java’s Socket class, which is used by both clients and servers, has methods that correspond to the first four of these operations.
The last three operations are needed only by servers, which wait for clients to connect to them.
They are implemented by the ServerSocket class, which is discussed in the next chapter.
Java programs normally use client sockets in the following fashion:
Once the connection is established, the local and remote hosts get input and output streams from the socket and use those streams to send data to each other.
What the data means depends on the protocol; different commands are sent to an FTP server than to an HTTP server.
There will normally be some agreed-upon handshaking followed by the transmission of data from one to the other.
When the transmission of data is complete, one or both sides close the connection.
Some protocols, such as HTTP 1.0, require the connection to be closed after each request is serviced.
Others, such as FTP and HTTP 1.1, allow multiple requests to be processed in a single connection.
Investigating Protocols with Telnet In this chapter, you’ll see clients that use sockets to communicate with a number of wellknown Internet services such as time, dict, and more.
The sockets themselves are simple enough; however, the protocols to communicate with different servers make life complex.
To get a feel for how a protocol operates, you can use Telnet to connect to a server, type different commands to it, and watch its responses.
To connect to servers on different ports, specify the port you want to connect to like this:
This requests a connection to port 25, the SMTP port, on the local machine; SMTP is the protocol used to transfer email between servers or between a mail client and a server.
If you know the commands to interact with an SMTP server, you can send email without going through a mail program.
For example, some years ago, the summer students at the National Solar Observatory in Sunspot, New Mexico, made it appear that the party one of the scientists was throwing after the annual volleyball match between the staff and the students was in fact a victory party for the.
Of course, the author of this book had absolutely nothing to do with such despicable behavior.
The interaction with the SMTP server went something like this; input the user types is shown in bold (the names have been changed to protect the gullible):
Beer and Ben-Gay will be provided so the staff may drown their sorrows and assuage their aching muscles after their public humiliation.
Several members of the staff asked Bart why he, a staff member, was throwing a victory party for the students.
The moral of this story is that you should never trust email, especially patently ridiculous email like this, without independent verification.
In the 20 years since this happened, most SMTP servers have added a little more security than shown here.
They tend to require usernames and passwords, and only accept connections from clients in the local networks and other trusted mail servers.
However, it’s still the case that you can use Telnet to simulate a client, see how the client and the server interact, and thus learn what your Java program needs to do.
Although this session doesn’t demonstrate all the features of the SMTP protocol, it’s sufficient to enable you to deduce how a simple email client talks to a server.
Reading from Servers with Sockets Let’s begin with a simple example.
You’re going to connect to the daytime server at the National Institute for Standards and Technology (NIST) and ask it for the current time.
Reading that, you see that the daytime server listens on port 13, and that the server sends the time in a human-readable format and closes the connection.
You can test the daytime server with Telnet like this:
When you read the Socket’s InputStream, this is what you will get.
The other lines are produced either by the Unix shell or by the Telnet program.
YY-MM-DD is the last two digits of the year, the month, and the current day of month.
HH:MM:SS is the time in hours, minutes, and seconds in Coordinated Universal Time (UTC, essentially Greenwich Mean Time)
Other values count down the number of days until the switchover.
In the preceding code, you can see that it added 888.8 milliseconds to this result, because that’s how long it estimates it’s going to take for the response to return.
The string UTC(NIST) is a constant, and the OTM is almost a constant (an asterisk unless something really weird has happened)
Although they do offer a lot of data, if you have a real programmatic need to sync with a network time server, you’re better off using the NTP protocol defined in RFC 5905 instead.
I’m not sure how long this example is going to work as shown here.
These servers are overloaded, and I did have intermittent problems connecting while writing this chapter.
Now let’s see how to retrieve this same data programmatically using sockets.
If the connection times out or fails because the server isn’t listening on port 13, then the constructor throws an IOException, so you’ll usually wrap this in a try block.
In Java 6 and earlier, you’ll want to explicitly close the socket in a finally block to release resources the socket holds:
Set a timeout on the connection using the setSoTimeout() method.
Timeouts are measured in milliseconds, so this statement sets the socket to time out after 15 seconds of nonresponsiveness:
Setting a timeout on the socket means that each read from or write to the socket will take at most a certain number of milliseconds.
Exactly how long a timeout to set depends on the needs of your application and how responsive you expect the server to be.
Fifteen seconds is a long time for a local intranet server to respond, but it’s rather short for an overloaded public server like time.nist.gov.
Once you’ve opened the socket and set its timeout, call getInputStream() to return an InputStream you can use to read bytes from the socket.
In general, a server can send any bytes at all; but in this specific case, the protocol specifies that those bytes must be ASCII:
You can, of course, use any data structure that fits your problem to hold the data that comes off the network.
Example 8-1 puts this all together in a program that also allows you to choose a different daytime server.
Typical output is much the same as if you connected with Telnet:
As far as network-specific code goes, that’s pretty much it.
In most network programs like this, the real effort is in speaking the protocol and comprehending the data formats.
For instance, rather than simply printing out the text the server sends you, you might want to parse it into a java.util.Date object instead.
For variety, I also wrote this example taking advantage of Java 7’s AutoCloseable and try-with-resources.
Notice, however, this class doesn’t actually do anything with the network that Example 8-1 didn’t do.
It just added a bunch of code to turn strings into dates.
When reading data from the network, it’s important to keep in mind that not all protocols use ASCII or even text.
Rather, it is sent as a 32-bit, unsigned, big-endian binary number.
The RFC never actually comes out and says that this is the format used.
It specifies 32 bits and assumes you know that all network protocols use big-endian numbers.
The fact that the number is unsigned can be determined only by calculating the wraparound date for signed and unsigned integers and comparing it to the date given in the specification (2036)
To make matters worse, the specification gives an example of a negative time that can’t actually be sent by time servers that follow the protocol.
Time is a relatively old protocol, standardized in the early 1980s before the IETF was as careful about such issues as it is today.
Nonetheless, if you find yourself implementing a not particularly well-specified protocol, you may have to do a significant amount of testing against existing implementations to figure out what you need to do.
Because the time protocol doesn’t send back text, you can’t easily use Telnet to test such a service, and your program can’t read the server response with a Reader or any sort of readLine() method.
A Java program that connects to time servers must read the raw bytes and interpret them appropriately.
In this example, that job is complicated by Java’s lack of a 32-bit unsigned integer type.
When speaking other protocols, you may encounter data formats even more alien to Java.
For instance, a few network protocols use 64-bit fixedpoint numbers.
You simply have to grit your teeth and code the math you need to handle the data in whatever format the server sends.
Here’s the output of this program from a sample run:
Writing to Servers with Sockets Writing to a server is not noticeably harder than reading from one.
You simply ask the socket for an output stream as well as an input stream.
Although it’s possible to send data over the socket using the output stream at the same time you’re reading data over the input stream, most protocols are designed so that the client is either reading or writing over a socket, not both at the same time.
In the most common pattern, the client sends a request.
The client may send another request, and the server responds again.
This continues until one side or the other is done, and closes the connection.
In this protocol, the client opens a socket to port 2628 on the dict server and sends commands such as “DEFINE eng-lat gold”
This tells the server to send a definition of the word gold using its English-to-Latin dictionary.
After the first definition is received, the client can ask for another.
You can see that control response lines begin with a three-digit code.
The actual definition is plain text, terminated with a period on a line by itself.
If the dictionary doesn’t contain the word you asked for, it returns 552 no match.
Of course, you could also find this out, and a lot more, by reading the RFC.
Once again you’ll want to set a timeout in case the server hangs while you’re connected to it:
In the dict protocol, the client speaks first, so ask for the output stream using getOut putStream():
The getOutputStream() method returns a raw OutputStream for writing data from your application to the other end of the socket.
You usually chain this stream to a more convenient class like DataOutputStream or OutputStreamWriter before using it.
For performance reasons, it’s a good idea to buffer it as well.
Because the dict protocol is text based, more specifically UTF-8 based, it’s convenient to wrap this in a Writer:
Finally, flush the output so you’ll be sure the command is sent over the network:
When you see a period on a line by itself, you know the definition is complete.
You can then send the quit over the output stream:
It connects to dict.org, and translates any words the user enters on the command line into Latin.
However, it does specifically check for a line that begins “552 no match” in case the server doesn’t recognize the word.
It reads a line of input from the console, sends it to the server, and waits to read a line of output it gets back.
The close() method shuts down both input and output from the socket.
On occasion, you may want to shut down only half of the connection, either input or output.
The shutdownInput() and shutdownOutput() methods close only half the connection:
Instead, they adjust the stream connected to the socket so that it thinks it’s at the end of the stream.
Further reads from the input stream after shutting down input return –1
Further writes to the socket after shutting down output throw an IOException.
Many protocols, such as finger, whois, and HTTP, begin with the client sending a request to the server, then reading the response.
It would be possible to shut down the output after the client has sent the request.
For example, this code fragment sends a request to an HTTP server and then shuts down the output, because it won’t need to write anything else over this socket:
Notice that even though you shut down half or even both halves of a connection, you still need to close the socket when you’re through with it.
They don’t release the resources associated with the socket, such as the port it occupies.
The isInputShutdown() and isOutputShutdown() methods tell you whether the input and output streams are open or closed, respectively.
You can use these (rather than isConnected() and isClosed()) to more specifically ascertain whether you can read from or write to a socket:
Other client-oriented classes that make TCP network connections such as URL, URLConnection, Applet, and JEditorPane all ultimately end up invoking the methods of this class.
This class itself uses native code to communicate with the local TCP stack of the host operating system.
Basic Constructors Each Socket constructor specifies the host and the port to connect to.
Hosts may be specified as an InetAddress or a String.
These constructors connect the socket (i.e., before the constructor returns, an active network connection is established to the remote host)
If the connection can’t be opened for some reason, the constructor throws an IOException or an UnknownHostExcep tion.
In this constructor, the host argument is just a hostname expressed as a String.
If the socket cannot be opened for some other reason, the constructor throws an IOException.
There are many reasons a connection attempt might fail: the host you’re trying to reach may not accept connections on that port, the hotel WiFi service may be blocking you until you log in to its website and pay $14.95, or routing problems may be preventing your packets from reaching their destination.
Because this constructor doesn’t just create a Socket object but also tries to connect the socket to the remote host, you can use the object to determine whether connections to a particular port are allowed, as in Example 8-5
Here’s the output this program produces on my local host (your results will vary, depending on which ports are occupied):
If you’re curious about what servers are running on these ports, try experimenting with Telnet.
On a Unix system, you may be able to find out which services reside on which ports by looking in the file /etc/services.
If LowPortScanner finds any ports that are running servers but are not listed in /etc/services, then that’s interesting.
Although this program looks simple, it’s not without its uses.
The first step to securing a system is understanding it.
This program helps you understand what your system is doing so you can find (and close) possible entrance points for attackers.
These provide more control over exactly how the underlying socket behaves, for instance by choosing a different proxy server or an encryption scheme:
Picking a Local Interface to Connect From Two constructors specify both the host and port to connect to and the interface and port to connect from:
This socket connects to the host and port specified in the first two arguments.
It connects from the local network interface and port specified by the last two arguments.
The network interface may be either physical (e.g., an Ethernet card) or virtual (a multihomed host with more than one IP address)
Selecting a particular network interface from which to send data is uncommon, but a need does come up occasionally.
One situation where you might want to explicitly choose the local address would be on a router/firewall that uses dual Ethernet ports.
Incoming connections would be accepted on one interface, processed, and forwarded to the local network from the other interface.
Suppose you were writing a program to periodically dump error logs to a printer or send them over an internal mail server.
You’d want to make sure you used the inward-facing network interface instead of the outward-facing network interface.
By passing 0 for the local port number, I say that I don’t care which port is used but I do want to use the network interface bound to the local hostname router.
In addition, it throws an IOException (probably a BindException, although again that’s just a subclass of IOException and not specifically declared in the throws clause of this method) if the socket is unable to bind to the requested local network interface.
For instance, a program running on a.example.com can’t connect from b.example.org.
You could take deliberate advantage of this to restrict a compiled program to run on only a predetermined host.
It would require customizing distributions for each computer and is certainly overkill for cheap products.
Furthermore, Java programs are so easy to disassemble, decompile, and reverse engineer that this scheme is far from foolproof.
Nonetheless, it might be part of a scheme to enforce a software license.
Constructing Without Connecting All the constructors we’ve talked about so far both create the socket object and open a network connection to a remote host.
If you give no arguments to the Socket constructor, it has nowhere to connect to:
You can connect later by passing a SocketAddress to one of the connect() methods.
You can pass an int as the second argument to specify the number of milliseconds to wait before the connection times out:
That’s not quite as nice as the autoclosing version in Java 7, but it is an improvement.
It is an empty abstract class with no methods aside from a default constructor.
At least theoretically, the SocketAddress class can be used for both TCP and non-TCP sockets.
In practice, only TCP/IP sockets are currently supported and the socket addresses you actually use are all instances of InetSocketAddress.
The primary purpose of the SocketAddress class is to provide a convenient store for transient socket connection information such as the IP address and port that can be reused to create new sockets, even after the original socket is disconnected and garbage collected.
Both of these methods return null if the socket is not yet connected.
For example, first you might connect to Yahoo! then store its address:
The InetSocketAddress class (which is the only subclass of SocketAddress in the JDK, and the only subclass I’ve ever encountered) is usually created with a host and a port (for clients) or just a port (for servers):
InetSocketAddress has a few getter methods you can use to inspect the object:
Proxy Servers The last constructor creates an unconnected socket that connects through a specified proxy server:
Normally, the proxy server a socket uses is controlled by the socksProxyHost and socksProxyPort system properties, and these properties apply to all sockets in the system.
However, a socket created by this constructor will use the specified proxy server instead.
Most notably, you can pass Proxy.NO_PROXY for the argument to bypass all proxy servers completely and connect directly to the remote host.
Of course, if a firewall prevents direct connections, there’s nothing Java can do about it; and the connection will fail.
To use a particular proxy server, specify it by address.
Getting Information About a Socket Socket objects have several properties that are accessible through getter methods:
These properties are set as soon as the socket connects, and are fixed from there on.
The getInetAddress() and getPort() methods tell you the remote host and port the Socket is connected to; or, if the connection is now closed, which host and port the Socket was connected to when it was connected.
The getLocalAddress() and getLo calPort() methods tell you the network interface and port the Socket is connected from.
Unlike the remote port, which (for a client socket) is usually a “well-known port” that has been preassigned by a standards committee, the local port is usually chosen by the system at runtime from the available unused ports.
This way, many different clients on a system can access the same service at the same time.
The local port is embedded in outbound IP packets along with the local host’s IP address, so the server can send data back to the right port on the client.
Example 8-6 reads a list of hostnames from the command line, attempts to open a socket to each one, and then uses these four methods to print the remote host, the remote port, the local address, and the local port.
Closed or Connected? The isClosed() method returns true if the socket is closed, false if it isn’t.
If you’re uncertain about a socket’s state, you can check it with this method rather than risking an IOException.
If the socket has never been connected in the first place, isClosed() returns false, even though the socket isn’t exactly open.
It does not tell you if the socket is currently connected to a remote host (like if it is unclosed)
Instead, it tells you whether the socket has ever been connected to a remote host.
If the socket was able to connect to the remote host at all, this method returns true, even after that socket has been closed.
To tell if a socket is currently open, you need to check that isConnected() returns true and isClosed() returns false.
Finally, the isBound() method tells you whether the socket successfully bound to the outgoing port on the local system.
Whereas isConnected() refers to the remote end of the socket, isBound() refers to the local end.
The toString() method produces a string that looks like this:
Don’t rely on this format; it may change in the future.
All parts of this string are accessible directly through other methods (specifically getInetAddress(), getPort(), and getLocalPort())
Because sockets are transitory objects that typically last only as long as the connection they represent, there’s not much reason to store them in hash tables or compare them to each other.
Therefore, Socket does not override equals() or hashCode(), and the semantics for these methods are those of the Object class.
Two Socket objects are equal to each other if and only if they are the same object.
Setting Socket Options Socket options specify how the native sockets on which the Java Socket class relies send and receive data.
The funny-looking names for these options are taken from the named constants in the C header files used in Berkeley Unix where sockets were invented.
Thus, they follow classic Unix C naming conventions rather than the more legible Java naming conventions.
Setting TCP_NODELAY to true ensures that packets are sent as quickly as possible regardless of their size.
Normally, small (one-byte) packets are combined into larger packets before being sent.
Before sending another packet, the local host waits to receive acknowledgment of the previous packet from the remote system.
The problem with Nagle’s algorithm is that if the remote system doesn’t send acknowledgments back to the local system fast enough, applications that depend on the steady transfer of small parcels of information may slow down.
This issue is especially problematic for GUI programs such as games or network computer applications where the server needs to track client-side mouse movement in real time.
On a really slow network, even simple typing can be too slow because of the constant buffering.
Setting TCP_NODELAY to true defeats this buffering scheme, so that all packets are sent as soon as they’re ready.
For example, the following fragment turns off buffering (that is, it turns on TCP_NODELAY) for the socket s if it isn’t already off:
These two methods are each declared to throw a SocketException, which will happen if the underlying socket implementation doesn’t support the TCP_ NODELAY option.
The SO_LINGER option specifies what to do with datagrams that have not yet been sent when a socket is closed.
By default, the close() method returns immediately; but the system still tries to send any remaining data.
If the linger time is set to zero, any unsent packets are thrown away when the socket is closed.
If SO_LINGER is turned on and the linger time is any positive value, the close() method blocks while waiting the specified number of seconds for the data to be sent and the acknowledgments to be received.
When that number of seconds has passed, the socket is closed and any remaining data is not sent, acknowledgment or no.
These two methods each throw a SocketException if the underlying socket implementation does not support the SO_LINGER option.
However, the getSoLinger() method may return –1 to indicate that this option is disabled, and as much time as is needed is taken to deliver the remaining data; for example, to set the linger timeout for the Socket s to four minutes, if it’s not already set to some other value:
The maximum linger time is 65,535 seconds, and may be smaller on some platforms.
Times larger than that will be reduced to the maximum linger time.
SO_TIMEOUT public void setSoTimeout(int milliseconds) throws SocketException public int getSoTimeout() throws SocketException.
Normally when you try to read data from a socket, the read() call blocks as long as necessary to get enough bytes.
By setting SO_TIMEOUT, you ensure that the call will not block for more than a fixed number of milliseconds.
Although this read() call failed, you can try to read from the socket again.
Zero is interpreted as an infinite timeout; it is the default value.
These two methods each throw a SocketException if the underlying socket implementation does not support the SO_TIMEOUT option.
Larger buffers tend to improve performance for reasonably fast (say, 10Mbps and up) connections whereas slower, dialup connections do better with smaller buffers.
Generally, transfers of large, continuous blocks of data, which are common in file transfer protocols such as FTP and HTTP, benefit from large buffers, whereas the smaller transfers of interactive sessions, such as Telnet and many games, do not.
Relatively old operating systems designed in the age of small files and slow networks, such as BSD 4.2, use two-kilobyte buffers.
For example, on Windows XP suppose the latency between two hosts is half a second (500 ms)
That’s the maximum speed of any socket, regardless of how fast the network is.
That’s plenty fast for a dial-up connection, and not bad for ISDN, but not really adequate for a DSL line or FIOS.
However, latency is a function of the network hardware and other factors outside the control of your application.
On the other hand, you do control the buffer size.
Of course, the network itself has limits on maximum bandwidth.
Set the buffer too high and your program will try to send and receive data faster than the network can handle, leading to congestion, dropped packets, and slower performance.
Thus, when you want maximum bandwidth, you need to match the buffer size to the latency of the connection so it’s a little less than the bandwidth of the network.
The SO_RCVBUF option controls the suggested send buffer size used for network input.
The SO_SNDBUF option controls the suggested send buffer size used for network output:
Although it looks like you should be able to set the send and receive buffers independently, the buffer is usually set to the smaller of these two.
However, the underlying implementation is free to ignore or adjust this suggestion.
If you attempt to set a larger value, Java will just pin it to the maximum possible buffer size.
On Linux, it’s not unheard of for the underlying implementation to double the requested size.
By contrast, if you’re dropping packets and experiencing congestion, try decreasing the buffer size.
However, most of the time, unless you’re really taxing the network in one direction or the other, the defaults are fine.
In particular, modern operating systems use TCP window scaling (not controllable from Java) to dynamically adjust buffer sizes to fit the network.
As with almost any performance tuning advice, the rule of thumb is not to do it until you’ve measured a problem.
And even then you may well get more speed by increasing the maximum allowed buffer size at the operating system level than by adjusting the buffer sizes of individual sockets.
If the server fails to respond to this packet, the client keeps trying for a little more than 11 minutes until it receives a response.
These methods turn SO_KEEPALIVE on and off and determine its current state:
This code fragment turns SO_KEEPALIVE off, if it’s turned on:
Furthermore, the receiver is notified when the urgent data is received and may elect to process the urgent data before it processes any other data that has already been received.
This method sends the lowest-order byte of its argument almost immediately.
How the receiving end responds to urgent data is a little confused, and varies from one platform and API to the next.
Some systems receive the urgent data separately from the regular data.
However, the more common, more modern approach is to place the urgent data in the regular received data queue in its proper order, tell the application that urgent data is available, and let it hunt through the queue to find it.
By default, Java ignores urgent data received from a socket.
However, if you want to receive urgent data inline with regular data, you need to set the OOBINLINE option to true using these methods:
This code fragment turns OOBINLINE on, if it’s turned off:
Once OOBINLINE is turned on, any urgent data that arrives will be placed on the socket’s input stream to be read in the usual way.
That makes it less than ideally useful, but if you have a particular byte (e.g., a Ctrl-C) that has special meaning to your program and never shows up in the regular data stream, then this would enable you to send it more quickly.
SO_REUSEADDR When a socket is closed, it may not immediately release the local port, especially if a connection was open when the socket was closed.
It can sometimes wait for a small amount of time to make sure it receives any lingering packets that were addressed to the port that were still crossing the network when the socket was closed.
The system won’t do anything with any of the late packets it receives.
It just wants to make sure they don’t accidentally get fed into a new process that has bound to the same port.
This isn’t a big problem on a random port, but it can be an issue if the socket has bound to a well-known port because it prevents any other socket from using that port in the meantime.
If the SO_REUSEADDR is turned on (it’s turned off by default), another socket is allowed to bind to the port even while data may be outstanding for the previous socket.
In Java this option is controlled by these two methods:
For this to work, setReuseAddress() must be called before the new socket binds to the port.
Both the socket that was previously connected and the new socket reusing the old address must set SO_REUSEADDR to true for it to take effect.
IP_TOS Class of Service Different types of Internet service have different performance needs.
For instance, video chat needs relatively high bandwidth and low latency for good performance, whereas email can be passed over low-bandwidth connections and even held up for several hours without major harm.
It might be wise to price the different classes of service differentially so that people won’t ask for the highest class of service automatically.
After all, if sending an overnight letter cost the same as sending a package via media mail, we’d all just use FedEx overnight, which would quickly become congested and overwhelmed.
The class of service is stored in an eight-bit field called IP_TOS in the IP header.
Java lets you inspect and set the value a socket places in this field using these two methods:
In 21st-century TCP stacks, the high-order six bits of this byte contain a Differentiated Services Code Point (DSCP) value and the low-order two bits contain an Explicit Congestion Notification (ECN) value.
The DSCP thus has room for up to 26 different traffic classes.
However, it’s up to individual networks and routers to specify exactly what the 64 different possible DSCP values mean.
The four values shown in Table 8-1 are fairly common.
Assured Forwarding (AF) multiple Assured delivery up to a specified rate.
For example, the Expedited Forwarding PHB is a good choice for for VOIP.
This code fragment sets a socket to use Expedited Forwarding by setting the traffic class to 10111000:
Remember the low-order two bits of this number are Explicit Congestion Notification, and should be set to zero.
The purpose here is to allow a sender to express relative preferences for which packets to drop when the network is congested.
Within a class, packets with lower priority are dropped before packets with a higher priority.
Between classes, packest from a higher-priority class are given preference, though lower-priority classes are not starved completely.
For example, the following code fragment sets up three sockets with different forwarding characteristics.
In practice, although DSCP values are respected on some networks internally, any time a packet crosses ISPs, this information is almost always ignored.
The JavaDoc for these options is severely out of date, and describes a quality of service scheme based on bit fields for four traffic classes: low cost, high reliability, maximum throughput, and minimum delay.
This scheme was never widely implemented and probably hasn’t been used in this century.
The specific TCP header where these values were stored has been repurposed for the DSCP and EN values described here.
However, in the unlikely event you need it, you can put these values in the high-order three bits of a class selector PHB, followed by zero bits.
The underlying socket implementation is not required to respect any of these requests.
They only provide a hint to the TCP stack about the desired policy.
Android in particular treats the setTraffic Class() method as a no-op.
If the TCP stack is unable to provide the requested class of service, it may, but is not required to, throw a SocketException.
Exactly how any given VM implements this is implementation dependent.
However, knowing that a problem occurred is often not sufficient to deal with the problem.
Did the remote host refuse the connection because it was busy? Did the remote host refuse the connection because no service was listening on the port? Did the connection attempt timeout because of network congestion or because the host was down? There are several subclasses of SocketException that provide more information about what went wrong and why:
A BindException is thrown if you try to construct a Socket or ServerSocket object on a local port that is in use or that you do not have sufficient privileges to use.
A Connec tException is thrown when a connection is refused at the remote host, which usually happens because the host is busy or no process is listening on that port.
The java.net package also includes ProtocolException, which is a direct subclass of IOException:
This is thrown when data is received from the network that somehow violates the TCP/ IP specification.
None of these exception classes have any special methods you wouldn’t find in any other exception class, but you can take advantage of these subclasses to provide more informative error messages or to decide whether retrying the offending operation is likely to be successful.
HotJava has been discontinued, but there are still numerous network-aware client applications written in Java, including the Eclipse IDE and the Frostwire BitTorrent client.
It is completely possible to write commercial-quality client applications in Java; and it is especially possible to write network-aware applications, both clients and servers.
This section demonstrates a network client, whois, to illustrate this point; and to discuss the special considerations that arise when integrating networking code with Swing applications.
The example stops short of what could be done, but only in the user interface.
Indeed, once again you find out that network code is easy; it’s user interfaces that are hard.
Whois Whois is a simple directory service protocol defined in RFC 954; it was originally designed to keep track of administrators responsible for Internet hosts and domains.
A whois client connects to one of several central servers and requests directory information for a person or persons; it can usually give you a phone number, an email address, and a snail mail address (not necessarily current ones, though)
With the explosive growth of the Internet, flaws have become apparent in the whois protocol, most notably its centralized nature.
Let’s begin with a simple client to connect to a whois server.
The client opens a TCP socket to port 43 on the server.
The client sends a search string terminated by a carriage return/linefeed pair (\r\n)
The search string can be a name, a list of names, or a special command, as discussed shortly.
The server sends an unspecified amount of human-readable information in response to the command and closes the connection.
The search string the client sends has a fairly simple format.
At its most basic, it’s just the name of the person you’re searching for.
Domain names in the .com and .net domains can now be registered with many different competing registrars.
To single out one record, look it up with "xxx", where xxx is one of the of the records displayed above.
If the records are the same, look them up with "=xxx" to receive a full display for each record.
Although the previous input has a pretty clear format, that format is regrettably nonstandard.
Different whois servers can and do send decidedly different output.
For example, here are the first couple of results from the same search at the main French whois server, whois.nic.fr:
Here each complete record is returned rather than just a list of sites.
This protocol is not at all designed for machine processing.
You pretty much have to write new code to handle the output of each different whois server.
Handles are guaranteed to be unique, and are used to get more specific information about a person or a network.
If you search for a handle, you will get at most one match.
If your search only has one match, either because you’re lucky or you’re searching for a handle, the server returns a more detailed record.
Because there is only one oreilly.com in the database, the server returns all the information it has on this domain:
Domain names in the .com and .net domains can now be registered with many different competing registrars.
The whois protocol supports several flags you can use to restrict or expand your search.
For example, if you know you want to search for a person named “Elliott” but you aren’t sure whether he spells his name “Elliot,” “Elliott,” or perhaps even something as unlikely as “Elliotte,” you would type:
This tells the whois server that you want only matches for people (not domains, gateways, groups, or the like) whose names begin with the letters “Elliot.” Unfortunately, you need to do a separate search if you want to find someone who spells his name “Eliot.” The rules for modifying a search are summarized in Table 8-3
Each prefix should be placed before the search string on the command line.
Expand or * Search only for group records and show all individuals in that group.
Partial or suffix Match records that start with the given string.
Summary or $ Show just the summary, even if there’s only one match.
SUBdisplay or % Show the users of the specified host, the hosts on the specified network, etc.
These keywords are all useful, but they’re way too much trouble to remember.
In fact, most people don’t even know that they exist.
They just type “whois Harold” at the command line and sort through the mess that comes back.
A good whois client doesn’t rely on users remembering arcane keywords; rather, it shows them the options.
Supplying this requires a graphical user interface for end users and a better API for client programmers.
A Network Client Library It’s best to think of network protocols like whois in terms of the bits and bytes that move across the network, whether as packets, datagrams, or streams.
No network protocol neatly fits into a GUI (with the arguable exception of the Remote Framebuffer Protocol used by VNC and X11)
It’s usually best to encapsulate the network code into a separate library that the GUI code can invoke as needed.
Two fields define the state of each Whois object: host, an InetAddress object, and port, an int.
Together, these define the server that this particular Whois object connects to.
Five constructors set these fields from various combinations of arguments.
Furthermore, the host can be changed using the se tHost() method.
The main functionality of the class is in one method, lookUpNames()
The lookUp Names() method returns a String containing the whois response to a given query.
The arguments specify the string to search for, what kind of record to search for, which database to search in, and whether an exact match is required.
I could have used strings or int constants to specify the kind of record to search for and the database to search in, but because there are only a small number of valid values, lookUpNames() defines enums with a fixed number of members instead.
This solution provides much stricter compile-time type-checking and guarantees the Whois class won’t have to handle an unexpected value.
String prefix = category.label + " " + group.label; String query = prefix + target + suffix;
This interface has a text field to enter the name to be searched for and a checkbox to determine whether the match should be exact or partial.
A group of radio buttons lets users specify which group of records they want to search.
Another group of radio buttons chooses the fields that should be searched.
By default, this client searches all fields of all records for an exact match.
When a user enters a string in the Whois: search box and presses Enter or clicks the Find button, the program makes a connection to the whois server and retrieves records that match that string.
These are placed in the text area in the bottom of the window.
The main() method is the usual block of code to start up a standalone application.
It constructs a Whois object and then uses that to construct a WhoisGUI object.
Because you’d probably use a visual designer to build such an application, I won’t describe it in detail here.
When the constructor returns, the main() method attaches an anonymous inner class to the window that will close the application when the window is closed.
This isn’t in the constructor because other programs that use this class may not want to exit the program when the window closes.
From that point on, all activity takes place in the event dispatch thread.
The first event this program must respond to is the user typing a name in the Whois: search box and either clicking the Find button or hitting Enter.
In this case, the Lookup Names inner class sets the main text to the empty string and executes a SwingWorker to make the network connection.
SwingWorker (introduced in Java 6) is a really important class to learn if you’re going to write GUI applications that access the network, or for that matter perform any I/O at all.
In any Java GUI application there are two rules you must follow in order to avoid deadlock and slowness:
All updates to Swing components happen on the event dispatch thread.
No slow blocking operations, especially I/O, happen on the event dispatch thread.
These two rules are at loggerheads for network- and I/O-heavy code because the part of the code that performs the I/O can’t update the GUI and vice versa.
There are several ways to sidestep this paradox, but prior to Java 6 they’re all quite complex.
In Java 6 and later, however, the solution is easy.
Define a subclass of Swing Worker and override two methods:
It can return any convenient type and throw any exception.
The done() method is automatically invoked on the event dispatch thread after the doInBackground() method returns, so it can update the GUI.
This method can call the get() method to retrieve the return value calculated by doInBackground()
Example 8-8 uses an inner class named Lookup as its SwingWorker.
The doInBack ground() method talks to the whois server, and returns the server’s response as a String.
The done() method updates the names text area with the server’s response.
The second event this program must respond to is the user typing a new host in the server text field.
In this case, an anonymous inner class tries to construct a new Whois object and stores it in the server field.
If it fails (e.g., because the user mistyped the hostname), the old server is restored.
The most glaring omission is that it doesn’t provide a way to save the data and quit the program.
However, it does demonstrate how to safely make network connections from a GUI program without blocking the event dispatch thread.
The previous chapter discussed sockets from the standpoint of clients: programs that open a socket to a server that’s listening for connections.
However, client sockets themselves aren’t enough; clients aren’t much use unless they can talk to a server, and the Socket class discussed in the previous chapter is not sufficient for writing servers.
To create a Socket, you need to know the Internet host to which you want to connect.
When you’re writing a server, you don’t know in advance who will contact you; and even if you did, you wouldn’t know when that host wanted to contact you.
In other words, servers are like receptionists who sit by the phone and wait for incoming calls.
They don’t know who will call or when, only that when the phone rings, they have to pick it up and talk to whoever is there.
You can’t program that behavior with the Socket class alone.
For servers that accept connections, Java provides a ServerSocket class that represents server sockets.
In essence, a server socket’s job is to sit by the phone and wait for incoming calls.
More technically, a server socket runs on the server and listens for incoming TCP connections.
Each server socket listens on a particular port on the server machine.
When a client on a remote host attempts to connect to that port, the server wakes up, negotiates the connection between the client and the server, and returns a regular Socket object representing the socket between the two hosts.
In other words, server sockets wait for connections while client sockets initiate connections.
Once a ServerSocket has set up the connection, the server uses a regular Socket object to send data to the client.
Using ServerSockets The ServerSocket class contains everything needed to write servers in Java.
It has constructors that create new ServerSocket objects, methods that listen for connections on.
In Java, the basic life cycle of a server program is this:
A new ServerSocket is created on a particular port using a ServerSocket() constructor.
The ServerSocket listens for incoming connection attempts on that port using its accept() method.
Depending on the type of server, either the Socket’s getInputStream() method, getOutputStream() method, or both are called to get input and output streams that communicate with the client.
The server and the client interact according to an agreed-upon protocol until it is time to close the connection.
The server returns to step 2 and waits for the next connection.
When a client connects, the server sends the time in a human-readable format and closes the connection.
First, create a server socket that listens on port 13:
When a client does connect, the accept() method returns a Socket object.
The daytime protocol requires the server (and only the server) to talk, so get an OutputStream from the socket.
Now get the current time and write it onto the stream.
The daytime protocol doesn’t require any particular format other than that it be human readable, so let Java pick for you:
Do note, however, the use of a carriage return/linefeed pair to terminate the line.
This is almost always what you want in a network server.
You won’t always have to close the connection after just one write.
Many protocols, dict and HTTP 1.1 for instance, allow clients to send multiple requests over a single socket and expect the server to send multiple responses.
Some protocols such as FTP can even hold a socket open indefinitely.
If the client closes the connection while the server is still operating, the input and/or output streams that connect the server to the client throw an InterruptedIOExcep tion on the next read or write.
In either case, the server should then get ready to process the next incoming connection.
Of course, you’ll want to do all this repeatedly, so you’ll put this all inside a loop.
Each pass through the loop invokes the accept() method once.
This returns a Socket object representing the connection between the remote client and the local server.
Interaction with the client takes place through this Socket object.
There’s one big loop, and in each pass through the loop a single connection is completely processed.
This works well for a very simple protocol with very small requests and responses like daytime, though even with this simple a protocol it’s possible for one slow client to delay other faster clients.
Upcoming examples will address this with multiple threads or asynchronous I/O.
When exception handling is added, the code becomes somewhat more convoluted.
It’s important to distinguish between exceptions that should probably shut down the server and log an error message, and exceptions that should just close that active connection.
Exceptions within the scope of a particular connection should close that connection, but not affect other connections or shut down the server.
Exceptions outside the scope of an individual request probably should shut down the server.
In Chapter 8, I said that a client shouldn’t rely on the other side of a connection to close the socket; that goes triple for servers.
Clients time out or crash; users cancel transactions; networks go down in hightraffic periods; hackers launch denial-of-service attacks.
The class has a single method, main(), which does all the work.
The outer try block traps any IOExceptions that may arise while the ServerSocket object server is constructed on the daytime port.
The inner try block watches for exceptions thrown while the connections are accepted and processed.
The accept() method is called within an infinite loop to watch for new connections; like many servers, this program never terminates but continues listening until an exception is thrown or you stop it manually.
The command for stopping a program manually depends on your system; under Unix, Windows, and many other systems, Ctrl-C will do the job.
If you are running the server in the background on a Unix system, stop it by finding the server’s process ID and killing it with the kill command (kill pid )
When a client connects, accept() returns a Socket, which is stored in the local variable connection, and the program continues.
It calls getOutputStream() to get the output stream associated with that Socket and then chains that output stream to a new Out putStreamWriter, out.
The content is sent to the client by writing its string representation on out with write()
Serving Binary Data Sending binary, nontext data is not significantly harder.
You just use an Output Stream that writes a byte array rather than a Writer that writes a String.
Once again, the current time is found by creating a new Date object.
As with the TimeClient of the previous chapter, most of the effort here goes into working with a data format (32-bit unsigned integers) that Java doesn’t natively support.
Multithreaded Servers Daytime and time are both very quick protocols.
The server sends a few dozen bytes at most and then closes the connection.
It’s plausible here to process each connection fully before moving on to the next one.
Even in that case, though, it is possible that a slow or crashed client might hang the server for a few seconds until it notices the socket is broken.
If the sending of data can take a significant amount of time even when client and server are behaving, you really don’t want each connection to wait for the next.
Old-fashioned Unix servers such as wu-ftpd create a new process to handle each connection so that multiple clients can be serviced at the same time.
Java programs should spawn a thread to interact with the client so that the server can be ready to process the next connection sooner.
A thread places a far smaller load on the server than a complete child process.
In fact, the overhead of forking too many processes is why the typical Unix FTP server can’t handle more than roughly 400 connections without slowing to a.
On the other hand, if the protocol is simple and quick and allows the server to close the connection when it’s through, it will be more efficient for the server to process the client request immediately without spawning a thread.
The operating system stores incoming connection requests addressed to a particular port in a first-in, first-out queue.
By default, Java sets the length of this queue to 50, although it can vary from operating system to operating system.
Some operating systems (not Solaris) have a maximum queue length.
After the queue fills to capacity with unprocessed connections, the host refuses additional connections on that port until slots in the queue open up.
Many (though not all) clients will try to make a connection multiple times if their initial attempt is refused.
Several ServerSocket constructors allow you to change the length of the queue if its default length isn’t large enough.
However, you won’t be able to increase the queue beyond the maximum size that the operating system supports.
Whatever the queue size, though, you want to be able to empty it faster than new connections are coming in, even if it takes a while to process each connection.
The solution here is to give each connection its own thread, separate from the thread that accepts incoming connections into the queue.
For instance, Example 9-3 is a daytime server that spawns a new thread to handle each incoming connection.
This prevents one slow client from blocking all the other clients.
However, it deliberately does not use try-with-resources for the client sockets accepted by the server socket.
This is because the client socket escapes from the try block into a separate thread.
Because Example 9-3 spawns a new thread for each connection, numerous roughly simultaneous incoming connections can cause it to spawn an indefinite number of threads.
Eventually, the Java virtual machine will run out of memory and crash.
A better approach is to use a fixed thread pool as described in Chapter 3 to limit the potential resource usage.
Example 9-4 shouldn’t crash no matter what load it’s under.
The single difference is that it uses a Callable rather than a Thread subclass, and rather than starting threads it submits these callables to an executor service preconfigured with 50 threads.
Writing to Servers with Sockets In the examples so far, the server has only written to client sockets.
You’ll accept a connection as before, but this time ask for both an InputStream and an Out putStream.
Read from the client using the InputStream and write to it using the Out putStream.
The main trick is understanding the protocol: when to write and when to read.
The echo protocol, defined in RFC 862, is one of the simplest interactive TCP services.
The client opens a socket to port 7 on the echo server and sends data.
The echo protocol is useful for testing the network to make sure that data is not mangled by a misbehaving router or firewall.
This sample is line oriented because that’s how Telnet works.
It reads a line of input from the console, sends it to the server, then waits to read a line of output it gets back.
It doesn’t really care whether those bytes represent characters in some encoding or are divided into lines.
Unlike many protocols, echo does not specify lockstep behavior where the client sends a request but then waits for the full server response before sending any more data.
Unlike daytime and time, in the echo protocol the client is responsible for closing the connection.
This makes it even more important to support asynchronous operation with many threads because a single client can remain connected indefinitely.
Closing Server Sockets If you’re finished with a server socket, you should close it, especially if the program is going to continue to run for some time.
This frees up the port for other programs that may wish to use it.
Closing a ServerSocket should not be confused with closing a Socket.
Closing a ServerSocket frees a port on the local host, allowing another server to bind to the port; it also breaks all currently open sockets that the ServerSocket has accepted.
Server sockets are closed automatically when a program dies, so it’s not absolutely necessary to close them in programs that terminate shortly after the ServerSocket is no longer needed.
Programmers often follow the same closeif-not-null pattern in a try-finally block that you’re already familiar with from streams and client-side sockets:
You can improve this slightly by using the noargs ServerSocket() constructor, which does not throw any exceptions and does not bind to a port.
Instead, you call the bind() method to bind to a socket address after the ServerSocket() object has been constructed:
In Java 7, ServerSocket implements AutoCloseable so you can take advantage of trywith-resources instead:
After a server socket has been closed, it cannot be reconnected, even to the same port.
The isClosed() method returns true if the ServerSocket has been closed, false if it hasn’t:
ServerSocket objects that were created with the noargs ServerSocket() constructor and not yet bound to a port are not considered to be closed.
The isBound() method tells you whether the ServerSock et has been bound to a port:
As with the isBound() method of the Socket class discussed in the Chapter 8, the name is a little misleading.
If you need to test whether a ServerSocket is open, you must check both that isBound() returns true and that isClosed() returns false.
It’s often important to debug what happened when in a server long after the fact.
For this reason, it’s advisable to store server logs for at least some period of time.
What to Log There are two primary things you want to store in your logs:
Indeed, servers often keep two different logfiles for these two different items.
The audit log usually contains one entry for each connection made to the server.
Servers that perform multiple operations per connection may have one entry per operation instead.
For instance, a dict server might log one entry for each word a client looks up.
The error log contains mostly unexpected exceptions that occurred while the server was running.
The error log does not contain client errors, such as a client that unexpectedly disconnects or sends a malformed request.
The general rule of thumb for error logs is that every line in the error log should be looked at and resolved.
The ideal number of entries in an error log is zero.
Every entry in this log represents a bug to be investigated and resolved.
If investigation of an error log entry ends with the decision that that exception is not really a problem, and the code is working as intended, remove the log statement.
Error logs that fill up with too many false alarms rapidly become ignored and useless.
For the same reason, do not keep debug logs in production.
Do not log every time you enter a method, every time a condition is met, and so on.
If you need method-level logging for debugging, put it in a separate file, and turn it off in the global properties file when running in production.
More advanced logging systems provide log analysis tools that enable you to do things like show only messages with priority INFO or higher, or only show messages that originated from a certain part of the code.
These tools make it more feasible to keep a single logfile or database, perhaps even share one log among many different binaries or programs.
Nonetheless, the principle still applies that a log record no one will ever look at is worthless at best and more often than not distracting or confusing.
Do not follow the common antipattern of logging everything you can think of just in case someone might need it someday.
In practice, programmers are terrible at guessing in advance which log messages they might need for debugging production problems.
Once a problem occurs, it is sometimes obvious what messages you need; but it is rare to be able to anticipate this in advance.
Adding “just in case” messages to logfiles usually means that when a problem does occur, you’re frantically hunting for the relevant messages in an even bigger sea of irrelevant data.
Although you can load a logger on demand, it’s usually easiest to just create one per class like so:
Loggers are thread safe, so there’s no problem storing them in a shared static field.
Indeed, they almost have to be because even if the Logger object were not shared between threads, the logfile or database would be.
This example outputs to a log named “requests.” Multiple Logger objects can output to the same log, but each logger always logs to exactly one log.
What and where the log is depends on external configuration.
Most commonly it’s a file, which may or may not be named “requests”; but it can be a database, a SOAP service running on a different server, another Java program on the same host, or something else.
Once you have a logger, you can write to it using any of several methods.
For example, this catch block logs an unexpected runtime exception at the highest level:
Including the exception instead of just a message is optional but customary when logging from a catch block.
I use info for audit logs and warning or severe for error logs.
Lower levels are for debugging only and should not be used in production systems.
Info, severe, and warning all have convenience helper methods that log at that level.
For example, this statement logs a hit including the date and the remote address:
You can use any format that’s convenient for the individual log records.
Generally, each record should contain a timestamp, the client address, and any information specific to the request that was being processed.
If the log message represents an error, include the specific exception that was thrown.
Java fills in the location in the code where the message was logged automatically, so you don’t need to worry about that.
Example 9-6 demonstrates by adding logging to the daytime server.
As well as logging, Example 9-6 has also added catch blocks for RuntimeException that cover most of the code and all of the network connections.
Usually when this happens that request is going to fail, but you can continue processing other requests.
If you’re even more careful, you can send the client the appropriate error response.
In HTTP, this would be a 500 internal server error.
Not every exception automatically turns into an error log entry.
For example, if a client disconnects while you’re writing the time, that’s an IOException.
In some situations, you might want to log it in the audit log, or a third location.
However, remember the golden rule of logging: if no one’s going to look at it, don’t log it.
Unless you really plan to investigate and do something about client disconnects, don’t bother to record them.
By default, the logs are just output to the console.
For example, here’s the output from the preceding server when I connected to it a few times in quick succession:
You’ll want to configure the runtime environment such that logs go to a more permanent destination.
Although you can specify this in code, it’s usually advisable to set this up in a configuration file so log locations can be changed without recompiling.
For instance, in Mac OS X, it might be set in the VMOptions in the Info.plist file:
Example 9-7 is a sample logging properties file that specifies:
Limit the log size to about 10 megabytes, then rotate.
Keep two logs: the current one and the previous one.
Each line of the logfile should be in the form level message timestamp.
Here’s some typical log output (note that it looks like the timestamp is doubled in request messages because the log message also includes the current time; this would not typically be the case for a server whose purpose was anything other than serving the current time):
The one thing I don’t like about the Java Logging API is that it doesn’t give you an easy way to specify by configuration alone that different messages belong in different logs.
For instance, you can’t easily separate your error and your audit log.
It can be done, but it requires you to define a new subclass of FileHandler for each separate log so you can assign it a new file.
Finally, once you’ve configured your servers with logging, don’t forget to look in them, especially the error logs.
There’s no point to a logfile no one ever looks at.
You’ll also want to plan for and implement log rotation and retention policies.
Hard drives get bigger every year, but it’s still possible for a high-volume server to fill up a filesystem with log data if you aren’t paying attention.
Murphy’s law says this is most likely to happen at 4:00 A.M.
These constructors specify the port, the length of the queue used to hold incoming connection requests, and the local network interface to bind to.
They pretty much all do the same thing, though some use default values for the queue length and the address to bind to.
For example, to create a server socket that would be used by an HTTP server on port 80, you would write:
If you try to expand the queue past the operating system’s maximum queue length, the maximum queue length is used instead.
By default, if a host has multiple network interfaces or IP addresses, the server socket listens on the specified port on all the interfaces and IP addresses.
However, you can add a third argument to bind only to one particular local IP address.
That is, the server socket only listens for incoming connections on the specified address; it won’t listen for connections that come in through the host’s other addresses.
In all three constructors, you can pass 0 for the port number so the system will select an available port for you.
A port chosen by the system like this is sometimes called an anonymous port because you don’t know its number in advance (though you can find out after the port has been chosen)
This is often useful in multisocket protocols such as FTP.
In passive FTP the client first connects to a server on the well-known port 21, so the server has to specify that port.
However, when a file needs to be transferred, the server starts listening on any available port.
Thus, the data port can change from one session to the next and does not need to be known in advance.
Active FTP is similar except the client listens on an ephemeral port for the server to connect to it, rather than the other way around.
All these constructors throw an IOException, specifically, a BindException, if the socket cannot be created and bound to the requested port.
An IOException when creating a ServerSocket almost always means one of two things.
You can take advantage of this to write a variation on the LowPortScanner program of the previous chapter.
Rather than attempting to connect to a server running on a given port, you instead attempt to open a server on that port.
Example 9-8 checks for ports on the local machine by attempting to create Server Socket objects on them and seeing on which ports that fails.
If you’re using Unix and are not running as root, this program works only for ports 1024 and above.
Here’s the output I got when running LocalPortScanner on my Windows workstation:
Constructing Without Binding The noargs constructor creates a ServerSocket object but does not actually bind it to a port, so it cannot initially accept any connections.
The primary use for this feature is to allow programs to set server socket options before binding to a port.
Some options are fixed after the server socket has been bound.
You can also pass null for the SocketAddress to select an arbitrary port.
This is like passing 0 for the port number in the other constructors.
Getting Information About a Server Socket The ServerSocket class provides two getter methods that tell you the local address and port occupied by the server socket.
These are useful if you’ve opened a server socket on an anonymous port and/or an unspecified network interface.
This would be the case, for one example, in the data connection of an FTP session:
This method returns the address being used by the server (the local host)
If the local host has more than one IP address, the specific address returned is one of the host’s IP addresses.
If the ServerSocket has not yet bound to a network interface, this method returns null:
The ServerSocket constructors allow you to listen on an unspecified port by passing 0 for the port number.
This method lets you find out what port you’re listening on.
You might use this in a peer-to-peer multisocket program where you already have a means to inform other peers of your location.
Or a server might spawn several smaller servers to perform particular operations.
The well-known server could inform clients on what ports they can find the smaller servers.
Of course, you can also use getLocalPort() to find a nonanonymous port, but why would you need to? Example 9-9 demonstrates.
At least on this system, the ports aren’t truly random, but they are indeterminate until runtime.
If the ServerSocket has not yet bound to a port, getLocalPort() returns –1
As with most Java objects, you can also just print out a ServerSocket using its to String() method.
A String returned by a ServerSocket’s toString() method looks like this:
This will be 0.0.0.0 if it’s bound to all interfaces, as is commonly the case.
The localport is the local port on which the server is listening for connections.
This method is sometimes useful for debugging, but not much more.
Socket Options Socket options specify how the native sockets on which the ServerSocket class relies send and receive data.
It also allows you to set performance preferences for the socket’s packets.
You might need it if you were implementing a complicated and secure protocol that required multiple connections between the client and the server where responses needed to occur within a fixed amount of time.
However, most servers are designed to run for indefinite periods of time and therefore just use the default timeout value, 0 (never time out)
If you want to change this, the setSoTi meout() method sets the SO_TIMEOUT field for this server socket object:
The getSoTimeout() method returns this server socket’s current SO_TIMEOUT value.
It determines whether a new socket will be allowed to bind to a previously used port while there might still be data traversing the network addressed to the old socket.
As you probably expect, there are two methods to get and set this option:
This code fragment determines the default value by creating a new ServerSocket and then calling getReuseAddress():
On the Linux and Mac OS X boxes where I tested this code, server sockets were reusable by default.
Recall from the previous chapter that this option suggests a value for the size of the individual IP packets in the stream.
Faster connections will want to use larger buffers, although most of the time the default value is fine.
You can set this option before or after the server socket is bound, unless you want to set a receive buffer size larger than 64K.
In that case, you must set the option on an unbound ServerSocket before binding it.
Class of Service As you learned in the previous chapter, different types of Internet services have different performance needs.
For instance, live streaming video of sports needs relatively high bandwidth.
On the other hand, a movie might still need high bandwidth but be able to tolerate more delay and latency.
Email can be passed over low-bandwidth connections and even held up for several hours without major harm.
These traffic classes can be requested for a given Socket.
For instance, you can request the minimum delay available at low cost.
These measures are all fuzzy and relative, not guarantees of service.
Not all routers and native TCP stacks support these classes.
Exactly how any given VM implements this is implementation dependent.
The underlying socket implementation is not required to respect any of these requests.
They only provide a hint to the TCP stack about the desired policy.
As you saw in Chapter 5, a full-featured HTTP server must respond to requests for files, convert URLs into filenames on the local system, respond to POST and GET requests, handle requests for files that don’t exist, interpret MIME types, and much, much more.
However, many HTTP servers don’t need all of these features.
For example, many sites simply display an “under construction” message.
Such a site is a candidate for a custom server that does only one thing.
Java’s network class library makes writing simple servers like this almost trivial.
High-traffic sites like Yahoo! are also candidates for custom servers because a server that does only one thing can often be much faster than a general-purpose server such as Apache or Microsoft IIS.
It is easy to optimize a special-purpose server for a particular task; the result is often much more efficient than a general-purpose server that needs to respond to many different kinds of requests.
For instance, icons and images that are used repeatedly across many pages or on high-traffic pages might be better handled by a server that read all the image files into memory on startup and then served them straight out of RAM, rather than having to read them off disk for each request.
Furthermore, this server could avoid wasting time on logging if you didn’t want to track the image requests separately from the requests for the pages in which they were included.
Finally, Java isn’t a bad language for full-featured web servers meant to compete with the likes of Apache or IIS.
Even if you believe CPU-intensive Java programs are slower than CPU-intensive C and C++ programs (something I very much doubt is true in modern VMs), most HTTP servers are limited by network bandwidth and latency, not by CPU speed.
In particular, sites that make heavy use of dynamic content through servlets, PHP pages, or other mechanisms can often run much faster when reimplemented on top of a pure or mostly pure Java web server.
Indeed, there are several production web servers written in Java, such as the Eclipse Foundation’s Jetty.
These largely replaced traditional CGIs, ASPs, and server-side includes, mostly because the Java equivalents are faster and less resource intensive.
I’m not going to explore these technologies here because they easily deserve a book of their own.
However, it is important to note that servers in general and web servers in particular are one area where Java really is competitive with C for real-world performance.
A Single-File Server Our investigation of HTTP servers begins with a server that always sends out the same file, no matter what the request.
The filename, local port, and content encoding are read from the command line.
The constructors set up the data to be sent along with an HTTP header that includes information about content length and content encoding.
The header and the body of the response are stored in byte arrays in the desired encoding so that they can be blasted to clients very quickly.
The start() method creates a ServerSocket on the specified port, then enters an infinite loop that continually accepts connections and processes them.
Each incoming socket is processed by a runnable Handler object that is submitted to a thread pool.
Each Handler gets an InputStream from it which it reads the client request.
It looks at the first line to see whether it contains the string HTTP.
If it sees this string, the server assumes that the client understands HTTP/1.0 or later and therefore sends a MIME header for the file; then it sends the data.
If the client request doesn’t contain the string HTTP, the server omits the header, sending the data by itself.
The main() method just reads parameters from the command line.
The name of the file to be served is read from the first command-line argument.
If no file is specified or the file cannot be opened, an error message is printed and the program exits.
The URLConnection class makes a reasonable guess about the content type of the file, and that guess is stored in the contentType variable.
Next, the port number is read from the second command-line argument.
You could easily use this class as part of some other program.
If you added a setter method to change the content, you could easily use it to provide simple status information about a running server or system.
However, that would raise some additional issues of thread safety that Example 9-10 doesn’t have to address because the data is immutable.
Here’s what you see when you connect to this server via Telnet (the specifics depend on the exact server and file):
A Redirector Redirection is another simple but useful application for a special-purpose HTTP server.
In this section, you develop a server that redirects users from one website to anotherfor example, from cnet.com to www.cnet.com.
In this example, I chose to use a new thread rather than a thread pool for each connection.
This is perhaps a little simpler to code and understand but somewhat less efficient.
If you connect to this server via Telnet, this is what you’ll see:
If, however, you connect with a web browser, you should be sent to http://www.cafeconleche.org/ with only a slight delay.
The main() method provides a very simple interface that reads the URL of the new site to redirect connections to and the local port to listen on.
If the site is omitted, Redirector prints an error message and exits.
The start() method of Redirector binds the server socket to the port, prints a brief status message, and then enters an infinite loop in which it listens for connections.
Every time a connection is accepted, the resulting Socket object is used to construct a Redi rectThread.
All further interaction with the client takes place in this new thread.
The start() method then simply waits for the next incoming connection.
The run() method of RedirectThread does most of the work.
It begins by chaining a Writer to the Socket’s output stream and a Reader to the Socket’s input stream.
Then the run() method reads the first line the client sends.
Although the client will probably send a whole MIME header, you can ignore that.
It is possible that the first word will be POST or PUT instead or that there will be no HTTP version.
The second “word” is the file the client wants to retrieve.
Browsers are responsible for converting relative URLs to absolute URLs that begin with a slash; the server does not do this.
The third word is the version of the HTTP protocol the browser understands.
To handle a request like this, Redirector ignores the first word.
The second word is attached to the URL of the target server (stored in the field newSite) to give a full redirected URL.
The third word is used to determine whether to send a MIME header; MIME headers are not used for old browsers that do not understand HTTP/1.0
If there is a version, a MIME header is sent; otherwise, it is omitted.
Because all the data you send is pure ASCII, the exact encoding isn’t too important.
The only trick here is that the end-of-line character for HTTP requests is \r\n–a carriage return followed by a linefeed.
The next lines each send one line of text to the client.
This is an HTTP/1.0 response code that tells the client to expect to be redirected.
The second line is a Date: header that gives the current time at the server.
The third line is the name and version of the server; this line is also optional but is used by spiders that try to keep statistics about the most popular web servers.
The next line is the Location: header, which is required for this response type.
It tells the client where it is being redirected to.
You send the content type text/html to indicate that the client should expect to see HTML.
Finally, a blank line is sent to signify the end of the header data.
Everything after this will be HTML, which is processed by the browser and displayed to the user.
The next several lines print a message for browsers that do not support redirection, so those users can manually jump to the new site.
This next section develops a full-blown HTTP server, called JHTTP, that can serve an entire document tree, including images, applets, HTML files, text files, and more.
This server is still fairly lightweight; after looking at the code, we’ll discuss other features you might want to add.
Because this server may have to read and serve large files from the filesystem over potentially slow network connections, you’ll change its approach.
Rather than processing each request as it arrives in the main thread of execution, you’ll place incoming connections in a pool.
Separate instances of a RequestProcessor class will remove the connections from the pool and process them.
As in the previous two examples, the main() method of JHTTP handles initialization, but other programs can use this class to run basic web servers.
The main() method of the JHTTP class sets the document root directory from args[0]
You submit one RequestProcessor thread per incoming connection into the pool.
Each connection is handled by the run() method of the RequestProcessor class shown in Example 9-13
It gets input and output streams from the socket and chains them to a reader and a writer.
The reader reads the first line of the client request to determine the version of HTTP that the client supports—you want to send a MIME header only if this is HTTP/1.0 or later—and the requested file.
Assuming the method is GET, the file that is requested is converted to a filename on the local filesystem.
If the file requested is a directory (i.e., its name ends with a slash), you add the name of an index file.
You use the canonical path to make sure that the requested file doesn’t come from outside the document root directory.
Otherwise, a sneaky client could walk all over the local filesystem by including ..
This is all you’ll need from the client, although a more advanced web server, especially one that logged hits, would read the rest of the MIME header the client sends.
Next, the requested file is opened and its contents are read into a byte array.
If the HTTP version is 1.0 or later, you write the appropriate MIME headers on the output stream.
The byte array containing the file’s contents is written onto the output stream and the connection is closed.
If the file cannot be found or opened, you send the client a 404 response instead.
If the client sends a method you don’t support, such as POST, you send back a 501 error.
If an exception occurs, you log it, close the connection, and continue.
Support for other request methods, such as POST, HEAD, and PUT.
Support for multiple document roots so individual users can have their own sites.
Finally, spend a little time thinking about ways to optimize this server.
If you really want to use JHTTP to run a high-traffic site, there are a couple of things that can speed this server up.
Keep track of the requests you’ve received and store the data from the most frequently requested files in a Map so that they’re kept in memory.
You can also try using nonblocking I/O and channels instead of threads and streams.
And this is just a small sampling of government sponsored eavesdropping we know about.
As an Internet user, you do have defenses against snooping bureaucrats.
To make Internet connections more fundamentally secure, sockets can be encrypted.
Performing it properly requires a detailed understanding not only of the mathematical algorithms used to encrypt data, but also of the protocols used to exchange keys and encrypted data.
Even a small mistake can open a large hole in your armor and reveal your communications to an eavesdropper.
Consequently, writing encryption software is a task best left to experts.
Fortunately, nonexperts with only a layperson’s understanding of the underlying protocols and algorithms can secure their communications with software designed by experts.
Every time you order something from an online store, chances are the transaction is encrypted and authenticated using protocols and algorithms you need to know next to nothing about.
As a programmer who wants to write network client software that talks to online stores, you need to know a little more about the protocols and algorithms involved, but not a lot more, provided you can use a class library written by experts who do understand the details.
If you want to write the server software that runs the online store, you need.
Secure Communications Confidential communication through an open channel such as the public Internet absolutely requires that data be encrypted.
Most encryption schemes that lend themselves to computer implementation are based on the notion of a key, a slightly more general kind of password that’s not limited to text.
The plain-text message is combined with the bits of the key according to a mathematical algorithm to produce the encrypted ciphertext.
Using keys with more bits makes messages exponentially more difficult to decrypt by brute-force guessing of the key.
In traditional secret key (or symmetric) encryption, the same key is used to encrypt and decrypt the data.
Both the sender and the receiver have to know the single key.
She first sends Gus the key they’ll use to exchange the secret.
But the key can’t be encrypted because Gus doesn’t have the key yet, so Angela has to send the key unencrypted.
Now suppose Edgar is eavesdropping on the connection between Angela and Gus.
He will get the key at the same time that Gus does.
From that point forward, he can read anything Angela and Gus say to each other using that key.
In public key (or asymmetric) encryption, different keys are used to encrypt and decrypt the data.
A different key, called the private key, is used to decrypt the data.
This must be kept secret but needs to be possessed by only one of the correspondents.
If Angela wants to send a message to Gus, she asks Gus for his public key.
Angela uses Gus’s public key to encrypt her message and sends it to him.
If Edgar is eavesdropping when Gus sends Angela his key, Edgar also gets Gus’s public key.
However, this doesn’t allow Edgar to decrypt the message Angela sends Gus, because decryption requires Gus’s private key.
The message is safe even if the public key is detected in transit.
Asymmetric encryption can also be used for authentication and message integrity checking.
For this use, Angela would encrypt a message with her private key before sending it.
When Gus received it, he’d decrypt it with Angela’s public key.
If the decryption succeeded, Gus would know that the message came from Angela.
After all, no one else could have produced a message that would decrypt properly with her public.
Gus would also know that the message wasn’t changed en route, either maliciously by Edgar or unintentionally by buggy software or network noise, because any such change would have screwed up the decryption.
With a little more effort, Angela can double-encrypt the message, once with her private key, once with Gus’s public key, thus getting all three benefits of privacy, authentication, and integrity.
In practice, public-key encryption is much more CPU-intensive and much slower than secret-key encryption.
Therefore, instead of encrypting the entire transmission with Gus’s public key, Angela encrypts a traditional secret key and sends it to Gus.
Now Angela and Gus both know the secret key, but Edgar doesn’t.
Therefore, Gus and Angela can now use faster secret-key encryption to communicate privately without Edgar listening in.
Edgar still has one good attack on this protocol, however.
Important: the attack is on the protocol used to send and receive messages, not on the encryption algorithms used.
This attack does not require Edgar to break Gus and Angela’s encryption and is completely independent of key length.
Edgar can not only read Gus’s public key when he sends it to Angela, but he can also replace it with his own public key! Then when Angela thinks she’s encrypting a message with Gus’s public key, she’s really using Edgar’s.
When she sends a message to Gus, Edgar intercepts it, decrypts it using his private key, encrypts it using Gus’s public key, and sends it on to Gus.
Working alone on an insecure channel, Gus and Angela have no easy way to protect against this.
The solution used in practice is for both Gus and Angela to store and verify their public keys with a trusted third-party certification authority.
Rather than sending each other their public keys, Gus and Angela retrieve each other’s public key from the certification authority.
This scheme still isn’t perfect—Edgar may be able to place himself in between Gus and the certification authority, Angela and the certification authority, and Gus and Angela—but it makes life harder for Edgar.
As this example indicates, the theory and practice of encryption and authentication, both algorithms and protocols, is a challenging field that’s fraught with mines and pitfalls to surprise the amateur cryptographer.
It is much easier to design a bad encryption algorithm or protocol than a good one.
And it’s not always obvious which algorithms and protocols are good and which aren’t.
Fortunately, you don’t have to be a cryptography expert to use strong cryptography in Java network programs.
All you have to do is send your data over the same streams and sockets you’re familiar with from previous chapters.
The abstract classes that define Java’s API for secure network communication.
The abstract socket factory classes used instead of constructors to create secure sockets.
The classes for handling the public-key certificates needed for SSL.
The concrete classes that implement the encryption algorithms and protocols in Sun’s reference implementation of the JSSE.
Other implementers may replace this package with one of their own; for instance, one that uses native code to speed up the CPU-intensive key generation and encryption process.
Creating Secure Client Sockets If you don’t care very much about the underlying details, using an encrypted SSL socket to talk to an existing secure server is truly straightforward.
SSLSocketFacto ry is an abstract class that follows the abstract factory design pattern.
This either returns an instance of SSLSocketFactory or throws an InstantiationEx ception if no concrete subclass can be found.
Once you have a reference to the factory, use one of these five overloaded createSocket() methods to build an SSLSocket:
The first two methods create and return a socket that’s connected to the specified host and port or throw an IOException if they can’t connect.
The third and fourth methods connect and return a socket that’s connected to the specified host and port from the specified local network interface and port.
It begins with an existing Socket object that’s connected to a proxy server.
It returns a Socket that tunnels through this proxy server to the specified host and port.
The autoClose argument determines whether the underlying proxy socket should be closed when this socket is closed.
If autoClose is true, the underlying socket will be closed; if false, it won’t be.
Once the secure socket has been created, you use it just like any other socket, through its getInput Stream(), getOutputStream(), and other methods.
Each order is sent as an ASCII string using a single TCP connection.
I’m leaving out a lot of details that would be necessary in a real-world system, such as the server sending a response code telling the client whether the order was accepted.
There’s enough information in this message to let someone snooping packets use John Smith’s credit card number for nefarious purposes.
The simplest way to do that without burdening either the server or the client with a lot of complicated, error-prone encryption code is to use a secure socket.
The following code sends the order over a secure socket:
Only the first three statements in the try block are noticeably different from what you’d do with an insecure socket.
The rest of the code just uses the normal methods of the Socket, OutputStream, and Writer classes.
Example 10-1 is a simple program that connects to a secure HTTP server, sends a simple GET request, and prints out the response.
Here are the first few lines of output from this program when you connect to the U.S.
When I tested this program for the previous edition, it initially refused to connect to www.usps.com because it couldn’t verify the identity of the remote server.
The problem was that the root certificates shipped with the version of the JDK I was using (1.4.2_02-b3) had expired.
Upgrading to the latest minor version (1.4.2_03-b2) fixed the problem.
If you see any exception messages like “No trusted certificate found,” try upgrading to the latest minor version of the JDK.
When you run this program, you may notice that it’s slower to respond than you expect.
There’s a noticeable amount of both CPU and network overhead involved in generating.
Even over a fast network, it can take a few seconds to establish a connection.
Consequently, you may not want to serve all your content over HTTPS, only the content that really needs to be private and isn’t latency sensitive.
Choosing the Cipher Suites Different implementations of the JSSE support different combinations of authentication and encryption algorithms.
The stock JSSE bundled with the JDK actually does have code for stronger 256-bit encryption, but it’s disabled unless you install the JCE Unlimited Strength Jurisdiction Policy Files.
I don’t even want to begin trying to explain the legal briar patch that makes this necessary.
However, not all cipher suites that are understood are necessarily allowed on the connection.
The getEnabledCipher Suites() method of SSLSocketFactory tells you which suites this socket is willing to use:
The actual suite used is negotiated between the client and server at connection time.
It’s possible that the client and the server won’t agree on any suite.
It’s also possible that although a suite is enabled on both client and server, one or the other or both won’t have the keys and certificates needed to use the suite.
In either case, the createSocket() method will throw an SSLException, a subclass of IOException.
The argument to this method should be a list of the suites you want to use.
Each name has an algorithm divided into four parts: protocol, key exchange algorithm, encryption algorithm, and checksum.
You should probably avoid any of these suites that contain NULL, ANON, or EXPORT in their names unless you want the NSA to read your messages.
Most others are subject to attacks of varying levels of severity.
Besides key lengths, there’s an important difference between DES/AES and RC4-based ciphers.
If 64 bits aren’t available, the encoder has to pad the input with extra bits.
This isn’t a problem for file transfer applications such as secure HTTP and FTP, where more or less all the data is available at once.
However, it’s problematic for user-centered protocols such as chat and Telnet.
RC4 is a stream cipher that can encrypt one byte at a time and is more appropriate for protocols that may need to send a single byte at a time.
For example, let’s suppose that Edgar has some fairly powerful parallel computers at his disposal and can quickly break any encryption that’s 64 bits or less and that Gus and Angela know this.
Furthermore, they suspect that Edgar can blackmail one of their ISPs or the phone company into letting him tap the line, so they want to avoid anonymous connections that are vulnerable to man-in-the-middle attacks.
This code fragment limits their connection to that one suite:
If the other side of the connection doesn’t support this encryption protocol, the socket will throw an exception when they try to read from or write to it, thus ensuring that no confidential information is accidentally transmitted over a weak channel.
Event Handlers Network communications are slow compared to the speed of most computers.
The necessary key generation and setup for a secure connection can easily take several seconds.
Consequently, you may want to deal with the connection asynchronously.
Session Management SSL is commonly used on web servers, and for good reason.
Web connections tend to be transitory; every page requires a separate socket.
For instance, checking out of Amazon.com on its secure server requires seven separate page loads, more if you have to edit an address or choose gift wrapping.
Imagine if every one of those pages took an extra 10 seconds or more to negotiate a secure connection.
Because of the high overhead involved in handshaking between two hosts for secure communications, SSL allows sessions to be established that extend over multiple sockets.
Different sockets within the same session use the same set of public and private keys.
Amazon.com takes seven sockets, all seven will be established within the same session and use the same keys.
Only the first socket within that session will have to endure the overhead of key generation and exchange.
As a programmer using JSSE, you don’t need to do anything extra to take advantage of sessions.
If you open multiple secure sockets to one host on one port within a reasonably short period of time, JSSE will reuse the session’s keys automatically.
However, in highsecurity applications, you may want to disallow session-sharing between sockets or force reauthentication of a session.
In the JSSE, sessions are represented by instances of the SSLSession interface; you can use the methods of this interface to check the times the session was created and last accessed, invalidate the session, and get various information about the session:
The getSession() method of SSLSocket returns the Session this socket belongs to:
It is more secure to renegotiate the key for each and every transaction.
If you’ve got really spectacular hardware and are trying to protect your systems from an equally determined, rich, motivated, and competent adversary, you may want to avoid sessions.
On rare occasions, you may even want to reauthenticate a connection (i.e., throw away all the certificates and keys that have previously been agreed to and start over with a new session)
Client Mode It’s a rule of thumb that in most secure communications, the server is required to authenticate itself using the appropriate certificate.
That is, when I buy a book from Amazon using its secure server, it has to prove to my browser’s satisfaction that it is indeed Amazon and not Joe Random Hacker.
For the most part, this is as it should be, because purchasing and installing the trusted certificates necessary for authentication is a fairly user-hostile experience that readers shouldn’t have to go through just to buy the latest Nutshell Handbook.
To avoid problems like this, sockets can be required to authenticate themselves.
This strategy wouldn’t work for a service open to the general public.
However, it might be reasonable in certain internal, high-security applications.
The setUseClientMode() method determines whether the socket needs to use authentication in its first handshake.
It can be used for both client- and server-side sockets.
However, when true is passed in, it means the socket is in client mode (whether it’s on the client side or not) and will not offer to authenticate itself.
When false is passed, it will try to authenticate itself:
This property can be set only once for any given socket.
The getUseClientMode() method simply tells you whether this socket will use authentication in its first handshake:
Creating Secure Server Sockets Secure client sockets are only half of the equation.
If that were all there was to creating secure server sockets, they would be quite straightforward and simple to use.
To get encryption as well, server-side secure sockets require more initialization and setup.
The details vary from JSSE implementation to JSSE implementation, but to create a secure server socket in the reference implementation, you have to:
Create a KeyManagerFactory for the type of key material you’ll be using.
Fill the KeyStore object with keys and certificates; for instance, by loading them from the filesystem using the passphrase they’re encrypted with.
The last two can be null if you’re willing to accept the defaults.
Example 10-2 demonstrates this procedure with a complete SecureOrderTaker for accepting orders and printing them on System.out.
Of course, in a real application, you’d do something more interesting with the orders.
What this example doesn’t show you is how that file was created.
It was built with the keytool program that’s bundled with the JDK like this:
Enter key password for <ourstore> (RETURN if same as keystore password):
When this is finished, you’ll have a file named jnp4e.keys, which contains your public keys.
However, no one will believe that these are your public keys unless you have them certified by a trusted third party such as GeoTrust or GoDaddy.
If you just want to explore the JSSE before deciding whether to go through the hassle and expense of purchasing a verified certificate, Oracle includes a verified keystore file called testkeys, protected with the password “passphrase,” that has some JSSE samples.
Another approach is to use cipher suites that don’t require authentication.
These are not enabled by default because they’re vulnerable to a man-in-the-middle attack, but at least they allow you to write simple programs without paying money.
However, there are times when you need to adjust its behavior a little.
Like SSLSocket, SSLServerSocket provides methods to choose cipher suites, manage sessions, and establish whether clients are required to authenticate themselves.
Most of these methods are similar to the methods of the same name in SSLSocket.
The difference is that they work on the server side and set the defaults for sockets accepted by an SSLServerSocket.
In some cases, once an SSLSocket has been accepted, you can still use the methods of SSLSocket to configure that one socket rather than all sockets accepted by this SSLServerSocket.
Choosing the Cipher Suites The SSLServerSocket class has the same three methods for determining which cipher suites are supported and enabled as SSLSocket does:
These use the same suite names as the similarly named methods in SSLSocket.
The difference is that these methods apply to all sockets accepted by the SSLServerSocket rather than to just one SSLSocket.
For example, the following code fragment has the effect of enabling anonymous, unauthenticated connections on the SSLServerSocket server.
It relies on the names of these suites containing the string anon.
This is true for Oracle’s reference implementations, though there’s no guarantee that other implementers will follow this convention:
It looks at the name of every supported suite to see whether it contains the substring “anon.” If the suite name does contain this substring, the suite is added to a list of anonymous cipher suites.
Once the list of anonymous cipher suites is built, it’s combined in a new array with the previous list of enabled cipher suites.
The new array is then passed to setEnabledCipher Suites() so that both the previously enabled and the anonymous cipher suites can now be used.
Session Management Both client and server must agree to establish a session.
If the server disallows session creation, then a client that wants a session will still be able to connect.
It just won’t get a session and will have to handshake again for every socket.
Similarly, if the client refuses sessions but the server allows them, they’ll still be able to talk to each other but without sessions.
Client Mode The SSLServerSocket class has two methods for determining and specifying whether client sockets are required to authenticate themselves to the server.
By passing false, you specify that authentication is not required of clients.
The setUseClientMode() method allows a program to indicate that even though it has created an SSLServerSocket, it is and should be treated as a client in the communication with respect to authentication and other negotiations.
For example, in an FTP session, the client program opens a server socket to receive data from the server, but that doesn’t make it less of a client.
The getUseClientMode() method returns true if the SSLServerSocket is in client mode, false otherwise:
Furthermore, networking speeds are often referred to in kilo/mega/giga bits per second rather than bytes per second.
Here I’m reporting all numbers in bytes so I can compare hard drive, memory, and network bandwidths.
Compared to CPUs and memory or even disks, networks are slow.
A high-end modern PC is capable of moving data between the CPU and main memory at speeds of around six gigabytes per second.
And the speed across the public Internet is generally at least an order of magnitude smaller than what you see across a LAN.
CPUs, disks, and networks are all speeding up over time.
These numbers are all substantially higher than I reported in the third edition of this book 10 years ago.
Nonetheless, CPUs and disks are likely to remain several orders of magnitude faster than networks for the foreseeable future.
The last thing you want to do in these circumstances is make the blazingly fast CPU wait for the (relatively) molasses-slow network.
The traditional Java solution for allowing the CPU to race ahead of the network is a combination of buffering and multithreading.
Multiple threads can generate data for several different connections at once and store that data in buffers until the network is actually ready to send it; this approach works well for fairly simple servers and clients without extreme performance needs.
However, the overhead of spawning multiple threads and switching between them can be nontrivial.
On a large server that may be processing thousands of requests a second, you may not want to assign a thread to each connection.
It’s faster if one thread can take responsibility for multiple connections, pick one that’s ready to receive data, fill it with as much data as that connection can manage as quickly as possible, then move on to the next ready connection.
To work well, this approach needs to be supported by the underlying operating system.
Fortunately, pretty much every modern operating system you’re likely to be using as a high-volume server supports such nonblocking I/O.
However, it might not be well supported on some client systems of interest, such as tablets, cell phones, and the like.
Indeed, the java.nio package that provides this support is not part of any current or planned Java ME profiles, though it is found in Android.
However, the whole new I/O API is designed for and only really matters on servers, which is why I haven’t done more than allude to it until we began talking about servers.
Client and even peer-to-peer systems rarely need to process so many simultaneous connections that multithreaded, stream-based I/O becomes a noticeable bottleneck.
Are there any situations in which asynchronous I/O does beat classic I/O? Maybe.
The one situation I can still imagine is a server that needs to support a colossal number of long-lived, simultaneous connections, say 10,000+, but where each client doesn’t send very much data very frequently.
For instance, imagine a central server in the home office collecting transactions from each cash register in a nationwide chain of convenience stores.
This scenario is tailor-made for NIO, and can probably be implemented much more efficiently with asynchronous or nonblocking on-demand processing in just a few threads.
An Example Client Although the new I/O APIs aren’t specifically designed for clients, they do work for them.
I’m going to begin with a client program using the new I/O APIs because it’s a little simpler.
In particular, many clients can be implemented with one connection at a time, so I can introduce channels and buffers before talking about selectors and nonblocking I/O.
A simple client for the character generator protocol defined in RFC 864 will demonstrate the basics.
When a client connects, the server sends a continuous sequence of characters until the client disconnects.
The RFC does not specify which character sequence to send, but recommends that the server use a recognizable pattern.
I picked this protocol for the examples in this chapter because both the protocol for transmitting the data and the algorithm to generate the data are simple enough that they won’t obscure the I/O.
However, chargen can transmit a lot of data over a relatively few connections and quickly saturate a network.
It’s thus a good candidate for the new I/O APIs.
Chargen is not commonly used these days, and may be blocked by local firewalls even if it’s turned on.
It’s vulnerable to a “ping-pong” denialof-service attack, in which spoofed Internet packets cause two hosts to spew an unlimited amount of data at each other.
Furthermore, because it’s almost infinitely asymmetric—the server sends an unlimited amount of data in response to the smallest of client requests—it’s very easy for even a few dozen compromised hosts, much less a large botnet, to convince a chargen server to saturate its local bandwidth.
For example, this fragment connects the channel to rama.poly.edu on port 19:
The channel is opened in blocking mode, so the next line of code won’t execute until the connection is established.
If the connection can’t be established, an IOException is thrown.
If this were a traditional client, you’d now ask for the socket’s input and/or output streams.
With a channel you write directly to the channel itself.
The channel fills this buffer with the data it reads from the socket.
It returns the number of bytes it successfully read and stored in the buffer:
By default, this will read at least one byte or return –1 to indicate the end of the data, exactly as an InputStream does.
It will often read more bytes if more bytes are available to be read.
Shortly you’ll see how to put this client in nonblocking mode where it will return 0 immediately if no bytes are available, but for the moment this code blocks just like an InputStream.
As you could probably guess, this method can also throw an IOException if anything goes wrong with the read.
There are ways to extract a byte array from a ByteBuffer that can then be written on a traditional OutputStream such as System.out.
However, it’s more informative to stick with a pure, channel-based solution.
Such a solution requires wrapping the OutputStream System.out in a channel using the Channels utility class, specifically, its newChannel() method:
You can then write the data that was read onto this output channel connected to System.out.
However, before you do that, you have to flip the buffer so that the output channel starts from the beginning of the data that was read rather than the end:
You don’t have to tell the output channel how many bytes to write.
However, in general, the output channel is not guaranteed to write all the bytes in the buffer.
In this specific case, though, it’s a blocking channel and it will either do so or throw an IOException.
You shouldn’t create a new buffer for each read and write.
You’ll need to clear the buffer before reading into it again:
Flipping leaves the data in the buffer intact, but prepares it for writing rather than reading.
The old data is still present; it’s not overwritten, but it will be overwritten with new data read from the source as soon as possible.
Because chargen is by design an endless protocol, you’ll need to kill the program using Ctrl-C.
So far, this is just an alternate vision of a program that could have easily been written using streams.
The really new feature comes if you want the client to do something besides copying all input to output.
You can run this connection in either blocking or nonblocking mode in which read() returns immediately even if no data is available.
This allows the program to do something else before it attempts to read.
It doesn’t have to wait for a slow network connection.
In nonblocking mode, read() may return 0 because it doesn’t read anything.
There’s not a lot of call for this in a one-connection client like this one.
Perhaps you could check to see if the user has done something to cancel input, for example.
However, as you’ll see in the next section, when a program is processing multiple connections, this enables code to run very quickly on the fast connections and more slowly on the slow ones.
Each connection gets to run at its own speed without being held up behind the slowest driver on the one-lane road.
An Example Server Clients are well and good, but channels and buffers are really intended for server systems that need to process many simultaneous connections efficiently.
Handling servers requires a third new piece in addition to the buffers and channels used for the client.
Specifically, you need selectors that allow the server to find all the connections that are ready to receive output or send input.
To demonstrate the basics, this example implements a simple server for the character generator protocol.
Initially, this channel is not actually listening on any port.
To bind it to a port, retrieve its ServerSocket peer object with the socket() method and then use the bind() method on that peer.
For example, this code fragment binds the channel to a server socket on port 19:
As with regular server sockets, binding to port 19 requires you to be root on Unix (including Linux and Mac OS X)
Nonroot users can only bind to ports 1024 and higher.
To accept one, call the accept() method, which returns a SocketChannel object:
On the server side, you’ll definitely want to make the client channel nonblocking to allow the server to process multiple simultaneous connections:
By default, this accept() method blocks until there’s an incoming connection, like the accept() method of ServerSocket.
A nonblocking accept() returns null almost immediately if there are no incoming connections.
There are now two open channels: a server channel and a client channel.
Furthermore, processing the server channel will create more open client channels.
In the traditional approach, you assign each connection a thread, and the number of threads climbs rapidly as clients connect.
Instead, in the new I/O API, you create a Selector that enables the program to iterate over all the connections that are ready to be processed.
To construct a new Selector, just call the static Selector.open() factory method:
Next, you need to register each channel with the selector that monitors it using the channel’s register() method.
When registering, specify the operation you’re interested in using a named constant from the SelectionKey class.
For the server socket, the only operation of interest is OP_ACCEPT; that is, is the server socket channel ready to accept a new connection?
However, you’re only going to need to use that key for the client channels, because there can be more than one of them.
This is normally used to hold an object that indicates the current state of the connection.
In this case, you can store the buffer that the channel writes onto the network.
Fill an array with the data that will be copied into each buffer.
Rather than writing to the end of the buffer, and then rewinding to the beginning of the buffer and writing again, it’s easier just to start with two sequential copies of the data so every line is available as a contiguous sequence in the array:
Because this array will only be read from after it’s been initialized, you can reuse it for multiple channels.
However, each channel will get its own buffer filled with the contents of this array.
You’ll stuff the buffer with the first 72 bytes of the rotation array, then add a carriage return/linefeed pair to break the line.
Then you’ll flip the buffer so it’s ready for draining, and attach it to the channel’s key:
To check whether anything is ready to be acted on, call the selector’s select() method.
For a long-running server, this normally goes in an infinite loop:
Assuming the selector does find a ready channel, its selectedKeys() method returns a java.util.Set containing one SelectionKey object for each ready channel.
Removing the key from the set tells the Selector that you’ve dealt with it, and the Selector doesn’t need to keep giving it back every time you call select()
The Selec tor will add the channel back into the ready set when select() is called again if the channel becomes ready again.
It’s really important to remove the key from the ready set here, though.
If the ready channel is the server channel, the program accepts a new socket channel and adds it to the selector.
If the ready channel is a socket channel, the program writes as much of the buffer as it can onto the channel.
If no channels are ready, the selector waits for one.
In this case, it’s easy to tell whether a client or a server channel has been selected because the server channel will only be ready for accepting and the client channels will only be.
Both of these are I/O operations, and both can throw IOExceptions for a variety of reasons, so you’ll want to wrap this all in a try block:
Retrieve the key’s attachment, cast it to Byte Buffer, and call hasRemaining() to check whether there’s any unwritten data left in the buffer.
Otherwise, refill the buffer with the next line of data from the rotation array and write that.
The algorithm that figures out where to grab the next line of data relies on the characters being stored in the rotation array in ASCII order.
From this number you subtract the space character (32) because that’s the first character in the rotation array.
This tells you which index in the array the buffer currently starts at.
You add 1 to find the start of the next line and refill the buffer.
In the chargen protocol, the server never closes the connection.
Example 11-2 puts this all together in a complete chargen server that processes multiple connections efficiently in a single thread.
There are situations where you might still want to use multiple threads, especially if different operations have different priorities.
For instance, you might want to accept new connections in one high-priority thread and service existing connections in a lower-priority thread.
However, you’re no longer required to have a 1:1 ratio between threads and connections, which improves the scalability of servers written in Java.
It may also be important to use multiple threads for maximum performance.
Multiple threads allow the server to take advantage of multiple CPUs.
Even with a single CPU, it’s often a good idea to separate the accepting thread from the processing threads.
The thread pools discussed in Chapter 3 are still relevant even with the new I/O model.
The thread that accepts the connections can add the connections it’s accepted into the queue for processing by the threads in the pool.
This is still faster than doing the same thing without selectors because select() ensures you’re never wasting any time on connections that aren’t ready to receive data.
On the other hand, the synchronization issues here are tricky, so don’t attempt this until profiling proves there is a bottleneck.
Buffers In Chapter 2, I recommended that you always buffer your streams.
Almost nothing has a greater impact on the performance of network programs than a big enough buffer.
In the new I/O model, you’re no longer given the choice.
Instead of writing data onto output streams and reading data from input streams, you read and write data from buffers.
Buffers may appear to be just an array of bytes as in buffered streams.
However, native implementations can connect them directly to hardware or memory or use other, very efficient implementations.
From a programming perspective, the key difference between streams and channels is that streams are byte-based whereas channels are block-based.
A stream is designed to provide one byte after the other, in order.
However, the basic notion is to pass data one byte at a time.
By contrast, a channel passes blocks of data around in buffers.
Before bytes can be read from or written to a channel, the bytes have to be stored in a buffer, and the data is written or read one buffer at a time.
The second key difference between streams and channels/buffers is that channels and buffers tend to support both reading and writing on the same object.
For instance, a channel that points to a file on a CD-ROM can be read but not written.
A channel connected to a socket that has shutdown input could be written but not read.
However, more often than not network programs can read from and write to the same channels.
Without worrying too much about the underlying details (which can vary hugely from one implementation to the next, mostly as a result of being tuned very closely to the host operating system and hardware), you can think of a buffer as a fixed-size list of elements of a particular, normally primitive data type, like an array.
The methods in each subclass have appropriately typed return values and argument lists.
For example, the DoubleBuffer class has methods to put and get doubles.
The IntBuffer class has methods to put and get ints.
The common Buffer superclass only provides methods that don’t need to know the type of the data the buffer contains.
Network programs use Byte Buffer almost exclusively, although occasionally one program might use a view that overlays the ByteBuffer with one of the other types.
Besides its list of data, each buffer tracks four key pieces of information.
All buffers have the same methods to set and get these values, regardless of the buffer’s type: position.
The next location in the buffer that will be read from or written to.
This starts counting at 0 and has a maximum value equal to the size of the buffer.
It can be set or gotten with these two methods:
This is set when the buffer is created and cannot be changed thereafter.
You cannot write or read at or past this point without changing the limit, even if the buffer has more capacity.
It is set at the current position by invoking the mark() method.
The current position is set to the marked position by invoking reset():
If the position is set below an existing mark, the mark is discarded.
Unlike reading from an InputStream, reading from a buffer does not actually change the buffer’s data in any way.
It’s possible to set the position either forward or backward so you can start reading from a particular place in the buffer.
Similarly, a program can adjust the limit to control the end of the data that will be read.
The common Buffer superclass also provides a few other methods that operate by reference to these common properties.
The clear() method “empties” the buffer by setting the position to zero and the limit to the capacity.
However, the clear() method does not remove the old data from the buffer.
It’s still present and could be read using absolute get methods or changing the limit and position again.
The rewind() method sets the position to zero, but does not change the limit:
The flip() method sets the limit to the current position and the position to zero:
It is called when you want to drain a buffer you’ve just filled.
Finally, there are two methods that return information about the buffer but don’t change it.
The remaining() method returns the number of elements in the buffer between the current position and the limit.
The hasRemaining() method returns true if the number of remaining elements is greater than zero:
Creating Buffers The buffer class hierarchy is based on inheritance but not really on polymorphism, at least not at the top level.
You normally need to know whether you’re dealing with an.
IntBuffer or a ByteBuffer or a CharBuffer or something else.
You write code to one of these subclasses, not to the common Buffer superclass.
Buffers that are prefilled with data are created by wrap methods.
The allocate methods are often useful for input, and the wrap methods are normally used for output.
The basic allocate() method simply returns a new, empty buffer with a specified fixed capacity.
For example, these lines create byte and int buffers, each with a size of 100:
The cursor is positioned at the beginning of the buffer (i.e., the position is 0)
A buffer created by allocate() will be implemented on top of a Java array, which can be accessed by the array() and arrayOffset() methods.
For example, you could read a large chunk of data into a buffer using a channel and then retrieve the array from the buffer to pass to other methods:
The array() method does expose the buffer’s private data, so use it with caution.
Changes to the backing array are reflected in the buffer and vice versa.
The normal pattern here is to fill the buffer with data, retrieve its backing array, and then operate on the array.
This isn’t a problem as long as you don’t write to the buffer after you’ve started working with the array.
The ByteBuffer class (but not the other buffer classes) has an additional allocateDir ect() method that may not create a backing array for the buffer.
The VM may implement a directly allocated ByteBuffer using direct memory access to the buffer on an Ethernet card, kernel memory, or something else.
It’s not required, but it’s allowed, and this can improve performance for I/O operations.
From an API perspective, allocate Direct() is used exactly like allocate():
Invoking array() and arrayOffset() on a direct buffer will throw an UnsupportedO perationException.
Direct buffers may be faster on some virtual machines, especially if the buffer is large (roughly a megabyte or more)
However, direct buffers are more expensive to create than indirect buffers, so they should only be allocated when the buffer is expected to be around for a while.
As is generally true for most performance advice, you probably shouldn’t even consider using direct buffers until measurements prove performance is an issue.
Wrapping If you already have an array of data that you want to output, you’ll normally wrap a buffer around it, rather than allocating a new buffer and copying its components into the buffer one at a time.
Here, the buffer contains a reference to the array, which serves as its backing array.
Again, changes to the array are reflected in the buffer and vice versa, so don’t wrap the array until you’re finished with it.
Recall that each buffer has a curent position identified by the position() method that is somewhere between zero and the number of elements in the buffer, inclusive.
The buffer’s position is incremented by one when an element is read from or written to the buffer.
For example, suppose you allocate a CharBuffer with capacity 12, and fill it by putting five characters into it:
You can only fill the buffer up to its capacity.
Before you can read the data you wrote in out again, you need to flip the buffer:
Buffer classes also have absolute methods that fill and drain at specific positions within the buffer without updating the position.
For example, using absolute methods, you can put the same text into a buffer like this:
However, you no longer need to flip before reading it out, because the absolute methods don’t change the position.
Bulk Methods Even with buffers, it’s often faster to work with blocks of data rather than filling and draining one element at a time.
The different buffer classes have bulk methods that fill and drain an array of their element type.
For example, ByteBuffer has put() and get() methods that fill and drain a ByteBuff er from a preexisting byte array or subarray:
These put methods insert the data from the specified array or subarray, beginning at the current position.
The get methods read the data into the argument array or subarray beginning at the current position.
Both put and get increment the position by the length of the array or subarray.
Data Conversion All data in Java ultimately resolves to bytes.
Any primitive data type—int, double, float, etc.—can be written as bytes.
Any sequence of bytes of the right length can be interpreted as a primitive datum.
For example, any sequence of four bytes corresponds to an int or a float (actually both, depending on how you want to read it)
A sequence of eight bytes corresponds to a long or a double.
The ByteBuffer class (and only the ByteBuffer class) provides relative and absolute put methods that fill a buffer with the bytes corresponding to an argument of primitive type (except boolean) and relative and absolute get methods that read the appropriate number of bytes to form a new primitive datum:
In the world of new I/O, these methods do the job performed by DataOutputStream and DataInputStream in traditional I/O.
These methods do have an additional ability not present in DataOutputStream and DataInputStream.
You can choose whether to interpret the byte sequences as big-endian or little-endian ints, floats, doubles, and so on.
The two order() methods inspect and set the buffer’s byte order using the named constants in the ByteOrder class.
For example, you can change the buffer to little-endian interpretation like so:
Suppose instead of a chargen protocol, you want to test the network by generating binary data.
This test can highlight problems that aren’t apparent in the ASCII chargen protocol, such as an old gateway configured to strip off the high-order bit of every byte, throw away every 230 byte, or put into diagnostic mode by an unexpected sequence of control characters.
I’ve seen variations on all of these at one time or another.
You could test the network for such problems by sending out every possible int.
This would, after almost 4.3 billion iterations, test every possible four-byte sequence.
On the receiving end, you could easily test whether the data received is expected with a simple numeric comparison.
If any problems are found, it is easy to tell exactly where they occurred.
In other words, this protocol (call it Intgen) behaves like this:
The server will eventually wrap around into the negative numbers.
The server would store the current int in a four-byte-long direct ByteBuffer.
When the channel becomes available for writing, the buffer is drained onto the channel.
Then the buffer is rewound and the content of the buffer is read with getInt()
The program then clears the buffer, increments the previous value by one, and fills the buffer with the new value using putInt()
Finally, it flips the buffer so it will be ready to be drained the next time the channel becomes writable.
View Buffers If you know the ByteBuffer read from a SocketChannel contains nothing but elements of one particular primitive data type, it may be worthwhile to create a view buffer.
Changes to the view buffer are reflected in the underlying buffer and vice versa.
However, each buffer has its own independent limit, capacity, mark, and position.
View buffers are created with one of these six methods in ByteBuffer:
This protocol is only going to read ints, so it may be helpful to use an IntBuffer rather than a ByteBuffer.
For variety, this client is synchronous and blocking, but it still uses channels and buffers.
Although you can fill and drain the buffers using the methods of the IntBuffer class exclusively, data must be read from and written to the channel using the original ByteBuffer of which the IntBuffer is a view.
The SocketCh annel class only has methods to read and write ByteBuffers.
It cannot read or write any other kind of buffer.
This also means you need to clear the ByteBuffer on each pass through the loop or the buffer will fill up and the program will halt.
The positions and limits of the two buffers are independent and must be considered separately.
Finally, if you’re working in nonblocking mode, be careful that all the data in the underlying ByteBuffer is drained before reading or writing from the overlaying view buffer.
Nonblocking mode provides no guarantee that the buffer will still be aligned on an int, double, or char.
It’s completely possible for a nonblocking channel to write half the bytes of an int or a double.
When using nonblocking I/O, be sure to check for this problem before putting more data in the view buffer.
If it weren’t for invocation chaining, these six methods could have been replaced by one method in the common Buffer superclass.
Compacting shifts any remaining data in the buffer to the start of the buffer, freeing up more space for elements.
Any data that was in those positions will be overwritten.
The buffer’s position is set to the end of the data so it’s ready for writing more data.
Compacting is an especially useful operation when you’re copying—reading from one channel and writing the data to another using nonblocking I/O.
You can read some data into a buffer, write the buffer out again, then compact the data so all the data that wasn’t written is at the beginning of the buffer, and the position is at the end of the data remaining in the buffer, ready to receive more data.
This allows the reads and writes to be interspersed more or less at random with only one buffer.
Several reads can take place in a row, or several writes follow consecutively.
If the network is ready for immediate output but not input (or vice versa), the program can take advantage of that.
This technique can be used to implement an echo server as shown in Example 11-5
The echo protocol simply responds to the client with whatever data the client sent.
Also like chargen, echo relies on the client to close the connection.
Unlike chargen, however, an echo server must both read and write from the connection.
One thing I noticed while writing and debugging this program: the buffer size makes a big difference, although perhaps not in the way you might think.
If the buffer is large enough to hold complete test cases without being flipped or drained, it’s very easy to not notice that the buffer isn’t being flipped or compacted at the right times because the test cases never actually need to do that.
Before shipping your program, try turning the buffer size down to something significantly lower than the input you’re expecting.
This test degrades performance, so you shouldn’t ship with such a ridiculously small buffer, but you absolutely should test your code with small buffers to make sure it behaves properly when the buffer fills up.
Duplicating Buffers It’s often desirable to make a copy of a buffer to deliver the same information to two or more channels.
The duplicate() methods in each of the six typed buffer classes do this:
The duplicated buffers share the same data, including the same backing array if the buffer is indirect.
Changes to the data in one buffer are reflected in the other buffer.
Thus, you should mostly use this method when you’re only going to read from the buffers.
Otherwise, it can be tricky to keep track of where the data is being modified.
The original and duplicated buffers do have independent marks, limits, and positions even though they share the same data.
One buffer can be ahead of or behind the other buffer.
Duplication is useful when you want to transmit the same data over multiple channels, roughly in parallel.
You can make duplicates of the main buffer for each channel and.
For example, recall the single-file HTTP server in Example 9-10
Every time a client connects, the program makes a duplicate of this buffer just for that channel, which is stored as the channel’s attachment.
Without duplicates, one client has to wait until the other finishes so the original buffer can be rewound.
The constructors set up the data to be sent along with an HTTP header that includes information about content length and content encoding.
The header and the body of the response are stored in a single ByteBuffer so that they can be blasted to clients very quickly.
However, although all clients receive the same content, they may not receive it at the same time.
Different parallel clients will be at different locations in the file.
This is why we duplicate the buffer, so each channel has its own buffer.
The overhead is small because all channels do share the same content.
All incoming connections are handled by a single Selector in the run() method.
The initial setup here is very similar to the earlier chargen server.
When a SocketChannel is accepted, the same Selector object is registered with it.
Initially it’s registered for reading because the HTTP protocol requires the client to send a request before the server responds.
The program reads as many bytes of input as it can up to 4K.
Then it resets the interest operations for the channel to writability.
A more complete server would actually attempt to parse the HTTP header request here and choose the file to send based on that information.
Next, the content buffer is duplicated and attached to the channel.
The next time the program passes through the while loop, this channel should be ready to receive data (or if not the next time, the time after that; the asynchronous nature of the connection means we won’t see it until it’s ready)
At this point, you get the buffer out of the attachment, and write as much of the buffer as you can onto the channel.
It’s no big deal if you don’t write it all this time.
You’ll just pick up where you left off the next pass through the loop.
Although many incoming clients might result in the creation of many buffer objects, the real overhead is minimal because they’ll all share the same underlying data.
The name of the file to be served is read from the first command-line argument.
If no file is specified or the file cannot be opened, an error message is printed and the program exits.
A reasonable guess is made about the content type of the file, and that guess is stored in the contentType variable.
Next, the port number is read from the second command-line argument.
The encoding is read from the third command-line argument if present.
Slicing Buffers Slicing a buffer is a slight variant of duplicating.
Slicing also creates a new buffer that shares data with the old buffer.
However, the slice’s zero position is the current position of the original buffer, and its capacity only goes up to the source buffer’s limit.
That is, the slice is a subsequence of the original buffer that only contains the elements from the current position to the limit.
Rewinding the slice only moves it back to the position of the original buffer when the slice was created.
The slice can’t see anything in the original buffer before that point.
Again, there are separate slice() methods in each of the six typed buffer classes:
This is useful when you have a long buffer of data that is easily divided into multiple parts such as a protocol header followed by the data.
You can read out the header, then slice the buffer and pass the new buffer containing only the data to a separate method or class.
Marking and Resetting Like input streams, buffers can be marked and reset if you want to reread some data.
Unlike input streams, this can be done to all buffers, not just some of them.
For a change, the relevant methods are declared once in the Buffer superclass and inherited by all the various subclasses:
The mark is also unset when the position is set to a point before the mark.
Object Methods The buffer classes all provide the usual equals(), hashCode(), and toString() methods.
They have the same type (e.g., a ByteBuffer is never equal to an IntBuffer but may be equal to another ByteBuffer)
They have the same number of elements remaining in the buffer.
The remaining elements at the same relative positions are equal to each other.
Note that equality does not consider the buffers’ elements that precede the position, the buffers’ capacity, limits, or marks.
For example, this code fragment prints true even though the first buffer is twice the size of the second:
The hashCode() method is implemented in accordance with the contract for equality.
That is, two equal buffers will have equal hash codes and two unequal buffers are very unlikely to have equal hash codes.
However, because the buffer’s hash code changes every time an element is added to or removed from the buffer, buffers do not make good hash table keys.
Comparison is implemented by comparing the remaining elements in each buffer, one by one.
If all the corresponding elements are equal, the buffers are equal.
If one buffer runs out of elements before an unequal element is found and the other buffer still has elements, the shorter buffer is considered to be less than the longer buffer.
The toString() method returns strings that look something like this:
The notable exception is CharBuffer, which returns a string containing the remaining chars in the buffer.
Channels Channels move blocks of data into and out of buffers to and from various I/O sources such as files, sockets, datagrams, and so forth.
The channel class hierarchy is rather convoluted, with multiple interfaces and many optional operations.
SocketChannel The SocketChannel class reads from and writes to TCP sockets.
The data must be encoded in ByteBuffer objects for reading and writing.
Each SocketChannel is associated with a peer Socket object that can be used for advanced configuration, but this requirement can be ignored for applications where the default options are fine.
Instead, you create a new SocketChannel object using one of the two static open() methods:
This method blocks (i.e., the method will not return until the connection is made or an exception is thrown)
It creates an initially unconnected socket that must be connected later using the connect() method.
You might choose this more roundabout approach in order to configure various options on the channel and/or the socket before connecting.
Specifically, use this approach if you want to open the channel without blocking:
With a nonblocking channel, the connect() method returns immediately, even before the connection is established.
The program can do other things while it waits for the operating system to finish the connection.
However, before it can actually use the connection, the program must call finishConnect():
If the connection is now ready for use, finishConnect() returns true.
If the connection has not been established yet, finishConnect() returns false.
Finally, if the connection could not be established, for instance because the network is down, this method throws an exception.
If the program wants to check whether the connection is complete, it can call these two methods:
The isConnected() method returns true if the connection is open.
The isConnection Pending() method returns true if the connection is still being set up but is not yet open.
To read from a SocketChannel, first create a ByteBuffer the channel can store data in.
The channel fills the buffer with as much data as it can, then returns the number of bytes it put there.
When it encounters the end of stream, the channel fills the buffer with any remaining bytes and then returns –1 on the next call to read()
If the channel is blocking, this method will read at least one byte or return –1 or throw an exception.
Because the data is stored into the buffer at the current position, which is updated automatically as more data is added, you can keep passing the same buffer to the read() method until the buffer is filled.
For example, this loop will read until the buffer is filled or the end of stream is detected:
It is sometimes useful to be able to fill several buffers from one source.
These two methods accept an array of ByteBuffer objects as arguments and fill each one in turn:
The second method fills length buffers, starting with the one at offset.
To fill an array of buffers, just loop while the last buffer in the list has space remaining.
In order to write, simply fill a ByteBuffer, flip it, and pass it to one of the write methods, which drains it while copying the data onto the output—pretty much the reverse of the reading process.
The basic write() method takes a single buffer as an argument:
As with reads (and unlike OutputStreams), this method is not guaranteed to write the complete contents of the buffer if the channel is nonblocking.
Again, however, the cursor-based nature of buffers enables you to easily call this method again and again until the buffer is fully drained and the data has been completely written:
It is often useful to be able to write data from several buffers onto one socket.
For example, you might want to store the HTTP header in one buffer and the HTTP body in another buffer.
The implementation might even fill the two buffers simultaneously using two threads or overlapped I/O.
These two methods accept an array of ByteBuffer objects as arguments, and drain each one in turn:
The second method drains length buffers, starting with the one at offset.
Closing Just as with regular sockets, you should close a channel when you’re done with it to free up the port and any other resources it may be using:
Attempting to write data to or read data from a closed channel throws an exception.
If you’re uncertain whether a channel has been closed, check with isOpen():
Naturally, this returns false if the channel is closed, true if it’s open (close() and isOpen() are the only two methods declared in the Channel interface and shared by all channel classes)
Starting in Java 7, SocketChannel implements AutoCloseable, so you can use it in trywith-resources.
The only operation it supports is accepting a new incoming connection.
The class itself only declares four methods, of which accept() is the most important.
And finally, like all channels, it has a close() method that shuts down the server socket.
This method does not actually open a new server socket.
Before you can use it, you need to call the socket() method to get the corresponding peer ServerSocket.
At this point, you can configure any server options you like, such as the receive buffer size or the socket timeout, using the various setter methods in ServerSocket.
Then connect this ServerSocket to a SocketAddress for the port you want to bind to.
A factory method is used here rather than a constructor so that different virtual machines can provide different implementations of this class, more closely tuned to the local hardware and OS.
The open() method always returns an instance of the same class when running in the same virtual machine.
In blocking mode, the accept() method waits for an incoming connection.
It then accepts that connection and returns a SocketChannel object connected to the remote client.
The thread cannot do anything until a connection is made.
This strategy might be appropriate for simple servers that can respond to each request immediately.
In this case, the ac cept() method returns null if there are no incoming connections.
Nonblocking mode is more appropriate for servers that need to do a lot of work for each connection and thus may want to process multiple requests in parallel.
Nonblocking mode is normally used in conjunction with a Selector.
The accept() method is declared to throw an IOException if anything goes wrong.
The security manager refused to allow this application to bind to the requested port.
The Channels Class Channels is a simple utility class for wrapping channels around traditional I/O-based streams, readers, and writers, and vice versa.
It’s useful when you want to use the new I/O model in one part of a program for performance, but still interoperate with legacy APIs that expect streams.
It has methods that convert from streams to channels and methods that convert from channels to streams, readers, and writers:
ServerSock etChannel implements neither of these because you can’t read from or write to it.
For example, all current XML APIs use streams, files, readers, and other traditional I/O APIs to read the XML document.
If you’re writing an HTTP server designed to process SOAP requests, you may want to read the HTTP request bodies using channels and parse the XML using SAX for performance.
In this case, you’d need to convert these channels into streams before passing them to XMLReader’s parse() method:
The data read or written is further processed by a Future or a CompletionHandler.
The con nect() and accept() methods also execute asynchronously and return Futures.
For example, suppose a program needs to perform a lot of initialization at startup.
Some of that involves network connections that are going to take several seconds each.
You can start several asynchronous operations in parallel, then perform your local initializations, and then request the results of the network operations:
The advantage of this approach is that the network connections run in parallel while the program does other things.
When you’re ready to process the data from the network, but not before, you stop and wait for it by calling Future.get()
You could achieve the same effect with thread pools and callables, but this is perhaps a little simpler, especially if buffers are a natural fit for your application.
This approach fits the situation where you want to get results back in a very particular order.
However, if you don’t care about order, if you can process each network read independently of the others, then you may be better off using a CompletionHandler instead.
For example, imagine you’re writing a search engine web spider that feeds pages.
The generic CompletionHandler interface declares two methods: completed(), which is invoked if the read finishes successfully; and failed(), which is invoked on an I/O error.
For example, here’s a simple CompletionHandler that prints whatever it received on System.out:
When you read from the channel you pass a buffer, an attachment, and a Completion Handler to the read() method:
This is one way to push the data read from the network into the CompletionHandler where it can handle it.
Another common pattern is to make the CompletionHandler an anonymous inner class and the buffer a final local variable so it’s in scope inside the completion handler.
One thread can read and another thread can write simultaneously, though.
The options have the same meaning in the underlying TCP stack whether set on a socket or a channel.
However, the interface to these options is a little different.
Rather than individual methods for each supported option, the channel classes each have just three methods to get, set, and list the supported options:
The SocketOption class is a generic class specifying the name and type of each option.
The type parameter <T> determines whether the option is a boolean, Integer, or Net workInterface.
Example 11-7 is a simple program to list all supported socket options for the different types of network channels.
Here’s the output showing which options are supported by which types of channels, and what the default values are:
Readiness Selection For network programming, the second part of the new I/O APIs is readiness selection, the ability to choose a socket that will not block when read or written.
This is primarily of interest to servers, although clients running multiple simultaneous connections with several windows open—such as a web spider or a browser—can take advantage of it as well.
In order to perform readiness selection, different channels are registered with a Selec tor object.
The program can then ask the Selector object for the set of keys to the channels that are ready to perform the operation you want to perform without blocking.
Normally, a new selector is created by invoking the static factory method Selector.open():
The next step is to add channels to the selector.
There are no methods in the Selec tor class to add a channel.
The register() method is declared in the SelectableChan nel class.
Not all channels are selectable—in particular, FileChannels aren’t selectable —but all network channels are.
Thus, the channel is registered with a selector by passing the selector to one of the channel’s register methods:
This approach feels backward to me, but it’s not hard to use.
The first argument is the selector the channel is registering with.
The second argument is a named constant from the SelectionKey class identifying the operation the channel is registering for.
The SelectionKey class defines four named bit constants used to select the type of the operation:
Therefore, if a channel needs to register for multiple operations in the same selector (e.g., for both reading and writing on a socket), combine the constants with the bitwise or operator (|) when registering:
The optional third argument is an attachment for the key.
This object is often used to store state for the connection.
For example, if you were implementing a web server, you might attach a FileInputStream or FileChannel connected to the local file the server streams to the client.
After the different channels have been registered with the selector, you can query the selector at any time to find out which channels are ready to be processed.
Channels may be ready for some operations and not others.
For instance, a channel could be ready for reading but not writing.
They differ in how long they wait to find a ready channel.
It returns immediately if no connections are ready to be processed now:
The first method waits until at least one registered channel is ready to be processed before returning.
These methods are useful if your program doesn’t have anything to do when no channels are ready to be processed.
When you know the channels are ready to be processed, retrieve the ready channels using selectedKeys():
You iterate through the returned set, processing each SelectionKey in turn.
You’ll also want to remove the key from the iterator to tell the selector that you’ve handled it.
Otherwise, the selector will keep telling you about it on future passes through the loop.
Finally, when you’re ready to shut down the server or when you no longer need the selector, you should close it:
More importantly, it cancels all keys registered with the selector and interrupts up any threads blocked by one of this selector’s select methods.
The SelectionKey Class SelectionKey objects serve as pointers to channels.
They can also hold an object attachment, which is how you normally store the state for the connection on that channel.
SelectionKey objects are returned by the register() method when registering a channel with a selector.
The selectedKeys() method returns the same objects again inside a Set.
When retrieving a SelectionKey from the set of selected keys, you often first test what that key is ready to do.
In some cases, the selector is only testing for one possibility and will only return keys to do that one thing.
But if the selector does test for multiple readiness states, you’ll want to test which one kicked the channel into the ready state before operating on it.
It’s also possible that a channel is ready to do more than one thing.
Once you know what the channel associated with the key is ready to do, retrieve the channel with the channel() method:
If you’ve stored an object in the SelectionKey to hold state information, you can retrieve it with the attachment() method:
Finally, when you’re finished with a connection, deregister its SelectionKey object so the selector doesn’t waste any resources querying it for readiness.
However, this step is only necessary if you haven’t closed the channel.
Closing a channel automatically deregisters all keys for that channel in all selectors.
Similarly, closing a selector invalidates all keys in that selector.
Previous chapters discussed network applications that run on top of the TCP transport layer protocol.
If data is lost or damaged in transmission, TCP ensures that the data is resent.
If packets of data arrive out of order, TCP puts them back in the correct order.
If the data is coming too fast for the connection, TCP throttles the speed back so that packets won’t be lost.
A program never needs to worry about receiving data that is out of order or incorrect.
Establishing and tearing down TCP connections can take a fair amount of time, particularly for protocols such as HTTP, which tend to require many short transmissions.
The User Datagram Protocol (UDP) is an alternative transport layer protocol for sending data over IP that is very quick, but not reliable.
When you send UDP data, you have no way of knowing whether it arrived, much less whether different pieces of data arrived in the order in which you sent them.
The UDP Protocol The obvious question to ask is why anyone would ever use an unreliable protocol.
Surely, if you have data worth sending, you care about whether the data arrives correctly? Clearly, UDP isn’t a good match for applications like FTP that require reliable transmission of data over potentially unreliable networks.
However, there are many kinds of applications in which raw speed is more important than getting every bit right.
For example, in real-time audio or video, lost or swapped packets of data simply appear as static.
Static is tolerable, but awkward pauses in the audio stream, when TCP requests a retransmission or waits for a wayward packet to arrive, are unacceptable.
In other applications, reliability tests can be implemented in the application layer.
For example, if a client sends a short UDP request to a server, it may assume that the packet is lost if no response is returned within an established period of time; this is one way the Domain.
In fact, you could implement a reliable file transfer protocol using UDP, and many people have: Network File System (NFS), Trivial FTP (TFTP), and FSP, a more distant relative of FTP, all use UDP.
The latest version of NFS can use either UDP or TCP.
In these protocols, the application is responsible for reliability; UDP doesn’t take care of it (the application must handle missing or out-of-order packets)
This is a lot of work, but there’s no reason it can’t be done—although if you find yourself writing this code, think carefully about whether you might be better off with TCP.
The difference between TCP and UDP is often explained by analogy with the phone system and the post office.
When you dial a number, the phone is answered and a connection is established between the two parties.
As you talk, you know that the other party hears your words in the order in which you say them.
If the phone is busy or no one answers, you find out right away.
Most of the letters arrive, but some may be lost on the way.
The letters probably arrive in the order in which you sent them, but that’s not guaranteed.
The farther away you are from your recipient, the more likely it is that mail will be lost on the way or arrive out of order.
If this is a problem, you can write sequential numbers on the envelopes, then ask the recipients to arrange them in the correct order and send you mail telling you which letters arrived so that you can resend any that didn’t get there the first time.
However, you and your correspondent need to agree on this protocol in advance.
Both the phone system and the post office have their uses.
Although either one could be used for almost any communication, in some cases one is definitely superior to the other.
The past several chapters have all focused on TCP applications, which are more common than UDP applications.
However, UDP also has its place; in this chapter, we’ll look at what you can do with UDP.
If you want to go further, the next chapter describes multicasting over UDP.
A multicast socket is a fairly simple variation on a standard UDP socket.
Java’s implementation of UDP is split into two classes: DatagramPacket and Datagram Socket.
The DatagramPacket class stuffs bytes of data into UDP packets called datagrams and lets you unstuff datagrams that you receive.
To send data, you put the data in a DatagramPacket and send the packet using a DatagramSocket.
To receive data, you take a DatagramPacket object from a DatagramSocket and then inspect the contents of the packet.
In UDP, everything about a datagram, including the address to which it is directed, is included in the packet itself; the socket only needs to know the local port on which to listen or send.
This division of labor contrasts with the Socket and ServerSocket classes used by TCP.
First, UDP doesn’t have any notion of a unique connection between two hosts.
A single DatagramSocket can send data to and receive data from many independent hosts.
The socket isn’t dedicated to a single connection, as it is in TCP.
In fact, UDP doesn’t have any concept of a connection between two hosts; it only knows about individual datagrams.
Figuring out who sent what data is the application’s responsibility.
Second, TCP sockets treat a network connection as a stream: you send and receive data with input and output streams that you get from the socket.
All the data you stuff into a single datagram is sent as a single packet and is either received or lost as a group.
Given two packets, there is no way to determine which packet was sent first and which was sent second.
Instead of the orderly queue of data that’s necessary for a stream, datagrams try to crowd into the recipient as quickly as possible, like a crowd of people pushing their way onto a bus.
And occasionally, if the bus is crowded enough, a few packets, like people, may not squeeze on and will be left waiting at the bus stop.
As in “Reading from Servers with Sockets” on page Technology (NIST) and ask it for the current time.
Recall that the daytime server listens on port 13, and that the server sends the time in a human-readable format and closes the connection.
Now let’s see how to retrieve this same data programmatically using UDP.
The socket does not know the remote host or address.
By specifying port 0 you ask Java to pick a random available port for you, much as with server sockets.
Set a timeout on the connection using the setSoTimeout() method.
Timeouts are measured in milliseconds, so this statement sets the socket to time out after 10 seconds of nonresponsiveness:
Timeouts are even more important for UDP than TCP because many problems that would cause an IOException in TCP silently fail in UDP.
For example, if the remote host is not listening on the targeted port, you’ll never hear about it.
You’ll need two, one to send and one to receive.
For the daytime protocol it doesn’t matter what data you put in the packet, but you do need to tell it the remote host and remote port to connect to:
The packet that receives the server’s response just contains an empty byte array.
This needs to be large enough to hold the entire response.
If it’s too small, it will be silently truncated—1k should be enough space:
First send the packet over the socket and then receive the response:
Finally, extract the bytes from the response and convert them to a string you can show to the end user:
The constructor and send() and receive() methods can each throw an IOException, so you’ll usually wrap all this in a try block.
In Java 6 and earlier, you’ll want to explicitly close the socket in a finally block to release resources the socket holds:
Typical output is much the same as if you connected with TCP:
Begin by opening a datagram socket on a well-known port.
You can either use sudo to run the program or simply change the port to something 1024 or higher.
Next, create a packet into which to receive a request.
You need to supply both a byte array in which to store incoming data, the offset into the array, and the number of bytes to store.
When it does, Java fills the byte array with data and the receive() method returns.
This has four parts: the raw data to send, the number of bytes of the raw data to send, the host to send to, and the port on that host to address.
In this example, the raw data comes from a String form of the current time, and the host and the port are simply the host and port of the incoming packet:
Finally, send the response back over the same socket that received it:
Example 12-2 wraps this sequence up in a while loop, complete with logging and exception handling, so that it can process many incoming requests.
As you can see in this example, UDP servers tend not to be as multithreaded as TCP servers.
They usually don’t do a lot of work for any one client, and they can’t get blocked waiting for the other end to respond because UDP never reports errors.
Unless a lot of time-consuming work is required to prepare the response, an iterative approach works just fine for UDP servers.
The DatagramPacket Class UDP datagrams add very little to the IP datagrams they sit on top of.
The UDP header adds only eight bytes to the IP header.
The UDP header includes source and destination port numbers, the length of everything that follows the IP header, and an optional checksum.
Because port numbers are given as two-byte unsigned integers, 65,536 different possible UDP ports are available per host.
These are distinct from the 65,536 different TCP ports per host.
Because the length is also a two-byte unsigned integer, the number of bytes in a datagram is limited to 65,536 minus the eight bytes for the header.
The exact number depends on the size of the IP header.
The checksum field is optional and not used in or accessible from application layer programs.
If the checksum for the data fails, the native network software silently discards the datagram; neither the sender nor the receiver is notified.
Although the theoretical maximum amount of data in a UDP datagram is 65,507 bytes, in practice there is almost always much less.
And implementations are not required to accept datagrams with more than 576 total bytes, including data and headers.
Consequently, you should be extremely wary of any program that depends on sending or receiving UDP packets with more than 8K of data.
Most of the time, larger packets are simply truncated to 8K of data.
For maximum safety, the data portion of a UDP packet should be kept to 512 bytes or less, although this limit can negatively affect performance compared to larger packet sizes.
This is a problem for TCP datagrams too, but the stream-based API provided by Socket and ServerSocket completely shields programmers from these details.
In Java, a UDP datagram is represented by an instance of the DatagramPacket class:
This class provides methods to get and set the source or destination address from the IP header, to get and set the source or destination port, to get and set the data, and to get and set the length of the data.
The remaining header fields are inaccessible from pure Java code.
The Constructors DatagramPacket uses different constructors depending on whether the packet will be used to send data or to receive data.
Normally, constructors are overloaded to let you provide different kinds of information when you create an object, not to create objects of the same class that will be used in different contexts.
In this case, all six constructors take as arguments a byte array that holds the datagram’s data and the number of bytes in that array to use for the datagram’s data.
When you want to receive a datagram, these are the only arguments you provide.
When the socket receives a datagram from the network, it stores the datagram’s data in the DatagramPacket object’s buffer array, up to the length you specified.
The second set of DatagramPacket constructors is used to create datagrams you will send over the network.
Like the first, these constructors require a buffer array and a length, but they also require an address and port to which the packet will be sent.
In this case, you pass to the constructor a byte array containing the data you want to send and the destination address and port to which the packet is to be sent.
The DatagramSock et reads the destination address and port from the packet; the address and port aren’t stored within the socket, as they are in TCP.
These two constructors create new DatagramPacket objects for receiving data from the network:
If the first constructor is used, when a socket receives a datagram, it stores the datagram’s data part in buffer beginning at buffer[0] and continuing until the packet is completely stored or until length bytes have been written into the buffer.
For example, this code fragment creates a new DatagramPacket for receiving a datagram of up to 8,192 bytes:
If the second constructor is used, storage begins at buffer[offset] instead.
This is a RuntimeEx ception, so your code is not required to catch it.
It is OK to construct a DatagramPack et with a length less than buffer.length - offset.
In this case, at most the first length bytes of buffer will be filled when the datagram is received.
The constructor doesn’t care how large the buffer is and would happily let you create a DatagramPacket with megabytes of data.
In practice, however, many UDP-based protocols such as DNS and TFTP use packets with 512 bytes of data per datagram or fewer.
The largest data size in common usage is 8,192 bytes for NFS.
Almost all UDP datagrams you’re likely to encounter will have 8K of data or fewer.
In fact, many operating systems don’t support UDP datagrams with more than 8K of data and either truncate, split, or discard larger datagrams.
If a large datagram is too big and as a result the network truncates or drops it, your Java program won’t be notified of the problem.
Consequently, you shouldn’t create Data gramPacket objects with more than 8,192 bytes of data.
These four constructors create new DatagramPacket objects used to send data across the network:
Each constructor creates a new DatagramPacket to be sent to another host.
The packet is filled with length bytes of the data array starting at offset or 0 if offset is not used.
If you try to construct a DatagramPacket with a length that is greater than data.length (or greater than data.length - offset), the constructor throws an IllegalArgumen tException.
It’s OK to construct a DatagramPacket object with an offset and a length that will leave extra, unused space at the end of the data array.
In this case, only length bytes of data will be sent over the network.
The InetAddress or SocketAddress object destination points to the host you want the packet delivered to; the int argument port is the port on that host.
Choosing a Datagram Size The correct amount of data to stuff into one packet depends on the situation.
For example, rlogin transmits each character to the remote system almost as soon as the user types it.
Therefore, packets tend to be short: a single byte of data, plus a few bytes of headers.
For example, file transfer is more efficient with large buffers; the only requirement is that you split files into packets no larger than the maximum allowable packet size.
Several factors are involved in choosing the optimal packet size.
If the network is highly unreliable, such as a packet radio network, smaller packets are preferable because they’re less likely to be corrupted in transit.
On the other hand, very fast and reliable LANs should use the largest packet size possible.
Eight kilobytes—that is, 8,192 bytes—is a good compromise for many types of networks.
It’s customary to convert the data to a byte array and place it in data before creating the DatagramPacket, but it’s not absolutely necessary.
Changing data after the datagram has been constructed and before it has been sent changes the data in the datagram; the data isn’t copied into a private buffer.
For example, you could store data that changes over time in data and send out the current datagram (with the most recent data) every minute.
However, it’s more important to make sure that the data doesn’t change when you don’t want it to.
This is especially true if your program is multithreaded, and different threads may write into the data buffer.
If this is the case, copy the data into a temporary buffer before you construct the DatagramPacket.
For instance, this code fragment creates a new DatagramPacket filled with the data “This is a test” in UTF-8
Most of the time, the hardest part of creating a new DatagramPacket is translating the data into a byte array.
The get Methods DatagramPacket has six methods that retrieve different parts of a datagram: the actual data plus several fields from its header.
These methods are mostly used for datagrams received from the network.
The getAddress() method returns an InetAddress object containing the address of the remote host.
If the datagram was received from the Internet, the address returned.
On the other hand, if the datagram was created locally to be sent to a remote machine, this method returns the address of the host to which the datagram is addressed (the destination address)
This method is most commonly used to determine the address of the host that sent a UDP datagram, so that the recipient can reply.
The getPort() method returns an integer specifying the remote port.
If this datagram was received from the Internet, this is the port on the host that sent the packet.
If the datagram was created locally to be sent to a remote host, this is the port to which the packet is addressed on the remote machine.
The getSocketAddress() method returns a SocketAddress object containing the IP address and port of the remote host.
As is the case for getInetAddress(), if the datagram was received from the Internet, the address returned is the address of the machine that sent it (the source address)
On the other hand, if the datagram was created locally to be sent to a remote machine, this method returns the address of the host to which the datagram is addressed (the destination address)
You typically invoke this method to determine the address and port of the host that sent a UDP datagram before you reply.
The net effect is not noticeably different than calling getAddress() and getPort()
Also, if you’re using nonblocking I/O, the DatagramChannel class accepts a SocketAd dress but not an InetAddress and port.
The getData() method returns a byte array containing the data from the datagram.
It’s often necessary to convert the bytes into some other form of data before they’ll be useful to your program.
One way to do this is to change the byte array into a String.
For example, given a DatagramPacket dp received from the network, you can convert it to a UTF-8 String like this:
If the datagram does not contain text, converting it to Java data is more difficult.
One approach is to convert the byte array returned by getData() into a ByteArrayInput Stream.
You must specify the offset and the length when constructing the ByteArrayInput Stream.
The array returned by packet.getData() probably has extra space in it that was not filled with data from the network.
The data can then be read using the DataInputStream’s readInt(), readLong(), read Char(), and other methods.
Of course, this assumes that the datagram’s sender uses the same data formats as Java; it’s probably the case when the sender is written in Java, and is often (though not necessarily) the case otherwise.
Most modern computers use the same floating-point format as Java, and most network protocols specify two’s complement integers in network byte order, which also matches Java’s formats.
The getLength() method returns the number of bytes of data in the datagram.
This is not necessarily the same as the length of the array returned by getData() (i.e., getDa ta().length)
The int returned by getLength() may be less than the length of the array returned by getData()
This method simply returns the point in the array returned by getData() where the data from the datagram begins.
Example 12-3 uses all the methods covered in this section to print the information in the DatagramPacket.
This example is a little artificial; because the program creates a DatagramPacket, it already knows what’s in it.
More often, you’ll use these methods on a DatagramPacket received from the network, but that will have to wait for the introduction of the DatagramSocket class in the next section.
The setter Methods Most of the time, the six constructors are sufficient for creating datagrams.
However, Java also provides several methods for changing the data, remote address, and remote port after the datagram has been created.
These methods might be important in a situation where the time to create and garbage collect new DatagramPacket objects is a significant performance hit.
In some situations, reusing objects can be significantly faster than constructing new ones: for example, in a networked twitch game that sends a datagram for every bullet fired or every centimeter of movement.
However, you would have to use a very speedy connection for the improvement to be noticeable relative to the slowness of the network itself.
The setData() method changes the payload of the UDP datagram.
You might use this method if you are sending a large file (where large is defined as “bigger than can comfortably fit in one datagram”) to a remote host.
You could repeatedly send the same DatagramPacket object, just changing the data each time.
This overloaded variant of the setData() method provides an alternative approach to sending a large quantity of data.
Instead of sending lots of new arrays, you can put all the data in one array and send it a piece at a time.
For instance, this loop sends a large array in 512-byte chunks:
On the other hand, this strategy requires either a lot of confidence that the data will in fact arrive or, alternatively, a disregard for the consequences of its not arriving.
It’s relatively difficult to attach sequence numbers or other reliability tags to individual packets when you take this approach.
The setAddress() method changes the address a datagram packet is sent to.
This might allow you to send the same datagram to many different recipients.
Whether this is a sensible choice depends on the application.
If you’re trying to send to all the stations on a network segment, as in this fragment, you’d probably be better off using the local broadcast address and letting the network do the work.
For more widely separated hosts, you’re probably better off using multicasting.
However, it uses different IP addresses and a MulticastSocket instead of a DatagramSocket.
The setPort() method changes the port a datagram is addressed to.
I honestly can’t think of many uses for this method.
It could be used in a port scanner application that tried to find open ports running particular UDP-based services such as FSP.
Another possibility might be some sort of networked game or conferencing server where the clients that need to receive the same information are all running on different ports as.
In this case, setPort() could be used in conjunction with se tAddress() to change destinations before sending the same datagram out again.
The setSocketAddress() method changes the address and port a datagram packet is sent to.
For example, this code fragment receives a datagram packet and responds to the same address with a packet containing the string “Hello there”:
You could certainly write the same code using InetAddress objects and ports instead of a SocketAddress.
The setLength() method changes the number of bytes of data in the internal buffer that are considered to be part of the datagram’s data as opposed to merely unfilled space.
This method is useful when receiving datagrams, as we’ll explore later in this chapter.
When a datagram is received, its length is set to the length of the incoming data.
This means that if you try to receive another datagram into the same DatagramPacket, it’s limited to no more than the number of bytes in the first.
This method lets you reset the length of the buffer so that subsequent datagrams aren’t truncated.
The DatagramSocket Class To send or receive a DatagramPacket, you must open a datagram socket.
In Java, a datagram socket is created and accessed through the DatagramSocket class:
All datagram sockets bind to a local port, on which they listen for incoming data and which they place in the header of outgoing datagrams.
If you’re writing a client, you don’t care what the local port is, so you call a constructor that lets the system assign an unused port (an anonymous port)
This port number is placed in any outgoing datagrams and will be used by the server to address any response datagrams.
If you’re writing a server, clients need to know on which port the server is listening for incoming datagrams; therefore, when a server constructs a DatagramSocket, it specifies the local port.
However, the sockets used by clients and servers are otherwise identical: they differ only in whether they use an anonymous (system-assigned) or a well-known port.
There’s no distinction between client sockets and server sockets, as there is with TCP.
The Constructors The DatagramSocket constructors are used in different situations, much like the Data gramPacket constructors.
The first constructor opens a datagram socket on an anonymous local port.
The second constructor opens a datagram socket on a well-known local port that listens to all local network interfaces.
The last two constructors open a datagram socket on a well-known local port on a specific network interface.
All constructors deal only with the local address and port.
The remote address and port are stored in the DatagramPacket, not the DatagramSocket.
Indeed, one DatagramSocket can send and receive datagrams from multiple remote hosts and ports.
Pick this constructor for a client that initiates a conversation with a server.
In this scenario, you don’t care what port the socket is bound to because the server will send its response to the port from which the datagram originated.
Letting the system assign a port means that you don’t have to worry about finding an unused port.
If, for some reason, you need to know the local port, you can find out with the getLocalPort() method described later in this chapter.
The same socket can receive the datagrams that a server sends back to it.
The constructor throws a SocketException if the socket can’t bind to a port.
It’s unusual for this constructor to throw an exception; it’s hard to imagine situations in which the socket could not be opened, because the system gets to choose an available port.
Two different programs can use the same port number if one uses UDP and the other uses TCP.
Example 12-4 is a port scanner that looks for UDP ports in use on the local host.
It decides that the port is in use if the DatagramSocket constructor throws an exception.
You can easily extend it to check ports below 1024, however, if you have root access or are running it on Windows.
Here are the results from the Linux workstation on which much of the code in this book was written:
The high-numbered ports in the 30,000 range are Remote Procedure Call (RPC) services.
It’s much harder to scan UDP ports on a remote system than to scan for remote TCP ports.
Whereas there’s always some indication that a listening port, regardless of application layer protocol, has received your TCP packet, UDP provides no such guarantees.
To determine that a UDP server is listening, you have to send it a packet it will recognize and respond to.
Unlike sockets created by the other four constructors, this socket is not initially bound to a port.
Before using it, you have to bind it to a SocketAddress using the bind() method:
You can pass null to this method, binding the socket to any available address and port.
Sending and Receiving Datagrams The primary task of the DatagramSocket class is to send and receive UDP datagrams.
Indeed, it can send and receive to and from multiple hosts at the same time.
Once a DatagramPacket is created and a DatagramSocket is constructed, send the packet by passing it to the socket’s send() method.
For example, if theSocket is a Datagram Socket object and theOutput is a DatagramPacket object, send theOutput using the Socket like this:
If there’s a problem sending the data, this method may throw an IOException.
However, this is less common with DatagramSocket than Socket or ServerSocket, because the unreliable nature of UDP means you won’t get an exception just because the packet.
You may get an IOException if you’re trying to send a larger datagram than the host’s native networking software supports, but then again you may not.
This depends heavily on the native UDP software in the OS and the native code that interfaces between this and Java’s DatagramSocketImpl class.
This method may also throw a SecurityException if the SecurityManager won’t let you communicate with the host to which the packet is addressed.
This is primarily a problem for applets and other remotely loaded code.
It reads lines of user input from Sys tem.in and sends them to a discard server, which simply discards all the data.
Many of the simpler Internet protocols, such as discard and echo, have both TCP and UDP implementations.
It has a single static field, PORT, which is set to the standard port for the discard protocol (port 9), and a single method, main()
The main() method reads a hostname from the command line and converts that hostname to the InetAddress object called server.
A BufferedReader is chained to System.in to read user input from the keyboard.
After creating the socket, the program enters an infinite while loop that reads user input line by line using readLine()
Example 12-5 is careful, however, to use only readLine() to read data from the console, the one place where it is guaranteed to work as advertised.
Because the discard protocol deals only with raw bytes, it can ignore character encoding issues.
In the while loop, each line is converted to a byte array using the getBytes() method, and the bytes are stuffed in a new DatagramPacket, theOutput.
Finally, theOutput is sent over theSocket, and the loop continues.
If at any point the user types a period on a line by itself, the program exits.
The DatagramSocket constructor may throw a Sock etException, so that needs to be caught.
Because this is a discard client, you don’t need to worry about data coming back from the server.
The datagram’s buffer should be large enough to hold the data received.
If it’s not, receive() places as much data in the buffer as it can hold; the rest is lost.
Remember that the maximum size of the data portion of a UDP datagram is 65,507 bytes.
Some application protocols that use UDP further restrict the maximum number of bytes in a packet; for instance, NFS uses a maximum packet size of 8,192 bytes.
If there’s a problem receiving the data, receive() may throw an IOException.
In practice, this is rare because problems like dropped packets that would shut down a TCP stream are silently discarded by the network or network stack before Java ever sees them.
Example 12-6 shows a UDP discard server that receives incoming datagrams.
Just for fun, it logs the data in each datagram to System.out so that you can see who’s sending what to your discard server.
This is a simple class with a single method, main()
It reads the port the server listens to from the command line.
It then opens a DatagramSocket on that port and creates a DatagramPacket with a 65,507-byte buffer—large enough to receive any possible packet.
Then the server enters an infinite loop that receives packets and prints the contents and the originating host on the console.
Indeed, there’s no particular reason these packets have to be text at all.
As each datagram is received, the length of packet is set to the length of the data in that datagram.
Consequently, as the last step of the loop, the length of the packet is reset to the maximum possible value.
Otherwise, the incoming packets would be limited to the minimum size of all previous packets.
You can run the discard client on one machine and connect to the discard server on a second machine to verify that the network is working.
Calling a DatagramSocket object’s close() method frees the port occupied by that socket.
As with streams and TCP sockets, you’ll want to take care to close the datagram socket in a finally block:
In Java 7, DatagramSocket implements AutoCloseable so you can use try-withresources:
It’s never a bad idea to close a DatagramSocket when you’re through with it; it’s particularly important to close an unneeded socket if the program will continue to run for a significant amount of time.
For example, the close() method was essential in Example 12-4, UDPPortScanner: if this program did not close the sockets it opened, it would tie up every UDP port on the system for a significant amount of time.
On the other hand, if the program ends as soon as you’re through with the DatagramSocket, you don’t need to close the socket explicitly; the socket is automatically closed upon garbage collection.
However, Java won’t run the garbage collector just because you’ve run out of ports or sockets, unless by lucky happenstance you run out of memory at the same time.
Closing unneeded sockets never hurts and is good programming practice.
A DatagramSocket’s getLocalPort() method returns an int that represents the local port on which the socket is listening.
Use this method if you created a DatagramSock et with an anonymous port and want to find out what port the socket has been assigned.
A DatagramSocket’s getLocalAddress() method returns an InetAddress object that represents the local address to which the socket is bound.
Normally, you either already know or simply don’t care which address a socket is listening to.
Managing Connections Unlike TCP sockets, datagram sockets aren’t very picky about whom they’ll talk to.
In fact, by default they’ll talk to anyone; but this is often not what you want.
For instance, applets are only allowed to send datagrams to and receive datagrams from the applet host.
An NFS or FSP client should accept packets only from the server it’s talking to.
A networked game should listen to datagrams only from the people playing the game.
The next five methods let you choose which host you can send datagrams to and receive datagrams from, while rejecting all others’ packets.
The connect() method doesn’t really establish a connection in the TCP sense.
However, it does specify that the DatagramSocket will only send packets to and receive packets from the specified remote host on the specified remote port.
Packets received from a different host or a different port will be discarded without an exception or other notification.
A security check is made when the connect() method is invoked.
If the VM is allowed to send data to that host and port, the check passes silently.
However, once the connection has been made, send() and receive() on that DatagramSocket no longer make the security checks they’d normally make.
The disconnect() method breaks the “connection” of a connected DatagramSocket so that it can once again send packets to and receive packets from any host and port.
If and only if a DatagramSocket is connected, the getPort() method returns the remote port to which it is connected.
If and only if a DatagramSocket is connected, the getInetAddress() method returns the address of the remote host to which it is connected.
This value can be changed with the setSoTimeout() method and inspected with the getSoTimeout() method:
The default is to never time out, and indeed there are few situations in which you need to set SO_TIMEOUT.
You might need it if you were implementing a secure protocol that required responses to occur within a fixed amount of time.
You might also decide that the host you’re communicating with is dead (unreachable or not responding) if you don’t receive a response within a certain amount of time.
The setSoTimeout() method sets the SO_TIMEOUT field for a datagram socket.
You cannot change it while receive() is waiting for a datagram.
The timeout argument must be greater than or equal to zero.
The getSoTimeout() method returns the current value of this DatagramSocket object’s SO_TIMEOUT field.
It determines the size of the buffer used for network I/O.
Larger buffers tend to improve performance for reasonably fast (say, Ethernet-speed) connections because they can store more incoming datagrams before overflowing.
Sufficiently large receive buffers are even more important for UDP than for TCP, because a UDP datagram that arrives when the buffer is full will be lost, whereas a TCP datagram that arrives at a full buffer will eventually be retransmitted.
Furthermore, SO_RCVBUF sets the maximum size of datagram packets that can be received by the application.
Packets that won’t fit in the receive buffer are silently discarded.
DatagramSocket has methods to set and get the suggested receive buffer size used for network input:
However, the underlying implementation is free to ignore this suggestion.
Both methods throw a SocketException if the underlying socket implementation does not recognize the SO_RCVBUF option.
SO_SNDBUF DatagramSocket has methods to get and set the suggested send buffer size used for network output:
Once again, however, the operating system is free to ignore this suggestion.
Both methods throw a SocketException if the underlying native network software doesn’t understand the SO_SNDBUF option.
For UDP, SO_REUSEADDR controls whether multiple datagram sockets can bind to the same port and address at the same time.
If multiple sockets are bound to the same port, received packets will be copied to all bound sockets.
For this to work reliably, setReuseAddress() must be called before the new socket binds to the port.
This means the socket must be created in an unconnected state using the protected constructor that takes a DatagramImpl as an argument.
In other words, it won’t work with a plain vanilla DatagramSocket.
Reusable ports are most commonly used for multicast sockets, which will be discussed in the next chapter.
Datagram channels also create unconnected datagram sockets that can be configured to reuse ports, as you’ll see later in this chapter.
Routers and gateways do not normally forward broadcast messages, but they can still kick up a lot of traffic on the local network.
This option is turned on by default, but if you like you can disable it thusly:
This option can be changed after the socket has been bound.
On some implementations, sockets bound to a specific address do not receive broadcast packets.
This is necessary in addition to setting the SO_BROADCAST option to true.
After all, packets are actually routed and prioritized according to IP, which both TCP and UDP sit on top of.
There’s really no difference between the setTrafficClass() and getTrafficClass() methods in DatagramSocket and those in Socket.
They just have to be repeated here because DatagramSocket and Socket don’t have a common superclass.
These two methods let you inspect and set the class of service for a socket using these two methods:
The JavaDoc for these options is severely out of date, and describes a quality of service scheme based on bit fields for four traffic classes: low cost, high reliability, maximum throughput, and minimum delay.
This scheme was never widely implemented and probably hasn’t been used in this century.
This code fragment sets a socket to use Expedited Forwarding by setting the traffic class to 10111000:
The underlying socket implementation is not required to respect any of these requests.
Android in particular treats the setTrafficClass() method as a noop.
If the native network stack is unable to provide the requested class of service, Java may but is not required to throw a SocketException.
Some Useful Applications In this section, you’ll see several Internet servers and clients that use DatagramPacket and DatagramSocket.
Some of these will be familiar from previous chapters because many Internet protocols have both TCP and UDP implementations.
When an IP packet is received by a host, the host determines whether the packet is a TCP packet or a UDP datagram by inspecting the IP header.
As I said earlier, there’s no connection between UDP and TCP ports; TCP and UDP servers can share the same port number without problems.
By convention, if a service has both TCP and UDP implementations, it uses the same port for both, although there’s no technical reason this has to be the case.
Simple UDP Clients Several Internet services need to know only the client’s address and port; they ignore any data the client sends in its datagrams.
Daytime, quote of the day, time, and chargen are four such protocols.
Each of these responds the same way, regardless of the data contained in the datagram, or indeed regardless of whether there actually is any data in the datagram.
Clients for these protocols simply send a UDP datagram to the server and read the response that comes back.
Therefore, let’s begin with a simple client called UDPPoke , shown in Example 12-7, which sends an empty UDP packet to a specified host and port and reads a response packet from the same host.
The bufferSize field specifies how large a return packet is expected.
An 8,192-byte buffer is large enough for most of the protocols that UDPPoke is useful for, but it can be increased by passing a different value to the constructor.
The timeout field specifies how long to wait for a response.
The host and the port fields specify the remote host to connect to.
If the buffer length is not specified, 8,192 bytes is used.
The host, port, and buffer size are also used to construct the outgoing DatagramPacket.
Once a UDPPoke object has been constructed, clients call its poke() method to send an empty outgoing datagram to the target and read its response.
When the expected datagram appears, its data is copied into the response field.
This method returns null if the response doesn’t come quickly enough or never comes at all.
The main() method merely reads the host and port to connect to from the command line, constructs a UDPPoke object, and pokes it.
Most of the simple protocols that this client suits will return ASCII text, so this example attempts to convert the response to an ASCII string and print it.
For example, this connects to a daytime server over UDP:
Given this class, UDP daytime, time, chargen, and quote of the day clients are almost trivial.
A time client is only slightly harder, and only because you need to convert the four raw bytes returned by the server to a java.util.Date object.
UDPServer Clients aren’t the only programs that benefit from a reusable implementation.
They all wait for UDP datagrams on a specified port and reply to each datagram with another datagram.
The servers differ only in the content of the datagram that they return.
Example 12-9 is a simple iterative UDPServer class that can be subclassed to provide specific servers for different protocols.
The UDPServer class has two fields, the int bufferSize and the DatagramSocket sock et, the latter of which is protected so it can be used by subclasses.
The constructor opens a datagram socket on a specified local port to receive datagrams of no more than bufferSize bytes.
UDPServer implements Runnable so that multiple instances can run in parallel.
Its run() method contains a loop that repeatedly receives an incoming datagram and responds by passing it to the abstract respond() method.
This method will be overridden by particular subclasses in order to implement different kinds of servers.
Assuming this class may be used as part of other programs that do more than just run one server, you need a way to shut it down.
This is provided by the shutDown() method, which sets a flag.
The main loop checks this flag each pass to see if it should exit.
Because the receive() call can block indefinitely if there’s no traffic, you also set a timeout on the socket.
This will wake it up once every 10 seconds to check for shutdown whether there’s traffic or not.
Subclasses can send zero, one, or many datagrams in response to each incoming datagram.
If a lot of processing is required to respond to a packet, the respond() method can spawn a thread to do it.
However, UDP servers tend not to have extended interactions with a client.
Each incoming packet is treated independently of other packets, so the response can usually be handled directly in the respond() method without spawning a thread.
All that’s needed is a main() method that sets the port and starts the thread.
Example 12-10 is a high-performance UDP discard server that does nothing with incoming packets.
It isn’t much harder to implement an echo server, as Example 12-11 shows.
Unlike a stream-based TCP echo server, multiple threads are not required to handle multiple clients.
In particular, protocols that require multiple datagrams require a different implementation.
Implementing the echo protocol with TCP is simple; it’s more complex with UDP because you don’t have I/O streams or the concept of a connection to work with.
A TCP-based echo client can send a message and wait for a response on the same connection.
However, a UDP-based echo client has no guarantee that the message it sent was received.
Therefore, it cannot simply wait for the response; it needs to be prepared to send and receive data asynchronously.
This behavior is fairly simple to implement using threads, however.
One thread can process user input and send it to the echo server, while a second thread accepts input from the server and displays it to the user.
The client is divided into three classes: the main UDPEchoClient class, the SenderThread class, and the ReceiverThread class.
It reads a hostname from the command line and converts it to an InetAddress object.
UDPEchoClient uses this object and the default echo port to construct a SenderThread object.
This constructor can throw a SocketException, so the exception must be caught.
The same DatagramSocket that the SenderThread uses is used to construct a ReceiverTh read, which is then started.
It’s important to use the same DatagramSocket for both sending and receiving data because the echo server will send the response back to the port the data was sent from.
The SenderThread class reads input from the console a line at a time and sends it to the echo server.
The input is provided by System.in, but a different client could include an option to read input from a different stream—perhaps opening a FileInputStream to read from a file.
The fields of this class define the server to which it sends data, the port on that server, and the DatagramSocket that does the sending, all set in the single constructor.
The DatagramSocket is connected to the remote server to make sure all datagrams received were in fact sent by the right server.
It’s rather unlikely that some other server on the Internet is going to bombard this particular port with extraneous data, so this is not a big flaw.
However, it’s a good habit to make sure that the packets you receive come from the right place, especially if security is a concern.
The run() method processes user input a line at a time.
To do this, the BufferedRead er userInput is chained to System.in.
A period on a line by itself signals the end of user input and breaks out of the loop.
Next, the data array is placed in the payload part of the DatagramPacket output, along with information about the server, the port, and the data length.
This packet is then sent to its destination by socket.
This thread then yields to give other threads an opportunity to run.
The ReceiverThread class shown in Example 12-14 waits for datagrams to arrive from the network.
When a datagram is received, it is converted to a String and printed on System.out for display to the user.
A more advanced echo client could include an option to send the output elsewhere.
The more important is the DatagramSocket, theSocket, which must be the same DatagramSocket used by the SenderThread.
Data arrives on the port used by that DatagramSocket; any other DatagramSocket would not be allowed to connect to the same port.
The second field, stopped, is a boolean used to halt this thread without invoking the deprecated stop() method.
The run() method is an infinite loop that uses socket’s receive() method to wait for incoming datagrams.
When an incoming datagram appears, it is converted into a String with the same length as the incoming data and printed on System.out.
As in the input thread, this thread then yields to give other threads an opportunity to execute.
You can run the echo client on one machine and connect to the echo server on a second machine to verify that the network is functioning properly between them.
This is useful in servers where one thread can manage communications with multiple clients.
However, UDP is by its nature much more asynchronous than TCP so the net effect is smaller.
In UDP, a single datagram socket can process requests from multiple clients for both input and output.
What the DatagramChannel class adds is the ability to do this in a nonblocking fashion, so methods return quickly if the network isn’t immediately ready to receive or send data.
In Java 6 and earlier, you still need to use the DatagramSocket class to bind a channel to a port.
Instead, you read and write byte buffers, just as you do with a SocketChannel.
Instead, you create a new DatagramChannel object using the static open() method For example:
To bind it, you access the channel’s peer DatagramSocket object using the socket() method.
Java 7 adds a convenient bind() method directly to DatagramChannel, so you don’t have to use a DatagramSocket at all.
The receive() method reads one datagram packet from the channel into a ByteBuffer.
It returns the address of the host that sent the packet:
If the channel is blocking (the default), this method will not return until a packet has been read.
If the channel is nonblocking, this method will immediately return null if no packet is available to read.
If the datagram packet has more data than the buffer can hold, the extra data is thrown away with no notification of the problem.
This behavior introduces an additional layer of unreliability into the system.
The data can arrive safely from the network and still be lost inside your own program.
Using this method, you can reimplement the discard server to log the host sending the data as well as the data sent.
It avoids the potential loss of data by using a buffer that’s big enough to hold any UDP packet and clearing it before it’s used again.
The send() method writes one datagram packet into the channel from a ByteBuffer to the address specified as the second argument:
The source ByteBuffer can be reused if you want to send the same data to multiple clients.
This will either be the number of bytes that were available in the buffer to be written or zero, nothing in between.
It is zero if the channel is in nonblocking mode and the data can’t be sent immediately.
Otherwise, if the channel is not in nonblocking mode, send() simply waits to return until it can send all the data in the buffer.
Example 12-16 demonstrates with a simple echo server based on channels.
Just as it did in Example 12-15, the receive() method reads a packet.
However, this time, rather than logging the packet on System.out, it returns the same data to the client that sent it.
This is much less of a problem for UDP-based protocols than for TCP protocols.
The unreliable, packet-based, connectionless nature of UDP means that the server at most has to wait for the local buffer to clear.
It does not wait for the client to be ready to receive data.
There’s much less opportunity for one client to get held up behind a slower client.
Connecting Once you’ve opened a datagram channel, you connect it to a particular remote address using the connect() method:
The channel will only send data to or receive data from this host.
Unlike the con nect() method of SocketChannel, this method alone does not send or receive any packets across the network because UDP is a connectionless protocol.
It merely establishes the host it will send packets to when there’s data ready to be sent.
Thus, con nect() returns fairly quickly, and doesn’t block in any meaningful sense.
There is an isConnected() method that returns true if and only if the DatagramSocket is connected:
This tells you whether the DatagramChannel is limited to one host.
Unlike SocketChan nel, a DatagramChannel doesn’t have to be connected to transmit or receive data.
This doesn’t really close anything because nothing was really open in the first place.
It just allows the channel to be connected to a different host in the future.
Besides the special-purpose receive() method, DatagramChannel has the usual three read() methods:
However, these methods can only be used on connected channels.
That is, before invoking one of these methods, you must invoke connect() to glue the channel to a particular remote host.
This makes them more suitable for use with clients that know who they’ll be talking to than for servers that must accept input from multiple hosts at the same time that are normally not known prior to the arrival of the first packet.
Each of these three methods only reads a single datagram packet from the network.
As much data from that datagram as possible is stored in the argument ByteBuffer(s)
Each method returns the number of bytes read or –1 if the channel has been closed.
This method may return 0 for any of several reasons, including:
As with the receive() method, if the datagram packet has more data than the Byte Buffer(s) can hold, the extra data is thrown away with no notification of the problem.
Naturally, DatagramChannel has the three write methods common to all writable, scattering channels, which can be used instead of the send() method:
These methods can only be used on connected channels; otherwise, they don’t know where to send the packet.
Each of these methods sends a single datagram packet over the connection.
None of these methods are guaranteed to write the complete contents of the buffer(s)
Fortunately, the cursor-based nature of buffers enables you to easily call this method again and again until the buffer is fully drained and the data has been completely sent, possibly using multiple datagram packets.
You can use the read and write methods to implement a simple UDP echo client.
On the client side, it’s easy to connect before sending.
Because packets may be lost in transit (always remember UDP is unreliable), you don’t want to tie up the sending while waiting to receive a packet.
Thus, you can take advantage of selectors and nonblocking I/O.
You’ll print out the values returned so it will be easy to figure out if any packets are being lost.
There is one major difference between selecting TCP channels and selecting datagram channels.
Because datagram channels are truly connectionless (despite the connect() method), you need to notice when the data transfer is complete and shut down.
In this example, you assume the data is finished when all packets have been sent and one minute has passed since the last packet was received.
Any expected packets that have not been received by this point are assumed to be lost in the ether.
Closing Just as with regular datagram sockets, a channel should be closed when you’re done with it to free up the port and any other resources it may be using:
Attempting to write data to or read data from a closed channel throws an exception.
If you’re uncertain whether a channel has been closed, check with isOpen():
This returns false if the channel is closed, true if it’s open.
Like all channels, in Java 7 DatagramChannel implements AutoCloseable so you can use it in try-with-resources statements.
Prior to Java 7, close it in a finally block if you can.
Integer Size of the buffer used for sending datagram packets.
Integer Size of the buffer used for receiving datagram packets.
The getOption() method tells you the current value of any of these.
For example, suppose you want to send a broadcast message.
SO_BROADCAST is usually turned off by default, but you can switch it on like so:
Example 12-18 opens a channel just to check the default values of these options.
It’s a bit surprising that my send buffer is so much larger than my receive buffer.
The sockets in the previous chapters are unicast: they provide point-to-point communication.
Unicast sockets create a connection with two well-defined endpoints; there is one sender and one receiver and, although they may switch roles, at any given time it is easy to tell which is which.
However, although point-to-point communications serve many, if not most needs (people have engaged in one-on-one conversations for millennia), many tasks require a different model.
For example, a television station broadcasts data from one location to every point within range of its transmitter.
The signal reaches every television set, whether or not it’s turned on and whether or not it’s tuned to that particular station.
Indeed, the signal even reaches homes with cable boxes instead of antennas and homes that don’t have a television.
It’s indiscriminate and quite wasteful of both the electromagnetic spectrum and power.
Videoconferencing, by contrast, sends an audio-video feed to a select group of people.
Usenet news is posted at one site and distributed around the world to hundreds of thousands of people.
However, the sender relies on the intermediate sites to copy and relay the message to downstream sites.
The sender does not address its message to every host that will eventually receive it.
These are examples of multicasting, although they’re implemented with additional application layer protocols on top of TCP or UDP.
These protocols require fairly detailed configuration and intervention by human beings.
For instance, to join Usenet you have to find a site willing to send news to you and relay your outgoing news to the rest of the world.
To add you to the Usenet feed, the news administrator of the news relay has to specifically add your site to their news config files.
However, recent developments with the network software in most major operating systems as well as Internet routers have opened up a new possibility—true multicasting, in which the routers decide how to efficiently move a message to individual hosts.
In particular, the initial router sends only one copy of the message to a router near the receiving hosts, which then makes multiple copies for different recipients at or closer.
Multicasting in Java uses the DatagramPacket class introduced in Chapter 12, along with a new Multicast Socket class.
Multicasting Multicasting is broader than unicast, point-to-point communication but narrower and more targeted than broadcast communication.
Multicasting sends data from one host to many different hosts, but not to everyone; the data only goes to clients that have expressed an interest by joining a particular multicast group.
People can come and go as they please, leaving when the discussion no longer interests them.
Before they arrive and after they have left, they don’t need to process the information at all: it just doesn’t reach them.
On the Internet, such “public meetings” are best implemented using a multicast socket that sends a copy of the data to a location (or a group of locations) close to the parties that have declared an interest in the data.
In the best case, the data is duplicated only when it reaches the local network serving the interested clients: the data crosses the Internet only once.
More realistically, several identical copies of the data traverse the Internet; but, by carefully choosing the points at which the streams are duplicated, the load on the network is minimized.
The good news is that programmers and network administrators aren’t responsible for choosing the points where the data is duplicated or even for sending multiple copies; the Internet’s routers handle all that.
Protocols require broadcasts only when there is no alternative; and routers limit broadcasts to the local network or subnet, preventing broadcasts from reaching the Internet at large.
Even a few small global broadcasts could bring the Internet to its knees.
Broadcasting highbandwidth data such as audio, video, or even text and still images is out of the question.
A single email spam that goes to millions of addresses is bad enough.
Imagine what would happen if a real-time video feed were copied to all billion+ Internet users, whether they wanted to watch it or not.
However, there’s a middle ground between point-to-point communications and broadcasts to the whole world.
There’s no reason to send a video feed to hosts that aren’t interested in it; we need a technology that sends data to the hosts that want it, without bothering the rest of the world.
One way to do this is to use many unicast streams.
If 1,000 clients want to watch a BBC live stream, the data is sent a thousand times.
Still, if the number of interested clients is large enough, you will eventually run out of bandwidth or CPU power—probably sooner rather than later.
Another approach to the problem is to create static connection trees.
This is the solution employed by Usenet news and some conferencing systems.
This is more efficient than sending everything to all interested clients via multiple unicasts, but the scheme is kludgy and beginning to show its age.
New sites need to find a place to hook into the tree manually.
The tree does not necessarily reflect the best possible topology at any one time, and servers still need to maintain many point-to-point connections to their clients, sending the same data to each one.
It would be better to allow the routers in the Internet to dynamically determine the best possible routes for transmitting distributed information and to replicate data only when absolutely necessary.
When people talk about multicasting, audio and video are the first applications that come to mind.
Indeed, the BBC has been running a multicast trial covering both TV and radio for several years now, though ISP participation has been regrettably limited.
However, audio and video are only the tip of the iceberg.
Other possibilities include multiplayer games, distributed filesystems, massively parallel computing, multiperson conferencing, database replication, content delivery networks, and more.
Multicasting can be used to implement name services and directory services that don’t require the client to know a server’s address in advance; to look up a name, a host could multicast its request to some well-known address and wait until a response is received from the nearest server.
Multicasting has been designed to fit into the Internet as seamlessly as possible.
Most of the work is done by routers and should be transparent to application programmers.
An application simply sends datagram packets to a multicast address, which isn’t fundamentally different from any other IP address.
The routers make sure the packet is delivered to all the hosts in the multicast group.
The biggest problem is that multicast routers are not yet ubiquitous; therefore, you need to know enough about them to find out whether multicasting is supported on your network.
For instance, although the BBC has been multicasting for several years now, their multicast streams are only accessible to subscribers of about a dozen relatively small British ISPs.
As far as the application itself, you need to pay attention to an additional header field in the datagrams called the Time-To-Live (TTL) value.
The TTL is the maximum number of routers that the datagram is allowed to cross.
Once the packet has crossed that many routers, it is discarded.
Multicasting uses the TTL as an ad hoc way to limit how far a packet can travel.
For example, you don’t want packets for a friendly on-campus game of Dogfight reaching routers on the other side of the world.
Multicast Addresses and Groups A multicast address is the shared address of a group of hosts called a multicast group.
All addresses in this range have the binary digits 1110 as their first four bits.
Like any IP address, a multicast address can have a hostname.
For example, the multicast address 224.0.1.1 (the address of the Network Time Protocol distributed service) is assigned the name ntp.mcast.net.
A multicast group is a set of Internet hosts that share a multicast address.
Any data sent to the multicast address is relayed to all the members of the group.
Membership in a multicast group is open; hosts can enter or leave the group at any time.
Permanent groups have assigned addresses that remain constant, whether or not there are any members in the group.
However, most multicast groups are transient and exist only as long as they have members.
The IANA is responsible for handing out permanent multicast addresses as needed.
Multicast routers never forward datagrams with destinations in this range.
Other Teredo clients on the same IPv4 subnet respond to this multicast address.
Permanently assigned multicast addresses that extend beyond the local subnet begin with 224.1
A few blocks of addresses ranging in size from a few dozen to a few thousand addresses have also been reserved for particular purposes.
The complete list is available from iana.org, though you should note that it contains many now defunct services, protocols, and companies.
The remaining 248 million multicast addresses can be used on a temporary basis by anyone who needs them.
Multicast routers (mrouters for short) are responsible for making sure that two different systems don’t try to use the same address at the same time.
Multicasting is used to communicate between the different interfaces being measured.
You can look at this with the X Window utility sdr or the Windows/Unix multikit program.
The idea is to allow the possible group membership to be established in advance without relying on less-than-reliable TTL values.
Clients and Servers When a host wants to send data to a multicast group, it puts that data in multicast datagrams, which are nothing more than UDP datagrams addressed to a multicast group.
If you think about it, multicast over TCP would be next to impossible.
If you’re developing a multicast application that can’t tolerate data loss, it’s your responsibility to determine whether data was damaged in transit and how to handle missing data.
For example, if you are building a distributed cache system, you might simply decide to leave any files that don’t arrive intact out of the cache.
Earlier, I said that from an application programmer’s standpoint, the primary difference between multicasting and using regular UDP sockets is that you have to worry about the TTL value.
Each time the packet passes through a router, its TTL field is decremented by at least one; some routers may decrement the TTL by two or more.
The TTL field was originally designed to prevent routing loops by guaranteeing that all packets would eventually be discarded.
It prevents misconfigured routers from sending packets back and forth to each other indefinitely.
For example, a TTL value of 16 limits the packet to the local area, generally one organization or perhaps an organization and its immediate upstream and downstream neighbors.
A TTL of 127, however, sends the packet around the world.
However, there is no precise way to map TTLs to geographical distance.
Generally, the farther away a site is, the more routers a packet has to pass through before reaching it.
Packets with small TTL values won’t travel as far as packets with large TTL values.
Table 13-3 provides some rough estimates relating TTL values to geographical reach.
Estimated TTL values for datagrams originating in the continental United States.
Once the data has been stuffed into one or more datagrams, the sending host launches the datagrams onto the Internet.
The sending host begins by transmitting a multicast datagram to the local network.
This packet immediately reaches all members of the multicast group in the same subnet.
If the Time-To-Live field of the packet is greater than 1, multicast routers on the local network forward the packet to other networks that have members of the destination group.
When the packet arrives at one of the final destinations, the multicast router on the foreign network transmits the packet to each host it serves that is a member of the multicast group.
If necessary, the multicast router also retransmits the packet to the next routers in the paths between the current router and all its eventual destinations.
When data arrives at a host in a multicast group, the host receives it as it receives any other UDP datagram—even though the packet’s destination address doesn’t match the receiving host.
The host recognizes that the datagram is intended for it because it belongs to the multicast group to which the datagram is addressed, much as most of us accept mail addressed to “Occupant,” even though none of us are named Mr.
The receiving host must be listening on the proper port, ready to process the datagram when it arrives.
Routers and Routing Figure 13-3 shows one of the simplest possible multicast configurations: a single server sending the same data to four clients served by the same router.
A multicast socket sends one stream of data over the Internet to the clients’ router; the router duplicates the stream and sends it to each of the clients.
Without multicast sockets, the server would have to send four separate but identical streams of data to the router, which would route each stream to a client.
Using the same stream to send the same data to multiple clients significantly reduces the bandwidth required on the Internet backbone.
Of course, real-world routes can be much more complex, involving multiple hierarchies of redundant routers.
However, the goal of multicast sockets is simple: no matter how complex the network, the same data should never be sent more than once over any given network segment.
Just create a MulticastSocket, have the socket join a multicast group, and stuff the address of the multicast group in the DatagramPacket you want to send.
The routers and the Multi castSocket class take care of the rest.
The biggest restriction on multicasting is the availability of special multicast routers (mrouters)
Mrouters are reconfigured Internet routers or workstations that support the IP multicast extensions.
Many consumer-oriented ISPs quite deliberately do not enable multicasting in their routers.
In 2013, it is still possible to find hosts between which no multicast route exists (i.e., there is no route between the hosts that travels exclusively over mrouters)
To send and receive multicast data beyond the local subnet, you need a multicast router.
Check with your network administrator to see whether your routers support multicasting.
If any router responds, then your network is hooked up to a multicast router:
This still may not allow you to send to or receive from every multicast-capable host on the Internet.
For your packets to reach any given host, there must be a path of multicastcapable routers between your host and the remote host.
Alternatively, some sites may be connected by special multicast tunnel software that transmits multicast data over unicast UDP that all routers understand.
If you have trouble getting the examples in this chapter to produce the expected results, check with your local network administrator or ISP to see whether multicasting is actually supported by your routers.
As you would expect, MulticastSocket’s behavior is very similar to DatagramSocket’s: you put your data in DatagramPacket objects that you send and receive with the Mul ticastSocket.
Therefore, I won’t repeat the basics; this discussion assumes that you already know how to work with datagrams.
To receive data that is being multicast from a remote site, first create a MulticastSock et with the MulticastSocket() constructor.
As with other kinds of sockets, you need to know the port to listen on.
This code fragment opens a MulticastSocket that listens on port 2300:
Next, join a multicast group using the MulticastSocket’s joinGroup() method:
This signals the routers in the path between you and the server to start sending data your way and tells the local host that it should pass you IP packets addressed to the multicast group.
Once you’ve joined the multicast group, you receive UDP data just as you would with a DatagramSocket.
You create a DatagramPacket with a byte array that serves as a buffer.
When you no longer want to receive data, leave the multicast group by invoking the socket’s leaveGroup() method.
You can then close the socket with the close() method inherited from DatagramSocket:
Sending data to a multicast address is similar to sending UDP data to a unicast address.
You do not need to join a multicast group to send data to it.
You create a new Datagram Packet, stuff the data and the address of the multicast group into the packet, and pass it to the send() method:
There is one caveat to all this: multicast sockets are a security hole big enough to drive a small truck through.
Consequently, untrusted code running under the control of a SecurityManager is not allowed to do anything involving multicast sockets.
Remotely loaded code is normally only allowed to send datagrams to or receive datagrams from the host it was downloaded from.
However, multicast sockets don’t allow this sort of restriction to be placed on the packets they send or receive.
Once you send data to a multicast socket, you have very limited and unreliable control over which hosts receive that data.
Consequently, most environments that execute remote code take the conservative approach of disallowing all multicasting.
You can either pick a port to listen on or let Java assign an anonymous port for you:
All three constructors throw a SocketException if the Socket can’t be created.
If you don’t have sufficient privileges to bind to the port or if the port you’re trying to bind to is already in use, then a Socket cannot be created.
Note that because a multicast socket is a datagram socket as far as the operating system is concerned, a MulticastSocket cannot occupy a port already occupied by a DatagramSocket, and vice versa.
You can pass null to the constructor to create an unbound socket, which will be connected later with the bind() method.
This is useful when setting socket options that can only be set before the socket is bound.
For example, this code fragment creates a multicast socket with SO_REUSEADDR disabled (that option is normally enabled by default for multicast sockets):
Communicating with a Multicast Group Once a MulticastSocket has been created, it can perform four key operations:
No new methods are required to send or receive data.
The send() and receive() methods of the superclass, DatagramSocket, suffice for those operations.
You can perform these operations in any order, with the exception that you must join a group before you can receive data from it.
You do not need to join a group to send data to it, and you can freely intermix sending and receiving data.
To join a group, pass an InetAddress or a SocketAddress for the multicast group to the joinGroup() method:
Once you’ve joined a multicast group, you receive datagrams exactly as you receive unicast datagrams, as shown in the previous chapter.
That is, you set up a Datagram Packet as a buffer and pass it into this socket’s receive() method.
Information about membership in multicast groups is stored in multicast routers, not in the object.
In this case, you’d use the address stored in the incoming datagram to determine which address a packet was intended for.
Multiple multicast sockets on the same machine and even in the same Java program can all join the same group.
If so, each socket receives a complete copy of the data addressed to that group that arrives at the local host.
A second argument allows you to join a multicast group only on a specified local network interface.
If no such interface exists, then it joins on all available network interfaces:
Other than the extra argument specifying the network interface to listen from, this behaves pretty much like the single-argument joinGroup() method.
For instance, passing a SocketAddress object that does not represent a multicast group as the first argument throws an IOException.
Call the leaveGroup() method when you no longer want to receive datagrams from the specified multicast group, on either all or a specified network interface:
It signals the local multicast router, telling it to stop sending you datagrams.
However, no exception occurs if you leave a multicast group you never joined.
Pretty much all the methods in MulticastSocket can throw an IOException, so you’ll usually wrap all this in a try block.
In Java 6 and earlier, you’ll want to explicitly close the socket in a finally block to release resources the socket holds:
Sending data with a MulticastSocket is similar to sending data with a DatagramSock et.
Stuff your data into a DatagramPacket object and send it off using the send() method inherited from DatagramSocket.
The data is sent to every host that belongs to the multicast group to which the packet is addressed.
By default, multicast sockets uses a TTL of 1 (that is, packets don’t travel outside the local subnet)
The getTimeToLive() method returns the default TTL value of the Multi castSocket:
For example, this code fragment sets a TTL of 64:
Loopback mode Whether or not a host receives the multicast packets it sends is platform dependentthat is, whether or not they loop back.
Passing true to setLoopback() indicates you don’t want to receive the packets you send.
Passing false indicates you do want to receive the packets you send:
Because loopback mode may not be followed on all systems, it’s important to check what the loopback mode is if you’re both sending and receiving packets.
Mode() method returns true if packets are not looped back and false if they are.
I suspect this method was written by a programmer following the ill-advised convention that defaults should always be true.
If the system is looping packets back and you don’t want it to, you’ll need to recognize the packets somehow and discard them.
If the system is not looping the packets back and you do want it to, store copies of the packets you send and inject them into your internal data structures manually at the same time you send them.
You can ask for the behavior you want with setLoopback(), but you can’t count on it.
The setter methods throw a SocketException if the argument is not the address of a network interface on the local machine.
It is unclear why the network interface is immutably set in the constructor for unicast Socket and DatagramSocket objects but is variable and set with a separate method for MulticastSocket objects.
To be safe, set the interface immediately after constructing a MulticastSocket and don’t change it thereafter.
However, it does so based on the local name of a network interface such as “eth0” (as encapsulated in a NetworkInterface object) rather than on the IP address bound to that network interface (as encapsulated in an InetAddress object)
For example, this code fragment prints the network interface used by a socket:
Two Simple Examples Most multicast servers are indiscriminate about who they will talk to.
Therefore, it’s easy to join a group and watch the data that’s being sent to it.
Example 13-1 is a MulticastS niffer class that reads the name of a multicast group from the command line, constructs an InetAddress from that hostname, and creates a MulticastSocket, which attempts to join the multicast group at that hostname.
If the attempt succeeds, MulticastSniff er receives datagrams from the socket and prints their contents on System.out.
This program is useful primarily to verify that you are receiving multicast data at a particular host.
Most multicast data is binary and won’t be intelligible when printed as text.
The program begins by reading the name and port of the multicast group from the first two command-line arguments.
Next, it creates a new MulticastSocket ms on the specified port.
This socket joins the multicast group at the specified InetAddress.
Then it enters a loop in which it waits for packets to arrive.
As each packet arrives, the program reads its data, converts the data to an ISO Latin-1 String, and prints it on Sys tem.out.
Finally, when the user interrupts the program or an exception is thrown, the socket leaves the group and closes itself.
You can use this program to listen to those messages.
If such a device is broadcasting, you should see a message pop through within the first minute or two.
I collected about a megabyte and a half of announcements within the first couple of minutes I had this program running.
It appears that my Google TV is very chatty, sending an announcement about once a second.
Most devices only announce when they’re first connected to the network, or when they’re queried by another device.
Example 13-2 is a MulticastSender class that reads input from the command line and sends it to a multicast group.
Example 13-2 reads the address of a multicast group, a port number, and an optional TTL from the command line.
Next, it constructs the MulticastSocket ms, which joins the group ia.
Once it has joined the group, ms sends the datagram packet dp to the group ia 10 times.
The TTL value is set to one to make sure that this data doesn’t go beyond the local subnet.
Having sent the data, ms leaves the group and closes itself.
Next, send data to that group by running MulticastSender on another machine in your local subnet.
You can also run it in a different window on the same machine, although that option is not as exciting.
However, you must start running the MulticastSniff er before you start running the MulticastSender.
Back on the first machine, you should see this output:
Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data Here's some multicast data.
For this to work beyond the local subnet, the two subnets must each have multicast routers, and the routers in between them need to have multicast enabled.
We’d like to hear your suggestions for improving our indexes.
About the Author Elliotte Rusty Harold is originally from New Orleans, and he returns there periodically in search of a decent bowl of gumbo.
However, he currently resides in the Prospect Heights neighborhood of Brooklyn with his wife, Beth, and dog, Thor.
He’s a frequent speaker at industry conferences including Software Development, Dr.
His open source projects include the XOM Library for processing XML with Java and the Amateur media player.
These small carnivores are found in all major waterways of the United States and Canada, and in almost every habitat except the tundra and the hot, dry regions of the southwestern United States.
They weigh about 20 pounds and are approximately two and a half feet long, and females tend to be about a third smaller than males.
Their diet consists mainly of aquatic animals like fish and frogs, but since they spend about two-thirds of their time on land, they also eat the occasional bird or rodent.
Two layers of fur—a coarse outer coat and a thick, dense inner coat—protect a river otter from the cold, and, in fact, they seem to enjoy playing in snow and ice.
These animals are sociable and domesticated easily, and in Europe, a related species was once trained to catch fish for people to eat.
