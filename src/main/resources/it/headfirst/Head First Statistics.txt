Head First Statistics is by far the most entertaining, attention-catching study guide on the market.
By presenting the material in an engaging manner, it provides students with a comfortable way to learn an otherwise cumbersome subject.
Breeze through the explanations and exercises and you just may find yourself  raising the topic of  normal vs.
Dawn Griffiths has split some very complicated concepts into much smaller, less frightening, bits of stuff  that real-life people will find very easy to digest.
Thought Head First was just for computer nerds? Try the brain-friendly way with statistics and you’ll change your mind.
This book is a great way for students to learn statistics—it is entertaining, comprehensive, and easy to understand.
Kathy and Bert’s Head First Java transforms the printed page into the closest thing to a GUI you’ve ever seen.
Beyond the engaging style that drags you forward from know-nothing into exalted Java warrior status, Head First Java covers a huge amount of  practical matters that other texts leave as the dreaded “exercise for the reader...”  It’s clever, wry, hip and practical—there aren’t a lot of  textbooks that can make that claim and live up to it while also teaching you about object serialization and network launch protocols.
Just the right tone for the geeked-out, casual-cool guru coder in all of  us.
There are books you buy, books you keep, books you keep on your desk, and thanks to O’Reilly and the Head First crew, there is the penultimate category, Head First books.
They’re the ones that are dog-eared, mangled, and carried everywhere.
Head First SQL is at the top of  my stack.
Usually when reading through a book or article on design patterns, I’d have to occasionally stick myself in the eye with something just to make sure I was paying attention.
Odd as it may sound, this book makes learning about design patterns fun.
Wouldn’t it be dreamy if there was a statistics book that was more fun than an overdue trip.
O’Reilly Media books may be purchased for educational, business, or sales promotional use.
Many of  the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in this book, and O’Reilly Media, Inc., was aware of  a trademark claim, the designations have been printed in caps or initial caps.
While every precaution has been taken in the preparation of  this book, the publisher and the authors assume no responsibility for errors or omissions, or for damages resulting from the use of  the information contained herein.
No snorers were harmed in the making of  this book, although a horse lost its toupee at one point and suffered a minor indignity in front of  the other horses.
Also a snowboarder picked up a few bruises along the way, but nothing serious.
Thanks for the support and believing I could do it.
But you’ll have to wait a while for the car.
Dawn Griffiths started life as a mathematician at a top UK university.
She was awarded a First-Class Honours degree in Mathematics, but she turned down a PhD scholarship studying particularly rare breeds of differential equations when she realized people would stop talking to her at parties.
Instead she pursued a career in software development, and she currently combines IT consultancy with writing and mathematics.
When Dawn’s not working on Head First books, you’ll find her honing her Tai Chi skills, making bobbin lace or cooking nice meals.
She hasn’t yet mastered the art of  doing all three at the same time.
She also enjoys traveling, and spending time with her lovely husband, David.
Dawn has a theory that Head First Bobbin Lacemaking might prove to a be a big cult hit, but she suspects that Brett and Laurie might disagree.
Here you are trying to learn something, while here your brain is doing you a favor by making sure the learning doesn’t stick.
Can’t tell your facts from your figures? Statistics help you make sense of confusing sets of data.
And when you’ve found out what’s really going on, you.
See what I mean, the profit’s about the same each month.
The Middle Way Sometimes you just need to get to the heart of  the matter.
It can be difficult to see patterns and trends in a big pile of figures, and finding the.
Power Ranges3 Not everything’s reliable, but how can you tell? Averages do a great job of giving you a typical value in your data set, but they don’t tell you the full story.
OK, so you know where the center of your data is, but often.
In this chapter, we’ll show you how to take your data skills.
All three players have the same average score for shooting, but I need some way of choosing between them.
Sometimes it can be impossible to say what will happen from one minute to the.
But certain events are more likely to occur than others, and that’s where.
Manage Your Expectations5 Unlikely events happen, but what are the consequences? So far we’ve looked at how probabilities tell you how likely certain events are.
What probability doesn’t tell you is the overall impact of these events, and what it means.
Sure, you’ll sometimes make it big on the roulette table, but is it really worth it.
Counting all the possible ways in which you can order things is time.
So far we’ve looked at probability distributions where we’ve been able to specify exact.
Life can be so much simpler with the normal distribution.
Why spend all your time working out individual probabilities when you can look up entire ranges in one swoop, and.
Taking Samples Statistics deal with data, but where does it come from? Some of the time, data’s easy to collect, such as the ages of people attending a health.
In this chapter, we’ll take a look at how you.
Making Predictions11 Wouldn’t it be great if  you could tell what a population was like, just by taking one sample? Before you can claim full sample mastery, you need to know how to use your samples.
In this chapter, we’ll show you how knowing your sample helps you.
This is awesome! We have a lot of impressive statistics we can use in our.
Guessing with Confidence Sometimes samples don’t give quite the right result.
You’ve seen how you can use point estimators to estimate the precise value of the.
The trouble is, how do you know when what you’re being told isn’t right? Hypothesis tests give you a way of using samples to test whether or not statistical claims are likely.
They give you a way of weighing the evidence and testing whether extreme.
Come with us on a ride through this chapter, and we’ll show you how you can use.
Sometimes things don’t turn out quite the way you expect.
When you model a situation using a particular probability distribution, you have a.
Have you ever wondered how two things are connected? So far we’ve looked at statistics that tell you about just one variable—like men’s height, points scored by basketball players, or how long gumball flavor lasts—but there are other.
Stay with us while we show you the key to spotting connections:
Sweet! But is that a rain cloud I see up there?
There are just a few more things we think you need to know.
Where would you be without your trusty probability tables? Understanding your probability distributions isn’t quite enough.
For some of them, you need to be able to look up your probabilities in standard probability tables.
Do you need to understand statistics for a course, for your line of work, or just because you think it’s about time you learned what standard deviation means or how to find the probability of winning at roulette?
Do you want to learn, understand, and remember how to use probability and statistics to get the right results, every time?
Do you prefer stimulating dinner party conversation to dry, dull, academic lectures?
You don’t need to be advanced, but you should understand basic addition and subtraction, multiplication and division.
Are you a kick-butt statistician looking for a reference book?
Are you afraid to try something different? Would you rather have a root canal than mix stripes with plaid? Do you believe that a statistics book can’t be serious if Venn diagrams are anthropomorphized?
It was built that way, and it helps you stay alive.
So what does your brain do with all the routine, ordinary, normal things you encounter? Everything it can to stop them from interfering with the brain’s real job—recording things that matter.
It doesn’t bother saving the boring things; they never make it past the “this is obviously not important” filter.
How does your brain know what’s important? Suppose you’re out for a day hike and a tiger jumps in front of  you, what happens inside your head and body?
This must be important! Don’t forget it! But imagine you’re at home, or in a library.
Or trying to learn some tough technical topic your boss thinks will take a week, ten days at the most.
It’s trying to make sure that this obviously non-important content doesn’t clutter up scarce resources.
Resources that are better spent storing the really big things.
Like how you should never have posted those “party” photos on your Facebook page.
And there’s no simple way to tell your brain, “Hey brain, thank you very much, but no matter how dull this book is, and how little I’m registering on the emotional Richter scale right now, I really do want you to keep this stuff  around.”
We think of a “Head First” reade r as a learner.
If  you really want to learn, and you want to learn more quickly and more deeply, pay attention to how you pay attention.
Most of  us did not take courses on metacognition or learning theory when we were growing up.
We were expected to learn, but rarely taught to learn.
But we assume that if  you’re holding this book, you really want to learn statistics.
And you probably don’t want to spend a lot of  time.
If  you want to use what you read in this book, you need to remember what you read.
To get the most from this book, or any book or learning experience, take responsibility for your brain.
The trick is to get your brain to see the new material you’re learning as Really Important.
Otherwise, you’re in for a constant battle, with your brain doing its best to keep the new content from sticking.
So just how DO you get your brain to treat statistics like it was a hungry tiger? There’s the slow, tedious way, or the faster, more effective way.
You obviously know that you are able to learn and remember even the dullest of  topics if  you keep pounding the same thing into your brain.
With enough repetition, your brain says, “This doesn’t feel important to him, but he keeps looking at the same thing over and over and over, so I suppose it must be.”
The faster way is to do anything that increases brain activity, especially different types of  brain activity.
The things on the previous page are a big part of  the solution, and they’re all things that have been proven to help your brain work in your favor.
For example, studies show that putting words within the pictures they describe (as opposed to somewhere else in the page, like a caption or in the body text) causes your brain to try to makes sense of  how the words and picture relate, and this causes more neurons to fire.
More neurons firing = more chances for your brain to get that this is something worth paying attention to, and possibly recording.
A conversational style helps because people tend to pay more attention when they perceive that they’re in a conversation, since they’re expected to follow along and hold up their end.
The amazing thing is, your brain doesn’t necessarily care that the “conversation” is between you and a book! On the other hand, if  the writing style is formal and dry, your brain perceives it the same way you experience being lectured to while sitting in a roomful of  passive attendees.
Here’s what WE did: We used pictures, because your brain is tuned for visuals, not text.
As far as your brain’s concerned, a picture really is worth a thousand words.
And when text and pictures work together, we embedded the text in the pictures because your brain works more effectively when the text is within the thing the text refers to, as opposed to in a caption or buried in the text somewhere.
We used redundancy, saying the same thing in different ways and with different media types, and multiple senses, to increase the chance that the content gets coded into more than one area of  your brain.
We used concepts and pictures in unexpected ways because your brain is tuned for novelty, and we used pictures and ideas with at least some emotional content, because your brain is tuned to pay attention to the biochemistry of  emotions.
That which causes you to feel something is more likely to be remembered, even if  that feeling is nothing more than a little humor, surprise, or interest.
We used a personalized, conversational style, because your brain is tuned to pay more attention when it believes you’re in a conversation than if  it thinks you’re passively listening to a presentation.
We included more than 80 activities, because your brain is tuned to learn and remember more when you do things than when you read about things.
We used multiple learning styles, because you might prefer step-by-step procedures, while someone else wants to understand the big picture first, and someone else just wants to see an example.
But regardless of  your own learning preference, everyone benefits from seeing the same content represented in multiple ways.
We include content for both sides of  your brain, because the more of  your brain you engage, the more likely you are to learn and remember, and the longer you can stay focused.
Since working one side of  the brain often means giving the other side a chance to rest, you can be more productive at learning for a longer period of  time.
And we included stories and exercises that present more than one point of  view, because your brain is tuned to learn more deeply when it’s forced to make evaluations and judgments.
We included challenges, with exercises, and by asking questions that don’t always have a straight answer, because your brain is tuned to learn and remember when it has to work at something.
Think about it—you can’t get your body in shape just by watching people at the gym.
But we did our best to make sure that when you’re working hard, it’s on the right things.
That you’re not spending one extra dendrite processing a hard-to-understand example, or parsing difficult, jargon-laden, or overly terse text.
In stories, examples, pictures, etc., because, well, because you’re a person.
And your brain pays more attention to people than it does to things.
These tips are a starting point; listen to your brain and figure out what works for you and what doesn’t.
Your brain works best in a nice bath of  fluid.
Dehydration (which can happen before you ever feel thirsty) decreases cognitive function.
Practice solving problems! There’s only one way to truly master statistics: practice answering questions.
And that’s what you’re going to do throughout this book.
Using statistics is a skill, and the only way to get good at it is to practice.
We’re going to give you a lot of  practice: every chapter has exercises that pose problems for you to solve.
Don’t just skip over them—a lot of  the learning happens when you solve the exercises.
But try to solve the problem before you look at the solution.
And definitely make sure you understand what’s going on before you move on to the next part of  the book.
Groaning over a bad joke is still better than feeling nothing at all.
If  you find yourself  starting to skim the surface or forget what you just read, it’s time for a break.
Once you go past a certain point, you won’t learn faster by trying to shove more in, and you might even hurt the process.
If  you’re trying to understand something, or increase your chance of  remembering it later, say it out loud.
Better still, try to explain it out loud to someone else.
You’ll learn more quickly, and you might uncover ideas you hadn’t known were there when you were reading about it.
Part of  the learning (especially the transfer to long-term memory) happens after you put the book down.
Your brain needs time on its own, to do more processing.
If  you put in something new during that processing time, some of  what you just learned will be lost.
They’re not optional sidebars—they’re part of  the core content! Don’t skip them.
The more you understand, the less you have to memorize.
When the book asks you a question, don’t just skip to the answer.
The more deeply you force your brain to think, the better chance you have of learning and remembering.
Here’s what YOU can do to bend your brain into submission.
We put them in, but if  we did them for you, that would be like having someone else do your workouts for you.
There’s plenty of evidence that physical activity while learning can increase the learning.
We deliberately stripped out everything that might get in the way of  learning whatever it is we’re working on at that point in the book.
And the first time through, you need to begin at the beginning, because the book makes assumptions about what you’ve already seen and learned.
We begin by teaching basic ways of representing and summarizing data, then move on to probability distributions, and then more advanced techniques such as hypothesis testing.
While later topics are important, the first thing you need to tackle is fundamental building blocks such as charting, averages, and measures of  variability.
So we begin by showing you basic statistical problems that you actually solve yourself.
That way you can immediately do something with statistics, and you will begin to get excited about it.
Then, a bit later in the book, we show you how to use probability and probability distributions.
By then you’ll have a solid grasp of  statistics fundamentals, and can focus on learning the concepts.
After that, we show you how to apply your knowledge in more powerful ways, such as how to conduct hypothesis tests.
We teach you what you need to know at the point you need to know it because that’s when it has the most value.
We cover the same general set of topics that are on the AP and A Level curriculum.
While we focus on the overall learning experience rather than exam preparation, we provide good coverage of  the AP and A Level curriculum.
This means that while you work your way through the topics, you’ll gain the deep understanding you need to get a good grade in whatever exam it is you’re taking.
This is a far more effective way of  learning statistics than learning formulae by rote, as you’ll feel confident about what you need when, and how to use it.
Our readers tell us that sometimes you need a bit of  extra help, so we provide online resources, right at your fingertips.
We give you an online forum where you can go to seek help, online papers, and other resources too.
The exercises and activities are not add-ons; they’re part of  the core content of  the book.
Some of  them are to help with memory, some are for understanding, and some will help you apply what you’ve learned.
The crossword puzzles are the only thing you don’t have to do, but they’re good for giving your brain a chance to think about the words and terms you’ve been learning in a different context.
One distinct difference in a Head First book is that we want you to really get it.
And we want you to finish the book remembering what you’ve learned.
Most reference books don’t have retention and recall as a goal, but this book is about learning, so you’ll see some of  the same concepts come up more than once.
For some of  them, there is no right answer, and for others, part of  the learning experience of  the activities is for you to decide if  and when your answers are right.
In some of  the Brain Power and Brain Barbell exercises, you will find hints to point you in the right direction.
Dru Kleinfeld is a graduate of  Cornell University, class of  2007, with a BA in Economics.
Having started his career as a research physicist, Andy Parker thought he knew a thing or two about statistics.
Sadly, having read this book, that turned out not to be the case.
Andy spends most of  his time now, worrying about what other important things he may have forgotten.
Prerau is a researcher in Computational Neuroscience creating new statistical methods to analyze how the neurons encode information in the brain.
Sanders has been a delight to work with, and over the course of  phone calls, emails and chat clients has become a good friend.
He’s amazingly dedicated and hard-working, and the advice and support I’ve received from him have been first-rate.
Thanks Sanders! You’re awesome and I couldn’t have done this without you.
I wish there was space to mention everyone who has helped me along the way, but special thanks must go to David, Mum, Dad, Steve Harvey, Gill Chester, Paul Burgess, Andy Tatler, and Peter Walker.
You guys have kept me going, and I can’t tell you how much I’ve appreciated your support and encouragement.
A big thank you goes to Brett McLaughlin for flying me over to Boston for the Head First boot camp, and giving me the.
Brett’s instincts for Head First are phenomenal, and I’ve truly appreciated all the guidance he’s given me over the course of  the book.
It’s hard to imagine what this book would have been like without Lou Barr.
Lou is an amazing graphics designer who has sprinkled magic through all the pages of  this book.
Not only that, she’s added so much to the overall learning experience.
No challenge has been too great for her, and I’m so grateful to her.
The rest of  the Head First team also deserve a great big thank you.
Catherine Nolan helped me through the early stages of  the book and made me feel at home in Head First.
Keith McNamara did a great job organizing the tech review team, and Caitrin McCullough managed everything on the website.
A special mention goes to Kathy Sierra and Bert Bates for being the original masterminds behind this wonderful series of  books.
I want to look clean and pretty, so I give the right impression.
Can’t tell your facts from your figures? Statistics help you make sense of confusing sets of data.
And when you’ve found out what’s really going on, you.
Statistics are everywhere Everywhere you look you can find statistics, whether you’re browsing the Internet, playing sports, or looking through the top scores of  your favorite video game.
Statistics are numbers that summarize raw facts and figures in some meaningful way.
They present key ideas that may not be immediately apparent by just looking at the raw data, and by data, we mean facts or figures from which we can draw conclusions.
As an example, you don’t have to wade through lots of  football scores when all you want to know is the league position of  your favorite team.
You need a statistic to quickly give you the information you need.
The study of  statistics covers where statistics come from, how to calculate them, and how you can use them effectively.
Draw conclusions When you’ve analyzed your data, you make decisions and predictions.
Once you have data, you can analyze it and generate statistics.
You can calculate probabilities to see how likely certain events are, test ideas, and indicate how confident you are about your results.
You can say what you want with statistics, even lie.
But why learn statistics? Understanding what’s really going on with statistics empowers you.
If  you really get statistics, you’ll be able to make objective decisions, make accurate predictions that seem inspired, and convey the message you want in the most effective way possible.
Statistics can be a convenient way of  summarizing key truths about data, but there’s a dark side too.
Statistics are based on facts, but even so, they can sometimes be misleading.
They can be used to tell the truth—or to lie.
The problem is how do you know when you’re being told the truth, and when you’re being told lies?
Having a good understanding of  statistics puts you in a strong position.
You’re much better equipped to tell when statistics are inaccurate or misleading.
In other words, studying statistics is a good way of  making sure you don’t get fooled.
As an example, take a look at the profits made by a company in the latter half of  last year.
How can there be two interpretations of  the same set of  data? Let’s take a closer look.
You can use statistics to help explain things about the world.
A tale of two charts So how can we explore these two different interpretations of  the same data? What we need is some way of  visualizing them.
If  you need to visualize information, there’s no better way than using a chart or graph.
They can be a quick way of  summarizing raw information and can help you get an impression of  what’s going on at a glance.
But you need to be careful because even the simplest chart can be used to subtly mislead and misdirect you.
Here are two time graphs showing a companies profits for six months.
They’re both based on the same information, so why do they look so different? They give drastically different versions of  the same information.
See what I mean, the profit’s about the same each month.
Both of these charts are based on the same information, but they look wildly different.
Take a look at the two charts on the facing page.
What would you say are the key differences? How do they give such different first impressions of the data?
Q: Why not just go on the data? Why chart it? A: Sometimes it’s difficult to see what’s really going on just by looking at the raw data.
There can be patterns and trends in the data, but these can be very hard to spot if you’re just looking at a heap of numbers.
Charts give you a way of literally seeing patterns in your data.
They allow you to visualize your data and see what’s really going on in a quick glance.
Q: What’s the difference between information and data? A: Data refers to raw facts and figures that have been collected.
Information is data that has some sort of added meaning.
If you’re then told that these are the ages of three children, you have information as the numbers are now meaningful.
What would you say are the key differences? How do they give such different first impressions of the data?
The first chart shows that the profit is relatively steady.
It achieves this by having the vertical axis start at 0, and then plotting the profit for each month against this.
The second chart gives a different impression by making the vertical axis start at a different place and adjusting the scale accordingly.
At a glance, the profits appear to be rising dramatically each month.
It’s only when you look closer that you see what’s really going on.
Both charts are based on the same underlying data, but they each send a different message.
Chart software can save you a lot of  time and produce effective charts, but you still need to understand what’s going on.
At the end of  the day, it’s your data, and it’s up to you to choose the right chart for the job and make sure your data is presented in the most effective way possible and conveys the message you want.
Software can translate data into charts, but it’s up to you to make sure the chart is right.
Why should I care about charts? Chart software can handle everything for you, that’s what it’s there for.
Manic Mango needs some charts One company that needs some charting expertise is Manic Mango, an innovative games company that is taking the world by storm.
The CEO has been invited to deliver a keynote presentation at the next worldwide games expo.
He needs some quick, slick ways of  presenting data, and he’s asked you to come up with the goods.
If  the keynote goes well, Manic Mango will get extra sponsorship revenue, and you’re bound to get a hefty bonus for your efforts.
The first thing the CEO wants to be able to do is compare the percentage of  satisfied players for each game genre.
He’s started off  by plugging the data he has through some charting software, and here are the results:
Take a good look at the pie chart that the CEO has produced.
What does each slice represent? What can you infer about the relative popularity of different video game genres?
The humble pie chart Pie charts work by splitting your data into distinct groups or categories.
The chart consists of  a circle split into wedge-shaped slices, and each slice represents a group.
The size of  each slice is proportional to how many are in each group compared with the others.
The larger the slice, the greater the relative popularity of  that group.
The number in a particular group is called the frequency.
Pie charts divide your entire data set into distinct groups.
This means that if  you add together the frequency of  each slice, you should get 100%
Let’s take a closer look at our pie chart showing the number of  units sold per genre:
This slice is much larger than all the others, which means that the frequency is highest for this category.
The slice here is much smaller than the others, so this means sales are a lot lower for this category.
So when are pie charts useful? We’ve seen that the size of  each slice represents the relative frequency of  each group of  data you’re showingg.
Because of this, pie charts can be useful if  you want to compare basic proportions.
It’s usually easy to tell at a glance which groups have a high frequency compared with the others.
Pie charts are less useful if  all the slices have similar sizes, as it’s difficult to pick up on subtle differences between the slice sizes.
So what about the pie chart that the Manic Mango CEO has created?
Frequency Frequency describes how many items there are in a particular group or interval.
Chart failure Creating a pie chart worked out so great for displaying the units sold per genre that the CEO’s decided to create another to chart consumer satisfaction with Manic Mango’s game.
The CEO needs a chart that will allow him to compare the percentage of  satisfied players for each game genre.
He’s run the data through the charting software again, but this time he’s not as impressed.
Take a look at the data, and think about the problems there are with this chart.
What would be a better sort of chart for this kind of information?
Pie charts are used to compare the proportions of different groups or categories, but in this case there’s little variation between each group.
It’s difficult to take in at a glance which category has the highest level of  player satisfaction.
It’s also generally confusing to label pie charts with percentages that don’t relate to the overall proportion of the slice.
Another problem is that we don’t know whether there’s an equal number of  responses for each genre, so we don’t know whether it’s fair to compare genre satisfaction in this way.
What happened here? All the slices are the same size, but the percentages are all different and are much larger than the slices.
Bar charts can allow for more accuracy A better way of  showing this kind of  data is with a bar chart.
Just like pie charts, bar charts allow you to compare relative sizes, but the advantage of  using a bar chart is that they allow for a greater degree of  precision.
They’re ideal in situations where categories are roughly the same size, as you can tell with far greater precision which category has the highest frequency.
It makes it easier for you to see small differences.
On a bar chart, each bar represents a particular category, and the length of  the bar indicates the value.
All the bars have the same width, which makes it easier to compare them.
Vertical bar charts Vertical bar charts show categories on the horizontal axis, and either frequency or percentage on the vertical axis.
The height of  each bar indicates the value of  its category.
Here’s an example showing the sales figures in units for five regions, A, B, C, D, and E:
Horizontal bar charts Horizontal bar charts are just like vertical bar charts except that the axes are flipped round.
With horizontal bar charts, you show the categories on the vertical axis and the frequency or percentage on the horizontal axis.
As you can see, it’s much easier to quickly gauge which category has the highest value, and which the lowest.
Vertical bar charts tend to be more common, but horizontal bar charts are useful if  the names of  your categories are long.
They give you lots of space for showing the name of  each category without having to turn the bar labels sideways.
Each bar’s length represents the percentage of satisfied players for the genre.
The vertical bar chart shows frequency, and the horizontal bar chart shows percentages.
When should I use frequencies and when should I use percentages?
It’s a matter of scale Understanding scale allows you to create powerful bar charts that pick out the key facts you want to draw attention to.
But be careful—scale can also conceal vital facts about your data.
Using percentage scales Let’s start by taking a deeper look at the bar chart showing player satisfaction per game genre.
The horizontal axis shows player satisfaction as a percentage, the number of  people out of  every hundred who are satisfied with this genre.
Be very wary if you’re given percentages with no frequencies, or a frequency with no percentage.
Sometimes this is a tactic used to hide key facts about the underlying data, as just based on a chart, you have no way of telling how representative it is of the data.
You may find that a large percentage of people prefer one particular game genre, but that.
Alternatively, you might find that 10,000 players like sports games most, but by itself, you can’t tell whether this is a high or low proportion of all game players.
The purpose of  this chart is to allow us to compare different percentages and also read off  percentages from the chart.
There’s just one problem—it doesn’t tell us how many players there are for each genre.
This may not sound important, but it means that we have no idea whether this reflects the views of  all players, some of  them, or even just a handful.
In other words, we don’t know how representative this is of  players as a whole.
The golden rule for designing charts that show percentages is to try and indicate the frequencies, either on the chart or just next to it.
Using frequency scales You can show frequencies on your scale instead of  percentages.
This makes it easy for people to see exactly what the frequencies are and compare values.
So are you telling me that I have to choose between showing frequency or percentages? What if I want both?
There are ways of drawing bar charts that give you more flexibility.
The problem with these bar charts is that they show either the number of  satisfied players or the percentage, and they only show satisfied players.
Let’s take a look at how we can get around this problem.
This is something to watch out for on other people’s charts, as it’s very easy to miss and can give you the wrong impression of  the data.
The split-category bar chart One way of  tackling this is to use one bar for the frequency of  satisfied players and another for those dissatisfied, for each genre.
This sort of  chart is useful if  you want to compare frequencies, but it’s difficult to see proportions and percentages.
The segmented bar chart If  you want to show frequencies and percentages, you can try using a segmented bar chart.
For this, you use one bar for each category, but you split the bar proportionally.
The overall length of  the bar reflects the total frequency.
This sort of  chart allows you to quickly see the total frequency of  each category—in this case, the total number of  players for each genre—and the frequency of  player satisfaction.
Dealing with multiple sets of data With bar charts, it’s actually really easy to show more than one set of  data on the same chart.
As an example, we can show both the percentage of  satisfied players and the percentage of  dissatisfied players on the same chart.
Here’s the data; see if you can sketch the bar chart.
Here’s the data, see if you can create the chart.
In 2006, the Strategy genre sold more units than any other genre.
This data looks different from the other types of data we’ve seen so far.
How do you think this type of data is different? What impact do you think this could have on charts?
Nice work! Those charts are going to be a big hit at the expo.
We’ve been testing a new game with a group of volunteers, and we need a chart to show the breakdown of scores per game.
The frequency is the number of times a score within each range was achieved.
Your bar charts rock The CEO is thrilled with the bar charts you’ve produced, but there’s more data he needs to present at the keynote.
Once you’ve figured that out, you’ll find it easier to make key decisions about what chart you need to best represent your data.
Categorical or qualitative data Most of  the data we’ve seen so far is categorical.
The data is split into categories that describe qualities or characteristics.
An example of  qualitative data is game genre; each genre forms a separate category.
The key thing to remember with qualitative data is that the data values can’t be interpreted as numbers.
Numerical or quantitative data Numerical data, on the other hand, deals with numbers.
It’s data where the values have meaning as numbers, and that involves measurements or counts.
Numerical data is also called quantitative data because it describes quantities.
So what impact does this have on the chart for Manic Mango?
Dealing with grouped data The latest set of  data from the Manic Mango CEO is numeric and, what’s more, the scores are grouped into intervals.
So what’s the best way of  charting data like this?
That’s easy, don’t we just use a bar chart like we did before? We can treat each group as a separate category.
Rather than treat each range of  scores as a separate category, we can take advantage of  the data being numeric, and present the data using a continuous numeric scale instead.
This means that instead of  using bars to represent a single item, we can use each bar to represent a range of  scores.
Histograms are like bar charts but with two key differences.
The first is that the area of  each bar is proportional to the frequency, and the second is that there are no gaps between the bars on the chart.
Here’s an example of  a histogram showing the average number of games bought per month by households in Statsville:
There are no gaps between the bars.The area of each bar is proportional to the frequency.
The first step to creating a histogram is to look at each of  the intervals and work out how wide each of  them needs to be, and what range of  values each one needs to cover.
While doing this, we need to make sure that there will be no gaps between the bars on the histogram.
Histograms shouldn’t have gaps between the bars, so to get around this, we extend their ranges slightly.
Doing this forms a single boundary and makes sure that there are no gaps between the bars on the histogram.
If  we complete this for the rest of  the intervals, we get the following boundaries:
As all the intervals have the same width, we create the histogram by drawing vertical bars for each range of  scores, using the boundaries to form the start and end point of  each bar.
The height of  each bar is equal to the frequency.
See if you can use the class boundaries to create a histogram for this data.
See if you can use the class boundaries to create a histogram for this data.
The frequency is a statistical way of saying how many items there are in a category.
Numerical data deals with numbers and quantities; categorical data deals with words and qualities.
Horizontal bar charts are used for categorical data, particularly where the category names are long.
Vertical bar charts are used for numerical data, or categorical data if the category names are short.
You can show multiple sets of data on a bar chart, and you have a choice of how to do this.
You can compare frequencies by showing related bars sideby-side on a split-category bar chart.
You can show proportions and total frequencies by stacking the bars on top of each other on a segmented bar chart.
Q: So is a histogram basically for grouped numeric data? A: Yes it is.
The advantage of a histogram is that because its numeric, you can use it to show the width of each interval as well as the frequency.
Q: What about if the intervals are different widths? Can you still use a histogram?
It’s more common for the interval widths to be equal size, but with a histogram they don’t have to be.
There are a couple more steps you need to go through to create a histogram with unequal sized intervals, but we’ll show you that very soon.
The first is to show that there are no gaps in the values, and that every value is covered.
The second is so that the width of the interval reflects the range of the values you’re covering.
Q: So why do we make the bars meet midway between the two?
A: The bars have to meet, and it’s usually at the midway point, but it all comes down to how you round your values.
When you round values, you normally round them to the nearest whole number.
Q: Are there any exceptions to this? A: Yes, age is one exception.
Manic Mango needs another chart The CEO is very pleased with the histogram you’ve created for him—so much so, that he wants you to create another histogram for him.
This time, he wants a chart showing for how long Manic Mango players tend to play online games over a 24-hour period.
This is frequency with which people play for this lengh of time.
It’s grouped like last time, but the intervals aren’t all the same width.
If  you take a look at the intervals, you can see that they’re different widths.
If  we had access to the raw data, we could look at how we could construct equal width intervals, but unfortunately this is all the data we have.
We need a way of  drawing a histogram that makes allowances for the data having different widths.
For histograms, the frequency is proportional to the area of each bar.
How would you use this to create a histogram for this data? What do you need to be aware of?
I think we can just create this in the same way we did before—it’s no big deal.
We draw bars on a numeric scale; it’s just that this time the bars are different widths.
Do you think she’s right? Here’s a sketch of  the chart, using frequency on the vertical scale and drawing bar widths proportional to their interval size.
The problem with this chart is that making the width of  each bar reflect the width of  each interval has made some of  the bars look disproportionately large.
Just glancing at the chart, you might be left with a misleading impression about how many hours per day people really play games for.
As an example, the bar that takes up the largest area is the bar showing game play of  10–24 hours, even though most people don’t play for this long.
As this is a histogram, we need to make the bar area proportional to the frequency it represents.
As the bars have unequal widths, what should we do to the bar height?
Up until now, we’ve been able to use the height of  each bar to represent the frequency of  a particular number or category.
This time around, we’re dealing with grouped numeric data where the interval widths are unequal.
We can make the width of  each bar reflect the width of  each interval, but the trouble is that having bars of  different widths affects the overall area of  each bar.
We need to make sure the area of  each bar is proportional to its frequency.
This means that if  we adjust bar width, we also need to adjust bar height.
That way, we can change the widths of  the bars so that they reflect the width of  the group, but we keep the size of  each bar in line with its frequency.
Step 1: Find the bar widths We find how wide our bars need to be by looking at the range of  values they cover.
In other words, we need to figure out how many full hours are covered by each group.
If  we calculate the rest of  the widths, we get:
Now that we’ve figured out the bar widths, we can move onto working out the heights.
Step 2: Find the bar heights Now that we have the widths of  all the groups, we can use these to find the heights the bars need to be.
Remember, we need to adjust the bar heights so that the overall area of  each bar is proportional to the group’s frequency.
First of  all, let’s take the area of  each bar.
As we already know what the frequency of  each group is, we know what the areas should be too:
Area of bar = Frequency of group We were given these righ.
Now each bar is basically just a rectangle, which means that the area of each bar is equal to the width multiplied by the height.
We found the widths of  the bars in the last step, which means that we can use these to find what height each bar should be.
The height of  the bar is used to measure how concentrated the frequency is for a particular group.
It’s a way of  measuring how densely packed the frequency is, a way of  saying how thick or thin on the ground the numbers are.
The height of  the bar is called the frequency density.
What should the height of each bar be? Complete the table.
What should the height of each bar be? Complete the table.
Step 3: Draw your chart—a histogram Now that we’ve worked out the widths and heights of  each bar, we can draw the histogram.We draw it just like before, except that this time, we use frequency density for the vertical axis and not frequency.
This legend makes it easier to see what the area represents.
Frequency density refers to the concentration of  values in data.
It’s related to frequency, but it’s not the same thing.
Here’s an analogy to demonstrate the relationship between the two.
Imagine you have a quantity of  juice that you’ve poured into a glass like this:
What if  you then pour the same quantity of  juice into a different sized glass, say one that’s wider? What happens to the level of  the juice? This time the glass is wider, so the level the juice comes up to is lower.
The level of  the juice varies in line with the width of  the glass; the wider the glass, the lower the level.
The converse is true too; the narrower the glass, the higher the level of  juice.
The glass is wider, so the level isn’t as high.
Juice = Frequency Imagine that instead of  pouring juice into glasses, you’re “pouring” frequency into the bars on your chart.
Just as you know the width of  the glass, you know what width your bars are.
And just like the space the juice occupies in the glass (width x height) tells you the quantity of  juice in the glass, the area of  the bar on the graph is equivalent to its frequency.
The frequency density is then equal to the height of  the bar.
Keeping with our analogy, it’s equivalent to the level your juice comes to in each glass.
Just as a wider glass means the juice comes to a lower level, a wider bar means a lower frequency density.
So what does juice have to do with frequency density?
Q: Why do we use area to represent frequency when we’re graphing histograms?
A: It’s a way of making sure the relative sizes of each group stay in proportion to the data, and stay honest.
With grouped data, we need a visual way of expressing the width of each group and also its frequency.
Changing the width of the bars is an intuitive way of reflecting the group range, but it has the side effect of making some of the bar sizes look disproportionate.
Adjusting the bar height and using the area to represent frequency is a way around this.
This way, no group is misrepresented by taking up too much or too little space.
Q: What’s frequency density again? A: Frequency density is a way of indicating how concentrated values are in a particular interval.
It gives you a way of comparing different intervals that may be different widths.
It makes the frequency proportional to the area of a bar, rather than height.
To find the frequency density, take the frequency of an interval, and divide it by the width.
Q: If I have grouped numeric data, but all the intervals are the same width, can I use a normal bar chart?
A: Using a histogram will better represent your data, as you’re still dealing with grouped data.
You really want your frequency to be proportional to its area, not height.
Q: Do histograms have to show grouped data? Can you use them for individual numbers as well as groups of numbers?
The key thing to remember is to make sure there are no gaps between the bars and that you make each bar 1 wide.
Normally you do this by positioning your number in the center of the bar.
Frequency density relates to how concentrated the frequencies are for grouped data.
A histogram is a chart that specializes in grouped data.
It looks like a bar chart, but the height of each bar equates to frequency density rather than frequency.
When drawing histograms, the width of each bar is proportional to the width of its group.
In a histogram, the frequency of a group is given by the area of its bar.
Here’s a histogram representing the number of levels completed in each game of Cows Gone Wild.
How many games have been played in total? Assume each level is a whole number.
Here’s a histogram representing the number of levels completed in each game of Cows Gone Wild.
How many games have been played in total? Assume each level is a whole number.
We need to find the total number of games played, which means we need to find the total frequency.
The total frequency is equal to the area of each bar added together.
In other words, we multiply the width of each bar by its frequency density to get the frequency, and then add the whole lot up together.
What sort of information do you think we should show on the chart? What sort of information should we plot? Write your answer below.
It’s tricky to see at a glance what the running totals are in this chart.
In order to find the frequency of  players playing for up to 5 hours, we need to add different frequencies together.
I’d really like to be able to see at a glance how many people play for less than a certain number of hours.
While histograms are an excellent way to display grouped numeric data, there are still some kinds of  this data they’re not ideally suited for presenting—like running totals…
The CEO needs some sort of  chart that will show him the total frequency below a particular value: the cumulative frequency.
What we need to come up with is some sort of  graph that shows hours on the horizontal axis and cumulative frequency on the vertical axis.
That way, the CEO will be able to take a value and read off  the corresponding frequency up to that point.
Before we can draw the chart, we need to know what exactly we need to plot on the chart.
We need to calculate cumulative frequencies for each of  the intervals that we have, and also work out the upper limit of  each interval.
So what are the cumulative frequencies? First off, let’s suppose the CEO needs to plot the cumulative frequency, or total frequency, of  up to 1 hour.
Can you see a pattern? If  we take the upper limit of  each of  the groups of hours, we can find the total frequency of  hours up to that value by adding together the frequencies.
Drawing the cumulative frequency graph Now that we have the upper limits and cumulative frequencies, we can plot them on a chart.
Draw two axes, with the vertical one for the cumulative frequency and the horizontal one for the hours.
Once you’ve done that, plot each of  the upper limits against its cumulative frequency, and then join the points together with a line like this:
The CEO wants you to find the number of instances of people playing online for up to 4 hours.
See if you can estimate this using the cumulative frequency diagram.
If your cumulative frequency decreases at any point, check your calculations.
Q: What’s a cumulative frequency? A: The cumulative frequency of a value is the sum of the frequencies up to and including that value.
It tells you the total frequency up to that point.
As an example, suppose you have data telling you how old people are.
A: Not at all; you can use them for any sort of numeric data.
The key thing is whether you want to know the total frequency up to a particular value, or whether you’re more interested in the frequencies of particular values instead.
Q: On some charts you can show more than one set of data on the same chart.
A: You can do this for cumulative frequency graphs by drawing a separate line for each set of data.
If, say, you wanted to compare the cumulative frequencies by gender, you could draw one line showing males and the other females.
It would be far more effective to show both lines on one chart, as it makes it easier to compare the two sets of data.
Q: Is there a limit to how many lines you can show on one chart?
A: There’s no specific limit, as it all depends on your data.
Don’t have so many lines that the graph becomes cluttered and you can no longer use it to read off cumulative frequencies and compare sets of data.
Q: Remind me, how do I find the cumulative frequency of a value?
A: You can find the cumulative frequency by reading it straight off the graph.
You locate the value you want to find the cumulative frequency for on the horizontal axis, find where this meets the cumulative frequency curve, and then read the value of cumulative frequency off the vertical axis.
Q: If I already know the cumulative frequency, can I use the graph to find the corresponding value?
Look for the cumulative frequency on the vertical axis, find where it meets the cumulative frequency curve, and then read off the value.
To do this, we find 4 on the horizontal axis, find where this value meets the line of the graph, and read off the corresponding cumulative frequency on the vertical axis.
The CEO wants you to find the number of instances of people playing online for less than 4 hours.
See if you can estimate this using the cumulative frequency diagram.
During the Manic Mango keynote, the CEO wants to explain how he wants to target particular age groups.
He has a cumulative frequency graph showing the cumulative frequency of the ages, but he needs the frequencies too, and the dog ate the piece of paper they were written on.
See if you can use the cumulative frequency graph to estimate what the frequencies of each group are.
During the Manic Mango keynote, the CEO wants to explain how he wants to target particular age groups.
He has a cumulative frequency graph showing the cumulative frequency of the ages, but he needs the frequencies too, and the dog ate the piece of paper they were written on.
See if you can use the cumulative frequency graph to piece together what the frequencies of each group are.
Don’t worry if you get slightly different results—they’re just estimates.
Choosing the right chart The CEO is really happy with your work on cumulative frequency graphs, and your bonus is nearly in the bag.
He’s nearly finished preparing for the keynote, but there’s just one more thing he needs: a chart showing Manic Mango profits compared with the profits of  their main rivals.
Here are two possible charts that the CEO could use in his keynote.
Your task is to annotate each one, and say what you think the strengths and weaknesses are of each one relative to the other.
Here are two possible charts that the CEO could use in his keynote.
Your task is to annotate each one, and say what you think the strengths and weaknesses are of each one relative to the other.
The bar chart does a good job of comparing the profit on a year-by-year basis, and it’s great if you want to compare profits in an individual year.
A weaknesses of this chart is that if the CEO suddenly decided to add a third competitor, it might make the chart a bit harder to take in at a single glance.
The line chart is better at showing a trend, the year-on-year profits for each company.
The trend line for each company is well-defined, which means we easily see the pattern profits: Manic Mango profits are climbing well, where its competition is beginning to slacken off.
It would also be easy to add another company without swamping the chart.
A weakness is that you can also compare year-by-year profit, but perhaps the bar chart is clearer.
We’d choose the line chart, as the overall trend is clearer than on the bar chart.
But don’t worry if you chose the other; the chart you use depends on which key facts you want to emphasize.
Line charts are good at showing trends in your data.
For each set of  data, you plot your points and then join them together with lines.
You can easily show multiple sets of  data on the same chart without it getting too cluttered.
As with other sorts of  charts, you have a choice of  showing frequency or percentages on the vertical axis.
The scale you use all depends on what key facts you want to draw out.
Time always goes on the horizontal axis, and frequency on the vertical.
You can read off  the frequency for any period of  time by choosing the time value on the horizontal axis, and reading off  the corresponding frequency for that point on the line.
Line charts should be used for numerical data only, and not categorical.
This is because it makes sense to compare different categories, but not to draw a trend line.
Only use a line chart if  you’re comparing categories over some numerical unit such as time, and in that case you’d use a separate line for each category.
Cumulative frequency is the total frequency up to a particular value.
Use a cumulative frequency graph to plot the upper limit of each group of data against cumulative frequency.
Use a line chart if you want to show trends, for example over time.
You can show more than one set of data on a line chart.
Use one line for each set of data, and make sure it’s clear which line is which.
You can use line charts to make basic predictions as it’s easy to see the shape of the trend.
Just extend the trend line, trying to keep the same basic shape.
Don’t use line charts to show categorical data unless you’re showing trends for each category, for example over time.
Q: Are line charts the same thing as time series charts? I think I’ve heard that name used before.
A: A time series chart is really a line chart that focuses on time intervals, just like the examples we used.
A line chart doesn’t have to focus on just time, though.
The cumulative frequency graph is a type of line chart that shows the total frequency up to a certain value.
Q: Can line charts show categorical data as well as data that’s numeric?
A: Line charts should only be used to show categorical data if you’re showing trends for each category, and use a separate line for each category.
What you shouldn’t do is use a line chart to draw lines from category to category.
Q: So line charts are better for showing overarching trends, and bar charts are better for comparing values or categories?
Which chart you use really comes down to what message you want to put across, and what key facts you want to minimize.
Q: Now that I know how to create charts properly, can I use charting software to do the heavy lifting?
A: Absolutely! Charting software can save you a lot of time and hard work, and the results can be excellent.
The key thing with using software to produce your charts is to remember that the software can’t think for you.
You still have to decide which chart best represents your key facts, and you have to check that the software produces exactly what you expect it to.
Manic Mango conquered the games market! You’ve helped produce some killer charts for Manic Mango, and thanks to you, the keynote was a huge success.
Manic Mango has gained tons of  extra publicity for their games, and money from sponsorship and advertising is rolling in.
The only thing left for you to do is think about all the things you could do and the places you could go with your well-earned bonus.
You’ve had your first taste of  how statistics can help you and what you can achieve by understanding what’s really going on.
Keep reading and we’ll show you more things you can do with statistics, and really start to flex those statistics muscles.
Nice work with those charts! We’ve got investors lining up outside the office.
Sometimes you just need to get to the heart of  the matter.
It can be difficult to see patterns and trends in a big pile of figures, and finding the.
People say I’m just an average golfer, but I’ll show them I’m really mean.
Welcome to the Health Club The Statsville Health Club prides itself  on its ability to find the perfect class for everyone.
Whether you want to learn how to swim, practice martial arts, or get your body into shape, they have just the right class for you.
The staff  at the health club have noticed that their customers seem happiest when they’re in a class with people their own age, and happy customers always come back for more.
It seems that the key to success for the health club is to work out what a typical age is for each of  their classes, and one way of  doing this is to calculate the average.
The average gives a representative age for each class, which the health club can use to help their customers pick the right class.
Here are the current attendees of  the Power Workout class:
How do we work out the average age of the Power Workout class?
A common measure of average is the mean It’s likely that you’ve been asked to work out averages before.
One way to find the average of  a bunch of  numbers is to add all the numbers together, and then divide by how many numbers there are.
What’s wrong with just calling it the average? It’s what I’m used to.
You have to know what to call each average, so you can easily communicate which one you’re referring to.
It’s a bit like going to your local grocery store and asking for a loaf  of  bread.
The chances are you’ll be asked what sort of  bread you’re after: white, whole-grain, etc.
So if  you’re writing up your sociology research findings, for example, you’ll be expected to specify exactly what kinds of  average calculations you did.
Likewise, if  someone tells you what the average of  a set of  data is, knowing what sort of  average it is gives you a better understanding of what’s really going on with the data.
It can give you vital clues about what information is being conveyed—or, in some cases, concealed.
We’ll be looking at other types of  averages, besides the mean, later in this chapter.
Mean math If  you want to really excel with statistics, you’ll need to become comfortable with some common stats notation.
It may look a little strange at first, but you’ll soon get used to it.
Letters and numbers Almost every statistical calculation involves adding a bunch of numbers together.
As an example, if  we want to find the mean of the Power Workout class, we first have to add the ages of  all the class attendees together.
We don’t necessarily know in advance how many numbers we’re dealing with, or what they are.
We currently know how many people are in the Power Workout class and what their ages are, but what if  someone else joins the class? If  we could only generalize this, we’d have a way of  showing the calculation without rewriting it every time the class changes.
Statisticians get around this problem by using letters to represent numbers.
As an example, they might use the letter x to represent ages in the Power Workout class like this:
Each x represents the age of  a separate person in the class.
It’s a bit like labeling each person with a particular number x.
Now that we have a general way of  writing ages, we can use our x’s to represent them in calculations.
We can write the sum of  the 5 ages in the class as.
But what if we don’t know how many numbers we have to sum? What if we don’t know how many people are in the class?
Dealing with unknowns Statisticians use letters to represent unknown numbers.
But what if  we don’t know how many numbers we might have to add together? Not a problemwe’ll just call the number of  values n.
If  we didn’t know how many people were in the Power Workout class, we’d just say that there were n of  them, and write the sum of  all the ages as:
In this case, xn represents the age of  the nth person in the class.
We’re far more likely to say “add together all of  the ages.” It’s quicker, simpler, and to the point.
Now that we know some handy math shortcuts, let’s see how we can apply this to the mean.
Writing out all those x’s looks like it could get arduous...
Some people say I’m average, but deep down, I’m mean.
Back to the mean We can use math notation to represent the mean.
To find the mean of  a group of  numbers, we add them all together, and then divide by how many there are.
We’ve already seen how to write summations, and we’ve also seen how statisticians refer to the total count of  a set of  numbers as n.
If  we put these together, we can write the mean as:
In other words, this is just a math shorthand way of  saying “add together all of  the numbers, and then divide by how many numbers there are.”
The mean has its own symbol The mean is one of  the most commonly used statistics around, and statisticians use it so frequently that they’ve given it a symbol all of  its own:
Remember, it’s just a quick way of  representing the mean.
Have a go at calculating the mean age of the Power Workout class?  Here are their ages.
The Case of  the Ambiguous Average The staff  at a local company are feeling mutinous about perceived unfair pay.
One of  the managers overhears this and joins in with the demands.
You’re all wrong; the average salary is $500 per week.
What’s going on with the average? Who do you think is right?
Have a go at calculating the mean age of the Power Workout class?  Here are their ages.
Multiply each number by its frequency, then add the results together.
Handling frequencies When you calculate the mean of  a set of  numbers, you’ll often find that some of  the numbers are repeated.
It’s really important to make sure that you include the frequency of  each number when you’re working out the mean.
To make sure we don’t overlook it, we can include it in our formula.
If  we use the letter f to represent frequency, we can rewrite the mean as.
This is just another way of  writing the mean, but this time explicitly referring to the frequency.
Back to the Health Club Here’s another hopeful customer looking for the perfect class.
I want a nice quiet class on a Tuesday evening where I can meet people my age.
According to the brochure, the Health Club has places available in three of  its Tuesday evening classes.
Clive needs to find the class with an average student age that’s closest to his own.
Meet Clive, a man in his late fifties who wants an exercise class composed of other middle-aged folks.
What could have gone wrong? The last thing Clive expected (or wanted) was a class that was primarily made up of  teenagers.
Let’s see if  sketching the data helps us see what the problem is.
He was expecting a gentle class where he could get some nonstrenuous exercise and meet other people his own age.
I ended up in the Kung Fu class with lots of young ‘uns and a few ancient masters.
How do the shapes of the distributions compare? Why was Clive sent to the wrong class? Power Workout Classmate Ages.
How do the shapes of the distributions compare? Why was Clive sent to the wrong class? Power Workout Classmate Ages.
Do you think the mean can ever be the highest value in a set of numbers? Under what circumstances?
Our data has outliers Did you see the difference in the shape of  the charts for the Power Workout and Kung Fu classes? The ages of  the Power Workout class form a smooth, symmetrical shape.
It’s easy to see what a typical age is for people in the class.
The shape of  the chart for the Kung Fu class isn’t as straightforward.
Most of  the ages are around 20, but there are two masters whose ages are much greater than this.
What would the mean have been if the ancient masters weren’t part of the class? Compare this with the actual mean.
What does this tell you about the effect of the outliers?
The mean is 38, but nobody in the class is around that age.
Can you see how the outliers have pulled the mean higher? This effect is caused by outliers in the data.
The Kung Fu class data is skewed to the right because if  you line the data up in ascending order, the outliers are on the right.
If  you look at the data and chart of  the Kung Fu class, it’s easy to see that most of  the people in the class are around 20 years old.
In fact, this would be the mean if  the ancient masters weren’t in the class.
We can’t just ignore the ancient masters, though; they’re still part of the class.
Unfortunately, the presence of  people who are way above the “typical” age of  the class distorts the mean, pulling it upwards.
Do you think the mean can ever be the highest value in a set of numbers? Under what circumstances?
The mean is the highest value if all of the numbers in the data set are the same.
Skewed Data When outliers “pull” the data to the left or right.
Outlier An extreme high or low value that stands out from the rest of the data.
Without the ancient masters, the mean would be around here.
Skewed to the right Data that is skewed to the right has a “tail” of high outliers that trail off  to the right.
If  you look at a right-skewed chart, you can see this tail.
The high outliers in the Kung Fu class data distort the mean, pulling it higher—that is, to the right.
Skewed to the left Here’s a chart showing data that is skewed to the left.
Can you see the tail of  outliers on the left? This time the outliers are low, and they pull the mean over to the left.
In this situation, the mean is lower than the majority of  values.
Symmetric data In an ideal world, you’d expect data to be symmetric.
If  the data is symmetric, the mean is in the middle.
There are no outliers pulling the mean in either direction, and the data has about the same shape on either side of  the center.
Most values are around here, but the mean is higher.
Clive: They told me the average age for the class is about 38, so I thought I’d fit in alright.
I had to sit down after 5 minutes before my legs gave out.
Bendy Girl: But I didn’t see anyone that age in the class, so there must have been some sort of  mistake in their calculations.
Clive: I don’t think their calculations were wrong; they just didn’t tell me what I really needed to know.
Bendy Girl: And that’s not really typical, is it? I mean, just looking at the people in the class, I would’ve thought that a younger age would be a bit more representative.
Clive: If  only they’d left the Ancient Masters out of  their calculations, I would’ve known not to go to the class.
Bendy Girl: Well, if  the Ancient Masters are such a big problem, why can’t they just ignore them? Maybe that way they could come up with a more typical age for the class...
Finding the median If  the mean becomes misleading because of  skewed data and outliers, then we need some other way of  saying what a typical value is.
We can do this by, quite literally, taking the middle value.
This is a different sort of  average, and it’s called the median.
To find the median of  the Kung Fu class, line up all the ages in ascending order, and then pick the middle value, like this:
If  you line all the ages up in ascending order, the value 20 is exactly halfway along.
What if  there had been an even number of  people in the class?
If there’s an even number of people in the class, there will be no single middle number.
If  you have an even set of  numbers, just take the mean of  the two middle numbers (add them together, and divide by 2), and that’s your median.
Line your numbers up in order, from smallest to largest.
If you have an odd number of values, the median is the one in the middle.
The two middle numbers are on either side of this point.
Q: Is it still OK to use the mean with skewed data if I really want to?
However, in this situation the mean won’t give you the best representation of what a typical value is.
Q: You say that, but surely the whole point of the mean is that it gives a typical value.
A: The big danger is that the mean will give a value that doesn’t exist in the data set.
If you were to go into the class and pick a person at random, the chances are that person would be around 20 years old because most people in the class are that sort of age.
Just going with the mean doesn’t give you that impression.
Finding the median can give you a more accurate perspective on the data.
But sometimes even the median will give a value that’s not in the data set, like our example on the previous page.
That’s precisely why there’s more than one sort of average; sometimes you need to use different methods in order to accurately say what a typical value is.
Q: So is the median better than the mean? A: Sometimes the median is more appropriate than the mean, but that doesn’t make it better.
Most of the time you’ll need to use the mean because it usually offers significant advantages over the median.
The mean is more stable when you are sampling data.
A: You can only find the mean and median of numerical data.
Don’t worry, though, there’s another sort of average that deals with just this problem that we’ll explore later on.
Q: I always get right- and left-skewed data mixed up.
To see which direction the data is skewed in, find the direction the tail is pointing in.
For example, right-skewed data has a tail that points to the right.
The data is skewed to the right, which pulls the mean higher.
The data is skewed to the left, so the mean is pulled to the left.
If the data is skewed to the right, the mean is to the right of the median (higher)
If the data is skewed to the left, the mean is to the left of the median (lower)
Business is booming Your work on averages is really paying off.
More and more people are turning up for classes at the Health Club, and the staff  is finding it much easier to find classes to suit the customers.
This teenager is after a swimming class where he can make new friends his own age.
The swimming class you have for teenagers sounds cool! Sign me up right now.
The swimming class has a mean age of  17, and coincidentally, that’s the median too.
It sounds like this class will be perfect for him.
The Little Ducklings swimming class The Little Ducklings class meets at the swimming pool twice a week.
In this class, parents teach their very young children how to swim, and they all have lots of  fun splashing about in the water.
What do you think might have gone wrong this time?
Frequency Magnets Here are the ages of people who go to the Little Ducklings class, but some of the frequencies have fallen off.
Your task is to put them in the right slot in the frequency table.
When you’ve figured out the frequencies for the Little Ducklings class, sketch the histogram.
Frequency Magnets Here are the ages of people who go to the Little Ducklings class, but some of the frequencies have fallen off.
Your task is to put them in the right slot in the frequency table.
When you’ve figured out the frequencies for the Little Ducklings class, sketch the histogram.
It doesn’t look like one set of data, but two: one for the parents and one for the children.
What went wrong with the mean and median? Let’s take a closer look at what’s going on.
Here are the ages of  people who go to the Little Ducklings class.
But what if  there had been an odd number of  people in the class.
Both the mean and median would still have been misleading.
But that fails to reflect all the kids in the class.
Whichever value we choose for the average age, it seems misleading.
This reflects the age of  the children, but doesn’t take the adults into account.
Here’s where you have to really think about how you can best give a representative age (or ages) for the Little Ducklings class.
Why do you think the mean and median both failed for this data? Why are they misleading?
If you had to pick one age to represent this class, what would it be? Why?
What if you could pick two ages instead? Which two ages would you pick, and why?
Head First: Hey, Average, great to have you on the show...
You see, there’s more than one type of  Average in Statsville, and I’m one of  them, the Mean.
Mean: Not really, not once you get used to it.
You see, we all say what a typical value is for a set of numbers, but we have different opinions about how to say what that is.
Head First: So which one of  you is the real Average? You know, the one where you add all the numbers together, and then divide by however many numbers there are?
Mean: That’s me, but please don’t call me the “real” Average; the other guys might get offended.
The truth is that a lot of  people new to Statsville see me as being Mr.
I have the same calculation that students see when they first encounter Averages in basic arithmetic.
It’s just that in Statsville, I’m called Mean to differentiate between the other sorts of  Average.
Head First: So why are any of  the other sorts of Average needed?
Mean: I hate to say it, but I have weaknesses.
I lose my head a bit when I deal with data that has outliers.
Without the outliers I’m fine, but then when I see outliers, I get kinda mesmerized and move towards them.
I can sometimes end up well away from where most of  the values are.
No matter what you throw at him, he always stays right in the middle of  the data.
Of  course, the downside of  the Median is that you can’t calculate him as such; you can only work out what position he should be in.
It makes him a bit less useful further down the line.
Head First: Do the two of  you ever have the same value?
Mean: We do if  the data’s symmetric; otherwise, there tends to be differences between us.
As a general rule, if  there are outliers, then I tend to wander towards them, while Median stays where he is.
Head First: We’re running out of  time, so here’s one final question.
Are there any situations where both you and Median have problems saying what a typical value is?
Sometimes we need a little helping hand from another sort of  Average.
He doesn’t get out all that much, but he’s a useful guy to know.
Stick around, and I’ll show you some of  the things he’s up to.
Here’s where you have to really think about how you can best give a representative age (or ages) for the Little Ducklings class.
Why do you think the mean and median both failed for this data? Why are they misleading?
If you had to pick one age to represent this class, what would it be? Why?
What if you could pick two ages instead? Which two ages would you pick, and why?
Both the mean and median are misleading for this set of data because neither fully represents the typical ages of people in the class.
The mean suggests that teenagers go to the class, when in fact there are none.
The median also has this problem, but it can fluctuate wildly if other people join the class.
It’s not really possible to pick a single age that fully represents the ages in the class.
The class is really made up of two sets of ages, those of the children and those of the parents.
You can’t really represent both of these groups with a single number.
As it looks like there are two sets of data, it makes sense to pick two ages to represent the class, one for the children and one for the parents.
Introducing the mode In addition to the mean and median, there’s a third type of average called the mode.
The mode of  a set of  data is the most popular value, the value with the highest frequency.
Unlike the mean and median, the mode absolutely has to be a value in the data set, and it’s the most frequent value.
If  there is more than one value with the highest frequency, then each one of  these values is a mode.
If  the data looks as though it’s representing more than one trend or set of  data, then we can give a mode for each set.
If  a set of  data has two modes, then we call the data bimodal.
This is exactly the situation we have with the Little Ducklings class.
There are really two sets of  ages we’re looking at, one for parents and one for children, so there isn’t a single age that’s totally representative of  the entire class.
Instead, we can say what the mode is for each set of  ages.
On a chart, the modes are the ones with the highest frequencies.
These two values are the most popular, so they are both modes.
It even works with categorical data The mode doesn’t just work with numeric data; it works with categorical data, too.
In fact, it’s the only sort of  average that works with categorical data.
When you’re dealing with categorical data, the mode is the most frequently occurring category.
You can also use it to specify the highest frequency group of values.
The category or group with the highest frequency is called the modal class.
Find all the distinct categories or values in your set of data.
Pick out the one(s) with the highest frequency to get the mode.
Congratulations! Your efforts at the Health Club are proving to be a huge success, and demand for classes is high.
But don’t tell the ladies my median score is two.
Three cheers for M-O-D-E! Most of the class is the same age as me!
An experienced tennis coach like me earns a median salary of $33/hour.
I can run a mile in a mean of 25 minutes, but that includes.
I lose a mean of 7 teeth per hockey match.
The mode here is 2, as it has the highest frequency.
When the data set has a low number of modes, or when the data is categorical instead of numerical.
Neither the mean nor the median can be used with categorical data.
Mode The mode has to be in the data set.
For each type of average we’ve encountered in the chapter, write down how to calculate it, and then give the circumstances in which you should use each one.
Try your hardest to fill this out without looking back through the chapter.
For each type of average we’ve encountered in the chapter, write down how to calculate it, and then give the circumstances in which you should use each one.
Try your hardest to fill this out without looking back through the chapter.
When the data is fairly symmetric and shows just the one trend.
If there are an odd number of values, the median is the one in the middle.
If there are an even number of values, add the two middle ones together, and divide by two.
If the data is showing two clusters of data, report a mode for each group.
When the data shows two or more clusters of data.
The only type of average you can calculate for categorical data is the mode.
The generous CEO of Starbuzz Coffee wants to give all his employees a pay raise.
If you earn the mean wage, you’ll get a larger pay increase if you get a 10% pay raise.
If you earn the mode wage, you’ll get more money if you ask for the straight $2,000 pay increase.
Median: Every wage has $2,000 added to it, and this includes the middle value—the median.
Median: Every wage is multiplied by 1.1, and this includes the middle value—the median.
The generous CEO of Starbuzz Coffee wants to give all his employees a pay rise.
What’s going on with the average? Who do you think is right?
The workers, the managers, and the CEO are each using a different sort of  average.
The workers are using the median, which minimizes the effect of  the CEO’s salary.
The large salary of  the CEO is skewing the data to the right, which is making the mean artificially high.
Most workers are paid $500 per week, and so this is the mode of  the salaries.
So who’s right? In a sense, they all are, although it has to be said that each group of  people are using the average that best supports what they want.
Remember, statistics can be informative, but they can also be misleading.
For balance, we think that the most appropriate average to use in this situation is the median because of  the outliers in the data.
Not everything’s reliable, but how can you tell? Averages do a great job of giving you a typical value in your data set, but they.
OK, so you know where the center of your data.
When you have an oven with a lower standard deviation, you’ll never burn anything again.
Wanted: one player The Statsville All Stars are the hottest basketball team in the neighborhood, and they’re the favorite to win this year’s league.
There’s only one problem—due to a freak accident, they’re a player down.
The new recruit must be good all-round, but what the coach really needs is a reliable shooter.
If  he can trust the player’s ability to get the ball in the basket, they’re on the team.
The coach has been conducting trials all week, and he’s down to three players.
All three players have the same average score for shooting, but I need some way of choosing between them.
All three players had the same average score in the trials, so how should the coach decide which to pick?
What information in addition to the average would help the coach make his decision?
Each player has a mean, median, and mode score of  10 points, but if  you look at their scores, you’ll see they’ve all achieved it in different ways.
There’s a difference in how consistently the players have performed, which the average can’t measure.
What we need is a way of  differentiating between the three sets of  scores so that we can pick the most suitable player for the team.
We need some way of  comparing the sets of  data in addition to the average—but what?
Here, frequency tells us the number of games where the player got each score.
Use the range to differentiate between data sets So far we’ve looked at calculating averages for sets of  data, but quite often, the average only gives part of  the picture.
Averages give us a way of determining where the center of  a set of  data is, but they don’t tell us how the data varies.
Each player has the same average score, but there are clear differences between each data set.
We can differentiate between each set of  data by looking at the way in which the scores spread out from the average.
Each player’s scores are distributed differently, and if  we can measure how the scores are dispersed, the coach will be able to make a more informed decision.
To calculate the range, we subtract the lower bound from the upper bound.
Looking at the data, the smallest value is 7, which means that this is the lower bound.
Subtracting the lower bound from the upper bound gives us:
The range is a simple and easy way of  measuring how spread out values are, and it gives us another way of  comparing sets of  data.
The mean tells us nothing about how spread out the data is, so we need some other measure to tell us this.
Measuring the range We can easily do this by calculating the range.
The range tells us over how many numbers the data extends, a bit like measuring its width.
To find the range, we take the largest number in the data set, and then subtract the smallest.
The smallest value is called the lower bound, and the largest value is the upper bound.
Let’s take a look at the set of  scores for one of  the players and see how this works.
Range The range is a way of measuring how spread out a set of values are.
It’s given by Upper bound - Lower bound where the upper bound is the highest value, and the lower bound the lowest.
Work out the mean, lower bound, upper bound, and range for the following sets of data, and sketch the charts.
Are values dispersed in the same way? Does the range help us describe these differences?
Work out the mean, lower bound, upper bound, and range for the following sets of basketball scores, and sketch the charts.
Are values dispersed in the same way? Does the range help us describe these differences?
The range only describes the width of the data, not how it’s dispersed between the bounds.
Both sets of  data above have the same range, but the second set has outliers—extreme high and low values.
It looks like the range can measure how far the values are spread out, but it’s difficult to get a real picture of  how the data is distributed.
Both data sets above have the same range, but the values are distributed.
I wonder if the range really gives us the full story about measuring spread?
The problem with outliers The range is a simple way of  saying what the spread of  a set of data is, but it’s often not the best way of  measuring how the data is distributed within that range.
If  your data has outliers, using the range to describe how your values are dispersed can be very misleading because of  its sensitivity to outliers.
Here, numbers are fairly evenly distributed between the lower bound and upper bound, and there are no outliers for us to worry about.
But what happens if  we introduce an outlier, like the number 10?
Here’s the data on a vertical line chart (a type of bar chart that uses lines instead of bars)
Each line represents the frequency of each number in the data set.
The range has increased by 5 just because we added one extra number, an outlier.
Without the outlier, the two sets of  data would be identical, so why should there be such a big difference in how we describe how the values are distributed?
Can you think of a way in which we can construct a range that’s less sensitive to outliers?
So is it a bad idea to use the range then?
The range is a great quick-and-dirty way to get an idea of how values are distributed, but it’s a bit limited.
The range tells you how far apart your highest and lowest values are, but that’s about it.
It only provides a very basic idea of  how the values are distributed.
The primary problem with the range is that it only describes the width of your data.
Because the range is calculated using the most extreme values of  the data, it’s impossible to tell what that data actually looks like—and whether it contains outliers.
There are many different ways of  constructing the same range, and sometimes this additional information is important.
The range is so simple that it’s easily understood by lots of  people, even those who have had very little exposure to statistics.
If  you talk about a range of  ages, for example, people will easily understand what you mean.
Be careful, though, because there’s danger in its pure simplicity.
As the range doesn’t give the full picture of what’s going on between the highest and lowest values, it’s easy for it to be used to give a misleading impression of  the underlying data.
If the range is so limited, why do people use it?
Wait a sec, do you mean we pretend the outliers don’t exist? That doesn’t sound very scientific.
We need to get away from outliers The main problem with the range is that, by definition, it includes outliers.
If data has outliers, the range will include them, even though there may be only one or two extreme values.
What we need is a way of  negating the impact of these outliers so that we can best describe how values are dispersed.
One way out of  this problem is to look at a kind of  mini range, one that ignores the outliers.
Instead of  measuring the range of  the whole set of  data, we can find the range of  part of  it, the part that doesn’t contain outliers.
One of  the problems with ignoring outliers on an ad hoc basis is that it’s difficult to compare sets of  data.
How do we know that all sets of  data are omitting outliers in exactly the same way?
We need to make sure that we use the same mini range definition for all the sets of  data we’re comparing.
This is the same data as before, but this time it’s split into quarters.
We can then construct a range using the values that fall between the two outer splits:
The values that split the data into equal chunks are known as quartiles, as they split the data into quarters.
Instead of  finding the value that splits the data in half, we’re finding the values that split the data into quarters.
The quartile in the middle (Q2) is the median, as it splits the data in half.
The range of  the values in these two quartiles is called the interquartile range (IQR)
Taking the range between these values gives us a brand new “mini” range.
The interquartile range gives us a standard, repeatable way of  measuring how values are dispersed.
It’s another way in which we can compare different sets of  data.
But what about outliers? Does the interquartile range help us deal with these too? Let’s take a look.
Quartiles come to the rescue One way of  constructing a mini range is to just use values around the center of the data.
We can construct a range in this way by first lining up the values in ascending order, and then splitting the data into four equally sized chunks, with each chunk containing one quarter of  the data.
Some textbooks refer to quartiles as the set of values within each.
We’re using the term quartile to specifically refer to the values that split the data into quarters.
Quartiles Quartiles are values that split your data into quarters.
The lowest quartile is called the lower quartile, and the highest quartile is called the upper quartile.
The interquartile range excludes outliers The good thing about the interquartile range is that it’s a lot less sensitive to outliers than the range is.
This means that the interquartile range only uses the central 50% of  the data, so outliers are disregarded.
As we’ve said before, outliers are extreme high or low values in the data, so by only considering values around the center of  the data, we automatically exclude any outliers.
Can you see how the interquartile range effectively ignores any outliers?
As the interquartile range only uses the central 50% of  the data, outliers are excluded irrespective of  whether they are extremely high or extremely low.
This means that any outliers in the data are effectively cut out.
The interquartile range includes the middle part of the data...
Outliers are always extreme high or low values, and the interquartile range cuts these out.
Excluding the outliers with the interquartile range means that we now have a way of  comparing different sets of  data without our results being distorted by outliers.
Before we can figure out the interquartile range, though, we have to work out what the quartiles are.
Flip the page, and we’ll show you how it’s done.
Interquartile Range A “mini range” that’s less sensitive to outliers.
You find it by calculating Upper quartile - Lower quartile.
If  we then further split the data into quarters, the quartiles are the values at each of these splits.
The lowest is the lower quartile, and the highest is the upper quartile:
Finding the position of  the quartiles is slightly trickier than finding the position of  the median, as we need to make sure the values we choose keep the data split into the right proportions.
There is a way of  doing it though; let’s start with the lower quartile.
If  this gives you an integer, then the lower quartile is positioned halfway between this position and the next one.
Take the average of  the numbers at these two positions to get your lower quartile.
If  it’s an integer, then the upper quartile is positioned halfway between this position and the next.
The lower bound of this set of data is 3, as that’s the lowest number of points scored.
The interquartile range is the lower bound subtracted from the upper bound.
Q: I get why mean, median, and mode are useful, but why do I need to know how the data is spread out?
A: Averages offer you only a one-dimensional view of your data.
They tell you what the center of your data is, but that’s it.
You need some other way of summarizing your data in addition to the average.
Q: So is the median the same as the interquartile range? A: No.
The median is the middle value of the data, and the interquartile range is the range of the middle 50% of the values.
Q: What’s the point of all this quartiles stuff? It seems like a really tedious way to calculate ranges.
A: The problem with using the range to measure how your data is dispersed is that it’s very sensitive to outliers.
It gives you the difference between the lower and upper bounds of your data, but just one outlier can make a huge difference to the result.
We can get around this by focusing only on the central 50% of the data, as this excludes outliers.
So even though finding quartiles is trickier than finding the lower and upper bounds, there are definite advantages.
Q: Should I always use the interquartile range to measure the spread of data?
A: In a lot of cases, the interquartile range is more meaningful than the range, but it all depends on what information you really need.
There are other ways of measuring how values are dispersed that you might want to consider too; we’ll come to these later.
Q: Would I ever want to look at just one quartile of my data instead of the range or the interquartile range?
For example, you might be interested in what the high values look like, so you’d just look at what values are in the upper quarter of your data set, using the upper quartile as a cut-off point.
A: Yes, there are times when you might want to do this.
The upper and lower bounds of the data are the highest and lowest values in the data set.
The range is a simple way of measuring how values are dispersed.
The interquartile range is less sensitive to outliers than the range.
The highest quartile is called the upper quartile, and the lowest quartile is called the lower quartile.
The interquartile range is the range of the central 50% of the data.
We’re not just limited to quartiles So far we’ve looked at how the range and interquartile range give us ways of  measuring how values are dispersed in a set of  data.
The range is the difference between the highest number and the lowest, while the interquartile range focuses on the middle 50% of  the data.
So are they the only sorts of ranges I can use? Do I get any other options?
There are other sorts of ranges we can use in addition to the range and interquartile range.
Our original problem with the range was that it’s extremely sensitive to outliers.
To get around this, we divided the data into quarters, and we used the interquartile range to provide us with a cut-down range of  the data.
While the interquartile range is quite common, it’s not the only way of constructing a mini range.
Instead of  splitting the data into quarters, we could have split it into some other sort of  percentage and used that for our range instead.
As an example, suppose we’d divided our set of  data into tenths instead of  quarters so that each segment contains 10% of  the data.
If  you break up a set of  data into percentages, the values that split the data are called percentiles.
In the case above, our data is split into tenths, so the values are called deciles.
We can use percentiles to construct a new range called the interpercentile range.
We can use these divisions to create a brand new mini range.
So what are percentiles? Percentiles are values that split your data into percentages in the same way that quartiles split data into quarters.
In general, the xth percentile is the value that is k% of  the way through the data.
Percentile uses Even though the interpercentile range isn’t that commonly used, the percentiles themselves are useful for benchmarking and determining rank or position.
They enable you to determine how high a particular value is relative to all the others.
As an example, suppose you heard you scored 50 on your statistics test.
With just that number by itself, you’d have no idea how well you’d done relative to anyone else.
Finding percentiles You can find percentiles in a similar way to how you find quartiles.
First of  all, line all your values up in ascending order.11
To find the position of  the kth percentile out of  n numbers, start off  by calculating.
If  this gives you an integer, then your percentile is halfway between the value at position     and the next number along.
Take the average of  the numbers at these two positions to give you your percentile.
Percentile The kth percentile is the value that’s k% of the way through your data.
We’ve talked a lot about different sorts of  ranges, and it would be useful to be able to compare the ranges of  different sets of  data in a visual way.
There’s a chart that specializes in showing different types of  ranges: the box and whisker diagram, or box plot.
A box and whisker diagram shows the range, interquartile range, and median of  a set of  data.
More that one set of  data can be represented on the same chart, which means it’s a great way of  comparing data sets.
To create a box and whisker diagram, first you draw a box against a scale with the left and right sides of  the box representing the lower and upper quartiles, respectively.
Then, draw a line inside the box to mark the value of  the median.
This box shows you the extent of  the interquartile range.
After that, you draw “whiskers” to either side of your box to show the lower and upper bounds and the extent of  the range.
Here’s a box and whisker diagram for the scores of  our player from page 95:
If  your data has outliers, the range will be wider.
On a box and whisker diagram, the length of  the whiskers increases in line with the upper and lower bounds.
You can get an idea of how data is skewed by looking at the whiskers on the box and whisker diagram.
If  the box and whisker diagram is symmetric, this means that the underlying data is likely to be fairly symmetric, too.
So box and whisker diagrams are really just a neat way of showing ranges and quartiles.
Here are box and whisker diagrams for two more basketball players.
If you had to choose between having player A or player B on the team, which would you pick? Why?
Q: I’m sure I’ve seen box and whisker diagrams that look a bit different than this.
A: There are actually several versions of box and whisker diagrams.
Some have deliberately shorter whiskers and explicitly show outliers as dots or stars extending beyond the whiskers.
This makes it easier to see how many outliers there are and how extreme they really are.
Other diagrams show the mean as a dot, so you can see where it’s positioned in relation to the median.
If you’re taking a statistics course, it would be a good idea to check which version of the box and whisker diagram is likely to be used.
Q: So if you show the mean as a dot, is it to the left or right of the median?
A: If the data is skewed to the right, then the mean will be to the right of the median, and the whisker on the right will be longer than that of the left.
If the data is skewed to the left, the mean will be to the left of the median, and the whisker on the left will be the longest.
Here are box and whisker diagrams for each basketball player.
If you had to choose between having player A or player B on the team, which would you pick? Why?
Player A has a relatively small range, and his median score is a bit higher than Player B’s.
Sometimes this player scores a lot higher than Player A, but sometimes a lot lower.
Player A plays more consistently and usually scores higher than Player B (compare the medians and interquartile range), so we’d pick Player A.
The kth percentile is k% of the way through your data.
An interpercentile range is like the interquartile range but, this time, between two percentiles.
Box and whisker diagrams, or box plots, are a useful way of showing ranges and quartiles on a chart.
A box shows where the quartiles and interquartile range are, and the whiskers give the upper and lower bounds.
More than one set of data can be shown on the same chart, so they’re useful for comparisons.
The coach doesn’t just need to compare the range of  the players’ scores; he needs some way of  more accurately measuring where most of  the values lie to help him determine which player he can truly rely on come game day.
In other words, he needs to find the player whose scores vary the least.
The problem with the range and interquartile range is that they only tell you the difference between high and low values.
What they don’t tell you is how often the players get these high or low scores versus scores closer to the center—and that’s important to the coach.
The coach needs a team of  players he can rely on.
The last thing he wants is an erratic player who will play well one week and score badly the next.
What can we do to help the coach make his decision?
The interquartile range looks useful, but what about players who sometimes get really low scores? If a player messes up on game day, it could cost us the league! I’m not sure that the range or the interquartile range tell me which.
Variability is more than just spread We don’t just want to measure the spread of  each set of  scores; we want some way of  using this to see how reliable the player is.
In other words, we want to be able to measure the variability of the players’ scores.
One way of  achieving this is to look at how far away each value is from the mean.
If  we can work out some sort of  average distance from the mean for the values, we have a way of measuring variation and spread.
The smaller the result, the closer values are to the mean.
The values here are spread out quite a long way from the mean.
If  the coach picks this player for the team, he’s unlikely to be able to predict how the player will perform on game day.
The player may achieve a very high score if  he’s having a good day.
On a bad day, however, he may not score highly at all, and that means he’ll potentially lose the game for the team.
The values for this second set of  data are much closer to the mean and vary less.
If  the coach picks this player, he’ll have a good idea of  how well the player is likely to perform in each game.
So does that mean we just calculate the average distance from the mean?
What happens if  we find the average distance of values from the mean?
Q: Can’t we just take the positive distances and average those?
A: That sounds intuitive, but in practice, statisticians rarely do this.
There’s another way of making sure that the distances don’t cancel out, and you’ll see that very soon.
This other way of determining how close typical values are to the mean is used a lot in statistics, and you’ll see it through most of the rest of the book.
Q: Surely the distances don’t cancel out for all values.
A: No matter what values you choose, the distances to the mean will always cancel out.
Here’s a challenge for you: take a group of numbers, work out the mean, work out the distance of each value from the mean, and then add the distances together.
Q: Can’t I use the interquartile range to see how reliable the scores are?
A: The interquartile range only uses part of the data for measuring spread.
If a player has one bad score, this will be excluded by the interquartile range.
In order to truly determine reliability and consistency, we need to consider all the scores.
A: The range is only really good for describing the difference between the highest and lowest number.
As you saw earlier, this doesn’t represent how the values are actually distributed.
The positive and negative distances from the mean cancel each other out.
We need a way of making all the numbers positive.
This time we get a meaningful number, as the distances don’t cancel each other out.
Every number we add together has to be non-negative because we’re squaring the distance from the mean.
Adding these numbers together gives us a non-negative result—every time.
This method of  measuring spread is called the variance, and it’s a very common way of  describing the spread of  a set of  data.
Here’s a general form of  the equation: The variance is.
We want a way to measure the average distance of  values from the mean in a way that stops the distances from cancelling each other out.
Variance The variance is a way of measuring spread, and it’s the average of the distance of values from the mean squared.
But why should I have to think about distances squared? I hardly call that intuitive.
Statisticians use the variance a lot as a means of  measuring the spread of  data.
It’s useful because it uses every value to come up with the result, and it can be thought of  as the average of  the distances from the mean squared.
Standard deviation know-how We’ve seen that the standard deviation is a way of  saying how far typical values are from the mean.
The smaller the standard deviation, the closer values are to the mean.
What we really want is a number that gives the spread in terms of the distance from the mean, not distance squared.
The problem with the variance is that it can be quite difficult to think about spread in terms of  distances squared.
All we need to do is take the square root of  the variance.
Let’s work out the standard deviation for the set of  numbers we had before.
In other words, typical values are a distance of  3.56 away from the mean.
If you need to measure distances from the mean, give me a call.
Head First: To start off, I was wondering if  you could tell me a bit more about yourself  and what you do.
Standard Deviation: I’m really all about measuring the spread of  data.
Mean does a great job of  telling you what’s going on at the center, but quite often, that’s not enough.
Sometimes Mean needs support to give a more complete picture.
Mean gives the average value, and I say how values vary.
Head First: Without meaning to be rude, why should I care about how values vary? Is it really all that important? Surely it’s enough to know just the average of  a set of  values.
How would you feel if  you ordered a meal from the local diner, and when it arrived, you saw that half  of  it was burnt and the other half  raw?
Head First: I’d probably feel unhappy, hungry, and ready to sue the diner.
Standard Deviation: Well, according to Mean, your meal would have been cooked at the perfect temperature.
Clearly, that’s not the full picture; what you really need to know is the variation.
I look at what Mean thinks is a typical value, and I say how you can expect values to vary from that number.
I just say how far values are from the mean, on average.
Suppose the standard deviation of  a set of  values is 3 cm.
You can think of  that as saying values are, on average, 3 cm away from the mean.
There’s a bit more to it than that, but if  you think along those lines, you’re on the right track.
Head First: Speaking of  numbers, Standard Deviation, is it better if  you’re large or small?
Standard Deviance: Well, that really all depends what you’re using me for.
If  you’re manufacturing machine parts, you want me to be small, so you can be sure all the pieces are about the same.
If  you’re looking at wages in a large company, I’ll naturally be quite large.
Tell me, do you have anything to do with Variance?
Take the square root of  Variance, and there I am again.
We’re a bit like Clark Kent and Superman, but without the cape.
Do you ever feel overshadowed by Mean? After all, he gets a lot more attention than you.
It’s time for you to flex those standard deviation muscles.
Calculate the mean and standard deviation for the following sets of numbers.
It’s time for you to flex those standard deviation muscles.
Calculate the mean and standard deviation for the following sets of numbers.
But there is a much simpler formula for variance that produces the same result.The equation’s on the opposite page, but first you’ll need to rescue the derivation from the pool.
Each snippet will be used only once, but you won’t need to use every one.
Note: each snippet from the pool can only be used once!
Pool Puzzle Solution There’s an easier calculation for calculating the.
Each snippet will be used only once, but you won’t need to use every one.
Q: So which form of the variance equation should I use?
A: If you’re performing calculations, it’s generally easier to use the second form, which is:
This is particularly important if you have a mean with lots of decimals.
Q: How do I work out the standard deviation with this form of the variance equation?
Taking the square root of the variance gives you the standard deviation.
Q: What if I’m told what the standard deviation is, can I find the variance?
The standard deviation is the square root of the variance, which means that the variance is the square of the standard deviation.
To find the variance from the standard deviation, square the value of the standard deviation.
A: The standard deviation is a way of measuring spread.
It describes how far typical values are from the mean.
If the standard deviation is high, this means that values are typically a long way from the mean.
If the standard deviation is low, values tend to be close to the mean.
Q: Can the standard deviation ever be 0? A: Yes, it can.
The standard deviation is 0 if all of the values are the same.
A: It’s measured in the same units as your data.
Q: I’m sure I’ve seen formulas for variance where you divide by (n - 1) instead of n.
A: It’s not wrong, but that form of the variance is really used when you’re dealing with samples.
We’ll show you more about this when we talk about sampling later in the book.
Your job is to play like you’re the coach, and work out the standard deviation for each.
Which player is the most reliable one for your team?
The generous CEO of Starbuzz Coffee wants to give all his employees a pay raise.
Your job is to play like you’re the coach, and work out the standard deviation for each.
Which player is the most reliable one for your team?
The generous CEO of Starbuzz Coffee wants to give all his employees a pay raise.
The figures are, in effect, picked up and moved sideways, so the standard deviation doesn’t change.
What if we need a baseline for comparison? We’ve seen how the standard deviation can be used to measure how variable a set of  values are, and we’ve used it to pick out the most reliable player for the Statsville All Stars.
Imagine a situation in which you have two basketball players of  different ability.
Just looking at the percentages doesn’t give the full picture.
Each player has scored more than their personal mean, but which has fared better against their personal track record? How can we compare the two players?
The two players have different means and standard deviations, so how can we compare their personal performance?
Does this sort of  situation sound impossible? Don’t worry, we can achieve this with the standard score, or z-score.
Standard scores give you a way of  comparing values across different sets of  data where the mean and standard deviation differ.
They’re a way of  comparing related data values in different circumstances.
As an example, you can use standard scores to compare each player’s performance relative to his personal track record—a bit like a personal trainer would.
You find the standard score of  a particular value using the mean and standard deviation of  the entire data set.
The standard score is normally denoted by the letter z, and to find the standard score of  a particular value x, you use the formula:
These are the mean and standard deviation of the set of data containing the value x.
Let’s calculate the standard scores for each player, and see what those scores tell us.
Interpreting standard scores Standard scores give us a way of  comparing values across different data sets even when the sets of  data have different means and standard deviations.
They’re a way of  comparing values as if  they came from the same set of  data or distribution.
Each player’s shooting success rate has a different mean and standard deviation, which makes it difficult to compare how the players are performing relative to their own track record.
We can see that in a particular practice, one player got the ball in the net more times than the other.
We also notice that both players are scoring at a higher rate than their average.
The difficulty lies in comparing performances relative to the personal track record of  each player.
The standard score makes such comparisons possible by transforming each set of  data into a more generic distribution.
We can find the standard score of  each player at the practice session, and then transform and compare them.
In other words, when we standardize the scores, the score for Player 2 is higher.
It’s a generic distribution that can be used for comparisons.
Standard scores effectively transform your data so that it fits this model while making sure it keeps the same basic shape.
Standard scores can take any value, and they indicate position relative to the mean.
Positive z-scores mean that your value is above the mean, and negative z-scores mean that your value is below it.
If  your z-score is 0, then your value is the mean itself.
The size of  the number shows how far away the value is from the mean.
Standard deviations from the mean Sometimes statisticians express the relative position of  a particular value in terms of  standard deviations from the mean.
As an example, a statistician may say that a particular value is within 1 standard deviation of  the mean.
It’s really just another way of  indicating how close values are to the mean, but what does it mean in practice?
If  a value is within 1 standard deviation of  the mean, this tells us that the standard score of  the value is between.
Standard score = number of standard deviations from the mean.
The variance and standard deviation measure how values are dispersed by looking at how far values are from the mean.
The standard deviation is equal to the square root of the variance, and the variance is the standard deviation squared.
Standard scores, or z-scores, are a way of comparing values across different sets of data where the means and standard deviations are different.
To find the standard score of a value x, use:
Q: So variance and standard deviation both measure the spread of your data.
A: The range is quite a simplistic measure of the spread of your data.
It tells you the difference between the highest and lowest values, but that’s it.
You have no way of knowing how the data is clustered within it.
The variance and standard deviation are a much better way of measuring the variability of your data and how your data is dispersed, as they take into account how the data is clustered.
They look at how far values typically are from the center of your data.
Q: And what’s the difference between variance and standard deviation? Which one should I use?
A: The standard deviation is the square root of the variance, which means you can find one from the other.
The standard deviation is probably the most intuitive, as it tells you roughly how far your values are, on average, from the mean.
Q: How do standard scores fit into all this? A: Standard scores use the mean and standard deviation to convert values in a data set to a more generic distribution, while at the same time, making sure your data keeps the same basic shape.
They’re a way of comparing different values across different data sets even when the data sets have different means and standard deviations.
Q: Do standard scores have anything to do with detecting outliers?
A: Good question! Determining outliers can be subjective, but sometimes outliers are defined as being more than 3 standard deviations of the mean.
Statisticians have different opinions about this though, so be warned.
Name each type of measure of dispersion we’ve encountered in the chapter, and show how to calculate it.
Try your hardest to fill this out without looking back through the chapter.
Name each type of measure of dispersion we’ve encountered in the chapter, and show how to calculate it.
Try your hardest to fill this out without looking back through the chapter.
Let’s hear it for the standard deviation, our new team mascot!
Statsville All Stars win the league! All the basketball matches for the season have now been played, and the Statsville All Stars finished at the top of  the league.
You clearly helped the coach pick the best player for the team.
Just remember: you owe it all to the friendly neighborhood standard deviation.
Sometimes it can be impossible to say what will happen from one minute to the.
But certain events are more likely to occur than others, and that’s where.
What’s the probability he’s remembered I’m allergic to non-precious metals?
All sorts of  games are offered, from roulette to slot machines, poker to blackjack.
It just so happens that today is your lucky day.
Head First Labs has given you a whole rack of  chips to squander at Fat Dan’s, and you get to keep any winnings.
Want to give it a try? Go on—you know you want to.
There’s a lot of  activity over at the roulette wheel, and another game is just about to start.
Roll up for roulette! You’ve probably seen people playing roulette in movies even if  you’ve never tried playing yourself.
The croupier spins a roulette wheel, then spins a ball in the opposite direction, and you place bets on where you think the ball will land.
The roulette wheel used in Fat Dan’s Casino has 38 pockets that the ball can fall into.
For instance, you can bet on a particular number, whether that number is odd or even, or the color of  the pocket.
You’ll hear more about other bets when you start playing.
One other thing to remember: if  the ball lands on a green pocket, you lose.
Roulette boards make it easier to keep track of  which numbers and colors go together.
You place bets on the pocket the ball will fall into on the wheel using the board.
Place your bets now! Have you cut out your roulette board? The game is just beginning.
Where do you think the ball will land? Choose a number on your roulette board, and then we’ll place a bet.
Right, before placing any bets, it makes sense to see how likely it is that you’ll win.
What things do you need to think about before placing any roulette bets? Given the choice, what sort of bet would you make? Why?
Hold it right there! You want me to just make random guesses? I stand no chance of winning if I.
What are the chances? Have you ever been in a situation where you’ve wondered “Now, what were the chances of  that happening?” Perhaps a friend has phoned you at the exact moment you’ve been thinking about them, or maybe you’ve won some sort of  raffle or lottery.
Probability is a way of  measuring the chance of  something happening.
You can use it to indicate how likely an occurrence is (the probability that you’ll go to sleep some time this week), or how unlikely (the probability that a coyote will try to hit you with an anvil while you’re walking through the desert)
In stats-speak, an event is any occurrence that has a probability attached to it—in other words, an event is any outcome where you can say how likely it is to occur.
A lot of  the time, you’ll be dealing with probabilities somewhere in between.
A freak coyote anvil attack is quite unlikely; let’s put it here.
Falling asleep at some point during a 168-hour period is almost certain.
Throwing a coin and it landing heads up happens in about half of all tosses.
Can you see how probability relates to roulette? If  you know how likely the ball is to land on a particular number or color, you have some way of  judging whether or not you should place a particular bet.
It’s useful knowledge if  you want to win at roulette.
Event An outcome or occurrence that has a probability assigned to it.
How many pockets are there for the ball to land in?
How would you describe how likely it is that you’ll get a 7?
How many pockets are there for the ball to land in?
Mark the probability on the scale below? How would you describe how likely it is that you’ll get a 7?
Find roulette probabilities Let’s take a closer look at how we calculated that probability.
Here are all the possible outcomes from spinning the roulette wheel.
To find the probability of  winning, we take the number of ways of  winning the bet and divide by the number of  possible outcomes like this:
We can write this in a more general way, too.
It’s a shorthand way of  referring to all of  the possible outcomes.
Probabilities can quickly get complicated, so it’s often very useful to have some way of  visualizing them.
One way of  doing so is to draw a box representing the possibility space S, and then draw circles for each relevant event.
This sort of  diagram is known as a Venn diagram.
Very often, the numbers themselves aren’t shown on the Venn diagram.
Instead of  numbers, you have the option of  using the actual probabilities of  each event in the diagram.
It all depends on what kind of  information you need to help you solve the problem.
Complementary events There’s a shorthand way of  indicating the event that A does not occur—AI.
If  something’s in A, it can’t be in AI, and if  something’s not in A, it must be in AI.
In other words, there’s a 100% chance that something will be in either A or AI.
In this diagram, A’ is used instead of 37 to indicate all the possible events that aren’t in A.
Q: Why do I need to know about probability? I thought I was learning about statistics.
A: There’s quite a close relationship between probability and statistics.
A lot of statistics has its origins in probability theory, so knowing probability will take your statistics skills to the next level.
Probability theory can help you make predictions about your data and see patterns.
In set theory, the possibility space is equivalent to the set of all possible outcomes, and a possible event forms a subset of this.
You don’t have to already know any set theory to use Venn diagrams to calculate probability, though, as we’ll cover everything you need to know in this chapter.
Q: Do I always have to draw a Venn diagram? I noticed you didn’t in that last exercise.
But sometimes they can be a useful tool for visualizing what’s going on with probabilities.
You’ll see more situations where this helps you later on.
Q: Can anything be in both events A and AI?
If an element is in A, then it can’t possibly be in AI.
Similarly, if an element is in AI, then it can’t be in A.
The two events are mutually exclusive, so no elements are shared between them.
It’s time to play! A game of  roulette is just about to begin.
We’ll place a bet on the one that’s most likely to occur—that the ball will land in a black pocket.
Oh dear! Even though our most likely probability was that the ball would land in a black pocket, it actually landed in the green 0 pocket.
Probabilities are only indications of how likely events are; they’re not guarantees.
The important thing to remember is that a probability indicates a long-term trend only.
Even though you’d expect the ball to land in a green pocket relatively infrequently, that doesn’t mean it can’t happen.
No matter how unlikely an event is, if it’s not impossible, it can still happen.
The ball landed in the 0 pocket, so you lost some chips.
We can use the probabilities we already know to work out the one we don’t know.
There are only three colors for the ball to land on: red, black, or green.
As we’ve already worked out what P(Green) is, we can use this value to find our probability without having to count all those black and red pockets.
Calculate the probability of getting a black or a red by counting how many pockets are black or red and dividing by the number of pockets.
Let’s look at the probability of  an event that should be more likely to happen.
Instead of  betting that the ball will land in a black pocket, let’s bet that the ball will land in a black or a red pocket.
To work out the probability, all we have to do is count how many pockets are red or black, then divide by the number of  pockets.
Calculate the probability of getting a black or a red by counting how many pockets are black or red and dividing by the number of pockets.
You can also add probabilities There’s yet another way of  working out this sort of probability.
If  we know P(Black) and P(Red), we can find the probability of  getting a black or red by adding these two probabilities together.
Two of the pockets are neither red nor black, so we’ve put 2 out here.
Q: It looks like there are three ways of dealing with this sort of probability.
A: It all depends on your particular situation and what information you are given.
Suppose the only information you had about the roulette wheel was the probability of getting a green.
In this situation, you’d have to calculate the probability by working out the probability of not getting a green: 1 - P(Green)
On the other hand, if you knew P(Black) and P(Red) but didn’t know how many different colors there were, you’d have to calculate the probability by adding together P(Black) and P(Red)
Q: So I don’t have to work out probabilities by counting everything?
A: Often you won’t have to, but it all depends on your situation.
It can still be useful to double-check your results, though.
Q: If some events are so unlikely to happen, why do people bet on them?
A: A lot depends on the sort of return that is being offered.
In general, the less likely the event is to occur, the higher the payoff when it happens.
If you win a bet on an event that has a high probability, you’re unlikely to win much money.
People are tempted to make bets where the return is high, even though the chances of them winning is negligible.
Q: Does adding probabilities together like that always work? A: Think of this as a special case where it does.
Don’t worry, we’ll go into more detail over the next few pages.
Probability To find the probability of an event A, use.
You win! This time the ball landed in a red pocket, the number 7, so you win some chips.
Sometimes you can add together probabilities, but it doesn’t work in all circumstances.
We might not be able to count on being able to do this probability calculation in quite the same way as the previous one.
Try the exercise on the next page, and see what happens.
This time, you picked a winning pocket: a red one.
Time for another bet Now that you’re getting the hang of  calculating probabilities, let’s try something else.
What’s the probability of  the ball landing on a black or even pocket?
What do you get if you add these two probabilities together?
Finally, use your roulette board to count all the holes that are either black or even, then divide by the total number of holes.
What do you get if you add these two probabilities together?
Finally, use your roulette board to count all the holes that are either black or even, then divide by the total number of holes.
What sort of effect do you think this intersection could have had on the probability?
When we were working out the probability of  the ball landing in a black or red pocket, we were dealing with two separate events, the ball landing in a black pocket and the ball landing in a red pocket.
These two events are mutually exclusive because it’s impossible for the ball to land in a pocket that’s both black and red.
What about the black and even events? This time the events aren’t mutually exclusive.
It’s possible that the ball could land in a pocket that’s both black and even.
If two events are mutually exclusive, only one of the two can occur.
If two events intersect, it’s possible they can occur simultaneously.
Problems at the intersection Calculating the probability of  getting a black or even went wrong because we included black and even pockets twice.
First of  all, we found the probability of  getting a black pocket and the probability of  getting an even number.
When we added the two probabilities together, we counted the probability of  getting a black and even pocket twice.
To get the correct answer, we need to subtract the probability of  getting both black and even.
We can now substitute in the values we just calculated to find P(Black or Even):
Some more notation There’s a more general way of  writing this using some more math shorthand.
So why is the equation for exclusive events different? Are you just giving.
How many enthusiasts play baseball in total? How many play basketball? How many play football? Are any sports’ rosters mutually exclusive? Which sports are exhaustive (fill up the possibility space)?
A or B To find the probability of getting event A or B, use.
How many enthusiasts play baseball in total? How many play basketball? How many play football? Are any sports’ rosters mutually exclusive? Which sports are exhaustive (fill up the possibility space)?
This information looks complicated, but drawing a Venn diagram will help us to visualize what’s going on.
A and AI can have no common elements, so they are mutually exclusive.
Together, they make up the entire possibility space so they’re exhaustive too.
It can sometimes be useful to think of different ways of forming the same probability, though.
You don’t always have access to all the information you’d like, so being able to think laterally about probabilities is a definite advantage.
Q: Is there a limit on how many events can intersect?
We suggest that if you’re in doubt, draw a Venn diagram and take a good, hard look at which probabilities need to be added together and which need to be subtracted.
The numbers we’ve been given all add up to 50, the total number of sports lovers.
The croupier decides to take pity on us and offers a little inside information.
After she spins the roulette wheel, she’ll give us a clue about where the ball landed, and we’ll work out the probability based on what she tells us.
Here’s your next bet…and a hint about where the ball landed.
Should we take this bet? How does the probability of  getting even given that we know the ball landed in a black pocket compare to our last bet that the ball would land on black or even.
Conditions apply The croupier says the ball has landed in a black pocket.
This is a slightly different problem We don’t want to find the probability of  getting a pocket that is both black and even, out of  all possible pockets.
Instead, we want to find the probability that the pocket is even, given that we already know it’s black.
In other words, we want to find out how many pockets are even out of  all the black ones.
It turns out that even with some inside information, our odds are actually lower than before.
The probability of  even given black is actually less than the probability of  black or even.
In other words, just flip around the A and the B.
Find conditional probabilities So how can we generalize this sort of  problem? First of all, we need some more notation to represent conditional probabilities, which measure the probability of  one event occurring relative to another occurring.
If  we want to express the probability of  one event happening given another one has already happened, we use the “|” symbol to mean “given.” Instead of  saying “the probability of  event A occurring given event B,” we can shorten it to say.
So now we need a general way of  calculating P(A | B)
What we’re interested in is the number of  outcomes where both A and B occur, divided by all the B outcomes.
It looks like it can be difficult to show conditional probability on a Venn diagram.
Venn diagrams aren’t always the best way of visualizing conditional probability.
Don’t worry, there’s another sort of  diagram you can use—a probability tree.
Because we’re trying to find the probability of A given B, we’re only interested in the set of events where B occurs.Th.
It’s not always easy to visualize conditional probabilities with Venn diagrams, but there’s another sort of  diagram that really comes in handy in this situation—the probability tree.
Here’s a probability tree for our problem with the roulette wheel, showing the probabilities for getting different colored and odd or even pockets.
Here are the first set of exclusive events, the colors.
The probabilities for each event go along the relevant branch.
The second set of  branches shows the probability of  outcomes given the outcome of  the branch it is linked to.
Probability trees don’t just help you visualize probabilities; they can help you to calculate them, too.
Let’s take a general look at how you can do this.
Here’s another probability tree, this time with a different number of  branches.
It shows two levels of  events: A and AI and B and BI.
The probability of not getting A given that B hasn’t happened.
Using probability trees gives you the same results you saw earlier, and it’s up to you whether you use them or not.
Probability trees can be timeconsuming to draw, but they offer you a way of  visualizing conditional probabilities.
Probability Magnets Duncan’s Donuts are looking into the probabilities of their customers buying donuts and coffee.
They drew up a probability tree to show the probabilities, but in a sudden gust of wind, they all fell off.
Your task is to pin the probabilities back on the tree.
Try and work out the differ ent levels of  probability tha.
If  you’re given a series of  p robabilities, put them onto.
If  you add together the pro babilities for all of  the bran.
You should be able to find m ost other probabilities by us.
They drew up a probability tree to show the probabilities, but in a sudden gust of wind they all fell off.
Your task is to pin the probabilities back on the tree.
We haven’t quite finished with Duncan’s Donuts! Now that you’ve completed the probability tree, you need to use it to work out some probabilities.
Your job was to use the completed probability tree to work out some probabilities.
You’ll only be able to do this if you found P(Coff ee)
We can find this by multiplying together P(DonutsI) and P(Coffee | DonutsI)
P(A | B) is the probability of event A given event B.
In other words, you make the assumption that event B has occurred, and you work out the probability of getting A under this assumption.
Q: So does that mean that P(A | B) is just the same as P(A)?
When you calculate P(A | B), you have to assume that event B has already happened.
When you work out P(A), you can make no such assumption.
A: It’s quite a common mistake, but they are very different probabilities.
P(A | B) is the probability of getting event A given event B has already happened.
P(B | A) is the probability of getting event B given event A occurred.
You’re actually finding the probability of a different event under a different set of assumptions.
A: Both diagrams give you a way of visualizing probabilities, and both have their uses.
Venn diagrams are useful for showing basic probabilities and relationships, while probability trees are useful if you’re working with conditional probabilities.
It all depends what type of problem you need to solve.
Q: Is there a limit to how many sets of branches you can have on a probability tree?
In practice you may find that a very large probability tree can become unwieldy, but you may still find it easier to draw a large probability tree than work through complex probabilities without it.
Bad luck! You placed a bet that the ball would land in an even pocket given we’ve been told it’s black.
Unfortunately, the ball landed in pocket 17, so you lose a few more chips.
Maybe we can win some chips back with another bet.
This time, the  croupier says that the ball has landed in an even pocket.
But that’s a similar problem to the one we had before.
So how do we find P(Black | Even)? There’s still a way of  calculating this using the probabilities we already have even if  it’s not immediately obvious from the probability tree.
All we have to do is look at the probabilities we already have, and use these to somehow calculate the probabilities we don’t yet know.
Let’s start off  by looking at the overall probability we need to find, P(Black | Even)
Sound difficult? Don’t worry, we’ll guide you through how to do it.
Use the probabilities you have to calculate the probabilities you need.
We can find P(Black l Even) using the probabilities we already have.
How do you think we can use it to find P(Even)?
So where does this get us? We want to find the probability P(Black | Even)
So how do we find the next part of  the formula, P(Even)?
Step 2: Finding P(Even) The next step is to find the probability of  the ball landing in an even pocket, P(Even)
We can find this by considering all the ways in which this could happen.
A ball can land in an even pocket by landing in either a pocket that’s both black and even, or in a pocket that’s both red and even.
These are all the possible ways in which a ball can land in an even pocket.
To find the probability of the ball landing in an even pocket, add these probabilities together.
This means that we now have a way of  finding new conditional probabilities using probabilities we already know—something that can help with more complicated probability problems.
After that we moved on to finding an expression for P(Even), and found that.
Putting these together means that we can calculate P(Black | Even) using probabilities from the probability tree.
We calculated these earlier, so we can substitute in our result.
These results can be generalized to other problems Imagine you have a probability tree showing events A and B like this, and assume you know the probability on each of  the branches.
Now imagine you want to find P(A | B), and the information shown on the branches above is all the information that you have.
How can you use the probabilities you have to work out P(A | B)?
Use the Law of Total Probability to find P(B) To find P(B), we use the same process that we used to find P(Even) earlier; we need to add together the probabilities of  all the different ways in which the event we want can possibly happen.
There are two ways in which even B can occur: either with event A, or without it.
We can rewrite this in terms of  the probabilities we already know from the probability tree.
This is sometimes known as the Law of  Total Probability, as it gives a way of  finding the total probability of  a particular event based on conditional probabilities.
To find P(B), add the probabilities of these branches together.
Bayes’ Theorem is one of  the most difficult aspects of probability.
Don’t worry if  it looks complicated—this is as tough as it’s going to get.
And even though the formula is tricky, visualizing the problem can help.
It gives you a means of  finding reverse conditional probabilities, which is really useful if  you don’t know every probability up front.
Introducing Bayes’ Theorem We started off  by wanting to find P(A | B) based on probabilities we already know from a probability tree.
What we need is a general expression for finding conditional probabilities that are the reverse of  what we already know, in other words P(A | B)
The Manic Mango games company is testing two brand-new games.
They’ve asked a group of volunteers to choose the game they most want to play, and then tell them how satisfied they were with game play afterwards.
Your first task is to fill in the probability tree for this scenario.
Manic Mango selects one of the volunteers at random to ask if she enjoyed playing the game, and she says she did.
Given that the volunteer enjoyed playing the game, what’s the probability that she played game 2? Use Bayes’ Theorem.
Hint: What’s the probability of someone choosing game 2 and being satisfied? What’s the probability of someone being satisfied overall? Once you’ve found these, you can use Bayes Theorem to obtain the right answer.
The Manic Mango games company is testing two brand-new games.
They’ve asked a group of volunteers to choose the game they most want to play, and then tell them how satisfied they were with game play afterwards.
Your first task is to fill in the probability tree for this scenario.
We know the probability that a player chose each game, so we can use these for the first set of branches.
We also know the probability of a player being satisfied or dissatisfied with the game they chose.
Manic Mango selects one of the volunteers at random to ask if she enjoyed playing the game, and she says she did.
Given that the volunteer enjoyed playing the game, what’s the probability that she played game 2? Use Bayes’ Theorem.
Bayes’ Theorem If you have n mutually exclusive and exhaustive events, A1 through to An, and B is another event, then.
We have a winner! Congratulations, this time the ball landed on 10, a pocket that’s both black and even.
A: Use it when you want to find conditional probabilities that are in the opposite order of what you’ve been given.
A: You can either use Bayes’ Theorem right away, or you can use a probability tree to help you.
Using Bayes’ Theorem is quicker, but you need to make sure you keep track of your probabilities.
Using a tree is useful if you can’t remember Bayes’ Theorem.
It will give you the same result, and it can keep you from losing track of which probability belongs to which event.
Q: When we calculated P(Black | Even) in the roulette wheel problem, we didn’t include any probabilities for the ball landing in a green pocket.
They are two separate probabilities, and making this sort of assumption could actually cost you valuable points in a statistics exam.
You need to use Bayes’ Theorem to make sure you end up with the right result.
For example, it can be used in computing as a way of filtering emails and detecting which ones are likely to be junk.
It’s time for one last bet Before you leave the roulette table, the croupier has offered you a great deal for your final bet, triple or nothing.
If  you bet that the ball lands in a black pocket twice in a row, you could win back all of  your chips.
Notice that the probabilities for landing on two black pockets in a row are a bit different than they were in our probability tree on page 166, where we were trying to calculate the likelihood of  getting an even pocket given that we knew the pocket was black.
The probability of  getting black followed by black is a slightly different problem from the probability of  getting an even pocket given we already know it’s black.
For P(Even | Black), the probability of  getting an even pocket is affected by the event of  getting a black.
We already know that the ball has landed in a black pocket, so we use this knowledge to work out the probability.
We look at how many of  the pockets are even out of  all the black pockets.
If  we didn’t know that the ball had landed on a black pocket, the probability would be different.
To work out P(Even), we look at how many pockets are even out of  all the pockets.
In other words, the knowledge we have that the pocket is black changes the probability.
In general terms, events A and B are said to be dependent if P(A | B) is different from P(A)
It’s a way of  saying that the probabilities of  A and B are affected by each other.
Look at the probability tree on the previous page again.
What do you notice about the sets of branches? Are the events for getting a black in the first game and getting a black in the second game dependent? Why?
You think I care about your outcomes? They’re irrelevant to me.
Sometimes events remain completely unaffected by each other, and the probability of  an event occurring remains the same irrespective of  whether the other event happens or not.
As an example, take a look at the probabilities of  P(Black) and P(Black | Black)
In other words, the event of  getting a black pocket in this game has no bearing on the probability of  getting a black pocket in the next game.
They don’t influence each other’s probabilities in any way at all.
If  one event occurs, the probability of  the other occurring remains exactly the same.
If  events A and B are independent, then the probability of  event A is unaffected by event B.
We can also use this as a test for independence.
If  you have two events A and B where P(A | B) = P(A), then the events A and B must be independent.
If events do not affect each other, they are independent.
In other words, if  two events are independent, then you can work out the probability of getting both events A and B by multiplying their individual probabilities together.
What’s the probability of the ball landing in a black pocket twice in a row?
If A and B are mutually exclusive, they can’t be independent, and if A and B are.
If A and B are mutually exclusive, then if event A occurs, event B cannot.
This means that the outcome of A affects the outcome of B, and so they’re dependent.
Similarly if A and B are independent, they can’t be mutually exclusive.
Q: What’s the difference between being independent and being mutually exclusive?
If A and B are mutually exclusive, then if event A happens, B cannot.
In other words, it’s impossible for both events to occur.
If A and B are independent, then the outcome of A has no effect on the outcome of B, and the outcome of B has no effect on the outcome of A.
Q: Do both events have to be independent? Can one event be independent and the other dependent?
The two events are independent of each other, so you can’t have two events where one is dependent and the other one is independent.
Q: Are all games on a roulette wheel independent? Why?
Separate spins of the roulette wheel do not influence each other.
In each game, the probabilities of the ball landing on a red, black, or green remain the same.
Q: You’ve shown how a probability tree can demonstrate independent events.
How do I use a Venn diagram to tell if events are independent?
A: A Venn diagram really isn’t the best way of showing dependence.
Venn diagrams are great if you need to examine intersections and show mutually exclusive events.
What’s the probability of the ball landing in a black pocket twice in a row?
As a result, it is extremely popular with both young and old.
The Health Club is wondering how best to market its new yoga class, and the Head of  Marketing wonders if  someone who goes swimming is more likely to go to a yoga class.
I think that people who go swimming and people who go to yoga are independent.
They ask a group of  96 people whether they go to the swimming or yoga classes.
So who’s right? Are the yoga and swimming classes dependent or independent?
I’ve been wanting to catch up with you for some time.
Even if people do decide to use me instead of  you, I don’t see that it can make all that much difference.
I can’t say I pay all that much attention to him.
I think that people need to think of  me first instead of  you; that would sort out all of  these problems.
By really thinking through whether events are dependent or not.
Suppose you have a deck of  52 cards, and thirteen of  them are diamonds.
Imagine you choose a card at random and it’s a diamond.
What if  you pick out a second card? What’s the probability of  pulling out a second diamond?
Just make sure you think things through a bit more carefully next time.
Not fair, I assumed you put the first card back! That would have meant the probability of  getting a diamond would have been the same as before, and I would have been right.
Well, thanks for the chat, Dependent, I’m glad we had a chance to sort things out.
So how do we know the classes are independent? Let’s multiply together P(Yoga) and P(Swimming) and see what we get.
Your task is to say which of these are dependent, and which are independent.
Throwing a coin and getting heads twice in a row.
Removing socks from a drawer until you find a matching pair.
Choosing chocolates at random from a box and picking dark chocolates twice in a row.
Choosing a card from a deck of  cards, and then choosing another one.
Choosing a card from a deck of  cards, putting the card back in the deck, and then choosing another one.
Your task was to say which of  these are dependent, and which are independent.
Throwing a coin and getting heads twice in a row.
Removing socks from a drawer until you find a matching pair.
Choosing chocolates at random from a box and picking dark chocolates twice in a row.
Choosing a card from a deck of  cards, and then choosing another one.
Choosing a card from a deck of  cards, putting the card back in the deck, and then choosing another one.
When you remove one sock, there are fewer socks to choose.
It’s no more or less likely to rain just because it’s Thursday, so these two events are independent.
It’s great that we know our chances of winning all these different bets, but don’t we need to know more than just probability to make smart bets?
Winner! Winner! On both spins of  the wheel, the ball landed on 30, a red square, and you doubled your winnings.
You’ve learned a lot about probability over at Fat Dan’s roulette table, and you’ll find this knowledge will come in handy for what’s ahead at the casino.
It’s a pity you didn’t win enough chips to take any home with you, though.
Besides the chances of winning, you also need to know how much you stand to win in order to decide if the bet is worth the risk.
Betting on an event that has a very low probability may be worth it if  the payoff  is high enough to compensate you for the risk.
In the next chapter, we’ll look at how to factor these payoffs into our probability calculations to help us make more informed betting decisions.
The Absent-Minded Diners Three absent-minded friends decide to go out for a meal, but they forget where they’re going to meet.
If it lands heads, he’ll go to the diner; tails, and he’ll go to the Italian restaurant.
George throws a coin, too; heads, it’s the Italian restaurant; tails, it’s the diner.
Ron decides he’ll just go to the Italian restaurant because he likes the food.
What’s the probability all three friends meet? What’s the probability one of them eats alone?
Here are some more roulette probabilities for you to work out.
The probability of the ball having landed on the number 17 given the pocket is black.
The probability of the ball landing on pocket number 22 twice in a row.
The probability of the ball having landed in a pocket with a number greater than 4 given that it’s red.
Fred goes to the Diner while George goes to Italian restaurant, or George goes to the Diner and Fred gets Italian..
Three absent-minded friends decide to go out for a meal, but they forget where they’re going to meet.
If it lands heads, he’ll go to the diner; tails, and he’ll go to the Italian restaurant.
George throws a coin, too; heads, it’s the Italian restaurant; tails, it’s the diner.
Ron decides he’ll just go to the Italian restaurant because he likes the food.
What’s the probability all three friends meet? What’s the probability one of them eats alone?
Here are some more roulette probabilities for you to work out.
The probability of the ball having landed on the number 17 given the pocket is black.
The probability of the ball landing on pocket number 22 twice in a row.
The probability of the ball having landed in a pocket with a number greater than 4 given that it’s red.
OK, so falling out the tree was unexpected, but you have to take a long-term view of these things.
Unlikely events happen, but what are the consequences? So far we’ve looked at how probabilities tell you how likely certain events are.
Sure, you’ll sometimes make it big on the roulette table, but is it really worth it.
Back at Fat Dan’s Casino Have you ever felt mesmerized by the flashing lights of  a slot machine? Well, you’re in luck.
At Fat Dan’s Casino, there’s a full row of  shiny slot machines just waiting to be played.
Let’s play one of  them, which costs $1 per game (pull of  the lever)
The slot machine has three windows, and if  all three windows line up in the right way, the cash will come cascading out.
The amount of money you can win looks tempting, but I’d like to know the probability of getting any of these combinations.
Here are the probabilities of  a particular image appearing in a particular window:
The three windows are independent of  each other, which means that the image that appears in one of the windows has no effect on the images that appear in any of  the others.
The probability of a cherry appearing in this window is 0.2
Your job is to play like you’re the gambler and work out the probability of getting each combination on the poster.
Rather than work out all the possible ways in which.
The probability of a dollar sign appearing in a window is 0.1
A lemon appearing in a window is independent of ones appearing in the other two windows, so you multiply the three probabilities together.
Your job is to play like you’re the gambler and work out the probability of getting each combination on the poster.
Here are the probabilities of  the different winning combinations on the slot machine.
We don’t just want to know the probability of winning, we want to know how much we stand to win.
The probabilities are currently written in terms of  combinations of symbols, which makes it hard to see at a glance what out gain will be.
Instead of  writing the probabilities in terms of  slot machine images, we can write them in terms of  how much we win or lose on each game.
All we need to do is take the amount we’ll win for each combination, and subtract the amount we’ve paid for the game.
The table gives us the probability distribution of  the winnings, a set of  the probabilities for every possible gain or loss for our slot machine.
This looks useful, but I wonder if we can take it one step further.
We’ve found the probabilities of getting each of the winning combinations, but what we’re really interested in is how much we’ll win or lose.
These are the same probabilities, just written in terms of how much we’ll gain.
We lose $1 if we don’t hit a winning combination.
Our gain for hitting each winning combination: the payoff minus the $1 we paid to play.
We can compose a probability distribution for the slot machine.
When you derived the probabilities of  the slot machine, you calculated the probability of  making each gain or loss.
In other words, you calculated the probability distribution of  a random variable, which is a variable that can takes on a set of  values, where each value is associated with a specific probability.
In the case of  Fat Dan’s slot machine, the random variable represents the amount we’ll gain in each game.
When we want to refer to a random variable, it’s usual to represent it by a capital letter, like X or Y.
The particular values that the variable can take are represented by a lowercase letter—for example, x or y.
Using this notation, P(X = x) is a way of  saying “the probability that the variable X takes a particular value x.”
Here’s our slot machine probability distribution written using this notation:
The value of each combination’s winnings is represented by x.
As well as giving a table of  the probability distribution, we can also show the distribution on a chart to help us visualize it.
Here is a bar chart showing the slot machine probabilities.
In this type of bar chart, the bars are so thin they’re just lines.
Why should I care about probability distributions? All I want to know is how much I’ll win on the slot machine.
Once you’ve calculated a probability distribution, you can use this information to determine the expected outcome.
In the case of  Fat Dan’s slot machine, we can use our probability distribution to determine how much you can expect to win or lose long-term.
Q: Why couldn’t we have just used the symbols instead of winnings? I’m not sure we’ve really gained that much.
A: We could have, but we can do more things if we have numeric data because we can use it in calculations.
You’ll see shortly how we can use numeric data to work out how much we can expect to win on each game, for instance.
We couldn’t have done that if we had just used symbols.
Q: What if I want to show probability distributions on a Venn diagram?
A: It’s not that appropriate to show probability distributions like that.
Venn diagrams and probability trees are useful if you want to calculate probabilities.
With a probability distribution, the probabilities have already been calculated.
Q: Can you use any letter to represent a variable?
A: Yes, you can, as long as you don’t confuse it with anything else.
It’s most common to use letters towards the end of the alphabet, though, such as X and Y.
Q: Should I use the same letter for the variable and the values? Would I ever use X for the variable and y for the values?
A: Theoretically, there’s nothing to stop you, but in practice you’ll find it more confusing if you use different letters.
It’s best to stick to using the same letter for each.
Q: You said that a discrete random variable is one where you can say precisely what the values are.
With the slot machine winnings, you know precisely what the winnings are going to be for each symbol combination.
You can’t get any more precise, and it wouldn’t matter how many times you played.
Sometimes you’re given a range of values where any value within the range is possible.
The length could be literally any value within that range.
Don’t worry about the distinction too much for now; we’ll look at this in more detail later on in the book.
For now, every random variable we look at will be discrete.
You have a probability distribution for the amount you could gain on the slot machines, but now you need to know how much you can expect to win or lose long-term.
You can do this by calculating how much you can typically expect to win or lose in each game.
The expectation of  a variable X is a bit like the mean, but for probability distributions.
To find the expectation, you multiply each value x by the probability of  getting that value, and then sum the results.
E(X) = xP(X = x)E(X) is the expectation of X.
Once you’ve done multiplying, add the whole lot up together.
Let’s use this to calculate the expectation of  the slot machine gain.
In other words, over a large number of  games, you can expect to lose $0.77 for each game.
This is the amount in $’s you can expect to gain on each pull of the lever—and it’s negative!
The expectation tells you how much on average you can expect to win or lose with each game.
If  you lost this amount every single time, where would the fun be, and who would play?
Just because you can expect to lose each time you play doesn’t mean there isn’t a small chance you’ll win big.
Just like the mean, the expectation doesn’t give the full story as the amount you stand to gain on each game could vary a lot.
The expectation gives the typical or average value of a variable but it doesn’t tell you anything about how the values are spread out.
For our slot machine, this will tell us more about the variation of  our potential winnings.
Just like we did in Chapter 3, we can use variance to measure this spread.
A shorthand way of referring to the variance of X is Var(X)
When we calculate E(X), we take each value in the probability distribution, multiply it by its probability, and then add the results together.
What about the standard deviation? Can we calculate that too?
Would you prefer to play on a slot machine with a high or low variance? Why?
As well as having a variance, probability distributions have a standard deviation.
It serves a similar function to the standard deviation of  a set of  values.
It’s a way of  measuring how far away from the center you can expect your values to be.
As before, the standard deviation is calculated by taking the square root of  the variance like this:
Is there anything for probability distributions that’s like the median or mode?
A: You can work out the most likely probability, which would be a bit like the mode, but you won’t normally have to do this.
When it comes to probability distributions, the measure that statisticians are most interested in is the expectation.
Q: Shouldn’t the expectation be one of the values that X can take?
Just as the mean of a set of values isn’t necessarily the same as one of the values, the expectation of a probability distribution isn’t necessarily one of the values X can take.
Q: Are the variance and standard deviation the same as we had before when we were dealing with values?
A: They’re the same, except that this time we’re dealing with probability distributions.
The variance and standard deviation of a set of values are ways of measuring how far values are spread out from the mean.
The variance and standard deviation of a probability distribution measure how the probabilities of particular values are dispersed.
Q: So what’s the difference between a slot machine with a low variance and one with a high variance?
A: A slot machine with a high variance means that there’s a lot more variability in your overall winnings.
In general, the smaller the variance is, the closer your average winnings per game are likely to be to the expectation.
If you play on a slot machine with a larger variance, your overall winnings will be less reliable.
Use the following formula to find the expectation of a variable X: E(X) =   xP(X = x)
The Case of  the Moving Expectation Statsville broadcasts a number of  popular quiz shows, and among these is Seal or No Seal.
In this show, the contestant is shown a number of boxes containing different amounts of  money, and they have to choose one of  them, without looking inside.
The remaining boxes are opened one by one, and with each one that’s opened, the contestant is offered.
The Statsville Seal Sanctuary get a donation based on any winnings the contestant gets.
The latest contestant is an amateur statistician, and he figures he’ll be in a better position to win if  he knows what the expectation.
He’s just finished calculating the expectation when the producer comes over to him.
You’re on in three minutes,” says the producer, “and we’ve changed all the values in the boxes.
Are all his calculations for nothing? He can’t possibly work out the expectation from scratch in three minutes.
How can the contestant figure out the new expectation in record time?
In the past few minutes, Fat Dan has changed the cost and prizes of  the slot machine.
If  we win, we’ll be able to make a lot more money than before.
If we knew what the expectation and variance were, we’d have an idea of how much we could win long-term.
The expectation is slightly lower, so in the long term, we can expect to lose $0.85 each game.
This means that we stand to lose more money in the long term on this machine, but there’s less certainty.
Do you mean to tell me we have to run through complicated calculations.
The cost of  each game has gone up to $2, and the prizes are now five times higher than they were.
As there’s a relationship between the old and new gains, maybe their expectations and variance are related too.
You may not use the same number more than once, and you won’t need to use all the numbers.
Note: each thing from the pool can only be used once!
Pool Puzzle Solution It’s time for a bit of algebra.
You may not use the same number more than once, and you won’t need to use all the numbers.
Note: each thing from the pool can only be used once!
This gives us the winnings of the original game in terms of X.
We can substitute in our expression for the original winnings.
What we want to do now is see if  there’s a relationship between E(X) and E(Y), and Var(X) and Var(Y)
If  there is a relationship, this will save us lots of  time if  Fat Dan changes his prices again.
As long as we know what the relationship is between the old and the new, we’ll be able to quickly calculate the new expectation and variance.
Let’s see whether there’s a pattern in the relationship between E(X) and E(Y), and Var(X) and Var(Y)
How could you generalize this for any probability distribution where Y = aX + b?
Let’s see whether there’s a pattern in the relationship between E(X) and E(Y), and Var(X) and Var(Y)
How could you generalize this for any probability distribution aX + b?
E(aX + b) = a E(X) + b Var(aX + b) = a2  Var(X)
Slot machine transformations So what did you accomplish over the past few pages?
First of  all, you found the expectation and variance of  X, where X is the amount of  money you stand to make in each game.
You then wanted to know the effect of  Fat Dan’s price changes but without having to recalculate the expectation and variance from scratch.
You did this by working out the relationship between the old and the new gains, and then using the relationship to work out the new expectation and variance.
This is called a linear transform, as we are dealing with a linear change to X.
In other words, the underlying probabilities stay the same but the values are changed into new values of  the form aX + b.
Q: Do a and b have to be constants? A: Yes they do.
If a and b are variables, then this result won’t hold true.
Q: Where did the b go in the variance? A: Adding a constant value to the distribution makes no difference to the overall variance, only to the expectation.
When you add a constant to a variable, it in effect moves the distribution along while keeping the same basic shape.
This means that the expectation shifts along by b, but as the shape remains unchanged, the variance says the same.
Q: I’m surprised I have to multiply the variance by a2
A: When you multiply a variable by a constant, you multiply all its underlying values by that constant.
When you calculate the variance, you perform calculations based on the square of the underlying values.
And as these have been multiplied by a, the end result is that you multiply the variance by a2
Q: Do I really have to remember how to do linear transforms? Are they important?
They can save you a lot of time in the long run, as they eliminate the need for you to have to calculate the expectation and variance of a probability distribution every time the values change.
Rather than calculating a new probability distribution, then calculating the expectation and variance from scratch, you can just plug the expectation and variance you already calculated into the equations above.
Knowing linear transforms can also help you out in exams.
First of all, you can save valuable time if you know what shortcuts you can take.
Furthermore, exam papers don’t always give you the underlying probability distribution.
You might be told the expectation of variable, and you may have to transform it based on very basic information.
Q: I tried calculating the expectation and variance the long way round and came up with a different answer.
A: You’ve seen by now that it’s easy to make mistakes when you calculate expectations and variances.
If you calculate these longhand, there’s a good chance you made a mistake somewhere along the line.
How can the contestant figure out the new expectation in record time?
The contestant looks around in panic for a brief  moment and then relaxes.
The change in values isn’t such a big problem after all.
The contestant has already spent time calculating the expectation of  the original values of  all the boxes, and this has given him an idea of  how much money is available for him to win.
The producer has told him that the new prizes are ten dollars less than twice the original prizes.
Probability distributions describe the probability of all possible outcomes of a given variable.
The expectation of a function of X is given by E(f(X)) = f(x)P(X=x)
Linear transforms are when a variable X is transformed into aX + b, where a and b are constants.
The expectation and variance are given by: E(aX + b) = aE(X) + b Var(aX + b) = a2Var(X)
Linear Transforms If you have a variable X and numbers a and b, then:
So do linear transforms give me a quick way of calculating the expectation and variance when I want to play multiple games?
There’s a difference between using linear transforms and playing multiple games.
With linear transforms, all of  the probabilities stay the same, but the possible values change.
When you play multiple games, both the values and the probabilities are different, and even the number of  possible values can change.
It’s not possible to just transform the values, and working out the probabilities can quickly become complicated.
Imagine you were playing on a very simple slot machine with probability distribution X.
What if  you were going to play two games on the slot machine? You’d need to work out the probability distribution from scratch by considering all the possible outcomes from both games.
The underlying values change because the potential gains have doubled.
So how can we find the expectation and variance for this situation?
When we play multiple games on the slot machine, each game is called an event, and the outcome of  each game is called an observation.
Each observation has the same expectation and variance, but their outcomes can be different.
You may not gain the same amount in each game.
We need some way of  differentiating between the different games or observations.
We have the same expectation and variance, but we’re separate events.
In other words, they have the same probability distribution, even though they are separate observations and their outcomes can be different.
We can extend this for any number of  independent observations.
This means that if  we were to play two games on a slot machine where E(X) = -0.77, the expectation would be.
If  we want to find the expectation of  n observations, we can use.
In other words, to find the expectation and variance of  multiple observations, just multiply E(X) and Var(X) by the number of  observations.
With E(2X), you want to find the expectation of a variable where the underlying values have been doubled.
In other words, there’s only one variable, but the values are twice the size.
They both have the same probability distribution, but the actual outcome of each might be different.
Q: I see that the new variance is nVar(X) and not n2Var(X) like we had for linear transforms.
A: This time we have a series of independent observations, all distributed the same way.
This means that we can find the overall variance by adding the variance of each one together.
If we have n independent observations, then this gives us nVar(X)
When we calculate the variance of Var(nX), we multiply the underlying values by n.
As the variance is formed by squaring the underlying values, this means that the resulting variance is n2Var(X)
Probability distributions describe the probability of all possible outcomes of a given random variable.
The variance of a random variable X is given by.
Linear transforms are when a random variable X is transformed into aX + b, where a and b are numbers.
The amount of coffee in an extra large cup of coffee; X is the amount of coffee in a normal-sized cup.
Assuming you know the distribution of  each X, and your task is to say whether you can solve each problem using linear transforms or independent observations.
Finding the net gain from a lottery ticket after the price of tickets goes up; X is the net gain of buying 1 lottery ticket.
Drinking an extra cup of coffee per day; X is the amount of coffee in a cup.
Buying an extra hen to lay eggs for breakfast; X is the number of eggs laid per week by a certain breed of hen.
The amount of coffee in an extra large cup of coffee; X is the amount of coffee in a normal-sized cup.
Assuming you know the distribution of  each X, and your task is to say whether you can solve each problem using linear transforms or independent observations.
Finding the net gain from a lottery ticket after the price of tickets goes up; X is the net gain of buying 1 lottery ticket.
Drinking an extra cup of coffee per day; X is the amount of coffee in a cup.
Buying an extra hen to lay eggs for breakfast; X is the number of eggs laid per week by a certain breed of hen.
The winnings from each lottery ticket are independent of the others.
Changing the price of a ticket changes the expected winnings, but not the probability of winning, so this can be solved with linear transforms.
The local diner has started selling fortune cookies at $0.50 per cookie.
Most messages predict a good future for the buyer, but others offer money off at the diner.
If X is the net gain, what’s the probability distribution of X? What are the values of E(X) and Var(X)?
The diner decides to put the price of the cookies up to $1
The local diner has started selling fortune cookies at $0.50 per cookie.
Most messages predict a good future for the buyer, but others offer money off at the diner.
If X is the net gain, what’s the probability distribution of X? What are the values of E(X) and Var(X)?
The diner decides to put the price of the cookies up to $1
New slot machine on the block Fat Dan has brought in a new model slot machine.
Each game costs more, but if  you win you’ll win big.
Each game costs more than the other slot machine, but just look at the jackpot!
We’ve looked at the expectation and variance of  playing a single machine, and also for playing several independent games on the same machine.
What happens if  we play two different machines at once?
In this situation, we have two different, independent probability distributions for our machines:
We could work out the probability distribution of X + Y, but that would be timeconsuming, and we might make a mistake.
These are the current gains of Fat Dan’s new slot machine.
Add E(X) and E(Y) to get E(X + Y)… We want to find the expectation and variance of  playing one game each on both of  the slot machines.
In other words, we want to find E(X + Y) and Var(X + Y) where X and Y are random variables representing the two machines.
One way of  doing this would be to calculate the probability distribution of  X + Y, and then calculate the expectation and variance.
To find E(X + Y), all we need to do is add together E(X) and E(Y)
To find Var(X +Y), we add the two variances together.
If X and Y are not independent, then Var(X + Y) is no longer equal to Var(X) + Var(Y)
You’re not just limited to adding random variables; you can also subtract one from the other.
Instead of  using the probability distribution of  X + Y, we can use X – Y.
If  you’re dealing with the difference between two random variables, it’s easy to find the expectation.
Finding the variance of  X – Y is less intuitive.
To find Var(X – Y), we add the two variances together.
When we subtract one random variable from another, the variance of  the probability distribution still increases.
When we subtract independent random variables, the variance is exactly the same as if  we’d added them together.
It’s easy to make this mistake as at first glance it seems counterintuitive.
Just remember that if the two variables are independent, Var(X - Y) = Var(X) + Var(Y)
As well as adding and subtracting random variables, we can also add and subtract their linear transforms.
Imagine what would happen if  Fat Dan changed the cost and prizes on both machines, or even just one of  them.
The last thing we’d want to do is work out the entire probability distribution in order to find the new expectations and variances.
Suppose the gains on the X and Y slot machines are changed so that the gains for X become aX, and the gains for Y become bY.
To find the expectation and variance for combinations of  aX and bY, we can use the following shortcuts.
Adding aX and bY If  we want to find the expectation and variance of aX + bY, we use.
Subtracting aX and bY If  we subtract the random variables and calculate E(aX - bY) and Var(aX - bY), we  use.
It’s a linear transform, so we square the numbers here.
Just as before, we add the variances, even though we’re subtracting the random variables.
We square the numbers because it’s a linear transform, just like before.
Q: So if X and Y are games, does aX + bY mean a games of X and b games of Y?
A: aX + bY actually refers to two linear transforms added together.
In other words, the underlying values of X and Y are changed.
This is different from independent observations, where each game would be an independent observation.
Q: I can’t see when I’d ever want to use X – Y.
A: X – Y is really useful if you want to find the difference between two variables.
E(X – Y) is a bit like saying “What do you expect the difference between X and Y to be”, and Var(X – Y) tells you the variance.
Q: Why do you add the variances for X – Y? Surely you’d subtract them?
A: At first it sounds counterintuitive, but when you subtract one variable from another, you actually increase the amount of variability, and so the variance increases.
The variability of subtracting a variable is actually the same as adding it.
Another way of thinking of it is that calculating the variance squares the underlying values.
Q: Can we do this if X and Y aren’t independent?
A: No, these rules only apply if X and Y are independent.
If you need to find the variance of X + Y where there’s dependence, you’ll have to calculate the probability distribution from scratch.
Each observation has the same probability distribution, but the outcomes can be different.
The expectation and variance of linear transforms of X and Y are given by.
Write the formula or shortcut for each one in the table.
A restaurant offers two menus, one for weekdays and the other for weekends.
Each menu offers four set prices, and the probability distributions for the amount someone pays is as follows:
Write the formula or shortcut for each one in the table.
A restaurant offers two menus, one for weekdays and the other for weekends.
Each menu offers four set prices, and the probability distributions for the amount someone pays is as follows:
Let’s start by finding the expectation of a weekday and a weekend.
Each person eating at the restaurant is an independent observation, and to find the amount spent by each group, we multiply the expectation by the number in each group.
Jackpot! You’ve covered a lot of  ground in this chapter.
You learned how to use probability distributions, expectation, and variance to predict how much you stand to win by playing a specific slot machine.
And you discovered how to use linear transforms and independent observations to anticipate how much you’ll win when the payout structure changes or when you play multiple games on the same machine.
Restaurant A is generally more expensive than restaurant B, but the food quality is generally much better.
Below you’ll find two probability distributions detailing how much Sam tends to spend at each restaurant.
As a general rule, what would you say is the difference in price between the two restaurants? What’s the variance of this?
Let’s start by finding the expectation and variance of X and Y.
Restaurant A is generally more expensive than restaurant B, but the food quality is generally much better.
Below you’ll find two probability distributions detailing how much Sam tends to spend at each restaurant.
As a general rule, what would you say is the difference in price between the two restaurants? What’s the variance of this?
Counting all the possible ways in which you can order things is time.
If I try every permutation, sooner or later I’ll get through to Tom’s Tattoo Parlor.
Horses and jockeys travel from far and wide to see which horse can complete the track in the shortest time, and you can place bets on the outcome of  each race.
There’s a lot of  money to be made if  you can predict the top three finishers in each race.
The opening set of  races is for rookies, horses that have never competed in a race before.
This time, no statistics are available for previous races to help you anticipate how well each horse will do.
This means you have to assume that each horse has an equal chance of  winning, and it all comes down to simple probability.
The first race of  the day, the three-horse race, is just about to begin, and the Derby is taking bets.
You have $500 of  winnings from Fat Dan’s Casino to spend at the Derby.
Should we take this bet? Let’s work out some probabilities and find out.
Want to join in with the fun? If you know a thing or two about probability, you could do very well indeed.
It’s a three-horse race The first race is a very simple one between three horses, and in order to make the most amount of  money, you need to predict the exact order in which horses finish the race.
What’s the probability of winning a bet on the correct finishing order?
What’s the probability of winning a bet on the correct finishing order?
There are 6 different ways in which the race can be finished:
A three-horse race? How likely is that? Most races will.
So what we need is some quick way of  figuring out how many finishing orders there are for each race, one that works irrespective of  how many horses are racing.
Working out the number of  ways in which three horses can finish a race is straightforward; there are only 6 possibilities.
The trouble is, the more horses there are taking part in the race, the harder and more time consuming it is to work out every possible finishing order.
Let’s take a closer look at the different ways of  ordering the three horses we have for the race and see if  we can spot a pattern.
We can do this by looking at each position, one by one.
Let’s start by looking at the first position of  the race.
One of  the horses has to win the race, and this can be any one of  the three horses taking part.
This means that there are three ways of  filling the number one position.
If  one of  the horses has finished the race, this means there are two horses left.
This means that there are two ways of  filling the number two position, no matter which horse came first.
Only one horse can cross the finish line first, but it can be any of the three horses.
Once two horses have finished the race, there’s only one position left for the final horse—third place.
One horse has already finished the race, so there are only two horses that can finish second.
So how does this help us calculate all the possible finishing orders?
Only one horse hasn’t finished the race, so there’s only one position left for him: last.
This means that if  you have to work out the number of  ways in which you can order n separate objects, you can come up with a precise figure without having to figure out every possible arrangement.
This type of  calculation is called the factorial of  a number.
In math notation, factorials are represented as an exclamation point.
So when we write n!, this is just a shorthand way of  saying “take all the numbers from n down to 1, and multiply them together.” In other words, perform the following calculation:
And no matter how those first two slots are filled, there’s only one way of  filling the last position.
In other words, the number of  ways in which we can fill all three positions is:
This means that we can tell there are 6 different ways of  ordering the three horses, without us having to figure out each of  the arrangements.
Going round in circles There’s one exception to this rule, and that’s if  you’re arranging objects in a circle.
Imagine you want to stand four horses in a circle, and you want to find the number of  possible ways in which you can order them.
Now, let’s focus on arrangements where Frisky Funboy has Ruby Toupee on his immediate right, and Cheeky Sherbet on his immediate left.
Here are two of  the four possible arrangements of  this.
The key here is to fix the position of  one of  the horses, say Frisky Funboy.
With Frisky Funboy standing in a fixed position, you can count the number of  ways in which the remaining 3 horses can be ordered, and this will give you the right result without any duplicates.
In general, if  you have n objects you need to arrange in a circle, the number of  possible arrangements is given by.
At first glance, these two arrangements look different, but they’re actually the same.
The horses are in exactly the same positions relative to each other, the only difference is that in the second arrangement, the horses have walked a short distance round the circle.
This means that some of the ways in which you can order the horses are actually the same.
Q: How do I pronounce n!? A: You pronounce it as “n factorial.” The ! symbol is used to indicate a mathematical operation, and not to indicate any sort of exclamation.
Factorials also come into play in other branches of mathematics, like calculus.
In general, they’re a useful math shorthand, and you’ll see the factorial symbol whenever you’re faced with this sort of multiplication task.
This may seem like a strange result, but it’s a bit like saying there’s only one way to arrange 0 objects.
Q: What about if you want to find the factorial of a negative number? Or one that’s not an integer?
A: Factorials only work with positive integers, so you can’t find the factorial of a negative number, or one that’s not an integer.
One way of looking at this is that it doesn’t make sense to arrange bits of objects.
Each thing you’re arranging is classed as a whole object.
Q: Can the result of a factorial ever be an odd number?
Q: If I’m arranging n objects in a circle, there are (n - 1)! arrangements.
What if clockwise and counterclockwise arrangements are considered to be the same?
A: In this case, the number of arrangements is (n - 1)!/2
Calculating (n - 1)! gives you twice the number of arrangements you actually need as it gives you both clockwise and counterclockwise arrangements.
Q: What if I’m arranging objects in a circle and absolute position matters?
A: In this case the number of arrangements is given by n!
In that situation, it’s exactly the same as arranging n objects.
Formulas for arrangements If you want to find the number of possible arrangements of n objects, use n! where n! = n x (n-1) x ...
If you are arranging n objects in a circle, then there are (n - 1)! possible arrangements.
Paula wants to telephone the Statsville Health Club, but she has a very poor memory.
What’s the probability of getting the right number at random?
She can’t remember the order of each set of numbers though.
What’s the probability of getting the right telephone number now?
The Statsville Derby is organizing a parade for the end of the season.
The exact horse order will be chosen at random, and if you guess the horse order correctly, you win a prize.
What’s the probability that if you make a guess on the exact horse order, you’ll win the prize?
Hint: This time you need to arrange two groups of numbers.
Paula wants to telephone the Statsville Health Club, but she has a very poor memory.
What’s the probability of getting the right number at random?
She can’t remember the order of each set of numbers though.
What’s the probability of getting the right telephone number now? Hint: This time you need to arrange two groups of numbers.
The Statsville Derby are organizing a parade for the end of the season.
The exact horse order will be chosen at random, and if you guess the horse order correctly, you win a prize.
What’s the probability that if you make a guess on the exact horse order, you’ll win the prize?
To find the total number of possible arrangements, we multiply together the number of ways of arranging each group.
In the last race, you had a 1/6 probability of predicting the top finishers correctly.
But let’s see how you fare in the novelty race; it’s a.
It’s time for the novelty race The Statsville Derby is unusual in that not all of  the animals taking part in the races have to be horses.
In the next race, three of  the contenders are zebras, and they’re racing against three horses.
In this race, it’s the type of  animal that matters rather than the particular animal itself.
In other words, all we’re interested in is which sort of  animal finishes the race in which position.
The question is, how many ways are there of  ordering all the animals by species?
The Derby’s offering a special bet: if  you can predict whether a horse or zebra will finish in each place, the payout is 15:1
How would you go about solving this sort of problem? Write down your ideas in the space below.
So if  there are three horses and three zebras in today’s novelty race, how can we calculate how many different orderings there are of  horses and zebra.
This time we’re only interested in the type of animal, and not the particular animal itself.
So far we’ve only looked at the number of  ways in which we can order unique objects such as horses, and calculating 6! would be the correct result if  this was what we needed on this occasion.
We no longer care about which particular horse or zebra is in a particular position; we only care about what type of  animal it is.
As an example, if  we looked at an arrangement where the three zebras came first and the three horses came last, we wouldn’t want to count all of  the ways of  arranging those three horses and three zebras.
It doesn’t matter which particular zebra comes first; it’s enough to know it’s a zebra.
For this sort of problem, we care about which type of animal is in which position, but we don’t care about the name of the animal itself.
But since we’re not concerned about which individual zebra goes where, these arrangements are all the same.
So, to eliminate these repetitions, we can just divide the total number of arrangements by 3!
As with the zebras, we divide the end result by 3! to eliminate duplicate orderings.
This time we’re classing the 3 horses as being alike.
This means that the number of  ways of  arranging the 6 animals according to species is.
In other words, the probability of  betting correctly on the right order in which the different species finish the race is 1/20
Turn the page and we’ll look at this in more detail.
Imagine you want to arrange n objects, where k of  one type are alike, and j of another type are alike, too.
You can find the number of  possible arrangements by calculating:
If you have n objects wh ere k are alike the numbe.
Imagine you need to count the number of  ways in which n objects can be arranged.
To find the number of  arrangements, start off  by calculating the number of arrangements for the n objects as if  they were all unique.
Then divide by the number of  ways in which the k objects (the ones that are alike) can be arranged.
The number of ways of arranging n objects whe re j of one.
Arranging by type If you want to arrange n objects where j of one type are alike, k of another type are alike, so are m of another type and so on, the number of arrangements is given by n! j!k!m!...
The Statsville Derby have decided to experiment with their races.
How many ways are there of finishing the race if we’re interested in individual animals?
How many ways are there of finishing the race if we’re just interested in the species of animal in each position?
The Statsville Derby have decided to experiment with their races.
How many ways are there of finishing the race if we’re interested in individual animals?
How many ways are there of finishing the race if we’re just interested in the species of animal in each position?
First of all, let’s find the number of ways in which the 5 camels can finish the race together.
To do this, we class the 5 camels as one single object.
Q: Why did you treat the 5 camels as one object in the last part of the exercise? Surely they’re individual camels.
A: They’re individual camels, but in the last part of that problem we need to make sure we keep the camels together.
To do this, we bundle all the camels together and treat them as one object.
Q: It seems like the number of arrangements for the different objects has a lot to do with how you group them into like groups.
Mastering arrangements is a skill, but a lot depends on how you think things through.
The key thing is to think really carefully about what sort of problem you’re actually trying to solve and to get lots of practice.
Q: Are there many races where horses, zebras and camels all race together?
But hey, this is Statsville, and the Statsville Derby runs its own events.
It’s time for the twenty-horse race The novelty race is over, with the zebras taking the lead.
How would you go about finding the number of ways in which you can pick three horses out of twenty?
There are twenty horses racing, and we need to find the number of  possible arrangements of  the top three horses.
This way, we can work out the probability of  guessing the exact order correctly.
We can work out the solution the same way we did earlier, by looking at how many ways there are of  filling the first three positions.
We need a more concise way of solving this sort of problem.
At the moment we only have three numbers to multiply together, but what if  there were more?
We need to generalize a formula that will allow us to find the total number of  arrangements of  a certain number of  horses, drawn from a larger pool of  horses.
So the probability of  guessing the precise order in which the top three horses finish the race is 1/6,840
In this race, we’re not interested in how the rest of  the positions are filled, it’s only the first three positions that concern us.
This means that the total number of  arrangements for the top three horses is.
That gives us the right answer, but it could get complicated if there were more horses, or if we wanted to fill more positions.
How many ways can we fill the top three positions?
Examining permutations So how can we rewrite the calculation in terms of  factorials?
This is the number of positions we want to fill.
If we multiply it by 17!/17!, this will still give us the same answer.
This is the same expression written in terms of factorials.
This is the same expression that we had before, but this time written in terms of  factorials.
In general, the number of  permutations of  r objects taken from n is the number of  possible way in which each set of  r objects can be ordered.
Just guess which horses are in the top three and I’ll make it worth your while...
So if  you want to know how many ways there are of  ordering r objects taken from a pool of  n, permutations are the key.
Permutations give the total number of ways you can order a certain number of objects (r), drawn from a larger pool of objects (n)
What if horse order doesn’t matter So far we’ve found the number of  permutations of  ordering three horses taken from a group of twenty.
This means that we know how many exact arrangements we can make.
This time around, we don’t want to know how many different permutations there are.
We want to know the number of  combinations of  the top three horses instead.
We still want to know how many ways there are of  filling the top three positions, but this time the exact arrangement doesn’t matter.
We don’t need to know the precise order in which the horses finish the race, it’s enough to know which horses are in the top three.
At the moment, the number of  permutations includes the number of  ways of arranging the 3 horses that are in the top three.
This will give us the number of  ways in which the top three positions can be filled but without the exact order mattering.
With a 1/1,140 chance of winning here, the odds are way against you.
But the payout is also huge at 1,500:1, so you can actually expect to come out ahead.
It all depends on how much of a risk taker you are.
Examining combinations Earlier on we found a general way of  calculating permutations.
Well, there’s a way of  doing this for combinations too.
In general, the number of  combinations is the number of  ways of choosing r objects from n, without needing to know the exact order of  the objects.
This is the number of positions we want to fill.
You divide by an extra r! if it’s a combination.
This bit is calculated in the same way as a permutation.
So what’s the difference between a combination and a permutation?
A combination is the number of  ways in which you can choose objects from a pool, without caring about the exact order in which you choose them.
It’s a lot more general than a permutation as you don’t need to know how each position has been filled.
A permutation is the number of  ways in which you can choose objects from a pool, and where the order in which you choose them counts.
It’s a lot more specific than a combination as you want to count the number of  ways in which you fill each position.
Head First: Combination, great to have you on the show.
A lot of  people have noticed that you and Permutation are very similar to each other.
Combination: I can see why people might think that because we deal with very similar situations.
We’re both very much concerned with choosing a certain number of  objects from a pool.
Having said that, I’d say that’s where the similarity ends.
Combination: Well, for starters we both have very different attitudes.
Permutation is very concerned about order, and really cares about the exact order in which objects are picked.
Not only does he want to select objects, he wants to arrange them too.
Combination: No way! I’m sure permutation shows a lot of  dedication and all that, but quite frankly, life’s too short.
As far as I’m concerned, if  an object’s picked from the pool, then that’s all anyone needs to know.
Combination: I wouldn’t like to say that either one of  us is better as such; it just depends which of  us is the most appropriate for the situation.
Lots of  music players have playlists where you can choose which songs you want to play.
Combination: Now, both Permutation and I are both interested in what’s on the playlist, but in different ways.
I’m happy just knowing what songs are on it, but Permutation takes it way further.
He doesn’t just want to know what songs are on the playlist, he wants to know the exact order too.
Change the order of  the songs, and it’s the same Combination, but a different Permutation.
Is calculating a Combination similar to how you’d calculate a Permutation?
With Permutation, you find n!, and then divide it by (n-r)!
My calculation is similar, except that you divide by an extra r!
This makes me generally smaller—which makes sense because I’m not as fussy as Permutation.
Q: Can a permutation ever be smaller than a combination?
To calculate a combination, you divide by an extra number, so the end result is smaller.
The closest you get to this is when a permutation and combination are identical.
Q: Which is a permutation and which is a combination? I get confused.
A: A permutation is when you care about the number of possible arrangements of the objects you’ve chosen.
A combination is when you don’t mind about their precise order; it’s enough that you’ve chosen them.
If I want to find the number of combinations of choosing r objects from n, do I write that nCr or rCn?
One way of remembering this is that the higher of the two numbers is higher up in the shorthand.
Q: Are there other ways of writing this? I think I’ve seen combinations somewhere else, but they didn’t look like that.
We’ve used the shorthand nCr, but an alternative is (n)            r.
You’ll see more of these a bit later on in the book, so look out for when you might need them.
Q: Dealing with permutations and combinations looks similar to when you’re dealing with like objects.
When you’re dealing with like objects, you divide the total number of arrangements by the number of ways in which you can divide the like objects.
For permutations, it’s as though you’re treating all the objects you don’t choose as being alike, so you divide n! by (n-r)!
For combinations, it’s as though the objects you pick are alike, too.
This means you divide the number of permutations by r!
Permutations If you choose r objects from a pool of n, the number of permutations is given by.
If you choose r objects from a pool of n, the number of combinations is given by.
The Statsville All Stars are due to play a basketball match.
How many different arrangements are there for choosing who’s on the court at the same time?
The coach classes 3 of the players as expert shooters.
What’s the probability that all 3 of these players will be on the court at the same time, if they’re chosen at random?
It’s time for you to work out some poker probabilities.
A royal flush is a hand that consists of a 10, Jack, Queen, King and Ace, all of the same suit.
What’s the probability of getting this combination of cards? Use your answer above to help you.
Four of a kind is when you have four cards of the same denomination.
A flush is where all 5 cards belong to the same suit.
The Statsville All Stars are due to play a basketball match.
How many different arrangements are there for choosing who’s on the court at the same time?
The coach classes 3 of the players as expert shooters.
What’s the probability that all 3 of these players will be on the court at the same time, if they’re chosen at random?
We don’t need to consider the order in which we pick the players, so we can work this out using combinations.
Let’s start by finding the number of ways in which the three shooters can be on the court at the same time.
If the three expert shooters are on the court at the same time, this means that there are 2 more places left for the other players.
It’s time for you to work out some poker probabilities.
A royal flush is a hand that consists of a 10, Jack, Queen, King and Ace, all of the same suit.
What’s the probability of getting this combination of cards? Use your answer above to help you.
There’s one way of getting this combination for each suit, and there are 4 suits.
Four of a kind is when you have four cards of the same denomination.
Let’s start with the 4 cards of the same denomination.
A flush is where all 5 cards belong to the same suit.
To find the number of possible combinations, find the number of ways of choosing a suit, and then choose 5 cards from the suit.
It’s the end of the race The race between the twenty horses is over, and the overall winner is Ruby Toupee, followed by Cheeky Sherbet and Frisky Funboy.
If  you decided to bet on these three horses, you just won big!
In this chapter, you’ve learned how to cope with different arrangements, and how to quickly count the number of possible combinations and permutations without having to work out each and every possibility.
The sort of  knowledge you’ve gained gives you enormous probability and statistical power.
Keep reading, and we’ll show you how to gain even greater mastery.
So far we’ve looked at how to calculate and use probability distributions, but wouldn’t it be.
So far we’ve looked at how to calculate and use probability distributions, but wouldn’t it be.
Meet Chad, the hapless snowboarder Chad likes to snowboard, but he’s accident-prone.
If  there’s a lone tree on the slopes, you can guarantee it will be right in his path.
Chad wishes he didn’t keep hitting trees and falling over; his insurance is costing him a fortune.
Chad’s about here—just follow the tree damage to see how well his first run went.
There’s a lot riding on Chad’s performance on the slopes: his ego, his success with the ski bunnies on the trail, his insurance premiums.
If  it’s likely he’ll make it down the slopes in less than 10 tries, he’s willing to risk embarrassment, broken bones, and a high insurance deductible to try out some new snowboarding tricks.
The probability of  Chad making a clear run down the slope is 0.2, and he’s going to keep on trying until he succeeds.
After he’s made his first successful run down the slopes, he’s going to stop snowboarding, and head back to the lodge triumphantly.
The probability of Chad making a successful run down the slopes is 0.2 for any given trial (assume trials are independent)
What’s the probability he’ll need two trials? What’s the probability he’ll make a successful run down the slope in one or two trials? Remember, when he’s had his first successful run, he’s going to stop.
Hint: You may want to draw a probability tree to help visualize the problem.
Chad is remarkably resilient, and any collisions in a given run don’t affect his performance in future trials.
The probability of Chad making a successful run down the slopes is 0.2 for any given trial (assume trials are independent)
What’s the probability he’ll need two trials? What’s the probability he’ll make a successful run down the slope in one or two trials? Remember, when he’s had his first successful run, he’s going to stop..
Here’s a probability tree for the first two trials, as these are all that’s needed to work out the probabilities.
If we have to work out every single probability, we’ll be here forever.
So you expect me to come up with the probability distribution of something that’s neverending? Is that your idea of a joke?
There’s a problem because the number of possibilities is neverending.
Chad will continue with his attempts to make it down the slope until he is successful.
There are no guarantees about exactly when Chad will first successfully make it down the slopes.
Even though it’s neverending, there’s still a way of figuring out this type of probability distribution.
This is actually a special kind of  probability distribution, with special properties that makes it easy to calculate probabilities, along with the expectation and variance.
So far you’ve found the probability that Chad will need fewer than three attempts to make it down the slope.
Rather than work out the probabilities from scratch every time, it would be useful if  we could use a probability distribution.
To do this, we need to work out the probability for every single possible number of  attempts Chad needs to get down the slope.
Let’s define the variable X to be the number of  trials needed for Chad to make a successful run down the slope.
Chad only needs to make one successful run, and then he’ll stop.
Let’s start off  by examining the first four trials so that we can calculate probabilities for the first four values of  X.
By doing this, we can see if  there’s some sort of  pattern that will help us to easily work out the probabilities of  other values.
Here are the probabilities for the first four values of  X.
Here’s a table containing the the probabilities of X for different values.
Can you guess what the probability will be in terms of r?
When we use P(X = x), we’re using it to demonstrate x taking on any value in the probability distribution.
In the table above, we show various values of  x, and we calculate the probability of  getting each of  these values.
When we use P(X = r), x takes on the particular value r.
We’re looking for the probability of  getting this specific value.
It’s just that we haven’t specified what the value of  r is so that we can come up with a generalized calculation for the probability.
It’s a bit like saying that x can take on any value, including the fixed value r.
Here’s a table containing the the probabilities of X for different values.
For X = 4, Chad fails three times and succeeds on his fourth attempt.
For X = 5, Chad fails on his first four attempts.
So what if P(X = r)? For Chad to be successful on his r’th attempt, he must have failed in his first (r-1) attempts, before succeeding in his r’th.
First you say P(X = x), then you say P(X = r)
As you can see, the probabilities of  Chad’s snowboarding trials follow a particular pattern.
You can quickly work out the probabilities for any value r by using:
In other words, if  you want to find P(X = 100), you don’t have to draw an enormous probability tree to work out the probability, or think your way through exactly what happens in every trial.
If  the probability of  success in a trial is represented by p and the probability of  failure is 1 - p, which we’ll call q, we can work out any probability of  this nature by using:
If p represents the probability of success, then q represen.
Q: What’s the point in generalizing this? It’s just one particular problem we’re dealing with.
A: We’re generalizing it so that we can apply the results to other similar problems.
If we can generalize the results for this kind of problem, it will be quicker to use it for other similar situations in the future.
Q: You said we needed to find an expression for P(X = r)
A: P(X = r) means “the probability that X is equal to value r,” where r is the number of trials we need to get the first success.
This would give you a quick way of finding the probability.
Q: Why is it the letter r? Why not some other letter?
A: We used the letter r so that we could generalize the result for any particular number.
We could have used practically any other letter, but using r is common.
Q: How can we have a probability distribution if the number of possibilities is endless?
A: We don’t have to specify a probability distribution by physically listing the probability of every possible outcome.
The key thing is that we need a way of describing every possibility, which we can do with a formula for computing the probability.
Q: Wouldn’t Chad’s snowboarding skills eventually improve? Is it realistic to say the probability of success is 0.2 for every trial?
But in this problem, Chad is truly hapless when it comes to snowboarding, and we have to assume that his skills won’t improve—which means his probability of success on the slopes will follow the geometric distribution.
Let’s use the variable X to represent the number of  trials needed to get the first successful outcome—in other words, the number of  trials needed for the event we’re interested in to happen.
To find the probability of  X taking a particular value r, you can get a quick result by using:
There can be either a success or failure for each trial, and the probability of  success is the same for each trial.
The main thing you’re interested in is how many trials are needed in order to get the first successful outcome.
In other words, to get a success on the rth attempt, there must first have been (r – 1) failures.
So if  you have a situation that matches this set of  criteria, you can use the geometric distribution to help you take a few shortcuts.
The important thing to be aware of  is that we use the word “success” to mean that the event we’re interested in happens.
If  we’re looking for an event that has negative connotations, in statistical terms it’s still counted as a success.
P(X = r) is at its highest when r = 1, and it gets lower and lower as r increases.
Notice that the probability of  getting a success is highest for the first trial.
This means that the mode of  any geometric distribution is always 1, as this is the value with the highest probability.
This may sound counterintuitive, but it’s most likely that only one attempt will be needed for a successful outcome.
We said that Chad’s snowboarding exploits are an example of  the geometric distribution.
We can use this to find P(X  r), the probability that r or fewer trials are needed in order for there to be a successful outcome.
If  a variable X follows a geometric distribution where the probability of success in a trial is p, this can be written as.
As well as finding exact probabilities for the geometric distribution, there’s also a quick way of  finding probabilities that deal with inequalities.
P(X > r) is the probability that more than r trials will be needed in order to get the first successful outcome.
In order for more than r trials to be needed, this means that the first r trials must have ended in failure.
This means that you find the probability by multiplying the probability of  failure together r times.
For the number of trials needed fo r a success to be greater.
I’m getting bruised! How many attempts do you expect me to have to make before I make it down the.
So far we’ve found probabilities for the number of  attempts Chad needs to make before successfully makes it down the slope, but what if  we want to find the expectation and variance? If  we know the expectation, for instance, we’ll be able to say how many attempts we expect Chad to make before he’s successful.
Can you remember how we found expectations earlier in the book? We find E(X) by calculating xP(X = x)
The probabilities in this case go on forever, but let’s start by working out the first few values to see if  there’s some sort of  pattern.
Can you see what happens to the values of  xP(X = x)?
When x is larger than 5, the values start decreasing again, and keep on decreasing as x gets larger.
As x gets larger, xP(X = x) becomes smaller and smaller until it makes virtually no difference to the running total.
We can see this more clearly if  we chart the cumulative total of  xP(X = x):
As a reminder, expectation is the average value that you expect to get, a bit like the mean but for probability distributions.
Variance is a measure of how much you can expect this to varies by.
Let’s see if we can find an expression for the variance of the geometric distribution in the same way that we did for the expectation.
In fact, the running total of  xP(X = x) for an infinite number of  trials is 5 itself.
We’re not just limited to finding the expectation of  the geometric distribution, we can find the variance too.
The expectation is 1 divided by the probability of success.
I can expect to make it down in 5 tries? Not bad!
Let’s see if we can find an expression for the variance of the geometric distribution in the same way that we did for the expectation.
When x reaches 10 it starts to go down again.
I get it, so x2P(X = x) gets larger for a while, but after that, it gets smaller and smaller as x gets larger and larger.
Finding the variance for our distribution So how does this help us find the variance of  the number of  trials it takes Chad to make a successful run down the slopes?
We find the variance of  a probability distribution by calculating.
This means that we calculate x2P(X = x), and then subtract E(X) squared.
By graphing the resulting values against the values of  x, you can see the pattern of  Var(X) as x increases.
Even though there’s no fixed number of trials, you can still work out what the expectation and variance are.
A quick guide to the geometric distribution Here’s a quick summary of  everything you could possibly need to know about the Geometric distribution.
When do I use it? Use the Geometric distribution if  you’re running independent trials, each one can have a success or failure, and you’re interested in how many trials are needed to get the first successful outcome.
How do I calculate probabilities? Use the following handy formulae.
What about the expectation and variance? Just use the following.
Q: Can I trust these formulae? Can I use them any time I need to find probabilities and expectations?
A: You can use these shortcuts whenever you’re dealing with the geometric distribution, as they’re shortcuts for that probability distribution.
If you’re dealing with a situation that can’t be modelled by the geometric distribution, don’t use these shortcuts.
Remember, the geometric distribution is used for situations where you’re running independent trials (so the probability stays the same for each one), each trial ends in either success or failure, and the thing you’re interested in is how many trials are needed to get the first successful outcome.
Q: What about if my circumstances are different? What if I have a fixed number of trials and I want to find the number of successful outcomes?
A: You can’t use the geometric distribution to model this sort of situation, but don’t worry, there are other methods.
Q: Do I have to learn all of these shortcuts?
A: If you have to deal with the geometric distribution, knowing the formulae will save you a lot of time.
If you’re sitting for a statistics exam, check whether your exam syllabus covers it.
Q: Why does the distribution use the letters p and q?
In this case, it’s the probability of getting a successful outcome in one trial.
The letter q is often used in statistics to represent 1 - p, or pI.
You’ll see quite a lot of it through the rest of this chapter and the rest of the book.
The probability of the first success being in the r’th trial.
The probability you’ll need more than r trials to get your first success The probability you’ll need.
Your job is to play like you’re the snowboarder and work out the.
The probability that you will be successful on your second attempt, while failing on your first.
The probability that you will be successful in 4 attempts or fewer.
The probability that you will need more than 4 attempts to be successful.
The number of attempts you expect you’ll need to make before being successful.
Your job is to play like you’re the snowboarder and work out the.
The probability that you will be successful on your second attempt, while failing on your first.
The probability that you will need more than 4 attempts to be successful.
The number of attempts you expect you’ll need to make before being successful.
You’ve mastered the geometric distribution Thanks to your skills with the geometric distribution, Chad not only knows the probability of  him making a clear run down the slopes after any number of  tries, but also how many times he can expect it to take to get down the hill successfully, and how much variability there is.
We’ve got some fiendishly difficult questions on the show tonight.
We’ve got some great questions for you today, so let’s get started.
In Round One I’m going to ask you three questions, and for each question there are four possible answers.
You can quit now and walk away with the consolation prize, but if you play on and beat your competitors, you’ll move on to the next round and be one step closer to winning a swivel chair.
Q: What’s a quiz show doing in the middle of my chapter? I thought we were talking about probability distributions.
This situation is ideal for another sort of probability distribution.
A: If you don’t know the answers you’ll have to answer them at random.
Give it your best shot - you might win a swivel chair.
What are the probabilities for this problem?  What sort of pattern can you see? We’re using X to represent the number of questions you get correct out of three.
Should you play, or walk away? It’s unlikely you’ll know the game show host well enough to answer these questions, so let’s see if  we can find the probability distribution for the number of  questions you’ll get correct if  you choose answers at random.
That should help you decide whether or not to play on.
What are the probabilities for this problem?  What sort of pattern can you see? We’re using X to represent the number of questions you get correct out of three.
How do you think they might help you with this sort of problem?
So far we’ve looked at the probability distribution of  X, the number of questions we answer correctly out of  three.
Just as with the geometric distribution, there seems to be a pattern in the way the probabilities are formed.
There are 3 questions r is the number of questions we get right.
What’s the missing number? For each probability, we need to answer a certain number of  questions correctly, and there are different ways of  achieving this.
As an example, there are three different ways of  answering exactly one question correctly out of  three questions.
Another way of  looking at this is that there are 3 different combinations.
Just to remind you, a combination nCr is the number of  ways of  choosing r objects from n, without needing to know the exact order.
This means that the probability of  getting r questions correct out of  3 is given by.
So, by this formula, the probability of  getting 1 question correct is:
It looks like these questions are just as obscure as the ones in the previous round, so you’ll have to answer questions at random again.
Let’s see if  we can work out the probability distribution for this new set of  questions.
As before, there are four possible answers to each question.
Let’s generalize the probability further So far you’ve seen that the probability of  getting r questions correct out of  3 is given by.
Rather than rework this probability for 5 questions, let’s rework it for n questions instead.
That way we’ll be able to use the same formula for every round of  Who Wants To Win A Swivel Chair.
So what’s the formula for the probability of  getting r questions right out of n? It’s actually.
What if the probability of getting a question right changes? I wonder if we.
Imagine the probability of  getting a question right is given by p, and the probability of  getting a question wrong is given by 1 – p, or q.
The probability of  getting r questions right out of  n is given by.
Guessing the answers to the questions on Who Wants To Win A Swivel Chair is an example of  the binomial distribution.
There can be either a success or failure for each trial, and the probability of  success is the same for each trial.
Just like the geometric distribution, you’re running a series of  independent trials, and each one can result in success or failure.
The difference is that this time you’re interested in the number of  successes.
Let’s use the variable X to represent the number of  successful outcomes out of  n trials.
The exact shape of  the binomial distribution varies according to the values of  n and p.
The closer to 0.5 p is, the more symmetrical the shape becomes.
What’s the expectation and variance? So far we’ve looked at how to use the binomial distribution to find basic probabilities, which allows us to calculate the probability of  getting a certain number of  questions correct.
But how many questions can we actually expect to get right if  we choose the answers at random? That will help you better decide whether we should answer the next round of  questions.
Let’s see if  we can find a general expression for the expectation and variance.
We’ll start by working out the expectation and variance for a single trial, and then see if  we can extend it to n independent trials.
Let’s look at one trial Suppose we conduct just one trial.
We can use this to find the expectation and variance of  X.
So for a single trial, E(X) = p and Var(X) = pq.
In general, what happens to the expectation and variance when there are n independent observations? How can this help us now?
Pool Puzzle Let’s see if you can derive the expectation.
Your job is to take elements from the pool and place them into the blank lines of the calculations.
You may not use the same element more than once, and you won’t need to use all.
Note: each element in the pool can only be used once!
E(Xi) = p, and Var(Xi) = pq You need to find the expectation and variance of n independent trials.
Pool Puzzle Solution Let’s see if you can derive the expectation.
Your job is to take elements from the pool and place them into the blank lines of the calculations.
You may not use the same element more than once, and you won’t need to use all.
E(Xi) = p, and Var(Xi) = pq You need to find the expectation and variance of n independent trials.
Binomial expectation and variance Let’s summarize what we just did.
First of  all, we took at one trial, where the probability of  success is p, and where the distribution is binomial.
Using this, we found the expectation and variance of  a single trial.
We then considered n independent trials, and used shortcuts to find the expectation and variance of  n trials.
This is useful to know as it gives us a quick way of  finding the expectation and variance of  any probability distribution, without us having to work out lots of  individual probabilities.
Q: The geometric distribution and the binomial distribution seem similar.
What’s the difference between them? Which one should I use when?
A: The geometric and binomial distributions do have some things in common.
Both of them deal with independent trials, and each trial can result in success or failure.
The difference between them lies in what you actually need to find out, and this dictates which probability distribution you need to use.
If you have a fixed number of trials and you want to know the probability of getting a certain number of successes, you need to use the binomial distribution.
You can also use this to find out how many successes you can expect to have in your n trials.
If you’re interested in how many trials you’ll need before you have your first success, then you need to use the geometric distribution instead.
The mode of a probability distribution is the value with the highest probability.
If p is 0.5 and n is even, the mode is np.
If p is 0.5 and n is odd it has two modes, the two values either side of np.
For other values of n and p, finding the mode is a matter of trial and error, but it’s generally fairly close to np.
Q: So for both the geometric and the binomial distributions you run a series of trials.
Does the probability of success have to be the same for each trial?
A: In order for the geometric or binomial distribution to be applicable, the probability of success in each trial must be the same.
If it’s not, then neither the geometric nor binomial distribution is appropriate.
Q: I’ve tried calculating E(X) and it’s not a value that’s in the probability distribution.
A: When you calculate E(X), the result may not be a possible value in your probability distribution.
It may not be a value that can actually occur.
If you get a result like this, it doesn’t mean that you’ve made a mistake, so don’t worry.
Your quick guide to the binomial distribution Here’s a quick summary of  everything you could possibly need to know about the binomial distribution.
When do I use it? Use the binomial distribution if  you’re running a fixed number of  independent trials, each one can have a success or failure, and you’re interested in the number of  successes or failures.
The probability of getting a successful outcome in a single trial is 0.25
What’s the probability of getting two or three questions right?
The probability of getting a successful outcome in a single trial is 0.25
What’s the probability of getting two or three questions right?
It’s been great having you as a contestant on the show, and we’d love to have you back later on.
But we’ve just had a phone call from the Statsville cinema.
So how do we find probabilities? The trouble with this sort of  problem is that while we know the mean number of  popcorn machine malfunctions per week, the actual number of  breakdowns varies each week.
We need to find the probability that the popcorn machine won’t break down next week.
Sound difficult? Don’t worry, there’s a probability distribution that’s designed for just this sort of  situation.
Where’s my popcorn? I want popcorn now! Give me my popcorn!
The trouble is that the popcorn machine at the Statsville Cinema keeps breaking down, and the customers aren’t happy.
The cinema has a big promotion on next week, and the cinema manager needs everything to be perfect.
He doesn’t want the popcorn machine to break down during the week, or people won’t come back.
The mean number of  popcorn machine malfunctions per week, or rate of malfunctions, is 3.4
What’s the probability that it won’t break down at all next week?
If  they expect the machine to break down more than a few times next week, the Statsville Cinema will buy a new popcorn machine, but if  not, they’ll stick with the current one and run the risk of  a breakdown.
It’s a different sort of distribution This is a different sort of  problem from the ones we’ve encountered so far.
Instead, we have a situation where we know the rate at which malfunctions happen, and where malfunctions occur at random.
Individual events occur at random and independently in a given interval.
This can be an interval of  time or space—for example, during a week, or per mile.
The formula for the probability uses the exponential function ex, where x is some number.
It’s a standard function available on most calculators, so even though the formula might look daunting at first, it’s actually quite straightforward to use in practice.
We’re not going to derive it here, but to find the probability that there are r occurrences in a specific interval, use the formula:
So if  X follows a Poisson distribution, what’s its expectation and variance? It’s easier than you might think...
It always stands for 2.718, so you can just substitute in this number for e in the Poisson formula.
Many scientific calculators have an ex key that will calculate powers of e for you.
Finding the expectation and variance for the Poisson distribution is a lot easier than finding it for other distributions.
I tell you everything you need to know about the Poisson distribution.
Remember, the mean number of times you break down in a week is 3.4
What’s the probability of the machine not malfunctioning next week?
What’s the probability of the machine malfunctioning three times next week?
What’s the probability of the machine not malfunctioning next week?
Let’s use X to represent the number of times the popcorn machine malfunctions in a week.
What’s the probability of the machine malfunctioning three times next week?
Remember, the mean number of times you break down in a week is 3.4
Q: Where does the formula for the Poisson distribution come from?
A: It can actually be derived from the other distributions, but the mathematics are quite involved.
In practice it’s best to just accept the formula, and remember the situations in which it’s useful.
Q: What’s the difference between the Poisson distribution and the other probability distributions?
A: The key difference is that the Poisson distribution doesn’t involve a series of trials.
Instead, it models the number of occurrences in a particular interval.
A: e is a constant in mathematics that stands for the number 2.718
So you can substitute in 2.718 for e in the formula for calculating Poisson probabilities.
The constant e is used frequently in calculus, and it also has many other applications in everything from calculating compound interest to advanced probability theory.
Further discussion of e is outside the scope of this book, though.
Q: I keep getting the wrong answer when I try to calculate probabilities using the Poisson distribution.
Where’s my drink? I want a drink to go with my popcorn.
It’s not just the popcorn machine that keeps breaking down, now the drinks machine has begun malfunctioning too.
The mean number of  breakdowns per week of  the drinks machine is 2.3
The cinema manager can’t afford for anything to go wrong next week when the promotion is on.
What’s the probability that there will be no breakdowns next week, either with the popcorn machine nor the drinks machine?
What’s the probability distribution of the drinks machine? How can we find the probability that neither the popcorn machine nor the drinks machine go wrong next week?
So what’s the probability distribution? Let’s take a closer look at this situation.
We have two machines, a popcorn machine and a drinks machine, and we know the mean number of  breakdowns of  each machine in a week.
We want to find the probability that there will be no breakdowns next week.
Drinks machine The mean number of breakdowns per week of the popcorn machine is 3.4
The mean number of breakdowns per week of the drinks machine is 2.3
If  X represents the number of  breakdowns of  the popcorn machine and Y represents the number of  breakdowns of  the drinks machine, then both X and Y follow Poisson distributions.
In other words, the popcorn machine breaking down has no impact on the probability that the drinks machine will malfunction, and the drinks machine breaking down has no impact on the probability that the popcorn machine will malfunction.
If X and Y are independent variables, how can we find probabilities for X + Y?
Combine Poisson variables You saw in previous chapters that if  X and Y are independent random variables, then.
This means that if  X and Y both follow Poisson distributions, then so does X + Y.
In other words, we can use our knowledge of  the way both X and Y are distributed to find probabilities for X + Y.
Once you’ve found how X + Y is distributed, you can use it to find probabilities.
Once you’ve found how X + Y is distributed, you can use it to find probabilities.
Q: Does that mean that the probability and expectation shortcuts we saw earlier in the book work for the Poisson distribution too?
This means that we can use all of the shortcuts that apply to independent variables.
A: X + Y follows a Poisson distribution because both X and Y are independent, and they both follow a Poisson distribution.
Both the popcorn machine and drinks machine each malfunction at random but at a mean rate.
This means that together they also breakdown at random and at a mean rate.
Together, they still meet the criteria for the Poisson distribution.
Q: So can we use the distribution of X + Y in the same we would any other Poisson distribution?
Only a .003 chance of no breakdowns next week? Guess we better get some new machines after all.
The Case of  the Broken Cookies Kate works at the Statsville cookie factory, and her job is to make sure that boxes of  cookies meet the factory’s strict rules on quality control.
Kate picks up her calculator, but when she tries to calculate 100!, her calculator displays an error because the number is too big.
Well,” says her boss, “you’ll just have to calculate it manually.
She’s managed to find the probability and has managed to avoid calculating 100! altogether.
She picks up her coat and walks out the door.
How did Kate find the probability so quickly, and avoid the error on her calculator?
The Poisson in disguise The Poisson distribution has another use too.
Under certain circumstances it can be used to approximate the binomial distribution.
Why should I care? Why would I want to do that?
Sometimes it’s simpler to use the Poisson distribution than the binomial.
At some point you’d need to calculate 3000!, which would be difficult even with a good calculator.
Because of  this, it’s useful to know when you can use the Poisson distribution to accurately approximate the answer instead.
So under what circumstances can we use this, and how?
Let’s start off  by looking at the expectation and variance of  the two distributions.
We want to find the circumstances in which the expectation and variance of  the Poisson distribution are like those of  the Binomial distribution.
A student needs to take an exam, but hasn’t done any revision for it.
He needs to guess the answer to each question, and the probability of getting a question right is 0.05
What’s the probability he’ll get 5 questions right? Use the Poisson approximation to the binomial distribution to find out.
Q: Why would I ever want to use the Poisson distribution to approximate the binomial distribution?
A: When n is very large, it can be difficult to calculate nCr.
Some calculators run out of memory, and the results can be so large they’re just unwieldy.
Using the Poisson distribution in this way is a way round this sort of problem.
When this is the case, the binomial distribution and the Poisson distribution are approximately the same.
Q: Why do we use np as the parameter for the Poisson distribution?
How did Kate find the probability so quickly, and avoid the Out of  Memory error on her calculator?
Kate spotted that even though she needed to use the binomial distribution, her values of  n and p were such that she could approximate the probability using the Poisson distribution instead.
A lot of  calculators can’t cope with high factorials, and this can sometimes make the binomial distribution unwieldy.
Knowing how to approximate it with the Poisson distribution can sometimes save you quite a bit of  time.
A student needs to take an exam, but hasn’t done any revision for it.
He needs to guess the answer to each question, and the probability of getting a question right is 0.05
What’s the probability he’ll get 5 questions right? Use the Poisson approximation to the binomial distribution to find out.
Anyone for popcorn? You’ve covered a lot of  ground in this chapter.
You’ve built on your existing knowledge of  probability and statistics by tackling three of  the most important discrete probability distributions.
Moreover, you’ve gained a deeper understanding of  how probability distributions work and the sort of  shortcuts you can make to save yourself  time and produce reliable results, skills that will come in useful in the rest of  the book.
So sit back and enjoy the popcorn — you’ve earned it.
Your quick guide to the Poisson distribution Here’s a quick summary of  everything you could possibly need to know about the Poisson distribution.
How do I calculate probabilities, and the expectation and variance? Use.
What connection does it have to the binomial distribution? If  X ~ B(n, p), where n is large and p is small, then X can be approximated using.
Your job is to say which distribution each of them follows, say what the expectation and variance are, and find any required probabilities.
The probability of him knocking all the pins over is 0.3
If he has 10 shots, what’s the probability he’ll knock all the pins over less than three times?
What’s the probability that no buses will turn up in a single 15 minute interval?
What’s the probability you’ll need to open fewer than 4 cereal packets before finding your first toy?
Your job is to say which distribution each of them follows, say what the expectation and variance are, and find any required probabilities.
The probability of him knocking all the pins over is 0.3
If he has 10 shots, what’s the probability he’ll knock all the pins down less than three times?
For a general probability, P(X = r) = nCr x p r x qn-r.
What’s the probability that no buses will turn up in a single 15 minute interval?
What’s the probability you’ll need to open fewer than 4 cereal packets before finding your first toy?
The geometric distribution applies when you run a series of independent trials, there can be either a success or failure for each trial, the probability of success is the same for each trial, and the main thing you’re interested in is how many trials are needed in order to get your first success.
If the conditions are met for the geometric distribution, X is the number of trials needed to get the first successful outcome, and p is the probability of success in a trial, then.
The binomial distribution applies when you run a series of finite independent trials, there can be either a success or failure for each trial, the probability of success is the same for each trial, and the main thing you’re interested in is the number of successes in the n independent trials.
If the conditions are met for the binomial distribution, X is the number of successful outcomes out of n trials, and p is the probability of success in a trial, then.
If X ~ B(n, p), you can calculate probabilities using.
The Poisson distribution applies when individual events occur at random and independently in a given interval, you know the mean number of occurrences in the interval or the rate of occurrences and this is finite, and you want to know the number of occurrences in a given interval.
So far we’ve looked at probability distributions where we’ve been able to specify exact.
So far we’ve looked at probability distributions where we’ve been able to specify exact.
Discrete data takes exact values… So far we’ve looked at probability distributions where the data is discrete.
By this we mean the data is composed of  distinct numeric values, and we’re been able to calculate the probability of  each of these values.
As an example, when we looked at the probability distribution for the winnings on a slot machine, the possible amounts we could win on each game were very precise.
We knew exactly what amounts of  money we could win, and we knew we’d win one of  them.
If  data is discrete, it’s numeric and can take only exact values.
It’s often data that can be counted in some way, such as the number of gumballs in a gumball machine, the number of  questions answered correctly in a game show, or the number of  breakdowns in a particular period.
Sometimes data covers a range, where any value within that range is possible.
It’s frequently data that is measured in some way rather than counted, and a lot depends on the degree of  precision you need to measure to.
The type of data you have affects how you find probabilities.
So far we’ve only looked at probability distributions that deal with discrete data.
Using these probability distributions, we’ve been able to find the probabilities of exact discrete values.
The problem is that a lot of  real-world problems involve continuous data, and discrete probability distributions just don’t work with this sort of  data.
To find probabilities for continuous data, you need to know about continuous data and continuous probability distributions.
What’s the delay? Julie is a student, and her best friend keeps trying to get her fixed up on blind dates in the hope that she’ll find that special someone.
The only trouble is that not many of  her dates are punctual—or indeed turn up.
Julie hates waiting alone for her date to arrive, so she’s made herself  a rule: if  her date hasn’t turned up after 20 minutes, then she leaves.
Here’s a sketch of  the frequency showing the amount of  time Julie spends waiting for her date to arrive:
We need to find probabilities for the amount of time Julie spends waiting for her date.
Is the amount of time discrete or continuous? Why? How do you think we can go about finding probabilities?
Statsville men on blind dates aren’t punctual; they could arrive at any time.
We need to find the probability that Julie will have to wait for more than 5 minutes for her date to turn up.
The trouble is, the amount of  time Julie has to wait is continuous data, which means the probability distributions we’ve learned thus far don’t apply.
When we were dealing with discrete data, we were able to produce a specific probability distribution.
We could do this by either showing the probability of each value in a table, or by specifying whether it followed a defined probability distribution, such as the binomial or Poisson distribution.
By doing this, we were able to specify the probability of  each possible value.
As an example, when we found the probability distribution for the winnings per game for one of  Fat Dan’s slot machines, we knew all of  the possible values for the winnings and could calculate the probability of  each one..
We can no longer give the probability of  each value because it’s impossible to say what each of  these precise values is.
Instead, we need to focus on a particular level of  accuracy and the probability of  getting a range of  values.
For discrete probability distributions, we look at the probability of getting a particular value; for continuous probability distributions, we look at the probability of getting a particular range.
We can describe the probability distribution of  a continuous random variable using a probability density function.
A probability density function f(x) is a function that you can use to find the probabilities of  a continuous variable across a range of  values.
It tells us what the shape of  the probability distribution is.
Here’s a sketch of  the probability density function for the amount of  time Julie spends waiting for her date to turn up:
Hello? I thought we were going to find some probabilities.
Can you see how it matches the shape of  the frequency? This isn’t just a coincidence.
Probability is all about how likely things are to happen, and the frequency tells you how often values occur.
The higher the relative frequency, the higher the probability of  that value occurring.
As the frequency for the amount of  time Julie has to wait is constant across the 20 minute period, this means that the probability density function is constant too.
Probability = area For continuous random variables, probabilities are given by area.
To find the probability of  getting a particular range of  values, we start off  by sketching the probability density function.
The probability of  getting a particular range of  values is given by the area under the line between those values.
The total area under the line must be equal to 1, as the total area represents the total probability.
This is because for any probability distribution, the total probability must be equal to 1, and, therefore, the area must be too.
Let’s use this to help us find the probability that Julie will need to wait for over 5 minutes for her date to arrive.
Before we can find probabilities for Julie, we need to find f(x), the probability density function.
If  we can find the height of  the rectangle, we’ll have the value of  f(x)
We find the area of  a rectangle by multiplying its width and height together.
Do I have to use area to find probability?  Can’t I just pick all the exact values in that range and add their probabilities together? That’s what we did for discrete probabilities.
For continuous probabilities, we have to find the probability by calculating the area under the probability density line.
We can’t add together the probability of  getting each value within the range as there are an infinite number of  values.
The only way we can find the probability for continuous probability distributions is to work out the area underneath the curve formed by the probability density function.
When dealing with continuous data, you calculate probabilities for a range of values.
Q: So there’s a function called the probability density function.
A: Probability density tells you how high probabilities are across ranges, and it’s described by the probability density function.
Probability density uses area to tell you about probabilities, and frequency density uses area to tell you about frequencies.
Q: So aren’t probability density and probability the same thing?
A: Probability density gives you a means of finding probability, but it’s not the probability itself.
The probability density function is the line on the graph, and the probability is given by the area underneath it for a specific range of values.
Q: I see, so if you have a chart showing a probability density function, you find the probability by looking at area, instead of reading it directly off the chart.
For continuous data, you need to find probability by calculating area.
Reading probabilities directly off a chart only works for discrete probabilities.
Q: Doesn’t finding the probability get complicated if you have to calculate areas?  I mean, what if the probability density function is a curve and not a straight line?
A: It’s still possible to do it, but you need to use calculus, which is why we’re not expecting you to do that in this book.
The key thing is that you see where the probabilities come from and how to interpret them.
If you’re really interested in working out probabilities using calculus, by all means, give it a go.
How do I find the probability of a precise value?
A: When you’re dealing with continuous data, you’re really talking about acceptable degrees of accuracy, and you form a range based on these values.
Let’s look at an example: Suppose you wanted a piece of string that’s 10 inches long to the nearest inch.
It would be tempting to say that you need a piece of string that’s exactly 10 inches long, but that’s not entirely accurate.
Q: But what if I want to find the probability of a precise single value?
What you’re really talking about is the probability that you have a precise value to an infinite number of decimal places.
The probability of the string being precisely 10 inches long is virtually impossible.
Q: But I’m sure that degree of accuracy isn’t needed.
Surely it would be enough to measure it to the nearest hundredth of an inch?
A: Ah, but that brings us back to the degree of accuracy you need in order for the length to pass as 10 inches, rather than finding the probability of a value to an infinite degree of precision.
You use your degree of accuracy to construct your range of acceptable measurements so that you can work out the probability.
The area of a triangle is 1/2 the base multiplied by the height.
Continuous data covers a range, where any value within that range is possible.
It’s frequently data that is measured in some way, rather than counted.
Continuous probability distributions can be described with a probability density function.
You find the probability for a range of values by calculating the area under the probability density function between those values.
We’ve found the probability So far, we’ve looked at how you can use probability density functions to find probabilities for continuous data.
That’s great, at least now I have an idea of how long I’ll be waiting.
Searching for a soul mate As well as preferring men who are punctual, Julie has preconceived ideas about what the love of  her like should be like.
I need a man who’ll be taller than me when I wear my highest heels.
Julie loves wearing high-heeled shoes, and the higher the heel, the happier she is.
The only problem is that she insists that her dates should be taller than her when she’s wearing her most extreme set of heels, and she’s running out of  suitable men.
Unfortunately, the last couple of  times Julie was sent on a blind date, the guys fell short of  her expectations.
She’s wondering how many men out there are taller than her and what the probability is that her dates will be tall enough for her high standards.
So how can we work out the probability this time?
Male modelling So far we’ve looked at very simple continuous distributions, but it’s unlikely these will model the heights of  the men Julie might be dating.
It’s likely we’ll have several men who are quite a bit shorter than average, a few really tall ones, and a lot of  men somewhere in between.
We can expect most of  the men to be average height.
There’ll be a few men who are much shorter than the average.
Given this pattern, the probability density of  the height of  the men is likely to look something like this.
There are fewer shorter guys, so the probability density is low.
There’ll be a smaller number of tall guys.This shape of  distribution is actually fairly common and can be applied to lots of  situations.
The normal distribution is called normal because it’s seen as an ideal.
It’s what you’d “normally” expect to see in real life for a lot of  continuous data such as measurements.
The normal distribution is in the shape of  a bell curve.
The curve is symmetrical, with the highest probability density in the center of  the curve.
The probability density decreases the further away you get from the mean.
Both the mean and median are at the center and have the highest probability density.
The greatest probability density is around the mean, so values around here are most likely.
The normal distribution is an “ideal” model for continuous data.
As with any other continuous probability distribution, you find probabilities by calculating the area under the curve of  the distribution.
The curve gives the probability density, and the probability is given by the area between particular ranges.
If, for instance, you wanted to find the probability that a variable X lies between a and b, you’d need to find the area under the curve between points a and b.
Another way of  looking at this is that events become more and more unlikely to occur, but there’s always a tiny chance they might.
Sound complicated? Don’t worry, it’s easier than you might think.
Working out the area under the normal curve would be difficult if  you had to do it all by yourself, but fortunately you have a helping hand in the form of probability tables.
All you need to do is work out the range of  the area you want to find, and then look up the corresponding probability in the table.
The shaded area gives the probability between that X is between a and b.
There are a few  steps you need to take in order to find normal probabilities.
We’ll guide you through the process, but for now here’s a roadmap of  where we’re headed.
Once you’ve transformed your normal curve, you can look up probabilities using handy probability tables.
Step 1: Determine your distribution The first thing we need to do is determine the distribution of  the data.
Julie has been given the mean and standard deviation of  the heights of  eligible men in Statsville.
We also need to know which range of  values will give us the right probability area.
In this case, we need to find the probability that Julie’s blind date will be sufficiently tall.
Julie wants her date to be taller than her, so we can work out probabilities based on her height.
Julie is 64 inches tall, so we’ll find the probability that her date is taller.
Is that your idea of fun? Why would I want to do that?
How do you think we might be able to standardize our normal distribution?
To do this, we “squash” our distribution by dividing by the standard deviation.
In general, you can find the standard score for any normal variable X using.
The mean of X X is the variable we’re trying to find probabilities for.
In our situation, we want to find the probability that Julie’s date is taller than her.
Now that we have this, we can move onto the final step, using tables to look up the probability.
Now find Z for the specific value you want to find probability for.
We’ll give you a distribution and value, and you have to tell us what the standard score is.
Q: Is this the same standard score that we saw before? A: Yes it is.
It has more uses than just the normal distribution, but it’s particularly useful here as it allows us to use standard normal probability tables.
Q: Is the probability for my standardized range really the same as for my original distribution? How does that work?
A: The probabilities work out the same, but using the probability tables is a lot more convenient.
When we standardize our original normal distribution, everything keeps the same proportion.
The overall area doesn’t grow or shrink, and as it’s area that gives the probability, the probability stays the same too.
We’ll give you a distribution and value, and you have to tell us what the standard score is.
We’re given the standard score, and we have to find the original value.
We can do this by substituting in the values we know, and finding x.
So we’ve found our distribution, standardized it, and found Z.
Now can we find the probability of my blind date being taller than me?
Now that we have a standard score, we can use probability tables to find our probability.
Standard normal probability tables allow you to look up any value z, and then read off  the corresponding probability P(Z < z)
So how do you use probability tables? Start off  by calculating z to 2 decimal places.
This is the value that you will need to look up in the table.
To look up the probability, you need to use the first column and the top row to find your value of  z.
The first column gives the value of  z to 1 decimal place (without rounding), and the top row gives the second decimal place.
Here’s the row for z = -3.2x, where x is some number.
Here’s the column for .07, the second decimal place for z.
Step 3: Look up the probability in your handy table.
We’ve put all the probability tables you need in Appendix ii of  the book.
Just flip to pages 658-659 for the normal distribution tables you need to find probabilities in this chapter.
Julie’s probability is in the table Let’s go back to our problem with Julie.
So, looking up the value of  –1.56 in the probability table gives us a probability of.
In other words, the probability that Julie’s date is taller than her is 0.9406
You can find normal probability tables in the appendix at the back of the book.
Here’s the row for z = -1.5x, where x is some number.
Here’s the column for .06, the second decimal place for z.
There’s a 94% chance my date will be taller than me? I like those.
Probability tables allow you to look up the probability P(Z < z) where z is some value.
The problem is you don’t always want to find this sort of  probability; sometimes you want to find the probability that a continuous random variable is greater than z, or between two values.
How can you use probability tables to find the probability you need?
The big trick is to find a way of  using the probability tables to get to what you want, usually by finding a whole area and then subtracting what you don’t need.
In other words, take the area where Z < z away from the total probability.
A: Another name for the normal distribution is the Gaussian distribution.
If you hear someone talking about a Gaussian distribution, they’re talking about the same thing as the normal distribution.
A: All normal probability tables give the same probabilities for your values.
However, there’s some variation between tables as to what’s actually covered by them.
Q: Variation? What do you mean? A: Some tables and exam boards use different degrees of accuracy in their probability tables.
Also, some show the tables in a slightly different format, but still give the same information.
Q: So what should I do if I’m taking a statistics exam?
A: First of all, check what format of probability table will be available to you while you’re sitting the exam.
Once you have a copy of the probability tables used by your exam board, spend time getting used to using them.
That way you’ll be off to a flying start when the exam comes around.
Q: Finding the probability of a range looks kinda tricky.
A: The big thing here is to think about how you can get the area you want using the probability tables.
Probability tables generally only give probabilities in the form P(Z < z) where z is some value.
The big trick, then, is to rewrite your probability only in these terms.
Once you have these probabilities, subtract the smallest from the largest.
Q: Do continuous distributions have a mode? Can you find the mode of the normal distribution?
Q: What’s a standard score? A: The standard score of a variable is what you get if you subtract its mean and divide by its standard deviation.
Standard scores are useful when you’re dealing with the normal distribution because it means you can look up the probability of a range using standard normal probability tables.
The standard score of a particular value also describes how many standard deviations away from the mean the value is, which gives you an idea of its relative proximity to the mean.
It’s time to put your probability table skills to the test.
It’s time to put your probability table skills to the challenge.
We can find this probability by looking up 1.42 in the probability tables.
We’re given the probability, and need to find the value of z.
When we calculated the probability of her date being taller than her, we failed to take her high heels into account.
See if you can find the probability of Julie’s date being taller than her while she’s wearing shoes with 5 inch heels.
Wait a sec, if I wear my 5-inch heels, I’m much taller.
Won’t that affect the probability that my date is taller than me?
When we calculated the probability of her date being taller than her, we failed to take her high heels into account.
See if you can find the probability of Julie’s date being taller than her while she’s wearing shoes with 5 inch heels.
So, I can wear my highest heels, and there’s still a 67% chance he’ll be taller? Sweet!
He needs to give his boss the mean and standard deviation of  the number of  minutes people take to complete level one of  their new game.
This shouldn’t be difficult, but unfortunately a ferocious terrier has eaten the piece of paper he wrote them on.
First of  all, Will knows that the number of  minutes people spend playing level one follows a normal distribution.
Will can use probability tables and standard scores to get expressions for the mean and standard deviation that he can then solve.
If  we put this into the standard score formula, we get.
If  we subtract the first equation from the second, we get.
If  we then substitute this into the second equation, we get.
This is a pair of equations we can now solve.
And they all lived happily ever after Just as the odds predicted, Julie’s latest blind date was a success! Julie had to make sure her intended soulmate was compatible with her shoes, so she made sure she wore her highest heels to put him to the test.
What’s more, he was already at the venue when she arrived, so she didn’t have to wait around.
The first thing he said to me was how much he liked my shoes.
We’re not entirely sure whether she’s referring to her date or her shoes, but at least she’s happy.But it doesn’t stop there.
Keep reading and we’ll show you more things you can do with the normal distribution.
You’ve only just scratched the surface of  what you can do.
To find normal probabilities, start by identifying the probability range you need.
Then find the standard score for the limit of this range using.
You find normal probabilities by looking up your standard score in probability tables.
Probability tables give you the probability of getting this value or lower.
Life can be so much simpler with the normal distribution.
Life can be so much simpler with the normal distribution.
Love is a roller coaster The wedding market is big business nowadays, and Dexter has an idea for making that special day truly memorable.
Why get married on the ground when you can get married on a roller coaster?
Dexter’s convinced there’s a lot of  money to be made from his innovative Love Train ride, if  only it passes the health and safety regulations.
Before Dexter can go any further, he needs to make sure that his special ride can cope with the weight of the bride and groom, and he’s asked if you can help him.
The ride he has in mind can cope with combined weights of  up to 380 pounds.
What’s the probability that the combined weight will be less than this?
I need to make sure the combined weight of the bride and groom won’t be above 380 pounds.
All aboard the Love Train Before we start, we need to know how the weights of  brides and grooms in Statsville are distributed, taking into account the weight of  all their wedding clothes.
How do you think we can find the probability distribution for the combined weights of the bride and groom? What sort of distribution do you think this might be? Why?
We need to use these two probability distributions to somehow work out the probability that the weight of  a bride and groom will be less than the maximum weight allowance on the ride.
If  the probability is sufficiently high, we can be confident the ride is feasible.
We can calculate this probability if we know what the combined probability distribution is, but what’s that?
Normal bride + normal groom Let’s start by taking a closer look at how the weights of  the bride and groom are distriuted.
As you know, the weights follow normal distributions like this:
Most brides will have a weight around here And mo st grooms.
What we’re really after, though, is the probability distribution of  the combined weight of  the bride and groom.
In other words, we want to find the probability distribution of  the weight of  the bride added to the weight of  the groom.
Assuming the weights of  the bride and groom are independent, the shape of  the distribution should look something like this:
Can you remember the discrete shortcuts for the following formulas? Assume X and Y are independent.
It’s still just weight Can you remember when we first looked at continuous data and looked at how data such as height and weight tend to be distributed? We found that data such as height and weight are continuous, and they also tend to follow a normal distribution.
This time we’re looking at the combined weight of  the happy couple.
Even though it’s combined weight, it’s still just weight, and we already know how weight tends to be distributed.
In other words, the combined weight of  the bride and groom follows a normal distribution.
Knowing that the combined weight of  the bride and groom follows a normal distribution helps us a lot.
It means that we’ll be able to use probability tables just like we did before to look up probabilities, which means we’ll be able to look up the probability that the combined weight is less than 380 pounds—just what we need for the ride.
There’s only one problem—before we can go any further, we need to know the mean and variance of  the combined weight of  the bride and groom.
The combined weight of the bride and groom follows a norma.
Can you remember the discrete shortcuts for the following formulas? Assume X and Y are independent.
They’re for discrete data, and we’re dealing with continuous now.
When we originally encountered these shortcuts, we were dealing with discrete data.
Fortunately, the same rules and shortcuts also apply to continuous data.
Var(X + Y) = Var(X) + Var(Y) Remember that we ADD the variances, even though it’s for X - Y.
How do you think we can use these shortcuts to find the probability distribution of the weight of the bride + the weight of the groom?
How’s the combined weight distributed? So far, we’ve found that the combined weight of  the bride and groom are normally distributed, and this means we can use probability tables to look up the probability of  the combined weight being less than a certain amount.
In other words, before we go any further we need to find the mean and variance of X + Y.
Take a look at the answers to the last exercise.
When we were working with discrete probability distributions, we saw that as long as X and Y are independent we could work out E(X + Y) and Var(X + Y) by using.
So if  we know what the expectation and variance of  X and Y are, we can use these to work out the expectation and variance of  X + Y.
That means that if we know the distribution of X.
We can use what we already know to figure out what we don’t.
Because we know how the weight of  the bride and the weight of  the groom are distributed, we can find the distribution of  the combined weight of  the bride and groom.
Being able to find the distribution of  X + Y is useful if  you’re working with combinations of  normal variables.
If  independent random variables X and Y are normally distributed, then X + Y is normal too.
What’s more, you can use the mean and variance of  X and Y to calculate the distribution of  X + Y.
To find the mean and variance of  X + Y, you can use the same formulae that we used for discrete probability distributions.
In other words, the mean of  X + Y is equal to the mean of  X plus the mean of  Y, and the variance of  X + Y is equal to the variance of  X plus the variance of  Y.
What do you notice about the variance of X + Y?
The variance of  X + Y is greater than the variance of  X and also greater than the variance of  Y, which means that the curve of  X + Y is more elongated than either.
By adding the two variables together, you are in effect increasing the amount of  variability, and this elongates the shape of  the distribution.
Remember, two variables are independent if they have no im.
We can use these shortcuts if X and Y are independent, which makes life very easy indeed.
Sometimes X + Y just won’t give you the sorts of  probabilities you’re after.
If  you need to find probabilities involving the difference between two variables, you’ll need to use X - Y instead.
This is exactly the same criteria as for X + Y.
To find the mean and variance, we again use the same shortcuts that we used for discrete probability distributions.
In other words, the mean of  X – Y is equal to the mean of  Y subtracted from the mean of  X, and you find the variance of  X – Y by adding the X and Y variances together.
We ADD the variances together, just like we did for discrete probability distributions.
Adding the variances together may not make intuitive sense at first, but it’s exactly the same as when we worked with discrete probability distributions.
Even though we’re subtracting Y from X, we’re actually still increasing the amount of  variability.
As with the X + Y distribution, this leads to a flatter, more elongated shape than either X or Y.
If  you look at the actual shape of  the X - Y distribution, it’s the same shape curve as for X + Y distribution, except that the center has moved.
The two distributions have the same variances, but different means.
It’s the same shape as for X + Y but with the center of the curve in a different place.
They have the same shape because they have the same variance.
Q: Remind me, why did we need to find the distribution of X + Y?
A: We’re looking for the probability that the combined weight of a bride and groom will be less than 380 pounds, which means we need to know how the combined weight is distributed.
We’re using X to represent the weight of the bride, and Y to represent the weight of the groom, which means we need to use the distribution of X + Y.
Q: You say we can look up probabilities for X + Y using probability tables.
A: In exactly the same way as we did before.
We take our probability distribution, calculate the standard score, and then look this value up in probablity tables.
Looking up probabilities for X + Y is no different from looking up probabilities for anything else.
Just find the standard score, look it up, and that gives you your probability.
Q: So do all of the shortcuts we learned for discrete data apply to continuous data too?
This means we have an easy way of combining random variables and finding out how they’re distributed, which in turn means we can solve more complex problems.
The key thing to remember is that these shortcuts apply as long as the random variables are independent.
A: If two variables are independent, then their probabilities are not affected by each other.
In our case, we’re assuming that the weight of the bride is not influenced by the weight of the groom.
A: If X and Y aren’t independent, then we can’t use these shortcuts.
We’d need to do a lot more work to find out how X + Y is distributed because you’d have to find out what the relationship is between X and Y.
Finding probabilities Now that we know how to calculate the distribution of  X + Y, we can look at how to use it to calculate probabilities.
Sound familiar? These are exactly the same steps that we went through in the previous chapter for the normal distribution.
We know we need to us e X + Y, and.
Once we know the distribution and the range, we standardize it.
Find the probability that the combined weight of the bride and groom is less than 380 pounds using the following three steps.
With this information, find the probability distribution for the combined weight of the bride and groom.
Then, using this distribution, find the standard score of 380 pounds.
Find the probability that the combined weight of the bride and groom is less than 380 pounds using the following three steps.
With this information, find the probability distribution for the combined weight of the bride and groom.
We need to find the probability distribution of X + Y.
To find the mean and variance of X + Y, we add the means and variances of the X and Y distributions together.
Then, using this distribution, find the standard score of 380 pounds.
Let’s use X to represent the height of the men and Y to represent the height of the women.
We need to find the probability that a man is at least 5 inshes taller than a woman.
To find the mean and variance of X - Y, we take the mean of Y from the mean  of X, and add the variances together.
More people want the Love Train It looks like there’s a good chance that the combined weight of  the happy couple will be less than the maximum the ride can take.
But why restrict the ride to the bride and groom?
Let’s see what happens if  we add another car for four more members of the wedding party.
These could be parents, bridesmaids, or anyone else the bride and groom want along for the ride.
The car will hold a total weight of  800 pounds, and we’ll assume the weight of  an adult in pounds is distributed as.
But how can we work out the probability that the combined weight of  four adults will be less than 800 pounds?
Think back to the shortcuts you can use when you calculate expectation and variance.
What’s the difference between independent observations and linear transformations? What effect does each have on the expectation and variance? Which is more appropriate for this problem?
Customers are demanding that we allow more members of the wedding party to join the ride, and they’ll pay good money.
That’s great, but will the Love Train be able to handle.
Let’s start off  by looking at the probability distribution of  4X, where X is the weight of  one adult.
The distribution of  4X is actually a linear transform of  X.
This is exactly the same sort of  transform as we encountered earlier with discrete probability distributions.
Linear transforms describe underlying changes to the size of  the values in the probability distribution.
Rather than transforming the weight of  each adult, what we really need to figure out is the probability distribution for the combined weight of four separate adults.
In other words, we need to work out the probability distribution of  four independent observations of  X.
The weight of  each adult is an observation of  X, so this means that the weight of  each adult is described by the probability distribution of  X.
We need to find the probability distribution of  four independent observations of X, so this means we need to find the probability distribution of.
When we looked at the expectation and variance of  independent observations of discrete random variables, we found that.
Q: So what’s the difference between linear transforms and independent observations?
A: Linear transforms affect the underlying values in your probability distribution.
As an example, if you have a length of rope of a particular length, then applying a linear transform affects the length of the rope.
Independent observations have to do with the quantity of things you’re dealing with.
As an example, if you have n independent observations of a piece of rope, then you’re talking about n pieces of rope.
In general, if the quantity changes, you’re dealing with independent observations.
If the underlying values change, then you’re dealing with a transform.
Q: Do I really have to know which is which? What difference does it make?
A: You have to know which is which because it make a difference in your probability calculations.
You calculate the expectation for linear transforms and independent observations in the same way, but there’s a big difference in the way the variance is calculated.
If you have n independent observations then the variance is n times the original.
If you transform your probability distribution as aX + b, then your variance becomes a2 times the original.
Q: Can I have both independent observations and linear transforms in the same probability distribution?
To work out the probability distribution, just follow the basic rules for calculating expectation and variance.
You use the same rules for both discrete and continuous probability distributions.
We need to start by finding how the weight of 4 adults is distributed.
Looking this value up in standard normal probability tables gives us a value of 0.9452
We’ve got some more fiendishly difficult questions on tonight’s show.
We’ve got some more great questions lined up for you today, so let’s get on with the show.
In this round I’m going to ask you forty questions, and you need to get thirty or more right to get through to the next round.
Or you can walk away and take a consolation prize.
The title of this round is “Even More About Me.”
We’re not asking you to find the probability—just say how you’d go about finding it.
Should we play, or walk away? As before, it’s unlikely you’ll know the game show host well enough to answer questions about him.
It looks like you’ll need to give random answers to the questions again.
We’re not asking you to find the probability—just say how you’d go about finding it.
The outcome of each trial can be a success or failure, and we want to find the probability of getting a certain number of successes.
In order to do this, we need to use the binomial distribution.
We can find the mean and variance using n, p and q, where q = 1 - p.
The mean is equal to np, and the variance is equal to npq.
But doing all of those calculations is going to be horrible.
Using the binomial distribution can be a lot of work.
Each of these probabilities is tricky to find, and it would be very easy to make a mistake somewhere along the way.
What we really need is an easier way of  calculating binomial probabilities.
Wouldn't it be dreamy if there was a way of making other distributions as easy to work with as the normal? But I know it's just a fantasy…
Normal distribution to the rescue We’ve seen that life with the binomial distribution can be tough at times.
Some of the calculations can be tricky and repetitive, which in turn means that it’s easy to make mistakes and spend a lot of  time only to come up with the wrong answer.
In certain circumstances, you can use the normal distribution to approximate the binomial distribution.
You’re saying the normal distribution can approximate the binomial? I thought the Poisson did that.
The Poisson distribution can approximate the binomial in some situations, but the normal can in others.
Knowing how to approximate the binomial distribution with other distributions is useful because it can cut down on all sorts of  complexities, and in some situations the Poisson distribution can help us work out some tricky binomial probabilities.
In certain other circumstances, we can use the normal distribution to approximate the binomial instead.
There are some huge advantages with this, as it means that instead of  performing calculations, we can use normal probability tables to simply look up the probabilities we need.
All we need to do is figure out the circumstances under which this works.
It’s been a while since we looked at how we could use the Poisson distribution to approximate the binomial.
Out of all these distributions, this is the one that can best be approximated by the normal distribution.
Under certain circumstances, the shape of  the binomial distribution looks very similar to the normal distribution.
In these situations, we can use the normal distribution in place of  the binomial to give a close approximation of  its probabilities.
Instead of  calculating lots of  individual probabilities, we can look up whole ranges in standard normal probability tables.
Finding the mean and variance Before we can use normal probability tables to look up probabilities, we need to know what the mean and variance is so that we can calculate the standard score.
When we originally looked at the binomial distribution, we found that:
We can use these as parameters for our normal approximation.
If you’re taking a statistics exam, make sure you check the criteria used by your exam board.
Before we use the normal distribution for the full 40 questions for Who Wants To Win A Swivel Chair, let’s tackle a simpler problem to make sure it works.
Let’s start off by working this out using the binomial distribution.
Now let’s try using the normal approximation to the binomial and check that we get the same result.
Before we use the normal distribution for the full 40 questions for Who Wants To Win A Swivel Chair, let’s tackle a simpler problem to make sure it works.
Let’s start off by working this out using the binomial distribution.
What do you think could have gone wrong? How do you think we could fix it?
Did I miss something? In what way was that a good approximation?
The two methods of calculating the probability have given quite different results.
We should have been able to use the normal distribution in place of  the binomial, but the results aren’t close enough.
Now let’s try using the normal approximation to the binomial and check we get the same result.
Revisiting the normal approximation So what went wrong? Let’s take a closer look at the problem and see if  we can figure out what happened and also what we can do about it.
Take a really close look at the two probability distributions.
It’s tricky to spot, but there’s a crucial difference between the two—the ranges we used to calculate the two probabilities are slightly different.
We actually used a slightly larger range when we used the normal distribution, and this accounts for the larger probability.
We’ll look at this in more detail on the next page.
When we take integers from a discrete probability distribution and translate them onto a continuous scale, we don’t just look at those precise values in isolation.
Instead, we look at the range of  numbers that round to each of  the values.
There’s one thing we overlooked when we calculated the two probabilities—we didn’t make allowances for one distribution being discrete (the binomial), and the other being continuous (the normal)
This is important, as the probability range we use can make a big difference to the resulting probabilities.
We’ve highlighted where the probability range we used with the normal distribution extends beyond the range we used for the binomial distribution.
A continuity correction is the small adjustment that needs to be made when you translate discrete values onto a continuous scale.
Using the binomial distribution we found that the probability we’re aiming for is around 0.387
Let’s see how close an approximation the normal distribution gives us.
This is really close to the probability we came up with using the binomial distribution.
The binomial distribution gave us a probability of  0.387, so the normal distribution gives us a pretty close approximation.
In particular circumstances you can use the normal distribution to approximate the binomial.
If you’re approximating the binomial distribution with the normal distribution, then you need to apply a continuity correction to make sure your results are accurate.
They’re really close, so it looks like the continuity correction did the trick.
The big trick with using the normal distribution to approximate binomial probabilities is to make sure you apply the right continuity correction.
As you’ve seen, small changes in the probability range you choose can lead to significant errors in the actual probabilities.
This might not sound like too big a deal, but using the wrong probability could lead to you making the wrong decisions.
Let’s take a look at the kinds of  continuity corrections you need to make for different types of  probability problems.
Q: Does it really save time to approximate the binomial distribution with the normal?
Calculating binomial probabilities can be time-consuming because you generally have to work out the probability of lots of different values.
You have no way of simply calculating binomial probabilities over a range of values.
If you approximate the binomial distribution with the normal distribution, then it’s a lot quicker.
You can look probabilities up in standard tables and also deal with whole ranges at once.
Q: So is it really accurate? A:Yes, It’s accurate enough for most purposes.
The key thing to remember is that you need to apply a continuity correction.
If you don’t then your results will be less accurate.
Q: You can approximate the binomial distribution with both the normal and Poisson distributions.
Remember, you need to apply a continuity correction when you approximate the binomial distribution with the normal distribution.
Pool Puzzle Your job is to take snippets from the.
You may use the same snippet more than once, and you won’t need to.
Note: each thing from the pool can be used more than once!
Pool Puzzle Your job is to take snippets from the.
You may use the same snippet more than once, and you won’t need to.
Note: each thing from the pool can  be used more than once!
As np and nq are both greater than 5, it’s appropriate for us to use the normal distribution to approximate this probability.
If you lose, you’ll miss out on our great consolation prize.
It’s been great having you back as a contestant on the show, but we’ve just had an urgent email from someone called Dexter...
Head First: Hey, Normal, glad you could make it on the show.
Head First: Now, my first question is about your name.
Normal: It’s really because I’m so representative of  a lot of  types of  data.
They have a probability distribution that has a distinctive shape and a smooth, bell-curved shape, and that’s me.
Imagine you have a baker’s shop that sells loaves of  bread.
Now, each loaf  of  a particular sort of  bread should theoretically weigh about the same, but in practice, the actual weight of  each loaf of  bread will vary.
Head First: But surely they’ll all weigh about the same?
Normal: Well, it means that you can use me to work out probabilities.
Say you want to find the probability of  a randomly chosen loaf  of  bread being below a particular weight.
That sounds like something that could be quite difficult, but with me, it’s easy.
Normal: With a lot of  the other probability distributions, there can be lots of  complicated calculations involved.
With Binomial you have factorials, and with Poisson you have to work with exponentials.
Just look me up in a table and away you go.
Head First: Surely it’s not quite as simple as that?
Normal: Well, you do have to convert me to a standard score first, but that’s nothing, not in the grand scheme of  things.
Head First: So tell me, do you think you’re better than the other probability distributions?
Normal: I wouldn’t say that I’m better as such, but I’m a lot more flexible, and I’m useful in lots of  situations.
When the numbers get high for Poisson and Binomial distributions, they run into trouble.
Mind you, I do what I can to help out.
Normal: Well under certain circumstances both Binomial and Poisson look like me.
It’s uncanny; they’re often stopped at parties by people asking them if  they’re Normal.
Normal: Well, because they look like me, it means that you can actually use my probability tables to work out their probabilities.
How cool is that? No more late nights slaving over a calculator; just look it up.
Head First: I’m afraid that’s all we’ve got time for tonight.
All aboard the Love Train Remember Dexter’s Love Train? He’s started running trials of  the ride, and everyone who’s given it a trial run thinks it’s great.
There’s just one problem: sometimes the ride breaks down and causes delays, and delays cost money.
Dexter’s found some statistics on the Internet about the model of  roller coaster he’s been trying out, and according to one site, you can expect the ride to break down 40 times a year.
Given the huge profit the Love Train is bound to make, Dexter thinks that it’s still worth going ahead with the ride if  there’s a high probability of  it breaking down less than 52 times a year.
What sort of probability distribution does this follow? How would you work out the probability of the ride breaking down less than 52 times in a year?
What sort of probability distribution does this follow? How would you work out the probability of the ride breaking down less than 52 times in a year?
Situations where you’re dealing with things breaking down at a mean rate follow a Poisson distribution, taking a parameter of the mean.
Working out that probability is gonna be tricky and timeconsuming.
I wonder if we can take a shortcut like we did with the binomial.
Under certain circumstances, the shape of the Poisson distribution resembles that of the normal.
The advantage of  this is we can use standard normal probability tables to work out whole ranges of  probabilities.
This means that we don’t have to calculate lots of  individual probabilities in order to find what we need.
Approximating the Poisson distribution with the normal is very similar to when you use the normal in place of  the binomial.
Once you have the right set of  circumstances, you take the Poisson mean and variance, and use them as parameters in a normal distribution.
It all comes down to the shape of  the distribution.
We can use the normal distribution to approximate the Poisson whenever the Poisson distribution adopts a shape that’s like the normal, but when does this happen? Let’s take a look.
Hint: Use a normal approximation, and remember your continuity corrections.
Complete the table below, saying what normal distribution suits each situation, and what conditions there are.
Complete the table below, saying what normal distribution suits each situation, and what conditions there are.
Q: You can approximate the binomial and Poisson distributions with the normal, but what about the geometric disribution? Can the normal distribution ever approximate that?
A: We were able to use the normal distribution in place of the binomial and Poisson distributions because under particular circumstances, these distributions adopt the same shape as the normal.
The geometric distribution, on the other hand, never looks like the normal, so the normal can never effectively approximate it.
Q: Do I have to use a continuity correction if I approximate the Poisson distribution with the normal distribution?
This is because you’re approximating a discrete probability distribution with a continuous one.
This means that you need to apply a continuity correction, just as you would for the binomial distribution.
Q: What’s the advantage of approximating the binomial or poisson distribution with the normal? Won’t my results be more accurate if I just use the original distribution?
A: Your results will be more accurate if you use the original distribution, but using them can be time consuming.
If you wanted to find the probability of a range of values using the binomial or poisson distribution, you’d need to find the probability of every single value within that range.
Using the normal distribution, on the other hand, you can look up probabilities for whole ranges, and so they’re a lot easier to find.
In particular circumstances you can use the normal distribution to approximate the Poisson.
If you’re approximating the Poisson distribution with the normal distribution, then you need to apply a continuity correction to make sure your results are accurate.
Use a continuity correction if you approximate the Poisson distribution with the normal distribution.
A runaway success! Thanks to your savvy statistical analysis,the Love Train is open for business, and demand has outstripped Dexter’s highest expectations.
Statistics deal with data, but where does it come from? Some of the time, data’s easy to collect, such as the ages of people attending a health.
In this chapter, we’ll take a look at how you.
Statistics deal with data, but where does it come from? Some of the time, data’s easy to collect, such as the ages of people attending a health.
In this chapter, we’ll take a look at how you.
Stay nice and relaxed, and this won’t hurt a bit.
The Mighty Gumball taste test Mighty Gumball is the leading vendor of  a wide variety of  candies and chocolates.
It comes in all sorts of  colors to suit all tastes.
Mighty Gumball plans to run a series of  television commercials to attract even more customers, and as part of  this, they want to advertise just how long the flavor of  their gumballs lasts for.
They’ve decided to implement a taste test, and they’ve hired a bunch of  tasters to help with the tests.
There are just two problems: the tasters are using up all of  the gumballs, and their dental plans are costing the company a fortune.
They’re running out of gumballs The fatal flaw with the Mighty Gumball taste test is that the tasters are trying out all of  the gumballs.
Not only is this having a bad effect on the tasters’ teeth, it also means that there are no gumballs left to sell.
After all, they can hardly reuse their gumballs once the tasters have finished with them.
The whole point of  the taste test is for Mighty Gumball to figure out how long the flavor lasts for.
But does this really mean that the tasters have to try out every single gumball?
What would you do to establish how long the gumball flavor lasts for? What do you need to consider? Write your answer below in as much detail as possible.
Mighty Gumball is running into problems because they’re tasting every single gumball as part of  their taste test.
It’s costing them time, money, and teeth, and they have no gumballs left to actually sell to their customers.
So what should Mighty Gumball do differently? Let’s start by looking at the difference between populations and samples.
Gumball samples You don’t have to taste every gumball to get an idea of  how long the flavor lasts for.
Instead of  testing the entire population, you can test a sample instead.
A statistical sample is a selection of  items taken from a population.
You choose your sample so that it’s fairly representative of  the population as a whole; it’s a representative subset of  the population.
For Mighty Gumball, a sample of  gumballs means just a small selection of  gumballs rather than every single one of  them.
A study or survey involving just a sample of  the population is called a sample survey.
A lot of  the time, conducting a survey is more practical than a census.
It’s usually less time-consuming and expensive, as you don’t have to deal with the entire population.
And because you don’t use the whole population, taking a sample survey of  the gumballs means that there’ll be plenty left over when you’re done.
Gumball populations At the moment, Mighty Gumball is carrying out their taste test using every single gumball that they have available.
In statistical terms, they are conducting their test using an entire population.
A statistical population refers to the entire group of  things that you’re trying to measure, study, or analyze.
It can refer to anything from humans to scores to gumballs.
The key thing is that a population refers to all of  them.
A census is a study or survey involving the entire population, so in the case of  Mighty Gumball, they’re conducting a census of  their gumball population by tasting every single one of  them.
A census can provide you with accurate information about your population, but it’s not always practical.
When populations are large or infinite, it’s just not possible to include every member.
So how can you use samples to find out about a population? Let’s see.
A sample is a subset of the population, so just some of the gumballs.
How sampling works The key to creating a good sample is to choose one that is as close a match to your population as possible.
If  your sample is representative, this means it has similar characteristics to the population.
And this, in turn, means that you can use your sample to predict what characteristics the population will have.
Suppose you use a representative sample of  gumballs to test how long the flavor of each gumball lasts for.
The distribution of  the results might look something like this:
Can you see how closely the sample and population distributions agree?
If  you compare the two charts, the overall shape is very similar, even though one is for all of  the gumballs and the other is for just some of  them.
They share key characteristics such as where the center of  the data is, and this means you can use the sample data to make predictions about the population.
Even though you’ve only tried a small sample of gumballs, you still have an impression of  the shape of  the distribution, and the more gumballs you try, the clearer the shape is.
As an example, you can get a rough impression of  where the center of  the population distribution is by looking at the shape of the sample distribution.
So are you saying that all samples resemble their parent populations?
When sampling goes wrong If  only we could guarantee that every sample was a close match to the population it comes from.
This may not sound like a big deal, but using a misleading sample can actually lead you to draw the wrong conclusions about your population.
As an example, imagine if  you took a sample of  gumballs to find out how long flavor typically lasts for, but your sample only contained red gumballs.
Your sample might be representative of  red gumballs, but not so representative of all gumballs in the population.
If  you used the results of  this sample to gather information about the general gumball population, you could end up with a misleading impression about what gumballs are generally like.
Using the wrong sample could lead you to draw wrong conclusions about population parameters, such as the mean or standard deviation.
You might be left with a completely different view of  your data, and this could lead you to make the wrong decisions.
The trouble is, you might not know this at the time.
You might think your population is one thing when in fact it’s not.
We need to make sure we have some mechanism for making sure our samples are a reliable representation of  the population.
The Case of  the Lost Coffee Sales The Starbuzz CEO has an idea for a brand-new coffee he wants to sell in his coffee shops, but he’s not sure how popular it’s going to be with his customers.
He asks his new intern to conduct a survey to help predict the customers’ opinions.
The intern will ask customers to taste the new brew, and tell him what they think.
The intern is really happy to be given such a great opportunity.
First off, he’s been told that if  he does the job well, he stands to get a bonus at the end of  the month.
Secondly, he gets to give out free coffee to friendly Starbuzz customers and hear lots of positive things.
Thirdly, he’s been looking for an excuse to talk to.
After the intern conducts his survey, he’s delighted to tell the CEO that everyone loves the new coffee, and it’s bound to be a huge success.
When the new coffee is finally launched, sales are poor, and the CEO has to cancel the range.
How to design a sample You use samples to make inferences about the population in general, and to make sure you get accurate results, you need to choose your sample wisely.
Let’s start off  by pinning down what your population really is, so you can get as representative a sample as possible.
Define your sampling units Once you’ve defined your target population, you need to decide what sort of  object you’re going to sample.
Normally these will be the sorts of  things you described when you defined your target population.
As an example, this could be a single gumball or maybe a packet of  gumballs.
Define your target population The first thing to be clear about is what your target population is so that you know where you’re collecting your sample from.
By target population, we mean the group that you’re reseraching and want to collect results for.
The target population you choose depends, to a large extent, on the purpose of  your study.
For example, do you want to gather data about all the gumballs in the world, one particular brand, or one particular type?
Try to be as precise as possible, as that way it’s easier to make your sample as representative of  your population as possible.
We need data about Mighty Gumball’s super-long-lasting gumballs, so your target population is all of the gumballs.
The sampling unit in the taste test is a single Mighty Gumball super-long-lasting gumball.
Define your sampling frame Finally, you need a list of  all the sampling units within your target population, preferably with each sampling unit either named or numbered.
It’s basically a list from which you can choose your sample.
Sometimes it’s not possible to come up with a list that covers the entire target population.
As an example, if  you want to collect the views of  people living within a certain area, people moving in or out of  an area can affect who you have on your list of  names.
If  you’re dealing with similar objects such as gumballs, it might not be possible or practical to name or number each one.
Do I have to do all of these things? Can’t I just sample gumballs?
If you don’t design your sample well, your sample may not be accurate.
Designing your sample can take a bit of  extra preparation time, but this is much better than spending time and money on a survey only to find the results are inaccurate.
You will have lost time and money doing the survey, and what’s more, someone might make wrong decisions based on it.
Sometimes samples can be biased Not every sample is fair.
Unless you’re very careful, some sort of  bias can creep in to the sample, which can distort your results.
Bias is a sort of  favoritism that you can unwittingly (or maybe knowingly) introduce into your sample, meaning that your sample is no longer randomly selected from your population.
If  a sample is unbiased, then it’s representative of  the population.
It’s a fair reflection of  what the population is like.
Unbiased samples An unbiased sample is representative of the target population.
This means that it has similar characteristics to the population, and we can use these to make inferences about the population itself.
The shape of  the distribution of  an unbiased sample is similar to the shape of  the population it comes from.
If  we know the shape of  the sample distribution, we can use it to predict that of  the population to a reasonable level of  confidence.
Biased samples A biased sample is not representative of the target population.
We can’t use it to make inferences about the population because the sample and population have different characteristics.
If  we try to predict the shape of  the population distribution from that of the sample, we’d end up with the wrong result.
Sources of bias So how does bias creep into samples? Through any of  the following and more:
A sampling frame where items have been left off, such that not everything in the target population is included.
If  it’s not in your sampling frame, it won’t be in your sample.
Instead of  individual gumballs, maybe the sampling unit should have been boxes of  gumballs instead.
Individual sampling units you chose for your sample weren’t included in your actual sample.
As an example, you might send out a questionnaire that not everybody responds to.
Design your questions so that they’re neutral and everyone can answer them.
An example of  a biased question is “Mighty Gumball candy is tastier than any other brand, do you agree?” It would be better to ask the person being surveyed for the name of  their favorite brand of  confectionary.
As an example, if  you’re conducting a survey on the street, you may avoid questioning anyone that looks too busy to stop, or too aggressive.
This means that you exclude aggressive or busy-looking people from your survey.
How can I be certain I avoid bias? Where does it come from anyway?
As you can see, there are lots of sources of bias, and a lot of it comes down to how you choose your sample.
We need to take a look at ways in which you can choose your sample to minimize the chances of  introducing bias.
Q: So is the sampling frame a list of everything that we’re sampling?
A: The sampling frame lists all the individual units in the population, and it’s used as a basis for the sample.
It’s not the sample itself, as we don’t sample everything on it.
A: How you do it and what you use depends on your target population.
As an example, if your target population is all car owners, then you can use a list of registered car owners.
If your target population is all the students attending a particular college, you can use the college registrar.
Q: How about things like telephone listings? Can I use those for my sampling frame?
Telephone listings exclude households without a telephone, and there may also be households who have elected not to be listed.
If your target population is households with a listed telephone number, then using telephone lists is a good idea.
If your target population is all households with a telephone or even all telephones, then your sampling frame won’t be entirely accurate—and that can introduce bias.
Imagine if you had to survey all the fish in the sea.
It would be impossible to name and number every individual fish.
Q: Will I always have to have a target population?
You need to know what your target population is so that you can make sure your sample is representative of it.
Thinking carefully about what your target population is can help you avoid bias.
If you’re sampling for someone else, get as much detail as possible about who the target population should be.
Make sure you know exactly what is included and what is excluded.
Q: Why is bias so bad? A: Bias is bad because it can mislead you into drawing wrong conclusions about your target population, which in turn can lead you into making wrong decisions.
If, for example, you only sampled pink gumballs, your survey results might be accurate for all pink gumballs, but not for all gumballs in general.
There may be significant differences between the different color gumballs.
Q: How can the questions in a questionnaire cause bias?
A: Bias often creeps in through the phrasing of questions.
First off, if you present a series of statements and ask respondents to agree or disagree, it’s more likely that people will agree unless they have strong negative feelings.
This means that the results of your survey will be biased towards people agreeing.
Bias can also occur if you give a set of possible answers that don’t cover all eventualities.
As an example, imagine you need to ask people how often they exercise in a typical week.
This would mean that they wouldn’t be able to answer the question.
What would you choose as a target population? What’s the sampling unit? How would you develop a sampling frame? What other things might you need to consider when forming your sample?
The Statsville Health Club wants to conduct a survey to see what their customers think of their facilities.
What would you choose as a target population? What’s the sampling unit? How would you develop a sampling frame? What other things might you need to consider when forming your sample?
The Statsville Health Club wants to conduct a survey to see what their customers think of their facilities.
The target population is all the chocolates in the limited edition run.
The sampling frame needs to cover all of the chocolates;  as it’s a limited-edition run, it’s possible that Choc-O-Holic has records of how many chocolates are in the run, including numbers of each type of chocolate.
When forming the sample, you need to make sure that it is representative of the target population and unbiased.
If there are different types of chocolate in the run, you’d need to make sure that you included each sort of chocolate.
The target population is all the customers of the Statsville Health Club.
The sampling frame needs to cover all of the customers.
It’s likely that the health club has a list of registered customers, so you could use this as the sampling frame.
As before, you need to make sure that your sample is representative of the population and unbiased.
You’d need to make sure that each of the classes is fairly represented by customer gender, customer age group, and so on.
We don’t know for certain, but there’s a very good chance that the sample of  people surveyed by the intern wasn’t representative of  the target population.
First of  all, the intern was looking forward to giving away free coffee to friendly Starbuzz customers and hearing positive things.
Does this mean he only spoke to customers who looked friendly to him? Did he get their real opinions about the coffee, or did he only ask them whether they agreed it tasted nice?
The intern also hoped to use the job as an opportunity to speak to a girl at his local coffee shop.
Did he spend most of  his time in this particular coffee shop? Did the girl influence his sample choice?
Finally, the CEO launched the new coffee in a different season from the one in which the survey took place, and this may have affected sales too.
Any or all of  these factors could have lead to the sample being misleading, which in turn led to the wrong decision being made.
How to choose your sample We’ve looked at how to design your sample and explored types of  bias that need to be avoided.
Now we need to select our actual sample from the sample frame.
Simple random sampling One option is to choose the sample at random.
Imagine you have a population of  N sampling units, and you need to pick a sample of  n sampling units.
Simple random sampling is where you choose a sample of  n using some random process, and all possible samples of  size n are equally likely to be selected.
Sampling without replacement Sampling without replacement means that the sampling unit isn’t replaced back into the population.
An example of  this is the gumball taste test; you wouldn’t want to put gumballs that have been tasted back into the population.
Sampling with replacement Sampling with replacement means that when you’ve selected each unit and recorded relevant information about it, you put it back into the population.
By doing this, there’s a chance that a sampling unit might be chosen more than once.
You’d be sampling with replacement if  you decided to question people on the street at random without checking if  you had already questioned them before.
If  you stop a person for questioning and then let them go once you’ve finished asking them questions, you are in effect releasing them back into the population.
It means that you may question them more than once.
You wouldn’t want to replace gumballs once you’ve tasted them.
How to choose a simple random sample There are two main ways of  using simple random sampling: by drawing lots or using random numbers.
Drawing lots Drawing lots is just like pulling names out of  a hat.
You write the name or number of  each member of  the sampling frame on a piece of  paper or ball, and then place them all into a container.
You then draw out n names or numbers at random so that you have enough for your sample.
Random number generators If  you have a large sampling frame, drawing lots might not be practical, so an alternative is to use a random number generator, or random number tables.
For this, you give each member of  the sampling frame a number, generate a set of  n random numbers, and then pick the members of  the set whose assigned numbers correspond to the random numbers that were generated.
It’s important to make sure that each number has an equal chance of  occuring so that there’s no bias.
There are other types of sampling Even simple random sampling has its problems.
With simple random sampling, there’s still a chance that your sample will not represent the target population.
For example, you might end up randomly drawing only yellow gumballs for your sample, and the other colors would be left out.
With this type of sampling, the population is split into similar groups that share similar characteristics.
These charateristics or groups are called strata, and each individual group is called a stratum.
As an example, we could split up the gumballs into the different colors, yellow, green, red, and pink, so that each color forms a different stratum.
Once you’ve done this, you can perform simple random sampling on each stratum to ensure that each group is represented in your overall sample.
To do this, look at the proportions of  each stratum within the overall population and take a proportionate number from each.
As an example, if  50% of  the gumballs that Mighty Gumball produce are red, half  of  your sample should consist of  red gumballs.
Cluster sampling is useful if  the population has a number of  similar groups or clusters.
As an example, gumballs might be sold in packets, with each packet containing a similar number of  gumballs with similar colors.
With cluster sampling, instead of  taking a simple random sample of units, you draw a simple random sample of  clusters, and then survey everything within each of  these clusters.
As an example, you could take a simple random sample of  packets of  gumballs, and then taste all the gumballs in these packets.
Cluster sampling works because each cluster is similar to the others, and an added advantage is that you don’t need a sampling frame of the whole population in order to achieve it.
As an example, if  you were surveying trees and used particular forests as your cluster, you would only need to know about each tree within only the forests you’d selected.
The problem with cluster sampling is that it might not be entirely random.
As an example, it’s likely that all of  the gumballs in a packet will have been produced by the same factory.
If  there are differences between the factories, you may not pick these up.
As an example, you could choose to sample every 10th gumball.
Systematic sampling is relatively quick and easy, but there’s one key disadvantage.
If  there’s some sort of  cyclic pattern in the population, your sample will be biased.
As an example, if  gumballs are produced such that every 10th gumball is red, you will end up only sampling red gumballs, and this could lead to you drawing misleading conclusions about your population.
You can pick every 10th gumball to get a systematic sample.
Q: Does using one of these methods of sampling guarantee that the sample won’t be biased?
A: They don’t guarantee that the sample won’t be biased, but they do minimize the chances of this happening.
By really thinking about your target population and how you can make your sample representative of it, you stand a much better chance of coming up with an unbiased, representative sample.
Q: Do I have to use any of these methods? Can’t I just choose items at random.
Yes, this is one approach you can take, but one thing to be aware of is that there is a chance your sample will not be representative of the population at large.
Q: But why? Surely if I choose items at random, then my sample is bound to be representative of the target population.
You see, if you choose sampling units at random, then there’s a chance that purely at random, you could choose a sample that doesn’t effectively represent the target population.
As an example, if you choose customers of the Statsville Health Club completely at random, there’s a chance that you might choose only attendees of one particular class, or of one particular gender.
There might also be a case where you think you’re sampling at random, when really you’re not.
As an example, if you conduct a survey to find out customer satisfaction, but leave it up to customers whether or not they respond, you may well end up with a biased sample as customers have to be sufficiently motivated to respond.
The customers who are most motivated to take part in the survey will be those who are either strongly satisfied or strongly dissatisfied.
You are less likely to hear from those customers without strong feelings, yet those people may make up the bulk of the population.
Q: How about if I just increase the size of my sample? Will that get around bias?
A: The larger your sample, the less chance there is of your sample being biased, and this is one way of minimizing the chances of getting a biased sample using simple random sampling.
The trouble is, the larger your sample, the more cumbersome and time-consuming it can be to gather data.
Q: What’s the difference between stratified sampling and clustered sampling?
A: With stratified sampling, you divide the population into different groups or strata, where all the units within a stratum are as similar to each other as possible.
In other words, you take some characteristic or property such as gender, and use this as the basis for the strata.
Once you’ve split the population into strata, you perform simple random sampling on each stratum.
With clustered sampling, your aim is to divide the population into clusters, trying to make the clusters as alike as possible.
You then use simple random sampling to choose clusters, and then sample everything in those clusters.
So with stratified sampling, you make each stratum as different as possible, and with clustered sampling, you make each cluster as similar as possible.
A: With systematic sampling, you choose a number, k, and then choose every kth item for your sample.
This way of sampling is fairly quick and easy, but it doesn’t mean that your sample will be representative of the population.
In fact, this sort of sampling can only be used effectively if there are no repetitive patterns or organization in the sampling frame.
A: It’s not as common as it used to be, but it’s still a way of sampling.
How could you apply simple random sampling to this problem?
You’ve been given 10 boxes of chocolates and been asked to sample the chocolates in them.
There are whilte, milk, and dark chocolates in the boxes.
Your target population is all of the chocolates, and the sampling unit is one chocolate.
How could you apply simple random sampling to this problem?
You’ve been given 10 boxes of chocolates and been asked to sample the chocolates in them.
There are whilte, milk, and dark chocolates in the boxes.
Your target population is all of the chocolates, and the sampling unit is one chocolate.
You could apply simple random sampling by choosing chocolates at random, either through drawing lots or using random numbers.
That way, each chocolate stands an equal chance of being sampled.
For stratified smpling, you divide the chocolates into strata and apply simple random sampling to each one.
Each strata comprises of a group of chocolates with similar characteristics, so you could use the different types of chocolate.
One stratum could be white chocolates, another one could be milk chocolates, and the final one could be dark chocolates.
For cluster sampling, you divide the chocolates into groups, but this time each group needs to be similar.
Assuming each box of chocolates is similar, you could take one of the boxes, and sample all of the chocolates in it.
How would you go about conducting a sample survey of Mighty Gumball’s super-long-lasting gumballs? The gumballs come in four different colors, and they’re all made in the same factory.
How would you go about conducting a sample survey of Mighty Gumball’s super-long-lasting gumballs? The gumballs come in four different colors, and they’re all made in the same factory.
A population is the entire collection of things you are studying.
A sample is a relatively small selection taken from the population that you can use to draw conclusions about the population itself.
To take a sample, start off by defining your target population, the population you want to study.
Then decide on your sampling units, the sorts of things you need to sample.
Once you’ve done that, draw up a sampling frame, a list of all the sampling units in your target population.
A sample is biased if it isn’t representative of your target population.
Simple random sampling is where you choose sampling units at random to form your sample.
You can perform simple random sampling by drawing lots or using random number generators.
Stratified sampling is where you divide the population into groups of similar units or strata.
Each stratum is as different from the others as possible.
Once you’ve done this, you perform simple random sampling within each stratum.
Cluster sampling is where you divide the population into clusters where each cluster is as similar to the others as possible.
You use simple random sampling to choose a selection of clusters.
Systematic sampling is where you choose a number, k, and sample every kth unit.
The target population is all of Mighty Gumball’s super-long-lasting gumballs, and the sampling unit is an individual gumball.
For the sampling frame, we ideally need some sort of numbered list of the gumballs, but it’s likely that this isn’t practical.
Instead, we’ll settle for a list showing how many gumballs there are in the population for each color.
The type of sampling you use is subjective, but we’d choose to use stratified sampling, as this may be the best way of coming up with an unbiased sample.
We’d divide the gumballs into their different colors and then use simple random sampling to choose a proportionate number of each of the four colors.
The key thing is to think through how you can best make your survey representative of the population, and you may have different ideas.
Mighty Gumball has a sample With your help, Mighty Gumball has gathered a sample of  their super-long-lasting gumballs.
This means that rather than perform taste tests on the entire gumball population, they can use their sample instead.
That’s great! It means we’ll save time, money, and teeth.
So what’s next? We’ve looked at how we can put together a representative sample, but what we haven’t looked at is how we can use it.
We know that an unbiased sample shares the same characteristics as its parent population, but what’s the best way of  analyzing this?
Keep reading, and we’ll show you how in the next chapter.
Wouldn’t it be great if  you could tell what a population was like, just by taking one sample? Before you can claim full sample mastery, you need to know how to use your samples.
In this chapter, we’ll show you how knowing your sample helps you get to.
So how long does flavor really last for? With your help, Mighty Gumball has pulled together an unbiased sample of  super-long-lasting gumballs.
They’ve tested each of  the gumballs in the sample and collected lots of  data about how long gumball flavor within the sample lasts.
I don’t care how long flavor lasts in the sample.
What I do care about is flavor duration in the population.
That way, I can say how much longer our gumballs last than the competing brand.
To satisfy the CEO, we’re going to need to find both the mean and the variance of  flavor duration in the whole Mighty Gumball population.
How do you think we can use it to tell us what the mean of  the population is?
How would you use this data to estimate the mean and variance of the population? How reliable do you think your estimate will be? Why?
So how can we use the results of  the sample taste test to tell us the mean amount of  time gumball flavor lasts for in the general gumball population?
We assume that the mean flavor duration of  the gumballs in the sample matches that of  the population.
In other words, we find the mean of  the sample and use it as the mean for the population too.
Here’s a sketch showing the distribution of  the sample, and what you’d expect the distribution of  the population to look like based on the sample.
You’d expect the distribution of  the population to be a similar shape to that of  the sample, so you can assume that the mean of  the sample and population have about the same value.
So are you saying that the mean of the sample.
We can’t say that they exactly match, but it’s the best estimate we can make.
Based on what we know, the mean of  the sample is the best estimate we can make for the mean of  the population.
It’s the most likely value for the population mean that we can come up with based on the information that we have.
The mean of  the sample is called a point estimator for the population mean.
In other words, it’s a calculation based on the sample data that provides a good estimate for the mean of  the population.
This time around we don’t know the exact value of  the population parameters.
Instead of  calculating them using the population, we estimate them using the sample data instead.
To do this, we use point estimators to come up with a best guess of  the population parameters.
A point estimator of  a population parameter is some function or calculation that can be used to estimate the value of  the population parameter.
As an example, the point estimator of  the population mean is the mean of  the sample, as we can use the sample mean to estimate the population mean.
The point estimator for the population mean looks like the mean itself, except it’s topped with a ^
Add together the numbers in the sample, and divide by how many there are.
It occurs to me that we have a symbol for the population mean and one for its point estimator.
We can use this to write a shorthand expression for the point estimator for the population.
Since we can estimate the population mean using the mean of  the sample, this means that.
Use the sample data to estimate the value of the population mean.
Use the sample data to estimate the value of the population mean.
There’s the mean of the population, the mean of the sample, and the point estimator for the population mean.
Q: Does the size of the sample matter? A: In general, the larger the size of your sample, the more accurate your point estimator is likely to be.
A point estimator is an estimate for the value of a population parameter, derived from sample data.
To find the mean of the sample, use the formula.
The point estimator for the population mean is found by calculating x.
This means that if you want a good estimate for the true value of the population mean, you can use the mean of the sample.
This looks great! We can use your work in our television commercials to say how long gumball flavor lasts for, and it beats our main rival, hands down.
Just one question: how much variation do you expect there to be?
You’ve come up with a good estimate for the population mean, but what about the variance? If  we can come up with a good estimate for the population variance, then the CEO will be able to tell how much variation in flavor duration there’s likely to be in the gumball population, based on the results of  the sample data.
The variance of the data in the sample may not be the best way of estimating the population variance.
You already know that the variance of  a set of  data measures the way in which values are dispersed from the mean.
When you choose a sample, you have a smaller number of  values than with the population, and since you have fewer values, there’s a good chance they’re more clustered around the mean than they would be in the population.
More extreme values are less likely to be in your sample, as there are generally fewer of them.
The variance of the sample is bound to be the same as that of the population.
We can use the sample variance to estimate the population variance.
Let’s estimate the population variance So far we’ve seen how we can use the sample mean to estimate the mean of  the population.
This means that we have a way of  estimating what the mean flavor duration is for the super-long-lasting gumball population.
To satisfy the Mighty Gumball CEO, we also need to come up with a good estimate for the population variance.
So what can we use as a point estimator for the population variance? In other words, how can we use the sample data to find 2?
So what would be a better estimate of  the population variance?
Population There are fewer values in the sample, so there’s.
The problem with using the sample variance to estimate that of  the population is that it tends to be slightly too low.
The sample variance tends to be slightly less than the variance of  the population, and the degree to which this holds depends on the number of  values in the sample.
If  the number in the sample is small, there’s likely to be a bigger difference between the sample and population variances than if  the size of  the sample is large.
What we need is a better way of  estimating the variance of  the population, some function of  the sample data that gives a slightly higher result than the variance of  all the values in the sample.
In other words, we take each item in the sample, subtract the sample mean, and then square the result.
This is just like finding the variance of the values in the sample, but dividing by n – 1 instead of  n.
So what is the estimator? Rather than take the variance of  all the data in the sample to estimate the population variance, there’s something else we can use instead.
If  the size of the sample is n, we can estimate the population variance using.
This formula is a closer match to the value of the population variance.
Dividing a set of  numbers by n – 1 gives a higher result than dividing by n, and this difference is most noticeable when n is fairly small.
This means that the formula is similar to the variance of  the sample data, but gives a slightly higher result.
The population variance tends to be higher than the variance of the data in the sample.
This means that this formula is a slightly better point estimator for the population variance.
Take each item in the sample, subtract the sample mean, square the result, then add the lot together.
Estimating the population variance If  you need to estimate the variance of  a population using sample data, use.
Instead of  calculating the variance of  an actual population of  n values, you have to estimate the variance of  the population, based on the sample of  data you have.
To make you estimate a bit more accurate, you divide by n - 1 instead of  n, as this gives a slightly higher result.
The formula for the population variance point estimator is usually written s2, so.
Sample meanPoint estimator for the population variance, based on your sample.
Population variance If  you want to find the exact variance of  a population and you have data for the whole population, use.
In this situation, you have all the data for your population.
You know what the mean is for your population, and you want to find the variance of  all of these values.
This is the calculation that you’ve seen throughout this book so far.
This is similar to using x to represent the sample mean.
Some books tell you to divide by n – 1 for a sample, and some tell you to divide by n.
This is because different books make different assumptions about what you’re using your sample for.
You only need to divide by n if you want to calculate the variance of that exact set of values.
If you’re taking a statistics exam, check the approach that your exam board takes.
The golden rule to remember is that dividing by n gives you the actual variance for the set of  data that you have.
If  you have a sample of  data from the population, then chances are you’ll want to use this to estimate the variance of the population.
Here’s a reminder of the data from the Mighty Gumball sample.
Here’s a reminder of the data from the Mighty Gumball sample.
Q: Why do I divide by n – 1 for the sample variance? Why can’t I divide by n?
A: You divide by n – 1 for a sample because most of the time, you use your sample data to estimate the variance of the population.
Dividing by n – 1 gives you a slightly more accurate result than dividing by n.
This is because the variance of values in the sample is likely to be slightly lower than the population variance.
It’s something that we’re going to touch upon at the end of the chapter, but hold onto that thought; it’s a good one.
Q: How do I remember which symbols are used for the population, and which are used for the sample?
A: In general, Greek letters are used for the population, and normal Roman letters are used for the mean and variance for the sample.
Q: Is there a point estimator for the standard deviation in the same way that there is for the variance? How do I find it?
A: If you need to estimate the standard deviation, start by calculating the estimator for the variance.
The estimator for the standard deviation is the square root of this.
Mighty Gumball has done more sampling The Mighty Gumball CEO is so inspired by the results of  the taste test that he’s asked for another sampling exercise that he can use for his television advertisements.
This time, the CEO wants to be able to say how popular Mighty Gumball’s candy is compared with that of  their main rival.
The Mighty Gumball staff  have asked a random sample of  people whether they prefer gumballs produced by Mighty Gumball or whether they prefer those of  their main rival.
They’re hoping they can use the results to predict what proportion of  the population is likely to prefer Mighty Gumball.
How would you find the proportion of people in the sample who prefer Mighty Gumball’s candy? What distribution do you think this follows? How do you think you could apply this to the population?
It’s a question of proportion For the latest Mighty Gumball sample, the thing the CEO is interested in is whether or not each person prefers Mighty Gumball confectionery to that of their chief  rival.
In other words, every person who prefers Mighty Gumball candy can be classified as a success.
So how do we use the sample data to predict the proportion of  successes in the population?
Predicting population proportion If  we use X to represent the number of  successes in the population, then X follows a binomial distribution with parameters n and p.
In the same way that our best estimate of  the population mean is the mean of  the sample, our best guess for the proportion of  successes in the population has to be the proportion of  successes in the sample.
This means that if  we can find the proportion of  people in the sample who prefer Mighty Gumball’s treats, we’ll have a good estimate for the proportion of  people who prefer Mighty Gumball in the general population.
We can find the proportion of  successes in the sample by taking the total number of  people who prefer Mighty Gumball, and then dividing by the total number of  people in the sample.
If  we use ps to represent the proportion of  successes in the sample, then we can estimate the proportion of successes in the population using.
In other words, we can use the proportion of  successes in the sample as a point estimator for the proportion of  successes in the population.
Therefore, the point estimator for the proportion of  successes in the population is also 0.8
Point estimator for the proportion of successes in the population.
Probability and proportion are related There’s actually a very close relationship between probability and proportion.
Imagine you have a population for which you want to find the proportion of  successes.
To calculate this proportion, you take the number of  successes, and divide by the size of  the population.
Now suppose you want to calculate the probability of  choosing a success from the population at random.
To derive this probability, you take the number of  successes in the population, and divide by the size of  the population.
In other words, you derive the probability of  getting a success in exactly the same way as you derive the proportion of  successes.
We use the letter p to represent the probability of  success in the population, but we could easily use p to represent proportion instead—they have the same value.
So am I right in thinking that probability and proportion are related? They’re both represented by p, and they sound like they’re similar.
What proportion of people prefer pink gumballs in the population? What’s the probability of choosing someone from the population who doesn’t prefer pink gumballs?
What proportion of people prefer pink gumballs in the population? What’s the probability of choosing someone from the population who doesn’t prefer pink gumballs?
We can estimate the population proportion with the sample proportion.
A: The proportion is the number of successes in your population, divided by the size of your population.
This is the same calculation you would use to calculate probability for a binomial distribution.
Q: Does proportion just apply to the binomial distribution? What about other probability distributions?
A: Out of all the probability distributions we’ve covered, the only one which has any bearing on proportion is the binomial distribution.
It’s specific to the sorts of problems you have with this distribution.
Q: Is the proportion of the sample the same as the proportion of the population?
A: The proportion of the sample can be used as a point estimator for the proportion of the population.
It’s effectively a best guess as to what the value of the population proportion is.
Q: Is that still the case if the sample is biased in some way? How do I estimate proportion from a biased sample?
A: The key here is to make sure that your sample is unbiased, as this is what you base your estimate on.
If your sample is biased, this means that you will come with an inaccurate estimate for the population proportion.
Q: So how do I make sure my sample is unbiased?
A: Going through the points we raised in the previous chapter is a good way of making sure your sample is as representative as possible.
The hard work you put in to preparing your sample is worth it because it means that your point estimators are a more accurate reflection of the population itself.
This is awesome! We have a lot of impressive statistics we can use in our.
The point estimator for the population variance is given by.
The point estimator for p is given by ps, where ps is the proportion of successes in the sample.
You calculate ps by dividing the number of successes in the sample by the size of the sample.
Buy your gumballs here! Remember the Statsville Cinema? They’re recently been authorized to sell Mighty Gumball products to film-goers, and it’s a move that’s proving popular with most of  their customers.
I really like red gumballs, and I’d rather not eat the other colors.
Introducing new jumbo boxes The cinema sells mixed boxes of  gumballs, and this weekend, they’re putting on a film marathon of  classic films.
The event looks like it’s going to be popular, and tickets are selling well.
The trouble is, some people get cranky if  they don’t get their fix of  red gumballs.
A jumbo box of  gumballs is meant for sharing, and each box contains 100 gumballs.
I need 40 red gumballs to make it through the movie.
Is that likely? If there aren’t enough red gumballs in the box, I’ll get another snack instead.
We need to find the probability that in one particular jumbo box, 40 or more of the gumballs will be red.
So how does this relate to sampling? So far, we’ve looked at how to put together an unbiased sample, and how to use samples to find point estimators for population parameters.
Here, we’re told what the population parameters are, and we have to work out probabilities for one particular jumbo box of  gumballs.
In other words, instead of  working out probabilities for the population, we need to work out probabilities for the sample proportion.
Isn’t that the sort of thing that we were doing before? What’s the big deal?
This time, we’re looking for probabilities for a sample, not a population.
Rather than work out the probability of  getting particular frequencies or values in a probability distribution, this time around we need to find probabilities for the sample proportion itself.
We need to figure out the probability of  getting this particular result in this particular box of  gumballs.
Before we can work out probabilities for this, we need to figure out the probability distribution for the sample proportion.
Look at all possible samples the same size as the one we’re considering.
If  we have a sample of  size n, we need to consider all possible samples of size n.
Look at the distribution formed by all the samples, and find the expectation and variance for the proportion.
Every sample is different, so the proportion of  red gumballs in each box of  gumballs will probably vary.
Once we know how the proportion is distributed, use it to find probabilities.
Knowing how the proportion of  successes in a sample is distributed means we can use it to find probabilities for the proportion in a random sample—in this case, a jumbo box of  gumballs.
The sampling distribution of proportions So how do we find the distribution of  the sample proportions?
We’ve been told what the proportion of  red gumballs is in the population, and we can represent this as p.
Each jumbo box of  gumballs is effectively a sample of  gumballs taken from the population.
The proportion of  red gumballs in the sample depends on X, the number of red gumballs in the sample.
This means that the proportion itself  is a random variable.
We can write this as Ps, where Ps = X/n.
There are many possible samples we could have taken of  size n.
Each possible sample would comprise n gumballs, and the number of  red gumballs in each would follow the same distribution.
For each sample, the number of  red gumballs is distributed as B(n, p), and the proportion of successes is given by X/n.
Each sample contains n elements, just like the previous one.
We can form a distribution out of  all the sample proportions using all of  the possible samples.
This is called the sampling distribution of proportions, or the distribution of  Ps.
The sampling distribution of proportions is really a probability distribution made up of the proportions of all possible samples of size n.
If we know how the proportions are distributed, we’ll be able to use it to find probabilities for the proportion of one particular sample.
Using the sampling distribution of proportions, you can find probabilities for the proportion of successes in a sample of size n, chosen at random.
This means that we can use it to find the probability that the proportion of  red gumballs in one particular jumbo box of  gumballs will be at least 40%
But before we can do that, we need to know what the expectation and variance is for the distribution.
So far we’ve seen how we can form a distribution from the proportions of  all possible samples of  size n.
Before we can use it to calculate probabilities, we need to know more about it.
In particular, we need to know what the expectation and variance is of  the distribution.
Intuitively, we’d expect the proportion of  red gumballs in the sample to match the proportion of  red gumballs in the population.
Now X is the number of  red gumballs in the sample.
If  we count the number of red gumballs as the number of  successes, then X ~ B(n, p)
You’ve already seen that for a binomial distribution, E(X) = np.
Intuitively, you’d expect the proportion of red gumballs to be the same both in the sample and the population.
In other words, we want to find the expected value of  the sample proportion, where the sample proportion is equal to the number of  red gumballs divided by the total number of  gumballs in the sample.
We can expect the proportion of successes in the sample to match the proportion of  successes in the population.
Before we can find out any probabilities for the sample proportion, we also need to know what the variance is for Ps.
We can find the variance in a similar way to how we find the expectation.
So what’s Var(Ps)? Let’s start as we did before by using Ps = X/n.
As we’ve said before, X is the number of  number of  red gumballs in the sample.
If  we count the number of  red gumballs as the number of successes, then X ~ B(n, p)
This means that Var(X) = npq, as this is the variance for the binomial distribution.
Taking the square root of  the variance gives us the standard deviation of  Ps, and this tells us how far away from p the sample proportion is likely to be.
It’s sometimes called the standard error of  proportion, as it tells you what the error for the proportion is likely to be in the sample.
The standard error of  proportion gets smaller as n gets larger.
This means that the more items there are in your sample, the more reliable your sample proportion becomes as an estimator for p.
So how can we use the expectation and variance values we found to calculate probabilities for the proportion? Let’s take a look.
So far we’ve found the expectation and variance for Ps, the sampling distribution of  proportions.
We’ve found that if  we form a distribution from all the sample proportions, then.
But how? Don’t we need to know what the distribution of Ps is first?
Right, the distribution of Ps actually depends on the size of the samples.
Here’s a sketch of  the distribution for Ps when n is large.
Take a look at the sketch for the distribution of Ps where n is large.
When n is large, the distribution of  Ps becomes approximately normal.
The larger n gets, the closer the distribution of  Ps gets to the normal distribution.
We can use the normal distribution to calculate the probability that the proportion of  red gumballs in a jumbo box of  gumballs will be at least 40%
There’s just one thing to remember: the sampling distribution needs a continuity correction.
The number of  successes in each of  the samples is discrete, and as it’s used to calculate proportion, you need to apply a continuity correction when you use the normal distribution to find probabilities.
If  we substitute this in place of  X in the formula Ps = X/n, this means that the continuity correction for Ps is given by.
If  n is very large, the continuity correction can be left out.
As n gets larger, the continuity correction becomes very small, and this means that it makes very little difference to the overall probability.
Sometimes statisticians disagree about how large n needs to be.
If you’re taking a statistics exam, make sure that you check how your exam board defines this.
Q: What’s a sampling distribution? A: A sampling distribution is what you get if you take lots of different samples from a single population, all of the same size and taken in the same way, and then form a distribution out of some key characteristic of each sample.
This means that the sampling distribution of proportions is what you get if you form a sampling distribution out of the proportions for each of the samples.
Q: Do we actually have to gather all possible samples?
A: No, we don’t have to physically form all of the samples.
Instead we imagine that we do, and then come up with expressions for the expectation and variance.
Q: So a sampling distribution has an expectation and variance? Why?
A: A sampling distribution is a probability distribution in the same way as any other probability distribution, so it has an expectation and variance.
The expectation of the sampling population of proportions is like the average value of a sample proportion; it’s what you expect the proportion of a sample taken from a particular population to be.
A: The variance for the sampling distribution of proportions describes how the sample proportions vary.
The variance has a different value because it describes a different concept.
Q: So what use does the sampling distribution of proportions have?
A: It allows you to work out probabilities for the proportion of a sample taken from a known population.
It gives you an idea of what you can expect a sample to be like.
Q: What does the standard error of proportion really mean?
A: The standard error is the square root of the variance for the sampling distribution.
In effect, it tells you how far away you can expect the sample proportion to be from the true value of the population proportion.
This means it tells you what sort of error you can expect to have.
The sampling distribution of proportions is what you get if you consider all possible samples of size n taken from the same population and form a distribution out of their proportions.
We use Ps to represent the sample proportion random variable.
The standard error of proportion is the standard deviation of this distribution.
When working with this, you need to apply a continuity correction of.
If Ps is the proportion of red gumballs in the box, how is Ps distributed?
Let’s use p to represent the probability that a gumball is red.
Let’s use Ps to represent the proportion of gumballs in the box that are red.
If Ps is the proportion of red gumballs in the box, how is Ps distributed?
Sampling Distribution of Proportions Up Close The sampling distribution of  proportions is the distribution formed by taking the proportions of  all possible samples of  size n.
The proportion of  successes in a sample is represented by Ps, and it is is distributed as.
When n is large, say bigger than 30, the distribution of  Ps becomes approximately normal, so.
Ps ~ N(p, pq)         n Knowing the probability distribution of  Ps is useful because it means that given a particular population, we can calculate probabilities for the proportion of  successes in the sample.
We can approximate this with the normal distribution, and the larger the size of  the sample, the more accurate the approximation.
The sampling distribution continuity correction When you use the normal distribution in this way, it’s important to apply a continuity correction.
This is because the number of  successes in the sample is discrete, and it’s used in the calculation of  proportion.
How many gumballs? Using the sampling distribution of  proportions, you’ve successfully managed to find the probability of  getting a certain proportion of successes in one particular sample.
This means that you can now use samples to predict what the population will be like, and also use your knowledge of  the population to make predictions about samples.
The Mighty Gumball CEO has one more problem for you to work on.
In addition to selling jumbo boxes, gumballs are also sold in handy pocketsized packets that you can carry with you wherever you go.
The CEO is concerned that he will lose one of  his best customers, and he wants to offer him some form of  compensation.
The trouble is, he doesn’t want to compensate all of  his customers.
He needs to know what the probability is of  this happening again.
Now, there’s just one more thing that needs sorting out...
What do you need to know in order to solve this sort of problem?
We’re told what the population mean and variance are for the packets of  gumballs, and we have a sample of  packets we need to figure out probabilities for.
Instead of  working out probabilities for the sample proportion, this time we need to work out probabilities for the sample mean.
Before we can work out probabilities for the sample mean, we need to figure out its probability distribution.
Look at all possible samples the same size as the one we’re considering.
If  we have a sample of  size n, we need to consider all possible samples of size n.
Look at the distribution formed by all the samples, and find the expectation and variance for the sample mean.
Every sample is different, and the number of  gumballs in each packet varies.
Once we know how the sample mean is distributed, use it to find probabilities.
If  we know how the means of  all possible samples are distributed, we can use it to find probabilities for the mean in a random sample, in this case the, packets of  gumballs.
The population in this case is all the packets of gumballs.
The sampling distribution of the mean So how do we find the distribution of  the sample means?
We can represent the mean of  gumballs in these n packets of  gumballs with X.
The value of  X depends on how many gumballs are in each packet of the n pockets, and to calculate it, you add up the total number of  gumballs and divide by n.
The number of gumballs in each packet follows the same distribution.
Each Xi is an independent observation of X, so each packet has the same expectation and variance for the number of gumballs.
There are many possible samples we could have taken of  size n.
Each possible sample comprises n packets, which means that each sample comprises n independent observations of  X.
The number of  gumballs in each randomly chosen packet follows the same distribution as all the others, and we calculate the mean number of  gumballs for each sample in the same way.
Each sample contains n packets, just like the previous one.
We can form a distribution out of  all the sample means from all possible samples.
This is called the sampling distribution of means, or the distribution of  X.
So does this really help us? What does it give us?
This is the mean number of gumballs per packet in this sample.
The sampling distribution of means gives us a way of calculating probabilities for the mean of a sample.
Before you can work out the probability of  any variable, you need to know about its probability distribution, and this means that if  you want to calculate probabilities for the sample mean, you need to know how the sample means are distributed.
Just as with the sampling distribution of  proportions, before we can start calculating probabilities, we need to know what the expectation and variance are of  the distribution.
Find the expectation for X So far, we’ve looked at how to construct the sampling distribution of means.
In other words, we consider all possible samples of  size n and form a distribution out of  their means.
Before we can use it to find probabilities, we need to find the expectation and variance of  X.
Now X is the mean number of  gumballs in each packet of  gumballs in our sample.
These two expressions are the same, just written in a different way.
We can split this into n separate expectations because E(X + Y) = E(X) + E(Y)
This means that if  we know what the expectation is for each Xi, we’ll have an expression for E(X)
It means that overall, you’d expect the average number of  gumballs per packet in a sample to be the same as the average number of  gumballs per packet in the population.
In our situation, the mean number of  gumballs in each packet in the population is 10, so this is what we’d expect for the sample too.
What else do we need to know in order to find probabilities for the sample mean? How do you think we can find this?
What about the the variance of X? So far we know what E(X) is, but before we can figure out any probabilities for the sample mean, we need to know what Var(X) is.
This will bring us one step closer to finding out what the distribution of  X is like.
The distribution of X is different from the distribution of X.
We’ve been told what the mean number of  gumballs in a packet is, and we’ve also been given the variance.
E(X) refers to the mean value of  the sample means, and Var(X) refers to how they vary.
Finding Var(X) is actually a very similar process to finding E(X)
Statistics Magnets Here are some equations for finding an expression for the variance of the sample mean.
Your task is to fill in the blanks below by putting the magnets back in the right positions and derive the variance of the sample mean.
Statistics Magnets Solution Here are some equations for finding the variance of the sample mean.
Your task is to put the magnets back in the right positions and derive the variance of the sample mean.
Don’t worry if  you didn’t complete this exercise; it’s hard.
Most exam boards won’t ask you to derive this, and in real.
Sampling Distribution of the Means Up Close Let’s take a closer look at the sampling distribution of  means.
We then took all possible samples of  size n taken from the population X and formed a distribution out of  all the sample means, the distribution of  X.
The mean and variance of  this distribution are given by:
The standard error of  the mean gets smaller as n gets larger.
This means that the more items there are in your sample, the more reliable your sample mean becomes as an estimator for the population mean.
The larger n gets, the smaller the standard error becomes.
So how is X distributed? So far we’ve found what the expectation and variance is for X.
Before we can find probabilities, though, we need to know exactly how X is distributed.
Let’s start by looking at the distribution of  X if  X is normal.
For each of  these combinations, the distribution of  X is normal.
But is the number of gumballs in a packet distributed normally? What if it’s not?
We need to know how X is distributed so that we can work out probabilities for the sample mean.
The trouble is, we don’t know how X is distributed.
We need to know what distribution X follows if  X isn’t normal.
As n gets larger, X gets closer and closer to a normal distribution.
We’ve already seen that X is normal if  X is normal.
If  X isn’t normal, then we can still use the normal distribution to approximate the distribution of  X if  n is sufficiently large.
In our current situation, we know what the mean and variance are for the population, but we don’t know what its distribution is.
However, since our sample size is 30, this doesn’t matter.
We can still use the normal distribution to find probabilities for X.
Does this look familiar? It’s the same distribution that we had when X followed a normal distribution.
The only difference is that if  X is normal, it doesn’t matter what size sample you use.
If n is large, X can still be approximated by the normal distribution.
By the central limit theorem, if your sample of X is large, then X’s distribution is approximately normal.
Using the central limit theorem So how does the central limit theorem work in practice? Let’s take a look.
Finding probabilities Since X follows a normal distribution, this means that you can use standard normal probability tables to look up probabilities.
In other words, you can find probabilities in exactly the same way you would for any other normal distribution.
This probability is so small that it doesn’t appear on the probability tables.
We can assume that an event with a probability this small will hardly ever happen.
Q: Do I need to use any continuity corrections with the central limit theorem?
You use the central limit theorem to find probabilities associated with the sample mean rather than the values in the sample, which means you don’t need to make any sort of continuity correction.
Q: Is there a relationship between point estimators and sampling distributions?
Q: So is that a coincidence? A: No, it’s not.
The estimators are chosen so that the expectation of a large number of samples, all of size n and taken in the same way, is equal to the true value of the population parameter.
An unbiased estimator is likely to be accurate because on average across all possible samples, it’s expected to be the value of the true population parameter.
A: The best unbiased estimator for a population parameter is generally one with the smallest variance.
In other words, it’s the one with the smallest standard error.
The sampling distribution of means is what you get if you consider all possible samples of size n taken from the same population and form a distribution out of their means.
We use X to represent the sample mean random variable.
The standard error of the mean is the standard deviation of this distribution.
The central limit theorem says that if n is large and X doesn’t follow a normal distribution, then.
That means I don’t have to worry about compensating disgruntled customers, which means more money for me!
You’ve made a lot of progress Not only have you been able to come up with point estimators for population parameters based on a single sample, you’ve also been able to use population to calculate probabilities in the sample.
You’ve seen how you can use point estimators to estimate the precise value of the.
I put this in the oven for 2.5 hours, but if you bake yours for.
Someone else has conducted independent tests and come up with a different result.
They’re threatening to sue, and that will cost me money.
The CEO announced on primetime television that gumball flavor lasts for an average of  62.7 minutes.
It’s the best estimate for flavor duration that could possibly have been made based on the evidence, but what if  it gave a slightly wrong result?
If  Mighty Gumball is sued because of  the accuracy of  their claims, they could lose a lot of  money and a lot of  business.
They need your help to get them out of  this.
The Mighty Gumball CEO has gone ahead with a range of television advertisements, and he’s proudly announced exactly how long the flavor of  the super-long-lasting gumballs lasts for, right down to the last second.
What do you think could have gone wrong? Should Mighty Gumball have used the precise value of the point estimator in their advertising? Why? Why not?
The problem with precision As you saw in the last chapter, point estimators are the best estimate we can possibly give for population statistics.
You take a representative sample of  data and use this to estimate key statistics of  the population such as the mean, variance, and proportion.
This means that the point estimator for the mean flavor duration of  super-long-lasting gumballs was the best possible estimate we could possibly give.
The problem with deriving point estimators is that we rely on the results of  a single sample to give us a very precise estimate.
We’ve looked at ways of  making the sample as representative as possible by making sure the sample is unbiased, but we don’t know with absolute certainty that it’s 100% representative, purely because we’re dealing with a sample.
Now hold it right there! Are you saying that point estimators are no good? After all that hard work?
Point estimators are valuable, but they may give slight errors.
Because we’re not dealing with the entire population, all we’re doing is giving a best estimate.
If  the sample we use is unbiased, then the estimate is likely to be close to the true value of  the population.
Rather than give a precise value as an estimate for the population mean, there’s another approach we can take instead.
We can specify some interval as an estimation of  flavor duration rather than a very precise length of  time.
This still gives the impression that flavor lasts for approximately one hour, but it allows for some margin of  error.
The question is, how do we come up with the interval? It all depends how confident you want to be in the results...
Introducing confidence intervals Up until now, we’ve estimated the mean amount of  time that gumball flavor lasts for by using a point estimator, based upon a sample of  data.
Using the point estimator, we’ve been able to give a very precise estimate for the mean duration of  the flavor.
Here’s a sketch showing the distribution of  flavor duration in the sample of  gumballs.
So what happens if  we specify an interval for the population mean instead? Rather than specify an exact value, we can specify two values we expect flavor duration to lie between.
We place our point estimator for the mean in the center of  the interval and set the interval limits to this value plus or minus some margin of  error.
The interval limits are chosen so that there’s a specified probability of  the population mean being between a and b.
As an example, you may want to choose a and b so that there’s a 95% chance of  the interval containing the population mean.
In other words, you choose a and b so that.
As the exact value of  a and b depends on the degree of  confidence you want to have that the interval contains the population mean, (a, b) is called a confidence interval.
So how do we find the confidence interval for the population mean?
Four steps for finding confidence intervals Here are the broad steps involved in finding confidence intervals.
Don’t worry if  you don’t get what each step is about just yet, we’ll go through them in more detail soon.
Q: So can you construct a confidence interval for any population statistic?
A: Broadly speaking, you can construct a confidence interval for any population statistic where you know what the sampling distribution is like.
We’ve looked at sampling distributions for the mean and proportion, so we can construct confidence intervals for both of these.
Q: What about the variance? Can we construct a confidence interval for that?
A: Theoretically, yes, but we haven’t covered the sampling distribution for the variance, and we’re not going to.
It’s more common to construct confidence intervals for the mean and proportion, and these are what tend to be covered by statistics exams.
Q: Do these steps relate to the confidence interval for the mean or the confidence interval for the proportion?
You can use them for the population mean and for the population proportion.
A: The key thing is the sampling distribution of the statistic you’re trying to construct a confidence interval for.
If you want a confidence interval for the mean, you need to know the sampling distribution of means, and if you want a confidence interval for the proportion, you need to know the sampling distribution of proportions.
The main impact the population distribution has on the confidence interval is the effect it has on the sampling distribution.
Let’s see if  we can construct a confidence interval for the Mighty Gumball CEO that he can use in his television commercials.
Let’s find a confidence interval for the mean amount of  time gumball flavor lasts for.
To find the confidence limits, we need to know the level of confidence and the sampling distribution.
Step 1: Choose your population statistic The first step is to pick the statistic you want to construct a confidence interval for.
This all depends on the problem you want to solve.
Now that we’ve chosen the population statistic, we can move onto the next step.
Step 2: Find its sampling distribution To find a confidence interval for the population mean, we need to know what the sampling distribution is for the mean.
In other words, we need to know what the expectation and variance of  X is, and also what distribution it follows.
If  we go back to the work we did in the last chapter, then the sampling distribution of  means has the following expectation and variance:
This means that the expectation and variance for the sampling distribution of  means is.
We’ve found the distribution for X Now that we know how X is distributed, we have enough information to move onto the next step.
Step 3: Decide on the level of confidence The level of  confidence lets you say how sure you want to be that the confidence interval contains your population statistic.
As an example, suppose we want a confidence level of  95% for the population mean.
This means that the probability of  the population mean being inside the confidence interval is 0.95
How do you think the level of confidence affects the size of the confidence interval?
So who decides what the level of  confidence should be? What’s the right level of  confidence?
The answer to this really depends on your situation and how confident you need to be that your interval contains the population statistic.
As an example, the Mighty Gumball CEO might want to have a higher degree of  confidence that the population mean falls inside the confidence interval, as he intends to use it in his television advertisements.
The key thing to remember is that the higher the confidence level is, the wider the interval becomes, and the more chance there is of  the confidence interval containing the population statistic.
Well, why don’t we just make the confidence interval really wide? That way we’re bound to include the population statistic.
The trouble with making the confidence interval too wide is that it can lose meaning.
While this is true, it doesn’t give you an idea how long gumball flavor really lasts for.
You don’t know whether it lasts for seconds, minutes, or hours.
The key thing is to make the interval as narrow as possible, but wide enough so you can be reasonably sure the true mean is in the interval.
That way, there’ll be a high probability that it contains the population mean.
Now that we have the confidence level, we can move onto the final step: finding the confidence limits.
The exact value of  a and b depends on the sampling distribution we need to use and the level of confidence that we need to have.
Here’s a sketch of  what we need: We want to choose a and b so that this.
As X follows a normal distribution, we can use the normal distribution to find the confidence interval.
We can do this in a similar way to how we’ve solved other problems in the past.
We calculate a standard score, and we use standard normal probability tables to help us get the result we need.
We can find the values of  za and zb using probability tables.
Here’s a sketch of  the standardized version of  the confidence interval.
To find zb, we need to look up a value of 0.975
Note: Each thing from the pool can only be used once!
This is what you get if you put the two sides of the inequality together again.
Note: Each thing from the pool can only be used once!
This gives you the left hand side of the inequality.
If  we knew what to use as a value for X, we’d have values for the confidence limits.
I wonder if we can use the Mighty Gumball sample in some way.
For the Mighty Gumball sample, x is given by 62.7
Use this to come up with values for the confidence limits.
You’ve found the confidence interval Congratulations! You’ve found your first confidence interval.
That’s fantastic news! That means I can update the fine print on our advertisements.
Using confidence intervals in the television advertisement rather than point estimators means that the CEO can give an accurate and precise estimate for how long flavor lasts, but without having to give a precise figure.
It makes allowances for any margin of  error there might be in the sample.
For the Mighty Gumball sample, x is given by 62.7
Use this to come up with values for the confidence limits.
So does that mean I have to go through the same process every single time I want to construct a confidence interval?
Constructing confidence intervals can be a repetitive process, so there are some shortcuts you can take.
It all comes down to the level of confidence you want and the distribution of  the test statistic.
Let’s take a look at some of  the shortcuts we can take.
Let’s summarize the steps Let’s look back at the steps we went through in order to construct the confidence interval.
After that, we decided on the level of  confidence we needed for the confidence interval.
Finally, we had to find the confidence limits for the confidence interval.
We used the level of  confidence and sampling distribution to come up with a suitable confidence interval.
Handy shortcuts for confidence intervals Here are some of  the shortcuts you can take when you calculate confidence intervals.
All you need to do is look at the population statistic you want to find, look at the distribution of  the population and the conditions, and then slot in the population statistic or its estimator.
The value of c depend s on the level of.
What’s the interval in general? In general, the confidence interval is given by.
The margin of  error is given by the value of  c multiplied by the standard deviation of  the test statistic.
Construct a 99% confidence interval for the proportion of red gumballs in the population.
Construct a 99% confidence interval for the proportion of red gumballs in the population.
Q: Why did we use x as the value of X?
A: The distribution of X is the sampling distribution of means.
You form it by taking every possible sample of size n from the population, and then forming a distribution out of all the sample means.
Q: What’s the difference between the confidence interval and the confidence level?
A: The confidence interval is the probability that your statistic is contained within the confidence interval.
The confidence interval gives the lower and upper limit of the interval itself, the actual range of numbers.
A: What it means is that if you were to take many samples of the same size and construct confidence intervals for all of them, then 95% of your confidence intervals would contain the true population mean.
You know that 95% of the time, a confidence interval constructed in this way will contain the population mean.
Q: In the shortcuts, do the values of c apply to every confidence interval?
A: They apply to all of the shortcuts we’ve shown you so far because all of these shortcuts are based on the normal distribution.
This is because the sampling distribution in all of these cases follows the normal distribution.
Q: I’ve sometimes seen “a” instead of “c” in the shortcuts for the confidence intervals.
The key thing is that whether you refer to it as “a” or “c”, it represents a value that you can substitute into your confidence interval to give you the right confidence level.
The values stay the same no matter what you call it.
Q: So are all confidence intervals based on the normal distribution?
We’ll look at intervals based on other distributions later on.
Q: Why did we go through all those steps when all we have to do is slot values into the shortcuts?
A: We went through the steps so that you could see what was going on underneath and understand how confidence intervals are constructed.
Most of the time, you’ll just have to substitute in values.
Q: Do I need continuity corrections when I’m working with confidence intervals?
A: Theoretically, you do, but in practice, they’re generally omitted.
This means that you can just substitute values into the shortcuts to come up with confidence intervals.
I have one more problem I need your help with.
Mighty Gumball has one last problem for you to sort out.
One of  the candy stores selling gumballs wants to determine how much gumballs typically weigh, as they find that their customers often buy gumballs based on weight rather than quantity.
If  the store can figure out the typical weight of  a gumball, they can use this information to boost sales.
Mighty Gumball has taken a representative sample of  10 gumballs and weighed each one.
Assuming the weight of each gumball in the population follows a normal distribution, how would you go about creating a 95% confidence interval for this data? Hint: look at the table of confidence interval shortcuts and see which situation we have here.
That means I need you to come up with a confidence interval for gumball weight, but as it’s just for one store, I don’t want to sample a large number of gumballs.
The normal distribution isn’t a good approximation for every situation.
All of  the sampling distributions we’ve seen so far either follow a normal distribution or can be approximated by it.
The trouble is that we can’t use the normal distribution for every single confidence interval.
When sample sizes are large, the normal distribution is ideal for finding confidence intervals.
It gives accurate results, irrespective of  how the population itself  is distributed.
So what sort of  distribution does X follow? It actually follows a t-distribution.
The t-distribution works in a similar way to the normal distribution.
We start off  by converting the limit of  the probability area into a standard score, and then we use probability tables to get the result we want.
You’ll see how to calculate it on the next page.
We calculate the standard score for the t-distribution in the same way we did for the normal distribution.
As with the the normal distribution, we standardize by subtracting the expectation of  the sampling distribution and then dividing by its standard deviation.
The only difference is that we represent the result with T instead of  Z, as we’re going to use it with the t-distribution.
This is the same formula as for Z—subtract the mean and divide by the standard deviation.
This is the population mean we’re finding a confidence interval for.
All we need to do is substitute in the values for X, , and n.
Step 3: Decide on the level of confidence So what level of  confidence should we use for Mighty Gumball? Remember, the level of  confidence says how sure you want to be that the confidence interval contains the population statistic, and it helps us figure out how wide the confidence interval needs to be.
As before, let’s have a confidence level of  95% for the population mean.
This means that the probability of  the population mean being inside the confidence interval is 0.95
Using t-distribution probability tables t-distribution probability tables give you the value of  t where P(T > t) = p.
Once you’ve found the value of  t, you can use it to find your confidence interval.
Step 4: Find the confidence limits You find confidence limits with the t-distribution in a similar way to how you find them with the normal distribution.
We can find the value of  t using t-distribution probability tables.
This is the same as we had before, just replace c with t.
See if you can find the 95% confidence interval for the average weight of gumballs.
So why did we use the t-distribution for this problem? Why couldn’t we have used the normal distribution instead?
The t-distribution is more accurate when we have to estimate the population variance for small samples.
See if you can find the 95% confidence interval for the average weight of gumballs.
Mighty Gumball has noticed a problem with their gumball dispensers.
Construct a 99% confidence interval for the number of malfunctions per month.
Mighty Gumball has noticed a problem with their gumball dispensers.
Construct a 99% confidence interval for the number of malfunctions per month.
Q:Does X follow a t-distribution? A: X follows a t-distribution when the population is normal, the sample size is small, and you need to estimate the population variance using the sample data.
Q: In general, what happens to my confidence interval if the confidence level changes?
A: If your confidence level goes down, then your confidence interval gets narrower.
If your confidence level goes up, then your confidence interval gets wider.
Q: What happens to the confidence interval if the size of the sample, n, changes?
You’ve found the confidence intervals! You’ve made a lot of  progress in this chapter, and the result of  it is that you now know two ways of  estimating population statistics.
The first way of  estimating population statistics is to use point estimators.
Point estimators give you a way of  estimating the precise value for the population statistics.
It’s the best guess you can possibly make based on the sample data.
You also know how to come up with confidence intervals for the population statistics.
Rather than come up with a very precise estimate for the population statistics, you now know how to find a range of  values for the population statistic that you can feel truly confident about.
You’re great! I’ll tell the candy shop what the confidence interval is for the mean weight of gumballs, as that’s just what they wanted to know.
They’ll be able to sell more gumballs to their customers, and that means increased profits!
The trouble is, how do you know when what you’re being told isn’t right? Hypothesis.
They give you a way of weighing the evidence and testing whether extreme.
Come with us on a ride through this chapter, and we’ll show you how you can use.
Statsville’s new miracle drug Statsville’s leading drug company has produced a new remedy for curing snoring.
Frustrated snorers are flocking to their doctors in hopes of  finding nightly relief.
The drug company claims that their miracle drug cures 90% of people within two weeks, which is great news for the people with snoring difficulties.
The doctor at the Statsville Surgery has been prescribing SnoreCull to her patients, but she’s disappointed by the results.
She decides to conduct her own trial of  the drug.
She takes a random sample of  15 snorers and puts them on a course of  SnoreCull for two weeks.
After two weeks, she calls them back in to see whether their snoring has stopped.
If they were, more of my patients would be cured.
Only 11 people in the doctors sample were cured, which is much lower than the result you’d expect There are a specific number of trials and the doctor is interested in the number of successes, so the number of successes follows a binomial distribution.
So what’s the problem? Here’s the probability distribution for how many people the drug company says should have been cured by the snoring remedy.
The number of  people cured by SnoreCull in the doctor’s sample is actually much lower than you’d expect it to be.
This is how many people were actually cured by SnoreCull.
But can we really be certain that the drug company is at fault? Maybe the doctor was unlucky.
Rather than the drug company being at fault, it’s always possible that the patients in the doctor’s sample may not have been representative of  the snoring population as a whole.
It’s always possible that the snoring remedy does cure 90% of  snorers, but the doctor just happens to have a higher proportion of  people in her sample whom it doesn’t cure.
In other words, her sample might be biased in some way, or it could just come down to there being a small number of  patients in the sample.
Does that mean that the drug company is telling lies about their product? Shouldn’t the drug have cured more of the doctor’s patients?
The drug company might not be deliberately telling lies, but their claims might be misleading.
It’s possible that the tests of  the drug company were flawed, and this might have resulted in misleading claims being made about SnoreCull.
They may have inadvertent conducted flawed or biased tests on SnoreCull, which resulted in them making inaccurate predictions about the population.
How do you think we can resolve this? How can we determine whether to trust the claims of the drug company, or accept the doctor’s doubts instead?
Resolving the conflict from 50,000 feet So how do we resolve the conflict between the doctor and the drug company? Let’s take a very high level view of  what we need to do.
We can resolve the conflict between the drug company and the doctor by putting the claims of  the drug company on trial.
In other words, we’ll accept the word of  the drug company by default, but if  there’s strong evidence against it, we’ll side with the doctor instead.
See how much evidence we need to reject the drug company’s claim, and check this against the evidence we have.
We do this by looking at how rare the doctors results would be if the drug company is correct.
Depending on the evidence, accept or reject the claims of the drug company.
In general, this process is called hypothesis testing, as you take a hypothesis or claim and then test it against the evidence.
The six steps for hypothesis testing Here are the broad steps that are involved in hypothesis testing.
We’ll go through each one in detail in the following pages.
Why all the formality? It’s obvious there’s something going on.
We need to make sure we properly test the drug claim before we reject it.
That way we’ll know we’re making an impartial decision either way, and we’ll be giving the claim a fair trial.
What we don’t want to to do is reject the claim if  there’s insufficient evidence against it, and this means that we need some way of  deciding what constitutes sufficient evidence.
See whether the sample result is within the critical region.
We then see if it’s within our bounds of certainty.
So what’s the null hypothesis for SnoreCull? The null hypothesis for SnoreCull is the claim of  the drug company: that it cures 90% of  patients.
This is the claim that we’re going to go along with, unless we find strong evidence against it.
We need to accept this position unless there is sufficiently strong evidence to the contrary.
The claim that we’re testing is called the null hypothesis.
It’s represented by H0, and it’s the claim that we’ll accept unless there is strong evidence against it.
Step 1: Decide on the hypothesis Let’s start with step one of  the hypothesis test, and look at the key claim we want to test.
The null hypothesis is the claim you’re going to test.
It’s the claim you’ll accept unless there’s strong evidence against it.
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
You have to assume I cure 90% of people unless you can come up with good evidence that I don’t.
The doctor’s perspective The doctor’s view is that the claims of  the drug company are too good to be true.
She doesn’t think that as many as 90% of  patients are cured.
She thinks it’s far more likely that the cure rate is actually less than 90%
The counterclaim to the null hypothesis is called the alternate hypothesis.
If H0 let’s you down, then you’ll have to accept that you’re better off with.
So what’s the alternative? We’ve looked at what the claim is we’re going to test, the null hypothesis, but what if  it’s not true? What’s the alternative?
The alternate hypothesis for SnoreCull The alternate hypothesis for SnoreCull is the claim you’ll accept if  the drug company’s claim turns out to be false.
If  there’s sufficiently strong evidence against the drug company, then it’s likely that the doctor is right.
Q: Why are we assuming the null hypothesis is true and then looking for evidence that it’s false?
A: When you conduct a hypothesis test, you, in effect, put the claims of the null hypothesis on trial.
You give the null hypothesis the benefit of the doubt, but then you reject it if there is sufficient evidence against it.
It’s a bit like putting a prisoner on trial in front of a jury.
You only sentence the prisoner if there is strong enough evidence against him.
Q: Do the null hypothesis and alternate hypothesis have to be exhaustive? Should they cover all possible outcomes?
Q: Isn’t the sample size too small to do this hypothesis test?
A: Even though the sample size is small, we can still perform hypothesis tests.
It all comes down to what test statistic you use — and we’ll come to that on the next page.
Q: So are hypothesis tests used to prove whether or not claims are true?
They allow you to see how rare your observed results actually are, under the assumption that your null hypothesis is true.
If your results are extremely unlikely to have happened, then that counts as evidence that the null hypothesis is false.
When hypothesis testing, you assume the null hypothesis is true.
If there’s sufficient evidence against it, you reject it and accept the alternate hypothesis.
Step 2: Choose your test statistic Now that you’ve determined exactly what it is you’re going to test, you need some means of  testing it.
The test statistic is the statistic that you use to test your hypothesis.
What’s the test statistic for SnoreCull? In our hypothesis test, we want to test whether SnoreCull cures 90% of people or more.
To test this, we can look at the probability distribution according to the drug company, and see whether the number of successes in the sample is significant.
If  we use X to represent the number of  people cured in the sample, this means that we can use X as our test statistic.
As X follows a binomial distribution, this means that the test statistic is actually:
Why are we saying the probability of success is 0.9? Surely we don’t know that yet.
We choose the test statistic according to H0, the null hypothesis.
We need to test whether there is sufficient evidence against the null hypothesis, and we do this by first assuming that H0 is true.
For the SnoreCull hypothesis test, we assume that the probability of  success is 0.9 unless there is strong evidence against this being true.
To do this, we look at how likely it is for us to get the results we did, assuming the probability of  success is 0.9
In other words, we take the results of  the sample and examine the probability of  getting that result.
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
If 90% of people in the sample had been cured, we could easily have assumed that the drug company’s claims are correct.The fewer people who are cured, the more likely it is that the drug company claims are wrong.
The critical region of  a hypothesis test is the set of  values that present the most extreme evidence against the null hypothesis.
Let’s see how this works by taking another look at the doctor’s sample.
If  90% or more people had been cured, this would have been in line with the claims made by the drug company.
As the number of  people cured decreases, the more unlikely it becomes that the claims of  the drug company are true.
At what point can we reject the drug company claims? The fewer people there are in the sample who are successfully cured by SnoreCull, the stronger the evidence there is against the claims of  the drug company.
The question is, at what point does the evidence become so strong that we confidently reject the null hypothesis? At what point can we reject the claim that SnoreCull cures 90% of  snorers?
What we need is some way of  indicating at what point we can reasonably reject the null hypothesis, and we can do this by specifying a critical region.
If  the number of  snorers cured falls within the critical region, then we’ll say there is sufficient evidence to reject the null hypothesis.
If  the number of snorers cured falls outside the critical region, then we’ll accept that there isn’t sufficient evidence to reject the null hypothesis, and we’ll accept the claims of  the drug company.
We’ll call the cut off  point for the critical region c, the critical value.
If the number of people cure d by SnoreCull falls in.
If the number of people cured by SnoreCull falls in this critical region, then we can safely reject the claims of the drug company, H0
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
Before we can find the critical region of  the hypothesis test, we first need to decide on the significance level.
The significance level of a test is a measure of  how unlikely you want the results of  the sample to be before you reject the null hypothesis Ho.
Just like the confidence level for a confidence interval, the significance level is given as a percentage.
As an example, suppose we want to test the claims of  the drug company at a 5% level of  significance.
This means that we choose the critical region so that the probability of  fewer than c snorers being cured is less than 0.05
If the number of snorers cured by SnoreCull falls in the critical region, t.
So what significance level should we use? Let’s use a significance level of  5% in our hypothesis test.
This means that if  the number of  snorers cured in the sample is in the lowest 5% of  the probability distribution, then we will reject the claims of  the drug company.
If  the number of snorers cured lies in the top 95% of  the probability distribution, then we’ll decide there isn’t enough evidence to reject the null hypothesis, and accept the claims of  the drug company.
If  we use X to represent the number of  snorers cured, then we define the critical region as being values such that.
To find the critical region, first decide on the significance level.
When you’re constructing a critical region for your test, another thing you need to be aware of  is whether you’re conducting a one-tailed or two-tailed test.
Let’s look at the difference between the two, and what impact this has on the critical region?
The tail can be at either end of  the set of  possible values, and the end you use depends on your alternate hypothesis H1
If  your alternate hypothesis includes a < sign, then use the lower tail, where the critical region is at the lower end of  the data.
If  your alternate hypothesis includes a > sign, then use the upper tail, where the critical region is at the upper end of the data.
This is a two-tailed test, where the critical region is split over the two tails.
A p-value is the probability of  getting a value up to and including the one in your sample in the direction of  your critical region.
It’s a way of  taking your sample and working out whether the result falls within the critical region for your hypothesis test.
In other words, we use the p-value to say whether or not we can reject the null hypothesis.
How do we find the p-value? How we find the p-value depends on our critical region and our test statistic.
For the SnoreCull test, 11 people were cured, and our critical region is the lower tail of  the distribution.
This means that our p-value is P(X  11), where X is the distribution for the number of  people cured in the sample.
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
We’ve found the p-value To find the p-value of  our hypothesis test, we had to find P(X  11)
Do I always calculate p-values in the same way? What if my critical region had been the upper tail?
A p-value is the probability of getting the results in the sample, or something more extreme, in the direction of the critical region.
In our hypothesis test for SnoreCull, the critical region is the lower tail of the probability distribution.
We want to find whether 11 people being cure d is in the.
Had our critical region been the upper tail of  the probability distribution instead, we would have needed to find P(X  11)
We would have counted more extreme results as being greater than 11, as these would have been closer to the critical region.
Now that we’ve found the p-value, we can use it to see whether the result from our sample falls within the critical region.
If  it does, then we’ll have sufficient evidence to reject the claims of  the drug company.
Our critical region is the lower tail of  the probability distribution, and we’re using a significance level of  5%
This means that we can reject the null hypothesis if  our p-value is less that 0.05
As our p-value is 0.0555, this means that the number of  people cured by SnoreCull in the sample doesn’t fall within the critical region.
The p-value is 0.056, so it’s just outside the critical region.
Step 6: Make your decision We’ve now reached the final step of  the hypothesis test.
We can decide whether to accept the null hypothesis, or reject it in favor of  the alternative.
The p-value of  the hypothesis test falls just outside the critical region of the test.
This means that there isn’t sufficient evidence to reject the null hypothesis.
Step 5: Is the sample result in the critical region? Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
Once you’ve fixed the significance level of the test, you can’t change it.
This means that you decide what level you need the test to be at, based on what level of  evidence you require, before you look at what evidence you actually have.
If  you were to look at the amount of  evidence you have before deciding on the level of  the test, this could influence any decisions you made.
You might be tempted to decide on a specific level of  test just to get the result you want.
This would make the outcome of  the test biased, and you might make the wrong decision.
So what did we just do? Let’s summarize what we just did.
First of  all, we took the claims of  the drug company, which the doctor had misgivings about.
We used these claims as the basis of  a hypothesis test.
We formed a null hypothesis that the probability of  curing a patient is 0.9, and then we applied this to the number of  people in the doctors sample.
We then decided to conduct a test at the 5% level, using the success rate in the doctor’s sample.
In other words, we looked at the probability of  getting a result this extreme, or even more so.
Finally, we found that at the 5% level, there wasn’t strong enough evidence to reject the claims of  the drug company.
Q: What significance level should I normally test at? A: It all depends how strong you want the evidence to be before you reject the null hypothesis.
The stronger you want the evidence to be, the lower your significance level needs to be.
Q: Does the significance level have anything in common with the level of confidence for confidence intervals?
When you construct a confidence interval for a population parameter, you want to have a certain degree of confidence that the population parameter lies between two limits.
The level of significance reflects the probability that values will lie outside a certain limit.
I wonder what would happen if I took a larger sample...
In a hypothesis test, you take a claim and test it against statistical evidence.
The claim that you’re testing is called the null hypothesis test.
It’s represented as H0, and it’s the claim that’s accepted unless there’s strong statistical evidence against it.
The alternate hypothesis is the claim we’ll accept if there’s strong enough evidence against  H0
The test statistic is the statistic you use to test your hypothesis.
You choose the test statistic by assuming that H0 is true.
The critical region is the set of values that presents the most extreme evidence against the null hypothesis test.
You choose your critical region by considering the significance level and how many tails you need to use.
A one-tailed test is when your critical region lies in either the upper or the lower tail of the data.
A two-tailed test is when it’s split over both ends.
You choose your tail by looking at your alternate hypothesis.
A p-value is the probability of getting the result of your sample, or a result more extreme in the direction of your critical region.
If the p-value lies in the critical region, you have sufficient reason to reject your null hypothesis.
If your p-value lies outside your critical region, you have insufficient evidence.
What if the sample size is larger? So far the doctor has conducted her trial using a sample of  just 15 people, and on the basis of  this, there was insufficient evidence to reject the claims of  the drug company.
It’s possible that the size of  the sample wasn’t large enough to get an accurate result.
The doctor might get more reliable results by using a larger sample.
What’s the null hypothesis of this new problem? What’s the alternate hypothesis?
We want to determine whether the new data will make a difference in the outcome of the test.
Let’s run through another hypothesis test, this time with the larger sample.
I want to conduct a new hypothesis test using these new results.
There are a number of steps you need to run through to perform the hypothesis test, but can you remember what the order is? Put the magnets into the right order.
See whether the test statistic is within the critical region.
Hypothesis Magnets Solution It’s time to do another hypothesis test.
There are a number of steps you need to run through to perform the hypothesis test, but can you remember what the order is? Put the magnets into the right order.
See whether the test statistic is within the critical region.
Step 1: Decide on the hypotheses We need to start off  by finding the null hypothesis and alternate hypothesis of  the SnoreCull trial.
As a reminder, the null hypothesis is the claim that we’re testing, and the alternate hypothesis is what we’ll accept if there’s sufficient evidence against the null hypothesis.
It’s still the same problem For the last test, we took the claims made by the drug company and used these as the basis for the null hypothesis.
We’re testing the same claims, so the null hypothesis is still the same.
If  there is strong evidence against the claims made by the drug company, then we’ll accept that the drug cures fewer than 90% of  the patients.
So you still don’t believe me? Think you can have another shot at me? Bring it on!
Let’s conduct another hypothesis test The doctor still has misgivings about the claims made by the drug company.
Let’s conduct a hypothesis test based on the new data.
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
As before, the next step is to choose the test statistic.
In other words, we need some statistic that we can use to test the hypothesis.
For the previous hypothesis test, we conducted the test by looking at the number of  successes in the sample and seeing how significant the result was.
We used the binomial distribution to find the probability of  getting a result at least as extreme as the value we got in the sample.
Are you kidding me? If we have to calculate probabilities using the binomial distribution, we’ll be here forever.
We can use another probability distribution instead of the binomial.
Using the binomial distribution for this sort of  problem would be time consuming, as we’d have to calculate lots of  probabilities.
Rather than use the binomial distribution, we can use some other distribution instead.
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
To get the most out of hypothesis tests, you need to know how different variables and parameters are distributed.
What distributions would you use to find probabilities for the following situations?
Hint: We covered all of these earlier in the book.
To get the most out of hypothesis tests, you need to know how different variables and parameters are distributed.
What distributions would you use to find probabilities for the following situations? Hint: We covered all of these earlier in the book.
If n is large, then we can approximate X ~ B(n, p) using the normal distribution.
As E(X) = np and Var(X) = npq, this means we can use X ~ N(np, npq)
We still need to find a test statistic we can use in our hypothesis test, and as the number in the sample is large, this means that using the binomial distribution will be time consuming and complicated.
This means that for our test statistic we can use.
So our test statistic is the variable we use for our test.
You use the test statistic to work out probabilities you can use as evidence.
This means that we use Z as our test statistic, as we can easily use it to look up probabilities and see how unlikely the results of  our sample are given the claims of  the drug company.
Use the normal to approximate the binomial in our test statistic.
Step 3: Find the critical region Now that we have a test statistic for our test, we need to come up with a critical region.
The critical region also depends on the significance level of  the test.
Let’s choose the same significance level as before, so let’s test at the 5% level.
As our test statistic follows a standard normal distribution, we can use probability tables to find the critical value, c.
The critical value is the boundary between whether we have strong enough evidence to reject the null hypothesis or not.
This means that if  our test statistic is less than -1.64, we have strong enough evidence to reject the null hypothesis.
If the test statistic lies in this region, then there’s enough evidence to reject the null hypothesis.
Decide on the hypothesis you’re going to test Choose your test statistic Determine the critical region for your decision Find the p-value of the test statistic See whether the sample result is within the critical region Make your decision.
Think you can go through the remaining steps of the hypothesis test? See if you can find the following:
Step 4: Find the p-value The critical region is in the lower tail of the distribution.
Step 6: Make your decision Do you accept or reject the null hypothesis based on the evidence?
Think you can go through the remaining steps of the hypothesis test? See if you can find the following:
Step 4: Find the p-value The critical region is in the lower tail of the distribution.
Looking this up in probability tables gives us p-value = 0.0004
The test statistic is on the critical region if the p-value is less than 0.05
As the p-value is equal to 0.0004, this means that the test statistic is within the critical region.
Step 6: Make your decision Do you accept or reject the null hypothesis based on the evidence?
As the test statistic is within the critical region for the hypothesis test, this means that we have sufficient evidence to reject the null hypothesis at the 5% significance level.
SnoreCull failed the test This time when we performed a hypothesis test on SnoreCull, there was sufficient evidence to reject the null hypothesis.
In other words, we can reject the claims made by the drug company.
With a hypothesis test, you accept a claim and then put it on trial.
You only reject it if  there’s enough evidence against it.
This means that the tests are impartial, as you only make a decision based on whether or not there’s sufficient evidence.
If  we had just accepted the doctor’s opinion in the first place, we wouldn’t have properly considered the evidence.
We would have made a decision without considering whether the results could have been explained away by mere coincidence.
As it is, we have enough evidence to show that the results of  the sample are extreme enough to justify rejecting the null hypothesis.
The results are statistically significant, as they’re unlikely to have happened by chance.
So does this guarantee that the claims of  the drug company are wrong?
Shouldn’t we have just accepted the doctor’s opinion in the first place?
We’ve done a hypothesis test, and we’ve used it to prove that the drug company is lying.
Mistakes can happen So far we’ve looked at how we can use the results of  a sample as evidence in a hypothesis test.
If  the evidence is sufficiently strong, then we can use it to justify rejecting the null hypothesis.
We’ve found that there is strong evidence that the claims of  the drug company are wrong, but is this guaranteed?
Even though the evidence is strong, we can’t absolutely guarantee that the drug company claims are wrong.
Even though it’s unlikely, we could still have made the wrong decision.
We can examine evidence with a hypothesis, and we can specify how certain we want to be before rejecting the null hypothesis, but it doesn’t prove with absolute certainty that our decision is right.
Conducting a hypothesis test is a bit like putting a prisoner on trial in front of  a jury.
The jury assumes that the prisoner is innocent unless there is strong evidence against him, but even considering the evidence, it’s still possible for the jury to make wrong decisions.
Have a go at the exercise on the next page, and you’ll see how.
Q: How can we make the wrong decision if we’re conducting a hypothesis test? Don’t we do a hypothesis test to make sure we don’t?
A: When you conduct a hypothesis test, you can only make a decision based on the evidence that you have.
Your evidence is based on sample data, so if the sample is biased, you may make the wrong decision based on biased data.
This is because you test at a certain level of significance.
A prisoner is on trial for a crime, and you’re on the jury.
The jury’s task is to assume the prisoner is innocent, but if there’s enough evidence against him, they need to convict him.
In what ways can the jury make a verdict that’s correct?
In what ways can the jury make a verdict that’s incorrect?
A prisoner is on trial for a crime, and you’re on the jury.
The jury’s task is to assume the prisoner is innocent, but if there’s enough evidence against him, they need to convict him.
In what ways can the jury make a verdict that’s correct?
In what ways can the jury make a verdict that’s incorrect?
The null hypothesis is that the prisoner is innocent, as that is what we have to assume until there’s proof otherwise.
In other words, if there’s sufficient proof that the prisoner is not innocent, then we’ll accept that he’s guilty and convict him.
We can make a correct verdict if: The prisoner is innocent, and we find him innocent.
We can make an incorrect verdict if The prisoner is innocent, and we find him guilty.
The errors we can make when conducting a hypothesis test are the same sort of errors we could make when putting a prisoner on trial.
Hypothesis tests are basically tests where you take a claim and put it on trial by assessing the evidence against it.
If  there’s sufficient evidence against it, you reject it, but if  there’s insufficient evidence against it, you accept it.
You may correctly accept or reject the null hypothesis, but even considering the evidence, it’s also possible to make an error.
You may reject a valid null hypothesis, or you might accept it when it’s actually false.
A Type I error is when you wrongly reject a true null hypothesis, and a Type II error is when you wrongly accept a false null hypothesis.
The power of  a hypothesis test is the probability that that you will correctly reject a false null hypothesis.
So what does putting prisoners on trial have to do with hypothesis testing?
How do you think we can find the probability of making a Type I error? How do you think we can find the probability of making a Type II error?
Let’s start with Type I errors A Type I error is what you get when you reject the null hypothesis when the null hypothesis is actually correct.
It’s like putting a prisoner on trial and finding him guilty when he’s actually innocent.
So what’s the probability of getting a Type I error? If  you get a Type I error, then this means that the null hypothesis must have been rejected.
In order for the null hypothesis to have been rejected, the results of  your sample must be in the critical region.
If you get a Type I error, your test statistic must be here in the critical region.
What about Type II errors? A Type II error is what you get when you accept the null hypothesis, and the null hypothesis is actually wrong.
It’s like putting a prisoner on trial and finding him innocent when he’s actually guilty.
Without this, you can’t calculate the probability of  getting a Type II error.
Find the range of values outside the critical region of your test.
If  your test statistic has been standardized, the range of  values must be de-standardized.
Find the probability of getting this range of values, assuming H1 is true.
Finding errors for SnoreCull Let’s see if  we can find the probability of  getting Type I and Type II errors for the SnoreCull hypothesis test.
Let’s start with the Type I error A Type I error is what you get when you reject the null hypothesis when actually it’s true.
The probability of  getting this sort of  error is the same as the significance level of  the test, so this means that.
So what about the Type II error? A Type II error is what you get when you accept the null hypothesis when the alternate hypothesis is true.
The reason why H1 must specify an exact value for p is so that we can calculate probabilities using it.
If  you need to calculate the probability of  getting a Type II error in an exam, you’ll be given H1
This means that you won’t have to decide on the alternate hypothesis yourself.
If  you need to calculate this sort of  error, it will be given to you.
This gives you the probability of rejecting the null hypothesis that 90% of people are cured when it’s true.
To look up probabilities using the alternate hypothesis probability distribution, we need an exact value for p.
We need to find the range of values Now that the alternate hypothesis H1 gives a specific value for p, we can move on to the next step.
We need to find the values of  X that lie outside the critical region of  the hypothesis test.
In other words, we would have accepted the null hypothesis if  85.08 people or more had been cured by SnoreCull.
We calculate this in the same way we calculate other normal distribution probabilities, by finding the standard score and then looking up the value in standard normal probability tables.
This is the usual way of calculating the standard score; just subtract the expectation, and divide by the standard deviation.
Q: Why is it so much harder to find P(Type II error) than P(Type I error)?
Q: Do I need to use the normal distribution every time I want to find the probability of getting a Type II error?
A: The probability distribution you use all depends on your test statistic.
In this case, our test statistic followed a normal distribution, so that’s the distribution we used to find P(Type II error)
If our test statistic had followed, say, a Poisson distribution, we would have used a Poisson distribution instead.
Introducing power So far we’ve looked at the probability of  getting different types of  error in our hypothesis test.
In other words, it’s the probability that we will make the correct decision to reject H0
I hope it’s not as difficult to find as P(Type II error)
Once you’ve found P(Type II error), calculating the power of a hypothesis test is easy.
So what’s the power of SnoreCull? We’ve found the probability of  getting a Type II error is 0.102
This means that we can find the power of  the SnoreCull hypothesis test by calculating.
In other words, the power of  the SnoreCull hypothesis test is 0.898
This means that the probability that we will make the correct decision to reject the null hypothesis is 0.898
The doctor’s happy In this chapter, you’ve run through two hypothesis tests, and you’ve proved that there’s sufficient evidence to reject the claims made by the drug company.
You’ve been able to show that based on the doctor’s sample, there’s sufficient evidence that SnoreCull doesn’t cure 90% of  snorers, as the drug company claims.
I thought that the claims sounded too good to be true, and you’ve proved that there are strong statistical grounds for showing I’m right.
But it doesn’t stop there Keep reading, and we’ll show you what other sorts of  hypothesis tests you can use.
The drug company and their cough syrup manufacturer are having a dispute.
We’re going to guide you through this exercise in two parts.
Step 1: Decide on the hypothesis you’re going to test.
Does the critical region lie in the lower or upper tail of the distribution? What’s the significance level? What’s the critical value?
Hint: Your hypothesis concerns the mean, so what’s the distribution of X? How do you standardize this?
Step 1: Decide on the hypothesis you’re going to test.
Does the critical region lie in the lower or upper tail of the distribution? What’s the significance level? What’s the critical value?
The drug company and their cough syrup manufacturer are having a dispute.
We’re going to guide you through this exercise in two parts.
Here are the final three steps of the hypothesis test.
Use the distribution Z = (X - 355)/0.5, the mean amount of syrup in the sample, and remember that this time you’re seeing if your test statistic lies in the upper tail of the distribution, as this is where the critical region is.
Step 5: See whether the sample result is within the critical region.
Is there enough evidence to reject the null hypothesis at the 1% level of significance?
Here are the final three steps of the hypothesis test.
Use the distribution Z = (X - 355)/0.5, the mean amount of syrup in the sample, and remember that this time you’re seeing if your test statistic lies in the upper tail of the distribution as this is where the critical region is.
Looking this up in probability tables gives us p-value = 0.0013
Step 5: See whether the sample result is within the critical region.
Is there enough evidence to reject the null hypothesis at the 1% level of significance?
Sometimes things don’t turn out quite the way you expect.
When you model a situation using a particular probability distribution, you have a.
I thought his success with girls would follow a binomial distribution with p = 0.8
Fat Dan’s is used to making a tidy profit from its casino-goers, but this week there’s a problem.
The slot machines keep hitting the jackpot, the roulette wheel keeps landing on 12, the dice are loaded, and too many people are winning off  one of  the blackjack tables.
The casino can’t support the loss for much longer, and Fat Dan suspects foul play.
He needs your help to get to the bottom of  what’s going on.
Let’s start with the slot machines As you’ve seen before, Fat Dan’s Casino has a full row of  bright, shiny slot machines, just waiting to be played.
The trouble is that people keep on playing them—and winning.
Here’s the expected probability distribution for one of  the slot machines, where X represents the net gain from each game played:
The casino has collected statistics showing the number of  times people get each outcome.
Here are the frequencies for the observed net gains per game:
We need to compare the actual frequency of each value of x with what you’d expect the frequency to be based on the probability distribution.
If you hit the jackpot, your net gain is $98
The frequency shows you how many games had which net gain.
We need to compare the actual frequency of each value of x with what you’d expect the frequency to be based on the probability distribution.
Looking at the data, it looks like there might be something going on with the slot machine payouts.
But how can we be certain? It’s unlikely, but this could happen by pure chance.
We need some way of deciding whether these results show the slot machines have been rigged.
What we need is some sort of  hypothesis test that we can use to test the differences between the observed and expected frequencies.
That way, we’ll have some way of  deciding whether the slot machines have been tampered with to make sure they keep paying out lots of  money.
The question is, what sort of  distribution can we use for this hypothesis test?
There’s a difference between the number of people you’d expect to win the jackpot, based on the probability distribution, and the number of people actually winning it.
What we don’t know is how significant these differences are.
To find the test statistic, first make a table featuring the observed and expected frequencies for your problem.
When you’ve done that, use your observed and expected frequencies to compute the following statistic, where O stands for the observed frequency, and E for the expected frequency:
Use the table of observed and expected frequencies you just worked out on the previous page for Fat Dan’s slot machines to compute the test statistic.
What do you think a low value tells you? What about a high value?
In other words, for each probability in the probability distribution, you take the difference between the frequency you expect and the frequency you actually get.
You square the result, divide by the expected frequency, and then add all of  these results up together.
So what’s the test statistic for the slot machine problem?
Use the table of observed and expected frequencies you just worked out on the previous page for Fat Dan’s slot machines to compute the test statistic.
What do you think a low value tells you? What about a high value?
You divide by E, the expected frequency, as this makes the result proportional to the expected frequency.
The smaller the differences between O and E, the smaller X2 is.
Dividing by E makes the difference proportional to the expected frequency.
If the value of X2 is low, then this means there’s a less significant difference between the observed and expected frequencies.
The higher X2 is, the more significant the differences become.
First of  all, it’s used to test goodness of  fit.
This means that you can use it to test how well a given set of  data fits a specified distribution.
As an example, we can use it to test how well the observed frequencies for the slot machine winnings fits the distribution we expect.
Here’s another look at the table of  observed and expected frequencies for the slot machines:
The number of  degrees of  freedom is the number of  expected frequencies we have to calculate, taking into account any restrictions we have upon us.
Another way of  looking at this is that we had to calculate four of  the expected frequencies using the probability distribution.
We could work out the final frequency by looking at what the total expected frequency should be.
Decide on the hypothesis you’re going to test, and its alternative.
See whether the test statistic is within the critical region.
Look familiar? Most of  these steps are exactly the same as for other hypothesis tests.
In other words, it’s exactly the same process as before.
You go through pretty much all the steps you had to go through before.
Q: Do I always use the upper tail for my test?
Q: I think I’ve heard the term degrees of freedom before.
Remember when we looked at how we can use the t-distribution to create confidence intervals? Well, the t-distribution uses degrees of freedom, too.
These steps are just like the ones we had before.
These steps are different from the ones you saw before.
It’s your job to see whether there’s sufficient evidence at the 5% level to say that the slot machines have been rigged.
What’s the null hypothesis you’re going to test? What’s the alternate hypothesis?
Is your test statistic inside or outside the critical region?
It’s your job to see whether there’s sufficient evidence at the 5% level to say that the slot machines have been rigged.
What’s the null hypothesis you’re going to test? What’s the alternate hypothesis?
Is your test statistic inside or outside the critical region?
H0: The slot machine winnings per game follow the described probability distribution.
H1: The slot machine winnings per game do not follow this probability distribution.
The value of X2 is inside the critical region, so this means that we reject the null hypothesis.
In other words, there is sufficient evidence to reject the hypothesis that the slot machine winnings follow the described probability distribution.
Let’s summarize the steps you went through to discover this.
Your test statistic fell in the critical region, so you could reject the null hypothesis.
This sort of  hypothesis test is called a goodness of  fit test.
It tests whether observed frequencies actually fit in with an assumed probability distribution.
You use this sort of  test whenever you have a set of  values that should fit a distribution, and you want to test whether the data actually does.
Fat Dan thinks that the dice in the dice games are loaded.
Take a look at the following observed frequencies for one six-sided die, and test whether there’s enough evidence to support the claim that the die isn’t fair at the 1% significance level.
Step 1: Decide on the hypothesis you’re going to test, and its alternative.
Step 2: Find the expected frequencies and the degrees of freedom.
Start off by completing the expected frequencies for the die.
You’ll need to take into account how many times the die is thrown in total, and the probability of getting each value.
Once you’ve found the expected frequencies, what are the number of degrees of freedom?
You find this the same way you found the degrees of freedom for the slot machines.
You’ll need to use the significance level and number of degrees of freedom.
Step 5: See whether the test statistic is within the critical region.
Fat Dan thinks that the dice in the dice games are loaded.
Take a look at the following observed frequencies for one six-sided die, and test whether there’s enough evidence to support the claim that the die isn’t fair at the 1% significance level.
Step 1: Decide on the hypothesis you’re going to test, and its alternative.
To test whether the die is fair, we have to determine whether there’s sufficient evidence that it isn’t.
This gives you H0: The die is fair, and every value has an equal chance of being thrown.
This means the probability of getting each value is 1/6
Step 2: Find the expected frequencies and the degrees of freedom.
Start off by completing the expected frequencies for the die.
You’ll need to take into account how many times the die is thrown in total, and the probability of getting each value.
Once you’ve found the expected frequencies, what are the number of degrees of freedom?
You’ll need to use the significance level and number of degrees of freedom.
Step 5: See whether the test statistic is within the critical region.
As your test statistic lies within the critical region, this means that there is sufficient evidence at the 1% level to reject the null hypothesis.
In other words, you accept the alternate hypothesis that the die isn’t fair.
Fat Dan has another problem So far you’ve investigated whether the slot machines seem to be rigged in some way, by using a goodness of  fit test to see whether the observed frequencies you have correspond to the expected probability distribution.
Fat Dan has other problems, though, and this time it’s his staff.
Fat Dan thinks he’s losing more money than he should from one of  the croupiers on the blackjack tables.
Can you determine whether there’s significant evidence to show whether or not Fat Dan’s right?
What we need is some way of  testing whether the outcome of  the game is dependent on which croupier is leading the game.
What do you need to know in order to test this hypothesis?
These are the outcomes you get for each of the games.
Now hold it right there! I think you’re missing something.
How can we work out the expected frequencies? All we have to go on is the observed frequencies the actual game outcomes.
There are a few steps you need to go through to find the expected frequencies.
To start off, calculate the total frequencies for the outcomes and the croupiers, and also the grand total.
You can show the results in a table like this, called a contingency table.
Now we can use this information to find the expected number of  wins for each croupier.
Let’s start by finding the expected frequency for the number of  wins with croupier A.
First off, we can use these grand totals to find the probability of  getting a particular outcome, or a particular croupier.
As an example, to find the probability of  winning, you divide the total number of  wins by the grand total:
Now if  the croupier and the outcome of  the game are independent, as we assume they are, this means that you can find the probability of  getting a win with croupier A by multiplying together these two probabilities.
How can we use this to find the expected number of wins for croupier A?
Similarly, you can find the probability of  playing against croupier A by dividing the total for croupier A by the grand total.
So what are the frequencies? So far, we’ve found that the probability of  winning with croupier A, and we want to use this to find the expected frequency of  wins.
To do this, all we just need to multiply the probability of  winning with croupier A by the grand total.
In other words, to find the expected frequency of  wins with croupier A, multiply the total number of  wins by the total number of  games with croupier A, and divide by the grand total.
How do we find the frequencies in general? You can generalize this so that you have a nice, easy result you can apply to every frequency you need to find.
To find the expected frequency for a particular row and column combination, multiply the total for the row by the total for the column, and divide by the grand total.
The key is to ensure you include every observed frequency and every corresponding expected frequency.
For every observed frequency, subtract the expected frequency, square the result, and divide by the expected frequency.
Here’s the table showing the observed frequencies for the croupiers.
Your task is to figure out all the expected frequencies.
Use the values in the first two columns to help you calculate this.
Here’s the table showing the observed frequencies for the croupiers.
Your task is to figure out all the expected frequencies.
You saw earlier that the number of  degrees of  freedom is the number of  pieces of  independent information we are free to choose, taking into account any restrictions.
This means that we look at how many expected frequencies we have to calculate independently, and subtract the number of  restrictions.
Now for each row and for each column, we only actually had to calculate two of the expected frequencies.
We knew what the total frequency should be, so we could choose the third to make sure that the frequencies added up to the right result.
We only had to calculate these expected frequencies - we could figure out the others using the total frequency of each row and column.
We could figure the last row and column out using the totals.
Step 1: We want to test whether the outcome of the game is independent of the croupier manning the table.
This means we can use: H0: There is no relationship between the outcome of the game and the croupier manning the table.
H1: There is a relationship between the outcome of the game and the croupier manning the table.
There is insufficient evidence that there’s a relationship between game outcome and croupier.
Take a look at how we calculated the degrees of freedom for a 3x3 table.
How do you think we could generalize this? See if you can work this out, then turn the page.
Q: I’m still not sure I understand how you found the degrees of freedom for the croupiers.
Just as with other hypothesis tests, the smaller the level of significance, the stronger you need your evidence to be before you reject your null hypothesis.
I wonder what happens if you have a different size contingency table? How do you find the number of degrees of freedom then?
Imagine you’re comparing two variables, and you have h rows of  one variable and k columns of  another.
You know what the row and column totals should be.
Now imagine you want to find the number of  degrees of  freedom.
You know what the total of  each row should be, so you only actually need to calculate the expected frequency of (k – 1) of  the columns.
You automatically know what the kth column is because you know the total frequency of  the row.
You can figure out column k using the row total.
Each column has h rows, and you know what the total of  each column should be.
This means that you have to calculate (h – 1) of  the rows for each column.
You automatically know what the value of  the hth row is because you know the total frequency of  the column.
You need to calculate the frequencies of these h-1 rows.
You can figure out row h using the column total.
What are the degrees of freedom now? The outcomes of the game remain the same.
What are the degrees of freedom now? The outcomes of the game remain the same.
A, B, and C are the original croupiers, and Fat Dan has hired two more.
Thanks to you, he knows which of his casino games need to be investigated, and the blackjack croupiers get to keep their jobs.
Next time you’re in town, tell Fat Dan—he’ll supply you with extra chips, all on the house.
Fat Dan’s promised you a bunch of casino chips on the house!
Fat Dan thinks that one or more of his croupiers are somehow influencing the results of the roulette wheel.
Here’s data showing the observed frequency with which the ball lands in each color pocket for each of the croupiers.
Conduct a test at the 5% level to see whether pocket color and croupier are independent, or whether there is sufficient evidence to show there might be something going on.
Step 1: Decide on the hypothesis you’re going to test, and its alternative.
Step 2: Find the expected frequencies and the degrees of freedom.
Hint: Complete the row and column totals first these are the same as for the observed frequencies above.
Step 5: See whether the test statistic is within the critical region.
Fat Dan thinks that one or more of his croupiers are somehow influencing the results of the roulette wheel.
Here’s data showing the observed frequency with which the ball lands in each color pocket for each of the croupiers.
Conduct a test at the 5% level to see whether pocket color and croupier are independent, or whether there is sufficient evidence to show there might be something going on.
Step 1: Decide on the hypothesis you’re going to test, and its alternative.
You want to test whether or not pocket color is independent of croupier.
This gives H0: Roulette wheel pocket color and croupier are independent.
Step 2: Find the expected frequencies and the degrees of freedom.
You find the expected frequencies by multiplying each row and column total, and dividing by the grand total.
Step 5: See whether the test statistic is within the critical region.
As your test statistic lies outside the critical region, this means that there is insufficient evidence at the 5% level to reject the null hypothesis.
In other words, you accept the null hypothesis that pocket color and croupier are independent.
What’s My Line? The more I use this sandpaper, the less chance there is of him noticing my stubble.
Stay with us while we show you the key to spotting connections:
Never trust the weather Concerts are best when they’re in the open air—at least that’s what these groovy guys think.
They have a thriving business organizing open-air concerts, and ticket sales for the summer look promising.
Today’s concert looks like it will be one of  their best ones ever.
The band has just started rehearsing, but there’s a cloud on the horizon...
Sweet! But is that a rain cloud I see up there?
Before too long the sky’s overcast, temperatures are dipping, and it looks like rain.
The guys are in trouble, and they can’t afford for this to happen again.
What the guys want is to be able to predict what concert attendance will be given predicted hours of  sunshine.
That way, they’ll be able to gauge the impact an overcast day is likely to have on attendance.
If it looks like attendance will fall below 3,500 people, the point where ticket sales won’t cover expenses, then they’ll cancel the concert.
We can find the mean and standard deviation and look at the distribution.
Let’s analyze sunshine and attendance Here’s sample data showing the predicted hours of  sunshine and concert attendance for different events.
How can we use this to estimate ticket sales based on the predicted hours of  sunshine for the day?
Most of the time, that’s exactly the sort of thing we’d need to do to predict likely outcomes.
The problem this time is, what would we find the mean and standard deviation of ? Would we use the concert attendance as the basis for our calculations, or would we use the hours of  sunshine? Neither one of  them gives us all the information that we need.
Instead of  considering just one set of data, we need to look at both.
So far we’ve looked at independent random variables, but not ones that are dependent.
We can assume that if  the weather is poor, the probability of  high attendance at an open air concert will be lower than if  the weather is sunny.
But how do we model this connection, and how do we use this to predict attendance based on hours of  sunshine?
How would you go about modelling the connection between sets of data?
Exploring types of data Up until now, the sort of  data we’ve been dealing with has been univariate.
Univariate data concerns the frequency or probability of  a single variable.
As an example, univariate data could describe the winnings at a casino or the weights of brides in Statsville.
What univariate data can’t do is show you connections between sets of  data.
For example, if  you had univariate data describing the attendance figures at an open air concert, it wouldn’t tell you anything about the predicted hours of  sunshine on that day.
So what if  we do need to know what the connection is between variables? While univariate data can’t give us this information, there’s another type of  data that can—bivariate data.
Univariate data for concert attendance tells you nothing about the hours of sunshine.
All about bivariate data Bivariate data gives you the value of  two variables for each observation, not just one.
As an example, it can give you both the predicted hours of  sunshine and the concert attendance for a single event or observation, like this.
Bivariate data gives you the value of two variables for each observation.
If  one of  the variables has been controlled in some way or is used to explain the other, it is called the independent or explanatory variable.
The other variable is called the dependent or response variable.
In our example, we want to use sunshine to predict attendance, so sunshine is the independent variable, and attendance is the dependent.
Visualizing bivariate data Just as with univariate data, you can draw charts for bivariate data to help you see patterns.
Instead of  plotting a value against its frequency or probability, you plot one variable on the x-axis and the other variable against it on the y-axis.
This helps you to visualize the connection between the two variables.
This sort of  chart is called a scatter diagram or scatter plot, and drawing one of  these is a lot like drawing any other sort of  chart.
Start off  by drawing two axes, one vertical and one horizontal.
Use the x-axis for one variable and the y-axis for the other.
The independent variable normally goes along the x-axis, leaving the dependent variable to go on the y-axis.
Once you’ve drawn your axes, you then take the values for each observation and plot them on the scatter plot.
Here’s a scatter plot showing the number of  hours of  sunshine and concert attendance figures for particular events or observations.
As the predicted number of  hours sunshine is the independent variable, we’ve plotted it on the x-axis.
The concert attendance is the dependent variable, so that’s on the y-axis.
Can you see how the scatter diagram helps you visualize patterns in the data? Can you see how this might help us to define the connection between open air concert attendance and predicted number of  hours sunshine for the day?
Hours sunshine goes on the x-axis, attendance on the y-axis.
We know we haven’t shown you how to analyze bivariate data yet, but see how far you get in analyzing the scatter diagram for the concert organizers.
What sort of patterns do you see in the chart? How can you relate this to the underlying data? What do you expect open air concert attendance to be like if it’s sunny? What about if it’s overcast?
The Case of  the High Sunscreen Sales An intern at a sunscreen manufacturer has been given the task of looking at sunscreen sales in order to see how they can best market their particular brand.
He’s been given a pile of  generated scatter diagrams that model sunscreen sales against various other factors.
The first diagram that the intern finds plots sunscreen sales for the day against pollen count.
When the sales team hears his suggestion, they look at him blankly.
We know we haven’t shown you how to analyze bivariate data yet, but see how you get on with analyzing the scatter diagram for the concert organizers.
What sort of patterns do you see in the chart? How can you relate this to the underlying data? What do you expect open air concert attendance to be like if it’s sunny? What about if it’s overcast?
First of all, the chart shows that the data points are clustered around a straight line on the chart, and this line slopes upwards.
It looks like, if the predicted number of hours of sunshine in a day is relatively low, then the concert attendance is low too.
If the number of hours sunshine is high, then we can expect concert attendance to be high too.
This basically means that the sunnier the weather, the more people you can expect to go to the open air concert.
One thing that’s important to note is that we can only be confident about saying this within the range of the data.
Scatter diagrams show you patterns As you can see, scatter diagrams are useful because they show the actual pattern of  the data.
They enable you to more clearly visualize what connection there is between two variables, if  indeed there’s any connection at all.
The scatter diagram for the concert data shows a distinct patternthe data points are clustered along a straight line.
Positive linear correlation Positive linear correlation is when low values on the x-axis correspond to low values on the y-axis, and higher values of x correspond to higher values of  y.
In other words, y tends to increase as x increases.
Negative linear correlation Negative linear correlation is when low values on the x-axis correspond to high values on the y-axis, and higher values of x correspond to lower values of  y.
In other words, y tends to decrease as x increases.
No correlation If  the values of  x and y form a random pattern, then we say there’s no correlation.
You can identify correlations on a scatter diagram by the distinct patterns they form.
The correlation is said to be linear if  the scatter diagram shows the points lying in an approximately straight line.
Let’s take a look at a few common types of  correlation between two variables:
The points plotted for x and y are centered around a straight line.
This chart shows a random pattern, so there’s no correlation.
So if there’s a correlation, does that mean one of the variables caused the value of the other?
A correlation between two variables doesn’t necessarily mean that one caused the other or that they’re actually related in real life.
A correlation between two variables means that there’s some sort of mathematical relationship between the two.
This means that when we plot the values on a chart, we can see a pattern and make predictions about what the missing values might be.
What we don’t know is whether there’s an actual relationship between the two variables, and we certainly don’t know whether one caused the other, or if  there’s some other factor at work.
As an example, suppose you gather data and find that over time, the number of  coffee shops in a particular town increases, while the number of  record shops decreases.
While this may be true, we can’t say that there is a real-life relationship between the number of  coffee shops and the number of  record shops.
In other words, we can’t say that the increase in coffee shops caused the decline in the record shops.
What we can say is that as the number of  coffee shops increases, the number of  record shops decreases.
One of  the sales team members walks over to the intern.
Thanks for the idea,” she says, “but we’re not going to use it in our advertising.
That’s true,” says the salesperson, “but that doesn’t mean that the high pollen count has caused the high sales.
The days when the pollen count is high are generally days when the weather is sunny, so people are going outside more.
Q: So are we saying that the predicted sunshine causes low ticket sales?
A: The bivariate data shows that there is a mathematical relationship between the two variables, but we can’t use it to demonstrate cause and effect.
It’s intuitively possible that more people will go to open air concerts when it’s sunny, but we can’t say for certain that sunshine causes this.
We’d need to do more research, as there may be other factors.
Q: Other factors? Like what? A: One example would be the popularity of the artist performing.
If a well-known artist is holding a concert, then fans may want to go to the concert no matter what the weather.
Similarly, an unpopular artist is unlikely to have the same dedication from fans.
Q: Do scatter diagrams use populations or samples of data? A: They can use either.
A lot of the time, you’ll actually be using samples, but the process of plotting a scatter diagram is the same irrespective of whether you have a sample or a population.
Q: If there’s a correlation between two variables, does it have to be linear?
A: Correlation measures linear relationships, but not all relationships are linear.
As an example, a strong relationship between two variables could be a distinctive curve, such as y = x2
In this chapter, we’re only going to be dealing with linear relationships, though.
Far out, dude, I’m liking the way the sunshine and attendance connect.
But hold on, man! How can we predict concert attendance based on predicted sunshine? If the concert attendance drops below 3,500, we’ll have to bail out, and that’d be a burn.
We need to predict the concert attendance So far we’ve looked at what bivariate data is, and how scatter diagrams can show whether there’s a mathematical relationship between the two variables.
What we haven’t looked at yet is how we can use this to make predictions.
What we need to do next is see how we can use the data to make predictions for concert attendance, based on predicted hours of  sunshine.
How do you think we could go about making predictions like this for bivariate data?
A line of best fit? And you just guess what the line is based on what looks good to you? That’s hardly scientific.
Drawing the line in this way is just a best guess.
The trouble with drawing a line in this way is that it’s an estimate, so any predictions you make on the basis of  it can be suspect.
You have no precise way of  measuring whether it’s really the best fitting line.
It’s subjective, and the quality of  the line’s fit depends on your judgment.
Predict values with a line of best fit So far you’ve seen how scatter diagrams can help you see whether there’s a correlation between values, by showing you if  there’s some sort of  pattern.
But how can you use this to predict concert attendance, based on the predicted amount of  sunshine? How would you use your existing scatter diagram to predict the concert attendance if  you know how many hours of sunshine are expected for the day?
One way of  doing this is to draw a straight line through the points on the scatter diagram, making it fit the points as closely as possible.
You won’t be able to get the straight line to go through every point, but if  there’s a linear correlation, you should be able to make sure every point is reasonably close to the line you draw.
Doing this means that you can read off  an estimate for the concert attendance based on the predicted amount of  sunshine.
You can use the line to estimate concert attendance for a certain number of hours predicted sunshine.
The line that best fits the data points is called the line of  best fit.
Your best guess is still a guess Imagine if  you asked three different people to draw what each of  them think is the line of  best fit for the open air concert data.
It’s quite likely that each person would come up with a slightly different line of  best fit, like this:
All three lines could conceivably be a line of  best fit for the data, but what we can’t tell is which one’s really best.
What we really need is some alternative to drawing the line of  best fit by eye.
Instead of  guessing what the line should be, it will be more reliable if  we had a mathematical or statistical way of  using the data we have available to find the line that fits best.
We need to find the equation of the line The equation for a straight line takes the form y = a + bx, where a is the point where the line crosses the y-axis, and b is the slope of  the line.
This means that we can write the line of  best fit in the form y = a + bx.
In our case, we’re using x to represent the predicted number of hours of  sunshine, and y to represent the corresponding open air concert figures.
If  we can use the concert attendance data to somehow find the most suitable values of  a and b, we’ll have a reliable way to find the equation of  the line, and a more reliable way of  predicting concert attendance based on predicted hour of sunshine.
We need to minimize the errors Let’s take a look at what we need from the line of  best fit, y = a + bx.
The best fitting line is the one that most accurately predicts the true values of all the points.
This means that for each known value of  x, we need each of the y variables in the data set to be as close as possible to what we’d estimate them to be using the line of  best fit.
In other words, given a certain number of  hours sunshine, we want our estimates for open air concert attendance to be as close as possible to the actual values.
The line of  best fit is the line y = a + bx that minimizes the distances between the actual observations of  y and what we estimate those values of  y to be for each corresponding value of  x.
Let’s represent each of  the y values in our data set using yi, and its estimate using the line of  best fit as yi.
This is the same notation that we used for point estimators in previous chapters, as the ^ symbol indicates estimates.
We want to minimize the total distance between each actual value of  y and our estimate of  it based on the line of  best fit.
In other words, we need to minimize the total differences between yi and yi.
We need to take a slightly different approach, and it’s one that we’ve seen before.
These are the values we predict based on the line of best fit.
If we can find the line tha t minimizes all the.
These are the actual and estimated values of y for the same value of x.
The variance uses squared distances from the mean, and the SSE uses squared distances from the line.
The SSE isn’t the variance, but it does deal with the distance squared between two particular points.
It gives the total of  the distances squared between the actual value of  y and what we predict the value of  y to be, based on the line of  best fit.
What we need to do now is use the data to find the values of  a and b that minimize the SSE, based on the line y = a + bx.
Introducing the sum of squared errors Can you remember when we first derived the variance? We wanted to look at the total distance between sets of  values and the mean, but the total distances cancelled each other out.
To get around this, we added together all the distances squared instead to ensure that all values were positive.
Instead of  looking at the total distance between the actual and expected points, we need to add together the distances squared.
That way, we make sure that all the values are positive.
The total sum of  the distances squared is called the sum of  squared errors, or SSE.
In other words, we take each value of  y, subtract the predicted value of  y from the line of  best fit, square it, and then add all the results together.
Let’s start with b The value of  b for the line y = a + bx gives us the slope, or steepness, of the line.
In other words, b is the slope for the line of  best fit.
Let’s take a look at how you use this in practice.
This bit’s similar to how you find the variance of x.
For each value of x, subtract the mean of the x values and square the result.
If  you need to calculate this in an exam, you will almost certainly be given the formula.
This means that you won’t have to memorize the formula, just know how to use it.
Let’s see if  we can use this to find the slope of  the line y = a + bx for the concert data.
Let’s start by finding the values of  x and y, the sample means of  the x and y values.
We calculate these in exactly the same way as before, so.
Now that we’ve found x and y, we can use them to help us find the value of  b using the formula on the opposite page.
Finding the slope for the line of best fit, part ii Here’s a reminder of  the data for concert attendance and predicted hours of  sunshine:
In other words, the line of  best fit for the data is y = a + 5.32x.
Q: It looks like the formulas you’ve given are for samples rather than populations.
Q: Is the value of b always positive? A: No, it isn’t.
Whether b is positive or negative actually depends on the type of linear correlation.
A: Gradient is another term for the slope of the line, b.
Q: What about if there’s no correlation? Can I still work out b?
A: If there’s no correlation, you can still technically find a line of best fit, but it won’t be an effective model of the data, and you won’t be able to make accurate predictions using it.
A: Calculating b is tricky if you have lots of observations, but you can get software packages to calculate this for you.
Note, we don’t use y or y in this part of the equation.
We’ve found b, but what about a? So far we’ve found what the optimal value of  b is for the line of  best fit y = a + bx.
What we don’t know yet is the value of  a.
I’m sure we’d be able to find a if we knew one of the points it should go through.
It’s good for the line of  best fit to go through the the point (x, y), the means of  x and y.
We can make sure this happens by substituting x and y into the equation for the line y = a + bx.
This means that the line of  best fit is given by.
If  you’re taking a statistics exam, it’s likely you’ll be given this formula.
This means that you’re unlikely to have to memorize it, you just need to know how to use it.
The mathematical method we’ve been using to find the line of  best fit is called least squares regression.
Least squares regression is a mathematical way of  fitting a line of  best fit to a set of  bivariate data.
It’s a way of  fitting a line y = a + bx to a set of  values so that the sum of  squared errors is minimizedin other words, so that the distance between the actual values and their estimates are minimized.
To perform least squares regression on a set of  data, you need to find the values of  a and b that best fit the data points to the line y = a + bx and minimizes the SSE.
Once you’ve found the line of  best fit, y = a + bx, you can use it to predict the value of  y, given a value b.
To do this, just substitute your x value into the equation y = a + bx.
The line y = a + bx is called the regression line.
When you’re predicting values of y for a particular value of x, be wary of predicting values that fall outside the area you have data points for.
Linear regression is just an estimate based on the information you have, and it shows the relationship between the data points you know about.
This doesn’t mean that it applies well beyond the limits of the data.
We’ve found an equation for the regression line, so now the concert organizers have a couple of questions for you.
The predicted amount of sunshine on the day of the next concert is 6 hours.
If concert attendance looks like it’s dropping below 3,500, the concert organizers won’t make a profit and will have to cancel the concert.
The predicted amount of sunshine on the day of the next concert is 6 hours.
If concert attendance looks like it’s dropping below 3,500, the concert organizers won’t make a profit and will have to cancel the concert.
We’ve found an equation for the regression line, so now the concert organizers have a couple of questions for you.
We need to find the corresponding prediction for concert attendance, so this means we need to find y for this value of x.
This time, we want to find the value of x for a particular value of y.
Why do you think it’s important to know the strength of the correlation? What difference do you think this would make to the concert organizers?
You’ve made the connection So far you’ve used linear regression to model the connection between predicted hours of  sunshine and concert attendance.
Once you know what the predicted amount of  sunshine is, you can predict concert attendance using y = a + bx.
Being able to predict attendance means you’ll be able to really help the concert organizers know what they can expect ticket sales to be, and also what sort of  profit they can reasonably expect to make from each event.
It’s the line of best fit, but we don’t know how accurate it is.
The line y = a + bx is the best line we could have come up with, but how accurately does it model the connection between the amount of  sunshine and the concert attendance? There’s one thing left to consider, the strength of  correlation of  the regression line.
What would be really useful is if  we could come up with some way of indicating how far the points are dispersed away from the line, as that will give an indication of  how accurate we can expect our predictions to be based on what we already know.
Accurate linear correlation For this set of  data, the linear correlation is an accurate fit of  the data.
The regression line isn’t 100% perfect, but it’s very close.
It’s likely that any predictions made on the basis of  it will be accurate.
Let’s look at some correlations The line of  best fit of  a set of  data is the best line we can come up with to model the mathematical relationship between two variables.
Even though it’s the line that fits the data best, it’s unlikely that the line will fit precisely through every single point.
Let’s look at some different sets of  data to see how closely the line fits the data.
Both sets of  data have a regression line, but the actual fit of  the data varies quite a lot.
For the first set of  data, the correlation is very tight, but for the second, the points are scattered too widely for the regression line to be useful.
Least squares estimates can be used to predict values, which means they would be helpful if  there was some way of  indicating how tightly the data points fit the line, and how accurate we can expect any predictions to be as a result.
There’s a way of  calculating the fit of  the line, called the correlation coefficient.
No linear correlation For this set of  data, there is no linear correlation.
It’s possible to calculate a regression line using least squares regression, but any predictions made are unlikely to be accurate.
It’s a way of  gauging how well the regression line fits the data.
If  r is -1, the data is a perfect negative linear correlation, with all of  the data point in a straight line.
If  r is 1, the data is a perfect positive linear correlation.
If  r is negative, then there’s a negative linear correlation between the two variables.
The closer r gets to -1, the stronger the correlation, and the closer the points are to the line.
If  r is positive, then there’s a positive linear correlation between the variables.
The closer r gets to 1, the stronger the correlation.
In general, as r gets closer to 0, the linear correlation gets weaker.
The pattern might be random, or the relationship between the variables might not be linear.
If  we can calculate r for the concert data, we’ll have an idea of  how accurately we can predict concert attendance based on the predicted hours of  sunshine.
So how do we calculate r? Turn the page and we’ll show you how.
I say how strong the correlation is between the two variables.
The correlation coefficient measures how well the line fits the data.
We’re not going to show you the proof  for this, but the correlation coefficient r is given by.
We use the value of b to help us calculate r.
Since we’ve already calculated b, all we have left to find is sx and sy.
What’s more, we’re already most of  the way towards finding sx.
This is the standard deviation of the x values in the sample, it’s the same formula you’ve seen before.
The only remaining piece of  the equation we have to find is sy, the standard deviation of  the y values in the sample.
We calculate this in a similar way to finding sx.
Let’s try finding what r is for the concert attendance data.
This is the standard deviation of the x values in the.
Find r for the concert data Let’s use the formula to find the value of  r for the concert data.
To find r, we need to know the values of  b, sx, and sy so that we can use them in the formula on the opposite page.
The only piece of  the formula we have left to find is sy.
We already know that y = 38.875, as we found it earlier on, so this means that.
We can now use this to find sy , by dividing by n - 1 and taking the square root.
All we need to do now is use b, sx, and sy to find the value of  the correlation coefficient r.
This is the slope of the line we found earlier.
Finally, we use the y values in the sample to find sy, the standard deviation of y.
A: There are several different forms of the equation for finding r, but underneath, they’re basically the same.
We’ve used the simplest form of the equation so that it’s easier to see what you’ve already calculated through finding b.
Q: Are the results accurate with such a small sample?
A: A larger sample would definitely be better, but we used a small sample just to make the calculations easier to follow.
Q: You haven’t proved or derived why you calculate the values of b and r in this way.
A: Deriving the formula for b and r is quite complex and involved, so we’ve decided not to go through this in the book.
The key thing is that you understand when and how to use them.
Q: What’s the expected concert attendance if the predicted hours of sunshine is 0?
A: We can’t say for certain because this is quite a way outside the range of data we have.
The line of best fit is a pretty good estimate for the range of data that we have, but we can’t say with any certainty what the concert attendance will be like outside this range.
The data might follow a different pattern outside this range, so any estimate we gave would be unreliable.
Q: When we were looking at averages, we saw that univariate data can have outliers.
Outliers are points that lie a long way from your regression line.
If you have outliers, then this can mean that you have anomalies in your data set, or alternatively, that your regression line isn’t a good fit of the data.
A: Influential observations are points that lie a long way horizontally from the rest of the data.
Because of this, they have the effect of pulling the regression line towards them.
Q: So is an influential observation the same as an outlier?
Influential observations lie a long way horizontally from the data.
As r is very close to 1, this means that there’s strong positive correlation between open air concert attendance and hours of  predicted sunshine.
Awesome, dude, you rock! Here’s a free ticket for our next event.
You’ve saved the day! The concert organizers are amazed at the work you’ve done with their concert data.
They now have a way of  predicting what attendance will be like at their concerts based on the weather reports, which means they have a way of  maximizing their profits.
The evil Swindler has been collecting data on the effect radiation exposure has on Captain Amazing’s super powers.
Here is the number of minutes of exposure to radiation, paired with the number of tons Captain Amazing is able to lift:
Your job is to use least squares regression to find the line of best fit, and then find the correlation coefficient to describe the strength of the relationship between your line and the data.
If Swindler exposes Captain Amazing to radiation for 5 minutes, what weight do you expect Captain Amazing to be able to lift?
The evil Swindler has been collecting data on the effect radiation exposure has on Captain Amazing’s super powers.
Here is the number of minutes of exposure to radiation, paired with the number of tons Captain Amazing is able to lift:
Your job is to use least squares regression to find the line of best fit, and then find the correlation coefficient to describe the strength of the relationship between your line and the data.
If Swindler exposes Captain Amazing to radiation for 5 minutes, what weight do you expect Captain Amazing to be able to lift?
It does not mean that one variable causes the other.
A linear correlation is one that follows a straight line.
Positive linear correlation is when low x values correspond to low y values, and high x values correspond to high y values.
Negative linear correlation is when low x values correspond to high y values, and high x values correspond to low y values.
If the values of x and y form a random pattern, then there’s no correlation.
The line that best fits the data points is called the line of best fit.
Linear regression is a mathematical way of finding the line of best fit, y = a + bx.
The slope of the line y = a + bx is.
If r = -1, there is perfect negative linear correlation.
If r = 1, there is perfect positive linear correlation.
We’re sad to see you leave, but there’s nothing like taking what you’ve learned and putting it to use.
There are just a few more things we think you need to know.
We wouldn’t feel right about ignoring them, even though they only need a brief mention, and we really wanted to.
There are just a few more things we think you need to know.
We wouldn’t feel right about ignoring them, even though they only need a brief mention, and we really wanted to.
Other ways of presenting data We showed you a number of  charts in the first chapter, but here are a couple more that might come in useful.
If your data’s quantitive, dotplots show you the shape of your data.
Stemplots A stemplot is used for quantitive data, usually when your data set is fairly small.
Stemplots show each exact value in your data set in such a way that you can easily see the shape of  your data.
You stack them in a column above the value on the horizontal axis.
The entries on the left are called stems, and the entries on the right are called leaves.
In this stemplot, the stem shows tens, and the leaves show units.
To find each value in the raw data, you take each leaf  and add it to its stem.
There’s usually a key to help you interpret the stemplot correctly.
Dotplots A dotplot shows your data on a chart by representing each value as a dot.
You put each dot in a stacked column above the corresponding value on the horizontal axis like this:
A stemplot has a shape that is similar to a histogram’s, but flipped onto its side.
Distribution anatomy There are two rules that tell you where most of  your data values lie in a probability distribution.
Chebychev’s rule isn’t as precise as the empirical rule, as it only gives you the minimum percentages, but it still gives you a rough idea of  where values fall in the probability distribution.
The advantage of  Chebyshev’s rule is that it applies to any distribution, while the empirical rule just applies to the normal distribution.
The empirical rule for normal distributions The empirical rule applies to any set of  data that follows a normal distribution.
It states that almost all of  the values lie within three standard deviations of  the mean.
Chebyshev’s rule for any distribution A similar rule applies to any set of  data called Chebyshev’s rule, or Chebyshev’s inequality.
Just knowing the number of  standard deviations from the mean can give you a rough idea about the probability.
Experiments Experiments are used to test cause and effect relationships between variables.
As an example, an experiment could test the effect of  different doses of  SnoreCull on snorers.
In an experiment, indpendent variables or factors are manipulated so that we can see the effect on dependent variables.
As an example, we might want to examine the effect that different doses of  SnoreCull have on the number of  hours spent snoring in a night.
The doses of  SnoreCull would be the independent variable, and the number of hours spent snoring would be the dependent variable.
The subjects that you use for your experiment are called experimental units—in this case, snorers.
So what makes for a good experiment? There are three basic principles you need to bear in mind when you design an experiment: controls, randomization, and replication.
Just as with sampling, a key aim is to minimize bias.
You need to control the effects of external influences or natural variability.
When you conduct an experiment, you need to minimize effects that are not part of  the experiment.
To do this, the first thing is to have a control group, a neutral group that receives no treatments, or only neutral treatments.
You can assess the effectiveness of  the treatment by comparing the results of  your treated groups with the results of  your control group.
A placebo is a neutral treatment, one that has no effect on the dependent variable.
Sometimes the subjects of  your experiment can respond differently to having a neutral treatment as opposed to having no treatment at all, so giving a placebo to a group is a way of  controlling this effect.
If the group taking a placebo doesn’t know that it’s a placebo, then this is called blinding, and it’s called double blinding if  even those administering the treatments don’t know.
You need to use many snorers per treatment to gauge the effects, not just one snorer.
Confounding occurs when the controls in an experiment don’t eliminate other possible causes for the effect on the dependent variable.
As an example, imagine if  you gave doses to SnoreCull to men, but placebos to women.
If  you compared the results of  the two groups, you wouldn’t be able to tell whether the effect on the men was because of  the drug, or because one gender naturally snores more than another.
Designing your experiment We said earlier that you need to randomly assign subjects to experiments.
Completely randomized design One option is to use a completely randomized design.
For this, you literally assign treatments to subjects at random.
If we were to conduct an experiment testing the effect of  doses of  SnoreCull on snorers, we would randomly assign snorers to particular treatment groups.
As an example, we could give half of  the snorers a placebo and the other half  a single dose of SnoreCull.
Instead of  choosing a sample at random, you assign treatments at random.
Randomized block design Another option is to use randomized block design.
For this, you divide the subjects into similar groups, or blocks.
As an example, you could split the snorers into males and females.
Within each block, you assign treatments at random, so for each gender, you could give half  the snorers a dose of SnoreCull and give the other half  a placebo.
The aim of  this is to minimize confounding, as it reduces the effect of  gender.
Instead of  splitting your population into strata, you split your subjects into blocks.
Matched pairs design Matched pairs design is a special case of  randomized block design.
You can use it when there are only two treatment conditions and subjects can be grouped into like pairs.
As an example, the SnoreCull experiment could have two treatment conditions, to give a placebo or to give a single dose, and snorers could be grouped into similar pairs according to gender and age.
You then give one of  each pair a placebo, and the other a dose of  SnoreCull.
If  one pair consisted of  two men aged 30, for instance, you would give one of  the men a placebo and the other man a dose of SnoreCull.
If there were 1,000 subjects, we could give half a placebo and the other half a dose of SnoreCull.
You could also form matched pairs using gender and age to negate confounding due to these variables.
In Chapter 15 you saw how a least squares regression line takes the form y = a + bx, where.
There’s another form of  writing this that a lot of  people find easier to remember, and that’s to rewrite it in terms of  variances.
Just as the variance of  x describes how the x values vary, and the variance of  y describes how the y values vary, the covariance of  x and y is a measure of  how x and y vary together.
This is the formula for the slope of the line.
This is the same calculation written in a different way.
Sample variance of the x values Sample variance of the y values.
It’s the percentage of  variation in the y variable that’s explainable by the x variable.
As an example, you can use it to say what percentage of  the variation in open-air concert attendance is explainable by the number of  hours of  predicted sunshine.
The first way is to just square the correlation coefficient r.
Another way of  calculating it is to add together the squared distances of  the y values to their estimates, and then divide by the result of  adding together squared distances of  the y values to y.
Non-linear relationships If  two variables are related, their relationship isn’t necessarily linear.
Here are some examples of  scatter plots where there’s a clear mathematical relationship between x and y, but it’s non-linear:
Linear regression assumes that the relationship between two variables can be described by a straight line, so performing least squares regression on raw data like this won’t give you a good estimate for the equation of  the line.
You can sometimes transform x and y in such a way that the transformation is close to being linear.
You can then perform linear regression on the transformation to find the values of  a and b.
The big trick is to try and transform your non-linear equation of  the line so that it takes the form.
As an example, you might find that your line of  best fit takes the form.
In other words, you can perform least squares regression using the line y' = a + bx, where y' = 1/y.
Once you’ve transformed your y values, you can use least squares regression to find the values of  a and b, then substitute these back into your original equation.
If your line of best fit isn’t linear, you can sometimes transform it to a linear form.
This is just a quick overview, so you know what’s possible.
These all show definite patterns, but they’re not straight lines, so they’re not linear.
The margin of error for b The margin of  error is given by.
The standard deviation of  the sampling distribution of  b is given by.
To calculate this, add together the differences squared between each actual y observation and what you estimate it to be from the regression line.
Then divide by n – 2, and take the square root.
Once you’ve done this, divide the whole lot by the square root of the total differences squared between each x observation and x.
If  you’re taking a statistics exam where you have to use sb, the formula will be given to you.
This means that you don’t have to memorize it; you just need to know how to apply it.
Knowing the standard deviation of  b has other uses too.
As an example, you can also use it in hypothesis tests to test whether the slope of  a regression line takes a particular value.
This is the standard deviation of the sampling distribution of b.
Sampling distributions - the difference between two means Sometimes it’s useful to know what the sampling distribution is like for the difference between the means of  two normally distributed populations.
You may want to use this to construct a confidence interval or conduct a hypothesis test.
As an example, you may want to conduct a hypothesis test based on the means of  two normally distributed populations being equal.
The value of  c depends on the level of  confidence you need for your confidence interval:
Sampling distributions - the difference between two proportions There’s also a sampling distribution for the difference between the proportions of  two binomial populations.
You can use this to construct a confidence interval or conduct a hypothesis test.
As an example, you may want to conduct a hypothesis test based on the proportions of  two populations being equal.
If  np and nq are both greater than 5 for each population, then Px – Py can be approximated with a normal distribution.
The value of  c depends on the level of  confidence you need for your confidence interval.
They’re the same values of  c as on the opposite page.
If  you’re taking a statistics exam where you have to use the sampling distribution between two means or two proportions, the variance of  the sampling distribution will be given to you.
This means that you don’t have to memorize them; you just need to know how to apply them.
E(X) and Var(X) for continuous probability distributions When we found the expectation and variance of  discrete probability distributions, we used the equations.
When your probability distribution is continuous, you find the expectation and variance using area.
As an example, suppose you have a continuous probability distribution where the probability density function is given by.
Finding E(X) To find the expectation, we’d need to find the area under the curve xf(x) for the range of  the probability distribution.
This is called a uniform distribution, as f(x) is a constant value.
In general, you can find the expectation and variance of  a continuous random variable using.
You don’t often need to find the expectation and variance of  a continuous random variable.
A lot of  the time you’ll be working with distributions like the normal, and in this, case the expectation and variance are given to you.
Where would you be without your trusty probability tables? Understanding your probability distributions isn’t quite enough.
For some of them, you need to be able to look up your probabilities in standard probability tables.
Where would you be without your trusty probability tables? Understanding your probability distributions isn’t quite enough.
For some of them, you need to be able to look up your probabilities in standard probability tables.
These are the probabilities for P(Z < z) where z is negative.
These are the probabilities for P(Z < z) where z is positive.
