Scala is the most prominent representative of this exciting approach to programming, both in the small and in the large.
In this book we show how Scala proves to be a highly expressive, concise, and scalable language, which grows with the needs of the programmer, whether professional or hobbyist.
Use Scala for fun, for professional projects, for research ideas.
He has been working in the software industry for more than ten years, designing and implementing ﬂexible, enterprise-level systems and making strategic technical decisions.
He has also published research papers on topics including digital typography, service-oriented architectures, and highly available distributed systems.
Last but not least, he is an advocate of open source software.
His research interests focus on computability theory, category theory, fuzzy set theory, and digital typography.
He has authored or co-authored six books, was co-editor of a multi-author volume, and has published more than 50 papers and articles.
Subject to statutory exception and to the provision of relevant collective licensing agreements, no reproduction of any part may take place without the written permission of Cambridge University Press.
Cambridge University Press has no responsibility for the persistence or accuracy of urls for external or third-party internet websites referred to in this publication, and does not guarantee that any content on such websites is, or will remain, accurate or appropriate.
To Katerina, who is always here and is constantly making me a better person CKKL.
The distinguishing features of Scala include a seamless integration of functional programming features into an otherwise objectoriented language.
Scala owes its name to its ability to scale, that is, it is a language that can grow by providing an infrastructure that allows the introduction of new constructs and data types.
In addition, Scala is a concurrent programming language, thus, it is a tool for today as well as tomorrow! Scala is a compiled language.
Its compiler produces bytecode for the Java Virtual Machine, thus allowing the (almost) seamless use of Java tools and constructs from within scala.
The language has been used to rewrite Twitter’s1 back-end services.
In addition, almost all of Foursquare’s2 infrastructure has been coded in Scala.
This infrastructure is used by several companies worldwide (for example, Siemens, Sony Pictures Imageworks)
Thepurpose of this book is twofold: ﬁrst to teach the basics of Scala and then to show how Scala can be used to develop real applications.
Unlike other books on Scala, this one does not assume any familiarity with Java.
In fact, no previous knowledge of Java is necessary to read this book, though some knowledge of Java would be beneﬁcial, especially in the chapter on GUI applications.
On the other hand, the book assumes that readers do have a very basic understanding of programming concepts.
In particular, we expect readers to be familiar with terms like compiler, interpreter, (character) string, etc.
Thus, the book can be used by anyone who has done some high school computer programming.
However, the book covers a number of subjects that are quite advanced and so are appropriate for readers with.
Sections describing such topics are marked with an asterisk (*)
The intended audience of this book includes computer science students as well as computing professionals.
Essentially, the book is divided in two parts – the ﬁrst seven chapters introduce most of the language constructs and related software modules, while the remaining six chapters present various applications of Scala.
In particular, the ﬁrst chapter of the book is an introduction to the basic ideas described in the rest of the book.
InChapter 2we gradually introduce the various basic concepts and ideas of Scala.
In particular, we present the “basic” data-types, classes and objects, methods and operators, and functions.
Then we introduce some important predeﬁned typesclasses: sets, hash tables, lists and strings.
In addition, we discuss other important features such as memo functions, regular expressions, annotations, etc.
Pattern matching is an another important feature of Scala that can be used to deﬁne useful structures like trees.
In Chapter 3 we introduce traits in order to show how behaviors can be mixed in using them.
Polymorphism is an important characteristic of object-orientation and therefore is an important part of Scala.
We discuss all aspects of Scala polymorphism, even higher-order polymorphism.
We also discuss streams, setters and getters, memo functions, and we conclude with a discussion of monads.
Chapter 4 is about parser builders, that is, tools that can be used to implement language processors.
After introducing the so-called basic parser combinators, we show how they can be used to build the interpreter of a relatively simple programming language.
The chapter concludes with a short description of domain-speciﬁc languages and monadic parsing.
In Chapter 5 we discuss how one can create and manipulate XML content using Scala.
In addition, we show how to perform a number of important operations such as searching and printing.
Also, we show how to produce XHTML content with Scala.
In particular, we show how to use a number of GUI components such as frames, all sorts of.
In addition, we show how to implement applets in Scala.
The chapter concludes with a short discussion of functional graphics.
It was said above that Scala is a concurrent programming language in the sense that it includes a number of features that facilitate concurrent programming.
In particular, we discuss threads and synchronization, animation using threads, mailboxes (a precursor of actors), and actors.
Chapter 8 deals with a ubiquitous abstraction, that of paths.
We build three VFS implementations: a traditional ﬁle system, one based on zip (compressed archives) ﬁles and ﬁnally a memory-based VFS.
Chapter 10 introduces the concept of ﬁle matching, inspired by Unix-related terminology and tools.
But instead of just reproducing known behavior, we take full advantage of Scala’s DSL deﬁnition abilities and make ﬁle searches more userfriendly than ever.
Chapter 11 extends the basic idea of the previous chapter, regarding the methodologies to search for the appropriate ﬁles.
It presents two complementary techniques: one based on the classical notion of iteration and the other based on the emerging notion of traversal.
During the course of study, we discover not so traditional ways to abstract over our data and clearly show how a pre-order depth-ﬁrst search can share almost the same codebase with a breadth-ﬁrst search.We conclude with a set of thought provoking remarks on the interplay between iteration and traversal.
Chapter 12 introduces and analyzes the expression problem, a not so widely known software design problem.
Since its essence lies at the frontier of combining data with operations, we feel that this particular problem should be brought to the attention of a wider audience.
Based on work by well-known researchers (including the creator of Scala, Martin Odersky) we build a small code library that follows a consistent set of naming conventions in order to help us tackle the expression problem.
Chapter 13 is a short chapter that shows how one can easily construct a relatively simple computer algebra system.
The ﬁrst one brieﬂy discusses how one can construct multimedia applications with Scala.
The second one shows how we can use the open-source tool Proguard to package Scala applications along with the Scala.
The fourth and last appendix presents the wealth of command line options of Scala’s compiler and interpreter.
Each chapter contains a number of exercises that have been designed to help readers obtain a deeper understanding of the topics presented.
There are no solutions to exercises, though in some cases material that follows the exercises contains the solution.
In most cases these are not easy and some of them are quite challenging.
In the book we use the term Unix, but since this may mean different things, we need to calarify the meaning.
All of the examples presented in the following pages have been tested to work under OpenSolaris and MacOS X [Snow] Leopard.
We do not expect that readers who use different computer platforms will encounter any kind of problem, as long as they use the latest version of Java’s JDK from Oracle.
The book has been typeset using a Unicode-aware extension of LATEX that runs atop of a novel typesetting engine created by Jonathan Kew.
We have used Minion Pro to set the text of the book and GFS Neohellenic (by the Greek Font Society) to set captions.
In addition, we have used UM Typewriter (created by Apostolos) to typeset code snippets.
Asana Math (also by Apostolos) has been used to set mathematical text in this book.
Sometimes, when introducing a new language, a new technology, a new approach, wemayhear a great deal of technical arguments in favor.
For the reader who seeks technical ability and excellence in the everyday tools, Scala will provide a solid work-ﬁeld.
For the language enthusiast, the exploring student, the hobbyist programmer, the geek, the most important thing is that Scala can increase your enjoyment of programming.
This has been our feeling while preparing this book and while using Scala in our everyday work.
First of all we would like to thank Heather Bergman, a former computer science editor of CUP’s New York branch, who believed in this project.
Heather has helped us during the writing of the book in every possible way! Also,we would like to thank Clare Dennison, our pre-production editor, and Jonathan Ratcliffe, our production editor.
Scala is a scalable object-oriented programming language with features found in functional programming languages.
Nowadays, the object-oriented approach to software construction is considered the most succesful methodology for software design, mainly because it makes software reuse extremely easy.
On the other hand, functional programming offers some very elegant tools which when combined with an object-oriented program development philosophy deﬁne a really powerful programming methodology.
Generally, any programming language that can be extended seamlessly is called scalable.When all these ideas are combined in a single tool, then the result is a particularly powerful programming language.
The ﬁrst object-oriented programming language was SIMULA [18], which was designed and implemented by Ole-Johan Dahl and Kristen Nygaard.
The SIMUlation LAnguage was designed“to facilitate formal description of the layout and rules of operation of systems with discrete events (changes of state).” In other words, SIMULA was designed as a simulation tool of discrete systems.
Roughly, a simulation involves the representation of the functioning of one system or process by means of the functioning of another.
In order to achieve its design goal, the designers equipped the languagewith structures that wouldmake easy the correspondence between a software simulation and the physical system itself.
A process “is intended as an aid for decomposing a discrete event system into components, which are separately describable.” Processes,which nowadays are called classes, consist of two parts: a data part and a code part.
In the data part, programmers can declare and/or deﬁne variables, while in the code part they can deﬁne actions (procedures) to process the data.
Processes can be combined to describe the functionality of some system.
Elements, which nowadays are called objects, are instances of processes, thus, for a single process there may.
It turns out that these simple ideas are the core of what is now known as object-orientation.
The basic design principle of Smalltalk was the idea that all data manipulated by a program are objects, that is, software entities capable of interacting with other similar objects.
Then, if object 4 understands the message +, it starts the execution of a method that speciﬁes how to respond to this particular message.
The paradigm shift pioneered by SIMULAand Smalltalk shaped thewhole industry and this is evident in the number of object-oriented languages that emerged and their use in industry.
But what are the reasons for the success of the object-oriented programming paradigm?
The reason for this success is that object-oriented languages implement a number of principles that make the software design and construction process much simpler and elegant when compared to “traditional” approaches.
The four basic principles of object-orientation are described brieﬂy below.
Abstraction Objects lie at the heart of object-oriented programdesign.A software object is an abstraction of a real-world object.
An object has the essential characteristics of the real-world object that distinguish it from all other kinds of object.
Thus, it is important to classify the various characteristics as essential or insigniﬁcant.
This way the software becomes simpler and easier to understand.
Encapsulation An object is a software component that is characterized by its state and its behavior.
Typically, the ﬁelds of an object are accessible only through its methods.
In other words, one can either change the state of an object or become aware of its current state by invoking speciﬁc methods.
This implies that the internal state of an object is not visible to anyone, thus providing a data protection mechanism.
Usually, objects are related with an “isa” relationship, that is, if A and B are two objects such.
In fact, the designers of Smalltalk were the ﬁrst to introduce the widely used object-oriented parlance that includes terms such as object-oriented, method, etc.
Object B may extend the functionality of A either by deﬁning new ﬁelds and/or methods or by changing the actions taken by some methods.
It is customary to say that B inherits A when B is an A.
Objects may inherit characteristics from more than one object and in this case we talk about multiple inheritance, while if each object may inherit characteristics from only one object, we talk about single inheritance.
When building new systems, it is not necessary to design all objects from scratch.
Instead, one may opt to use existing objects and extend their functionality to suit one’s own needs by designing new objects that inherit existing objects.
In a nutshell, this is the essence of software reuse.
Polymorphism Seemingly different real-life structures may actually differ only in the items they process.
So instead of deﬁning an object for each instance of the real-life structure (something that is practically not possible),one candesign a generic software module and then instantiate it to model particular real-life structures.
For example, a stack consists of items that are put one atop the other and one can remove and/or add items only from/to the top of the stack.
Thus, if we want a stack of integers or a stack of software modules modeling books, we can create a generic software module that will implement the functionality of any stack and then use particular instances of this software module to simulate stacks of integers and/or books.
To put it very simply, a polymorphic software module is one that may have different instances with identical behavior.
Without worrying about the details, let us see by means of an example how these principles are realized in the language that is presented in this book.
Assume that we want to build a system simulating a zoo.
In order to achieve this goal we need to build a hierarchy of classes that will describe the species living in the zoo.
Naturally, we do not need to build a different class for each species since, for example, a bee is an insect and all insects are arthropods.
Let us start by deﬁning a class that describes arthropods:
Weare not interested in every aspect of whatmakes an animal an arthropod.
Instead, we center upon two quite important things: the number of eyes and the number of feet.
Obviously, our choice is subjective, but it depends on the task we are trying to accomplish and this is exactly the essence of abstraction.
Note that the values stored in the ﬁelds NumberOfEyes and NumberOfFeet cannot be changed.
An ant has six legs and let us assume it has two eyes.
The declaration that follows creates an ant object that corresponds to an ant:
Althoughwe cannot alter the number of feet or the number of eyes of an ant object, we can inspect these values.
Although we have used an indirect way to access the values of each ﬁeld, one can use the ﬁelds directly to access or modify the corresponding values, However, one can also declare the ﬁelds in such a way that such operations are not directly possible, and this is a simple example of data encapsulation.
Instead of deﬁning a new class for insects from scratch, we can extend the functionality of class arthropod to deﬁne a class for insects:
In this particular case, the numbers six and four will be printed on the computer screen.
Although the examples presented are very simple, nevertheless, any real-world application uses inheritance in exactly the same way.
The important beneﬁt of the introduction of inheritance is that software modules become reusable.
Thus, there is no need to invent the wheel every time one tries to solve a particular problem.
And when a programming language is equipped with a huge library of such software modules, then it attracts many users.
After all, this is just one of the reasons that the Java programming language has become so popular.
Although there are animals that change their forms entirely during their lifetime (thinkof butterﬂies for example), still itmakes no sensemerely to demonstrate polymorphismusing such a complex example.
As noted already, a stack is a structure where one can add/remove elements from its top.
Let us ﬁrst deﬁne a class that simulates a stack of integers:
Note that we have intentionally left out various checks that should be performed (for example, we cannot pop something from an empty stack) just to keep things simple.
We just specify the height of the stack as shown below:
The last command will print the number 4 on the computer screen.
The most “natural” thing to do is to deﬁne a StringStack by replacing all but the ﬁrst occurrence of Int with String.
Here the words Int and String are data types or just types.
With types one can distinguish between one as a natural number and one as a real number.
In the simplest case, types may be seen as sets of data values.
Thus, when one says x : Z, where Z is the set of integers, one means that x can assume any value that is an integer number.
Note that Int and String denote (a system dependent range of) integer numbers and ﬁnite character sequences, respectively.
After this brief but necessary explanation, let us continue with our example.
If one wants yet another stack structure, it can be deﬁned in a similar way.
The really great beneﬁt of polymorphism is that programmers do not have to spend time and energy deﬁning similar things.
On the other hand, ﬁnding the similarities between seemingly different structures is another problem that depends on the mathematical maturity of each person.
Another method to describe a function is to specify a single rule:
The second deﬁnition can be easily coded into a Scala function:
Assume that we want to deﬁne a function that computes the maximum of its two arguments.
Clearly, if the ﬁrst argument is greater than the second, then the ﬁrst argument is the maximum.
This function can be easily encoded as a Scala function as shown below:2
Let us make our life a little bit more difﬁcult and let us try to deﬁne a function that ﬁnds the maximum of three numbers.
In order to solve this problem we need to check the various cases – if the ﬁrst argument is greater than the second and the second is greater than the third, then the ﬁrst argument is the greatest of all three, etc.
Although this computes what we want, it does it in a very complicated way.
A simpler approach is to compute the maximum of the second and the third argument and then the maximum of the ﬁrst argument and the maximum of the second and the third argument, or in Scala.
This is a form of function composition, that is, a process by means of which one can generate a new function from two or more other functions.
In addition, functional programming can be deﬁned as a programming discipline where programs are usually composite functions.3 And this is the reason why functional programming.
This function is predeﬁned in Scala, but we use it to demonstrate the notion of function composition.
Then the composition of these solutions gives a solution to the original problem.
In order to ensure that procedure functions can be composed as their mathematical counterparts, one must avoid the so-called side effects.
To understand what we mean by side effects, consider the following code:
If f was a pure function, then the two commands would print exactly the same.
The problem with this code is the destructive assignment, that is, a command that modiﬁes the value of a variable.
Programming languages that allow the use of such assignments are called referentially opaque.
On the other hand, languages that do not permit the use of destructive assignments are called referentially transparent.
Obviously, one can keep side effects out of the programs in a referentially opaque language by deliberately avoiding the use of destructive assignments.
Nevertheless, functional programming languages provide a number of tools (for example, pattern matching, algebraic types, that is, the disjoint union of several types) that greatly facilitate programming in these languages.
But these are not the fundamental differences between an imperative language (i.e., nonfunctional for our purposes) and a functional programming language.
The fundamental difference lies in the way solutions to problems are expressed.
Typically, an imperative program is a sequence of “imperatives which describe how the computer must solve a problem in terms of state changes (updates to assignable variables)” while “a functional program describes what is to be computed, that is the program is just an expression, deﬁned in terms of the predeﬁned and user-deﬁned functions, the value of which constitues the result of the program” [21]
According to Steele there are two kinds of growth in a language – one should be able to change either the vocabulary or the rules that say what a sequence of words means (i.e., the semantics of a sequence of words)
The essence of these two kinds of growth is that one should be able either to deﬁne new keywords or to change the meaning of operators and/or keywords.
Similarly, there two ways by which a language can grow – either this can be done by a person, or a small group of persons (for example, a committee), or by a whole community.
In the second case, members of the user community can actively participate in the extention of a language.
For this reason a person or a small group of persons act as project coordinators.
But how can a language be designed to be extendable?
Steele argues that the best way to make a language extendable is to include generic types, operator redeﬁnition, and user-deﬁned types of light weight, which could be used to deﬁne numeric and related types.
In Section 1.1 we have discussed generic types, but we have said nothing about operator overloading and light weight user-deﬁned types.
Many engineers need to be able to manipulate complex numbers easily, thus, the availability of a numeric type providing the functionality of complex numbers is a key factor in their choice of programming language.
Deﬁning a light weight user-deﬁned type where ordinary arithmetic operators are redeﬁned while their original meaning is not lost solves this problem, see Figure 1.1
Here a complex number is simulated by a class with two ﬁelds that can assume as values real numbers of double precision.
Also, we (re)deﬁne the meaning of the operators +, -, *, and /
The last command will print “a + b = 5.5+0.5i” on the computer screen.
Note also that in the last command the ﬁrst + is used to concatenate character sequences and the second to add complex variables.
And this is the reason we need the extra parentheses, or else we will get the following “erroneous” output.
Figure 1.1 A Scala light weight user-deﬁned type implementing complex numbers.
In a nutshell, operator overloading is a facility that allows users to provide additional functionality for any existing operator.
Going one step further, it is possible to deﬁne new literals as operators.
In Scala the symbols // start a comment that extends to the end of the current source line.
Thus, the second deﬁnition of +, that is, the one that is commented out, should be useful when adding a variable that holds a complex number with a number literal (e.g., a+3)
However, this approach cannot be used to handle the opposite case, that is, it cannot perform additions like 3+a.
Fortunately, there are other better ways to handle problems like this.
For example, it is possible to convert number literals implicitly to objects of the proper type by deﬁning functions that.
Here the keyword val signals that the value of the variable declared cannot be changed.
On the other hand, variables declared with the var keyword are real variables, that is, they can change their value in the course of time.
Class Complex shows how easily one can deﬁne other numerical types.
For example, a reader with some programming experience in any programming language should have no difﬁculty deﬁning a light weight user-deﬁned data type for quaternions (i.e., a noncommutative extension of complex numbers) and/or octonions (i.e., a nonassociative extension of the quaternions)
Although Steele would be really happy with a language that has the capabilities presented so far, it would be a great idea to be able to deﬁne new control structures.
For example, although one can use a while to execute a block of code repeatedly, it would be nice to have a repetition construct,which is similar to the while construct but not the same.
The while construct checks the truth of an expression and if it is true it executes a block of code, otherwise it aborts.
Then it checks again the truth of the same expression and if it is again true it executes again the block of code, and so on, until the expression becomes false.
Assume now that we want to construct a loop that should execute a piece of code, then examine a condition and if the negation of the condition is true, then it should execute a second block of code and repeat the same procedure, or else it should abort.
This iteration construct, which was proposed by Dahl in [42], might have the following general form:
In Scala it is not difﬁcult to deﬁne a function that implements the functionality of this construct without adding syntactic sugar to the language.
The trick is to employ call-by-name in the deﬁnition of a procedure:
What is really surprising about this function is that when it is invoked, both pre and post can be pieces of real code! Here is a simple usage example of this function:
Amazing, isn’t it? But if one can deﬁne new control structures, would it not be nice to be able to change the semantics of a sequence of words? We do not believe this is a really good idea.
For example, the following piece of code in the PL/I programming language shows exactly why changing the meaning of words is not a very good idea:
Admitedly, the Java programming language is a very popular programming language.
The language owes its popularity to a number of reasons that include the following.
Java’s compiler produces code for the JavaVirtualMachine (JVM),4 whichhas beenported.
Java has a huge application programming interface (API) that provides support from computer-telephony integrated call control to advanced image handling andmp3playing.
The success of the Java programming language and its underlying technology had a profound effect on the development of programming languages.
The ﬁrst design philosophy is based on the idea of designing and implementing a new virtual machine similar to the JVM.
The second design philosophy is much cleverer – there is no need to re-invent the wheel, just use it! Thus, a host of programming languageswere implemented atop the JVM, making the languages immediately available to a number of different computer platforms.
In addition, language designers could opt to provide access directly to language users to the Java API, thus making these languages particularly powerful.
This philosophy has been adopted by a number of programming languages that include Clojure,5 which was developed by Rich Hickey, Groovy [8], which was based on ideas put forth by James Strachan, JRuby, a variant of Ruby that runs atop the JVM (Ruby was designed by Yukihiro “matz” Matsumoto), and Scala, which was designed by Martin Odersky.
In addition to the ideas presented so far, all these languages have in common some excellent design principles.
For example, all values are objects and one can easily add methods to existing types, thus extending the functionality of these “values.” Nevertheless, Scala is the only language that integrates these and a number of other important features in such a seamless way.
Thus, Scala is the best example of what Stuart Halloway calls a “Java.next” language, in his blog.
One may say that Scala is the Java.next, since it includes all features of the Java programming language, while it includes many features (for example, closures, traits, and pattern matching) that may ﬁnd their way into future releases of Java.
Since the designer of Scala haswritten two versions of the ofﬁcial Java compiler, Scala’s compiler produces output that is as fast and reliable as the output produced by the ofﬁcial Java compiler.
A virtual machine is a computer program that simulates a computer architecture and is able to run machine code for this particular computer architecture.
Scala can easily be used as a scripting language since Scala’s distribution includes a compiler as well as an interpreter.
In Scala one can deﬁne classes or traits, that is, classes that cannot be instantiated but only inherited, that can be composed via mixins.
On the other hand, Scala has a lightweight syntax, that is, a simpliﬁed form of its basic syntax that comes from a number of features: semicolon inference, type inference, lightweight classes, extensible APIs, and closures, that is, special functions, as control abstractions.
As a result, Scala programs tend to be shorter than their Java counterparts.
The actor model is a sort of object-oriented abstraction of concurrency [3]
An actor is an agent that has a mail address and, consequently, a mailbox and a behavior.
Actors communicate by message passing and carry out their actions concurrently.
Erlang was the ﬁrst widely used programming language that provided an actor libary.
However, the library has been implemented in such a way that users think it is part of the original syntax of the language.
This is the best example of Scala’s ability to grow as a language.
For example, one can assign an XML tree to a variable as follows:
These and a number of other features have made Scala a popular programming language that is currently used by many enterprises.
Our sincere hope is that this brief overview of the key features of Scala has whetted your appetite for more Scala!
Scala is a programming language designed in such a way that programs tend to be concise.
Thus, it does not include many predeﬁned data types and ﬂow control constructs.
The standard Scala distribution includes an interpreter as well as a compiler.
The compiler can be used to generate .class ﬁles, that is, binary ﬁles that can be executed by the JVM, while the interpreter can be used to execute source code contained in a text ﬁle or it can be used to work interactively with Scala.
The program that follows is the customary “Hello World!” program in Scala, that is, a program that just prints the message “Hello World!” on the computer screen:
The identiﬁer args refers to the command line arguments (for an explanation see Section 2.9)
Let us assume this code is stored in a ﬁle named hello.scala.
Note that, Java programs, Scala programs can be stored in ﬁles whose names are different from the name of the class/object that contains function main.
The commands that follow show what should be done to compile and then to execute the resulting .class ﬁle:
Also, -classpath is used to specify the location of one or more .class ﬁles.
Usually, people prefer to use the -cp switch, which has exactly the same functionality (see also the discussion in section 6.1)
If one wants to use the interpreter and is working on a Unix system or a Unix-like system such as OpenSolaris or Linux, respectively, one has to type in either the following code.
Then one has to change the attributes of this ﬁle and make it executable in order to be able to execute it:
The program can be executed by entering the following command:
The two versions presented do not produce exactly the same output.
For example, the second version will print the following message.
On Windows systems, users can get equivalent results by creating a text ﬁle, say hello.bat, which will contain the following lines:
This program can be executed from a CMD shell by entering a command like the following one:
Starting the Scala interpreter is easy: just type scala in your command prompt.
The next few lines show a typical session with the Scala interpreter.
A typical Scala program describes the interaction between objects, which interchange messages.
For example, things like numbers, character sequences, and character strings or just strings, are objects that can interact with other objects.
Table 2.1 Basic types supported by the Scala programming language.
Objects with no internal structure, that is with no components, are said to be of a basic type.
In what follows the Scala interpreter is used to demonstrate the properties of the basic types.
When declaring a variable or a constant, we write either the keyword var or the keyword val, the name of a variable or a constant, an equals sign (i.e., the symbol =), and then the value the variable or the constant will assume.
Optionally, we can specify the type of a variable or a constant by writing, after its name, a colon (:) and then its type:
If the value does not agree with the type, a type error occurs:
By default Scala assumes that an integer literal, that is, a sequence of digits possibly preﬁxed by a plus or minus sign, is of type Int:
An integer literal that is sufﬁxed by an L or an l is assumed to be of type Long:
Mixing an Int with a Long results in a Long:
In general, numbers can be written as decimal, octal or hexadecimal numerals.
Obviously, if one sufﬁxes an octal or a hexadecimal numeral with an L or an l, then it is assumed to be of type Long:
Under certain circumstances, every integer number is automatically transformed to its ﬂoating point equivalent:
A ﬂoating point number consists of an integral part and an optional decimal point (represented by a period character) that may be followed by an optional fractional part, an optional exponent and an optional type sufﬁx.
The exponent starts with either the letter E or the letter e and is followed by a signed integer, that is, an.
The exponent designates that the number is multiplied by ten raised to the power speciﬁed by the number that comes after the letters e or E.
The type sufﬁx can be either the letters f or F or the letters d or D.
The letters f and F denote a single precision ﬂoating point number, while the letters d and D are used to specify a double precision ﬂoating point number:
As it stands, one cannot assign to a character variable a single quotation mark:
We can solve this problem by using an escape sequence, that is, a sequence of easily accessible characters that represent other characters.
Unicode characters having the corresponding code point (see Table 2.2):
Note that println prints its arguments on the computer screen.
A String is a sequence of Chars that is enclosed in double quotes:
In fact, each basic Scala type corresponds to an instance of a class of package java.lang, which makes implementation of the language easier.
This description is actually an oversimpliﬁcation of the actual situation, nonetheless, for the time being the newcomer should not care about what is really going on under the hood.
Multiline strings can be typed in using the \n escape sequence:
However, this is not convenient and so Scala provides a better way to type in multiline strings – one starts a string with three consecutive double quotes, then the string follows with embedded new lines and the string closes with three consecutive double quotes.
Not quite what we expected, right? To remedy this problem, programmers should type a “|” (vertical line) after the three consecutive double quotes and at the beginning of each line and append the string with .stripMargin:
This program will produce the expected result, try it! Note that stripMargin is a method that any object of type String has (this method strips whatever comes before the “|” character), but we will say more about objects and methods in the next section.
The literals true and false denote truth and untruth, respectively.
Type Unit has only one value, which is designated by two parentheses:
When a function does not return a result (for example, when it merely assigns values to variables), then it yields a value of type Unit.
Scala demands that each variable/constant gets a value when it is declared/deﬁned.
However, if one does not want to assign a particular value, then one can use the special value _, which forces Scala to assign some default value to the variable/constant being declared/deﬁned.
For numbers the default value is 0 or NULL; and for all other objects it is the literal null.
This value is of type Null and designates that an object of some nonbasic type is empty.
A class is an archetypal software module that is used to create objects, that is, concrete instances of a class.
Unfortunately, in Scala software modules are called objects which is quite confusing, especially for newcomers.
In order to avoid confusion, when we have to refer to both software modules and objects, we will call the former class instances and the latter either objects or modules.
A class deﬁnition is a detailed description of the elements of a new type and the operations these elements may perform.
A class deﬁnition consists of ﬁeld declarations and method deﬁnitions.
Fields are used to store the state of an object and methods may provide access to ﬁelds, alter the state of an object, etc.
Let us start with a simple example borrowed from [1]
Class cell describes a storage-cell with one ﬁeld that is initialized to zero:
As is evident, the deﬁnition of a class begins with the keyword class, which is followed by the name of the class.
This class deﬁnition includes the deﬁnition of one ﬁeld, namely contents, and the deﬁnition of two methods, namely get and set.
In general, a ﬁeld can be viewed as a variable and so it is declared in exactly the same way.
As with variables, we use the keyword def to designate a method deﬁnition.
This keyword is followed by the name of the method being deﬁned.
If the method takes arguments, we need to specify the name of each parameter and its type.
Even if a method takes no arguments but returns a value, then one should type the parentheses to designate exactly this.
If a method returns a meaningful value, then one may specify its return type.
As noted in the previous section, methods that do not yield a value, are assumed to return a value of type Unit.
The code that will be executed each time the method is invoked is surrounded by braces, unless it is a simple expression.
In the ﬁrst case one can omit the equals sign.
The return value of a method can be speciﬁed either implictly by letting it be the last expression of the method, or explicitly by using one or more return commands.
In this case, it is mandatory to specify the return type of the method.
For example, here is how method get from the previous example should be written:
If the return type is omitted, then Scala infers the return type of the method by examining the body of the method.
Once a class is deﬁned one should be able to construct objects of this class.
New objects (or class instances) are constructed in the following generic way.
The expression new is used to construct an instance of a class.
For example, here is how one can construct a new object of class cell:
Interestingly, we can create a new object and at the same time we can give values to ﬁelds.
Accessing individual methods and ﬁelds is easy: we write the object’s name, a period, and then the name of the method or ﬁeld.
If a method takes arguments, we should specify them as well:
Exercise 2.3 This example violates the principle of encapsulation, why?
To ensure that the value of a ﬁeld cannot be directly modiﬁed or accessed, we need to declare it as private.
For example, if the deﬁnition of ﬁeld contents is modiﬁed as follows.
Note that even methods can be declared as private, with the expected semantics.
If you did Exercise 2.2 you may have noticed that it is quite unnatural ﬁrst to.
It is far more natural to set the value of its ﬁelds the very moment the object is created.
Indeed, Scala offers this capability and the example that follows shows how one should deﬁne class date:
If we skip the keyword var, theﬁelds are assumed tohavebeendeclared as constants.
Exercise 2.4 Modify the deﬁnition of class cell so that users are able to initialize its only ﬁeld when creating a new object.
Although it is really important to be able to set the value of all ﬁelds during initialization, still it is equally important to be able to have some ﬁelds assume a default value.
In Scala this can be achieved by specifying one or more deﬁnitions of a special function called this.
Actually, this is what is commonly called in most object-oriented languages a constructor, that is, a function that creates new instances of a class.
In Scala the default or primary constructor corresponds to the commands, deﬁnitions, and declarations that are speciﬁed in the body of the class.
The following code shows how one could rewrite the deﬁnition of class cell:
Of course, if there is more than one ﬁeld, we can deﬁne alternative constructors as shown below:
In certain cases it might be useful to have one or more methods and/or ﬁelds that are shared by all class instances.
This means that if the value of a ﬁeld is changed by one object, then the change will affect all objects.
Scala supports static ﬁelds and methods but there is no special ﬁeld modiﬁer to declare a ﬁeld or amethod as static.
Instead one has to declare a companion object, that is, one has to deﬁne a structure that is similar to a class but whose declaration is introducedwith object instead of class andwhich has the name of the class.
This entity cannot be initialized, but its methods and ﬁelds are immediately available to the class that has the same name.
Let us see a simple example that will make these ideas clear.
Assume we want to deﬁne a class of yellow fruits.
Typically, one could come up with a deﬁnition like the following one:
Since all fruits described by such a class are yellow, it makes no sense to specify the color of the fruit separately for each different fruit.
This is exactly the case where a static ﬁeld is an ideal solution.
The deﬁnition that follows is a modiﬁed version of the previous class accompanied by a companion object where the static ﬁeld is deﬁned:
As in the previous case, for all objects that are instances of this class, method getColor will print yellow.
Now, suppose that for some reason we alter the color of a lemon:
This commandwill change the color of all objects old andnew.
The object that was presented in Section 2.1 has nothing to do with the companion object that has been described here.
The former is a software module that is used to create a .class ﬁle that holds the body of a program.
Any software module with a main method is the equivalent of a main program found in conventional programming languages.
The last example is a typical example of an assignment command, that is, a command that updates the value of a variable.
Note also that one can use parentheses for clarity or to override the default way operations are performed.
But we will come back to this matter at the end of this section.
Therefore, it does make sense to multiply or add characters.
In the previous examples, the names of variables and constants consisted only of Latin latters.
But Scala does not impose any artiﬁcial restriction and, thus, an identiﬁer, that is, the name of class, an object, a variable, etc., can consist of any Unicode character that is used as a letter in some language as the following examples show:
In particular, the operators == and != can be used to check whether two objects are equal or not:
Exercise 2.6 Why do you think the last comparison does not evaluate to false?
For Strings Scala uses the usual lexicographic order and for numbers the usual number order:
Exercise 2.7 What is the result of the following comparisons:
Associativity of operators whose Operator precedence of operator name ends with the corresponding whose name starts with characters.
Table 2.3 describes the operator precedence and associativity of the operators supported by Scala.
The former provide the means to express algorithms, and the latter provide ways to organize information.
In Section 1.3 it was explained why Scala is an extendable language.
In this section, we are going to describe some basic built-in control structures.
A conditional control structure allows one to control the ﬂow of the code that is executed based on different conditions in the program, input taken from the user, etc.
On the other hand, a conditional expression is an expression one can use to select between values based on a condition.
Scala provides a conditional control structure that can also be used as a conditional expression.
The following example shows the dual nature of the if structure:
In both cases, the optional part appears only if the else keyword is present.
In addition, in either part if one wants to execute more than one command, these commands must be enclosed in curly brackets.
Also, note that if one wants to have more than one command in one line, these commands must be terminated by a semicolon (;)
However, note that the last “command” of each clause of a conditional expression must be of the same type and they should yield a value not of type Unit.
Clearly, if they return a value of type Unit, it is better to transform the conditional expression to a conditional command.
Here is a relatively simple example that demonstrates these points:
Table 2.4 Methods for reading values from the terminal provided by object Console.
Exercise 2.8 Can you say what the last command will print?
Nevertheless, the real problem is that we said nothing about interactive input.
Scala provides a number of methods that can be used to input numbers, strings, etc.
The most useful input methods are described in Table 2.4
Now it is very simple to write the program that computes the maximum of two numbers:
Note that method print does not add a new line character to the values being printed.
Suppose that we want to ﬁnd the maximum of an indeﬁnite number of comparable objects.
Obviously, we need a repetitive control structure, that is, a control structure that executes a number of commands while some condition holds true.
Scala has two basic repetitive control structures whose general form is shown below:
The structure on the left ﬁrst examines the condition and if it is true, then it executes the commands, otherwise it stops; next it re-examines the condition and so on.
The structure on the right is similar to the construct on the left except that it checks the condition only after it has executed the commands one time.
Let us see how we can solve the problem we posed in the beginning of this paragraph: to ﬁnd the maximum of an indeﬁnite number of comparable objects.
Exercise 2.9 Rewrite this code so that it ﬁnds the “maximum” of an indeﬁnite number of strings.
In the previous example the user has to enter the number zero in order to stop the iteration.
The error was reported by the runtime environment which, in general, is a virtual machine state that provides software services for processes or programs.
However, it is an indication of really poor programdesign to rely on the runtime environment to catch our programming errors.
The try command encloses commands that are potentially dangerous (i.e., input commands) and it is accompanied by a catch clause that contains fallback code that is executed when an error occurs.
In a pure object-oriented environment, even errors are objects and when they occur they send messages that are caught by the corresponding constructs.
For now, errors will be identiﬁed with special cases of class Exception.
For instance, the function deﬁnition shows a simple example that demonstrates how exceptions are thrown:
The careful reader may have noted that the if expression yields either an exception or an integer.
Clearly, this is not correct since the if expression should yield an integer value in both cases.
However, exceptions are of type Nothing, which is a subtype of every other Scala type.
Thus, the whole expression is well typed (i.e., does not violate the type rules of Scala)
As was noted above, the try command is used to evaluate dangerous code.
If the code triggers a runtime error, then execution is transferred to the catch clause.
It should be obvious that there are different kinds of errors which demand different handling.
For this reason, Scala provides a form of pattern matching, that is, a structure with which one can specify a number of different cases that are examined one after the other by the Scala implementation.
For now, it sufﬁces to say that the different cases are about similar objects.
In the code that follows, the command in the try command triggers a runtime error that is handled in the catch clause:
Such constructs allow programmers to specify how to stop the execution of a repetitive construct immediately.
Since these constructs have no place in the world of functional programming, Scala’s designer felt they should be excluded from the language.
On the contrary, one can use Boolean variables to control the ﬂow of control.
This may seem unnatural in certain cases, nevertheless, it helps programmers write better and more readable code.
Let us now proceed with a solution to our problem of ﬁnding the maximum of an indeﬁnite number of interactively provided values.
Exercise 2.11 Modify this code so it can compute the largest as well as the smallest numbers given.
In particular, any programming language equipped with a repetitive and a conditional construct can be used to compute anything a fully ﬂedged programming language can do.
A subclass describes the structure of a set of objects.
However, a subclass deﬁnition does so by describing extensions and changes to an existing class, which is called its superclass.
All ﬁelds of a superclass are implicitly included in the subclass deﬁnition.
Methods can be explicitly overridden or implicitly included, as is done with ﬁelds.
When amethod is overridden, it retains its name and possibly its type, but computes something different.
First let us deﬁne a very simple class that will be used to describe some aspects of inheritance:
Note that the keyword extends is used to designate that class Lemon is a subclass of class Fruit.
Exercise 2.12 What will be printed on the computer screen when the commands.
From this description one would conclude that a subclass deﬁnition is a convenient way to deﬁne new, unrelated classes from previous deﬁnitions without the need to repeat identical deﬁnitions.
Although f and l are of different types, nevertheless, Lemon is a subtype of type Fruit.
In addition,Liskov’s substitution principle [48] is the reasonwhy the assignment f = l is meaningful.
This principle can be stated as: If L is a subtype of F , then one can replace objects of type F with objects of type L without altering the meaning of a program.
However, one should note that the assignment l = f is incorrect (why?)
The keyword override is used to designate that themethod deﬁnition that follows is not a new method deﬁnition but rather a method that is overridden.
If l is of type Lemon and f is of type Fruit, then the following code.
We call this new class reCell, for restorable cell, that is a cell that remembers its previous value:
Recall that class cell has a ﬁeld called contents, which is also private.
However, they are not only nonaccessible, but they also cannot be inherited by subclasses and they may not override deﬁnitions in parent classes.
Thus, the previous deﬁnition is not correct, because the deﬁnition of class cell is practically nonextendable.
To remedy this problem, we need to deﬁne ﬁeld contents as protected.
Exercise 2.13 Modify the deﬁnition of class cell so it can be extended.
Note that ﬁeld backup is assigned the value of ﬁeld contents, while this ﬁeld gets its new value by invoking the method of the superclass – the keyword super refers to the superclass of the presently deﬁned class.
Suppose we have opted to deﬁne class cell as follows.
Unfortunately, it is not that obvious how one can deﬁne a subclass of this class.
Instead of explaining how one can specify a subclass of this class, let us give a simple example that will make all the relevant details clear:
Here x is a dummy variable that refers implicitly to ﬁeld contents.
Exercise 2.14 What will be the output of the following commands:
We have seen what to do when declaring a subclass that has the same number of members initialized when constructing an object of this subclass.
The question is: How can we declare a subclass with a different number of members which are.
Method toString is overriden since all classes deﬁne this method implicitly.
A proper subclass of this class is one that describes three-dimensional points.
Note that methods move and translate do not override the corresponding deﬁnitions of point since they are different deﬁnitions (for example, the former take two arguments while the latter take three arguments)
As is evident, one just adds the additional ﬁelds in the header.
If this code is fed to Scala, as shown below, it will print the output that is shown below:
Can you explain why the code is correct and why you get this output?
If we have two or more classes, it is not possible to create a new class that is a subclass of all these classes.
Technically, Scala does not supportmultiple inheritance, nevertheless, it does support tools to achieve the same effect without the problems of multiple inheritance.
It is possible to create an extension of a class while creating an instance of an existing class.
This can be achieved only for classes that do not have “parameters,” like the following simple class:
The following class instantiation shows exactly how this can be done:
In Section 2.3 we brieﬂy described how methods are declared and used.
In Scala functions are ﬁrst-class citizens since a function deﬁnition is equivalent to amodule deﬁnition (see Section 3.5) and thus a function deﬁnition can appear anywhere in a source ﬁle.
Unlike most programming languages that can be considered to descend from the C programming language, like C++ and Java, Scala permits nested function deﬁnitions, that is, function deﬁnitions inside other function deﬁnitions.
This is a feature pioneered by Algol and followed by its ancestors like Pascal.
There is nothing special about nested function deﬁnitions – one writes one function deﬁnition inside another function deﬁnition.
The following function deﬁnition is a very simple example that demonstrates the use of this feature:
Note that parameter y is not visible in the body of function E, since it is deﬁned in an inner deﬁnition.
As a general rule, variables that are declared in an inner deﬁnition are not visible outside the scope, that is, the range in which a variable can be referenced, while all variables and parameters declared outside this scope are visible.
In the case of name conﬂict, for example, where two or more variables have the same name but are declared in different scopes, then any use of these variables refers to the variable being declared in the current scope.
Thus, Q is invoked only when P is invoked and when it is invoked it will assign values to two variables and it will print the values of these variables.
The command that follows the invocation of Q will print 2, since b refers now to the variable that has type Int.
We will say more on scope later when we discuss inner classes in Section 2.17
Since Scala supports functional programming tools andmethodologies to a great extent, one can easily “deﬁne” anonymous functions.
For example, the following code snippet shows how to assign to an identiﬁer an anonymous function that increases the value of its argument by one:
Obviously, one can deﬁne anonymous functions with two ormore arguments.
Here is an anonymous function deﬁnition that multiplies its two arguments:
To be precise, here we deﬁne a function that takes one argument and returns a function that takes one argument.
And this explains why function mul is invoked this way.
Since mul is a function that takes one argument and returns a function, the invokation mul(n) returns a function that multiplies its only argument by n.
Exercise 2.16 Write an anonymous function which will compute the maximum of three integer numbers.
There are two standard functions that can be used to transform functions accepting pairs or, more generally, n-tuples as arguments to functions that take one argument and return a function.
These deﬁnitions are not readily available and one has to import them.
In certain cases, one has to import all deﬁnitions included in a package deﬁnition.
A package is a collection of classes and related constructs that provide access protection and name space management.
For example, one can import function curried with the following command:
Note that if the package identiﬁer is omitted, then it is assumed to be scala.
Thus, the previous import command could be written as follows:
If one wants to import two or more deﬁnitions, one has to separate by a comma the deﬁnitions that are needed:
More generally, one can import all deﬁnitions from a package with a command like the following one:
Here the character _ plays the role of a wildcard character that can be substituted with anything.
Now, let us present the functionality of curried and uncurried.
Function uncurried takes a function that returns a function and transforms it into a function that takes as argument an n-tuple, as the following shows:
On the other hand, function curried does exactly the opposite.
The following is a demonstration of its usage and its capabilities:
Observe that function curried actually takes two arguments, the second being the character _ because the function expects as argument a partially applied function.
At this point it is rather important to stress that Scala is a programming language where all values are ﬁrst-class citizens.
This capability is needed to implement a powerful feature: closures.
A closure is a function whose return value depends on the value of one or more variables declared outside this function.
The following interaction with the Scala interpreter has been designed to make clear what we mean by the previous “deﬁnition”:
In words, when the value of m changes, the function changes its deﬁnition too.
However, the previous example is not realistic and it does not show all the capabilities of closures.
A more realistic example is provided in the following code snippet:
This happens because the variables f and dx do not cease to exist even when the function that creates the closure ﬁnishes its computational task.
In other words, there is no need to deﬁne an argument separately if it happens to be a function – the whole function deﬁnition can be supplied as argument.
One can compose all these functions and the following code snippet shows how this can be done:
It consists of a collection of elements that have the same type.
Elements are associated with an index, usually an integer, which is used to access or replace a particular element.
In fact, an array is implemented as a number of consecutive memory locations indexed by consecutive numbers.
Most programming languages provide arrays as an elementary way to structure data, and Scala is no exception.
In Scala arrays are objects and, thus, have a number of methods associated with them.
Basically, there are two ways to deﬁne an array: either one speciﬁes the total number of elements and then assigns values to the elements, or one speciﬁes all values at once.
Naturally, these values can change provided we have declared the identiﬁer as a variable.
Let us see how we can deﬁne a simple array:
Here z is declared as an array of Strings that may hold up to three elements.
In most cases we can simplify the declaration as follows:
If one wants to assign values to individual elements or to get access to individual elements, one can do so by using commands like the following:
The index of the ﬁrst element of an array is the number zero and the index of the last element is the total number of elements minus one.
The last example shows that in general the index can be any expression that yields a whole number.
Let us now see how one could write the same commands in a more compact way.
The code that follows shows an alternative way to deﬁne an array:
As is evident, in this case we simply specify the elements after the keyword Array.
Note that the elements are separated by commas and they are enclosed in parentheses.
Exercise 2.19 Deﬁne and initialize an array of Doubles that contains ﬁve elements.
Assume that A and B are two arrays that represent two vectors.
If we have a tuple T that has as elements only integers and we want to compute their sum, then we should use the following code snippet:
Method productArity returns the number of elements of a tuple, which are indexed like an array.
Variable i assumes as values all the values in the speciﬁed range.
If we replace method to with method until, we can safely delete the minus one part.
This method produces a range that does not include the last element.
To return to the original example,method asInstanceOf is a method that performs type casting, that is, a method that changes an object of one data type into another.
Actually, this is not an arbitrary method that changes any type to any other type.
On the contrary, the two classes should be related with the subclassing relationship (see Section 3.6.6)
Method productElement yields objects of type Any, which explains why we need typecasting.
Another way to merge two arrays is by using the ++ operator, which creates a new array that consists of all elements of the ﬁrst array followed by all elements of the second array.
In the examples using the for comprehension we had to process all elements of a range.
However, there are cases where one needs to process only some elements that have some property in common.
For example, the double factorial of an integer n which is deﬁned as follows.
Exercise 2.21 Write a function that can be used to compute the double factorial of any integer number.
Some readers may come up with a solution that uses while commands, whereas others may have opted to use the for command with some test in the body of the command.
However, it is possible to attach the tests to a for command as our solution to this problem shows:
It is possible to attach more than one ﬁlter (i.e., a condition) to a for command, since ﬁlters are separarted by semicolons and each ﬁlter starts with the keyword if and is followed by some conditional expression.
In order to be able to solve this and other similar problems, Scala provides the types BigDecimal and BigInt, which are “inﬁnite precision” decimals and integers with the number of digits only limited by the available computer memory and CPU time.
Therefore, if one wants to be able to compute the double factorial of (almost) any integer, one has to change the deﬁnion of dfact as shown below:
The arrays we presented so far are unidimensional (i.e., their elements are not arrays)
However, there are many applications, especially numerical, where one needs to be able to deﬁne and use multi-dimensional arrays (i.e., arrays whose elements are arrays)
For example, matrices and tables are examples of structures that can be realized as two-dimensional arrays.
Instead, one can deﬁne arrays that have as elements other arrays,whichmay have as elements other arrays, etc.
If one wants to deﬁne a matrix, one can use a declaration like the following one:
This is an array that has three elements each being an array of integers that has three elements.
The code that follows shows how one can process a multi-dimensional array:
The expression A(i)(j) refers to the jth element of the ith array.
Since A(i) is an array, the following assignment is legal:
Exercise 2.23 Write a for command that prints all the elements of array A.
You should consider printing it as a real matrix, that is, one row on each line.
Given two arrays A and B that have elements of the same type, then the expression A ++= B appends to A all the elements of B:
The ++= operator can also be used for other random access structures and lists (see Section 2.13)
Scala has a predeﬁned array called args that can be used to process command line arguments (i.e., strings supplied to the program through the command line)
Each element of this array contains a command line argument.
The array is initialized the very moment Scala starts executing our code.
To keep things simple, we will use only the interpreter.
Assume we want to write a simple program that prints the phrase“Hello CLA!” for each command line argument CLA.
Before presenting the solution to this problem, let us say that method length returns the total number of elements of an array.
Since we have no idea how many command line arguments there will be in any case, we deﬁnitely need to use this method.
Let us now see how we can solve our little problem.
The code that follows does exactly what we have asked for:
Surprisingly, the same problem can be solved with the following expression:
The argument of this method is a form of pattern matching.
Here variable CLA, which has to be declared in parentheses, assumes the values of all elements of the array and for each such value the code after the => symbol is executed.
If A is an array of integers deﬁned as follows.
The example presented above shows the basic characteristics of array args as well as a simple usage example.
However, it would be far more interesting to present an example where the command line argument is processed.
Assume that the word “tato” is an acronym that expands to “tato and tato only,” which in turn expands to “tato and tato only and tato and tato only only,” etc.
Our problem is how to write a Scala program which will take a number from the command line and print the corresponding expansion of the “tato” acronym.
The most difﬁcult part is how to generate an expansion of the acronym.
The most natural solution to problems like this is to deﬁne a recursive function, which is a.
To understand what recursion is all about, consider the sum of the n ﬁrst positive integer numbers, which we will denote as s(n)
Note that the ﬁrst case is called the recurrence relationship while the second case is called the termination condition.
In general, each problem can be expressed as a recursive function or procedure by employing a design analysis similar to the one presented in this paragraph.
Let us now see how we can deﬁne a recursive Scala function that solves the “tato”-acronym problem.
When n is equal to one, the function should just print out the word “tato.” In all other cases, we need to expand the two occurrences of the word “tato” to the phrase.
Thus each occurrence of the word “tato” should be replaced by a recursive call, or in Scala:
What is left is to show how one should handle the command line argument.
Obviously, the user has to specify only one command line argument which has to be a positive integer.
For reasons of simplicity let us assume that the user may enter only.
Table 2.5 Methods that parse a string as a literal of some basic type and return an object of this type.
Here isEmpty returns true if the the array contains no elements.
Method toInt is one of a family of methods that parse a string as a literal of some basic type and return an object that corresponds to this literal (see Table 2.5)
Exercise 2.24 The following code handles better the command line argument:
By following a tradition pioneered by Pascal, Scala provides sets as predeﬁned structures.
Technically, a set is a collection of pairwise different elements of the same type.
In other words, there are no duplicate elements in a set.
The type annotation is necessary as the system needs to assign a concrete type to variable y.
On the other hand, when declaring a nonempty set, the type annotation is not necessary:
Given two sets, one should be able to compute their union and their intersection.3
Also, one should be able to check whether a set is empty or not and whether a set is a subset of another set (i.e., whether all elements of the ﬁrst set are elements of the second set):
The operators ** and ++ denote set intersection and set union, respectively.
As expected, operator subsetOf checks whether the left operand is a subset of the right operand; method isEmpty returns.
It is also possible to create a set by successively adding elements to it as the following example shows:
The rest of this section presents two simple set manipulation examples.
Assume that we have a skiing competition4 and we want to determine the order.
In the code that follows a set is used to hold the contestants.
In addition, we use a (pseudo-)random number generator to solve our problem.
Class Random, which is part of package scala.util, can be used to compute a sequence of pseudorandom numbers.
There are two ways to construct a new pseudorandom number generator: either by providing a seed or by not providing a seed.
In the former case, every time we execute the code, it will produce the same “random” sequence.
On the other hand, when we do not explicitly provide a seed, we get a different sequence each time the code is executed.
Having said enough about “random” numbers, let us present a solution to the problem we posed at the beginning of this paragraph:
In Greece, owing to the greenhouse effect, we do not expect to see much snow in the years to come.
In fact, we are more likely to see warm winters and very hot summers.
If humanity as a whole does not understand the severity of the current situation, and if therefore drastic measures are not taken, we will only be able to dream of winters, snow, and skiing competitions.
The expression B -= entrant removes the element on the right from the set on the left.
Exercise 2.26 In the previous example, people are identiﬁed with numbers.
Modify the code so that B becomes a set of strings that are input interactively from the computer keyboard.
An integer number p is called prime if its only divisors are the numbers 1 and p.
The sieve of Eratosthenes is an efﬁcient algorithm that can be used to generate the prime numbers that are less than or equal to a positive integer N.
The algorithm has as input a set of numbers that includes all integers greater than 1 and less than or equal to N.
Then we gradually remove all numbers that are multiples of other numbers.
The following program implements this idea and is based on a Pascal program presented in [4]:
Exercise 2.27 The previous program is static, that is, every time it is executed it will print the same output.
Many popular languages, like Perl and Ruby, provide a generalization of arrays that are called hash tables.
Instead of having as index only natural numbers, hash tables can have as index strings or any other object.
Note that in Perl indices can only be strings while in Ruby any kind of object can serve as an index.
In Scala hash tables can have objects of any type as indices, but, obviously, all indices have to have the same type.
For some reason hash tables are called maps in Scala, but we will stick to the generally accepted term.
We can initialize hash tables either by creating an empty table or by initializing a new table.
The following command creates a new empty hash table whose keys are strings and whose values are integers:
If we want to add a key-value pair to a hash table, we can use the operator +
As an example, suppose that A has as keys Greek Acrophonic Attic digits and as values the corresponding Arabic numerals.
Exercise 2.28 If you try this code, you will discover that Scala will complain about some illegal characters.
Which are these illegal characters and why are they illegal?
Now if we want to ﬁnd to which number corresponds a Greek Acrophonic Attic numeral, we can deﬁne a function as the following one:
Here method foreach scans all keys, thus, d takes the value of all keys in the table.
Obviously, it is very straightforward to use this function as the following usage example shows:
Assume that we are developing an application that generates web pages.
Since color is an important aspect of every serious web page, we could deﬁne a hash table to hold an association between names of colors and their hexadecimal representation like the following one:
One can check whether there is a particular key by using method contains as shown in the example that follows:
If we want to remove one or more pairs from a hash table, we can use the operator minus as is shown in the example that follows:
The condition evaluates to true and, consequently, a message is printed on the computer screen.
Although it is not particularly useful to delete all entries from a hash table, the following code achieves this task:
Method keys generates a special data structure from all the keys of the table.
One can easily process the elements of such a data structure, which is known as an iterator exactly for this reason.
In fact, even a hash table is an iterator, but one that returns pairs.
Thus, the code that follows does exactly what the previous command does:
If a hash table is empty, then method isEmpty will return true.
For example, if the following code is executed after the previous command has been executed.
Method values returns an iterator data structure that contains all values that are stored in a hash table.
Exercise 2.29 The expression x.toInt yields the Unicode code point of a Char object x.
Create a hash table that has as keys the letters of a string and as values their Unicode code points.
Assume that the hash table from the previous exercise is called letters.
Then the following code sums up the values of the table:
Method elements creates an iterator that consists of all pairs that make up a particular hash table.
Following the previous example, we can print all pairs of table letters with this command:
Let us conclude this section with an interesting example that we have borrowed from the Rosetta Code web page5: Given two arrays of equal length, create a hash table which has as keys the elements of the ﬁrst array and as values the elements of the second array.
Note that expression keys.zip(values) creates an array of pairs, while on the other hand Map expects a sequence of pairs.
By now, it should be obvious that the symbol : is used to specify the type of a variable or expression.
In general, if T is a type name, then T* is a shorthand of Seq[T]
This is the trick employed to declare a function or amethodwith a variable number of arguments or varargs, as they are usually called in computer jargon.
In the example above, using this trick we make the language processor “think” that the array of pairs is actually a sequence of pairs, which is exactly what Map expects.
Roughly, we can say that sequences, that is, objects of type Seq[T], are generalized lists.
First we deﬁne the companion object where we deﬁne the hash table where our program stores the Fibonacci numbers computed so far.
We know the ﬁrst and the second numbers and the third number is obviously equal to the second, so initially we store these three numbers in the table:
Figure 2.1 A memorized version of a function that computes the Fibonacci numbers.
The last two commands compute nothing since the corresponding Fibonacci numbers had been computed by the second command.
Lists are the most important data structure of functional programming languages.
Also,Lisp is a programming languagewhere programs aswell as data are represented as lists.
Roughly, a list of objects of some type A is a data structure that is either empty or else it is nonempty and consists of an object, called the head of the list, and another list of objects, called the tail of the list.
The empty list is speciﬁed by Nil, which is an object that represents any empty list.
An entity, for example the number one, and the empty list make a list with only one element.
The method ::, pronounced cons, transforms an object and a list into a new list whose head is the object and whose tail is the ﬁrst list.
Alternatively, one could use the following deﬁnitions for variables A, B, and C:
Writing down explicitly the elements of a list is not the best way to create a list.
As an alternative solution, one can use a for comprehension to specify the elements of a list implicitly.
For example, the following code creates a list that contains all whole numbers from one to ten:
Here the keyword by is used to specify the iteration step.
An easier way to create the same list is shown below:
Function range creates a sorted list of integers in a speciﬁed range.
If we omit the third argument, this function creates a sorted list of all integers in the speciﬁed range.
After the execution of this code, what will be printed on the computer screen?
In general, when processing a list, one ﬁrst needs to specify how the head of the list will be processed and then how the tail will be processed.
Since the tail is a list, this implies that the processing will stop once we have to process an empty list.
This implies that the most natural way to process a list is by using a recursive procedure.
As a ﬁrst example, let us see how one can compute the length of a list of integers:
Given a list A, its length is computed by A.length, nevertheless, we present this example for purely pedagogical reasons.
This function examines the list and if it is empty (method isEmpty returns true if the list is empty), it returns zero since the length of an empty list is zero.
If the list is not empty, then it returns one plus the length of the tail.
Methods head and tail return the head and the tail of a.
Although this function is correct, its deﬁnition seems unnatural to people with a background in functional programming.
In a typical functional programming language, someone would program this simple function using pattern matching.
When using this approach, one presents a number of general structural cases that are matched by concrete instances.
For example, when dealing with lists there are two general structural cases: either the list is empty or it is nonempty.
The match command, or expression if you ﬁnd this term more appropriate, is used to examine an object against such structural cases.
Before giving some of the relevant details, let us see how we could reprogram our function using pattern matching:
In a match expression we specify ﬁrst an object, then the keyword match and then the structural cases.
Each structural case starts with the keyword case followed by a pattern and the command or commands to be executed if the pattern is matched.
The symbol => separates a pattern from the command or commands.
In this particular example, we have two such cases: when the list is empty this is denoted by Nil and when it is not empty this is speciﬁed by the x::xs expression.
Here x denotes the head of the list and xs denotes its tail.
Exercise 2.32 Write down a function that sums up the elements of a list of integers.
Let us try to solve a slightly more difﬁcult problem: how to reverse only lists that contain only two elements.
This problem is not really hard, but it gives us the opportunity to present various forms of patterns.
Before proceeding, try to solve the problem without using pattern matching.
The empty list, a singleton list (i.e., a list with only one element) and a list with more than two elements should be returned intact.
A singleton list is one whose tail is the empty list, thus, the pattern x::Nil should be used to capture this case.
Alternatively, one could use the pattern List(x), but we do not recommend the use of such patterns as they cannot express really general cases.
A list with two elements is described by the pattern x::y::Nil.
The last case can be described by a similar pattern.
Let us now see a more challenging problem: to write a function that reverses the order of the elements in a list.
One way to solve this problem is by thinking that the head of the list has to be the last element of the list and this would apply to the head of the tail of the list, etc.
In order to implement this idea, we need to use the ::: operator, which is pronounced prepend.
The result of the expression A:::B is to have A prepended to B (remember that all operators whose name ends with : are right-to-left associative, see Table 2.3; this implies that A:::B is syntactic sugar for B.:::(A))
We are now ready to present a solution to our problem:
Unfortunately, this solution is not optimal and this is the reason most functional programming languages provide an alternative implementation of this function.
In order to deﬁne such an alternative implementation in Scala we need to introduce some important notions.However, before proceedingwith the presentation of these notions, we will present some (predeﬁned) methods that each List object can use.
The method count returns the number of elements of a list that have a particular property.
The following command prints the number of even elements of A:
Variable e is a dummy variable that successively assumes the value of each element of the list, examines the condition that follows the => symbol and if it yields true, then it increases the value of a hidden counter.
In the end, it returns the value of this counter.
Exercise 2.33 Deﬁne a list of strings and print the number of strings that contain only two characters.
Hint: If A is a string, then A.length returns its length, that is, the number of characters it contains.
The methods take, drop are used to take from a list a speciﬁc number of consecutive elements.
Sometimes it is more convenient to view certain methods as operators and this is just one such case.
The left operand of take is a list L and the right operand is an integer number n.
The expression “L take n” returns a sublist of L that consists of the ﬁrst n elements of L.
If n is greater than or equal to the length of L, it returns L.
Similarly, the operator drop has as operands a list L and an integer number n and the expression “L dropn” returns a sublist of L that consists of all but the ﬁrst n elements of L.
Finally, the expression “L splitAt n” returns a pair of lists deﬁned as follows:
This means that if for some reason we need to modify a list we practically have to create a new list from the original.
Now, if we want to remove a number of consecutive elements from the right-hand side of a list, we can use the method dropRight.
This method takes one argument which is the number of elements to be removed.
Method exists can be used to check whether some element of a list has a particular property.
On the other hand, method forall examines all elements of a list and if all of them have a property, then it returns true.
Method filter yields a list that includes all elements that have a particular property.
For example, the following function implements the quicksort sorting algorithm of Tony Hoare.
The function that follows is not really quicksort, but in a way looks like quicksort.
The reason is that quicksort relies on destructive assignments, while the style of this function is functional.
At any rate, this function does what it claims to do – it returns a list that contains the elements of its argument sorted.
Since the corresponding expression of the function deﬁnition above would not ﬁt on one line of this book, we had to transform it into an expression of the following form:
Method foreach has the same functionality as the corresponding method used by arrays.
However, method map, which functions as method foreach, takes as argument a function that returns a type other than Unit, which is the type of all arguments of foreach.
Here is an example that shows exactly what we mean:
Here the character _ stands for an anonymous variable that is supplied to this function by the operator from the list.
In certain cases, instead of the foreach method one can use a for expression.
A for expression differs from a for comprehension in that the former yields a value.
For example, the following shows how one can use a for expression:
Method reverse returns the elements of the list with their order reversed.
Method remove yields a list that does not contain the elements that satisfy a certain condition.
This method can be used just like most of the methods described above.
However, one can use closures, in order to make the deﬁnition look more natural:
A preﬁx of a list is a list of elements at the beginning of the list that satisfy a certain property.
Method dropWhile returns what is left from a list when the largest preﬁx of a list is removed from the list:
Method init returns all but the last element of a list, or in Scala parlance:
Let us repeat that two objects are equal when they have exactly the same structure.
Obviously, if they have different types, the comparison is always false, unless the type of one is a subtype of the other.
Method last returns the last element of a list, or in Scala parlance:
Although it is uncommon to ask for the nth element of some list, Scala provides the method apply which can be used to obtain an arbitrary element of some list:
Method zip takes as argument a list and creates a new list that consists of pairs: the ﬁrst element from this list and the second from the argument list.
If one list is shorter than the other, the resulting list has the length of the shorter list.
If we have a list whose elements are lists, then function flatten can be used to concatenate the elements of this list as shown below:
In addition, method flatMap concatenates the elements of a list of lists but ﬁrst it applies to each element a function.
For example, if double is a function that multiplies by two each element of a list, then one can use this function as shown below:
The method toString is used by any object to create a canonical string representation of this object.
Since it is not possible to redeﬁne this method, Scala’s implementor has equipped lists with the mkString method.
This method has three arguments – the ﬁrst speciﬁes the delimiter that opens a list, the second speciﬁes a symbol that will be used to separate elements, and the third speciﬁes the delimiter that closes a list.
Exercise 2.35 Explain how one could obtain the standard Scala string representation of lists using mkString.
In certain cases it would be useful to be able to copy a list to an array.
Method copyToArray has two arguments – an array and the starting position, which implies that we can copy part of a list.
The functions foldl and foldr are used very frequently in functional programming to compute various things.
Here f is a binary operator and y a sort of unit element of the operator (for example, if the operator is +, then y = 0)
In Scala the foldl and foldr operators are “called” /: and :/, respectively.
Suppose we want to deﬁne a function that computes the sum of any list of integers.
Then we can deﬁne this function using foldl as follows:
Exercise 2.36 Assume that prod is a function that computes the product of all elements of a list of integers.
Let us now deﬁne function reverse as it is actually deﬁned in Scala:
Note that List[Int]() is an annotated version of Nil, the empty list.
Exercise 2.37 Explain why function rev computes the reverse of a list.
As a ﬁnal example, let us present a function that can compute the ﬁrst n prime numbers using the sieve of Eratosthenes:
This algorithm was invented by David Turner and ﬁrst appeared in his unpublished SASL Language Manual.
In Scala, as in Java, a string is an immutable object, that is, an object that cannot be modiﬁed.
On the other hand, objects that can be modiﬁed, like arrays, are called mutable objects.
Each element of a string is associated with an index number.
In the case of strings, the rightmost empty string "" is considered to occur at the index value that is equal to the length of the string.
In the case that the method takes one argument, then the substring begins with the character at the speciﬁed index and extends to the end of this string.
In the case that the method takes two arguments, the substring begins at the index speciﬁed by the ﬁrst argument and extends to the character at the index speciﬁed by the second argument.
Exercise 2.38 Write a function to recognize palindromes, that is,words that read the same backwards as forwards.
A man, a plan, a canal: Panama! Evil rats on no star live.
Hint: Use replace to eliminate all punctuation marks, transform all sentences to lowercase, and use the fact that for any string A:
This is a knownbug in the language implementation and springs fromScala’s dependence on Java’s basic types and the desire of Scala’s designers and implementors to provide a really complete set of methods for each basic type.
Regular expressions are used by many editors and other programs to search, edit, or manipulate text and data.
A regular expression is a way of describing a set of strings using commonproperties (for example, strings that start with an“A”and end with an exclamation mark)
Although Scala provides a package that can be used to create regular expressions and use them,we will show how to use the corresponding standard Java libraries.
The libraries are actually a reimplementationof Perl’s regular expressions engine.
Before describing how to specify regular expressions, let us ﬁrst see how we can use them.
Since regular expressions are like tiny language processors, it is far better to compile them into some internal representation and then use them.
Table 2.7 Special characters that can appear in regular expressions.
The most simple regular expression is a sequence of characters (for example, the string bar) that will match any substring that contains the characters of the pattern in this order.
Thus, the pattern bar will match the “bar” in string Babar.
If for any reason we cannot directly type a particular character or need to use a character that has a reserved meaning, then one should consult Table 2.7
Character classes Assume we want to check whether a string contains either the string bar or the string par.
In other words, we want to check whether a string contains a substring that starts with either “b” or “p” and ends with “ar.” Thus, it.
To handle cases like this, one can use character classes that describe a set of characters and one can use them to check whether a character belongs to this set.
All elements of a character class are enclosed in square brackets.
Thus, we can use the following code to solve our little problem:
By placing the symbol ^ just after the left square bracket we specify that we are looking for strings that do not contain the characters in the character class.
Ranges are speciﬁed by writing the ﬁrst character of the range, a dash, and then the last character of the range.
Finally, there are a few predeﬁned character classes which are shown in Table 2.8
Quantiﬁers Inmany cases we do notwant the regular expression engine to perform an exhaustive search of the string and match against all possible substrings.
Quantiﬁers can be either greedy, reluctant, or possessive as shown in Table 2.9
Let us ﬁrst brieﬂy discuss the difference between these quantiﬁers.
As expected, the following code will ﬁnd two instances of “o” in the corresponding string:
Method find attempts to ﬁnd the next subsequence of the input sequence that matches the pattern.
It returns true if the attempt is successful, false otherwise.
Methods start and end return the start index of the previous match and the offset after the last character matched.
If we change the pattern to "o?," then this pattern will be matched ten times! This happens because it may match one or zero times.
But since empty strings are matched also, this explains the tenth time.
Similar results will be delivered if we change the pattern to "o*." However, if we change the pattern to "o+," then the pattern will be matched exactly two times.
Exercise 2.39 Write down the corresponding matcher deﬁnition and a while-loop like the one in the previous paragraph for each pattern.
Exercise 2.40 Assume we have the following regular expression and input string:
What do you expect to see on your computer screen when the code.
We can specify alternatives with classes, but we can employ a special notation involving groups.
In particular, we can specify the alternatives in a group where alternatives are separated by the symbol |
For example, the pattern (\+|-)? will match either a plus or a minus sign.
If we place a backslash (\) in front of any special character, then it is turned into a normal character.
Also, if for some reason we want to refer to a subpattern that forms a subgroup and which has been matched already, then we can do so by using \n, where n is the subgroup’s number.
Note that everything that has beenmatched is stored inmemory for future reference.
Boundary matchers These are special symbols that should be used when it matters where the string that will be matched is located.
For example, when one analyzes an input string it matters whether some token is in the beginning or the end of the string.
The various boundary matchers that are available are shown in Table 2.10
Compiler ﬂags The regular expression compiler can be invoked with an extra argument as shown below:
This extra argument is a ﬂag that can be either one of the following symbols or a combination of them using bitwise conjunction and/or disjunction.
The beginning of a line $ The end of a line.
There are some embedded ﬂag expressions, shown in Table 2.11, that can be used inside a regular expression.
This way, one can avoid specifying the ﬂags presented above.
Replacing text There are two methods that can be used to replace text that matches a given regular expression.
Method replaceFirst replaces the ﬁrst occurrence while method replaceAll replaces all occurrences.
The following code shows how these methods can be used:
Y(?!X) A zero-width negative lookahead; matches a Y and a trailing X while.
Second, the group (?!\\d) is a special group that does not count when numbering groups.
This group is used when we want to make sure a speciﬁc pattern is not followed on another speciﬁc pattern (see Table 2.12 for more details)
Exercise 2.41 The following regular expression can be used tomatch ﬂoat numbers:
The term scientiﬁc computation refers to the use of computers to compute numbers and functions important to sciences and engineering.
Scala has not been designed as a tool for scientiﬁc computation, but provides rudimentary support for it.
Scala deﬁnes an object that contains ﬁelds and methods that can be used to perform basic numeric operations such as the elementary exponential, logarithm, square root, and trigonometric functions.
Object Math deﬁnes a number of methods that are described in Table 2.13
Note that there are four different versions of max, min, abs, and signum: one for each number type.
In all other cases, methods expect arguments of type Double and return values of the same type.
Obviously, one can import all methods deﬁned by this object.
However, in certain cases it is better to use only the methods that are needed.
For example, if a and b are the lengths of the catheti of a right triangle, then the expression.
Object Math also deﬁnes a number of ﬁelds that are described in Table 2.14
The NaN ﬁelds represent something that is not a number.
Unfortunately, we cannot use these ﬁelds to test whether an expression evaluates to a value that is not a number.
Fortunately, there are some methods, which have found their way into Scala through the Java programming language, that can be used to test whether an expression evaluates to a value that is neither a number nor a ﬁnite number.
The example that follows shows how these methods can be used:
Assume we have to write a function that increments a Double number by EPS_DOUBLE.
At ﬁrst this may seem a trivial task, but it is not.
First, we need to check whether the argument is an inﬁnity or a nonnumber.
Clearly, in this case the function must return its argument intact.
To transform back and forth we need to use some methods available only to the corresponding Java objects.
As for the rest of the code, we leave it to the reader to ﬁnd out what it does.
The following two tests will both print OK, thus verifying that our function works as expected:
Classes and traits (see Section 3.3) can be declared inside other classes and/or traits and are called inner.
With inner classes it is possible to “connect logically related objects simply and effectively” [6]
In order to demonstrate the inner workings of inner classes, we will borrow the bank account example from [6]
In this example, the last action is always expressed as an instance of an inner class.
The code in Figure 2.2 shows a version of a very simpliﬁed bank account class that implements exactly this functionality.
The ﬁrst thing one should note in inner class deﬁnitions is that they introduce a scope.
All ﬁelds and methods deﬁned outside the inner class are accessible from within the inner class, however, methods and ﬁelds deﬁned inside an inner class.
Thus, if we add a ﬁeld act in class BankAccount, then the name act inside Action will not refer to the ﬁeld of class BankAccount.
One could say that the deﬁnition inside the inner class hides or shadows the corresponding deﬁnition that occurs just outside the inner class.
Shadowing occurs also when a ﬁeld or a method is inherited by an inner class.
Thus, when using simple names in an inner class they refer to themembers of the inner class whether they are declared or inherited.
The members of the enclosing class can be accessed explicitly with a qualiﬁed-this expression.
In particular, if class Z deﬁned inside class Y has a method m, then if class Y has a method deﬁned or inherited with the same name it can be referred to in code inside Z with Y.this.m.
For example, if the following deﬁnition is part of class BankAccount.
Similarly, if class Y extends class X, then we can refer to the superclass implementation of the method m in code deﬁned in Z with Y.super.m.
Packages are used to group classes and, thus, they can be used to separate source code in several source ﬁles.
The ﬁrst part of the name of a Java package represents the organization which created the package while the rest of the name reﬂects the contents of the package.
In addition, a Java package name also reﬂects its directory structure.
But Scala packages differ from Java packages in that Scala has incorporated ideas borrowed fromC#
In particular, it is possible to declare one package inside another, thus forming a hierarchy of nested packages.
When this code is compiled, itwill create adirectory called A and inside this directory it will create another directory, B, which will contain the ﬁle a.class.
Similar to inner classes, nested packages and/or classes deﬁne a scope, thus affecting the “visibility” of classes and/or class members.
Packages may affect the visibility of members of a class in a different way.When a member of a class is declared as private[this], this means that it can be accessed.
If instead of this we use a package name, then this member can be accessed by this package and packages declared inside this package.
For example, if we use the access modiﬁer private[parsing] and we have the following package hierarchy.
The command offers some options that can be used to control which classes, methods, objects, etc., will be imported.
In the simplest case, we can specify exacly what to import.
In addition, it is quite possible to give a new name to a member as shown below:
The last thing one should know about the import command is that one can have imports anywhere in a source ﬁle.
As was noted in Chapter 1, one can place comments in code by placing the symbol // anywhere in the source code.
In general, comments can be used to force a language processor to ignore a section of the source code and/or to include text that of course is ignored but explains the functionality of the source code.
In many cases, these comments serve as a basis for the construction of a reference manual.
To facilitate the construction of such documents, the designers of the Java programming language introduced the.
In a doc-comment, whatever comes before the ﬁrst period is considered a summary for the identiﬁer.Of course it is amatter of stylewhat one considers a good summary, so we will not make any attempt to dictate to the reader what to write in doc-comments.
One can add HTML tags inside a doc-comment to enhance readability, to provide links to documents that may contain speciﬁc details, etc.
Furthermore, one can use a number of different tags inside a doc-comment.
The @author tag can be used to specify the author of a class or a trait.
If there is more than one author, then one should specify each author with a different @author tag.
The @version tag should be used to specify the version number of a class or a trait.
Since different versions of the same software may introduce new features, add or remove functionality, etc., it is quite useful to keep track of when particular changes took place.
This necessity is served by the information stored in a @since tag.
The @param tag can be used to explain the functionality of parameters.
For each parameter there should be a corresponding tag line.
Each such line should have the tag followed by the name of the parameter followed by a description.
The @return tag should be used to describe what a method returns.
The @see tag provides a means to have references in the ﬁnal documentation.
If the tag is followed by simple text, then the tag will be replaced by a “See Also:” and the text of the tag will appear on the next line.
The text can be normal text (for example, the title of a book), an HTML hyperreference tag, or something like the text in the following tag:
The @throws adds a “Throws” subheading to the generated documentation.
Finally, the @deprecated tag followed by text adds a comment indicating that what is commented should no longer be used.
Annotations are comments of a special kind that do not directly affect the intended meaning of any program, but they supply information about how a program should be compiled, deployed or executed.
For example, the annotation @deprecated before a method as shown below.
Scala deﬁnes a number of annotations and in the rest of this section we will present most of them.
This annotation in front of a class deﬁnition designates that instances of this class are serializable.
Since Scala does have checked exceptions, if one wants to write code that interoperates with Java code, then Scala methods must be annotated with one or more @throws annotations such that Java code can catch exceptions thrown by a Scala method.
BeanProperty This is an annotation deﬁned in the scala.reflect package.
It adds setter and getter methods following the JavaBeans convention.
According to the JavaBeansAPI speciﬁcation (available fromOracle’s web site):A Java Bean is a reusable software component that can be manipulated visually in a builder tool.
Scala supports this idea but follows different conventions (see Section 3.12)
The constructs that have been presented in the previous chapter are enough for the creation of simple software systems.
On the other hand, it is quite possible to create very complex software systems with these constructs, but the design and implementation processes will be really difﬁcult.
Fortunately, Scala provides many advanced features and constructs that facilitate programming as a mental activity.
In this chapter we will describe most of these advanced features, while a few others like parsing combinators and actors will be presented thoroughly in later chapters.
In the previous chapter we presented many important data types, but we did not mention trees,which form a group of data types that havemany uses.
Also, from the discussion so far, it is not clear whether Scala provides a facility for the construction of recursive data types, that is data types that are deﬁned in terms of themselves.
For example, a binary tree is a typical example of a recursively deﬁned data structure that can be deﬁned as follows [4]
Deﬁnition 1 Given the type node, a binary tree over the type node is deﬁned in the following way.
Typically, when using an imperative programming language like C, one has to use records and pointers, that is, values that point to elements of some type T that are stored somewhere in a computer’s memory using their memory address, to deﬁne recursive data types.
Admittedly, this is a low-level mechanism and one that has no place in a high-level language like Scala.
Roughly, an algebraic data type is a type where it is necesary to specify the “shape” of each of its elements.
In particular, an algebraic data type is deﬁned as an alteration of constructors of the type.
For example, one could specify a binary tree over integers using a hypothetical data type speciﬁcation command as follows (the vertical bar is pronounced or):
Scala is an object-oriented programming language and its main data structuring facility is the class.
Since algebraic data types are particularly elegant and useful, Scala allows its users to deﬁne class hierarchies that mimic algebraic data types.
More speciﬁcally, the type itself is declared as an abstract class and all the forms of the type are declared as subclasses of the abstract class.
A type is called abstract if its identity is not precisely known.
When it comes to classes, one is termed abstract when its body is partially deﬁned or completely empty.
The deﬁnition that follows is the Scala equivalent of the previous deﬁnition:
Once we have deﬁned a case-class hierarchy, we can construct instances of these classes without using the new command.
For example, the following commands create an empty tree and a tree with only one node:
Instances of recursive data types are easily manipulated with recursive functions.
If we want to list the nodes of a binary tree, there are three different strategies.
These strategies are known as pre-order, in-order, and post-order tree traversals.
It is not difﬁcult to design a function that will ﬂatten a binary tree into a list using, say, the in-order tree traversal strategy.
Here we have used pattern matching since this is the easiest way to solve such problems.
Previously, we stated that in most situations the cases in a match command correspond to the cases introduced in a case class deﬁnition.
For example, consider the following function deﬁnition that computes the depths, that is, the longest path from the topmost node to the lowermost node:
Exercise 3.1 Write two functions that implement the pre-order and post-order tree traversal strategies.
Although it is interesting to see how one can manipulate binary trees or, more generally, recursive data types, it is equally important to showhowone can construct such structures.
Instead of showing how one can build any binary tree,we will show how to build binary search trees.
Roughly, a binary search tree is a tree such that given a node n its left subtree contains only values less than the node’s value and its right subtree contains only values greater than the node’s value.
In addition, we demand that no two different nodes can hold the same value.
Clearly, we do not need to provide a special deﬁnition for these trees – the one given above is OK.
Interestingly, if we traverse and print each element stored in a binary search tree using the in-order tree traversal strategy, the elements will be printed in ascending order.
In other words, building a binary search tree and then traversing the tree can be considered as a sorting algorithm.
We assume that we are going to build a binary search tree from data that are stored in a list.
The following code shows how one can build a list from data that are supplied interactively by a user.
On page 37 we showed how one can write a loop that inputs from the keyboard a sequence of numbers.
The skeleton code snippet that follows shows how we can build a list from input supplied from the keyboard:
Now that we have a list, the next thing is actually to build the tree.
For this we need a function that will insert one element at a time into the tree.
This function will be used repeatedly by another function that will insert all elements of the list into the tree.
The code in Figure 3.1 shows how this can be done.
We have opted to deﬁne function mkTree this way in order to keep things simple, at least for the user.
The recursive function insert has two arguments: the element to be inserted in the tree and the tree itself.
If the tree is empty, it just returns a new Node.
Otherwise, if the element is less than the element stored in the current node, it returns the current node with the element inserted in the left subtree of the tree; if the element is greater than the element stored in the current node, it returns the current node with the element stored.
Figure 3.1 A function that builds a binary search tree from a list.
Finally, if the element is equal to the element of the list it is disregarded and this is the reason the function returns an empty tree.
Function mkTree ﬁrst creates an empty tree and then it inserts the elements of the list in reverse order into the tree.
In order to help the reader fully grasp the way function mkTree operates, we provide a full trace of an invocation of this function in Figure 3.2
Exercise 3.2 Write a function reflect that will take a binary tree and return a second binary tree whose left subtree is the right subtree of the original tree and whose right subtree is the left subtree of the original tree.
Exercise 3.3 A linked list is a data type that can be deﬁned in Scala as follows:
Write functions that create a linked list, delete a particular element from a list, and add an element in a speciﬁc position.
A problem whose solution is reminiscent of in-order tree traversal is the problem of the Towers of Hanoi.
This problem can be stated as follows (see Apostolos’s web page for more information)
There are three poles and a tower of disks on the ﬁrst pole, with the smallest on the top and the largest on the bottom.
The purpose of the puzzle is to move the whole tower from the ﬁrst pole to the second, by moving only one disk each time, and by observing the rule that a larger disk cannot be placed atop a smaller one.
The problem can be solved by a simple problem-reduction approach.
One way of reducing the original problem, that is, that of moving a tower of n disks from pole A to pole B by using pole C , to a set of of simpler problems involves the following chain of reasoning.
Furthermore, the other disks should not be moved to pole B since then we would not be able to move the largest disk there.
Therefore we should ﬁrst move all the other disks to pole C.
In this way we have reduced the problem of moving a tower to the problem of moving a tower with height one less and that of moving the largest disk.
This solution can be most effectively rendered as a recursive function.
Function hanoi implements the recursive solution suggested by the solution above:
An s-expression is a data structure which forms the basis of pure Lisp.
Deﬁnition 2 Assume that T is a simple type whose elements are called atoms.
Then the set of s-expressions is deﬁned as the smallest set such that:
It is not difﬁcult to deﬁne a character s-expression as follows:
Nevertheless, the function that follows can be used to build an s-expression interactively:
Exercise 3.4 Write a function printSExp that will print its only argument fully parenthesized.
Exercise 3.5 Tradionally, the Lisp programming language includes three operators: car, which returns the ﬁrst element of an s-expression, cdr, which returns the rest of an s-expression, and cons, which takes two s-expressions and creates a new one.
Write three functions that implement the functionality of these operators.
In the previous chapter, in general, and the previous section, in particular, we discussed the various forms of patterns, without giving the whole picture.
In this section, we are going to present systematically all types of patterns as well as sealed classes and optional values.
The simplest pattern is the wildcard pattern _, that is, a pattern that matches anything.
For example, here is a simple function that examines whether a binary tree is empty or not:
Also, this pattern can be used as a “don’t care” pattern.
For example, if we want to print the information stored in the topmost or root node of a binary tree, we could use the following function:
Identiﬁers are like the wildcard pattern except that the values that are matched are stored in variables that have these names.
We have seen usage examples in the previous section.However, these variables cannot be used to alter the corresponding value.
A rather interesting problem is this: Since identiﬁers are actually wildcard patterns and as such match anything, what happens if we use as identiﬁer the name of a ﬁeld? The answer is that it ﬁrst checks whether an identiﬁer is the name of some ﬁeld and if this is true, then it matches only the value that this ﬁeld corresponds to.
However, this contradicts what was said above, that is, that identiﬁers are like wildcard patterns.
Unfortunately, we forgot to mention that only identiﬁers that start with a lowercase letter are treated as wildcard patterns.
Now, there is another problem: What if a ﬁeld starts with a lowercase letter? How can we match such a ﬁeld? The language designer suggests that the easiest way to tackle this problem is to preﬁx the identiﬁer with a class or an object name.
Thus, the language designer suggests enclosing the identiﬁer in backticks (the patterns are called stable identiﬁer patterns, see Section 6.7.1 for an explanation and a real usage example)
Thus, it is wise to plan ahead before attempting to use bare identiﬁers in pattern matching.
Fortunately, things are clearer when one uses identiﬁers in constructors of case classes.We have presented many usage examples of this kind in the previous section, so there is no reason to present more examples.
Patterns can also be used to process lists as was explained in Section 2.13
However, what we did not mention is how to specify patterns that, for example, match a list whose second element is the number two while we do not care whether it is followed by zero, one or more elements.
However, note that this pattern must be used only in cases like the one demonstrated in the code snippet that follows:
The code will print “matches” since A is a list whose second element is the number two.
In conclusion, the pattern _* cannot be used with general patterns that involve the :: operator.
We can even use tuples as expressions to be matched by and tuples patterns to match expressions.
This function takes as argument a triple, that is, a tuple that consists of three elements.
In general, the type of tuple is speciﬁed as follows.
Another interesting thing about this function is the use of pattern guards.
This is a feature of Scala that is activated if a pattern is matched.
In this case, some additional tests are performed and depending on the outcome of the test, the pattern matches or fails.
Thus, only if the value of the third element of the triple is greater than or equal to 1.65, does the pattern.
Then the commands that follow will print the messages “Mary is tall,” “Chanelle is tall,” and “Sophie is not tall,” respectively.
This is a type of pattern that can be used to match not only values but also types.
This is achieved by attaching a type to the pattern.
For example, the following function can be used to check whether its argument is a number or not:
Note that the argument of this function is of type Any, since any object is of this type.
The expression ifNum(M), where M is the triple from the previous example, evaluates to false, while isNum(4) evaluates to true.
Exercise 3.6 Write a function that returns the length of (a) strings, (b) hash tables, and (c) lists.
Hint: You do not need to care about the type of hash tables and lists.
Let us now see whether we can write a function that tests whether its argument is a list of integers or something similar.
The reason is that Scala, following the lead of the Java programming language,“forgets” the type of elements that make up a structured type.
The language remembers only the structure not the type.After all, if the programhas passed the type-checking phase,1 there is no reason to “remember” the types.
Thus, it is almost impossible to have some sort of type violation.
Therefore, function isIntListwill always return true whenever it is supplied with any list structure.
There are cases where one wants to be able to match a part of a constructor, but then needs to refer to this part as a single entity.
For instance, assume that we have a tree and we want to obtain its left subtree only if in the topmost node is stored a number less than zero.
The designer of Scala observed that there are many cases like this and so he decided to provide variable bindings, that is the capability to refer to a subpattern by preﬁxing this subpattern with an identiﬁer that is followed by the @ symbol.
For example, if we opt to use this feature here is how the previous code snippet might look:
Although the examples presented so far are simple and they do not involve many cases, still in most real-world applications a case-class will have many subclasses.
In situations like this, one needs to make sure that in a typical match expression all possible cases are covered.
For this reason, the designer of Scala introduced the notion of a sealed class.
In order to play with sealed classes all we have to do is to declare the top class as such.
Canonically, a compiler goes through a number of phases like grammatical and syntactical analysis, and typechecking is one of these phases.
A program is type-correct if the type-checker cannot ﬁnd inconsistencies, for example multiplying an integer with a string.
Remember that Scala allows mathematical operations between characters and numbers, since characters are represented by integers.
However, more strict language designs do not allow the mixing of characters with numbers.
The really great beneﬁt of using sealed classes is that the compiler detects whether there is a problem in some match expression.
If this function is included in a ﬁle where the deﬁnition of a binary tree is included, then the compiler will produce the following warning message:
However, if we deﬁne the same function in a ﬁle where binary trees are deﬁned as a nonsealed class hierarchy, then the compiler will not produce any warning at all.
Unfortunately, there can be no good without evil and this applies even to sealed classes.
In situations where we are absolutely sure that all cases are covered, Scala will warn about cases that may not be covered in a particular match expression.
The solution to this problem is to use the @unchecked annotation as shown below:
The meaning of this annotation is that an exhaustive check of the patterns that follow is turned off.
If you enter in the Scala interpreter the expression 3/0, the interpreter will print a / by zero error message.
However, it is an indication of poor program design, when a program relies on the language runtime system to detect rare and exceptional errors.
A better way is to use exceptions, but another way is to use optional values.
Typically, an optional value can be either None or Some(v), where v is a value of some type T while the type of both None and Some(v) is Option[T]
Here is a function deﬁnition that computes the quotient of the division of twowhole numbers a and b:
Another common use of optional values is in the deﬁnition of the method by which it is possible to obtain the value that corresponds to a particular key of some hash table.
In particular, method get returns a None if no value corresponds to a key and a Some(v) if the value v corresponds to a key k:
Once we have deﬁned functions that yield optional values, the next question is how do we use these values? The “obvious” answer is: with pattern matching.
Here is how it is possible to print the result of function div:
In this case the result will be the word problems, while the expression.
As was explained in Section 2.6, any class can inherit any other class.
However, no class can inherit methods and ﬁelds from more than one class.
On the other hand, when a class can inherit methods and ﬁelds from more than one class, then we are talking about multiple inheritance.
Obviously, single inheritance is too restrictive, nevertheless, multiple inheritance can be a problematic feature since it increases complexity (i.e., lack of simplicity) of the resulting program, while the order of inheriting classes may affect the features and the behavior of the new subclass.
A much cleaner way to solve the problems of multiple inheritance while avoiding the disadvantages of single inheritance is mix-in composition.
On the other hand, traits can be mixed in a class.
In other words, several traits can be used to extend the behavior of a class.
Assume we are implementing a maze adventure game (think of Doom or Quake for example)
A player moves a virtual character from one virtual room to another through virtual doors.
For example, there are many kinds of doors – open doors, locked doors, magic doors, electronic doors, etc.
A naive way to implement these different kinds of doors is to implement each different door as a different subclass of a basic class.
For example, the code in Figure 3.3 shows how one could implement a class describing a locked door and a class describing a short door.
Unfortunately, this design approach does not make it straightforward to deﬁne a class that describes a door that is both short and locked – one has to deﬁne a new class.
Traits solve this problem by allowing the user to deﬁne behaviors that can be mixed in with the behaviors of existing classes, thus making the deﬁnition of a class that describes a locked and short door easy.
For example, the code in Figure 3.4 shows exactly how one can deﬁne some behaviors andhow they can bemixed in.Note that in this example the curly brackets that surround some white space denote that there is no addition behavior deﬁned.
Clearly one can omit them, but we have included them just to stress this point.
For reasons of completeness one can assume that persons are described by a rudimentary class like the following one:
The code in Figure 3.4 shows how one can deﬁne and use.
Figure 3.3 Single inheritance makes it impossible to create a class that describes a locked and short door.
In addition, one or more traits can extend the behavior of a speciﬁc trait.
When extending the behavior of a class with the behaviors described by a trait, one should use the keyword with followed by the trait’s name.
If one trait extends the behavior described by another trait, then one should specify this using the keyword extends.
Moreover, if more than one trait extends the behavior of another trait, the ﬁrst is preceeded by the keyword extends and all others by the keyword with.
Figure 3.4 Mix-in composition allows the composition of classes and traits and so one can describe locked doors, short doors, and locked doors that are short too.
Then we can redeﬁne class Lemon so as to extend its behavior as shown below:
Obviously, it is possible to make the color a behavior that is added by some trait.
So far we have showed how to extend the behavior of a class, but nothing has been said or even implied about the ability to extend the behavior of objects (i.e., class instances)
Not so surprisingly, Scala makes it easy to extend the behavior of objects.
Of course one should not get too excited as the behavior of objects cannot change while they are in use.
To make things clear, let us give a simple example.
Assume we want to deﬁne a set of strings where each element is a string that contains only lowercase characters.
The trait deﬁnition in Figure 3.5 deﬁnes the required behavior.
Here we redeﬁne three operators and, unlike what happens in many other programming languages, there is nothing special about the deﬁnitions here.
Also note that it makes no sense to redeﬁne the removal operator since all elements of a set are already in lowercase form, nevertheless, it was included for reasons of completeness.
Having deﬁned the additional behavior, here is how we can actually use it:
The last command will print the following on the computer screen:
Note that we have deﬁned an object of a particular class where, at the same time, its behavior is augmented by the behavior deﬁned in the trait.
Figure 3.5 A trait that deﬁnes a set of strings that can have as elements lowercase strings only.
It is possible to preﬁx the deﬁnitions and the declarations of a trait or a class by a deﬁnition whose most general form is as follows.
This declaration enables one to redeﬁne the type of this (i.e., the trait or class being deﬁned)
The self-type of a trait, class, or object must not differ from the corresponding self-types of the objects, classes,or traits that are inherited by the type used in the self declaration.
It is quite possible to specify only a class or trait name (i.e., a type) followedby the symbol =>
In this case, the speciﬁed typewill become the type of this.
In many cases when declaring a new class it is imperative to be able to compare instances of this particular class.
However, it is not at all obvious how one can implement a generic method by which object comparison can be a straightforward task.
Fortunately, one can use Scala’s trait mechanism to implement such a mechanism.
In fact, the standard Scala implementation provides a trait that provides the required functionality.
Every class becomes comparable when it mixes in with trait Ordered.
To understand how this trait achieves this remarkable functionality, it is necessary to study its source code:
Thus, one might think that it is necessary to deﬁne this method.
As a simple example, consider the following deﬁnition of class Person:
Note that here we assume that persons are sorted alphabetically using ﬁrst their last names, then their ﬁrst names and lastly the names of their fathers.
Also, note that a person is “equal” to another person if their ﬁrst names, family names, and their fathers’ names are equal.
If you run the following code, the symbol <will be printed on the computer screen:
Functions in Scala are modules that have a special apply method.
In addition, an application of a function is actually a method invocation.
This deﬁnition is completely equivalent to the following module deﬁnition:
That the two deﬁnitions are completely equivalentmeans that once we have deﬁned themodule double,we can compute the double of, say, the number three as follows:
In addition, to all thesewe can overloadmethod apply (i.e.,we can providemultiple deﬁnitions of the same method; see Section 3.6 for more details), thus allowing the use of the same function in different cases.
For example, if we want to be able to compute the double of integers, long integers, ﬂoats, double ﬂoats, and strings, we should redeﬁne our module as follows:
With this deﬁnition we can easily compute the double of different values:
As was explained in Section 2.7, there are two ways to deﬁne functions of two parameters and more for functions of more parameters.
Similarly, one can deﬁne a function of two arguments as an object in two different ways.
Assume that one wants to pass the object just deﬁned to a function that has as parameter a function that takes two double precision ﬂoat numbers as arguments and returns a double precision ﬂoat number.
Unfortunately, we cannot use our function as an argument of this function! The reason is that the language processor cannot correctly deduce the type of the function object, something that should not be taken as a language deﬁciency, but, rather, as an open problem.
And this is exactly why the language processor complains about a type mismatch.
To solve this problem we need to specify which Function trait our object extends.
The following deﬁnition is a revisited deﬁnition of our object according to the solution just described:
Now, it is legitimate to use D in commands like the following one:
An alternative way to specify the type of a function object is to use the “symbol” => or its equivalent.
In general, an expression of the form S=>T denotes a function whose domain consists of all elements of type S and whose codomain consists of all elements of type T.
Thus, the type expression R=>S=>T, where R is yet another type, is the type of some higher-order function.
Now let us see how we could rewrite the deﬁnition of object D:
Using this notation one can easily specify the type of parameters of higher-order functions.
For instance, let us deﬁne a higher-order function and use it:
A list, a set or a hash table is an instance of some predeﬁned class and as such it should be created using new command.
Nevertheless, when creating lists, sets or hash tables we do not use this command.
Thus, either this is an exception to the general rule, which is most unlikely, or somehow the use of the command is made implicit, which seems to be the case.
Indeed, for each such class deﬁnition, there is a companion object in which there are one or more deﬁnitions of method apply.
These method deﬁnitions invoke the class constructor passing their arguments to the actual constructor.
Now that we have deﬁned this class and its companion object, we can create instances of this class and use them as shown below:
Exercise 3.8 Redeﬁne the companion object of class Complex so as to allow the creation of ordinary complex numbers and complex numbers whose imaginary part is equal to zero.
Parameter passing Arguments are passed to functions which use them to compute a number, a string, etc.
Although this is absolutely obvious, it is not obvious at all how these arguments are passed to functions.
There are several ways to pass arguments to a function, but we will discuss only those relevant to Scala.
Typically, when a variable is passed by-name, it can be both accessed and updated, nevertheless, Scala does not allow variables to be updated, thus avoiding side effects.
In order to designate that a formal parameter should be passed by-name, we preﬁx its type designation by the symbol =>
For instance, the following interaction with Scala’s interpreter shows the difference between call by-value and call by-name:
Note that the symbol => must be separated by at least one space from the colon that follows a parameter’s name.
The ﬁrst and the third are of type Unit (i.e., one can pass as arguments Scala commands and expressions) and the second is a boolean expression.
Since each argument is re-evaluated each time it is needed, it perfectly simulates the behavior of the corresponding loop construct.
Thus, all changes made to the local copy are actually global changes.
However, one cannot use the same “trick”when the objects are “simple” objects like numbers and strings.
Although this may seem strange, the truth is that it is not! In the ﬁrst case, we alter members of the object while in the second we try to alter the whole object which is not possible.
Functions as patterns In Section 3.2.1 we presented the various forms of patterns supported by Scala, but we did not say anything about functions.
Unfortunately, functions are not represented by case classes and this prohibits their use as patterns.
On the other hand, functions are ﬁrst-class values and so it should be possible to use them in pattern matching.
Method unapply solves this problem in a very elegant way.
First of all let us explain what this method does.
This method is called an extractor because it can be used to extract parts of a type.
In the case of function objects, if we have such an object and a particular value of this function, then it is possible to obtain the arguments of this function.
Here method unapply implicitly introduces case classes since Some and None are a case class and a case object, respectively.
The following code snippet shows how these two function-objects can be used:
When the language processor “sees” a function call as a pattern, then it invokes its corresponding unapply method, provided that the function has been deﬁned as a function object.
As noted above, this method returns a case class object that is used in the pattern matching.
In this case, one can specify an easy way to create and to decompose objects.
For example, think of a case class that encodes a multiplication between two factors, then the unapplymethod will yield the two factors.
Partial functions A partial function is a function that is not deﬁned for all possible values.
For example, the reciprocal of a real number x is the number 1x , which is.
In general, partial functions are usually undeﬁned for a few arguments, nevertheless, there are some cases where a function is deﬁned for a few arguments only.
In the ﬁrst case, one can deﬁne a function so it can handle these few exceptional arguments for which it is undeﬁned.
For example, here is how one could deﬁne a function that computes the reciprocal of a whole number:
Unfortunately,we cannot use the same technique to deﬁne a function that is deﬁned for a few arguments only.
Instead, one can use the PartialFunction trait to deﬁne such a function.
The following example shows how we could deﬁne a partial function that computes the reciprocal of some whole numbers:
Note howone has to specify the value of each argument that is deﬁned.
The keyword case is followed by a value, for which the function is deﬁned, while the “symbol” => separates the argument’s value with the result of the “computation.” Also, one can deﬁne partial functions that take two arguments, but then again two arguments can be viewed as one:
The predeﬁned method isDefinedAt should be used to check whether a partial function is deﬁned for some particular value.
Then we can deﬁne a new composite function using the orElse method as shown below:
The resulting partial function will use R when invoked, and only when R is not deﬁned for a particular value will it invoke S.
As was explained in Chapter 1, polymorphism is one of the four basic principles of object-orientation.
Although we have brieﬂy explained what polymorphism is and we have shown how it can be used in Scala, still it is necessary to give a thorough description of polymorphism, in general, and how it is realized in Scala, in particular.
In the next few pages, we present the various forms of polymorphism and how these have been incorporated into the Scala programming language.
When a programming language has functions, methods, structures, etc., that can have a unique type, they are called monomorphic.
On the other hand, if a programming language has functions, methods, procedures, etc., whose arguments can have more than one type not at the same time but at different moments, then they are called polymorphic.
As is noted in [13], Christopher Strachey, who was a pioneer in programming language design, distinguished two major kinds of polymorphism – parametric and adhoc polymorphism.
A parametric polymorphic function or procedure is one that works uniformly on a range of types, which normally exhibit a common structure (for example stacks)
On the other hand, an ad hoc function or procedure is one that works, or at least appears to work, on several different and possibly unrelated types and which may behave in different ways for each speciﬁc type.
Inclusion polymorphism was introduced tomodel subtypes and inheritance,which are necessary to deal with object orientation.
Parametric polymorphism achieves uniformity by using the idea of type parameters, nevertheless, this is not the only way to achieve uniformity and in this respect parametric polymorphism is a special case of universal polymorphism.
For example, inclusion polymorphism assumes that an object belongs to many different classes that may form a hierarchy of subclasses.
Note that functions, methods, procedures that exhibit parametric polymorphism are usually characterized as generic.
A typical example of a generic method is the length method that computes the length of any list structure.
Whenwe say that a function or an operator is overloaded, then we typicallymean that the same name or operator symbol is used to denote different functions and it depends on the context to say which particular function or operator is denoted.
A coercion is the operation of converting an argument or an operand to the type expected by a function or an operator, where otherwise a type error would have been detected.
To understand the difference between overloading and coercion, consider the following operations:
The ﬁrst of these operations will yield an Int and the others will yield Doubles.
This is justiﬁed since classes Int and Double provide among others the following.
Thus, Scala deﬁnes all possible cases and no coercion is needed.
However, class Complex, which is deﬁned in Section 1.3, does not include an exhaustive set of overloaded deﬁnitions and thus coercion is employed to solve this problem.
This is exactly what the functions doubleToComplex and intToComplex do.
To summarize, coercion is the implicit type conversion when needed and overloading allows the use of the same name for different semantic objects.
Subtyping is a form of inclusion polymorphism and, roughly, the idea that some type is a subtype of another type.
We have encountered this notion already when we talked about the type hierarchy of numerical types in Section 2.4
In addition, since any class is a type, a subclass of some class is a subtype of this type.
In certain programming languages the same constant value is shared by a number of different types.
This type of polymorphism, which is known as value sharing, is a special case of parametric polymorphism.
Thus, subtyping is an example of true polymorphism whereas parametric polymorphism is the purest form of polymorphism.
Nevertheless, languages like C++ make a distinction between operators and functions.
In Scala everything that can perform an action is a method and, thus, operators are methods.
To see the difference compare the following deﬁnition in C++
Since we have already presented a complete example of operator overloading, we will use this example todescribe the various aspects of operator overloading in Scala.
In general, a real number, and for that matter an integer number, is a complex number whose imaginary part is equal to zero.
A function that performs an implicit conversion is a map by which elements of one type are mapped to elements of another type.
For example, it is possible to map integer and real numbers to strings in an obvious way.
A Scala function that is designed to perform such a mapping must be preﬁxed by the implicit keyword.
For example, the following function transforms integers to complex numbers:
Whenever the user speciﬁes an operation between a Double and a Complex, the language processor will perform an implict transformation of the Double to a Complex whose imaginary part is equal to zero.
An interesting question is what should happen when one attempts to multiply a complex number by an integer.
The answer is that Scala will complain since the language processor does not know how to handle the multiplication of any complex number by any integer number.
The simplest solution to this problem is to add one more implicit value converter:
One may wonder how the language processor knows which type transformer to apply.
A naive answer would be that it checks the name of each value converter.
However, the names of the implicit conversion functions have been chosen so as to reﬂect the functionality of these functions and there is nothing special about them.
So how does the language processor choose the proper converter? The answer is simple: it checks the type of all functions that have been declared as implicit and chooses the one that matches a particular case.
In the example that we study, the implicit function deﬁnitions appear outside the class deﬁnition but are part of a ﬁle that can be fed to the language interpreter.
In general, the best place to deﬁne these implicit deﬁnitions is the companion object.
For instance, here is how we could declare two implicit type converters:
Now, if one includes the revised code of class Complex in a ﬁle and appends a command like the following.
This is really strange because we have already speciﬁed what to do when an integermust bemultiplied by a complex number.
The solution is to bring the deﬁnition into scope via an import command, though it is actually in scope.
Exercise 3.11 The output we get is not aesthetically correct.
One should avoid deﬁning two or more implicit value converters that perform the same conversion.
If by mistake one has deﬁned two value converters, then the language will complain that implicit conversions are not applicable because they are ambiguous.
Last but certainly not least, one must note that value conversions are applied only if they are necessary.
In other words, the expression 4+3 is a valid Scala expression, so there is no reason to convert the two integers to complex numbers.
Nevertheless, the value converters are called in all instances where they are needed, such as the following command:
Implicit function parameters are parameters that are implicitly inserted in argument lists.
The trick to deﬁning implicit parameters is tomake a function deﬁnition as if it is a special function.
For instance, here is a function thatmay have an implicit parameter:
Once we have deﬁned a function with an implicit parameter, we need to specify the implicit value of this parameter.
Note that the name used in this deﬁnition can be anything and so it may seem as if it is completely irrelevant.
Now that we have deﬁned our function and the value of.
The following two examples show how this can be done:
If we want to have more than one implicit parameter, then we have to declare them in a similar way and make sure they all have different type.
Otherwise, the language processor will complain about ambiguous implicit values.
Here is an example of a function with three implicit parameters:
Obviously, it is now necessary to deﬁne the value of the three implicit parameters:
As a more realistic example, here is how one could modify the deﬁnition of the companion object of class Complex:
Let us start with a simple problem: how to write down a Scala function that takes a list and returns its last element.
A possible solution to this problem is the function deﬁnition that follows:
This deﬁnition differs from the previous in that there is, just after the function name, a generic type name, enclosed in square brackets, which is subsequently used in the speciﬁcation of the return type and the type of the argument.
This generic type is instantiated the very moment one uses this particular function with a proper argument (i.e., a list of something not an array of something)
In the following examples we deﬁne two lists of different type and use the same function to compute their last element:
If we leave the [Int] part out, the language processor will complain that a type mismatch occurred.
Exercise 3.12 A queue is an ordered list in which insertions are made at one end, called the rear, and deletions are made at the other end, called the front.
A simple way to deﬁne such a structure is to use case classes that deﬁne each part of the speciﬁcation.
However, in this case we demand that all basic stack manipulation functions be deﬁned as methods.
Case classes are a convenient tool to deﬁne algebraic data types implicitly, but they are also ordinary classes.
The abstract class deﬁnition that follows includes the deﬁnition of three abstract methods, that is methods that have not been initialized yet.
Method push is supposed to insert an element onto the stack, while method pop is supposed to delete the topmost element from the stack.
Method top is supposed to return a copy of the topmost element of the stack:
As is evident, an abstract class deﬁnition is a bare bones deﬁnition.
As in the case for trees, an empty stack will be modeled by an object not a subclass.
In the deﬁnition that follows, only function push is redeﬁned to do something meaningful since it makes sense to push an element onto an empty stack, while it makes no sense to delete an element from an empty stack or to print the topmost element of an empty stack.
The exception used in the previous class deﬁnition is a standard Java exception that can be used in any Scala program.
The empty stack is a subtype of Stack[Any] since we want this value to denote an empty stack of any possible type.
Surprisingly, the easiest part is to deﬁne the class that describes the real action:
Now that we have deﬁned the functional data structure let us play with it.
The reader can type in the deﬁnitions given above in a source ﬁle and then append the code snippet that follows:
When the ﬁnal ﬁle is fed to the language processor, the following output will be printed on the computer screen:
Exercise 3.13 Deﬁne purely functional queues using the following data type speciﬁcation:
Assume we are asked to write a generic function that can sum up the elements of any list.
A function implementing this functionality is one that understands how to add two objects having the type of the elements of the list and also which is the unit element of the addition (i.e., which is the element that does not affect addition, just as 0 does not affect the addition of integer numbers)
Obviously, it is difﬁcult, if not impossible, to implement such a function mainly because we cannot cover all possible cases.
However, a better solution would be one that takes an implicit parameter that contains the relevant information about the type of the elements of the list.
In fact, Odersky and his colleagues [58] have shown us how this function can be implemented in Scala and in the rest of this section we are going to describe it.
The ﬁrst step involves the deﬁnition of a generic type that abstractly deﬁnes the unit element and how addition is performed:
Observe that the unit element is the empty string and addition is string concatenation.
Similarly,we can deﬁne the required behavior for integers as follows:
The next step is to deﬁne a function that can sum up the elements of a list.
We can now use this function in the following way:
However, it is possible to omit the second argument of the function, since the language processor can automatically infer which object it has to use.
The reason is that the proper value is chosen from those available.
We treat the concept of monoid again in Section 8.10.2 when dealing with the path abstraction.
In general, relation <:, which is termed the conformance relation, must satisfy the following properties.
Scala API documentation NotNull is a “marker trait for things that are not allowed to be null.”
In this example, the formal parameter of function ghas to be of type cell, butwhen the function is invoked the argument is of type reCell, which is a subtype of cell.
The question is: Which method is called when function g is invoked? Obviously, there are two answers to this question: the function will invoke either the method of class cell or the method of class reCell.
If a programming language behaves as in the ﬁrst case, then it supports static dispatch; otherwise it supports dynamic dispatch.
When deﬁning a new polymorphic type, it is possible to specify its variance.
More speciﬁcally, a plus sign before a type denotes that the type varies covariantly, aminus sign before a type denotes that the type varies contravariantly, and when there is no plus or minus sign, this denotes that the type varies invariantly.
An example of a covariant class declaration is the standard Scala class Tuple2:
Note that ProductN is a trait that deﬁnes a cartesian product of N elements.
Also, an example of a contravariant trait deﬁnition is the standart Scala trait Function1:
Butwhy is such the varianceof these classes?The reason is explainedby the following two short arguments.
Covariance of pairs Assume that there is a pair (a,b)whose type is Tuple2[A,B]
Obviously, the type of its ﬁrst component is A and the type of its second component is B.
Then, by subsumption, a is also of type C and b is also of type D.
Contravariance of functions Assume we have an object f of type Function1[A,B]
If B <: D, then, by subsumption, f produces also results of type D.
Invariance of mutable pairs A mutable pair is one whose components can be updated.
This deﬁnition uses setters and getters (see Section 3.12), thus, we do not expect readers to understand everything.
For the time being, it sufﬁces to say that these are method deﬁnitions that look like ﬁelds when used.
Note that if a type cannot vary covariantly or contravariantly, then even if we “force” it to vary in a speciﬁc way the language processor will detect this and signal an error message as happened in this case.
Exercise 3.16 Provide a simple argument for the invariance of mutable pairs.
It is not unrealistic to demand to be able to express some assumptions or restrictions on type parameters.
For instance, deﬁning a function that sorts collections of elements means that the elements are comparable.
Also, a matrix multiplication method of a matrix class is applicable only to matrices of numbers.
This situation is quite common and it is known as bounded polymorphism [13]
Scala supports bounded polymorphism by allowing type constraints on type parameters.
Let us see how one can specify contraints and how they affect the structure of classes.
Assume we are building a class hierarchy that is supposed to describe seats in air carriers.
Typically, passengers who travel in coach class sit in cradle seats, but if one is lucky enough one may get a better seat.4 Here is a skeleton class describing coach class:
Here is an anecdote that proves this claim: More than ﬁfteen years ago A.S.
On their return date, their friend drove them to the airport, but they arrived almost 30 minutes before the ﬂight’s departure.
Unfortunately, there were no remaining seats in coach class, which meant they could not travel! Fortunately, their friend had a plan – he “explained” to the manager that all three of them were hearing impaired persons! The manager was shocked! He apologized to all for his behavior and found for A.S.
So this was the ﬁrst and until now the only time A.S.
The type declaration can be used to deﬁne new names, but it can be used to do more interesting things.We will present these additional capabilities in the next few sections.
The type command can be used either to deﬁne a type alias or to declare a bounded abstract type.
The most general form of a bounded abstract type declaration is.
Basically, bounded abstract types are used in the declaration of abstract types.
For example, here is how one would deﬁne an abstract class for cells:
As was shown in the previous example, in a type deﬁnition one writes ﬁrst the new type and then an equals sign that is followed by a predeﬁned or user-deﬁned type.
In the most general case, one may specify type parameters and any other information.
The last example is interesting because Tuple2 is a case class and not so surprisingly the type deﬁnition introduces a new case class.
Also, after a new type has been introduced with a type deﬁnition, the language interpreter will consider it as a normal type.
In other words, it will not try to “expand” type names.
In Section 2.4 we talked about a subset relationship between basic Scala types.
Instead, for all basic numerical types the following view bounds hierarchy is predeﬁned:
Here the wildcard type _ is a shorthand for the most simple existential type:
This means that the previous deﬁnition of the heterogeneous list is completely equivalent to the following deﬁnition:
Note that one could easily deﬁne the same heterogeneous list as follows:
Assume one wants to deﬁne a heterogeneous list that contains only elements.
Similarly, if we want to create a list that has as elements lists that can have at most long numbers, then we should deﬁne our list as shown below:
Now that we have an understanding of Scala’s existential types let us see some other interesting examples.
First of all let us deﬁne a function that takes an argument of any type and returns something of any type.
Obviously, this is an ideal job for existential types and here is how we can deﬁne this function and, moreover, how this function can be used:
An even more interesting example is the following case class hierarchy that can be used to implement an algebraic type that can be either a generic value or a pair that consists of a function that can take any kind of argument and returns a value of some generic type and a value of this generic value:
If we enter these deﬁnitions into the Scala interpreter, then we can experiment with these deﬁnitions:
The part of existential type that appears in curly brackets is called the binding clause.
The binding clause can contain more than one type declaration that must be separated by semicolons.
In addition, a binding clause may also contain value declarations.
The Singleton type is a type that has two values: null and the single value stored to a variable p.
Alternatively, we can deﬁne a variable having a singleton type with an initialization like the one shown at the end of the following interaction with the language interpreter:
Currently, there is a disparity between Scala and the JVM: Scala supports generic types but, unfortunately, the current version of the JVMdoes not.5 This implies that generic types exist during compilationbut they are omitted from the generatedbytecode, for the reason just explained.
Thus, once Scala is moved to MLVM, type erasure will no longer be a problem.
On the other hand, when a language has access to information about generic types at run time,we say that the generic types are reiﬁed.
Because of type erasure the implementors of Scala devised a mapping from generic types to nongeneric types in order to ensure the proper functionality of any.
If you wonder what types have to do with machines and machine code, let us remind you that the JVM is a high level virtual machine.
In addition, it is possible to deﬁne a typed assembly language even for ordinary hardware like the x86 architecture.
In fact, Greg Morrisett [56] and his colleagues have deﬁned and implemented a typed assembly language.
In addition, one can use method erasure that returns an object that corresponds to the run time erasure of the Scala type represented by the manifest:
Instead of giving a formal description of nominal and structural typing, let us show their differenceswith a simple example.Consider the following two class deﬁnitions:
At ﬁrst, one can say that both deﬁnitions have exactly the same structure, but they introduce two different types since they have different names.
On the other hand, one would claim that both types are equivalent since their structure is identical.
The ﬁrst view is in accordance with nominal typing, while the second view is in accordance with structural typing.
Scala honors structural typing and so these two classes are of the same type.
Structural typing allows one to relax type requirements in value and function declarations.
For example, the following deﬁnes a list of objects that have at least a method called getname that simply returns a string:
Similarly, the following type deﬁnition introduces a newclass type that has amethod named setName:
It is very important to note that the type is deduced from the header of a function deﬁnition.
The question is whether ClassC is a subclass of ClassB.
According to structural typing the answer is afﬁrmative: yes ClassC is a subclass of ClassB.
Although one can deﬁne classes, traits, and methods that are polymorphic, still it is not clear whether it is possible to have functions that can have types as parameters and which might be able to return types as results.
In other words, it is not clear whether Scala provides facilities that allow its users to write programs that are parametrized by a datatype (for example, a list or a tree)
Fortunately, Scala provides all the necessary facilities for data generic programming, that is for writing programs that are parametrized by datatypes.
In other words, Scala is a language that provides the necessary facilities for higher order polymorphic programming.
In order to illustrate Scala’s expressive power we will show how to encode hylomorphisms.
But ﬁrst we need to explainwhat hylomorphisms are andwhat is the general idea behind them.
The idea behind hylomorphisms is to be able to express (functional) programs as instances of common patterns, rather than inventing the wheel every time we have to solve a particular problem.
Thus, one could say that hylomorphisms are a sort of design pattern for functional programming.
Since Scala is both an object-oriented and a functional programming language, both hylomorphisms and design patterns shouldmatter for the Scala programmer.
Gibbons prefers the term origami programming (from origami (from oru, folding, + kami, paper) the Japanese art of paper folding) over hylomorphism.
In the examples below we will use lists to show what hylomorphisms can achieve.
The function that follows is a typical example of a catamorphism:
Note that although we use lists this deﬁnition works for any other isomorphic data structure.
Also, this function does exactly what the :/ (foldr) operator does.
The next function is a typical example of an anomorphism:
Exercise 3.17 Provide a deﬁnition of unfoldL in terms of unfoldLa.
Let us see a ﬁrst example that shows the power of these functions.
The function that follows implements the insert sort algorithm for lists:
After executing these two commands, list L2 will contain the elements of list L sorted in ascending order.
As a second example, let us see how we can implement bubble sort.
Function bubble is the one that places an element in the proper position:
Function bsort can be used to sort a list using the bubble sort algorithm:
The following command creates a new list that contains the elements of list L sorted using bubble sort:
As noted above, if we compose the fold and the unfold functions, we get a hylomorphism.
A simple example of a hylomorphism is given by a function that computes.
In a real source ﬁle the second and the third lines must appear on the same physical line or else the language processor will “ﬁnd” errors.
Also, function id returns its argument and function pred returns its argument, if it is equal to zero, or its argument reduced by one if it is greater than zero.
We can encode the natural numbers using a data structure that is similar to lists.
In fact, we are going to encode numbers as deﬁned in Peano’s arithmetic, named after Giuseppe Peano.
In this arithmetic all numbers are expressed in terms of the constant zero and the successor function.
Thus, one is the successor of zero and two is the successor of one or the successor of the successor of zero.
In order to complete our task we need to write the corresponding fold and unfold functions.
But instead of writing such functions for each different data structure, one could write one folding and one unfolding function that could be used in every possible case.
Before we proceed with the really generic solution, let us see how we can encode natural numbers and how we can write the corresponding fold function.
The following function is the fold function for natural numbers:
Exercise 3.19 Deﬁne a simple function succ that takes a natural number and returns its successor.
Now we can deﬁne addition of natural numbers as follows:
Although Scala does not directly support kinds, still Adriaan Moors, Frank Piessens, andWouter Joosen were the ﬁrst to describe a library for datatype-generic programming in Scala [55]
In fact, they have translated a library written in Haskell to Scala.
Not surprisingly, the resulting library is more in spirit with the philosophy of object-oriented programming than with that of functional programming.
Nevertheless, later on Bruno Oliveira and Jeremy Gibbons presented a version of the.
The reader should be aware that since Scala does not support higher-ranked types, they have been encoded by wrapping methods in objects.
Figure 3.10 shows how one can use this library to encode lists.
The shape of lists is described by a case-class hierarchy.
The object biList deﬁnes a method to process list structures.
The function that follows can be used to sum up the elements of a.
Figure 3.10 Deﬁning lists using the library for datatype-generic programming in Scala.
The following command shows how to write down lists using this new tool and how the function can be used:
Exercise 3.20 Deﬁne Peano numerals using the library for datatype-generic programming and then deﬁne a function that sums up two such numerals.
There are cases where one has to use the ﬁrst n numbers of an inﬁnite sequence of numbers (like the Fibonacci numbers for example) but, unfortunately, there is no way to determine how many members of the sequence will be actually needed.
Obviously, it makes no sense to start computing a large number of consecutive elements since the large may turn out to be too large or even too little.
Although the computation of inﬁnite sequences of numbers in ﬁnite time is not impossible (see [72] for more details), still the computers on which Scala runs cannot perform such a task.
But Scala offers an even better solution – the ability to deﬁne inﬁnite sized data structures (for example, a list that holds all Fibonacci numbers) whose elements are computed on demand.
A stream is a list whose elements are not computed eagerly, but rather lazily.
Eager evaluation means that a function ﬁrst evaluates its arguments and then it uses them, while lazy evaluation means that an argument is evaluated only when it is needed.
In order to understand how one can create and use “inﬁnite” lists, we will present a simple example.
Assume we want to create a stream that consists of all integer numbers.
The code that follows can be used to create such a stream:
Now we can create an “inﬁnite” stream using the following command:
The keyword lazy designates that the value assigned to the constant N should not be evaluated.
Streams have their own print method that outputs elements of this stream one by one and separated by commas.
If for some reason we need a different separator symbol, we can supply one as an argument of method print.
In addition,methods foldRight and foldLeft are the stream equivalents of /: and :/
Also, one can get a list from a stream using the force method.
In most cases, we need to deﬁne some function that will create an “inﬁnite” stream, still in some simple cases there is no need to deﬁne such a function.
For example, the following constant deﬁnition creates an “inﬁnite” list of ones:
Exercise 3.21 Write an expression that will create a list that consists of ﬁve ones.
Exercise 3.22 Deﬁne a Scala stream that computes the Fibonacci numbers.
Hint: Construct a stream whose ﬁrst two elements are the ﬁrst two elements of the Fibonacci sequence.
Then deﬁne recursively the tail of the tail of this stream by zipping the stream with its tail and then by replacing each pair with the sum of its elements.
Figure 3.11 A generic representation of a memo function of one argument.
Assume we want to create a memo function to compute the factorial of a positive integer.
Then in order to compute the factorial using a recursive algorithm,we have to ﬁrst deﬁne a function whose ﬁxed point is the memorized factorial function.
Feeding this function to the ﬁxed point combinator will then yield the desired memorized factorial function:
Also, in order to be able to store the intermediate results, we need to make them available outside the function.
This is exactly why we had to introduce the extra parameter in the function deﬁnition.
The next thing is actually to use fac to compute the factorial of some numbers:
Assertions are used to check invariants, that is, conditions that should always be true.
If at any given moment an assertion does not hold and the program detects this, an exception is thrown.
Assertions can be used as internal invariants, control-ﬂow invariants, preconditions, postconditions, and class invariants.
Internal invariants are assertions that replace comments that would have been written to assert an invariant.
Control-ﬂow invariants are assertions placed at any location of the code one assumes will not be reached.
A precondition describes what must be true when a method is invoked while a postcondition describes what must be true after a.
Finally, class invariants describe what must be true about each instance of a class.
In Scala preconditions and postconditions can be asserted with the two forms of the assume method:
The following example shows how this method can be used:
The invariants can be better served with the two forms of method assert:
The following example shows how one could use method assert:
This method takes a string as argument and aborts program execution by throwing an exceptionwhich curries its only argument.
For example, if the reader feeds to the language interpreter a ﬁle containing the following line.
Finally, method exit should be used to stop program execution.
This is useful if there is no other way to stop program execution.
These two methods have nothing to do with assertions, but they are presented here for reasons of completeness.
By default assertions are on, that is, their conditions are examined and if they fail an exception is thrown.
JavaBeans are Java classes that, among others, provide getter and setter methods for accessing its properties.
In Scala whenever one deﬁnes a nonprivate ﬁeld, the language processor automatically creates a getter method, which is used to access the value of the ﬁeld, and a setter method, which is used to alter the ﬁeld’s value.
This is an internal representation of the source code above.
Ignoring all the incomprehensible symbols, one may note towards the end of the code that there are two method deﬁnitions – method a and method a_= (both the underscore and the equals sign are part of the method’s name)
Obviously, the ﬁrst method is the getter and the second one is the setter.
A rather interesting aspect of getters and setters is that one can deﬁne them manually and then use the variable that would correspond to these methods.
Objects of this class hold prices in both EUR and and USD.
Before we explain the functionality of this class, let us explain what method toString returns.
This method returns a string, in which the values speciﬁed as arguments of method format are formatted according to the formatting instructions contained in the string object.
Each formatting instruction starts with the % symbol that is followed by a conversion character, which denotes how the corresponding value should be formatted.
Between the symbol % and the conversion character one can specify a number, which speciﬁes the minimum number of characters that have to be used to represent the corresponding value, a period, which separates the width from the precision, and a number, which is the precision, that is, the maximum number of characters that have to be used to represent the information after the period.
In our example,we do not specify a number after the %, which means that we do not care about the number of characters that will be used to represent the two numbers.
However, we want each number to have only two decimal digits.
Then every time we assign a value to “ﬁeld” dollars the method dollars_= is invoked and the value that is assigned to the “ﬁeld” is passed to this method.
Thus, by deﬁning a getter and a setter method for a particular “ﬁeld,” we can implicitly specify actions that should be taken every time the“ﬁeld’s” value changes.
Obviously, this is not something one could do with ordinary ﬁelds:
Monads are mathematical structures that were introduced in homological algebra and later they were introduced in category theory.
Eugenio Moggi [53] was probably the ﬁrst researcher who used monads in structuring semantic descriptions of features such as state and exceptions.
Philip Wadler [76] established a connection between list comprehensions and monads that led to a generalization of list comprehensions to an arbitrary monad.
This feature was employed to express concisely in pure functional programming languages programs that handle exceptions, parse text ﬁles, etc.
Although it is not necessary to have a solid background in category theory in order to understand the various ideas described in the rest of this section, still we believe it is better to be familiar with some basic notion of category theory.
In this section we will introduce the reader to these ideas.
Readers who are either familiar with category theory or simply do not want to bother with these mathematical notions, can safely skip this section and ignore all future references to categories.
In a nutshell, a category can be viewed as a mathematical universe.
There are many categories and each of them consists of entities, which have the same nature, and ways to pass from one entity to another.
Also, there are ways to pass from one category to another.
In addition, it is possible to transform these ways from one category to another while preserving their internal structure.
A functor is away to go fromone category to another that preserves the categorical structure of its domain.
Exercise 3.24 Why does a function from the set of even numbers (with the usual numerical ordering) to the set of natural numbers deﬁne a functor?
The next notion that we need to introduce is the natural transformation.
Assume thatA andB are two categories and thatBA is the collection of all functors from A andB.
Then if we form a category whose objects are the functors that belong toBA , the morphisms of this category are natural transformations.
Monads in Scala Method map (see Section 2.13) has some really interesting properties.
Before discussing these properties, it is better to review the following interaction with Scala’s interpreter:
This interaction with Scala’s interpreter shows that this method maps a list to another list.
In general, the two lists can have different types as there is no restriction on this.
Also, if the only argument of this method is an identity function, then the result is as if one has applied the identity function for lists of a speciﬁc type to this particular list.
In addition, we see that if the argument of map is the composition of two functions, then by successively applying mapwith the ﬁrst function as argument and then with the second function we observe that the results are the same.
It is not difﬁcult to see that map is a functor.
Method flatten is a function that has an interesting property:
Note that this equality cannot be expressed directly in Scala.
Another function that has a similar property is function unit that takes an object and returns a singleton list with this object as its only element.
The following shows the essence of this property of unit:
Examples of monads List comprehensions, that is,for comprehensions that create lists, can be expressed in terms of the monad presented above:
In other words, we can have for expressions for free with monads! Also, the type Option is a monad (can you see why?)
However, a more interesting example involves the representation of continuations as a monad.
But ﬁrst let us say a few things about continuations.
Consider the following nontail recursive function that appends two lists:
Note that here s(A,B) = (tail(A),B) and by applying the technique just described we create a tail recursive version of this function:
Exercise 3.25 Deﬁne a tail recursive version of the following function:
Figure 3.12 An implementation of the continuation monad in Scala.
A parser is a piece of software capable of resolving a string into tokens and then checking whether the string belongs or not in a particular (formal) language.
However, a more interesting problem is that of constructing a particular parser from other (predeﬁned?) parsers rather than from scratch.
In the end, some of these parser builders have to be constructed from scratch, but all the complex parsers can be built from the other parser builders that parse components.
Scala includes a rich library for building parsers using parser builders.
In this chapter we ﬁrst give an overview of some relevant notions, then we describe the library and ﬁnally we use this library to construct an interpreter for a simple programming language.
Given an alphabet (i.e., a set of symbols or characters), the closure of this alphabet is a set that has as elements all strings that consist of symbols drawn from this particular alphabet.
A language can be considered a subset of the closure (including the empty string) of an alphabet.
The language that is the closure of an alphabet is not particularly interesting since it is too large.
Programming languages are also languages in the sense just described, thus, we need tools to deﬁne the set of valid strings that make up any particular programming language.
In simple cases, it is possible either to enumerate the strings that belong to a language or to write down a set-comprehension that describes the elements of a language.
For example, the following set includes all the sequences of zeros followed by ones:
Unfortunately, in most cases this is not a realistic way to describe a language.
A more realistic way is to specify the grammar of a language.
A grammar consists of a ﬁnite set of production rules that specify the syntax of the language.
A production rule is a formula like the following one:
Deﬁnition 1 A grammar is a quadruple G = (T ,N ,S,P), where.
The equals sign is such a metasymbol whose functionality was explained above.
Instead of giving the exact deﬁnition of each metasymbol, we will provide simple examples that demonstrate their use.
In other words, a B is a sequence of binary digits.
A major problem of rules like the second one is that they cannot be used for the construction of a parser.
Thus, we need a way to eliminate left recursion from production rules.
An easy way to eliminate left recursion is to replace it with right recursion and by introducing a rule that expands to nothing:
These symbols enclose terminal or nonterminal symbols that can be repeated zero or more times.
Thus, a far more readable way to specify the above production is the following formula:
This metanotation can be used to describe the grammar of any programming language.
To be fair, it is a fact that the syntax of common programming languages like Java, Perl, and Haskell cannot be described completely by a metanotation like the EBNF.
For example, one cannot specify that an array index should stay within speciﬁc bounds or the requirement that the invocation of a method or a function contains exactly as many arguments as there are parameters in the deﬁnition of the method or function.
Unfortunately, although there are some techniques for handling these additional requirements, still there are no truly successful realizations of them.
And this is the reason why the report of any programming language is given in two parts: one that speciﬁes the general syntax and one that describes these additional constraints.
There are several conventional techniques that can be used to construct a parser.
For example, the readermay consult [78] for a lucid account of parser construction.
One drawback of all these techniques is that they do not clearly reﬂect the grammar of any given language.
Nevertheless, another major problem is that one has to construct any particular parser from scratch – an exercise well suited only for experienced programmers.
A better idea is to use existing parsers, which can parse speciﬁc constructs, to build a new parser.
Obviously, even in this case one has to build a number of simple parsers since one cannot know a priori which symbols will have a particular signiﬁcance.
For example, the symbol “:=” is used in Pascal as an assignment operator while other programming languages use the symbol “=” for the same thing.
Fortunately, the construction of this simple parser is a trivial task as we will see later on.
Parser builders or parser combinators, as they are also known, are an intelligible way to build parsers.
If an input string matches a grammar,1 then the parser will produce a list of strings which will contain all symbols matched.
Otherwise, it will produce some error message and it will fail.
This scheme is based on ideas put forth by William H.
In addition, there is a small number of additional “parsers” that can be used to recognize identiﬁers and numbers (see Table 4.2)
Given the grammarG of some languageL, one canuse the parser builders to build a parser for G.
In general, for any grammar that can be speciﬁed with the EBNF metanotation, one can build a parser with Scala’s parser builders.
Nevertheless, special care should be taken to avoid grammars that are left recursive.
The reason left recursiveness is a bad thing is that most parser combinators cannot properly handle such grammars.
In some cases, if a Parser implements left recursive productions, it will loop forever and this is something no one wants!
When deﬁning a parser with parser builders, one must closely follow a particular grammar and this is a particularly interesting feature.
Let usmake clear what exactly we mean with a simple example.
Consider the following simpliﬁed production rule that describes an assignment command:
We can construct a parser,which can recognize assignment commands, using parser builders as follows:
If you have guessed that regular expressions are a kind of parser builder, then you have guessed correctly.
In fact, all regular expressions can be described with EBNF.
Moreover, it returns f applied to the result of p.
If f is not applicable, error (the result of p) should explain why.
The symbol ~ is used to specify succession or concatenation while it keeps track of what symbols have been parsed successfully so far.
In this example, an identiﬁer is followed by the symbol :=, which in turn is followed by a whole number, which is followed by a semicolon.
However, in a number of cases some symbols are just needed to separate or group syntactic entities, and once it is understood what these symbols separate or group, there is absolutely no need for them.
This means that it makes no sense to keep track of them.
The obvious way to write a parser for this production follows.
A better way to achieve the same functionality without the drawback just mentioned is:
Unfortunately, we cannot use the predeﬁned parser that recognizes whole numbers since this will accept even a negative number.
Fortunately, we can deﬁne a little parser to recognize natural numbers as follows:
The only thing one has to do in order to deﬁne such little parsers is to change the regular expression enclosed in three pairs of double quotation marks.
As a second example, the following code deﬁnes a parser that can parse octal numbers:
Exercise 4.2 Deﬁne a little parser that can recognize hexadecimal numbers.
When one wants to specify a rule with alterations, that is, a rule for which there are different possibilities to choose from,one has to use the | operator.
If we want to specify repetition, we need to use the rep parser combinator.
Once one has deﬁned a parser, the next question is can one use it?
As shown in Figure 4.1 a parser is deﬁned as a set of methods that are deﬁned in a subclass of a class JavaTokenParsers.
The special method parseAll is the one that must be used to invoke the parser.
Exercise 4.3 The functions thatmake up a parser can be deﬁned in an object instead of being methods of a class.
Rewrite the code of Figure 4.1 so that class BinDigit becomes an object.
Although the example shown in Figure 4.1 shows how one could deﬁne a parser for a real language, still there are a number of details that are not covered.
For example, it is not clear how one could build a parse tree (i.e., a tree that faithfully represents the original source code) or how optional nonterminals and/or terminals should be treated.
In this section we explain how to write an interpreter of a simple imperative programming language.
We have opted to describe the interpreter of RAM++ which is a relatively simple language that includes some of the features common to almost every programming language.
The various commands have the intended meaning and each variable is assumed to be initially equal to zero.
In addition, the value of each variable can be any integer number greater than or equal to zero.
Exercise 4.4 Write a “parser” that will recognize RAM++’s identiﬁers.
Programming in RAM++ is not difﬁcult but it is tricky because one cannot assign to a variable any value.
In fact, one can only increment or decrement by one the value of any variable.
Nevertheless, the language is Turing complete, which means that it can be used to compute anything a Turing machine can.
The following RAM++ program reads two numbers and computes their sum:
As was noted above, programming in RAM++ is tricky! Let us now describe how we can implement an interpreter for RAM++ in Scala.
The ﬁrst thing one has to do is deﬁne the structure of the parse tree.
The deﬁnitions that follow deﬁne structures that can represent the original code:
There are ﬁve different kinds of commands, therefore, for each command we need to deﬁne a different case-class that can keep the essential information of each kind of command.
For example, the IFcomm case-class has three ﬁelds that correspond to the variable that is used in the condition, the commands in the “then” part, and the commands in the “else” part, which might be empty.
Since a program is just a sequence of commands, there is no need to have a separate structure to hold a whole program.
In our case, a list of commands is the ideal structure to hold a complete program.
The next step is to deﬁne an object where all parser-related deﬁnitionswill be placed.
In fact, this object will be the parser of a particular language.
Figure 4.3 shows the deﬁnition of a Scala parser for RAM++
The rep combinator returns a list that contains objects of the same type, thus, the RAM++ parser will return a list each element of which will correspond to the commands that make up a RAM++ program.
In addition, this parser shows how one can use the ^^ parser combinator.
This combinator takes an anonymous function and passes the result of the parse into the anonymous function as a parameter.
Another interesting thing about the RAM++ parser is that it shows how one can handle optional syntactic constructs.
By inspecting the parser’s code, the reader may notice that the optElse parser returns either a None value or a Some(m)
A None value indicates that an optional construct was not there and, obviously, a Some value indicates that the parser has found the optional syntactic structure.
If the parser encounters an opening left parenthesis, it will print the errormessage unexpected symbol, because it was instructed to do so.
In general,when a parsermust choose from a number of alternatives, it is better to issue a speciﬁc error message if the parser fails.
This can be achieved by adding an alternative that has the following form:
Obviously, the error message must be informative and explain why the parser has failed.
Typically, a language evaluator executes source code stored in some input ﬁle after verifying that it is at least syntactically correct.
The parser in Figure 4.3 can be used to verify whether some input is correct or not.
Thus, we need to deﬁne a function that will evaluate the output generated by the parser.
Since our language supports variables, we need to deﬁne a structure that will hold the variables as well as their corresponding values.
Obviously, the natural choice is to use a hash table:
Figure 4.3 A parser for RAM++ deﬁned using Scala’s parser builders.
If the list is not empty, the evaluator needs to ﬁndwhat kind of command represents the head of the list (i.e., the ﬁrst command of the program) and then to evaluate it.
In the end, the program evaluator recursively evaluates the rest of the program.
Let us now see how each case should be handled.
We start by showing how an output command should be implemented:
Since variables are not declared, it is quite possible that some variable is used for the ﬁrst time in the output command.
Therefore, we need to add into the symbol table variables that have not been used before.
The next step is simple: just print the value of the variable.
As shown below, the code for the ouput command is more complicated:
As in the case of the output command, it is necessary to ensure that the variable used is in the symbol table.
Next, we use a standard Scala method to input the value of the variable which must be an integer greater than or equal to zero.
Exercise 4.5 Instead of relying on readInt’s way to deal with erroneous input, use method readLine and a regular expression to verify that the user enters only valid input.
There is nothing special about the “assignment” command except that when a variable is equal to zero, its value cannot be decreased further:
The if-command together with the while-command are the only choice and repetition constructs available in RAM++
Their meaning is standard and so their implementation is almost straightforward.
The code does the usual check and then checks whether the variable is equal to zero.
If it is, the then-part of the command is executed.
Exercise 4.6 If the elsePart.cmds is an empty list, then eval is invoked with an empty list and so it does nothing.
The implementation of the while-command is very simple – it is implemented by a while loop as shown below:
Figure 4.4 Putting together the RAM++ parser and the evaluator.
We deﬁned the parser as well as the evaluator of RAM++
The next step is to put these things together in order to build a RAM++ interpreter.
We will proceed by assuming that the name of the ﬁle that contains the RAM++ source code will be given as a command line argument (see Section 2.9)
The “main” program of the RAM++ interpreter is shown in Figure 4.4
The input ﬁle is opened using an instance of the standard Java FileReader class.
This is a class that can be used to read ﬁles that contain only characters, that is, ﬁles that do not contain raw bytes.
Since the name of the input ﬁle is supplied as a command line argument, we need to make sure that one and only one command argument is supplied.
Of course, the fact that some user has supplied a command line argument does not mean that this argument is the name of an existing ﬁle.
Thus, we need to make sure that Scala can open and read the contents of the ﬁle.
This is exactly why the code that opens and reads the input ﬁle is inside a try-block.
If the parser has successfully parsed the input ﬁle, then method get should be used to store the parse tree in a variable.
A program has only variable “X” whose value is a list of strings.
The expressions hd e and tl e compute the head and the tail of e, respectively.
A while loop while e do c ﬁrst evaluates e and if its value is ["nil"], the loop terminates.
The command X:=e assigns the value of e only to variables of the language.
Roughly, a domain-speciﬁc language (DSL) is a notation that is designed to describe solutions to problems of a very speciﬁc nature.
In other words, a DSL is a specialpurpose programming language designed to express solutions to problems that belong to a particular problem domain.
The canonical example of a widely used DSL is the “language” used to express the various calculations and contents of the cells in a spreadsheet.
The opposite of a DSL is a general purpose language (GPL) like Java and Scala.
In principle, a GPL can be used for just about any purpose, from creating a role playing game to programming a system to solve chemical problems.
Unfortunately, GPLs have drawbacks simply because they are very general tools.
For example, if one wants to perform a number of actions on a database and all one has at one’s disposal is a GPL, then it is necessary to write a computer program for each task.
However, the real problem is that for similar tasks one cannot use any previous program, unless one decides to create a DSL.
This DSL could be used to drive the programs to perform a number of generic tasks.
SQL, the structured query language, is considered by many a DSL.
A DSL can be easily implemented using Scala’s parser builders.
To make the general idea clear, assume that we have created a program that allows users to load images.
Users can instruct the program to generate a web page which will show the image as if there is a camera that maneuvers above it (this camera is usually called a viewport and this is basically something like the virtual camera system of many video games)
Now, a user can specify the viewport size, the initial camera position as well subsequent moves with commands like the following set of commands:
Clearly, it is not difﬁcult to write a grammar to describe these commands and from this grammar to write a parser using Scala’s parser builders.
The resulting parser can be used to generate a web page with the intended behavior.
For example, a grammar for this particular DSL is given below:
For example, one could add a command to repeat a number of commands a speciﬁc number of times.
Graham Hutton and Erik Meijer [34] have demonstrated how monads can be used to build recursive descent parsers.
Roughly, a parser is called recursive descent when for each nonterminal symbol there is a procedure (i.e., a method that returns Unit) that handles the corresponding nonterminal symbol.
In their work, Hutton and Meijer describe how they have used the Haskell type classes to build a parser monad.
In Scala, instead of deﬁning a parsing monad from scratch, it is better.
The following code shows how one could implement a basic parser:
In order to deﬁne choice combinators one needs structures that go beyondmonads.
In fact, one needs a monad with a zero and a monad with a zero and a plus.
The scalaz library deﬁnes the MonadEmpty and the MonadEmptyPlus traits that implement exactly these monads.
Therefore, it would be an interesting exercise to implement a parsing library based on the work of Hutton and Meijer and scalaz.
XML, the eXtensible Markup Language, is an industry standard for document markup.
The widespread use of XML dictated the design and implementation of tools capable of handling XML content.
Scala is a modern programming language and so it includes a standard library for the manipulation of XML documents.
This library, which was designed and implemented by Burak Emir, is the subject of this chapter.
A markup is an annotation to text that describes how it is to be structured, laid out, or formatted.
Markups are speciﬁed using tags that are usually enclosed in angle brackets.
For example, one can deﬁne tags for verses, stanzas, and strophes in order to express poems in XML.
When a speciﬁc set of tags is used to describe entities of a particular kind, then this set is called an XML application.
For example, if one precisely speciﬁes tags suitable to describe poems and uses them only for this purpose, then the resulting set of tags is an XML application.
The following lines show the use of a hypothetical set of tags designed for the representation of poems:
In general, white space is ignored but here it cannot be ignored so we explicitly specify that it should be preserved.
Most, if not all,XML applications assume that data are organized in a hierarchical datamodel, that is, data are organized in a tree-like structure.
For example, consider a set of tags designed to describe people.
The description of any person will form a structure of XML tags that will form a hierarchy, which is just a general tree structure.
An attribute is a piece of information expressed as a name-value pair attached to the start-tag of an element.
For example, xml:space is a standard XML attribute whose possible values are “default” and “preserve.” Note that the value of all attributes must be enclosed in quotation marks.
Also, when writing songs, that is, poems of a special kind, there are usually refrain verses and/or stanzas.
Unicode is the default character set of XML.Almost every legalUnicode character may appear in an XML document.
However, not all characters can be used in all different cases.
An element name as well as any other XML name may contain any alphanumeric character.
There are a few characters whose use is reserved and, therefore, they cannot be used for any other purpose.
If it is absolutely necessary to use these characters, then one should use an entity reference.
In case it is absolutely necessary to include some XML markup verbatim in another XML document, then one can use a CDATA section.
Usually an XML document starts with a line that has either the form.
The DOCTYPE information depends on the document type deﬁnition (DTD) being used.
In the second example, the header is the header of an SVG ﬁle.
Specifying a DTD for a relatively simple XML application is not a difﬁcult task, nevertheless, the reader interested in learning more about DTDs, in particular, and XML, in general, should consult a good refence book (for example, see [30])
It is not out of the question to ask for the design of a new XML application that deﬁnes one or more elements that have already been deﬁned in some other XML application.
At the same time, it makes no sense to demand that each new XML application should include names that are unique.
In order to overcome this problem, the designers of XMLhave included a provision fornamespaces.
Roughly, a namespace is amechanismbywhich elements and attributes fromdifferent applications can be distinguished.
Also, namespaces can be used to group related elements and attributes from a particular application so that software applications can recognize them.
In general, namespaces are speciﬁed by preﬁxing each element and attribute with a label, which is mapped to a URI by an xmlns:label attribute.
The easiest way to have XML content in a Scala program is to assign some XML content directly to a variable.
The following piece of code shows how this can be done:
Here we have started the XML content on a separate line purely for aesthetic reasons.
The XML content is not stored as a long string, but as an instance of class scala.xml.Elem.
Having explained the use of the ﬁelds of class Elem, it would be interesting to see how one can encode XML content as an Elem object.
The code snippet that follows shows how the XML content representing a poem can be represented as an Elem object:
We have presented two different ways by which XML content can be readily used in a Scala program, however, the question is: Is there any difference between the two ways? The only way to tell is by printing the variable and inspecting the output.
In the ﬁrst case, the output will look exactly like the following:
However, in the second case the output will look quite different:
In other words, white space before and after element content has been removed and the whole content is printed on one line.
Although this is not human readable, one should bear in mind that XML has been designed to be processed by machines not humans.
As it stands one can create XML content dynamically only by deﬁning it using Elem objects.
Fortunately, it is possible to embed Scala expressions into pure XML content by enclosing any Scala expression in curly brackets inside some XML content.
For example, the code that follows shows exactly how one can mix Scala expressions with XML content:
Obviously, this example is not very dynamic, but the following code snippet is more dynamic (can you guess what will be the result in either case?):
If n is greater than 9, then the second line of the result will be transformed to.
On the other hand, if n is less than or equal to 9, then the same line will look as follows:
As is obvious, if z evaluates to None, then the attribute is not included since it makes no sense to have an attribute with no value.
In the second case the attribute is included since it takes a valid value.
If for some reason we need to have curly brackets in a tag or attribute, then we have to write the curly brackets twice, as, for example, is shown below:
There are a few other classes that can be proved useful in certain cases.
Class Atom should be used when raw text that contains no tags and no children elements has to be used somewhere.
Class Comment can be used to embed comments in XML content.
Similarly, one can use class EntityRef to specify entity references.
If we use the following code snippet in our code.
The class Unparsed should be used when it is absolutely necessary to leave as is some entity.
Finally, class Group should be used to make a list of elements.
Exercise 5.1 Can you say what this example will produce?
Since XHTML is an XML application, one could use Scala’s XML manipulation library to generate XHTML content.
Indeed, in this section we will show how to generate XHTML content using this library.
In particular, we will show how to use Scala to generate an XHTML ﬁle which when viewed with a browser will show all ﬁles that are contained in a directory that has been supplied by the user.
Figure 5.1 shows a typical XHTML ﬁle that our application has to generate.
First of all there are two problems that must be solved in order to implement our solution.
The ﬁrst problem regards the ﬁrst four lines of the XHTML source.
This particular problem can be solved with tools provided by the XML library, nevertheless, here we solve it using alternative tools in order to show how to solve such problems generally.
The tags in the ﬁrst four lines are not normal tags and so need special treatment.
For example, if we assign to a variable the ﬁrst line of any XHTML ﬁle, the language interpreter will complain that xml is reserved.
And this is the reason why Unparsed has been introduced.
However, it is not possible to write XML content directly.
Thus, we need to use the classes introduced in the previous section.
The second problem is a little bit more involved – we need to ﬁnd a way to read the contents of the user-supplied directory and then to store them in an appropriate XHTML group.
Since Scala does not deﬁne any classes for ﬁle manipulation, we need to use Java’s java.io.File class.
This class is one that can be used to examine ﬁles and/or directories.
Thus, we are going to use this class ﬁrst to make sure that the user has supplied the name of an existing directory and only then to read its contents:
Method isDirectory returns true if the instance is a directory.
Similarly, method isFile returns true if the instance is a plain ﬁle.
Method list returns an array of strings that contains the names of the ﬁles and directories contained in the directory that is represented by the corresponding object.
The names will be stored in a Group structure, thus, we need to create a list whose elements will be Elem structures for each ﬁle and/or directory.
Use this method to write a function that recursively traverses a directory and prints all ﬁles and directories and their contents.
The next thing to do is to store the body of the XHTML source to a variable:
As was explained, the list that holds the ﬁle names is used to create a Group.
But now we need to concatenate the header and the body of the XHTML content and for this the most natural choice is the creation of a Group:
So far we have managed to create a structure that holds the whole XHTML content, however, we need to write this content into a real ﬁle.
Here listdir.html is the name of the output ﬁle and UTF-8 is the encoding of the output ﬁle.
However, this method prints strings, not XML node structures! In order to solve this problem, we use Scala’s PrettyPrinter class.
An object of this class generates from any Elem object a printable string:
The two numbers denote the width and the indent of the resulting multiline string.
Method flush is used to make sure that everything will be written to the ﬁle and nothing will remain in the computer’s memory.
And of course method close is used to close the output ﬁle.
Scala has two methods that can be used to input and output XML content directly from and to ﬁles.
Module XML provides the methods loadFile and save for reading XML content from ﬁles and writing XML content to ﬁles.
Method loadFile takes one argument, the name of a ﬁle, and creates an instance of Elem:
In addition, if some string contains XML content, then one can use method loadString to create an Elem object from it.
Method save takes two arguments: the name of an output ﬁle and an instance of Node (Node is the abstract superclass of all Scala classes designed to represent XML content)
A complete XML document has a header, however, as we have seen in the previous section, it is not obvious how to handle headers (the standard XML header and the document type header)
The XML library includes class DocType, deﬁned in package scala.xml.dtd, which can be used to store headers.
When instantiating this class we need to supply three values: a string that represents the document type, an instance of ExternalID (it can be either a PublicID or a SystemID), which is a comma separated list of public or system identiﬁers, and a sequence of internal subset declarations, which, in many cases, is just empty.
The third argument is the encoding of the output ﬁle and the fourth a boolean value that controls whether an XML declaration will be printed or not.
In particular, if it evaluates to true, then the XML declaration is included.
Method write takes the same arguments as method saveFull, except that the ﬁrst argument must be a java.io.Writer (see previous section)
Scala provides methods and operators that mimic the capabilities provided by languages like XPath and XQuery.
XPath is a language that can be used to navigate through elements and attributes in an XML document.
XQuery is an extension of XPath version 2.0 and operates on the logical structure of an XML document.
Scala’s XML library deﬁnes two projection functions that are similar to XPath axes, that is, a path through the XML structure that makes use of particular relationship between nodes.
In order to make clear what this means, let us start with a simple Scala command:
Assume that one needs to create a new object (for example, an array of objects) that will contain the name of each poet and the title of each poem (in this section we will concern ourselves only with the extraction of the data)
The ﬁrst thing we need to do is to extract the nodes that contain the relevant data.
Remember that what is printed is a visual representation of the node and its content.
Although this operator is quite useful, it does not produce exactly what we need – the text stored in the tags.
The XML library deﬁnes the text method, which does exactly what we want.
The following commands show how this method can be used:
Obviously, these commands solve the problemof extracting information fromXML content.
If one wants to print subelements of a particular element, one can use the following idiom:
The character _ is a wildcard “pattern.” For example, the command.
If a "tag" is preﬁxed with an @, then it refers to attributes with this name.
Exercise 5.3 Examine the output produced by the following command.
Suppose that we have a huge XML “database” of poems stored in a ﬁle.
An interesting question is how can we make queries to this “database.”For example, how can we print all poets and poems which have been published after 1960? Provided that the “database” is stored in ﬁle poems.xml, the following code ﬁnds all poems that have been published after 1960 and prints the title and the poet of each such poem:
Readers familiar with XQuery may see some resemblance between XQuery queries and this code.
Exercise 5.4 Write a Scala “query” that will print one time the name of each poet who has used the word freedom in one or more of their poems.
Since XML content is considered a legal Scala value, and since when performing pattern matching, a pattern can be any valid value, one may wonder whether it is possible to perform pattern matching when a pattern is some XML content.
The answer is afﬁrmative – real XML content can be used as a pattern.
In addition, an XML pattern may include a standard Scala pattern, which, however, must be.
In other words, when dealing with real XML content, curly brackets are used to interpolate Scala code in it, while in an XML pattern, the curly brackets can be used to interpolate Scala patterns in the XML content.
Let us begin our discussion with a rather complex example that shows how to match an attribute:
This is necessary since there is no way to match something inside the angle brackets, except of course the tags.
Thus, if x is <a> tag, then variable n contains the whole HTML content.
Obviously, this is a very simple pattern that matches the sentence XYZ Law Firm.
The expression on the right side of => is another match expression.
Method get(attr) returns Some value if the speciﬁc tag contains a particular attribute; otherwise, it returns None.
The code snippet that follows shows how to store all these strings in an array of strings:
Here is an explanation of what the long expression does: the pretty printer object yields a string from a Node.
This string is split into words, that is, substrings that are surrounded by spaces.
If m was a sequence of Nodes, then we would have to use method formatNodes.
Let us examine a similar problem to the one just described.
Assume that there is a tag that surrounds a sequence of other tags, that is, one has to handle XML content that looks like the content that is assigned to the following variable:
Method matches takes two arguments – a pattern and a string.
Thus, the code above will print on separate lines each nonempty tag, which is exactly what we wanted.
Assume now that we want to process the content of speciﬁc elements (for example, the content of element <b>)
It seems that in order to proceed we need a new match expression.
Not surprisingly, we can use a for comprehension to solve this problem.
The code snippet that follows shows how this can be done:
Most “real” programs have a graphical user interface (GUI for short)
Therefore, any serious modern programming language should provide tools for GUI programming.
Scala provides such tools through the scala.swing package, which is an interface to Java’s JFC/Swing packages.
The ambitious goal of this chapter is to teach you how to build GUI applications in Scala.
Typically, most introductory texts on programming are written without any coverage of GUI programming.
In addition, advanced texts on programming cover GUI programming only as a marginal or optional topic.
The truth is that the most “useful” applications have a graphical user interface that allows users to interact with the application.
This implies that GUI programming is more common than programming textbooks “assume.” GUI programming is excluded by most texts because it is assumed that it is signiﬁcantly harder than ordinary applications programming.
Nevertheless, this is not true – it is true that GUI programming differs from conventional application programming, but being different does not make a methodology more difﬁcult.
Creating simple GUI applications with Scala is relatively simple, however, one has to compile the source code of the application as it is not straightforward to create runnable GUI scripts.
When compiling even a very simple GUI application, the Scala compiler will generate a number of .class ﬁles.
This implies that if one wants to run this application, one needs to have all these ﬁles in a particular directory.
Fortunately, it is possible to create a Java ARchive, which is a ﬁle format whose ﬁlename extension is .jar.
One can create Java archives using the jar command line utility.
The resulting Java archive is treated by Scala as a directory that contains.
The following commands show what has to be done in order to compile and run an application that consists of many .class ﬁles:
The third command deletes all .class ﬁles from the current working directory.
Having explained how to compile and run an application, it is time to construct our ﬁrst GUI “application.”
Figure 6.1 shows the code of a simple GUI application which when compiled and run will show a little windowwhose title will beGreetings and which will display the customary Hello World! message.
The ouput produced by this program is shown in Figure 6.2
As is obvious from the code in Figure 6.1,we have to use some Java classes directly in order to accomplish a number of tasks.
Somemay see this as a drawback,however, we strongly disagree with such a view.
The main reason is that since Scala runs atop the JVM, it makes no sense to rewrite everything from scratch.
One should be encouraged to use Java classes as long as they ﬁt into the general programming.
Let us now turn our attention to the description of the code in Figure 6.1
This class should be used as a basis for most GUI applications.
Any class extending this class should implement method top, since this is an abstract method.
Method top must return an instance of Frame, which is a superclass of class MainFrame.
The advantage of returning an instance of MainFrame instead of a Frame is that the former quits the whole application when it is closed.
Fields title and preferredSize are in fact getter/setter methods and can be used to set the title and the dimensions of the window.
Again,text and font are not real ﬁelds, but correspond to getter/setter methods.
With text one speciﬁes the text that will appear on the label while font can be used to specify the font that should be used to render the text.
Class Font is a standard Java class that deﬁnes a representation of a font.
When initializing an object of this class we need to specify the name of a real font (Verdana in our case), the font style (BOLD in our case), and the font size.
If we want the regular or the italic style, we should replace BOLD with PLAIN or ITALIC, respectively.
The bold-italic style can be speciﬁed with the following sum:
In this example, GridBagPanel is a container that contains only a Label component.
The nonstandard ﬁeld c becomes an instance of class Constraints.
This ﬁeld is very important since it contains information that is used by the container to place its components.
The value REMAINDER means that the component is the last in a row.
Method add is used to include a component in the container.
This method takes two arguments – a component and an object containing constraints speciﬁc to this component.
The color can be either a predeﬁned color (as the one used in the example in Figure 6.1) or a user deﬁned color.
For example, it is possible to deﬁne an RGB color with Color(r,g,b), where the arguments are numbers in range 0.0–1.0
An RGB color is produced by mixing “quantities” of red, green, and blue.
The four numbers specify the top, the left, the bottom, and the right edges, respectively.
The example presented is simple and, in addition, it is the simplest possible static GUI application (i.e., it is a noninteractive application)
A more elaborate static example is shown in Figure 6.3
The example in Figure 6.3 shows how to deal with situations where more than one component is to be included in a container.
Also, it shows how to load and display an image, something very important for many GUI applications.
Let us start by explaining how one can include an image in an application.
An image must be loaded and displayed inside a container and the simplest container is a Panel.
In general, it is possible to have a container inside another container.
Typically, images, after they have been read with Image.read, are stored as BufferedImages.
Once an image is read and loaded, it must be displayed.
This method is invoked automatically when the system is ready to display a component and takes one argument which is an abstract class that allows an application to draw onto components.
It is possible to specify explicitly the width and the height of the image as shown below:
So, you can safely assume that it is always null.
If we comment out the following line from the code in Figure 6.3
These “ﬁelds,” and some others, can be used to ﬁne-tune the appearance of a component in a container.
In order to understand how the following “ﬁelds” affect the appearance of a particular component, please bear in mind that each component “lives” in a cell.
The value RELATIVE speciﬁes that the component be placed exactly below the component that was added to the container just before this component was added.
On the other hand, by setting gridxwe specify the cell containing the leading edge of the component’s display area.
The value RELATIVE speciﬁes that the component be placed immediately after the component that was added to the container just before this component was added.
When using any of these values, they must be speciﬁed as in the example below.
The four arguments specify the inset from the bottom, the left, the right, and the top.
Any useful GUI application should allow users to interact with it.
Even in the simplest case, a GUI application should include a button which, when pressed, will terminate the application.
This means that there has to be a way to listen to events and to react accordingly.
Method listenTo should be used to make the application listen to the events that take place in the component that is its only argument.
Once an application listens to events occurring in a certain component, we need to specify what to do with them.
All we have to do is add a reaction to ﬁeld reactions.
This can be done with a command like the following one:
Here event is a pattern that must match a class deﬁned in package swing.event and action is any legal Scala command.
Literal b2 plays no role here, but we will see in the next example that it can be used to distinguish seemingly identical events.
If you have tried the previous exercise, you may have noticed that the button goes exactly under the label, while in the screenshot shown in Figure 6.5 there is clearly some white space between the two components.
This additional space can be inserted by adding an invisible component.
There are two kinds of invisible components: glues and struts.
A glue is a component which can be stretched either horizontally or vertically and is useful in cases where components have a maximum width or height, respectively.
Methods Swing.HGlue and Swing.VGlue yield a horizontal and a vertical glue, respectively.
On the other hand, a strut should be used to adjust the space between components.
A strut takes an argument that forces the layout manager to leave a certain amount of space between two components.
Methods Swing.HStrut and Swing.VStrut yield a horizontal and a vertical strut, respectively.
Note that a horizontal strut has no height and no depth,while a vertical strut has no width.
In particular, we want to write a GUI application which will display a window with one label and two buttons – one of them will open a new window with some“help” information and the other one will shut down the application.
In addition, the second window must display some text and it must also include a button which, when pressed, will close only this new window.
There are two problems we need to solve in order to build this particular GUI application.
The ﬁrst problem was identiﬁed earlier: How can the compiler know.
Figure 6.6 A window with a label and two buttons.
The ﬁrst problem can be solved by using method equals.
This is a method that all classes have and is used to compare the receiver object with the argument object for equivalence – x.equals(y) is true if both x and y reference the same object.
The code that follows shows how we can solve our ﬁrst problem:
Having a solution for the ﬁrst problem, let us see how we can solve the second problem.
When we say that a GUI application opens a new window, this means practically that the application will create an instance of class Frame.
Since Frame is a superclass of MainFrame, creating an instance of Frame should be a procedure almost identical to the creation of a MainFrame.
This is true and the only difference is that for any instance of MainFrame, “ﬁeld” visible is always set to true, while this is not true for any instance of class Frame.
If the value of this “ﬁeld” is not true, then the window is not visible.
Thus, we always need to give the proper value explictly to this “ﬁeld.” Figure 6.7 shows what needs to be done in order to open a window when a button is pressed.
In particular, we specify that a new instance of a particular class should be created when this button is pressed.
The text is displayed in a TextArea, that is, a special component that can be used to display and/or input text.
Similarly, method append takes one string argument which is appended to the current contents of component.
Finally,“ﬁelds” columns and rows can be used to set the number of rows and columns a text area may have.
The last problem we need to deal with is to ﬁnd a way to close the new window when the user requests.
Method dispose is the method we need to invoke in order to release all resources occupied by a particular window.
The code in Figure 6.7 shows how we can assemble all these components to build our toy application.
Although we have revealed many of the secrets of GUI programming in Scala, still we have not presented a real application.
For this reason, in the next section we show how to build a (simple) desktop calculator in Scala.
Figure 6.7 A simple interactive GUI application with one label and two buttons one shuts down the application and the other opens a new window.
In this section we will describe how to build a rudimentary desktop calculator, that is, we are going to describe how to build an application that will look like the one shown in Figure 6.8
The ﬁrst and easiest part is to design the GUI.
Observe that the buttons must be placed as if they have been placed in a grid, which is the best arrangement for this particular application.
A GridPanel is a container that arranges its components in exactly this way, thus, it is the ideal tool to arrange the buttons.
Although there are several choices concerning the functionality of the display (for example, should or shouldn’t it be user editable), we have opted to make it an instance of Label.
Since the display has to be at least as wide as the panel that contains the buttons, we need to use another container that will include all components.
The following code shows how one should pack the display and the buttons:
The declaration of each button looks like the following declaration:
Once all buttons are declared, they must be packed into a grid container.
The code that follows shows how this can be done:
First of all note how we add components to this container: we just “increase” the value of contents.
Since components are placed on a grid and all componets occupy the same space, it makes no sense to specify constraints on the placement of components.
The numbers in parentheses after GridPanel specify the number of rows and columns of the grid.
If either number is equal to zero, then the system calculates the optimal number of rows or columns, respectively.
Let us now see what should be done each time a number button is pressed.
In other words, we demand that each number contains no more than a predeﬁned number of symbols.
As one should expect, each action depends on previous events or the lack of any previous event.
Thus, if the calculator displays the digit zero, which should be displayed when the calculator starts or is being reset by pressing the Clr (clear) button, or if it displays the word error, which happens when, for example, one attempts to ﬁnd the square root of a negative number, or if the button that was pressed previously is an operation button, then we need to clear the display.
The following ﬁelds are used to control the behavior of our calculator:
Field isDecimal is used to handle the button with the period:
Field leftOperand is used to store the left operand of an operation.
The following code shows what should be done when the plus button is pressed:
The following code shows what should be done when the square root button is pressed:
Programming project 6.1 Using the description of this section build your own calculator.
Add more buttons that compute the trigonometric functions, logarithms, etc.
In addition, add a button that can be used to close the calculator.
The word graphics refers to the creation and/or the manipulation of pictorial data with the aid of a computer.
In this section we will describe how one can write Scala code that is able to create pictorial data.
Roughly, if one wants to draw something, it is necessary to deﬁne a canvas.
The latter is a container that has a central component that takes most of the space and has other components that are placed on one of its four borders: north, east, south, and west.
In addition, we need to redeﬁne method paintComponent since this is the one that draws objects on the canvas.
In order to make all these concrete, we will start with a simple example.
In particular, we will construct a program that will allow the user to press the mouse button and then draw a circle having a radius of 5 pixels.
The source code of this program is shown in Figure 6.9
Note that mouse events are handled in a different way.
For most applications an instance of Graphics can be used to solve most problems.
However, there are cases that can be dealt with better using Graphics2D.
This class, which is a subclass of Graphics, provides more sophisticated control over geometry, coordinate transformations, color management, and text layout.
Although, we do not need these additional features for this particular example, still we show how it is possible to use it.
Figure 6.9 A simple graphics example in which the user presses the mouse button and in response it draws a little circle.
The value of “ﬁeld” opaque controls whether all the bits of the component will be painted or not.Method fill takes a shape and paints the area occupied by the shape with the current color.
There are many different shapes such as Polygons, Rectangles, etc.
In this particular case, the rectangle is speciﬁed by its width and height.
In the most general case, it is speciﬁed by giving the coordinates of the upper-left corner and the width and the height of the rectangle.
Figure 6.10 The standard coordinate system used in Scala/Java graphics.
The x coordinate increases to the right, and the y coordinate increases downward, as shown in Figure 6.10
If for some reason it is necessary to have a different coordinate system, one can use method transform.
This method takes an instance of a class that represents an afﬁne transformation.
The following code snippet shows how to construct such an instance:
The user-deﬁned ﬁeld mouseclicked is set false in order to prevent the program from printing a dot on the screen.
Now, let us see how the program handles the mouse events.
First of all, note that we specify that the system should listen to a particular event category (for example, Mouse.clicks) and not to any event that may happen on a component.
This event category should be used when the mouse is clicked, pressed, or released.
In addition, the event categories Mouse.moves and Mouse.wheel should be used when the mouse enters, exits, moves, and drags, or when the mouse wheel moves, respectively.
Each event can be handled one by of the following event handlers:
When the user clicks the mouse, then the current mouse position is grabbed and the coordinates are stored in two variables, variable mouseclicked becomes true, and method repaint is invoked, The result of the invocation is to reexecute method paintComponent.
Use the following method to print the coordinates on the canvas:
Although this example is quite instructive, still it does not show all the things one can do.
The next example will reveal some other capabilities and it will show how one can solve problems in unexpected ways.
A simple paint-like application Let us now construct a simple paint-like application (i.e., an application that allows users to sketch simple curves, see Figure 6.11)
Change the drawing color after user has // clicked the mouse on the color palette.
Called when mouse is pressed and user clicks //on the drawing area.
The “global”members of the skeleton code in Figure 6.12 are ﬁelds that are used throughout the application.
The following code snippet contains the deﬁnitions of all these “global”members:
Method paintComponent is redeﬁned so as to draw the window of the application.
In addition, there is provision for the color palette and also there is some space that will cover the white area.
Method drawRect draws a rectangle (i.e., four perpendicular lines in a particular color)
The next thing that must be done is to draw the CLEAR “button.” This “button” is drawn at the lower right corner of the canvas.
However, in order to make the button more realistic, we leave some space outside the “button” that is painted black.
The last thing we have to do is to put the label on the “button”;
Method drawString renders a string, the ﬁrst argument, using the current font.
The second and the third arguments refer to the coordinates of the left edge of the baseline where the ﬁrst character is placed.
The last thing that needs to be done is to draw a border around the color “button” that is currently active:
Method changeColor is invoked when the user clicks on the color palette in order to change the pen’s color.
It has as its only argument the y-coordinate which is used to compute the color that was chosen by the user.
Since all color “buttons” occupy the same space, one needs to divide the y-coordinate by colorSpacing to ﬁnd which “button” was chosen:
Each class of the scala.swing package overrides “ﬁeld” peer in order to provide direct access to the corresponding Java JFC/Swing class.
The code that follows resets the border color of the previous color “button” and after setting the new color it.
By invoking method dispose we free the corresponding graphics context and, consequently, release any system resources that it is using.
It just sets up the graphics context in the current color:
In this particular application, the user can press or release the mouse’s buttons or the user can drag the mouse while a button is pressed.
Let us ﬁrst see what should happen when the user just presses the mouse’s buttons.
In the code that follows p holds the coordinates of the mouse the moment the mouse’s button is pressed:
Now let us see what should happen when the user clicks on the white drawing area.
In order to draw a curve, the application needs to “remember” the previous coordinates of the mouse:
The test is necessary to ensure that the user has clicked the mouse on the white area.
Now let us see what should happen when the user releases the mouse’s button.
In the case that the user was drawing something, we assume that the user has ﬁnished.
Of course, we may resume later but this is something that should not concern us here:
The last thing we need to handle is the motion of the mouse while a mouse button is held down.
If the user is drawing, the program should draw a line segment from the previous mouse location to the current mouse location:
Method drawLine draws a line in the current color from one point to another.
Exercise 6.5 Redesign the applicationwindow tomake room for aCLOSE“button.” In addition, modify the code so that the window closes when the user presses this new “button.”
Programming project 6.2 Create a pen palette from which the user can choose pens with different strokes.
We have already seen how to draw images on a canvas on the computer screen.
However, we have not explained how to save graphical data directly to pictorial data or just image ﬁles.
In fact, if these image ﬁles have a fairly simple structure, then it is relatively simple to create such ﬁles.
In addition, it is not difﬁcult to save graphical data in common image ﬁle formats like JPEG or PNG.
Let us start by showing how one can create simple image ﬁles.
In [71], the author explained what is needed to save graphical data into PPM, PGM and PBM ﬁles.
A PPM (Portable Pixel Map) image ﬁle can be used to create colorful images.
The ﬁrst four lines of a PPM ﬁle have the following form:
The rest of the ﬁle contains pictorial data in nonbinary form, that is, the data are in a human readable form.
In particular, for each image pixel there are three positive integers that denote its corresponding RGB color.
The“maximumcolor value”must be less than 65536 and greater than zero.
As a ﬁrst exercise we will construct a program that will output a PPM image ﬁle depicting a chess-like board like the one shown in Figure 6.13
The code that follows creates the image shown in Figure 6.13
In order to create a PPM ﬁle with binary data, we ﬁrst need to store the data with a FileOutputStream instead of a FileWriter and then to transform the header.
Method getBytes encodesthis string into a sequenceof bytes using theplatform’s default character set.
In addition, each of the tree output commands inside the repetition construct must be replaced with a command like the following one:
Exercise 6.6 As it stands the program produces the same output all the time.
However, it is not difﬁcult to make the program draw as many squares in as many different colors as the number supplied as a command line argument.
Implement this idea and make sure there are enough different colors!
A PBM(Portable BitMap) image ﬁle can be used to create black andwhite images.
The ﬁrst three lines of a PBM ﬁle have the following form:
The rest of the ﬁle contains the pictorial data in nonbinary form.
Each digit represents the color of a pixel – ones represent black and zeros represent white.
If the pictorial data are in binary form, then each byte represents the color of 8 pixels.
Creating PBM ﬁles with nonbinary data is easy, but creating PBM ﬁles with binary data is rather tricky.
We will show how to create such a ﬁle by implementing an algorithm described in [63]
The algorithm examines a bit within the binary representation of an integer and paints the corresponding pixel.
In particular, if i and j are the coordinates of a pixel, then depending on the nth bit of the binary representation of i2j the algorithm paints pixel (i, j) accordingly.
The “chaos from bits” algorithm, as its author Clifford A.
Pickover calls it, produces images like the one shown in Figure 6.14
However, before proceeding we need to solve a few problems.
First of all, we need to ﬁnd out how to transform an integer number into a bit string, that is, a string that contains binary digits only.
An “obvious” solution is to use method toBinaryString which yields the bit string value corresponding to this:
Unfortunately, method toBinaryString generates strings that do not contain a ﬁxed number of digits.
So it is necessary to pad the string produced by this method with a number of zeros.
A PGM (Portable Grey Map) image ﬁle can be used to create gray scale images.
The ﬁrst four lines of a PGM ﬁle have the following form:
Here “maximum gray value” is a number that must be less than 65536 and greater than zero.
Each pixel is “colored” with a number in the speciﬁed range.
Exercise 6.8 There is a bug in the two programs presented in this section so far.
The term JPEG is a commonly used method of compression for photographic images.
The term PNG (Portable Network Graphics) refers to an open, extensible image format with lossless compression.
Basically, the PNG format was designed to replace the older and simpler GIF format and thus it is widely used in the Web.
In the rest of this section we will show how to create simple and complex images in these image formats.
Let us start with a simple example, which will form the basis of our explorations.
The code snippet that follows shows exactly what is needed to create a JPEG ﬁle:
To create a PNG ﬁle just replace jpg with png! Function CreateImage creates a RenderedImage object:
Graphics context no longer needed so dispose it G.dispose return bufferedImage.
As an exercise, we will show how to draw the Mandelbrot set with Scala.
We use the distance estimator method [62] to draw the Mandelbrot set.
The code presented above draws the Mandelbrot set quite fast which means that Scala can be used for scientiﬁc computation.
Obviously, it is not enough to provide facilities for scientiﬁc computation, we need also to be able to deliver results really fast.
A dialog window is one with an optional title and a border that is typically used to take some form of input from the user or to notify the user with a message (for example, a warning)
The most simple form of a dialog is a conﬁrmation dialog, that is, a window that asks a user to conﬁrm or to deny the execution of a particular action.
For example, if we replace the reaction part of the code that generates the.
Figure 6.17 Function MSetDist which is used in function drawMandelbrot.
Figure 6.18 The Mandelbrot set as drawn with the distance estimator method.
Figure 6.22 A dialog window with an alternative decoration icon.
Figure 6.23 A dialog window with a customized button text.
If the icon ﬁle resides in a remote computer connected to the Internet, it is possible to use this image by letting the system resolve the URL and fetching the ﬁle.
In many cases it is necessary to be able to customize what appears on the buttons.
For example, when constructing a GUI application for Greek users, the buttons should look like the those of the dialog window shown in Figure 6.23
Method showOptions can be used to create such customized buttons:
The text that should appear on the buttons is stored in an array which is passed as an argument to method showOptions.
Method showMessage should be used when we want just to display a message.
If we replace the code above in the GUI application with the code that follows.
In certain cases it is useful to be able to get input from the user.
For example, if one programs a network diagnostic tool, which needs to ask users to enter their network connection, then method showInput can be used to get input from the user.
The code that follows can be used to create the dialog window shown in Figure 6.25:
Method showInput returns a Some(v) value, if a value is selected or None if Cancel is pressed.
The entries appear as a pull-down menu from which the user can choose a value.
The last argument of the method is the default value.
In rare cases, one may need to let the user type a response instead of choosing one from a set of possible answers.
In this case, one can simply replace the sixth argument with Nil and so when the dialog window pops up, the user can enter the preferred value.
Typically, a menu is a list of options displayed on a window (for example, as a pull-down window) and from which the user may make a choice.
There are several forms of menus and in this section we will present all the different forms of menus.
A radio button is a type of GUI component that allows the user to choose only one of a predeﬁned set of options.
Suppose we want to create a set of radio buttons.
Then the following code snippet should be used to create a set of radio buttons:
Here BoxPanel is a panel that lays out its contents one after the other, either horizontally or vertically.
The next thing we need to know is how to respond to a user selection in a radio button group.
Figure 6.26 A simple GUI application with a radio buttons group.
Assume that a user has to press an ordinary button after selecting a radio button.
Then the following code shows exactly how to program a response to a user selection:
Here the patterns are stable identiﬁers, that is, patterns which in general are paths (i.e., parts of a named type like C.this or C.super.x) that end in an identiﬁer.
One should be careful and make sure that all a1,…,aN conform to the expected type of the pattern.
As an exercise let us build a simple GUI application with a radio button group like the one shown in Figure 6.26
After the user has made a choice and has pressed the “Choose a team” button, a question is printed just under this button.
The code that follows shows how to deﬁne the buttons:
And the code that follows shows what should be done in order to place the button in the panel and how to program the behavior of the application:
Exercise 6.9 Complete the code above and verify that it works in the expected way.
These are GUI components that allow users to make multiple selections from a number of options.
For example, a restaurant menu can be easily described with check boxes.
In order to show how to use check boxes, we will implement the (very simple) “calorie calculator” shown in Figure 6.27
First of all we need to create an instance of class CheckBox for each check box:
Figure 6.27 A “calorie calculator” that demonstrates the use of check boxes in Scala.
Once all check boxes have been deﬁned, we need to place them in a panel.
The best way is to deﬁne a special panel that will be included in the panel that includes all components:
The check boxes will be enclosed in a compound border (i.e., a border that allows multiple border objects) with a title drawn in etched border style.
In addition,we set the color of the background of each check box as well as the color of the background of the panel.
Observe how we add all the components in the panel and compare it with the way we added the button group in the same panel:
After arranging the buttons, we need to see how to handle the events that occur on these buttons:
Next we need to specify what to do when a button is selected and when it is deselected.
Since we compute the calories, when a button is selected we add the calories that correspond to the speciﬁc food and, naturally, we subtract them if the button is deselected:
Method isSelected checks whether a given check box is selected or not.
The two ordinary buttons that are shown in Figure 6.27 become part of a box panel:
Although putting all the components together is easy and the reader should be able to write the corresponding code, we still believe it makes sense to show one more time how things should be done.
The code snippet that follows shows how to put all the components together:
Now let us see what should happen when each of the ordinary buttons is pressed.
In the case of the leftmost button, all we need to do is to display the total calories in the specially designated label:
In the case of the reset button, we reset the value of the “global” ﬁeld cals, then deselect all buttons, and make the text of the result label empty:
A combo box is a GUI component which is a combination of a drop-down list and a single-line text box, allowing users either to type a value directly into the control or to choose from the list of existing options.
In Scala one can create combo boxes with a deﬁnition like the following one:
Then we could arrange them horizontally, one after the other, by including them in a FlowPanel.
Also, the code shows how to make the action listener listen to the events that occur on a combo box and how to handle these events:
Also, “ﬁelds” item and index return the item selected and the index of the item selected (with zero being the ﬁrst index)
With this information, we can create a GUI application like the one shown in Figure 6.28
Let us see how we can construct such an application.
First of all we need to deﬁne a hash table with the correct answers:
Figure 6.28 A simple GUI application that uses combo boxes.
Let us deﬁne the combo boxes and some auxiliary members:
Now that the combo boxes have been deﬁned we need to arrange them in a panel:
Exercise 6.10 Enclose the combo boxes in a border, like the one in the previous example.
Once the combo boxes have been arranged, we need to specify how to handle the events that occur on them:
As is evident, we simply assign to the auxiliary members, the values selected by the user.
The two buttons in the lower part of the application can be programmed easily:
Exercise 6.11 All componenents and subpanels are arranged in a GridBagPanel.
Write the code that arranges all these components in the panel.
The last thing we need to take care of is what should happen when the user presses either button.
In the code that follows we have used a different coding technique to show that one should experiment and not learn by heart all the programming idioms presented in this chapter, unless, of course, it is absolutely necesary:
Exercise 6.12 Add a label that will display how many correct and how many wrong answers the player has given.
Especially for combo boxes it is possible to have images instead of strings.
The simple GUI application shown in Figure 6.29 demonstrates the use of images in a combo box.
Since creating such a combo box is not straightforward, we will explain in detail what should be done in order to create similar combo boxes.
First of all we have to specify how the images will be loaded.
This method translates a string to an instance of java.net.URL, which can be consumed by ImageIcon.
If for some unpredictable reason the ﬁle that contains the image is not in the expected.
Figure 6.29 A simple GUI application that uses combo boxes with images.
And this exactly is the reason why the formation of the combo box is part of a try expression:
Object Swing.EmptyIcon stands for a no-image, that is, an imagewith no contents and no dimensions.
However, in order to be absolutely sure that our application will not have to use the fallback mechanism, we can include the images in the ﬁnal .jar ﬁle as shown below:
As expected, when the user clicks on the image that is shown on the combo box, a drop-down menu emerges.
As the user moves the mouse over the menu, the images are highlighted.
This “ﬁeld” is used to set the renderer for this combo box’s items.
The renderer that we are using provides a component that is responsible for item rendering and it assumes reasonable default settings.
Method configure can be used to specify how images should appear when the mouse is over them.
Method Swing.LineBorder draws a line as border in a speciﬁc color which is either user speciﬁed or system speciﬁed (i.e., there are two constructors)
The label likes is used to display the message “ So you like….” Integrating the code that deﬁnes the label into a GUI application is easy and the reader should have no problem doing so.
Combo boxes are not the only components with icons, one can also create labels with icons.
For example, the following deﬁnition creates a label with an image instead of some text:
Although the current version of Scala does not support the creation of buttons with icons, still it is very easy to deﬁne a new class that will create buttons with images.
The easiest way to deﬁne such a class is to create a subclass of the Button class.
Remember that all GUI related classes are actually wrappers around Java’s JFC/Swing classes, thus, trait SuperMixin is used to redirect certain calls from the peer to the wrapper and back.
If we replace the code that creates the button shown in Figure 6.1 with the following code.
Figure 6.30 A simple GUI application with a button that bears an image instead of some text.
Deﬁne a Scala class that creates such buttons and test its usability.
Any nontrivial GUI application has a menu bar, that is, a bar where a number of menus are available.
Typically, each menu is a pull-down window that offers a number of (different) choices to users.
Class Frame deﬁnes “ﬁeld” menuBar which should be used to deﬁne a menu bar.
Typically, one can deﬁne a menu bar inside method top as follows:
The menu bar consists of individual menus and each individual menu consists of menu items.
The next few commands show how to deﬁne a new menu and how to add menu items:
As expected, the string argument is the corresponding title of each menu and menu item.
Class Separator creates a horizontal line that separates menu items.
The ﬁrst thing we need to take care of is to deﬁne the component that will be used to edit and display the text.
When using an editor one needs to be able to open a ﬁle, to modify its contents, and then to save the changes made.
The capability to navigate the ﬁle system, and then to choose either a ﬁle or a directory from a list, or enter the name of a ﬁle or directory is provided by ﬁle choosers.
The argument of the constructor is the default directory from where the navigation of the ﬁle system begins.
As should be obvious, a user can pick up only ﬁles not directories.
We can use the ﬁle chooser to implement the expected functionality of the Open menu item from the File menu:
First of all, we are using class Action to program the behavior of the menu item.
Method selectedFile returns the File that the user has selected.
Class Source provides an iterable representation of input ﬁles and this is why we are able to use the ﬁle in a for comprehension.
Method getLines returns string iterator, that is, a structure that allows the iteration over a sequence of elements, which in our case are the lines of the input ﬁle including the line ending character.
Method Source.fromFile creates an iterator from, among others, a File.
Member backup is user deﬁned and it is used to check whether the contents have been modiﬁed since the last save operation took place.
Programming the behavior of menu item Save is more involved.
We have to distinguish two different cases – one where the contents of the text area have not been saved before (i.e., the user has typed something) and one where the user has opened a ﬁle in order to modify it.
The ﬁrst case can be handled by the following code snippet:
The user-deﬁned member currentFile holds an instance of a File that corresponds to the ﬁle that has been opened or to the ﬁle to which the program has just saved data.
If currentFile is null, then the user must choose the output ﬁle where the data will be stored.
Exercise 6.14 If the user selects an existing ﬁle, the code overwrites the existing ﬁle without asking! Remedy this deﬁciency of the code.
Hint: Use method exists() of class File, which checks whether the ﬁle denoted by a class instance exists.
If currentFile is not null, then the program will save the data to the file stored to this member:
When the user chooses New, the program must take care of the current contents (if any) of the text area:
The user-deﬁned method check_on_exit examines whether the text stored in the text area has been saved in a ﬁle.
If this is not true, then a dialog window pops up and asks whether the user wants to save the ﬁle or not.
Depending on the user’s response the program saves the contents, discards them, or continues as if nothing happened.
Now we can easily implement the menu item for Exit:
Exercise 6.15 Implement the functionality of the Close menu item.
Printing the contents of the text area is very simple:
Implementing the Editmenu,which includes the Find and FindNextmenu items, is more involved but not difﬁcult.
Of course, one must bear in mind that we are building a rudimentary editor and not some full-ﬂedged editing tool.
In order to make searching general enough, we have opted to use regular expressions.
Since the functionality of Find Next depends on the outcome of Find, we deﬁne the.
The easiest way to allow the user to enter the word (pattern) to be searched is by using an showInput dialog with an empty list of entries and no initial choice:
Once the user has closed the dialog window, we need to check whether some input has been provided:
Method isDefined returns true if s is not equal to None.
In the case when we want to check whether an option value is None, we should use isEmpty.
Since we are sure that s is not None, there is no reason to use pattern matching to obtain its value.
However, if we are not sure whether an option value is None, it is better to use getOrElse, if we insist on not using pattern matching.
This method returns the value if the option value is nonempty, otherwise it returns its argument evaluated.
Now that we are sure that the user has entered a “word,”we prepare the pattern matcher to start searching the text stored in the text area:
Object caret is a wrapper around a Java class that implements the idea of a place within a document view (roughly, the part of a document that is visible to a user) where things can be inserted.
Generally,we can say that a caret is the cursor and its.
If the pattern matcher ﬁnds a word that matches the pattern, then we move the cursor to the print where this word starts.
Otherwise, we have to inform the user that there was no match.
If the user chooses thismenu itemwhile the patternmatcher has not been initialized, then we must ensure that our program will not crash.
This is exactly the reason why we need to make sure that m is not equal to null.
In addition, we could use highlighting, but this requires extensive Java programming, so we skip it.
Exercise 6.16 Assume that the user will enter simple words not regular expressions.
Implement the searching mechanism using method indexOf (see Section 2.14)
We have deﬁned all menus and we have deﬁned the text area that will hold the text, what is left is to put it all together.
The good news is that for menu bars there is nothing special to be done: they are automatically included in the application once they are deﬁned.
Thus, we need a component that will contain only the text area.
But we need a container that will allow users to scroll both horizontally and vertically.
A ScrollPane is a component that can include at most one component that can be scrolled (i.e., scrolling makes sense):
The last thing we would like to say is that if we want our text editor to be copy and paste “aware,” then we need to include at least the following commands in our ﬁnal code:
A tab is a navigation widget that, in the simplest case, allows users to switch between sets of pages, which contain GUI component.
The real beneﬁt of using tabs is that users do not have to open many different windows – they just need to open a new tab for each window.
A simple GUI application with tabs is shown in Figure 6.32
The application shown in Figure 6.32 consists of ﬁve tabs, each of them showing a picture.
Each tab is a TabbedPane.Page and, at the same time, it is a member of an instance of a TabbedPane.
In order to achieve this we load the picture, as has already been described, and make it the value of “ﬁeld” icon:
Object TabbedPane.pages is a structure similar to an array and it holds the tabs and can be used to append, remove, and insert tabs.
Operator += “appends” a tab; method insertAt takes two arguments – an integer and a tab – and inserts a tab at a speciﬁc position; method remove takes an integer and deletes a tab from a position that corresponds to its argument; and, ﬁnally, method length returns the number of tabs stored in the class instance.
Typically, any application with tabs allows users to manipulate tabs.
Therefore, it is much more useful to build an application with disposable tabs, much like the one shown in Figure 6.33
The example is a rewrite of an example presented in the “The Swing Tutorial” at Oracle’s web site.
This application does not include provision for inserting tabs but, as we will see, adding this functionality is almost trivial once one has managed to deﬁne user-disposable tabs.
Aswas explained above, there is provision for changing a tab panel (i.e., by removing a tab)
However, what is missing are GUI components for the removal and/or insertion of tabs.
Typically, applications that provide this functionality include a menu item for the insertion of tabs and a button on the tab title for removing the tab.
In order to have this button, we need to redesign a new component to replace.
The ﬁrst part is not difﬁcult, but if there is no way to replace the title component, it is almost useless.
The skeleton of a class that deﬁnes such a component is shown in Figure 6.34
Figure 6.34 Skeleton of a class that deﬁnes a component that can be used to render the title of a tab.
Although we have explained how to handle mouse events, we did not give examples that show how to handle mouse events that happen over speciﬁc components.
Class ButtonTabComponent deﬁnes a component that includes two other components: a label and a button.
The label is used to display the title of the tab while the button is there for users who want to close a particular tab.
The label gets its text from the title of the last tab inserted in the tab panel:
The following commands are executed every-time a new instance of this class is created:
The value of “ﬁeld” rolloverEnabled determines whether rollover effects will occur or not.
An example of a rollover effect is an image which changes when the mouse is over it.
In our case, the rollover effect will be the change of color of the “X” mark on the button.
The deﬁnition of the class is completed with the redeﬁnition of method paintComponent:
The ﬁrst command is included so to make sure all other paintings will ﬁnish before we proceed with the painting described in this method.
In this case we create a simple stroke whose width is 2 units.
This code snippet changes the color of the “X” mark when the mouse is over it.
In particular, method isRollover returns true when the mouse is over the button.
These commands draw the two lines that make up the “X”mark.
When the mouse is on the tip of a tab and is pressed, it should remove the tab.
When the mouse is not over the button, then the border of the button will lose its painting:
The following code implements something that is obvious for a user but not always for a programmer – when the user clicks on the label, the program should make this tab the one in the foreground.
This is something that is handled automatically (try the previous example and you will see what we mean), but from the moment we placed a label over it, things are not the same:
So far we have seen only one way to change tabs – by pressing on the tab’s tip.
However, there are at least two more ways and we are going to describe them and show how to implement them.
The ﬁrst involes the use of sliders and the second GUI lists.
A slider is a component that lets users select a value graphically by sliding a knob within a bounded interval.
The slider can show ticks (both major and minor between the major ones)
In addition, sliders can print text labels at any location along the slider track.
A GUI list is a component that displays a list of objects (for example, text) and allows users to select one or more items.
It is quite instructive to think of GUI lists as hyperlinks.
The GUI application shown in Figure 6.35 demonstrates how one can use both sliders and GUI lists to change tabs in a GUI application with tabs.
Let us see how we can implement this GUI application.
The method we used in section 6.8.1 also works here, so we will not repeat it.
The core of the code of the application is shown in Figure 6.36
Member list is an instance of ListView and it is used to display a sequence of TabbedPane.Page, which automatically builds a nonmodiﬁable instance of a list model.
Method selectIndices takes as argument an integer, which corresponds to a selection, and changes the current selection to this number.
Figure 6.35 An application with tabs, sliders, and GUI lists.
The reader may have noticed so far that both the tabs and the GUI list are not yet part of the main application panel.
Also, it should be evident that the main panel is split into two subpanels, separated by a divider.
The constructor of a SplitPane takes three “arguments”: a value that corresponds to the pane’s orientation, the left and the right components.
In other words, by setting this property, the divider component (i.e., the little vertical line shown in Figure 6.35) gets the two little arrows that make it possible to shrink and expand either side of the split pane.
Also, “ﬁeld” continuousLayout should be set to true if we want the two components to be continuously redisplayed and laid out during user intervention.
If one wants to set the width of the divider, one should use “ﬁeld”dividerSize, whose value is an integer that denotes the width in pixels.
In addition, “ﬁeld” dividerLocation can be used to set the exact location of the divider.
In Scala, a slider is an instance of class Slider.
If we want to add labels to certain ticks, we can do this fairly easy.
For example, if we add the code that follows in the deﬁnition of slider.
Figure 6.37 A application with a slider that has ticks and labels.
A BorderPanel is a component that can contain other components.
There is always a central component that occupies most of the available space.
Other components can be placed on the north, south, east, or west of this central component.
There are three different kinds of events that may happen in our application: the user may slide the knob of the slider component, or the user may select a tab, or choose an element from the GUI list.
Therefore, the application must listen to all these events and adjust itself accordingly.
Note that member adjusting is set to true when the knob moves and this is why we check whether it is false.
In the end, the value of the slider, which is stored in member value, is used to set the current tab.
In Section 6.7.4 we used a TextArea component to build a rudimentary text editor.
However, this is not the only text-based component – Scala supports simple text.
Figure 6.38 A minimal application with a text and a password ﬁeld.
Roughly, a text ﬁeld is a TextArea with only one line, while a password ﬁeld is a text ﬁeld where one can see that something was typed, but one cannot see the original characters.
As in all previous cases, we will build a simple application in order to show the capabilities of both text and password ﬁelds.
Figure 6.38 shows such a minimal application that mimics a login screen.
Let us start with the text ﬁeld which is an instance of class TextField:
In other words, the length of the text ﬁeld (stored in “ﬁeld” columns) can be supplieddirectly to the constructor.2 Similarly,we can either directly supply the contents of a text component or assign it to “ﬁeld” text.
By default “ﬁeld” editable, which controls whether the text ﬁeld is editable, is true.
The value of this “ﬁeld” can be any function that takes a string and returns a Boolean.
Behind the scenes, when the editing is done, this function takes as argument the text of the text ﬁeld and only if the function returns true, the focus can move to another component (roughly, one cannot use any other component unless the function returns true)
The value of this “ﬁeld” does not imply that the length of the user name will be ten or at most ten characters long! It just means that the user can see at most ten characters and this happens only if the font used has glyphs that are wide enough.
It is possible to impose further restrictions on the data that can be entered in a text ﬁeld, but we will come back to this after we have discussed password ﬁelds.
But it makes sense to supply only a value for columns:
The value of “ﬁeld” echoChar is of type Char and it is the character that appears when the user enters something in a password ﬁeld.
Method password returns an array of characters that contains the characters the user has entered in the password ﬁeld.
When a user enters some text in a text ﬁeld, there is only one way to tell when the user has ﬁnished – the user has to press the enter key.
In our simple application the user will press the enter key after entering the password.
Class EditDone detects this event and the code that follows shows how we handle events in this application:
Our code is very simple since we assume that there is only one user and, naturally, only one password.
In the simplest case it takes only one argument which corresponds to a separator that will appear between array elements.
Naturally, method toString is invoked to create a string representation of each element.
In its most general form, method deepMkString takes three arguments which are all strings.
The ﬁrst one is the argument with which the string representation will start, the third is the one with which the string representation will ﬁnish, and the second is a separator.
Indeed, it lacks some features that will make it more realistic.
First of all, our application prints an error message when the user fails to enter the correct combination of user name and password, but it does not print a message inviting the user to retry.
Before presenting the other problem, let us see how we can solve this problem.
In order to print the error message and then prompt the user to retry, we need to insert some code that will delay the appearance of the second message, or else only the second will appear.
The simplest way to implement the required functionality is to use an actor (see Chapter 7 for details)
Roughly, in the code that follows the commands form a block expression (i.e., a block that evaluates to an expression, see Section 7.1 for more details) that is executed in a different thread of execution.
Putting it simply, this means that the commands that make up the block expression will be executed independently from the commands that precede or follow them.
In conclusion, the net effect of the deﬁnition above is that the ﬁrst command will be executed, then the thread will pause for 2.5 seconds, and, ﬁnally, the second command will be executed.
But this is not enough: focus must go to the text ﬁeld where the user name is entered while the previous user name must be.
Obviously, method requestFocus moves the focus to the component it is called from.
Table 6.1 Special characters that may appear in a MaskFormatter mask.
Any valid decimal digit (i.e., c.isDigit, where c is a Char and method isDigit returns true if c is a decimal digit,will return true)
Escape character, used to escape any of the special formatting characters.
A Any letter or digit character ? Any letter character.
Therefore, we deﬁne this new MaskFormatter component so that the users of the class use Java classes only implicitly.
A table is a GUI component that can be used to display data in a tabular form (for example, think of a spreadsheet, which is the archetypal application that displays data in a tabular form)
Usually, one cannot modify the contents of any cell, but, optionally, program designers may allow users to edit the data.
Obviously, the data displayed by a table are not part of the table as, for example, one can use the same table to display different sets of data.
A table can be constructed by creating an instance of class Table.
In order to construct a table, we can supply either two arrays or two integers to the constructor.
In the ﬁrst case, the ﬁrst array is actually an array of arrays of type Any that contains the data that are displayed in the table, while the second array contains the strings that are used as row names.
In the second case, we create a table that contains.
As a matter of fact “ﬁeld” preferredSize gets instances of this class as values.
Exercise 6.20 The input ﬁle that contains the XML content has the following format:
By design there can be at most three <author> elements.
The XML content will be loaded with the following command.
As it stands one cannot easily add or remove rows.
So, we cannot easily transform our XML viewer into an XML editor.
In order to be able to add/delete rows we need to be able to pass an ArrayBuffer instead of an Array.
The following interaction with the language interpreter shows the basic capabilities of ArrayBuffers (the output has been truncated for typographic reasons):
An applet is a program written in any language that runs atop the JVM and which can be included in anHTML page, just like an image can be included in such a page.
In order to include an applet in an HTML page, one needs to know the basics of the HTML <APPLET> tag.
However, for our needs the following general form of the tag is enough:
The attribute archive is used to specify the location of one or more Java archive ﬁles.
Naturally, a better idea would be to bundle these libraries with the ﬁnal archive (see appendix B for more details), but here we want to make things as simple as possible.
Building applets is similar to the construction of ordinary GUI applications.
The skeleton code that follows shows the general structure of an applet:
Abstract class Applet.UI declares the three methods shown above and provides a redeﬁnition of “ﬁeld” contents.
Trait Reactor deﬁnes the methods listenTo and deafTo whose effect is to remove events from the event listener.
Method init is called by the browser to inform the applet that it has been loaded into the system, method start is called to inform the applet that it should start its execution, and method stop is called to inform the applet that it should stop its execution.
Typically, one should use init to initialize some variables, nevertheless, this is not necesary in most cases.
So one can have the whole code of an applet in.
However, there are cases where the two methods have different roles to play (for example, see Section 7.2)
Instead of presenting a simple applet, we have opted to present an applet that is a rewrite of the “jumping box” Java applet that comes with every version of the Java Development Kit (JDK)
This way, readers with some experience in Java programming will be able to translate their applets easily in Scala, while readers with no familiarity with Java will see how to construct real applets.
Figure 6.40 is a screenshot that shows this applet in action.
The “jumping box” applet implements a simple game where the user tries to hit with the mouse a square that moves on the panel.
To make the game realistic, each user action is associated with a particular sound, while messages appear on the status bar (i.e., the bar that reads “HIT IT AGAIN! AGAIN!” at the bottom of the screenshot shown in Figure 6.40)
We will now reveal the code that implements this applet.
The ﬁrst two members hold the coordinates of the lower left corner to the square that the user tries to hit.
The third member holds the size of the applet and the fourth one counts the number of times the square has been hit.
As is obvious, method init does almost nothing! As was made clear above, the body of method start can replace the body of init and the result will be the same.
Here ComponentResized is cached when the applet or, more generally, a component is resized.
Other such events are described by the classes ComponentHidden, ComponentMoved , and ComponentRemoved.
The code that follows is the body of method paintComponent:
The code above erases the old square and redraws a new one in a new random position.
The code that follows is executed every time the mouse button is pressed:
Finally, method showStatus takes a string as argument and “forces” the browser to show its argument in the statusbar.
As is evident, the programming style employed in GUI programming is the imperative programming style.
Unfortunately, it is a common belief that functional programming has no role to play in GUI programming and graphics.
For example, Conal Elliott has designed and implemented a purely functional system for making graphical images.
This system, which is called Pan [20], is implemented as a Haskell library (a “domain-speciﬁc embedded language”)
The following code snippet is a typical usage example that shows how one can draw an image like the one shown in Figure 6.41:
In a nutshell, the let expression deﬁnes a scope that includes the expression speciﬁed in the in part.
Obviously, circles holds an expression that is equal to what the let expression has computed.
However, it would be quite interesting to see whether one could implement it as an internal DSL based on the fact that the language can grow itself.
Not so surprisingly, one can deﬁne such an internal DSL and the following code snippet.
Figure 6.42 A class that implements a very simple GUI domain-speciﬁc language.
Figure 6.42 shows the deﬁnition of a class that provides the required functionality in order to make the code just presented meaningful.
Class java.awt.Alpha Composite is used in order to make transparent the graphics generated by Graphics2D.
Today’s computers have multi-core processors (i.e., integrated circuits to which two or more processors have been attached), which, in principle, allow the concurrent execution of computer instructions.
In other words, today’s computers are able to perform two or more tasks at the same time.
Concurrent programming refers to the design and implementation of programs that consist of interacting computational processes that should be executed in parallel.
In addition, concurrent programming is not only the next logical step in software development, but the next necessary step.
Thus, all modern programming languages must provide constructs and libraries that will ease the construction of concurrent programs.
Scala allows users to design and implement concurrent programs using either threads, or mailboxes or actors.
Unfortunately, programming with threads is a cumbersome task, thus, concurrent applications in Scala are usually implemented using the actor model of programming.
Roughly, a process is a program loaded into memory that is being executed.
A thread, also known as a lightweight process, is a basic unit of processor utilization.
Processes may include more than one thread while traditional processes include only one thread.
Threads may effectively communicate but since they share a process’s resources (for example, memory and open ﬁles), their communication is not without problems.
Each Scala program has at least one thread while several other “system” threads take care of events in GUI applications, input and output, etc.
The main thread of every application can be used to create additional threads as we will see below.
Threads can be constructed by creating instances of a class that either extends class Thread or mixes in with trait Runnable.
Class Thread deﬁnes method run which, in the most general case, does nothing.
Figure 7.1 Creating a threaded application by extending class Thread.
Figure 7.1 shows how one can construct a threaded class by extending class Thread.
Each thread is created by constructing an object of Thread or, in this case, an object of a class that subclasses Thread.
Method start should be called when a thread is ready to run.
In our case, the Thread objects are immediately ready to run.
Method sleep suspends execution of a thread for a speciﬁc amount of time.
The time is expressed in either milliseconds or milliseconds plus nanoseconds.
In other words, this method takes either one or two arguments.
In the ﬁrst case, the argument is a time interval expressed in milliseconds while in the second case it is a time interval expressed in nanoseconds (milliseconds plus nanoseconds)
Note that where there is one “*” it is followed by either two or three “+” symbols.
Figure 7.2 Creating a threaded application by using trait Runnable.
As is evident, the body of the class is not modiﬁed, but now we have to start each thread using a different sequence of commands.
In particular, we ﬁrst create two instances of class PrintProgressMark and then we allocate new Thread objects.
Also, it is possible to name a thread by supplying a string variable as the second argument of this class constructor.
In both examples presented so far the two threads do not interact.
In fact, even if we add one or two or even more threads, nothing will change the essence of our application.
However, things will get really interesting if two or more threads have.
For example, how should we handle two or more threads that share memory cells? In other words, how can we ensure that memory cells are not accessed simultaneously, to prevent data corruption? This and other similar problems have made the need for synchronization vital.
In order to show how synchronization works, we will present a relatively simple example – two threads that continuously update a memory cell like the one presented in Section 2.3.1 In particular, assume that we deﬁne two threads where the ﬁrst halves the contents of a cell while the second doubles the contents of the same cell.
Then the question is how can we prevent the two threads from modifying the cell’s value at the same time? The answer is shown in Figure 7.3
In order to explain how these methods work, we need to say a few things about synchronization in general.
First of all, each method must acquire a lock on the object in order to ensure that its contents are accessed by one thread at a time.
Class AnyRef deﬁnes method synchronized, which should be used to acquire a lock on the object.
This can be done by replacing the code of a method with a call to.
A similar example was presented by Ted Neward in his article entitled “Explore Scala concurrency,”which is part of his “Busy Java developer’s guide to Scala” series of articles.
These articles are included in the technical library section of Java technology’s part of IBM’s developerWorks web pages.
In fact, this and its companion article entitled “Dive deeper into Scala concurrency” are excellent additional reading.
In the code shown in Figure 7.3 we did exactly this.
A method may take as argument a block expression, that is, a sequence of commands and a ﬁnal expression surrounded by curly brackets.
When a lock is acquired on an object, this has to be temporary in order to allow other threads to acquire a lock.
In other words, the execution of two synchronized threads must be mutually exclusive.
Each thread owns its own locks and so it is not possible to have nested locks, that is, a synchronized method that is called from another synchronized method cannot block execution.
Although locking prevents threads from interfering with each other, still we need to have a procedure to communicate between threads.
In the example of Figure 7.3 we have used a standard pattern that uses methods wait and notifyAll (or just notify)
The ﬁrst method may take as argument either a long integer or a long integer and a simple integer, or it may take no arguments.
In all cases this method causes the current thread towait until another thread invokes eithermethod notify ormethod notifyAll for this object, or if it is speciﬁedwith arguments, to wait until a speciﬁed amount of time has elapsed.
The amount of time is expressed in either milliseconds or milliseconds plus nanoseconds.
Methods notify and notifyAll wake up either a single thread or all the threads that are waiting on an object’smonitor, correspondingly.
Naturally, there are many more details about monitors, but a full treatment of all these details is beyond the scope of this book.
The interested reader should consult a more specialized book (for example, see [47])
But let us return to the description of the standard pattern.
A thread that is waiting should always execute a method that has to look like the following one:
The body of the method is synchronized in order to ensure, among other things, that once the condition becomes true it will remain so, at least until the method ﬁnishes.
In addition, when the condition becomes true, the lock is automatically released.
Finally, we are using a repetition construct because nothing guarantees that once a thread has been awakened the condition will become true.
Since our code handles both reading and writing requests, we need to notify waiting threads that our methods have completed their task when they have done so.
The deﬁnition of the skeleton method that follows shows what should be done:
In code that involves many threads, one should use method notify only if one knows exactly what one is doing.
In all other cases, it is advisable to use notifyAll.
In the code shown in Figure 7.3 we use two boolean variables that control the lock of each method.
In this particular example, reading is the operation that is most readily available and this is the reason we have given to the two boolean variables the corresponding values.
Now that we have deﬁned our synchronized cell class, let us ﬁrst deﬁne a class that reads the number stored in the cell and halves it:
By uncommenting the commented commands, the user can see the values received and dispatched by a thread that runs an instance of this class.
The code that doubles the number stored in the cell follows:
This is necessary in order to avoid a situation that is known as a deadlock.
In simple terms, a deadlock is a situation where there are two threads and each one waits for the other to complete in order to get a lock.
Since neither thread can get a lock, neither one will be able to run.
The following code completes our example and shows how the classes just presented can be used:
Exercise 7.2 Verify that by changing the body of method run of class halveCell as follows.
Threads have been used extensively in applets that draw images or include animations.
So the next step is to present such a usage example.
The term animation refers to the rapid display of a sequence of images to create an illusion of movement.
For instance, a full-blown feature-length movie and a simple animated GIF graphics ﬁle are examples of animation.
Fortunately, with Scala we can do things that are better than a simple animated GIF but, on the other hand, it is not practical to try to produce a movie with Scala.
In practical terms, Scala can be used to produce animations that are portable (for example, web-based applets or stand-alone programs)
In this section we describe some thread-based animation techniques and apply them to create Scala applets only.
Readers can use the same animation techniques to create stand-alone Scala programs.
Animation in Scala should always occur in a separate thread of execution.
This way, users can interact with the animation program without perceptibly degrading performance.
In practice, all we have to do is to mix in a module that extends.
Then we deﬁne a thread variable that is started by method start and stopped by method stop.
Method init is used to set up the graphical context.
In order to demonstrate the animation techniques, we will show how to design an applet that will show a black line on which a yellow ball moves continuously from one edge of the line to the other.
Figure 7.4 shows the skeleton of an applet that implements the required functionality.
The ﬁrst four variables correspond to the coordinates of the starting.
There is also a variable that holds the current x-coordinate of the yellow bullet.
The code that follows is the body of method paintComponent:
As should be obvious, the method draws a black line and then a yellow bullet.
In other words, the line is drawn every time the bullet changes position.
Figure 7.5 shows the deﬁnitions of methods start and stop.
Method run, which is shown in Figure 7.6, is actually the one that controls the animation.
Method run checks whether the thread is alive and if it is, it paints the bullet and then computes the next position of the bullet.
By increasing or decreasing the time the thread sleeps, the animation becomes slower or faster, respectively.
An annoying side effect in animations of the kind presented here is screen ﬂicker.
This phenomenon is more common on cathode ray tube (CRT) based computer screens while it is not completely alien on liquid crystal displays (LCD)
Nevertheless, presenting a solution to this “problem” has as a side effect the demonstration of the generation of off-screen drawings.
The reason is that screen ﬂicker happens when cleaning the drawing area just before any new drawing operations are performed.
Thus, to avoid this we create the image off-screen and when it is ﬁnished we replace the existing image with the new one.
To create an off-screen image one needs to invoke the drawing component’s createImage method.
These numbers correspond to the width and the height of the drawing area.
One can invoke this object’s getGraphicsmethod to get the image’s graphics context.
If we want to modify the code of the previous applet to draw using off-screen graphics, we ﬁrst need to declare some additional variables:
The last expression is necessary to inform all threads that all graphics operations have been completed.
In addition, this expression overrides all relevant notiﬁcations that are automatically “broadcasted” by all relevant components.
The code of method init concludes now with the following commands:
The last difference between the code of this applet and that of the old one is in method run:
As is evident, the only difference is that the method waits until the off-screen drawing is ready.
Package scala.concurrent provides an abstraction layer over the “traditional” concurrency constructs that have been described so far.
Needless to say, these “traditional” concurrency constructs are Java’s legacy to Scala programmers!
A mailbox is a convenient mechanism that allows values to be passed from one object to another.
Essentially, it is a mechanism that follows the spirit of objectorientation (i.e., the passing of messages between objects)
A typical example of this value-passing procedure has been presented in Section 7.1
There we used locks to establish the synchronous passing of values from one object to another.
In order to do the same thing with mailboxes, we need to deﬁne an instance of class MailBoxwhich must be accompanied by two auxiliary classes.
Class MailBox deﬁnes three methods – receive, receiveWithin, and send.
The ﬁrst method takes as argument a partial function which is used to evaluate any message that is delivered to the mailbox.
However, the effect of the method is to wait until a message is delivered.
Since one cannot always be sure whether a message will be actually delivered,method receiveWithin has been designed as the equivalent of receive that waits for a certain amount of time and not for ever.
Thismethod takes two arguments: an integer, which denotes the amount of time it has to wait, and a.
Roughly, method send places the message to be sent in a mailqueue if the receiver is not available; otherwise, the message is delivered to a mailbox.
The auxiliary classes play two different roles – one denotes that the mailbox is empty and the other denotes that the mailbox is not empty.
Typically, these two cases can be covered by deﬁnitions like those that follow:
Figure 7.7 shows how one could rewrite class cell using mailboxes.
Initially, we need to drop to the mailbox the value by which the class will be instantiated.
When method get receives a Nonemptymessage, then it replaces the message with an Empty message and returns the value received.
This means that there are two kinds of messages that correspond to the states of a mailbox (i.e., being empty or nonempty)
Similarly, when the mailbox receives the empty message (i.e., when it is empty), a full message should be dropped to the mailbox.
This is exactly what method set describes and the content of the message is the only argument of the method.
If we replace class cell of Section 7.1 with the one presented here, then.
Figure 7.7 Class cell rewritten in a message passing style.
However, it makes no sense to use threads directly in some parts of the code and to hide their usage in others.
Thus, we will replace all direct uses of threads with other higher level constructs.
Module concurrent.ops deﬁnes method spawn which is deﬁned as follows:
This means that one can delete the deﬁnition of classes doubleCell and halveCell and replace them with calls to method spawn with arguments the body of each class.
In particular, class doubleCell can be replaced by the following method invocation:
Exercise 7.4 Complete the transformation of our simple application by replacing the deﬁnition of class halveCell with an invocation of method spawn.
Uncomment the output commands and verify that the output generated by the initial application is comparable with the output generated by the application described in this section.
Programming project 7.1 Try to reimplement spawn using the Executor trait.
The actor model of concurrent computation has its roots in ideas that have been put forth by Carl Hewitt, Peter Bishop, and Richard Steiger [33]
Important milestones in the development of the theory include the work done byWilliam Douglas.
Thus, the inclusion of actors into the Scala programming language was a wise decision.
Each actor has a unique mail address and a sufﬁciently large mailbox, where messages appear in order of arrival.
In addition, each actor is characterized by its behavior, which is a function of actions to be taken for incoming communication.
In the simplest case, we can construct an actor by calling method actor of package scala.actor.
In fact, we have used this procedure to construct an actor in Section 6.9
What we did not say there is that as soon as an actor is constructed, it starts operating as if a new thread has been started.
Note that the number literal “2” is there since othewise Scala will complain that.
Remember that the curly brackets delimit a block expression that must end with something that is not a deﬁnition or a declaration.
Alternatively, we can deﬁne a class that subclasses trait Actor:
Method act of trait Actor is deﬁned as abstract and this is why every class that subclasses class Actor must implement it.
Thus, the following code shows how to create and a start an instance of class PrintProgressMark:
Let us now show how to “translate” the thread-based animation applet, which was presented in Section 7.2, into an actor-based animation applet.
First of all, object ui must not subclass trait Runnable.
Next we need to deﬁne a “global” variable that will play the role of the animation thread:
The last thing we need to do is to redeﬁne method start as follows:
In other words, the code of method run becomes the argument of method Actor.actor.
The simple examples shown so far did not demonstrate the real capabilities of actors.
Nevertheless, we have included them to show how one can construct and start actors.
In the rest of this chapter we are going to discuss the real capabilities of actors.
The standard example of an interactive actor is the one where an actor receives messages (usually strings) and just prints them.
The following interaction with Scala’s interpreter shows how one can deﬁne and use such an actor:
Method receive, which is the most typical message handler, takes as argument a partial function.
Method ! sends asynchronously a message to the calling actor.
Assume that we want to create another actor that can handle many and different types of objects.
For example, function isNum (see page 106) could be used as a basis for the construction of such an actor.
Thus, we need to reprogram it so that it can receive and process messages repeatedly.
In particular, we can use method loop that takes as argument the body of an actor and puts it in an inﬁnite loop.
If we try the previous commands, we will get all the expected responses, but the program will not terminate since it waits for ever.
Thus, we need to decide when the actor will stop.
In our case we can stop whenever a nonnumber is sent.
This can be easily implemented by deﬁning a boolean variable to control the loop:
Here we have usedmethod loopWhilewhich takes as arguments a boolean expression and a series of commands.
As expected, this method executes the commands as long as the boolean expression is true.
Unfortunately, this is the price we have to pay for ﬁxing the previous problem.
On the other hand, we can inform the actor that a particular message is the last one so after processing it, the actor must terminate.
Since we want essentially to send the same messages, all we have to do is to send instances of a more complex message that will include the messages as before and a termination reminder.
The following code shows how we should rewrite the actor in order to be able to handle these new kinds of messages:
When this program is executed it will handle all cases and only then will it stop.
Method ! is not the only one that can be used to send messages.
In addition, method !! may get as argument a message plus a partial function which, in conjunction with the Future returned, can be used to postprocess what the actor returns.
In order to make clear what we mean, consider the following redeﬁnition of our lousy actor:
Of course our example is totally useless, but it shows what is involved.
Method reply is used to send back a message from an actor to its sender.
If everything an actor is doing is included in the body of the message handler, it is better to use react instead of receive since the former consumes far less resources.
The real use of futures is in what is called fork/join parallelism.
This is a parallel programming technique in which, as Douglas Lea notes, “problems are solved by (recursively) splitting them into subtasks that are solved in parallel, waiting for them to complete, and then composing results” [46]
The most typical application of fork/join parallelism is a parallel version of the merge sort algorithm.
However, in order to keep things simple we will describe a simpler example.
In order to compute the hundredth power of an integer we will use the following (simple) function:
If wewant to solve our problem in parallel,we need to ﬁnd away to compute powers in parallel.
For this purpose we create a list that will include all these subproblems, then it will ﬁre up all of them making them operate concurrently, and in the end it will sum up the results.
How can we implement this idea? Easy! The following code snippet shows how:
One may wonder what is the speed that is gained by this technique.
We have “benchmarked” our program by modifying the code snippet presented above as follows:
In other words, the parallel version is 2.33 times faster.
Method nanoTime measures time elapsed since the program has started.
Method !? is another method that can be used to send messages to actors.
Also, method ? can be used to get the next message from an actor’s mailbox.
If for some reason we want to refer to an actor inside its deﬁnition, we should use method self which returns the currently executing actor.
Hewitt [32] has presented anoniterative implementationof factorial in hisPLASMA notation,where PLASMA stands for PLAnner-like SystemModeled onActors.
However, one can achieve the same effect using actor replication (i.e., by creating new instances of an actor that solve particular subproblems) and message passing.
In order to use this class we need to deﬁne an actor that will create the ﬁrst instance of class Fact.
Now we can use this actor to compute the factorial of some number:
Exercise 7.6 Use this technique to implement a message-passing “algorithm” that computes the Fibonacci numbers.
So far it has been demonstrated how to use actor replication to compute the factorial of some number.
Clearly, the next logical question would be whether it is possible to use only message passing to compute the same value.
Not surprisingly, Hewitt [32] has shown that this is possible.
Indeed, Figure 7.10 shows the deﬁnition of an actor that can compute the factorial of any number.
The actor uses an accumulator to keep the result computed so far while it reduces a counter each.
Figure 7.10 A purely iterative actor that computes the factorial of some number.
The ﬁrst time the actor is used, we store the return address to a local variable which is used to deliver the result at the end of the computation.
This actor sends messages that are instances of the following case class:
The following actor is something like a front-end to the actor shown in Figure 7.10:
Again actor factorial can be used as in the previous example.
Exercise 7.7 Modify the actors presented to compute the Fibonacci numbers.
It is quite probable that most of us are not consciously aware of an ever-appearing design pattern, which goes far beyond the design patterns in the normal sense of [24]
This pattern has to do with how we organize our data and, sometimes as a consequence, how we access these data.
What we are talking about is the hierarchical data organization pattern that we can abbreviate in short as:Hierarchies are everywhere!
A ﬁle system is the canonical example of hierarchical organization.
The Unix tradition has more to say about ﬁles, since the ﬁle system “pattern” has been extended to support other use cases than the traditional ones.
For example, in Linux, /proc is a special mounted ﬁle system which can be used to view some kernel conﬁguration and parameters.
In fact, normal ﬁle system I/O calls can be used to write data into this special ﬁle system, so that kernel and driver parameters can be changed at runtime.
Strangely enough, hierarchical databases have not survived, but probably XML strikes back on their behalf.
They will be made more happy to recollect that the Registry existed even before XML.
The Windows Registry can well be viewed as a special ﬁle system.
Inmodern enterprise Java-based applications, JNDI (JavaNaming andDirectory Interface) provides an excellent abstraction for hierarchical organization of data.
With its support for multiple namespaces and pluggable namespace providers, its ﬂexibility has a foundational value: so much so, that many enterprise developers often ignore its full potential.
The module and packaging systems of modern programming languages are another perfect example.
For example, Java’s hierarchical packages ﬁt nicely into an underlying ﬁle system.
In fact,whenwe see a Java package name,we instantaneously know where to look in the ﬁle system.
A parser generator, like the legendary yacc by Stephen Curtis Johnson, takes as input the description of a programming language in a notation similar to EBNF.
A language grammar normally starts with a top-level nonterminal symbol and proceeds to depths of varying complexity.
This is clearly a hierarchical organization, at the deﬁnition site of a language.
At the processing site (at least for a compiler) or even at the execution site (i.e., for an interpreter), usually a program is represented by an Abstract Syntax Tree (AST)
So, hierarchies are everywhere and, as a consequence, ﬁle systems are everywhere.
A fundamental notion in every hierarchical organization is that of a path.
We use paths to designate where in the hierarchy something resides.
Paths are naturally composed to create larger paths and can be deconstructed to simpler parts as well.
In the following, we are inspired by the utility of paths in order to model them in Scala.
In our discussion we use ﬁles to motivate things, since they are the foremost “client” of paths.
Unfortunately, but not uncommonly, these representations vary across different implementations.
The normal barrier between these implementations is the operating system.
For example, while for a hierarchical representation there exists the common notion of a root point, the possible ﬁle system roots vary.
Also, another striking difference is the separation of a child-path from its parent.
It is common knowledge and already evident from the above that / applies to Unix and \ applies to Windows.
Apart from Windows, the Samba software stack also uses it to represent network resource names.
Even before bothering with the previous incompatibilities, we should ask ourselves why model paths? After all, java.io.File handles all the underlying platform “difﬁculties” and can transform the paths correctly even if we are not in the “correct” platform.
The following simple example, which was run under Windows in order to get the C drive as the ﬁle system root, reveals this fact:
The truth is that File models two concepts with just one implementation.
The ﬁrst one is the ﬁle path and the second is the ﬁle itself.
We would like to separate the two concepts, so that they can be combined later only when necessary.
We want to elevate the path to a ﬁrst-class entity.
There must already be a lot of source code lines that just concatenate strings to create relative paths:
The example above demonstrates some string concatenation to obtain the directory where the local copy of a maven-managed library resides (Apache Maven is a software project management and comprehension tool)
So how exactly do we expect to handle paths and what requirements do we wish to impose on a Path API? Which should be our guiding principles for the design? It seems logical to assume that paths should be.
By typefull, we mean that it is best to avoid using plain strings.
Even if the lowlevel representation that either makes more sense or seems more obvious than the others is the String, do not expose strings at the user level directly.
Clearly, our codemust be behaviorally equivalent, nomatter what the underlying running environment is.
Although running under the JVM certainly gives a sense of uniformity, the JVM itself has to communicate with the operating system at some point.
There is the “opportunity” for an API to break and we actually need our path API to be platform independent.
In an epoch where the need for and fuss about concurrency constantly increases, designing with immutability in mind can be an asset for a software engineer.
If your object has no complex business logic and simple state, consider adopting an immutable implementation.
Also, in addition to the above, we would like the String representation of the paths to be normalized, especially when it comes to the appearance of (back)slashes.
Only the / character will be the separator of path elements.
More than one consecutive occurrence of / will be collapsed to just one /
The second requirement will be relaxed for the beginning of UNC paths and our convention is that in their normalized form they start with two slashes.
A ﬁrst-cut, reasonable API for paths is given in Figure 8.1
We just follow here the convention of the java.io.File API where the related method, following the JavaBeans convention, is getName.
Figure 8.1 A path API given as a trait with partial implementation.
The two methods with this name are the means to compose paths.
The Path(_) factory call is made on the companion object, which we will start implementing shortly.
Notice also howwe have implemented isRelative and isAbsolute bymutual recursion.
A subclass of Path is expected to provide an alternative implementation for one of them, whichever is more suitable for the particular case.
Empty paths play a special role and are represented by EmptyPath in Figure 8.2
They arise when, for example, we ask for the parent of a root path.
Also, when composing any path with EmptyPath, the latter is absorbed and the net result is the former.
From Figure 8.2, there is one point in the implementation of EmptyPath that we have not deﬁned yet, and it is the call Path(that) in method /(that: String)
We have already met Path in the deﬁnition of the main trait but we need to present a few more implementation bits before delving into the Path object.
One could say that they adhere to the canonical design.
There is only one root and one type of absolute path, so the implementation is rather straightforward and is shown in Figure 8.3
We are somewhat careful with the implementation of methods parent and paths.
Regarding parent, when the path is the root (/) then, as discussed previously, we get the EmptyPath.
For all other cases, we must check where the last / resides.
This is clearly the case, since if / is at zero index, then the path is in the form /somePath.
First, we split the full name into parts, using / as the separator.
We must keep in mind that split returns an array, so the transformation to a list is necessary.
Then, we need to take care of the special nature of /
If we split the string "/usr/bin" according to the same rule, then the result will contain an empty string at the beginning of the generated array:
Unfortunately, the three string parts in the generated array, do not correctly represent paths.
Just to remedy the situation, we resort to a simple transformation, the one shown above, via the higher-order function map.
As a ﬁnal note regarding the implementation of UnixPath, the composition methods.
Windows paths are a bit more complicated because of their variety.
In order to relate UNCPath and DriveAbsPath, we deﬁne a subclass of Path.
Exercise 8.1 Under Windows and to the best of our knowledge, there are two more cases one has to consider.
In particular, there are directory relative paths, which are in the form \somePath and drive relative paths that look like C:somePath.
Notice the missing drive letter in the former case and the missing backslash in the latter case.
After studying the implementations we give for the path types mentioned above, implement these two missing path types.
If we would like to reuse the implementation of UnixPaths for simple (relative) Windows paths, of course we need to take care of the slash-backslash difference.
For that reason, we will for now assume and later show how to implement our paths in some normalized form, where only forward slashes appear.
There is actually no pragmatic problem with this approach, since we can easily verify that java.io.File under Windows, when given a path with forward slashes, will properly handle it as if they were backslashes:
Notice the automatic transformation of / to \ in the above interactive session, performed on a Windows machine.
As in UnixPath, the most interesting methods are parent and parts.
For example, parent has to see where exactly the last / resides and break the path string representation accordingly.
Also, parts checks whether the UNCPath just represents "//", in which case it is just a root.
We consider an UNCPath to be a root path if and only if the length of its string representation equals two.
Notice howwe follow the general rule of normalized paths, according to which slashes are the sole path separators, regardless of the underlying platform.
Drive absolute paths are implemented using DriveAbsPath in Figure 8.5
If it is exactly three characters long, then it is a root path:
The deﬁnition of parent follows the same philosophy as previously.
It is time to work out the implementation of the Path companion object.
Every Java Virtual Machine deﬁnes the "os.name" system property and under Windows its lowercase transformation contains the value "windows".2 We use this piece of information to recognize the underlying operating system.
Also, we will obviously use isDriveLetter for paths under Windows.
Lowercase here is usual practice when a programmer does not exactly remember the speciﬁcation and just needs to be sure.
The other methods are checks that decide whether a character is a slash or backslash.
The last one, getSlashF is actually a method that returns a function.
We can discover the exact type by using the interpreter:
This just means that the result of getSlashF is a function from Char to Boolean values.
The ﬁrst parentheses, (Boolean), mean of course that getSlashF takes one Boolean parameter.
Question 8.1 If, in the above interpreter session, we issue the command:
But what is the purpose of getSlashF? The implementation clearly shows that it selects the proper check for a forward slash or backslash character.
In the ﬁrst case, which happens if and only if the input parameter is true, isAnySlash is selected as the slash check.
Here, we use the term “slash” in its generalized meaning, so it may be either a forward slash or a backslash.
In the second case, isSlash is selected as the slash check.
As we will see shortly, under Windows any slash, either a forward one or a backslash, counts as a path separator.
Under Unix, the (forward) slash character is the only separator.
Did you know that in Unix, this funny \/ directory can be created?
The / part has been “created” by the F switch in ls -alF.
Since our path string representation is going to be normalized, we will need two more utility methods:
Instead of searching via a while loop and decreasing a var, which is a mutating operation, we use a helper method that counts down until either it reaches the beginning of the input string or it ﬁnds the ﬁrst nonslash character.
No state is mutated and counting down is achieved via selective subtraction.
In such cases, coding style is a matter of taste and heritage.
A programmer coming from an object-oriented background may directly resort to the ﬁrst version.
Yet, for such a programmer, it may be a great opportunity to start thinking in a different style.
What we do here is to track the place where we see a slash, remember consecutive slash positions and collapse consecutive slashes to one /
The heart of the Path object is its apply method:
It simply consults the value of isWindows, in order to call the appropriate algorithm that will build a normalized path out of a string value.
Of the two algorithms, parseUnixPath is, as expected, the most straightforward one:
The details are shown in Figure 8.6 and we analyze them brieﬂy.
For the life of a call to parseWinPath, we always use true as the value to anySlash, since under Windows we assume that both / and \ are separators for.
The initial decision-making procedure is around the length of the input string.
If the length is just one, then we delegate to parseSimplePath.
Otherwise, meaning that the string is at least two characters long, we must see the exact character value at the initial positions.
If the ﬁrst two characters are slashes, then an UNCPath is parsed.
Otherwise, if the length is at least three characters, such that the initial three characters form an absolute drive designator in the form #:\, then an AbsDrivePath is parsed.
Question 8.2 Can you spot the reason why we need to treat the input string specially?
So far, the Path factory can handle any underlying operating system curiosities by selectively calling the appropriate internal method, either parseWinPath or parseUnixPath.
But since the UnixPath implementation is the canonical one and a great deal of applications would expect to use paths outside their dominant environment, that is the ﬁle system, we provide one more factory method:
We are in effect saving a platform-speciﬁc decision, stating that the default Path implementation is that of UnixPath.
The advantage of the new addition is that it gives us the opportunity to construct a UnixPath directly, if we know a priori that the semantics of the client code require that kind of construction and nothing more elaborate that would engage platform-speciﬁc decisions.
The interpreter session demonstrates that the path of a URI may start with a /
Let us assume that some client code manipulates the path part of a URI, translating it to an absolute path using a simple string concatenation.
But now remember thatwe are underWindows,our library has created an UNCPath, since uri.getPath already starts with a /
The above example is simple but the same simple, or rather innocent, thinking can lead to bugs.
And if it can, then according toMurphy’s Law it most certainlywill.
We always have to think of the path semantics we need when transforming strings to paths.
The introduction of the UnixPath factory gives us one more alternative to take into account.
The truth is that there is a particular piece of code that has been repeated in a few places without any attempt on our part to factor it out in some trait.
In all other cases, we simply concatenate the full names using the normal / separator.
It is obvious that for all Path subclasses we have chosen the full path name as the main representation.
The ﬁrst string is “caught” by string2path and converted to a Path.
After that, a normal call on method / of the newly created Path is issued.
We can even go a bit further and save one keystroke per path part:
Shouldn’t the two paths be equal? Well, the answer lies implicitly in our choice of words.
Speciﬁcally, we are talking about paths but are we really dealing with paths here? A little more experimentation will provide us with the needed answers:
So, a is a Path but b is a String and they cannot be equal, according to our deﬁnition of the equals method in Figure 8.1
The bottom line is that keeping in mind the types will make it a lot easier to reason about the values.
If we had spotted that the path combination operator / produces values of type Path but "/usr/bin" is just a String, then everything would seem quite normal in the ﬁrst place.
The compositional nature of paths should be more than evident right now.
Thanks to the expressiveness of the Scala language, we have been able to deﬁne a special operator, /, that composes two paths and gives another path as the result.
This operation of combining two objects and producing a third object of the same kind is ubiquitous, especially in mathematics: we can add, subtract,multiply real numbers.
In Scala we can even deﬁne complex numbers that can behave like real numbers in writing algorithms with arithmetic operations such as the ones mentioned above.
Another characteristic of the composition is that just as with high-school algebra.
This very property of associativity alone is a rather important one and deserves special credit.
Informally, a semigroup is a collection of objects and an associative binary operation that we use to combine these objects.
A binary operation takes two objects of the same kind and produces a third object of the same kind.
Remember that a semigroup is a collection of objects with some associative operation.
The key phrase here is collection of objects: the deﬁnition of SemigroupOther clearly represents just one of these objects, since in compose only the second object is passed as a parameter, while the ﬁrst is none other than the object-oriented this.
We could have adopted the second deﬁnition, in addition to the ﬁrst one, renaming it properly and providing some extra machinery that does the actual work:
Then an object of type A belonging to a semigroup can mix in IamInASemigroup[A] and the composition is achieved by providing an extra parameter, the actual semigroup.
The careful reader might already be thinking that only relative paths guarantee that their combination will not fail.
But Scala can be more expressive than that, if we desire so.
Let us say we have several predeﬁned types of semigroups that we want to be used implicitly, instead of explicitly passing them around as parameters:
The compose operation may also be seen as append, as in the Haskell libraries or Scalaz, a library with a wealth of abstractions currently missing from the ofﬁcial Scala distribution.
Returning to our paths, the relevant semigroup can be coded as.
Now the interesting design question arises: Should we have thought about it at the beginning and provided the actual implementation of combine inside PathSemigroup instead of the companion Path object? Well, yes! This is the essence of algebraic thinking : to start thinking about the structure of our objects (paths in this respect)
The word structure here means the way our objects are organized and how their organization is revealed by the permitted operations.
The structure of a semigroup, as expressed by the needed associative operation, is a minimal one.
Several other, more complicated “things” can be built on it or independent of it, if we wish to be precise about the meaning of our words.
In our implementation of paths, there is one particular path that stands out.
Let us again take a look at Figure 8.2 and consider the role of EmptyPath:
We say the identity and not just an identity, because it can be proved that there is only one object with this particular property.
Now we are ready for the introduction of another algebraic structure.
For example, the integers with addition as the binary operation form a monoid and the identity is the number zero.
For integers with multiplication, the identity is the number one.
Paths form a monoid with EmptyPath as the identity path.
Alternatively, we can make a standalone deﬁnition for an identity abstraction.
Continuing our investigations on path territory in Chapter 8, the natural evolution is to touch some of the actual ﬁle abstraction.
As a historical note, complete operating systems have been built based on this abstraction, Plan 9 being one that used it quite extensively.
Throughout the book,we are using ﬁles as they are deﬁned and implemented by a standard Java Development Kit distribution for an obvious reason: they use a pragmatic approach and at the same time make a very successful utility for everyday programming.
In this chapter, we will try to tickle a few of our brian neurons around this design.
The java.io.file class of the Java platform already provides a ﬁle abstraction, via the java.io.File class.
Despite the ofﬁcial online documentation, which states that File is.
The most common mapping of paths to underlying system resources is that related to native ﬁles.
So, we will develop here a small library for accessing ﬁles.
But, instead of just providing a Scala wrapper around Java’s File, we will abstract away common operations.
The goal is for the design to accommodate not only the native ﬁle system but also a variety of other virtual ﬁle systems.
For brevity, from now on we will use the term VFS to denote a Virtual File System.
Accordingly, the term VFile will denote a virtual ﬁle for some particular VFS.
Interestingly, the VFS notion and accompanying terminology is nowadays ubiquitous in operating systems.
Our basic notions are those of the ﬁle system (VFS) and the type of ﬁles (VFile) a ﬁle system supports.
For example, in Java the native ﬁle system is implicitly assumed by the java.io.File, which plays the role of a VFile.
Of course, there will be some connection – and we will shortly propose a plausible connection – but the design should reﬂect the fact that each one of the two serves a semantically distinct role.
The details of this medium may well constrain the way the respective VFiles function or the operations that they support.
When a VFS is attached (or mounted in Unix parlance) to the system in read-only mode, then it is not possible to modify any ﬁle contained in it.
Having the storage medium as the starting point, a VFile, on the other hand, is a provided entity.
We expect that operations that deal directly with the underlying medium will be delegated to appropriate functionality in the VFS.
From the above discussion, one might go ahead and model a VFile as a VFSdependent entity, reﬂecting this directly in the relevant type:
But the truth is that although we clearly expect a VFS to play a fundamental role in the implementation, the most important user-viewable entity is that of a VFile.
So, we express a VFS in terms of what it provides:
Althoughwe intend to give a quite usable implementation, programming a full-ﬂedged library is not our goal.
Separation of concerns and type safety are certainly on the agenda.
We achieve the ﬁrst by the essential separation and, for what it is worth, the explicit representation of VFS and VFiles.
This is in contrast to the native Java API which blurs the distinction of a ﬁle system that implicitly exists and a native-only ﬁle abstraction.
As far as type safety is concerned, as shown above,we expect that eachVFS type is related to a particularVFile type.
Thus,VFS types are separated by what kind of ﬁles they provide.
Generally, VFiles from different VFSs will not be compatible, unless of course they can be considered as such for the sake of generality.
Just to give a practical example, let us assume that all the lower-level details of how we read bytes from and how we write bytes to a ﬁle are properly implemented.
Then, providing a generic ﬁle copy operationwhere the source and target ﬁles cross theVFS boundary is not only legitimate but also desirable, at least as a ﬁrst approximation.
We say “as a ﬁrst approximation” because lower-level implementation details of a ﬁle system may demand a more ad hoc approach.
In the following sections, we present our API and explain the rationale and expectations of the deﬁned operations.
Notice the declared type, in the spirit of our previous discussion:
Of course,VFS[T <: VFile[T]] seems a bitmore complicated than VFS[VFile] but we will come to that in detail after we present the VFile API.
This may sound unnecessary in that we could always directly call the path constructor Path(_), thus letting our path library handle the different underlying operating system (OS) semantics.
But we aremissing one point here: Path(_) can surely handle the OS semantics, although now we are one design layer above that.
Our interest, having resolved the path issues, has shifted to some other functionality on top of the provided one.
For this particular reason, it is wise to anticipate new semantics for the extra design layer.
Here, we borrow the idea from ﬁle systems that have more than one root point.
The accompanying root method just returns the zero-indexed root, which by convention we can call the default one.
If all those places can be captured by the ideas developed in this chapter, then we can expect that a nested VFS exists within some generic ﬁle, its.
The underscore in VFile[_]means that we do not actually care about the exact type.
At any particular moment, where we use it, it is some type and in Scala it is called an existential type.
Just because we do not name this type, we cannot explicitly reuse it.
The conceptually derived method isContained is implemented using container by checking the returned Option value.
Only the VFS knows what its ﬁles look like and how they behave, so the VFS is the canonical ﬁle factory.
We need to make one comment on the method though.
The semantics of whether the method actually creates a new ﬁle at the underlying storage medium or whether it just creates a virtual representation of such a ﬁle (a ﬁle-to-be) are up to the particular VFS implementation.
For some VFSs it might be more relevant to return ﬁles that only exist, while for others new ﬁles are returned at will, independently of their existence.
Notice how we have two overloaded methods, one taking a Path as input type and a second taking a String.
We have introduced the second one because of a design choice we made in the Path implementation.
If only the version of newFile with the Path input parameter existed, then every client use of newFile with a string, as in.
This way we would lose the opportunity to let the VFS construct the path, using mkpath, which is exactly what the implementation of newFile with a String parameter does:
Although for the moment we do not distinguish programmatically between a ﬁle and a folder, we have two dimensions to consider:
If it does not exist, then the method returns None.
In the VFS trait, we have chosen to give a default implementation where contains is based on resolve but speciﬁc implementations may choose to override the deﬁnitions and express the relationship in the opposite direction.
Overall, we have factorymethods for paths and ﬁles, discoverymethods that provide a ﬁle only when it can be resolved in the underlying storage, and informational methods about the root structure of the ﬁle system.
Under Windows, for example, the native ﬁle system has more than one root point.
Let us now turn our attention to the VFile API, shown in Figure 9.2
The latter is the default implementation we give later regarding a native ﬁle system.
This method should not attempt to do any transformation to a native ﬁle.
Instead, it should wrap an existing NativeFile instance to an Option.
It provides a convenient utility when the client code either knows it manipulates native ﬁles or this has been determined by a call to isNative.
Each virtual ﬁle returned is described by its complete path, that is its path includes its parent.
The main difference is that we do not return an array or list but rather an Iterable.
This is in accordance with usual practice, where we just iterate over the children of some folder and do whatever actions during the iteration step.
Implementations are free to compute the names either using children directly.
This returns a newVFile whose path is the path of this VFile composed with the given argument.
Of course, for folders, the return value is expected to be None.
Note also that the equalitymethod is crafted so that onlyVFiles of exactly the same class and with the same paths are considered equal.
Under these two assumptions, it could have been written as.
Question 9.1 Why use the cast AnyRef in the above use of asInstanceOf?
But this approach or the one in Figure 9.2, are just simple proposals.
For example, with both, we are ruling out cases where subclasses might have to participate in the equality relation.
The three most important properties that the equals contract should have are reﬂexivity, symmetry and transitivity.
Properly implementing the required contract of equals, which according to Java also affects the implementation of hashCode, can be tricky but not impossible [59]
Now that we have deﬁned our basic concepts, let us look a little more closely at the exact types of VFS and VFile:
First of all, the type of VFS is a consequence of the type of VFile.
For example, we could not have written just VFile[T] for any T, since T has to be a subtype of any type a VFile has.
On the other hand, the type of VFile is deﬁned somewhat recursively.
The actual expected type of a virtual ﬁle is the T parameter, as we can see from the declaration self: T =>, where this is constrained to have type T.
As in the case of VFS, T is a subtype of VFile[T]
Let us sit back a little and think what we can do with such a kind of deﬁnition.
How could we investigate such a case? Obviously, since ultimately a VFile will be represented by some concrete class, the type T will need to be ﬁxed to something concrete too.
So, we seek a known type ConcreteFile for a concrete VFile implementation with the following properties:
As far as the ﬁrst property is concerned, a concrete implementation class ConcreteFile obviously gives to this a type of the same name.
Now, the second property dictates that the concrete ﬁle must be a subtype of VFile, so by literally translating into pseudocode, we arrive at.
But we have already established that ConcreteFile <: VFile because of the extends keyword.
So # must actually be the same as ConcreteFile itself and the complete deﬁnition reads.
By this type handling,wemake sure that the exact type of a VFile is present at the parent trait right from the beginning andproperly respected in any descendant.
This holds as long as we adhere to the convention of deﬁning concrete implementation in the way we have shown for ConcreteFile.
We now proceed to implementing some very useful ﬁle systems and their corresponding ﬁles.
The ﬁrst implementation, as expected, is that of the native ﬁle system.
The relevant VFS-descendant is shown in Figure 9.3 where we can see that we have aliased java.io.File with JavaFile.
This is a price to pay for the heavy semantics the method bears, anyway.
Representing it as a singleton seems a reasonable choice, although there are other use-cases where a singleton-based design might not be the most appropriate.
Question 9.2 Can you think of a case where it would be preferable to implement a native ﬁle system using multiple class instances instead of a singleton instance?
This composes the paths and gives a new ﬁle.We take advantage of the path / operator.
Note that the method checks to see whether we indeed have a ﬁle and not a folder.
As in the case of inputStream it is always the caller’s responsibility to close this stream when it is no longer needed.
An array of abstract pathnames denoting the ﬁles and directories in the directory denoted by this abstract pathname.
The array will be empty if the directory is empty.
Returns null if this abstract pathname does not denote a directory, or if an I/O error occurs.
So, we map a possible null value to Scala’s Array(), which is the empty array constructor.
Of course, all the needed types, for example the type for the Array() constructor, are inferred by the scala compiler.
There is an extra method in NativeFile that does not exist in VFile: nativeJavaFile.
It returns the underlying java.io.File as a convenience to client code that might need it.
For example, just to name a few missing cases, currently there is no provision for actually creating the native resource related to a folder.
There is also no provision for deleting the underlying ﬁle at the operating system level.
Programming project 9.1 Try to make the API more complete, exposing as much functionality as possible from the Java APIs.
The ultimate goal is not to have to expose Java APIs anymore, as we did with the nativeJavaFile method.
It is not mandatory that each Java method should be translated to an exact method in the new API.
After all, the java.io.File API leaves a lot to be desired from a design perspective.
Just to get an idea of how poor it is, the delete method mentioned above returns just a Boolean to indicate success or failure.
It would be better for the user to get some idea of what exactly is going on in the case of failure, for example an exception might be more indicative of the execution status.
We now turn our attention to another implementation: a ﬁle system that resides completely in memory.
But why would such an implementation be useful? The obvious reason is efﬁciency.
If anything is kept in memory, then I/O operation becomes signiﬁcantly faster.
It may not be uncommon that under certain conditions, an application does not have access to the native storage.
For example, applets (see secion 6.11) usually run under a restricted environment in the context of a web browser and they are not given access to the client disks.
Last, but not least, a very good reason for a hacker is curiosity.
If we have a VFS abstraction, how far can we go playing with it?
A compiler also presents a use case where a memory ﬁle system can be handy and in fact the Scala compiler uses some internal abstractions that enable it to work with in-memory ﬁles.
Also, in today’s highly dynamic JVM programming environments it is not uncommon to generate classes on-the-ﬂy and then instantly load them in the space of an application.
That instant loading can be achieved by using amemory ﬁle system.
It is evident from a walk-through of Figure 9.6 that we will need two separate abstractions forVFiles.A MemoryFile represents a ﬁle and a MemoryFolder represents an in-memory container of other MemoryFiles and MemoryFolders.
As we will see shortly, both MemoryFile and MemoryFolder are derived from a parent trait, MemFile.
Note that we use a val declaration in the constructor, so that this ﬁeld is visible outside the class.
MemRoot This is a value representing the sole root of the ﬁle system.
The design we have adopted favors storing full paths for all the ﬁles and folders of the in-memory ﬁle system.
But how then is the hierarchical nature of a VFS going to emerge? The.
Since we know the full names of all ﬁles, for each parent folder we can compute the contained children.
Instead of feeding the Path factory with the bare path name, we prepend a /
The reason is that, by our convention, an in-memory ﬁle path has to be an absolute one.
Regarding the path semantics we follow for this implementation, it is clear from the use of the UnixPath factory that we use the canonical path representation introduced in Section 8.6.3
Since this is common to all instances of MemFS, it would be a good idea to refactor it into some singleton object.
Exercise 9.2 Can you spot the error? Provide a better implementation.
Hint: The fact that one asks for a newFolder and the cache already contains some mapping with the same path does not necessarily mean that the contained mapping refers to a folder and not a ﬁle.
Also do not forget to update the cache if needed.
The same semantics as with newFile hold here as well.
The sole purpose of MemFile is to provide the method combinedwhich takes care of path composition.
The details, although easy to follow, are a bit more complex than what we have usually seen.
First, memory ﬁles and folders are separate entities and this is reﬂected by the particular memory ﬁle system implementation.
Second, we need a way to inform our MemFSAPI that, given a String which represents a path, the requestedVFile is a ﬁle or folder.
If its value is true, the API understands that the client code means folder instead of ﬁle.
Each MemoryFile is backed by an array of bytes for its storage.
This array, bytes, is mutable, since we need to update every time client code appends bytes to the ﬁle.
The most notable methods of MemoryFile are those regarding the input and output streams.
Creating an input stream is merely constructing a new byte array input stream.
Creating an output stream is just a bit more involved, since we need to update the underlying byte array when the stream is closed.
Of course, closing the stream is solely a responsibility of client code.
The method that returns the children contained in the folder.
The requirement for ischildOf is that it must return true if the current path (this) is a path contained in the immediate children hierarchy of the passed argument.
Exercise 9.3 Make an incremental modiﬁcation to the deﬁnition of Path and implement isChildOf.
Exercise 9.4 Redesign MemFS so that cache is not needed as it is.
Instead, take a hierarchical approach, where each MemoryFolder directly stores its children, so that information is kept in a more local manner.
We now develop aVFS implementation for zip (and jar) ﬁles.
Actually, we are going to use JDK APIs, so whatever can be processed by those APIs can be represented as a zip ﬁle system by our implementation.
We only have to open an .odt or a .docx ﬁle with a GUI archiver or just issue.
In fact, since we now have a little VFS framework we will take advantage of it and give the ability to create a ZipFS from any virtual ﬁle.
The intention is to keep the codebase to a minimum yet functional point.
We will not re-invent the wheel but will try to take advantage of existing JDK APIs.
So, it is clear that in order to reach generality, any VFile which will be used as the archive has to be transformed to a java.io.File or, in our library, to a NativeFile.
The above imperative loop must be almost everywhere on the Internet.
The next group of utility methods build upon the previous deﬁnition:
Remember that our goal is to create a NativeFile out of any kind of VFile.
An efﬁciency check at the beginning of its deﬁnition makes sure that an already NativeFile will not be copied over to someother temporary NativeFile.Of the twoothermethods inobject FileUtil, createTmpFile is a wrapper around our own VFS API and copy presents some interest regarding its T type.
The constraint we use, T <: VFile[T], is the same trick as in the very deﬁnition of VFile.
Before delving into the implementation of ZipFS, we need to say a few words about the approach we take.
The general idea is that on instantiation of a ZipFS, we load the archive and create a cache of its entries.
But this is not such a straightforward approach as it may seem initially.
The main problem is that in a zip archive, there may be missing directory entries.
Just to make sure the hierarchy is correct, we even inject manually the root folder /
The hierarchy that we create is a canonical, Unix-like ﬁle hierarchy.
Next, we iterate over all entries and update the caching map.
This procedure gives us a global view of what is in the archive.
But we are not done yet, since we need to create any missing entries synthetically.
The nested utility method mkAllPaths takes a path as input and generates a List of all the path’s hierarchy.
We then check this hierarchy of parent paths and record any part that was not discovered when we iterated the archive entries.
This procedure that checks a path hierarchy is repeated for all the discovered paths of the archive, as we can see by the outer loop.
The loop is over the path2vfile map entries and, of course, from the entry tuple we only consider the path.
The remaining methods are the usual VFS methods that must be implemented.
The ZipFS.RootPath value is given in the ZipFS object and we will also need to deﬁne NoFile.
During the implementation of ZipFS and in particular its newFile method the need has arisen to return a nonexistent VFile.
In the ﬁrst step, we deﬁne a concrete class with the proper type and make it sealed so that no client code can ever extend it.
In the second step we use the sealed class to deﬁne a singleton.
A VFile that does not exist has a uniform behavior across all cases and so there is no need to create new instances each time.
The above two-step procedure is necessary, since there is no way to satisfy the Scala type inferencer by trying to deﬁne the singleton directly:
In Scala, singletons have their own type which is distinct from the type of the class they extend.
A virtual zip ﬁle is tightly coupled not only to the container zip ﬁle system but also to the underlying native (at least as far as Java is concerned) entry in the actual archive:
Recall that we create synthetic entries in the ZipFS cache for all missing directory entries of the archive.
Now that we have all the ﬁle machinery, we can build a few abstractions based on them.
First, our motivation is the recurring pattern of searching for ﬁles that match speciﬁc criteria.
Those who feel more than comfortable working in the command line – and we refer, unless explicitly stated otherwise, to the Unix command line must have issued this or a relevant command more than a few times:
The above command gives us all subdirectories of the current one.
For what it is worth, find is really a very helpful command.
The reader is invited to search theWeb for more information on the find utility.
Returning to the VFile API, the task seems almost straightforward.
The children of a folder are already available, so we just need to pick the right ones:
The iteration procedure, which is inherent in the filtermethod, selects only those children that match the speciﬁc criterion expressed by _.isFolder.
We could use a similar approach to select just the regular ﬁles instead of the folders and the object-functional nature of Scala, with its native support for higher-order functions, usually makes this or similar goals a oneline experience, or quite close to it, if typesetting constraints must be obeyed.
These higher-order functions, like filter that we are using here, are fundamental building blocks.
These blocks act like small components ready to be composed by the programmer.
All we need to do is provide them with the appropriate input.
The input itself can be as simple as _.isFolder is or it can be the outcome of a more compositional approach, for example.
We are actually talking about two kinds of composition here.
It does not appear in the previous examples but we have emphasized its signiﬁcance.
It is easy to picture a series of function applications using, for example, map and filter that can help us select the appropriate data with the appropriate type and this is the traditional bottom-up approach of functional programming:
The second kind of composition, the one that is explicit in the above examples of selecting the appropriate ﬁles, relates to the argument passed to filter.
In the ﬁrst case, which is just a simple one, the selection is based on a straightforward function, since our _.isFolder is nothing more than an on-the-ﬂy deﬁnition of a function value.
We can use the Scala interpreter to verify this intuition and check that the types and the functionality are as expected:
Then, a VFile matcher can be represented as Matcher[VFile[_]] or, since we have already introduced the type alias.
The use of an existential type, via the wildcard-type nature of the underscore in the deﬁnition of AnyFile, is a design decision.
The origin of this decision is in the deﬁnition of matches in trait Matcher.
If type T of the supplied parameter corresponds to a ﬁle, then T will be in the form VFile[A]
But T is not reﬂected in the return type of matches and, as a consequence, the exact type of VFile[A] and therefore A is lost.
No matter what the parameter is, only a Boolean survives.
That is why our type alias for FileMatcher uses AnyFile.
It is time to write down an extension of VFile that incorporates the * operator for ﬁle matching:
The VFileWithStar object is responsible for some book-keeping and extra ﬂexibility, by deﬁning the FileMatcher type and providing an implicit conversion from an instance of VFile to an instance of the the VFileWithStar class.
The latter is an enriched version of VFile with the extra functionality of one-level ﬁle matching via the * method, which is trivially implemented using functional abstractions.
It can be even shorter by writing it as file.children filter matcher.matches, that is in the form object method parameter.
So, in order to make use of the new machinery, we should properly import the implicit deﬁnitions; and we are saying deﬁnitions, since there is still a bit more stuff to program before delving into testing and experimentation.
In contrast to our reasoning for FileMatcher and the use of an existential type, a closer look at the VFileWithStar class shows a clear intention to preserve the exact type information of VFile by explicitly using the symbol for type T.
The reason is the signature of method *, which is indicative of our expectations: a FileMatcher is expected to return the same type of ﬁle as that of the ﬁle used to construct an instance of VFileWithStar.
For instance, trying to match virtual ﬁles under a zip ﬁle system should normally return zip virtual ﬁles, not native ﬁles, and this is a useful piece of information we do not want to discard.
Towards our goal of implementing some concrete FileMatcher, we observe that a matcher for glob patterns can be thought of as a special FileMatcher that operates on just the path of a ﬁle:
A straightforward implementation of this sort of matcher is one that inspects the ﬁle path extension:
Then, the glob-style matcher in Figure 10.5 is another special case of a FilePathMatcher.
There are two things about the glob implementation that deserve a special remark.
First, we use the preﬁx Weak for the class name to denote that we do not support full glob-style matching, in the lines of the Unix tradition.
Exercise 10.1 Consult the Unix man page for the C function fnmatch in order to see the full potential of glob patterns.
Under a Unix shell this is normally achieved by executing the command man fnmatch.
The relevant piece of information can also be easily found on the Internet.
Then augment the current glob pattern implementation borrowing ideas from fnmatch.
Instead, in order to interpret a glob pattern,we leverage the power of regular expressions.We transform the pattern into a regular expression directly by following a few rules.
We are being careful ﬁrst to escape backslash itself and then other characters, like the bracket, since otherwise it would be escaped twice.
Figure 10.5 A class implementing weak glob-style matching on ﬁle names.
We transform the star “*” glob operator, which means one or more appearances of any character, to the equivalent regular expression form “.+.”
We transform the question mark “?” glob operator, which means zero or one appearance of any character, to the regular expression form “.?”
We use the (?i) special construct, which instructs the underlying regular expression engine to be case insensitive.
Alternatively, we can leave this piece off and just support case sensitivity as the default.
Method matchesPathuses the exposed val pattern of class Regex in order to obtain a proper matcher for the ﬁle name.
Another implementation detail is that we construct a matcher each time we need to make a glob match against a ﬁle name.
Usually, Java programmers either forget about this behavior or are totally unaware of it.
In any case, the relevant method of Matcher and the Java documentation is clear:
Resetting amatcher discards all of its explicit state information and sets its append position to zero…
So, following the above recommendation, the code can be changed by renaming globRE to globREMatcher, so that it reﬂects its purpose better, then using one more call to get a matcher.
Now we have already introduced regular expressions in Section 2.15
Everything seems in place and ready for immediate use, yet the observant reader may think that we have crossed language borders or, phrasing it more realistically, that we have crossed library borders.
Before discussing the reason for this, if any, let us consider the approach of using a pure-Scala API.
Looking at Regex, the method findFirstIn is of interest and seems to ﬁt the purpose:
Return optionally ﬁrst matching string of this regexp in given character sequence, None if it does not exist.
Returning to the glob matching problem, it is easy to see that if the glob pattern matches, then there is certainly a ﬁrst match and it is clear that Some(x) will be returned by findFirstIn.
Conversely, if findFirstIn returns Some(x), where x is the matching string, then obviously there was a match for our glob pattern! Once more, we change globRE and we patch matchesPath, so that now we stick.
Returning to the questions, the digression from a pure-Scala approach was not entirely on purpose.
There are several reasons why we might act similarly in other situations.
We are so used to programming in Java that the necessary ingredients for an algorithm are almost seen in front of our eyes in JDK terms.
This kind of behavior may persist even after one goes beyond the level of a beginner Scala programmer.
Although there is no study to analyze the relevant behavior, a possible factor playing a key role is how much is the percentage of coding divided between Java and Scala.
We are new to Scala programming, coming immediately from a Java background.
As in the previous case, familiar classes from the JDK and relevant coding idioms are recalled easily and on-the-spot.
In fact, one may argue that Scala still needs more libraries to reach a critical mass that would make it “feature-full.” In such a case, we will inevitably have to resort either to the JDK or to some external Java library.
The Scala library incorporates the necessary features, but in a not very satisfactory way.
Scala, being an object-functional language, is different from current mainstream programming.
A programmer who has been taught to think in a certain style or a particular language, may ﬁnd it difﬁcult to grasp the essence of this blend of object-oriented and functional programming.
It may even feel “unnatural” during the very ﬁrst steps.
In those moments, techniques and code from a previous language, like Java, may come in handy.
So, it depends on the current state of Scala, on one’s knowledge of the Scala platform and one’s approach or even taste for programming.
What can we do? One might be tempted to propose that the best overall advice to give is go with a Scala implementation or contribute one to the community unless the feature is considered a lower-level one.
But in reality there are also other dimensions to consider.
In fact, we have not yet mentioned deadlines, a scary fact of everyday professional programming.
What if the deadline is tight, we know the feature exists in Scala but we are much more proﬁcient in using an equivalent pure-Java library?
This deviates from the standard Java collections library, so that it can embrace the general programming style that Scala promotes.
This is evident in the use of higher-order functions (HOFs) like map and filter.
Since Scala provides such a comprehensive library, it is considered bad style to use Java collections when programming algorithms in pure Scala.
Of course, the mix with pure Java implementation is inevitable when dealing with the real world, but exactly for that reason appropriate wrappers exist, which bridge the gap between the two worlds.
On the other hand, there are some features that can be considered lower level.
These are either related to interfacingwith thenative world,meaning that the implementation is non-Java – probably something like C – or are considered fundamental building blocks that need not be duplicated.
The interface CharSequence is the common parent of String, StringBuffer and StringBuilder, the ubiquitous Java classes.
So, it is natural to transfer this interface to our Scala coding practice.
Yet, the truth is that time will tell exactly which coding patterns will survive.
What we have so far is essentially an operator implementation to match against the ﬁles of a folder and proper abstractions that can handle virtual ﬁle matching.
Concrete implementations of glob pattern matching took advantage of regular expression support, both in the Scala library and the JDK.
It provides among other features the building blocks of more scalable network and ﬁle I/O than is possible with the traditional java.io API.
Now, do we have any .scala ﬁles around? Let us see whether the * operator works:
First, we need to augment the VFileWithStar object with one more implicit conversion:
Second, we need to import the implicit conversion and we are ready to try again.
We can verify the correctness of the result, based on the previous directory listing.
It is not necessary to reproduce the above directory structure exactly, which resembles a tiny part of the authors’ hard disk, in order to test our library.
In fact, using different directory layouts and different search patterns can generally help in catching bugs! Testing algorithms with other than the usual inputs can be advantageous in professional programming.
The ﬁrst is the implicit conversion from a VFile[T] to a VFileWithStar class.
The second is the implicit conversion from the string description of the query to a more type-full representation, which is WeakGlobMatcher in this case.
Normally, equipped with a virtual ﬁle system implementation at the core of our library, there will be no change with a zip ﬁle system as well.
Using the same directory structure as previously, ﬁrst we get an idea of the contents from the test-2.jar sample jar ﬁle:
Then we go into the jar ﬁle via our VFS abstractions:
It is rewarding and encouraging to see how the abstractions ﬁt together.
The same API uniﬁes different implementations and the new features are uniformly “acquired.” Sometimes, a new API makes us forget that standard facilities are still there, ready to be used.
For example, once we have obtained a value for jarScalaFiles, we can combine it with more results:
Abstracting this away, so that it means “All the scala ﬁles plus other ﬁles whose type I will provide parametrically” should, by now, be easy in Scala:
We have omitted the fully qualiﬁed types of FileMatcher and ZipFile from the above output just in order to conserve space.
Normally, the Scala interpreter will show them instead of the one-word abbreviations given above:
Question 10.1 Why is the return type of scalaPlus a Collection?
There is more than one way to express the parametric concatenation of matched ﬁles.
Let us assume we do not want to create a def in the interpreter session but we prefer a function as a value:
Once more, the result reassures us of the expressiveness of Scala.
There is also just one subtle point that can usually come up in three ways:
The point in question is: What do we do if we need to combine searches from different virtual ﬁle systems? Can the API support this? If so, what are the types involved?
A closer look reveals that both the value of jarScalaFiles and the result of jarRoot * "*.jar" refer toZipFiles.All we have to do is trywith values that refer to results of different types.We recall that, in our examples,we have so far computed cwdScalaFiles, a collection of ﬁles at the native ﬁle system, and jarScalaFiles, a collection of ﬁles at the virtual jar ﬁle system.
Here we use the term“collection” in its broad sense, although the actual typesmay be speciﬁed by the Scala Collection type.
The interpreter is handy when we want to be reminded of the types:
Then, it just becomes a matter of a few keystrokes.
Remember that VFile is actually deﬁned as VFile[T <: VFile[T]] and that is why we see the nested VFile in the above interpreter session, where T has been replaced by NativeFile with ZipFile.
Question 10.2 What will be the result if we try to combine the two variables, cwdScalaFile and jarScalaFiles, using the ++ operator but with their order reversed?
Figure 10.6 The extended deﬁnition of a matcher, which provides support for boolean composition.
Using the facilities of our small library, it is easy to deﬁne a query for matching, for instance, all .scala ﬁles.
But what if we want to express more complex scenarios, like these?
Match .scala ﬁles whose name do not start with Test.
Evidently, the emerging pattern is that of boolean expressions, which is ubiquitous in programming.
So we need to provide support for boolean expressions at the matching level, which opts for an extension of Matcher[T]
Up until now, Matcher[T] only had one method, namely matches.
The special syntax unary_! is there to tell the Scala compiler correctly thatwewant a unary operator, sincemethod ! represents boolean NOT.
Now, let us start answering the scenarios at the beginning of the current section.
Equipped with the new tools, programming looks more and more like fun.
First, how about all the .scala or .jar ﬁles directly under the current folder?
Second, do we have any .scala ﬁles whose names do not start with test?
If we know that we will usually work with particular kinds of ﬁles, a couple of.
Themanual type annotations are here to assist the compiler in choosing the implicit conversion from a String to a generic type of Matcher for ﬁles, which is precisely what FileMatcher stands for.
We know, via VFileWithStar, already imported in scope, that the only such implicit conversion is glob2Matcher.
A quick look at Figure 10.6 reveals some redundancy regarding the deﬁnitions of the two binary operators.
This common structure can be easily abstracted away, resulting in tighter and aesthetically more pleasant deﬁnitions, as shown in Figure 10.7
In fact, the situation helps us a little towards a more object-functional path.
What we have are objects, which we wish to treat as values via their boolean composition.
The object-oriented nature (the matchers being instances of a class) and the functional nature (the boolean values that can be composed) seem so nicely.
Figure 10.7 The alternative, more concise deﬁnition of a matcher.
Yet, how successful an implementation is in this respect cannot be decided that easily.
It is truewe are experiencing the beginning of the object-functional era and as our experience along with the accumulated body of research and creative thinking grow, we will be able to tell with more accuracy.
Note that it took many years for the object-oriented design patterns to be clearly identiﬁed as such and then followed in enterprise computing cycles.
Returning to the problem at hand and Figure 10.7, the common structure of the binary boolean relations is abstracted by method binop.
Devise an implementation of the unary ! with the help of binop.
Exercise 10.4 Now that the functional nature of the approach has already surfaced, one might be tempted to encode it directly on our type hierarchy.
Since what basically a Matcher[T] does, via its matchesmethod, is to take a value of type T as input and give a value of type Boolean as output, one could deﬁne Matcher[T] as.
Looking back at ﬁgure 10.4 andour implementations from that point on,weobserve that we have not passed the one folder barrier.
It is responsible for traversing the hierarchy at all levels and this is achieved by utilizing flatMap.
The idea behind flatMap is to collect all the results and ﬂatten them in a container which resembles the original.
So, for each ﬁle, we obtain its children and for them we recursively obtain their children and concatenate the results.
The rest of the job, that is returning a ﬂattened Iterable of ﬁles, is done inside flatMap.
Note that, according to the last line of **, we ﬁrst collect all the ﬁles and then we do the ﬁltering.
Over directory structures with a lot of ﬁles and folders, this can be very memory intensive, wasting resources that will be subsequently ﬁltered out.
At the expense of clarity, we can possibly patch the code to be more selective rather earlier during the traversing operation.
Exercise 10.5 Implement the aforementioned feature, in order to save memory resources.
Hint:Youmust be careful not to reject folders as soon as possible, so some special treatment of them is needed.Will it be advantageous to use scala.Stream, so that the constructed lists are lazy? Explore possible alternatives with and without streams.
In Chapter 10 the goal was to match over a particular set of ﬁles, according to speciﬁc criteria.
To this end we moved in two steps, ﬁrst working one level down the folder hierarchy and then going deeper than the ﬁrst level.
In that second step, we walked over the ﬁlesystem tree, collecting all the possible ﬁles at once.
We will now study this kind of “hierarchy walking” a little further.
Our assumption is that we work over a tree structure.
For our exploration, we assume a general knowledge of the.
The Java tradition dictates that we do iteration following the Iterator and Iterable interfaces, under packages java.util and java.lang respectively.
An Iterable is the generator for Iterators, via its iterator method or, as the Java documentation speciﬁes:
Implementing this interface allows an object to be the target of the “foreach” statement.
Scala mimics this functionality with its Iterable and Iterator traits, both under the top-level scala package:
Collection classesmixing in this class provide amethod elements,which returns an iterator over all the elements contained in the collection.
It is interesting to note that this pattern is ubiquitous.
Microsoft’s C# deﬁnes IEnumerable, which plays the same role as Iterable:
Exposes the enumerator, which supports a simple iteration over a collection of a speciﬁed type.
The idea, in all three languages, is to return anobject thatwe canuse to iterate over all the elements of the underlying collection.
Also,while an Iterator is normally a one-off utility, an Iterable plays the role of a generator for iterators.
So, referring to the Scala version, one can repeatedly call elements and always get a fresh object to work on.
The usual programming pattern deals with some tedious code, like the following:
But we already know that Scala promotes another style of iteration, the one using the for construct:
With this approach, we provide the list with a code block to execute for each one of its elements.
Note that Java also provides a foreach construct which is syntactically similar to the above but is, in effect, translated by the compiler to equivalent code of the hasNext/next style.
In this programming style, the programmer is not responsible for checking whether there are more items in the collection and for.
The role of each node in the tree, apart from holding domain data, is to point to its children.
So, we model this directly, using the Iterable programming interface.
The idea is to model nodes generically that act as placeholders of other nodes and this should be applied recursively.
We have probably made a mistake in our deﬁnition of IterableNode1
Wecould go on and implement the needed search algorithms in a generic fashion, based on the previous deﬁnition; but let us take a closer look at the innocent-looking IterableNode trait.What is its original purpose? It is, of course, to model our tree nodes.
The motivating use case for searching over trees in this chapter comes from directory hierarchies.
So, what this means is that at some place in the design of our VFS API we should have predicted the existence of IterableNode.
Scala supports incremental, nondestructive modiﬁcations at the design level by employing the power of implicit conversions.
If the type is not there, we can make it happen without touching existing source code.
Beware that this power comes with a price, as having too many implicits in scope can render the code not only less understandable but also incorrect.
We also use the implicit in its own deﬁnition, in order for the children to come out with the proper type.
The Iterable[T] returned from method children of VFile[T] must be changed to IterableNode[T] but that is exactly what the implicit does, so we reused it as a normal method.
As the error message suggests, two type parameters with the same name T cannot be uniﬁed by the type inference procedure inside the Scala compiler, that is they cannot be proved to be the same type.
Let us help the situation in understanding the error, ﬁrst by avoiding the type parameter name clash.
Exercise 11.1 In the above example, the compiler needed some extra assistance by having us provide an explicit type parameter.
No matter how powerful and time-saving implicits may be, the previous solution can be charged as guilty of over-wrapping.
For every node in the hierarchy we create a wrapper, so it is as if we double the whole tree structure.
If this is going to be – and it is – an a priori memory requirement for any searching algorithm, then we start off with a disadvantage, since we cannot even know what extra memory requirements the algorithm will have.
Can we do better? If yes, how can we discover this better approach? Perhaps sitting back and thinking about our case a little bit might help.
Somemay seemor actually be trivial, othersmay not lead directly to an insight but experience reports reveal that the very process3 of just stating the known facts can be beneﬁcial.
This technique can be transferred with success to other activities, like when trying to ﬁgure out where the most recent, ferocious bug of our application came from.
Although not stated explicitly, we have silently assumed that nodes are of the same or.
For example, all the previous ﬁgures depict nodes of two kinds:
This assumption is directly reﬂected in the proposal of IterableNode[T], where the type T characterizes the exact nature of similarity.
As is typical in the usual implementation scenarios, a node will provide some way, that is someAPI, to expose its children.
It is obvious that different kinds of nodes have different ways of providing their children, but the most important thing is the existence of such a facility.
What do we want to do with the tree? Iterate over the nodes.
What does iterate over the nodes mean? Iterate over them and their children.
So, we have a set of similar nodes, the node as an entity can provide us with its children and we wish to iterate over all nodes.
Could it all appear clearer now? Why not start from somewhere in the tree (the root actually), ask each node to provide its children and just report them all in the proper order? The proper order is the essence behind the different search variations, whether BFS or DFS (pre-order, in-order, post-order)
It is a plausible strategy, so let us start abstracting over the ingredients.
There is no special handling here, as the prescribed idea of type T parameter is the one to follow.
We have stated that all kinds of nodes, that is nodes for each type T as given above, will have a way to expose their children.
The only detail that remains in order to handle them uniformly, is to give a unifying API that does exactly that:
For example, a children provider for plain Java Files is coded as:
Skeleton implementation Figure 11.5 presents a skeleton implementation of a tree iterator.
It returns true if and only if there is some node to report and sets _next according to the previous rule.
As a technical note, we could have used a private _next variable and have computeNext just return an Option[T]
This point will be clearer when presenting the actual DFS and BFS implementations.
One implementation detail about iterators, that new programmers usually ignore, is the fact that hasNext must not assume a subsequent call to next and vice versa.
A good question to ask in order to get into the heart of the problem is: How will the iterator behave if we continuously call hasNext (next) without ever calling next (hasNext)? Although it is an abuse of the programming interface, one may insist on getting all the nodes out of the iterator by just calling next, until an exception is thrown, which will signal the end of iteration.
So, ill-behaving clients may exist and our responsibility is to provide a robust implementation.
Keeping state We will implement our generic iterator using one of the DFS, BFS techniques.
Discovering each node does not necessarily mean that we will immediately report it as the next item to return from the iterator.
Figure 11.6 An abstract interface that models the idea of node buffering.
For example, in a post-order DFS, we discover a node but we report it only after all the subtree beneath it has been reported ﬁrst.
So, it is clear we will need some sort of buffering, the main idea of which is captured by the programming interface in Figure 11.6
The order in which we retrieve elements from the store is not necessarily the same as their insertion order.
The usual data structure “suspects” named LIFO (Last-In First-Out) and FIFO (First-In First-Out) will play their role as well.
As a preliminary observation, a LIFO backing store will be tied to a DFS implementation, while a FIFO store will be tied to a BFS implementation.
Wewill need two concrete implementations for NodeStore, namely LIFOStore and FIFOStore:
In fact, different implementations will lead to other variations of iteration and this is the reason behind our introduction of the addChildrenOf method.
For the FIFOStore, on the other hand,we directly use a Queue, which represents the canonical example of a FIFO data structure:
Pre-order depth-ﬁrst iteration We are now ready for the implementation of a DFS that will help us iterate over the tree nodes in a pre-order fashion.
We keep internal the state about which nodes we have to explore, using the toExplore value, which is of LIFOStore type.
The moment the PreOrderDFS iterator instance is created, we push the starting node, start, on the stack, since this is the ﬁrst node to explore.
So, speaking rather informally, a parent is reported ﬁrst, giving us the pre-order semantics.
And since after the parent we immediately see its children, we have the depth-ﬁrst property.
In fact, most, if not all, textbooks and tutorials will point out the difference between LIFO and FIFO regarding DFS and BFS respectively, but fail to abstract over the children nodes addition operation.
Post-order depth-ﬁrst iteration The implementation of a post-order, depth-ﬁrst iterator is shown in Figure 11.10
One extra detail, compared to the pre-order implementation of Figure 11.8, appears here and it is related to the fact that we must remember which nodes have been processed.
By “processed,” we mean that all their children have been returned as the next iteration node.
The relevant book-keeping is done via the processed variable of type Set[T]
So far,we have dealt with the ubiquitous Iterable and Iterator interfaces.
As a quick reminder, it contains just one method, foreach:
Having led the way by resolving some fundamental issues regarding data representation in the previous section, the approach to implementing depth-ﬁrst and breadth-ﬁrst tree traversals is nowmore straightforward.
Another issue is that it feels as if we are missing.
What the above programming interface says, is: give me a node and I will process all of its children using function f.
Pre-order depth-ﬁrst traversal The implementation of a pre-order depth-ﬁrst traversal is shown in Figure 11.11
Exercise 11.3 Implement a nonrecursive version of the pre-order depth-ﬁrst traversal.
Exercise 11.4 Implement the post-order depth-ﬁrst traversal and the breadth-ﬁrst traversal.
What are the differences between the two approaches (iteration, traversal)? How different or similar might they be? Are they the only approaches? What are the general concerns when iterating? Regardless of our investigation and ﬁndings in the previous sections, we attempt to name a few directions of interest in the following paragraphs.
We, the users of the API, drive the whole process.
We control when and whether to continue seeing the items, if more of them still exist.
On the other hand, we have no control on the iteration itself with a for, unless of course we force some kind of an abnormal exit, via throwing an exception.
Is should be evident by now that using hasNextperforms the iteration externally , while using for performs the iteration internally.
It is amatter of who is responsible for doing it.
Using the iterator explicitly, via the hasNext/next idiom, has a procedural ﬂavor.
We always specify the exact steps to follow, that is hasNext and next, in order to iterate over the items.
In contrast, we use for in a declarative style, by just giving the action to execute for each item in the collection.
Since this feature is built into the compiler logic, the compiler does the appropriate transformations and calls on our part.
These transformations, which amount to unrolling the iteration to speciﬁc method calls, are done mechanically, with one, bug-free algorithm.
Termination of the iteration is handled differently in the two cases.
With the hasNext/next idiom, we are sure the iteration is over only when hasNext returns false.
Since the iterator, as an object,must have some knowledge of the underlying structure of the items in order to hand them one-by-one properly to the user, it is responsible for closing any underlying resources.
If this is not apparent, we can think of a byte iterator that takes its contents from a ﬁle.
The iterator, either on creation or lazily on ﬁrst use of hasNext or next, opens the ﬁle for reading.
This corresponds to reserving some operating system data structure, so that our application can use it to read bytes from the ﬁle.
The question is, when is it appropriate to close the underlying resource represented by the opened ﬁle?
It is evident, by design, that such a decision cannot be made blindly.
The iterator object cannot decide by itself to close the ﬁle, since it is not aware of how the user calls hasNext/next.
But it will be safe for the iterator to release the underlying resource if the last call to hasNext returned false, since then it is known that no more bytes can be provided.
The situation is far from satisfactory, since it relies on the user exhausting the iterator.
Although this is normally what we do, the design relies on the good behavior of the client code.
Even if the user is very careful and systematic with its own code, side effects always lurk around when using third-party libraries, and they could present themselves in unpredictable ways.
Fortunately, when the collection of items itself is responsible for the iteration, as is the case when using for, then it is up to the collection design to behave appropriately.
The good news is that this can be programmed once in the code that implements the iteration and then all users can beneﬁt for free.
Iteration with hasNext/next has been used traditionally in an object-oriented context, whereas the other form is ubiquitous in functional programming.
It is believed that the latter is so because of the need to have closures in order to support.
Instead of passing a closure around, we can pass the implementation of the interface but depending on the programming language we may have to take care of the free variables.
In a language with support for closures, free variables are handled by the language itself, i.e., the compiler.
It is just that closures make our programming experience a lot easier and certainly more concise.
Iteration has a linear feeling, although the underlying collection could be a graph.
Whatwe get is a series of items one after the other, but does thismean the underlying data structure is an array?What decides how to select the items that are given in the linear fashion expected by the iteration procedure? For a tree, there is, for example, breadth-ﬁrst and depth-ﬁrst traversals and the latter can be pre-order or post-order, to name just a few combinations.
But abstraction has always been sought after and even favored in programming.
These notions can be “algebraic properties,” “duality” or “isomorphism” to name just a few.
We might wonder, for instance: Can we derive one approach from the other? If that is the case, then we say that the approaches are isomorphic, that is there is always an algorithm so that given one of the approaches we can derive the other.
Exercise 11.6 Derive a traversal-based implementation from an iterator-based implementation.
These conditions need not necessarily be all true and they are by no means exhaustive.
The expression problem, also known as the extensibility problem, refers to the situation where we need to extend the data types of a program as well as the operations on them, with two constraints: (a) we do not want to modify existing code and (b) we want to be able to resolve types statically.
Thus, the essence of the expression problem lies in the type-safe incremental modiﬁcation to both the data types and their corresponding operations, without recompilation and with the support/use of static typing.
At the heart of the expression problem is the Separation of Concerns principle.
Since its inception about forty years ago by Edsger Wybe Dijkstra [19], the Separation of Concerns principle has been elevated to one of the cornerstones of software engineering.
In plain words what it states is that when tackling a problem we have to identify the different concerns that apply to the speciﬁc problem and then try to separate them.
By separating the concerns, we produce untangled, clearer code, thus reducing the software complexity and increasing maintainability.
Of course, separation of concerns is only half the truth.We can identify our concerns and successfully separate them, but at some point we will need to recombine them: after all, they are parts of the original problem.
So, what exactly do we separate and then recombine in the expression problem? Data and operations are two different dimensions.
Incremental modiﬁcations to these dimensions should be done independently and in an extensible way.
At any point,we should be able to recombine the independent extensions, so thatmodiﬁed data are combined with modiﬁed operations.
In the following, we will see how the expression problem appears in the setting of a common and well understood problem space: the design of an interpreter for a minimalistic expression language.
We will study the problem by applying several techniques, using along the way several features of Scala.
The intention rather is to explore the design space and see alternative attacks.
Also, unless stated otherwise, from now on the acronym ExP refers to the Expression Problem.
The requirements for our minimalistic expression language are that we need to model a set of operations over a set of data and we want to design both in an extensible way.
Our data, which represent expressions, may come in the form of integer literals or combinations of other expressions, as for example in the case of the addition basic operation.
Operations can be like the obviously needed evaluation or the string representation for each expression form.
A grammar that describes the small language is the following:
Also, we begin by supporting a basic eval operation and we will study progressively the incorporation of a new operation repr that generates a string representation of an expression.
For the rest of the chapter, we will use the nouns data and expression interchangeably to denote the one dimension of the expression problem.
The straightforward object-oriented way to handle our expression language is to deﬁne a class representing our data and pack the needed operations as methods in the corresponding class, as shown in Figure 12.1
Here, a trait abstractly deﬁnes the evaluation method signature and the concrete class NumD provides an implementation.
Using this approach it is rather easy to extend our language with new kinds of expressions.
For example, an expression representing the plus rule in the above grammar can be deﬁned incrementally by PlusD.
Unfortunately, when a new operation is needed, the approach breaks down, since we have to modify every existing data class and add the new operation in its deﬁnition.
As a side note, this modeling approach is in effect the Interpreter design pattern [24]
Dual to the previous approach is the so-called operation-centric decomposition or functional decomposition.
This may not seem so obvious from an object-oriented perspective but is again based on another pattern, the Visitor design pattern.
The central idea is to make operations ﬁrst-class citizens in our design by behaviorally separating them from the corresponding data.
In effect, we have abstracted away any operation by deﬁning a performmethod.
In the above design, our data, represented by BaseD, abstractly reference its operations by the op parameter of the perform method.
At the same time, our operations, represented by BaseOp, abstractly reference the data they are applied to by the data parameter of their computemethod.
This gives the impression we have solved our problem by possessing a fully extensible design for both of our concerns: data and.
It deﬁnitely seems like a huge success, but not quite so, as the following arguments reveal.
First of all, we have departed a little from the standard naming conventions of the Visitor design pattern, where the usual method names are accept when we are in the deﬁnition of data and visit when we are in the deﬁnition of the Visitor itself.
The reason for this is to be semantically closer to our problem domain.
Note the functional appeal of EvalOp: since the visitor’s role is to evaluate expressions, we introduce an apply method.
Having this technique in our toolbox will be handy when we try to create more involved visitors, where computations may need to reuse other visitors.
In fact, we can take advantage of functional Scala objects and deﬁne the small utilities of Figure 12.3
Also,we have used Option[Int] instead of Int as the type of result, so as to denote the absence of any value in case the visitor has not been used.
The real strength of the functional decomposition boils down to the fact that adding a new operation is merely adding a new visitor.
After all, that is why we introduced visitors in the ﬁrst place:
Exercise 12.1 Notice how the functional appeal of EvalOp is very ad hoc: it appears only in a concrete implementation of BaseOp and not in BaseOp itself.
This means that, for example, the deﬁnition of ReprOp above should repeat the implementation of method apply in order to acquire the same functionality.
Generify BaseOpusing an “unknown” type for the result and implement apply in the base trait once.
New data mean new methods in every visitor, starting from the BaseOp trait and following down all the visitor hierarchy.
In order to study the expression problem in a consistent manner and follow the several examples with relative ease, we have made a few decisions on notation.
First, as already described previously, there is a slight departure from standard Visitor nomenclature: we use perform instead of accept and computeX instead of visitX for some X representing a data type.
Also, we name all data types with a D sufﬁx: BaseD, NumD and so on.
Finally, we name all of our operation types, that is Visitors, with an Op sufﬁx in their names: BaseOp, EvalOp and so on.
Having this consistent notation, any code snippet can be mentally partitioned to its semantic parts rather quickly, without having to resort to the accompanying text right away.
Also, we have kept the data naming the same for both the data-centric and the operation-centric approaches.
Obviously, looking at the methods supported by BaseD, namely eval in the data-centric approach and perform in the operation-centric approach respectively, reveals the nature of the approach.
We have mentioned that the data-centric approach does not work well with new operations because it needs modiﬁcation of existing source code.
Yet, the objectoriented way encourages the idea that new behavior can be added via subclassing, so we will try and see how far we can go with typical inheritance relationships.
A problem with this approach can be seen right away by noticing the constructor signature of ReprPlusD: its arguments are not just instances of BaseD but must be instances of the more speciﬁc type ReprD.
This is unfortunate: we may not have touched the source code of our BaseD trait but we cannot reuse pre-existing library code that generates instances of type BaseD and we cannot directly reuse instances of type BaseD produced by our code.
Imagine that we have a library which was compiled before the introduction of the ReprSomeD data variants:
It is expected to return the // tax percentage scale for my income.
The above issue could be resolved if we could have our code produce the correct instance type, namely ReprNumD instead of its super type NumD.
Of course, we will have to provide one implicit conversion per data type transformation.
Exercise 12.2 Explore this line of design.How canwe deﬁne such a generic implicit? How can we provide reﬁnements of this implicit, in order to cope with our model.
Another idea is to provide auxiliary constructors in the ReprSomeD variants that take the respective base traits as parameters:
Exercise 12.3 Notice how we have used numd.eval in the auxiliary constructor of ReprNumD above, instead of just numd.value.
The latter will clearly not pass through the scala compiler, since it is not visible outside the deﬁnition of NumD.
Explore this line of design that uses the call to eval instead of an explicit value getter in order to take advantage of the fact that eval is deﬁned for all BaseD instances.
On the constructor of ReprPlusD Let us take another look at the primary constructor of ReprPlusD.
The quick answer is, of course, it would not compile.
Not because the constructor is erroneous, but we need the a and b instances to have a repr method, in order for the repr method of ReprPlusD to compile:
A somewhat trivial observation one may note, but actually a fruitful one.
The question is: Can we constrain the constructor parameters in any way, so as to ensure they have a repr method and at the same time be BaseD instances?
Exercise 12.4 Try to model, in Scala, an answer to the above question.
Hint: You may have to decide whether something stronger is needed than the abstractions we have used so far.
After using subclassing for the data-centric approach, it is tempting to try it for the case of operations as well.
Let us say that we insert this new kind of data:
The required operation PlusOp and its concrete implementation EvalPlusOp are deﬁned as follows:
Note how in the body of computePlusD we take advantage of the previously deﬁned, in Figure 12.3, utility objects.
If we try to compile class PlusD we will get an error:
We have hit a wall! PlusD does not properly extend BaseD since it does not override method perform: it should have a parameter of type BaseOp instead of type PlusOp.
This can be readily veriﬁed by using the override modiﬁer.
Clearly, the implementation is not type-safe, since it applies asInstanceOf, casting the op object into something different from its deﬁnition type.
Casting here is destructive and, by deﬁnition, circumvents the static type system.
A general question may arise: Should we reject an implementation just because it applies casts? Should we stop pursuing our design further if it introduces casts at some point? Usually, casting is considered bad practice, especially in the context of a language with a rich and expressive type system, like Scala.
Destructive cast applications, like the one seen previously, may lead to runtime errors and we do not want our application to fail suddenly, in a way that cannot not be predicted.
In fact, if we think of Murphy’s Law, it will most certainly lead to runtime errors!
On the other hand, casts may appear in the form of conditionals:
Consecutive ifs reveal a procedure style, while under object-orientation polymorphism should be preferred.
Generally speaking, it is not rare in the application libraries landscape, even after the advent of generics into the Java platform, to use type casts while implementing a library.
The casts in the library are used to make the life of the application programmer easier.
In effect, they absorb all the small unsafe details, making them.
The following snippets from the Scala library implementation reveal exactly this fact:1
After all, casts exist in our code just because the language allows them to.
So far, our approaches could have been tried in plain-old Java, even before the advent of generics.
An interesting question arises of what we can expect if we pursue a design that employs generics in order to become more expressive.
In particular, so far our “parameterization” relied on simply denoting the proper interface either for data or operations.
We can call it ﬁrst-order parameterization and its roots are in the support for polymorphism, inherent in every object-oriented language.
Taking this a step further, we abstract away the needed interfaces as parameters of a generic type.
The basic idea is that since in the functional decomposition we have an extensibility issue regarding our data, we parameterize the data type with an operation type.
As a consequence, the actual computations in the operation classes need to be parameterized, since their parameters are now parameterized data.
The examples are from revision 16570 of the Scala subversion trunk repository.
The problem is that the perform method expects an operation of the generic type V, as can be seen from the deﬁnition of the BaseD[V] trait, but at the offending use site, this is of type EvalOp.
Clearly, this is unrelated to V, at least as far as the compiler is concerned: there is no declaration anywhere that ﬁxes2 V to EvalOp.
The solution, due to Madst Torgersen [73], is to use a trick.
Since this does not have the correct type,we can provide it using an extra parameter selfof type V.
The changes affect our NumD data and the operation deﬁnitions, as seen in Figure 12.4
After this change, it is straightforward to add the new data PlusD in a statically type-safe manner.
In particular, the alerted reader may well be anticipating F-bounds and typeconstructor ﬁxed points.
Figure 12.4 Operation-centric approach to ExP with generics and Torgersen’s self parameter.
Our code example has become a little more verbose but at least we have gained static type-safety by providing an extra parameter of the needed type.
Let us now turn to a somewhat dual design by trying to incorporate generics in a data-centric approach.
The need for generics in this case will emerge from the simple data-centric approach of Section 12.3 and especially our remarks on the following constructor:
If, instead of ReprD we use BaseD, the problem, as discussed previously, is that we cannot call repr on a or b because repr does not exist in BaseD.
How do we patch them in order to get the extra repr method? Our line of thought is the following.
We want BaseD instances to have the extra repr method, which is deﬁned in PlusD.
The above means that we want BaseD instances to acquire features existing in subclasses.
Then, we ask how to “parameterize” BaseD in a way that guarantees the extra features.
Following the previous points, T needs to have features of subclasses of BaseD.
Inobject-oriented terminology, subtyping constraintswhere the type tobebounded (BaseD in this case) is used in the constraint itself, are traditionally called Fbounds [12]
Equipped with the new constrained parameterization, the base deﬁnitions are seen in Figure 12.5 and the task is now to extend our model in the “difﬁcult” dimension of operations.
Choosing the string representation as our new operation, the data model is extended with the aid of ReprD.
Notice how we now constrain the abstract type T to be a subtype of the data supporting the new operation repr, in accordance of course with the general.
Figure 12.5 Generic, data-centric base deﬁnitions for the expression problem.
The respective concrete implementations for NumD and PlusD are the fully type-safe extensions.
One consideration with this approach is that the F-bounds requirement makes our classes unﬁnished in their implementation.
In order to create instances for our data, we need to ﬁx the bounds to something concrete.
In a rather informal way, an F-bound of the form.
Like in the case of the equation, we seek ﬁxed types or, in other words, we seek to ﬁnd the “ﬁxed-point” of the type in the bound, so that we can use nongeneric versions of that data type.
Notice how, once again, Scala’s design decision to provide a primary constructor saves us from extra keystrokes and unnecessary verbosity.
In Java, we would have to provide an implementation for the constructor and in there issue a super constructor call.
While most object-oriented languages allow the deﬁnition of abstract or “virtual” operations, Scala advances one step further and allows us to declare abstract types as well.
These are types given in the body of a class or trait that are not precisely speciﬁed: their exact deﬁnition can either be left totally unspeciﬁed or be constrained.
We can take advantage of this scheme in the context of the expression problem but we have to decide on what to abstract: the data type or the operation type? In the present section we will deal with an object-oriented decomposition that abstracts over data, ﬁrst presented by Odersky and Matthias Zenger [60]
Now, abstract types need an enclosing type and since we are modeling a small expression language with operations, we start like this:
In these base deﬁnitions, we can see that the data type Data is unspeciﬁed but yet constrained to always be a subtype of trait BaseD.
Our approach, as can readily be seen, is not based on visitors.
We could have included PlusD in BaseLang but it is easy to provide a new mini language with the extra data:
The new language, PlusLang, enriches BaseLang with a representation of data addition.
In the scope of PlusLang, the abstract type Data has no further reﬁnement, so it retains the constraints of the base language, BaseLang, being a subtype of BaseD.
By deﬁnition,PlusLang has all the data of BaseLang and, consequently, their operations.
One concernwith the approach so far is that, sincewebase everythingon top-level traits, we have nothing concrete to instantiate and use directly.
Actually, the main issue is that the abstract type Data needs to be made equal to something known.
For example, if we just try to make PlusLang concrete by deﬁning an object.
To correct the situation, we make Data equal to BaseD.
What saved us previously was just the intentional type we gave to n1
In fact, if we try to compile without the n1 immutable value.
The reason is exactly the fact that type Data has not been assigned a known value (BaseD in this case)
So, the moral is we must not forget to ﬁx the data type.
Since operations are built into the data types,we will have to create a new language for which the base type incorporates the new operation.
Also, we must “patch” the already deﬁned types of the base language with the new operation:
The reason is that in Scala the new deﬁnitions simply shadow the previous ones and overriding is not the default option.
For this, the super qualiﬁer is needed in ReprLang to access the trait BaseD of the same name in BaseLang.
Other than this technical detail, the enriched BaseD contains the new repr operation and the same is done with NumD.
Having deﬁned the new operation, we can mix in the several languages to create variations of the desired functionality.
For example, if we need a language that support both the repr operation and the PlusD data, we can mix in PlusLang and ReprLang:
Inside ReprPlusLang, the Data type refers to trait BaseD of ReprLang, so the parameters a and b already contain a repr method.
Exercise 12.5 So far, our operations return primitive types, for example, Int and String.
Note that the requirement is that negate does not just return an Int but an expression of our mini language.
For example, a NumD instance is expected to return another NumD instance with the underlying Int value negated.
We now turn to the dual approach, again leveraging abstract type members in the context of trait-based expression languages that are extended in order to provide the extra functionality.
Figure 12.6 Base language for an operation-centric decomposition of the ExPwith abstract type members.
The most important thing to notice is the use of an explicit self-type in the deﬁnition of class EvalOp:
This way we constrain the type of any instance of EvalOp actually to be a subtype of our abstract type Operation, which is absolutely necessary for the following code inside EvalOp to type check:
Actually, this is a point where Scala’s expressiveness really shines.
Had we not used the explicit self-type, this would just be of type BaseOp and not of type Operation, as expected by the signature of method perform in BaseOp.
The situation is similar to the one we faced in the context of the generic operation-centric approach developed in Section 12.5
There, the trick of an extra self parameter with the correct type was used.
Here, we constrain, by design, instances of BaseOp to be instances of Operation and we let the compiler enforce this constraint and either accept our program or complain accordingly.
Exercise 12.6 Explore the design decision of using self-types in the context of the generic operation-centric approach.
Generally speaking, with Scala, feel free to experiment in any direction that seems suitable.
The language is so expressive that even slight deviations from established knowledge may either lead to interesting results or at least provide a rewarding (in itself) working path.
Also, in Figure 12.6 an abstract factory method is provided, namely newEvalOp, that will be used to create, on demand, new instances of the evaluation operation.
The return type mixes EvalOp with Operation so that the self-type of EvalOp’s.
The evalobject is a convenient functionalwrapper around EvalOp’s apply method.
We normally expect that the addition of new operations poses no difﬁculties.
For example, the familiar string representation operation can be modeled as follows:
Again, the explicit self-type reference is mandatory, in order to preserve the correct semantics, and we have used the same recipe with the factory method newReprOp and the functional object repr.
Exercise 12.7 Create a second operation extension and provide a combination of the two operations by a proper mixin.
We now turn to the normally difﬁcult dimension, since we are in an operationcentric approach, of adding new data.
Actually, the case is rather easy, as the following implementation of the expr ::= expr '+' expr grammar rule shows:
Exercise 12.8 Provide a combination of a data extension with an operation extension.
We have presented the expression problem, which we believe is a fundamental design issue any software engineer should be aware of.
While tackling the problem,we have progressively used language features existing in.
The latter reveal the undeniably rich expressiveness of the Scala language.
In order to follow the examples presented in this chaptermore easily,we have used a common language thatmodels our problem domain, namely a small expression language.
In this direction, the naming of our traits and classes is consistent across all of the presented attacks on the expression problem.
In our opinion, the essence of the expression problem reveals a fundamental need: to come up with expressive designs that can model it; designs that should be based on reusable and extensible components.
Several questions emerge and one of them is: Since patterns play a fundamental role in modeling the problem (either the Interpreter or Visitor), can we provide reusable and extensible pattern implementations that can be tailored to our needs? Can we provide patterns as a generic library that can be further customized?
In this chapter we will explain why symbolic computation is interesting and what it can achieve, and then we are going to present a simple system that can differentiate functions.
In the beginning of the twentieth century, the great German mathematician David Hilbert askedwhether it would be possible to devise amethod to solvemechanically any diophantine equation, that is, any polynomial equationwith integer coefﬁcients.
In other words, he asked whether it is possible to solve any diophantine equation by dully following a clerical procedure.
In fact, Hilbert was dreaming of a fully mechanized mathematical science.
Unfortunately for Hilbert it has been shown that one cannot construct a general algorithm to solve any diophantine equation.1
A consequence of this proof was that the dream of a fully mechanized mathematical science was not feasible.
Nevertheless, certain problems of mathematics can be solved by purely mechanical methods.
For example, it has been demonstrated that certain operations like differentiation and integration can be performed mechanically.
In general, such systems are known as symbolic computation or computer algebra systems.
MathematicaTM and MapleTM are two very popular symbolic computation systems that are used by many people almost every day.
The reader interested in the details of this and related issues should consult a specialized book (for example, see [72])
For instance, although all science students learn how to differentiate and integrate functions, still many of them have difﬁculty ﬁnding the derivative and especially the indeﬁnite integral of some functions.
Of course, there are much more difﬁcult problems that can be solved relatively easily with symbolic computation systems, but these will not concern us here.
In addition, it is known that such systems employ techniques traditionally employed in Artiﬁcial Intelligence, thus, they seem to exhibit some sort of intelligence.
Again, whether this is indeed intelligence or not is something that will not concern us here.
Systems of symbolic computation are similar to modern programming language processors.
First of all, they read strings that belong to some language (for example, a language describing functions)
Second, they transform these strings into an internal representation (for example, some sort of parse tree)
After this, they transform the input using transformation and rewrite rules.
In the end, they ought to deliver their result in a form that is at least as readable as the strings of the input language.
For example, if someone uses a system that differentiates functions, when one enters.
Let us now outline what are the steps involved in the construction of a rudimentary symbolic computation system.
First of all,we need to describe precisely the grammar of the input language.
Here we have two choices: to deﬁne an external DSL or an internal DSL.
To keep things simple, we have opted to deﬁne an external DSL.
Next we need to decide how to get input and how to process it.
The simplest solution is to have an interactive system that takes one expression at a time, processes it, and produces output.
As expected, the program should stop when the user presses an end-of-input character.
Inmost cases users expect new systems to be able to understand input in some standard form.
For example, it is quite realistic to expect that a system that performs symbolic differentiation will be able to understand input in either TEX’s notation or the notation employed in most programming languages.
Again to keep things simple, we will use a subset of the notation employed by most programming languages.
In addition, since most common programming languages do not include.
Exercise 13.2 Write down a parser for the grammar above.
As in other similar cases, we need to deﬁne a case class hierarchy that will reﬂect the syntax of expressions.
At the top of the hierarchy, we need a sealed abstract class for obvious reasons:
Next we need to deﬁne classes that will handle the various syntactic entities that belong to syntactic class Primary.
First we need to deﬁne a module that will handle variables:
We have decided not to distinguish numbers and so to have only one class for numbers:
If we want to introduce more features, then we can augment this hierarchy accordingly.
Although it is not difﬁcult to see how functions can be represented by instances of classes of this hierarchy, still we believe it is instructive to present a few examples:
Although we have decided to design an external DSL, still it is quite instructive to see how we could implement an internal DSL.
In addition, we need to redeﬁne class Chi – it is completely unnatural to type Chi.
Clearly, we have not instructed Scala how to mix #s with numbers.
As expected, an implicit conversion (see Section 3.6.3) will do the job:
Similarly, we need to deﬁne singleton objects like the following one for all functions that our system is supposed to understand:
Note the override valmodiﬁers for the argument,needed to deﬁne the singleton correctly.
Finding the derivative of a function in most cases is a straightforward task.
Nevertheless, there are few cases like (sinx)cosx where the way to go is not that obvious.
In calculus, if f is a function of one variable, say x , then df /dx denotes its derivative.
Table 13.1 shows how one can ﬁnd the derivative of some basic functions and some.
Table 13.1 Derivatives of basic functions and combinations of functions.
Although this table is by no means complete, it includes the necessary information for our little programming project.
For a complete list of all (?) possible cases, one should consult any standard calculus textbook (for example, see [67])
Let us deﬁne a function that can compute the derivative of a given function:
Although the output produced by function D is correct, it is cluttered upwith useless “information.” For example, when x+1 is fed to D, the result will be.
This means that we have to simplify the result produced by this function.
Before proceeding with the deﬁnition of a function that does the actual simpliﬁcation, let us see what kind of simpliﬁcations can be performed.
First of all, we need to get rid of zeros and ones in additions and multiplications, respectively.
Thus, it is almost mandatory to deﬁne a function that will pretty-print expressions.
The easiest way to code a pretty-printer is to yield a string representation of each type of expression and, in certain cases, to surround subexpressions in parentheses:
By feeding this expression to the function just deﬁned, we will get the following string which will be transformed by pretty to.
Unfortunately, this is not pretty at all! In the case of a complex expression, the result will be cluttered with parentheses.
A way to solve this problem is to take into account the precedence of the various operators involved.
First of all let us deﬁne a function that computes the precedence of the various operators:
As is evident, the bigger the return value the higher the precedence of the operator.
Next we need to use these functions in order to decide whether a subexpression must be enclosed in parentheses when it is printed.
The idea is very simple – we compute the precedence of a subexpression and if its precedence is less than the precedence of the operator, then we enclose the subexpresion in parentheses.
And the following functions implement the same idea for unary operators:
The readermay have noticed that we have tackled the pretty-printing problem by dividing the task into smaller subtasks and solving the subtasks ﬁrst.
The complete solution is then a synthesis of the smaller solutions.
One can say that this is a typical example of the divide-and-conquer programming methodology.
Exercise 13.6 Change the deﬁnition of expressions, so that each expression type deﬁnes its precedence.
Now that we have solved all the subproblems involved (we assume that the reader has constructed the parser of Exercise 13.2), we can proceed and complete our programming project.
Again, we need to use some standard Java classes to handle input:
An InputStreamReader is a way to go from byte streams to character streams: it reads bytes and decodes them into characters using a speciﬁed character set (a Unicode character set by default)
Finally, a BufferedReader can read text from a character-input stream while being able to buffer input so as to provide for the efﬁcient reading of characters and whole lines.
Assume that we want to extend our system so as to be able to compute partial derivatives.
First of all, we need to replace the deﬁnition of Chi with something more ﬂexible.
In particular, we need to deﬁne a class that can be parametrized, such as the following:
Obviously, we need to rewrite the deﬁnition of function D to reﬂect this change.
In addition, function D needs to have a second argument that will correspond to the variable with respect to which it will differentiate its ﬁrst argument.
The last change in the code regards the handling of class Var.
In general, if x and y are independent variables, then the partial derivative of y with respect to x is zero and the partial derivative of x with respect to x equals one, or more compactly.
The skeleton code that follows shows how we have implemented the changes just described.
Exercise 13.8 Implement the missing cases in the previous function deﬁnition.
If we want to compute the partial derivative of some function f (x ,y) ﬁrst with respect to x and then with respect to y , we need to use an expression like the following:
In this chapter we have used Scala’s facilities to design and implement a simple algebraic system.The approach taken for differentiation is straightforward andprobably.
In fact, it is common practice to do it in this way in programming courses teaching Prolog and/or functional programming languages.
Exercise 13.9 Deﬁne dual numbers in Scala and implement their arithmetic as deﬁned above.
Then write an algorithm for differentiation of polynomials that takes into account the above property.
The Maclaurin series for any polynomial is the polynomial itself, so we can symbolically produce their derivative.
Our main symbolic manipulation has concentrated on differentiation but one should expect a computer algebra system to treat integration as well.
Unfortunately, as opposed to the exact differentiation rules, integration does not enjoy such a generic treatment.
Nevertheless, the set of known functions that are integrated exactly is not small.
The reader is invited to consult any general textbook in the ﬁeld for more details (for example, see [29])
In addition, we suggest the excellent overview of the ﬁeld of symbolic integration by the late Manuel Bronstein [10]
The termmultimedia refers to the integration of multiple forms of media, including text, graphics, audio, video, etc.
For example, an audio ﬁle is a typical example of a media ﬁle.
Typically one needs a codec to encode and/or decode a digital data stream.
In most cases, codecs are native libraries and this why it is not trivial to use them.
In addition, many common media codecs are proprietary, which poses yet another obstacle in the creation of media applications.
A simple solution is to use the Java Media Framework (JMF)
This includes native libraries for many common codecs that include codecs for the reproduction of MP3 ﬁles, QuickTime ﬁles, etc.
The following simple program shows how to program a trivial MP3-player using the JMF:
The essence of the code just presented is the few lines inside the try command.
In a nutshell, we create a new player capable of playing an MP3 ﬁle that is stored in a ﬁle whose name is supplied as a command line argument.
We create an instance of java.io.File to generate an object that will be used by the player.
Method toURI constructs a URI from an abstract representation of a ﬁle while method toURL creates a URL.
Escaping characters that are illegal in URLs is done if these methods are invoked in this order.
Once the new player is constructed, one can start playing the MP3 audio ﬁle.
Unfortunately, the JMF is not up-to-date and a better solution would be to use native libraries.
For example, one can use the libmpg123, which was developed by Michael Hipp and Thomas Orgis.
An easy way to do this is to use the Java Native Access framework.
But we do not plan to explain how this can be done.
Readers are very welcome to use all these tools to implement a simple MP3 player.
Let us assume that we have programmed our Scala application and the next major task is to provide it for download, so that people may try it.
What are our options? In fact, there are several parameters to consider.
One such parameter relates to whether we will use an installer creator in order to make a click-and-go executable.
Providing an installer is quite common if indeed what we have is an application and less common if our product is just a library.
Another parameter to consider is what assumptions we make on the requirements for the end-user’s client machine.
In this appendix we will concentrate on that last point and in particular what to do if a Scala installation at the client’s machine is not always a true assumption (an assumption that not always evaluates to true)
Distributing an application to an end user is different from distributing it to a developer.
Scala is not at the moment an integrated part of any operating system and so we cannot rely on the user’s open mind, curiosity and even a tendency for language exploration in order to assume that Scala is installed at people’s computers.
We will show a technique to incorporate all the needed runtime services of Scala inside one’s application, so that when we distribute the application, we distribute the relevant part of Scala as well, in just one package.
Of course, the trivial way would be just to copy the contents of the Scala-provided Java Archives (jar) inside our application jar ﬁle.
This way, though, we would not take advantage of great open-source projects that are better suited for the job of automatically deciding which parts to include and, as a consequence, we would miss the opportunity to familiarize ourselves with these projects.
Proguard1 is an open-source program that can shrink, optimize, obfuscate and preverify Java classes.
Shrinking is achieved by removing unused ﬁelds, methods and even whole Java classes.
Several optimizations can be performed, such as constant expression evaluation, unused.
Obfuscation prevents reverse engineering by stripping off any debugging information and.
When a class is loaded by the JVM, it is veriﬁed for correctness.
This is something that may slow down the whole class-loading procedure.
This piece of information can be discovered during class-loading, thus saving time and space.
Proguard deﬁnes an intuitive and easily mastered conﬁguration language that we can use to tailor its execution to our needs, at a level of ﬁne granularity.
Using an example directly from its documentation, we can preserve all applets in a jar ﬁle with the following conﬁguration option:
Of all the proguard features, the one we are interested in now is shrinking.
Our requirement is that given a jar ﬁle containing our application, we wish to generate a new archive which will, in addition to the application, include all the needed class ﬁles from a Scala distribution.
As a test application, we will use a handy script, shown in Figure B.1
The ﬁgure actually contains a skeleton, the missing parts of which we will ﬁll in shortly.
The script is intended as a command line utility, named ﬁndcmd, which takes a series of names as arguments and searches the executable PATHs for programs that match the name.
Here,we have searched for executables in the PATH that contain the string“exe.”The command was actually executed in one of the authors’MacBook, with the macports suite installed under folder /opt/local.
After splitting up the PATH according to the platform’s path separation character (semicolon “;” for Windows and colon “:” for Unix variants), the ﬁrst implementation “hole” has to do with keeping only those PATH elements that are directories and actually contain some ﬁles:
The second missing implementation part, and the most interesting one, selects only the nonempty directories in the PATH:
What we do ﬁrst is to see whether the name given in the command line is a substring of a ﬁle name.
If this fails, then we go for a more general regular expression check.
Now that the implementation is complete, the script can be run using.
We are almost complete before delving into proguard conﬁguration and execution details, except from one missing detail: we need a jar ﬁle containing the compiled code of our script.
To this end, the scala executable can be very handy with its wealth of command line options.
Xscript name This compiles the input ﬁle as a script, wrapping the scala code into an object with the given name.
So, before we move to the next step, let us just copy this jar to our working folder, i.e.
As you can see, the conﬁguration Domain Speciﬁc Language is primarily made of commands that start with a dash, like -injars.
This ﬁle is assumed as part of our application and will be included in the ﬁnal jar.
The ﬁrst use has to do with our, just generated, script jar.
The second use regards the scala library classes that we want to incorporate in the ﬁnal jar.
These dependencies mentioned here will not be included in the ﬁnal jar, but are assumed to exist at any machine that will run our application.
This is normally the case, since Java tends to be ubiquitous.
After all, our exercise in this appendix assumes that Java, at least, is installed.
Notice how we parametrically deﬁne the location of the Java runtime libraries, using the <java.home> property.
Also, there is a subtle conﬁguration point, regarding the exact location and name of the libraries under the <java.home> directory hierarchy.
The libraries given in Figure B.2 are in fact valid for a MacOS X machine, referring.
Figure B.2 Proguard conﬁguration used to produce a standalone application.
Unfortunately, for the moment, a lot of warnings are generated when processing our Scala application, so the command is mandatory.
In effect, we inform proguard which classes we want to be included in the ﬁnal archive.
In order not to compute resources, proguard detects if the output jar ﬁle is newer (in the underlying ﬁle system) than the conﬁguration ﬁle and in such a case does not even proceed with.
By using -forceprocessing, we make our intentions clear that we always want proguard to do its normal processing.
As a side note, from the source script ﬁle to the compiled jars ﬁles the ﬁle size has a clear tendency to increase.
We have shown how to produce a standalone jar ﬁle, containing a Scala application and all the Scala runtime facilities needed to run the application.
Can you verify the results? How much faster is using java than using scala?
In this appendix, we show how to use both the Scala compiler (scalac) and the Scala interpreter (scala) by experimenting with their command line arguments.
Part of our presentation is based on the man pages coming with every Scala distribution.
The good news is that Scala is indeed scalable in many ways and, after all, there is no harm in advertising features that already exist.
One such dimension of scalability has to do with the provided tools and how they can be used to increase the overall experience of programming in Scala.
We will see that the features provided give a pleasant feeling that the language “grows” to our needs.
For the following, we assume that Scala is installed under a folder denoted by the value of the environment variable SCALA_HOME.
It is good practice to set this variable, since other applications that use Scala may depend on it.
Even the interpreter uses it internally in order to give the impression of a scripting environment.
As expected, it is packed with a wealth of command line options.
Using scalac with no options and parameters informs us of all the options.
In the following, we describe the functionality provided by the majority of the options.
Table C.1 The options of scalac, as reported when we call the executable with no command line arguments.
Option -g lets the user decide how much debugging info will be generated into .class ﬁles.
For example, a source ﬁle named testwarn.scala with the following code.
Option -verbose is used when we want to inspect what the compiler is doing.
For example, adding a -verbose to the previous command line generates a series of lines:
This option is interesting since it provides an internal look at what the compiler does.
In fact, scalac is built around a ﬂexible and open architecture.
The compiler runs in several phases, like parsing (which generates an Abstract Syntax Tree representation, AST for short, of the source ﬁles), typing, intermediate code generation (the ICode that we can see in the output) and ﬁnal bytecode generation for the JVM.
Anyone can write plugins that manipulate the Abstract Syntax Tree.
Option -deprecation is a boolean one, accepting these values: on, off, yes and no.
Deprecated APIs should be marked as such by using the @deprecated annotation.
The idea behind the -unchecked option is to inform the user about conditions related to type erasure.
Using our sample code in testwarn.scala, we can compile with -unchecked and observe the extra information that scalac provides:
Option -classpath provides the same functionality as the counterpart in Java’s compiler, javac.
Usual rules for path separation apply, for example the use of a colon under Unix and semicolon under Windows.
If no class path is speciﬁed, then the current directory is assumed to be the one and this is in alignment with javac.
Option -bootclasspath should provide a class path that will be used to locate the standard Scala classes, as for example scala.List.
We can givemultiple or alternative source ﬁle paths with the relevant -sourcepath option.
In the case when we need to specify a particular folder where scalac will place the generated .class ﬁles, then option -d is handy.
Also, if our source ﬁles are stored with an encoding other than the default, then we can use option -encoding.
The target platform (back-end, in compiler terminology) for which code is generated can be given with the -target option.
The ﬁrst two refer, of course, to a JVM environment.
Target msil refers to a .Net environment, while the acronym cldc comes from “Connected Limited Device Conﬁguration,” which forms the basis of the Java Platform for devices with constrained resources.
If no value is given in the command line, then jvm-1.5 is assumed.
Option -explaintypes instructs the compiler to generate a sequence of statements, showing the exact decisions that led to a type error.
For example, let us assume we have a ﬁle named testtyperr.scala with the following contents:
We cannot assign an integer list to a string list, since there is no subtype relation between List[Int] and List[String]
For this to succeed, the type of the value we try to assign to strListmust be either the exact type of strList, that is List[String], or a subtype of it.
Since the given value is of type List[Int], scalac tries to see whether1
Now, since the actual generic type of lists, as speciﬁed in the Scala core library, is List[+A], which is covariant in its type parameter, it would be sufﬁcient to have.
But, clearly, this does not hold and so scalac complains with a type mismatch error.
Following the tradition of the Java compiler, which provides a set of “nonstandard” options, scalac provides a similar set of “advanced” options, as they are described.
Note that in these debug messages, scalac is a bit inconsistent with what operator represents subtyping.
Table C.2 A subset of the advanced options of scalac.
Here we will mainly discuss options related to compiler phases.
The Scala compiler is organized as a composite component that is executed in phases and it deﬁnes several subcomponents that are responsible for each one of these phases.
We have already seen a few of the phases when examining the output of the -verbose option, where we met phase names like namer, typer and pickler.
As a side note for Unix users, the options are printed in the standard error stream, instead of the standard output stream, so in case we want to pipe through some command line ﬁlter, we need to make an indirection, as in scalac -X 2>&1
We can obtain a list of all the available phases by using the -Xshow-phases option:
Providing a description of the purpose and inner workings of all these phases is beyond the scope of this book.More information can be found at the Scala web site.
After parsing, the source code is transformed to an intermediate AST representation.
Each phase then transforms this abstract syntax tree, potentially altering information on the symbols the tree contains, augmenting the tree with extra nodes or pruning existing nodes.
In the case that we wish to see how the compiler “sees” our initial program after some particular phase, then we have to include option -Xprint:<phase> in the command line.
For the sake of presentation, we avoid explicit typing, especially when using higherorder functions like map and reduceLeft.
Explicit typing of the factorial method is necessary, since the Scala type inference algorithm requires it whenever we deﬁne a recursive method.
Using -Xprint:namer The namer phase is responsible for declaring compiler internal symbols from our source code:
Respectively, the subtraction operator - is transformed to a call to method $minus.
The strange-looking names with the dollar signs are synthetic names generated on-the-ﬂy by scalac.
User programs should not deﬁne identiﬁers which contain “$” characters.
Using -Xprint:typer The next phase,typer, is responsible for type inference.
It makes sure that the types a programmer has deﬁned in the source code are correct and tries to ﬁnd, from local coding context, missing types.
This output certainly looks more noisy than the previous one.
For instance, the type of the anonymous function _+_, which we use as a parameter to reduceLeft.
The above is a function of two Int arguments, producing an Int result.
These compiler plugins are software components that can be injected between the several compiler phases and whose role is to provide some new functionality.
From Table C.2, all the plugin-related options start with -Xplugin.
Disabling assertions Assertions, that is conditions that are checked and for which an exception is thrown if not found to hold, are enabled by default.
Everyday practice, however, shows that people usually do not follow this advice and prefer to retain assertions all the time.
Compiling as a script Sometimes it is very convenient to write our little script in the most straightforward way and then use the -Xscript option to have the compiler wrap it as a normal Scala object.
We have already used this technique in Appendix B, where the small findcmd script was simultaneously wrapped as an object and saved as jar ﬁle.
We must take special care to not include a package deﬁnition in the script, like in the following case:
The correct way to achieve the same functionality is to have a simpler script.
Also, try to verify the packaged declaration of object printargs.
They are either meant to be used by the compiler development team for debugging or are considered experimental.
In any case they are subject to change without any notice.
Nevertheless, as we will see, they can be very useful.
Using -Ybrowse:typer This pops up a graphical application that shows the abstract syntax tree generated by scalac after successfully parsing the input ﬁle.
Table C.3 A subset of the private options of scalac.
Figure C.1 Using option -Ybrowse on ﬁle testprintphase after typer phase.
The Scala interpreter inherits all command line options from scalac.
This is easy to understand, since the underlying implementation makes heavy use of the compiler.
When running the interpreter, using the scala command, we either specify a script ﬁle or object to run, along its arguments, or we enter an interactive shell.
Option -howtorun takes as values one of script, object or guess.
If we use the ﬁrst, then the provided parameter denotes a script ﬁle.
If we use the second, then the provided parameter denotes an object name that will be pulled from the class path and run subsequently.
The third, guess, means that the interpreter will do its best to guess the situation.
Option -i is used only when invoking scala in order to enter the interactive shell.
It takes one parameter that is a ﬁle name to be preloaded before entering the interactive session.
For example, if we have a bunch of standard code, which we wish to evaluate every time the scala executable is ﬁred up, then this is a good place to do the job.
Option -e treats the next argument as inline Scala code, which is evaluated at once.
It compiles and packs everything to a .jar ﬁle, which is automatically reused the next time we issue the same command.
The exception to the above rule is when the source code itself has changed after the time of the original script ﬁle generation.
In the case when we need to set a Java-wide system property, then the -Dproperty=value notation exists.
Finally, option -nocompdaemon instructs Scala not to use a faster version of the compiler, if one is needed.
For example, when launching a Scala script, the script normally has to be compiled ﬁrst, so at that point either the normal scalac or a faster version is used.
This compiler, named fsc (Fast Scala Compiler), stays resident in memory and thus does not incur the time cost related to the starting up of scalac.
In the ﬁrst part, we present the grammar of lexical entities while in the second part we present the rest of the grammar.
Apart from some small typographical adjustments, the grammar is identical to the one presented in the The Scala Language Speciﬁcation Version 2.7
The expression problem revisited – four new solutions using generics.
Subtle type inferring issues Can we do better than wrapping?
