This book is an absolute gem and should be required reading for anybody looking to transition from OO to FP.
It is an extremely well-built safety rope for those crossing the bridge between two very different worlds.
This book sticks to the meat and potatoes of what functional programming can do for the object-oriented JVM programmer.
The functional patterns are sectioned in the back of the book separate from the functional replacements of the object-oriented patterns, making the book handy reference material.
As a Scala programmer, I even picked up some new tricks along the read.
This book is good for those who have dabbled a bit in Clojure or Scala but are not really comfortable with it; the ideal audience is seasoned OO programmers looking to adopt a functional style, as it gives those programmers a guide for transitioning away from the patterns they are comfortable with.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in this book, and The Pragmatic Programmers, LLC was aware of a trademark claim, the designations have been printed in initial capital letters or in all capitals.
Every precaution was taken in the preparation of this book.
However, the publisher assumes no responsibility for errors or omissions, or for damages that may result from the use of information (including program listings) contained herein.
Our Pragmatic courses, workshops, and other products can help you and your team create better software and have more fun.
For more information, as well as the latest Pragmatic titles, please visit us at http://pragprog.com.
No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior consent of the publisher.
Acknowledgments I’d like to thank my parents, without whom I would not exist.
Thanks also go to my wonderful girlfriend, who put up with many a night and weekend listening to me mutter about code samples, inconsistent tenses, and run-on sentences.
This book would have suffered greatly without a great group of technical reviewers.
Their book, The Pragmatic Programmer, is one of the first books I read when I started my career.
In the Pragmatic Bookshelf, they’ve created a publisher that’s truly dedicated to producing high-quality technical books and supporting the authors who write them.
Preface This book is about patterns and functional programming in Scala and Clojure.
It shows how to replace, or greatly simplify, many of the common patterns we use in object-oriented programming, and it introduces some patterns commonly used in the functional world.
Used together, these patterns let programmers solve problems faster and in a more concise, declarative style than with object-oriented programming alone.
If you’re using Java and want to see how functional programming can help you work more efficiently, or if you’ve started using Scala and Clojure and can’t quite wrap your head around functional problem-solving, this is the book for you.
Before we dig in, I’d like to start off with a story.
This story is true, though some names have been changed to protect the not-so-innocent.
The site isn’t down, but an awful lot of alarms are going off.
We trace the problems to changes someone made to a third-party API we use.
The changes are causing major data problems on our side; namely, we don’t know what the changes are and we can’t find anyone who can tell us.
It also turns out the system that talks to the API uses legacy code, and the only guy who knows how to work on it happens to be away on vacation.
I start up a Clojure REPL and use it to poke around the problem API.
Ten minutes later, my grandboss pokes his head into my office.
Another ten minutes pass by when my great-grandboss pokes his head into my office.
I get a half hour of silence before the CTO pokes his head into my office.
I whip up a way to keep the data clean until the legacy developer gets back and can put together a proper fix.
The support calls stop coming in, and everyone relaxes a bit.
A week or so later at an all-hands meeting, the great-grandboss thanks me for the Java program I wrote that saved the day.
The REPL, Clojure’s interactive programming environment, helped a lot in this story.
However, lots of languages that aren’t particularly functional have similar interactive programming environments, so that’s not all there is to it.
Earlier on, I had written a small instance of domain-specific language for working with these particular APIs that helped me explore them very quickly even though they’re very large and it was difficult to figure out where the problem might lie.
We’ll start with an introduction to patterns and how they relate to functional programming.
Then we’ll take a look at an extended example, a small web framework called TinyWeb.
We’ll first show TinyWeb written using classic object-oriented patterns in Java.
We’ll then rewrite it, piece by piece, to a hybrid style that is object oriented and functional, using Scala.
It will let us see how several of the patterns we cover in this book fit together in a comprehensive manner.
We also use it to introduce the basics of Scala and Clojure.
Finally, since we’ll transform TinyWeb from Java to Scala and Clojure bit by bit, it gives us a chance to explore how to easily integrate Java code with Scala and Clojure.
The remainder of the book is organized into two sections.
These take weighty object-oriented patterns and replace them with concise functional solutions.
Peter Norvig, author of the classic Lisp text Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp [Nor92], current director of research at Google, and all-around very smart guy, pointed out in Design.
Patterns in Dynamic Languages that expressive languages like Lisp could turn classic object-oriented patterns invisible.1
Unfortunately, not many people in the mainstream software development world seem to have read Norvig, but when we can replace a complicated pattern with something simpler, it makes sense that we should.
It makes our code more concise, easier to understand, and easier to maintain.
These patterns run the gamut from tiny—patterns consisting of a line or two of code—to very large—ones that deal with entire programs.
Sometimes these patterns have first-class language support, which means that someone else has done the hard work of implementing them for us.
This means that functional patterns are more lightweight than object-oriented patterns.
You still need to understand the pattern before you can use it, but the implementation becomes as simple as a few lines of code.
The patterns are laid out using the following format, with some exceptions.
The Intent subsection provides a quick explanation of the intent of this pattern and the problem it solves.
Here is where you’ll find a deeper motivation for the pattern and an explanation of how it works.
This subsection contains samples of the pattern—for object-oriented patterns, we first show a sketch of the object-oriented solution using either class diagrams or a sketch of the Java code before showing how to replace them in Clojure and Scala.
Functional patterns will be shown in Clojure and Scala only.
This area provides a summary and discussion of interesting points about the pattern.
Look here for a list of references for further information on the pattern.
This provides a list of other patterns in this book that are related to the current one.
Many of the patterns in this book can be applied using other languages with functional features, but we will focus on Clojure and Scala for our examples.
We focus on these two languages for quite a few reasons, but first and foremost because they’re both practical languages suitable for coding in production environments.
Both Scala and Clojure run on a Java virtual machine (JVM), so they interoperate well with existing Java libraries and have no issues being dropped into the JVM infrastructure.
This makes them ideal to run alongside existing Java codebases.
Finally, while both Scala and Clojure have functional features, they’re quite different from each other.
Learning to use both of them exposes us to a very broad range of functional programming paradigms.
It’s statically typed and combines a very sophisticated type system with local type inference, which allows us to often omit explicit type annotations in our code.
It has Lisp’s powerful macro system and dynamic typing, but Clojure has added some new features not seen in older Lisps.
Most important is its unique way of dealing with state change by using reference types, a software transactional memory system, and efficient immutable data structures.
While Clojure is not an object-oriented language, it does give us some good features that are common in object-oriented languages, just not in the way we may be familiar with.
For instance, we can still get polymorphism through Clojure’s multimethods and protocols, and we can get hierarchies through Clojure’s ad hoc hierarchies.
As we introduce the patterns, we’ll explore both of these languages and their features, so this book serves as a good introduction to both Scala and Clojure.
From there you can jump around, pattern by pattern, as needed.
Once you’re through the introduction, you can use it to look up a pattern that solves the particular problem you need to solve.
As you work through the book, you can download all the included code files from http://pragprog.com/titles/mbfpp/source_code.
On the book’s home page at http://pragprog.com/book/mbfpp, you can find links to the book forum and to report errata.
Also, for ebook buyers, clicking on the box above the code extracts downloads the code for that extract for you.
Patterns and Functional Programming Patterns and functional programming go together in two ways.
First, many object-oriented design patterns are simpler to implement with functional programming.
Functional languages give us a concise way of passing around a bit of computation without having to create a new class.
Also, using expressions rather than statements lets us eliminate extraneous variables, and the declarative nature of many functional solutions lets us do in a single line of code what might take five lines in the imperative style.
Some object-oriented patterns can even be replaced with a straightforward application of functional language features.
Second, the functional world also has its own set of useful patterns.
These patterns focus on writing code that avoids mutability and favors a declarative style, which helps us write simpler, more maintainable code.
The two main sections of this book cover these two sets of patterns.
Don’t the patterns we know and love extend across languages? Aren’t they supposed to provide common solutions to common problems regardless of what language you are using? The answer to both questions is yes, so long as the language you are using looks something like Java or its ancestor, C++
With the emergence of more expressive language features, many of these patterns fade away.
Classic Java itself has a great example of a language feature replacing a pattern: foreach.
That’s not to say that foreach loops are exactly equivalent to the Iterator.
Developers prefer the built-in foreach loops for the common-sense reasons that they are less work to implement and are less error prone.
Many functional language features and techniques have a similar effect on coding projects.
While they may not be the exact equivalent to a pattern, they often provide developers with a built-in alternative that solves the same problem.
Similar to the foreach-Iterator example, other language features give programmers techniques that are less work and often produce code that is more concise and easier to understand than the original.
Adding functional features and techniques adds more tools to our programming toolbox, just as Java 1.5 did with its foreach loop but on a grander scale.
These tools often complement the tools we already know and love from the object-oriented world.
The second set of patterns we cover in this book, native functional patterns, describes the patterns that evolved out of the functional style.
These functional patterns differ from the object-oriented patterns you may be familiar with in a few key ways.
The first, and most obvious, is that functions are the primary unit of composition, just as objects are in the object-oriented world.
The patterns from Design Patterns: Elements of Reusable Object-Oriented Software [GHJV95] (one of the original drivers of the software patterns movement) are generally templates that define a few classes and specify how they fit together.
They often don’t concern themselves either with very small issues that encompass just a few lines of code or with very large issues that encompass entire programs.
The functional patterns in this book cover a much broader range, as some of them can be implemented in a line or two of code.
Others tackle very big problems, such as creating new, miniature programming languages.
The range is in line with the book that started the patterns movement in general, A Pattern Language [AIS77]
Before we dig into the various patterns in this book, let’s spend some time getting familiar with functional programming itself.
At its core, functional programming is about immutability and about composing functions rather than objects.
Have first-class functions: First-class functions are functions that can be passed around, dynamically created, stored in data structures, and treated like any other first-class object in the language.
Favor pure functions: Pure functions are functions that have no side effects.
A side effect is an action that the function does that modifies state outside the function.
Compose functions:  Functional programming favors building programs from the bottom up by composing functions together.
Statements do not and exist only to control the flow of a program.
Use Immutability:  Since functional programming favors pure functions, which can’t mutate data, it also makes heavy use of immutable data.
Instead of modifying an existing data structure, a new one is efficiently created.
Transform, rather than mutate, data:  Functional programming uses functions to transform immutable data.
One data structure is put into the function, and a new immutable data structure comes out.
This is in explicit contrast with the popular object-oriented model, which views objects as little packets of mutable state and behavior.
A focus on immutable data leads to programs that are written in a more declarative style, since we can’t modify a data structure piece by piece.
Here’s an iterative way to filter the odd numbers out of a list, written in Java.
Notice how it relies on mutation to add odd numbers to filteredList one at a time.
The functional version is obviously much shorter than the object-oriented version.
As mentioned previously, this is because functional programming is declarative.
That is, it specifies what should be done rather than how to do it.
For many problems we encounter in programming, this style lets us work at a higher level of abstraction.
However, other problems are hard, if not impossible, to solve using strict functional programming techniques.
If you put a program in, you expect to get the same machine code out every time.
If we got the same results from a Google search query every time, we’d be stuck with a late 1990s view of the Web, which would be quite tragic.
For this reason, functional programming languages tend to lie on a spectrum of strictness.
Of the two languages we’re using in this book, Clojure is purer on the functional spectrum; at least, it is if we avoid its Java interoperability features.
For example, in idiomatic Clojure, we don’t mutate data as we do in Java.
Instead, we rely on an efficient set of immutable data structures, a set of reference types, and a software transactional memory system.
This allows us to get the benefits of mutability without the dangers.
Scala has more support for mutable data, but immutable data is preferred.
For instance, Scala has both mutable and immutable versions of its collections library, but the immutable data structures are imported and used by default.
Here is where we introduce all of the patterns we cover in the book and give a brief overview of each.
This is a great list to skim if you already have a specific problem you need to solve in a functional way.
This section shows how to replace common object-oriented patterns with functional language features.
This generally cuts down on the amount of code we have to write while giving us a more concise code to maintain.
Here we replace common types of functional interfaces, such as Runnable or Comparator, with native functional features.
The first type, higher-order functions, allows us to pass functions around as first-class data.
The second, anonymous functions, allows us to write quick one-off functions without giving them a name.
These features combine to let us replace most instances of Functional Interface very concisely.
With this pattern we replace instances of Functional Interface that need to carry around some bit of state—we introduce another new functional feature, closures, which lets us wrap up a function and some state to pass around.
Replacing Command encapsulates an action in an object—here we’ll take a look at how we can replace the object-oriented version using the techniques introduced in the previous two patterns.
Here we carry data using the classic Java convention, a class full of getters and setters—this approach is intimately tied up with mutability.
Here we’ll show how to get the convenience of a Java Bean along with the benefits of immutability.
Replacing Iterator gives us a way to access items in a collection sequentially—here we’ll see how we can solve many of the problems we’d solve with Iterator using higher-order functions and sequence comprehensions, which give us solutions that are more declarative.
This pattern defines the outline of an algorithm in a superclass, leaving subclasses to implement its details.
Here we’ll see how to use higher-order functions and function composition to replace this inheritance-based pattern.
In this pattern we define a set of algorithms that all implement a common interface.
This allows a programmer to easily swap out one implementation of an algorithm for another.
In this pattern we discuss how to replace Null Object and talk about other types of null handling—in Scala, we take advantage of the type system using Option.
In Clojure, we rely on nil and some language support to make it more convenient to deal with.
Replacing Decorator adds new behavior to an object without changing the original class.
Here we’ll see how to achieve the same effect with function composition.
Replacing Visitor makes it easy to add operations to a data type but difficult to add new implementations of the type.
Here we show solutions in Scala and Clojure that make it possible to do both.
This pattern injects an object’s dependencies into it, rather than instantiating them inline—this allows us to swap out their implementations.
We’ll explore Scala’s Cake pattern, which gives us a DI-like pattern.
Tail Recursion is functionally equivalent to iteration and provides a way to write a recursive algorithm without requiring a stack frame for each recursive call.
While we’ll prefer more declarative solutions throughout the book, sometimes the most straightforward way to solve a problem is more iterative.
Here we’ll show how to use Tail Recursion for those situations.
Mutual Recursion is a pattern where recursive functions call one another.
As with Tail Recursion, we need a way to do this without consuming stack frames for it to be practical.
Here we’ll show how to use a feature called trampolining to do just that.
Filter, map, and reduce are three of the most commonly used higher-order functions.
Used together, they’re a very powerful tool for data manipulation and are the inspiration for the popular MapReduce data-processing paradigm.
In this pattern, we’ll see how they can be used on a smaller scale.
Functional programming eschews mutability; so instead of mutating a data structure, we take one immutable data structure, operate on it, and produce a new one.
Chain of Operations examines the differing ways to do so in Scala and Clojure.
Higher-order functions can create other functions using the Function Builder pattern.
Here we’ll show some common instances of the pattern that are built into many functional languages, and we’ll explore a few custom ones.
This pattern caches the results of a pure function invocation to avoid having to do an expensive computation more than once.
Lazy Sequence is a pattern where a sequence is realized bit by bit only as it’s needed.
This allows us to create infinitely long sequences and to easily work with streams of data.
Focused Mutability makes a small critical section of code use mutable data structures to optimize performance.
The need for this is less common than you might think.
Clojure and Scala, backed by the JVM, provide very efficient mechanisms for working with immutable data, so immutability is rarely the bottleneck.
With most languages, it’s impossible to add a new way of doing control flow to the language without modifying the language itself.
Functional languages, however, usually provide a way to create custom control abstractions tailored for specific uses.
The Domain-Specific Language pattern allows us to create a language that is purpose-built for solving a specific problem.
Using a well-designed implementation of domain-specific language is the ultimate solution for often-solved problems, as it lets us program close to the problem domain.
This reduces the amount of code we have to write and the mental friction in transforming our thoughts into code.
We’ll start our journey with a look at an example of a program that makes heavy use of classic object-oriented patterns, a small web framework called TinyWeb.
After introducing TinyWeb, we’ll see how to rewrite it in a hybrid object-oriented and functional style using Scala.
Finally, we’ll move on to a more fully functional style in Clojure.
The first is to see several patterns working together in one codebase before we go into them in more detail.
The second is to introduce basic Scala and Clojure concepts for those unfamiliar with either, or both, of the languages.
A full introduction to the languages is beyond the scope of this book, but this section gives you enough of the basics to understand the majority of the remaining code.
Finally, we’ll work existing Java code into a Scala or Clojure codebase.
We’ll do this by taking the Java version of TinyWeb and transforming it into Scala and Clojure piece by piece.
It’s far from complete, but it should feel familiar to anyone who has worked with any of the popular frameworks, such as Spring MVC.
There’s one little twist to TinyWeb: since this is a book on functional programming, we’re going to do our best to work with immutable data, which can be quite challenging in Java.
The Java version of TinyWeb is a basic MVC web framework written in a classic object-oriented style.
To handle requests we use a Controller implemented using the Template method, which we cover in detail in Pattern 6, Replacing.
Our framework is built around core pieces of data objects, HttpRequest and HttpResponse.
Builder is a standard way of getting immutable objects in Java.
Finally, we’ve got request filters that run before a request is handled and that do some work on the request, such as modifying it.
Our filters also show how to handle changing data using immutable objects.
We’ll start off with a look at our core data types, HttpRequest and HttpResponse.
In this example we’ll only need a body and a response code in our response, so those are the only attributes we’ll add.
The following code block shows how we can implement the class.
Here we use the fluent builder of the type made popular in the Java classic, Effective Java [Blo08]
This approach encapsulates all mutability inside of a Builder object, which then builds an immutable HttpResponse.
While this gives us a clean way of working with immutable data, it’s quite verbose.
For example, we could create a simple test request using this code:
Without using Builder we’d need to pass all of our arguments in the constructor.
This is okay for our small example, but this practice grows unwieldy when working with larger classes.
Another option would be to use a Java Bean–style class with getters and setters, but that would require mutability.
Let’s move on and take a quick look at HttpRequest.
Since the class is similar to HttpResponse (though it lets us set a request body, headers, and a path), we won’t repeat the code in full.
In order to support request filters that “modify” the incoming request, we need to create a new request based off the existing one, since our request objects aren’t mutable.
This method takes an existing HttpRequest and uses it to set starting values for a new builder.
This may seem wasteful, but the JVM is a miracle of modern software engineering.
It’s able to garbage-collect short-lived objects very efficiently, so this style of programming performs admirably well in most domains.
Let’s continue our tour of TinyWeb with a look at view handling.
In a fully featured framework, we’d include some ways to plug template engines into our view, but for TinyWeb we’ll just assume we’re generating our response bodies entirely in code using string manipulation.
First we’ll need a View interface, which has a single method, render()
The experienced object-oriented programmer might grumble about extra effort to get immutable objects, especially if we’re doing it “just to be functional.” However, immutable data doesn’t just fall out of functional programming; it’s a good practice that can help us write cleaner code.
A large class of software bugs boil down to one section of code modifying data in another section in an unexpected way.
This type of bug becomes even more heinous in the multicore world we all live in now.
By making our data immutable, we can avoid this class of bugs altogether.
This is largely due to the fact that Java wasn’t designed with immutability in mind, so it takes a lot of programmer effort to get it.
Still, some popular, high-quality libraries, such as Joda-Time and Google’s collections library, provide excellent support for programming with immutable data.
The fact that both of these popular libraries provide replacements for functionality available in Java’s standard library speaks to the usefulness of immutable data.
Thankfully, both Scala and Clojure have much more first-class support for immutable data, to the extent that it’s often harder to use mutable data than immutable.
We’ll use a List<String> for our values so that a single attribute can have multiple values.
Next we need two classes that are designed to work together using the Strategy pattern: StrategyView and RenderingStrategy.
RenderingStrategy is responsible for doing the actual work of rendering a view as implemented by the framework user.
It’s an instance of a Strategy class from the Strategy pattern, and its code follows:
Now let’s examine the class that delegates to RenderingStrategy, StrategyView.
This class is implemented by the framework and takes care of properly handing exceptions thrown out of the RenderingStrategy.
To implement a view, the framework user creates a new subclass of RenderingStrategy with the right view-rendering logic, and the framework injects it into StrategyView.
It simply swallows exceptions and wraps them in RenderingException so that they can be handled properly at a higher level.
A more complete framework might use StrategyView as an integration point for various rendering engines, among other things, but we’ll keep it simple here.
The Controller itself is a simple interface with a single method, handleRequest(), which takes an HttpRequest and returns an HttpResponse.
We’ll use the Template Method pattern so that users can implement their own controllers.
To implement a controller, a user of the framework extends TemplateController and implements its doRequest() method.
Both the Template Method pattern we used for our controllers and the Strategy pattern we used for our views support similar tasks.
They let some general code, perhaps in a library or framework, delegate out to another bit of code intended to perform a specific task.
The Template Method pattern does it using inheritance, while the Strategy pattern does it using composition.
In the functional world, we’ll rely heavily on composition, which also happens be good practice in the object-oriented world.
However, it’ll be a composition of functions rather than a composition of objects.
The Filter class is a Functional Interface that lets us perform some action on HttpRequest before it’s processed.
For instance, we may want to log some information about the request or even add a header.
It has a single method, doFilter(), takes HttpRequest, and returns a filtered instance of it.
If an individual Filter needs to do something that modifies a request, it simply creates a new one based on the existing request and returns it.
This lets us work with an immutable HttpRequest but gives us the illusion that it can be changed.
Now that we’ve seen all of the pieces of TinyWeb, let’s see how they fit together.
To tie it all together, we’ll use the main class, TinyWeb.
The first is a Map, where the keys are Strings representing request paths and the values are Controller objects.
The second argument is a list of Filters to run on all requests before they are passed to the appropriate controller.
The TinyWeb class has a single public method, handleRequest(), which takes HttpRequest.
The handleRequest() method then runs the request through the filters, looks up the appropriate controller to handle it, and returns the resulting HttpResponse.
A full-featured Java web framework wouldn’t expose a class like this directly as its framework plumbing.
Instead it would use some set of configuration files and annotations to wire things together.
However, we’ll stop adding to TinyWeb here and move on to an example that uses it.
Let’s implement an example program that takes an HttpRequest with a commaseparated list of names as its value and returns a body that’s full of friendly greetings for those names.
We’ll also add a filter that logs the path that was requested.
When the controller receives an HttpRequest, it picks out the body of the request, splits it on commas, and treats each element in the split body as a name.
It then generates a random friendly greeting for each name and puts the names into the model under the key greetings.
This class iterates through the list of friendly greetings generated by the controller and places each into an <h2> tag.
Then it prepends the greetings with an <h1> containing "Friendly Greetings:", as the following code shows:
The LoggingFilter class just logs out the path of the request it’s being run on.
Wiring up a simple test harness that connects everything together into a TinyWeb, throws an HttpRequest at it, and then prints the response to the console gets us the following output.
Now that we’ve seen the TinyWeb framework in Java, let’s take a look at how we’ll use some of the functional replacements for the object-oriented patterns we’ll explore in this book.
This will give us a TinyWeb that’s functionally equivalent but written with fewer lines of code and in a more declarative, easier-to-read style.
We’ll do this a bit at a time so we can show how our Scala code can work with the existing Java code.
The overall shape of the framework will be similar to the Java version, but we’ll take advantage of some of Scala’s functional features to make the code more concise.
In Scala, we’ll stick with the Strategy pattern, but we’ll use higher-order functions for our strategy implementations.
We’ll also see some of the benefits of expressions over statements for control flow.
The biggest change we’ll make is to the view-rendering code.
Instead of using Functional Interface in the form of RenderingStrategy, we’ll use a higher-order function.
Here’s our modified view code in its full functional glory:
It defines a single method, render(), which takes a map representing the data in our model and returns a rendered String.
Next up, let’s take a look at the body of FunctionView.
The code below declares a class that has a constructor with a single argument, viewRenderer, which sets an immutable field of the same name.
The viewRenderer function parameter has a rather strange-looking type annotation, (Map[String, String]) => String.
It says that viewRenderer is a function that takes a Map[String, String] and returns a String, just like the renderView() on our Java RenderingStrategy.
Next, let’s take a look at the render() method itself.
As we can see from the code below, it takes in a model and runs it through the viewRender() function.
Notice how there’s no return keyword anywhere in this code snippet? This illustrates another important aspect of functional programming.
The value of a function is just the value of the last expression in it.
In this example, that expression happens to be a try block.
If no exception is thrown, the try block takes on the value of its main branch; otherwise it takes on the value of the appropriate case clause in the catch branch.
If we wanted to supply a default value rather than wrap the exception up into a RenderException, we can do so just by having the appropriate case branch take on our default, as illustrated in the following code:
Now when an exception is caught, the try block takes on the value of the empty string.
Now let’s take a look at transforming our controller code into Scala.
In Java we used the Controller interface and the TemplateController class.
In Scala, we rely on function composition just like we did with our views by passing in a doRequest() function when we create a Controller:
This code should look fairly similar to our view code.
This is a fairly literal translation of Java into Scala, but it’s not terribly functional because we’re using the try-catch as a statement to set the values of responseCode and responseBody.
Scala provides a more concise way to create these data-carrying classes, called case classes.
Switching over to use the try-catch as a statement, as well as using case classes, can help cut down on our code significantly.
We’ll make both of these changes in our next transformation.
Let’s start by switching over to case classes instead of using the Builder pattern.
We can create new HttpRequest and HttpResponse objects easily, as the following REPL output shows:
At first glance, this might seem similar to using a Java class with constructor arguments, except that we don’t need to use the new keyword.
However, in Pattern 4, Replacing Builder for Immutable Object, on page 62, we dig deeper and see how Scala’s ability to provide default arguments in a constructor, the natural immutability of case classes, and the ability to easily create a new instance of a case class from an existing instance lets them satisfy the intent of the Builder pattern.
Since a try-catch block in Scala has a value, we can use it as an expression rather than as a statement.
This might seem a bit odd at first, but the upshot is that we can use the fact that Scala’s try-catch is an expression to simply have the try-catch block take on the value of the HttpResponse we’re returning.
First, we’ve eliminated a couple of extraneous variables, responseCode and responseBody.
Second, we’ve reduced the number of lines of code a programmer needs to scan to understand which HttpRequest we’re returning from the entire method to a single line.
Rather than tracing the values of responseCode and responseBody from the top of the method through the try block and finally into the HttpResponse, we only need to look at the appropriate piece of the try block to understand the final value of the HttpResponse.
These changes combine to give us code that’s more readable and concise.
Now let’s add in the class that ties it all together, TinyWeb.
Like its Java counterpart, TinyWeb is instantiated with a map of Controllers and a map of filters.
Unlike Java, we don’t define a class for filter; we simply use a list of higherorder functions!
Also like the Java version, the Scala TinyWeb has a single method, handleRequest(), which takes in an HttpRequest.
Let’s take a look at it in greater detail starting with the class definition.
Here we’re defining a class that takes two constructor arguments, a map of controllers and a list of filters.
Note the type of the filters argument, List[(HttpRequest) => HttpRequest]
This says that filters is a list of functions from HttpRequest to HttpRequest.
Next up, let’s look at the signature of the handleRequest() method:
The Option type is a container type with two subtypes, Some and None.
If we’ve got a value to store in it, we can store it in an instance of Some; otherwise we use None to indicate that we’ve got no real value.
Now that we’ve seen the TinyWeb framework, let’s take a look at it in action.
We’ll use the same example from the Java section, returning a list of friendly greetings.
However, since it’s Scala, we can poke at our example in the REPL as we go.
Let’s take a look at using our Scala TinyWeb framework.
We’ll start by creating a FunctionView and the rendering function we’ll compose into it.
We’re using a couple of new bits of Scala here.
First, we introduce the map() method, which lets us map a function over all the elements in a sequence and returns a new sequence.
Second, we’re using a bit of syntactic sugar that Scala provides that allows us to treat any method with a single argument as an infix operator.
The object on the left side of the operator is treated as the receiver of the method call, and the object on the right is the argument.
This bit of syntax means that we can omit the familiar dot syntax when working in Scala.
For instance, the two usages of map() below are equivalent:
As a helper, we use makeGreeting(), which takes in a name and generates a random friendly greeting.
We then use that list as the value for the "greetings" key in our model map:
Since Scala is a hybrid language, it’s got both functions and methods.
Methods are defined using the def keyword, as we do in the following code snippet:
We can create a function and name it by using Scala’s anonymous function syntax, assigning the resulting function to a val, like we do in this code snippet:
For instance, here we pass both the method and the function version of addOne() into map()
Since method definitions have a cleaner syntax, we use them when we need to define a function, rather than using the function syntax.
When we need to manually convert a method into a function, we can do so with the underscore operator, as we do in the following REPL session:
The need to do this is very rare, though; for the most part Scala is smart enough to do the conversion automatically.
This function simply writes the path that it finds in the passed-in HttpRequest to the console and then returns the path unmodified:
To finish up the example, we need to create an instance of TinyWeb with the controller, the view, and the filter we defined earlier, and we need to create a test HttpResponse:
We can now run the test request through TinyWeb’s handleRequest() method in the REPL and view the corresponding HttpResponse:
We’ve made a few changes to the style that we used in our Java version.
First, we replaced most of our iterative code with code that’s more declarative.
Second, we’ve replaced our bulky builders with Scala’s case classes, which give us a built-in way to handle immutable data.
Finally, we’ve replaced our use of Functional Interface with plain old functions.
Taken together, these small changes save us quite a bit of code and give us a solution that’s shorter and easier to read.
Next up, we’ll take a look at TinyWeb in Clojure.
This is going to be a bigger leap than the translation from Java to Scala, so we’ll take it slowly.
The most obvious difference between Clojure and Java is the syntax.
It’s very different than the C-inspired syntax found in most modern programming languages.
Clojure uses prefix syntax, which just means that the function name comes before the function arguments in a function call.
Here we call the count function to get the size of a vector, one of Clojure’s immutable data structures:
Like Scala, Clojure has excellent interoperability with existing Java code.
Calling a method on a Java class looks almost exactly like calling a Clojure function; you just need to prepend the method name with a period and put it before the class instance rather than after.
For instance, this is how we call the length() method on an instance of a Java String:
Instead of organizing Clojure code into objects and methods in Java or into objects, methods, and functions in Scala, Clojure code is organized into functions and namespaces.
Our Clojure version of TinyWeb is based on models, views, controllers, and filters, just like the Java and Scala versions; however, these components will take quite a different form.
Our views, controllers, and filter codes are simply functions, and our models are maps.
To tie everything together, we use a function named TinyWeb, which takes in all our components and returns a function that takes in an HTTP request, runs it through the filters, and then routes it to the proper controller and view.
Let’s start our look at the Clojure code with the controllers.
Below, we implement a simple controller that takes the body of an incoming HTTP request and uses it to set a name in a model.
For this first iteration, we’ll use the same HttpRequest as our Java code.
We’ll change it to be more idiomatic Clojure later on:
Let’s take a look at this code piece by piece, starting with the namespace declaration.
A namespace is simply a collection of functions that form a library that can be imported in full or in part by another namespace.
The second one might look a little strange, but it’s just the full name for the static inner Builder class we created as part of our HttpRequest.
Clojure doesn’t have any special syntax for referring to static inner classes, so we need to use the full class name.
The keyword :import is an example of a Clojure keyword.
A keyword is just an identifier that provides very fast equality checks and is always prepended with a colon.
Here we’re using the :import keyword to indicate what classes should be imported into the namespace we’ve just declared, but keywords have many other uses.
They’re often used as keys in a map, for instance.
Now let’s take a look at our controller, which takes an HttpRequest from the original Java solution and produces a Clojure map as a model:
Here we call the getBody() method on the HttpRequest to get the body of the request, and we use it to create a map with a single key-value pair.
The key is the keyword :name, and the value is the String body of the HttpRequest.
Before we move on, let’s look at Clojure maps in greater detail.
In Clojure, it’s common to use maps to pass around data.
The syntax for creating a map in Clojure is to enclose key-value pairs inside curly braces.
For instance, here we’re creating a map with two key-value pairs.
The first key is the keyword :name, and the value is the String "Mike"
The second is the keyword :sex, and the value is another keyword, :male>:
This means that we can call a map as a function, passing a key we expect to be in the map, and the map will return the value.
If the key isn’t in the map, nil is returned, as the code below shows:
When they are passed a map, they will look themselves up in it, as in the following snippet, which shows the most common way to look up a value from a map:
First, the forward slash lets us call a static method or reference a static variable on a class.
As another example, we can use this syntax to parse an integer from a String using the parseInt() method on the Integer class:
Then it takes that result and calls the path() method on it with the argument "say-hello" and finally calls build() on that result to return an instance of HttpResult.
Now that we’ve seen some basic Clojure and Clojure/Java interoperability, let’s take the next step in transforming TinyWeb into Clojure.
Here we’ll change test-controller so that the HTTP request it takes in is also a map, just like the model it returns.
We’ll also introduce a view function and a render function that’s responsible for calling views.
Let’s take a closer look at the pieces, starting with our new test-controller.
As we can see in the code, we’re expecting http-request to be a map with a :body key that represents the body of the HTTP request.
We’re pulling out the value for that key and putting it into a new map that represents our model:
We can explore how test-controller works very easily using the REPL.
All we need to do is define a test-http-request map and pass it into test-controller, which we do in this REPL output:
Now that we’ve got our controller approach buttoned up, let’s take a look at some view code.
They take a map that represents the model they operate on and return a String that represents the output of the view.
Here is some code for a simple test-view that just wraps a name in an <h1> tag:
Again, we can try this out simply in the REPL by defining a test model and passing it into the function:
We need one more piece to finish our view-handling code.
As the code below shows, all we need to do is pass our view function into the render function, which takes care of running the view and wrapping any exceptions:
Now that we’ve got a handle on our Clojure views and controllers, let’s finish up the example by adding in filters and the glue code that ties everything together.
We’ll do this final step in a namespace called core.
This is the standard core namespace that Clojure’s build tool Leiningen creates when you create a new project, so it’s become the de facto standard core namespace for Clojure projects.
To do this, we’ll add an execute-request function, which is responsible for executing an http-request.
The request handler is simply a map containing the controller and view that should be used to handle the request.
We’ll also need apply-filters, which takes an http-request, applies a series of filters to it, and returns a new http-request.
It takes in two arguments: a map of request handlers keyed off the path each should handle and a sequence of filters.
It then returns a function that takes an http-request, applies the sequence of filters to it, routes it to the appropriate request handler, and returns the result.
Here is the code for the full Clojure TinyWeb library:
The render method is unchanged from the previous iteration, so let’s start by examining the execute-request function.
We have already defined the function in the full Clojure TinyWeb library.
To start picking apart the execute-request function, let’s first define some test data in the REPL.
We’ll need the test-controller and test-view we defined in our last iteration to create a test request handler, which we do below:
Now we just need our test-http-request, and we can verify that execute-request runs the passed-in request-handler on the passed-in http-request, as we’d expect:
Let’s look at the pieces of execute-request in more detail by trying them out in the REPL, starting with the let statement that picks the controller and view out of request-handler, which we’ve outlined here:
A let statement is how you assign local names in Clojure, somewhat like a local variable in Java.
However, unlike a variable, the value these names refer to isn’t meant to be changed.
In the let statement above, we’re picking the view and controller functions out of the request-handler map and naming them controller and view.
We can then refer to them by those names inside the let statement.
Let’s take a look at a simpler example of a let expression.
Below, we use let to bind name to the String "Mike" and to bind greeting to the String "Hello"
Then, inside the body of the let expression, we use them to create a greeting:
Now that we’ve got let under our belts, let’s take a look at the try expression, which we’ve repeated below.
Much like in Scala, try is an expression with a value.
If no exception is thrown, try takes on the value of the body of the expression itself; otherwise it takes on the value of a catch clause:
If no exception is thrown, then the try expression takes the value of a map with two key-value pairs, which represents our HTTP response.
Its value is computed by passing the http-request into the controller and then passing that result into the render function along with the view to be rendered.
We can see this in action using our test-view and test-controller below:
Before we move on, let’s take a bit of a closer look at Clojure’s exception handling using a couple of simpler examples.
Below, we see an example of a try expression where the body is just the String "hello, world", so the value of the whole expression is "hello, world":
Here’s a simple example of how try expressions work when things go wrong.
In the body of the try expression below, we’re throwing a RuntimeException with the message "It's broke!"
In the catch branch, we’re catching Exception and just pulling the message out of it, which then becomes the value of the catch branch and thus the value of the entire try expression:
Next up, let’s take a look at how we apply our filters.
We use an apply-filters function, which takes a sequence of filters and an HTTP request, composes them into a single filter, and then applies it to the HTTP request.
To finish off our Clojure TinyWeb implementation, we need a function, tinyweb, to tie everything together.
This function takes in a map of request handlers and a sequence of filters.
It returns a function that takes an HTTP request, using apply-filters to apply all the filters to the request.
Then it picks the path out of the HTTP request, looks in the map of request handlers to find the appropriate handler, and uses execute-request to execute it.
Let’s take a look at using the Clojure version of TinyWeb.
Now let’s take a look at our controller code, which is just a simple function and works much like our Scala version:
Running our test request through it returns the appropriate model map, as seen below:
It’s just another function that takes in the appropriate model map and returns a string:
If we run greeting-view over the output of handle-greeting, we get our rendered HTML:
This is just a simple function that logs out the path of the request before returning it:
Finally, we’ll wire everything together into an instance of TinyWeb, as we do in the following code:
If we run our test request through the instance of TinyWeb, it’s filtered and processed as it should be:
That wraps up our look at TinyWeb! The code in this chapter has been kept simple; we’ve stuck to a minimal set of language features and omitted much error handling and many useful features.
However, it does show how quite a few of the patterns we’ll examine in this book fit together.
Throughout the remainder of the book, we’ll take a closer look at these patterns and many others as we continue our journey through functional programming.
In this chapter, we’ll take a look at some of the most common ones and the problems they solve.
Then we’ll introduce more functional solutions that solve the same sorts of problems that the object-oriented patterns solve.
For each pattern that we introduce, we’ll first look at it in Java.
Then we’ll look at a Scala approach that solves the same problems, and finally we’ll wrap up with a look at a Clojure version that does as well.
Sometimes the Scala and Clojure replacements will be quite similar.
Other times the solutions we explore in these two languages will be quite different but still embody the same functional concept.
However, in both cases they show straightforward ways of working with immutable data.
By exploring both the similarities and the differences between Scala and Clojure, you should get a good feel for how each language approaches functional programming and how it differs from the traditional imperative style you may be used to.
To encapsulate a bit of program logic so that it can be passed around, stored in data structures, and generally treated like any other first-class construct.
It consists of an interface with a single method with a name like run, execute, perform, apply, or some other generic verb.
Implementations of Functional Interface perform a single well-defined action, as any method should.
Functional Interface lets us call an object as if it were a function, which lets us pass verbs around our program rather than nouns.
This turns the traditional object-oriented view of the world on its head a bit.
In the strict objectoriented view, objects, which are nouns, are king.
Verbs, or methods, are second-class citizens, always attached to an object, doomed to a life of servitude to their noun overlords.
A strict view of object orientation makes some problems clumsier to solve.
I’ve lost track of the number of times I’ve written five or six lines of boilerplate to wrap a single line of useful code into Runnable or Callable, two of Java’s most popular instances of Functional Interface.
To simplify things, we can replace Functional Interface with plain functions.
It might seem strange that we can replace an object with seemingly more primitive functions, but functions in functional programming are much more powerful than functions in C or methods in Java.
In functional languages, functions are higher order: they can be returned from functions and used as arguments to others.
They are first-class constructs, which means that in addition to being higher order they can also be assigned to variables, put into data structures, and generally manipulated.
They can be unnamed, or anonymous functions, which are extremely handy for small, one-off pieces of code.
In fact, Functional Interface (as its name might suggest) is a pattern that in the object-oriented world approximates the behavior of the functions of the functional world.
We’ll cover a couple of different flavors of a Functional Interface replacement in this section.
The first replaces smaller instances of the pattern—say ones that take a few lines of code—with an anonymous function.
The second covers instances of the pattern that span more than a few lines.
Our first example demonstrates anonymous functions and how we can use them to replace small instances of Functional Interface.
One common situation where we’d do this is when we need to sort a collection differently than its natural ordering, the way it’s commonly ordered.
To do so, we need to create a custom comparison so that the sorting algorithm knows which elements come first.
In classic Java, we need to create a Comparator implemented as an anonymous class.
In Scala and Clojure, we get right to the point by using an anonymous function.
We’ll take a look at a simple example of sorting differently than the natural ordering for an object: sorting a Person by first name rather than last.
In classic Java, we’ll use a Functional Interface named Comparator to help with our sort.
We’ll implement it as an anonymous function, since it’s only a tiny bit of code, and we’ll pass it into the sorting function.
This works, but most of the code is extra syntax to wrap our one line of actual logic into an anonymous class.
Let’s see how anonymous functions can help clean this up.
Let’s take a look at how we’d solve the problem of sorting by first rather than last name in Scala.
We’ll use a case class to represent people, and we’ll do away with the Functional Interface Comparator.
Creating an anonymous function in Scala uses the following syntax:
For instance, the following REPL session creates an anonymous function that takes two integer arguments and adds them together.
Now that we’ve got the basic syntax down, let’s see how to use an anonymous function to solve our person-sorting problem.
To do so we use a method in Scala’s collections library, sortWith()
Let’s start with the code for our Person case class:
Here’s a vector full of them to use for test data:
The sortWith() method expects its comparison function to return a Boolean value that tells it whether the first argument is higher than the second argument.
We can omit the type annotations for the function parameters.
Scala is able to infer them from the sortWith() method:
Running this in Scala’s REPL gets us the following output.
This is shorter and simpler than using an equivalent implementation of Functional Interface!
We define an anonymous function in Clojure using the fn special form, as the following code outline shows.
In Clojure, we won’t define a class to carry around data; we’ll use a humble map:
Now we create an anonymous ordering function and pass it into the sort function along with the people we want to sort, as the following code demonstrates:
By eliminating the extra syntax we need in Java to wrap our ordering function in a Comparator, we write code that gets right to the point.
We’ll add a middle name to each person in our list and modify our unusual sorting algorithm to sort by first name, then last name if the first names are the same, and finally middle name if the last names are also the same.
This makes the comparison code long enough that we should no longer embed it in the code that’s using it.
In Java we move the code out of an anonymous inner class and into a named class.
In Clojure and Scala, we move it into a named function.
Anonymous classes and functions are great when the logic they’re wrapping is small, but when it grows larger it gets messy to embed.
In classic Java, we move to using a named class, as is sketched out below:
We start off by expanding our Scala case class to have a middle name and by defining some test data:
Now we create a named comparison function and pass it into sortWith(), as the following code demonstrates:
The Clojure solution is quite similar to the Scala one.
We’ll need a named function that can compare people according to our more complex set of rules, and we’ll need to add middle names to our people.
Now we can call sort as before, but instead of passing in an anonymous function, we pass the named function complicated-sort:
It comes from Java’s current insistence on turning everything into an object, a noun.
This is like having to use a ShoePutterOnner, a DoorOpener, and a Runner just to go for a run! Replacing the pattern with higher-order functions helps us in several ways.
The first is that it reduces the syntactic overhead of many common tasks, cruft you have to write in order to write the code you want to write.
For instance, the first Comparator we came across in this section required five lines of Java code (formatted properly) to convey just one line of actual computation:
More importantly, using higher-order functions gives us a consistent way of passing around small bits of computation.
With Functional Interface, you need to look up the right interface for every little problem you want to solve and figure out how to use it.
We’ve seen Comparator in this chapter and mentioned a few other common uses of the pattern.
Hundreds of others exist in Java’s standard libraries and other popular libraries, each as unique as a snowflake, but more annoyingly different than beautiful.
Functional Interface and its replacements in this chapter have some differences that don’t touch on the core problem that it’s meant to solve.
Since Functional Interface is implemented with a class, it defines a type and can use common object-oriented features such as subclassing and polymorphism.
This is actually a strength of higher-order functions over Functional Interface: you don’t need a new type for each type of Functional Interface when just the existing function types will do.
To encapsulate a bit of state along with program logic so it can be passed around, stored in data structures, and generally treated like any other firstclass construct.
In this pattern, we’ll take a look at how we can replace Functional Interface implementations that need state using a powerful construct called a closure.
Functions in the functional world are part of a powerful construct called a closure.
A closure wraps up a function along with the state available to it when it was created.
This means that a function can reference any variable that was in scope when the function was created at the time it’s called.
The programmer doesn’t have to do anything special to create a closure; the compiler and runtime take care of it, and the closure simply captures all the state that it needs automatically.
In classic Java, we’d carry state around by creating fields on the class and by providing setters for them or setting them through a constructor.
In the functional world, we can take advantage of closures to handle this without any extra machinery.
Closures are a bit magical, so it’s worth examining them in more detail before we move on.
A closure is composed of a function and the state that was available to that function when it was created.
Let’s see what this might look like pictorially, as shown in the figure.
A closure is a structure that consists of a function and its context at the time it was defined.
Here we can see that the closure has a function in it and a scope chain that lets it look up any variables that it needs to do its job.
Scope 1 - Top Level (def foo "first foo") (def bar "first bar") (def baz "first baz")
If we use this code to make a printer function and run it, it prints the foo, bar, and baz from the deepest scope that they’re defined in, just as any experienced developer would expect:
This may not seem surprising, but what if we took a-printer and passed it around our program, or stored it in a vector to retrieve and use later? It would still print the same values for foo, bar, and baz, which implies that those values stick around somewhere.
Behind the scenes, Clojure and Scala need to do an awful lot of magic to make that work.
However, actually using a closure is as simple as declaring a function.
I like to keep the previous figure in mind when working with closures because it’s a good mental model of how they work.
To demonstrate closures, we’ll take one last look at comparisons, with a bit of a twist.
This time, we’ll see how to create a comparison that’s composed of a list of other comparisons, which means that we need someplace to store this list of comparisons.
In Java, we’ll just pass them in as arguments to a constructor in our custom Comparator implementation, and we’ll store them in a field.
In Scala and Clojure, we can just use a closure.
When the compare() method on a ComposedComparator is called, it runs through all the comparators in its array and returns the first nonzero result.
If all the results are zero, then it returns zero.
In the functional world, we can use closures instead of having to create new classes.
In Scala, we’ll take advantage of closures to avoid explicitly keeping track of our list of comparisons in our composed comparison.
One other difference between the Java and Scala solutions is in how we return the final result.
In Java, we iterated through the list of Comparators, and as soon as we saw a nonzero comparison, we returned it.
We use map() to run our comparisons over our input.
If we don’t find a nonzero value, all our comparisons were the same and we return zero.
Now we can take two comparison functions and compose them together.
Let’s take a look at our composed comparison function in action by defining a couple of people and comparing them:
One optimization we could make is to create a short-circuiting version of the composed comparison that stops running comparisons as soon as it comes across the first nonzero result.
We’ll wrap up the code samples for this pattern with a look at how we’d create composed comparisons in Clojure.
We’ll rely on a make-composed comparison, but it’ll work a bit differently than the Scala version.
In Scala, we could use the find() method to find the first nonzero result; in Clojure we can use the some function.
In Clojure, the some function takes a predicate and a sequence, and it returns the first value for which the predicate is true.
Here we use Clojure’s some and for to run all of the comparisons and select the correct final value:
That wraps up our look at using closures to replace state-carrying Functional Interface implementations.
Before we move on, let’s discuss the relationship between closures and classes in a bit more detail.
There’s a joke about closures and classes: classes are a poor man’s closure, and closures are a poor man’s class.
Besides demonstrating that functional programmers probably shouldn’t go into standup comedy, this illustrates something interesting about the relationship between classes and closures.
Classes have a whole bunch of object-oriented machinery around them, they define types, they can be part of hierarchies, and so on.
Closures are much simpler—they’re just composed of a function and the context it was created in.
Having closures makes it much simpler to solve a whole host of common programming tasks, as we’ve seen in this section, which is why classes are a poor man’s closure.
However, classes have many programming features that closures don’t, which is why closures are a poor man’s class.
Scala solves this problem by giving us both classes and closures, and Clojure solves it by deconstructing the good stuff from classes, such as polymorphism and type hierarchies, and giving it to programmers in other forms.
Having closures and higher-order functions can simplify many common patterns (Command, Template Method, and Strategy to name a few) to such an extent that they almost disappear.
It’s not one that the stewards of Java undertook lightly; but because higher-order functions are such a big win, it was deemed important to include them.
It’s taken years of effort to specify and implement, but they’re finally coming!
To turn a method invocation into an object and execute it in a central location so that we can keep track of invocations so they can be undone, logged, and so forth.
Command encapsulates an action along with the information needed to perform it.
Though it seems simple, the pattern has quite a few moving parts.
In addition to the Command interface and its implementations, there’s a client, which is responsible for creating the Command; an invoker, which is responsible for running it; and a receiver, on which the Command performs its action.
The invoker is worth talking about a little because it’s often misunderstood.
It helps to decouple the invocation of a method from the client asking for it to be invoked and gives us a central location in which all method invocations take place.
This, combined with the fact that the invocation is represented by an object, lets us do handy things like log the method invocation so it can be undone or perhaps serialized to disk.
Here, the client is any class that needs to do logging and the receiver is a Logger instance.
The invoker is the class that the client calls instead of calling the Logger directly.
Command has a few moving parts, as does our functional replacement.
Next we’ll replace the invoker with a simple function responsible for executing commands, which I’ll call the execution function.
Just like the invoker, the execution function gives us a central place to control execution of our commands, so we can store or otherwise manipulate them as needed.
Finally, we’ll create a Function Builder that’s responsible for creating our commands so we can create them easily and consistently.
Let’s look at how we’d implement a simple cash register with Command.
Our cash register is very basic: it only handles whole dollars, and it contains a total amount of cash.
We’ll keep a log of transactions so that we can replay them.
We’ll take a look at how we’d do this with the traditional Command pattern first before moving on to the functional replacements in Scala and Clojure.
A Java implementation starts with defining a standard Command interface.
A Purchase will contain a reference to the CashRegister it should be executed against.
To round out the pattern, we’ll need an invoker, PurchaseInvoker, to actually execute our purchases.
A diagram of this implementation is below, and the full source can be found in this book’s code samples.
The structure of a cash register as a Command pattern in Java.
Now that we’ve sketched out a Java implementation of the Command pattern, let’s see how we can simplify it using functional programming.
The cleanest replacement for Command in Scala takes advantage of Scala’s hybrid nature.
We’ll retain a CashRegister class, just as in Java; however, instead of creating a Command interface and implementation, we’ll simply use higherorder functions.
Instead of creating a separate class to act as an invoker, we’ll just create an execution function.
Let’s take a look at the code, starting with the CashRegister itself:
Next we’ll create the function makePurchase to create our purchase functions.
It takes amount and register as arguments to add to it, and it returns a function that does the deed, as the following code shows:
It just adds the purchase function it was passed to a Vector to keep track of purchases we’ve made before executing it.
The code on page 57 has a mutable reference front and center.
This might seem a bit odd in a book on functional programming.
Shouldn’t everything be immutable? It turns out that it’s difficult, though not impossible, to model everything in a purely functional way.
Never fear though; all we’re doing here is moving around a reference to a bit of immutable data.
For instance, we can safely create as many references to our original Vector without worrying about accidentally modifying the original, as the following code shows:
It’s possible to program in a purely functional way using the excellent Scalaz library,a.
As you can see, the register now has the correct total:
If we reset the register to 0, we can replay the purchases using the ones we’ve stored in the purchases vector:
Compared to the Java version, the Scala version is quite a bit more straightforward.
No need for a Command, Purchase, or separate invoker class when you’ve got higher-order functions.
The overall structure of the Clojure solution is similar to the Scala one.
We’ll use higher-order functions for our commands, and we’ll use an execution function to execute them.
The biggest difference between the Scala and Clojure solutions is the cash register itself.
Since Clojure doesn’t have object-oriented features, we can’t create a CashRegister class.
Instead, we’ll simply use a Clojure atom to keep track of the cash in the register.
To do so, we’ll create a make-cash-register function that returns a fresh atom to.
We’ll also create a reset function to reset our register to zero.
Now that we’ve got our cash register, let’s take a look at how we’ll create commands.
Remember, in Java this would require us to implement a Command interface.
In Clojure we just use a function to represent purchases.
To create them, we’ll use the make-purchase function, which takes a register and an amount and returns a function that adds amount to register.
Here we use it to create a couple of purchases:
To finish off the example, we’ll need our execution function, execute-purchase, which stores the purchase commands before executing them.
We’ll use an atom, purchases, wrapped around a vector for that purpose.
Now we can use execute-purchase to execute the purchases we defined above so that this time we’ll get them in our purchase history.
Now if we reset the register again, we can run through our purchase history to rerun the purchases:
That’s our Clojure solution! One tidbit I find interesting about it is how we modeled our cash register without using objects by simply representing it as a bit of data and functions that operate on it.
This is, of course, common in the functional world and it often leads to simpler code and smaller systems.
This might seem limiting to the experienced object-oriented programmer at first; for instance, what if you need polymorphism or hierarchies of types? Never fear, Clojure provides the programmer with all of the good stuff from the object-oriented world, just in a different, more decoupled form.
I’ve found that Command, though it’s used everywhere, is one of the most misunderstood patterns of Design Patterns: Elements of Reusable Object-Oriented Software [GHJV95]
People often conflate the Command interface with the Command pattern.
This isn’t to say that the way it’s commonly used is wrong, but it is often different than the way the Gang of Four describes it, which can lead to some confusion when talking about the pattern.
For example, if we didn’t need our command to be able to work with multiple registers, we wouldn’t have to pass a register into makePurchase.
To create an immutable object using a friendly syntax for setting attributes—because we can’t modify them, we also need a simple way to create new objects based off existing ones, setting some attributes to new values as we do so.
In this section, we’ll cover Fluent Builder, which produces immutable objects.
This is a common pattern; Java’s standard library uses it with its StringBuilder and StringBuffer.
Many other common libraries use it as well, such as Google’s protocol buffers framework.
Using immutable objects are a good practice that’s often ignored in Java, where the most common way of carrying data around is in a class with a bunch of getters and setters.
This forces data objects to be mutable, and mutability is the source of many common bugs.
The easiest way to get an immutable object in Java is just to create a class that takes in all the data it needs as constructor arguments.
The first is that a Java class with many constructor arguments is very hard to use.
A programmer has to remember which argument goes in which position, rather than referring to it by name.
The second is that there is no easy way to create defaults for attributes, since values for all attributes need to be passed into the constructor.
One way to get around that is to create several different constructors that take only a subset of values and that default the ones not passed in.
For large objects this leads to the telescoping constructor problem, where a class has to implement many different constructors and pass values from the smaller constructors to ever larger ones.
The builder pattern we examine in this section, outlined in Effective Java [Blo08], solves both of these problems at the cost of quite a bit of code.
The techniques used to replace these two patterns in Scala and Clojure are quite different, but both share the very important property that they make it extremely simple to create immutable objects.
We’ll cover three different techniques for creating immutable data structures in Scala, each of which has its own strengths and weaknesses.
First we’ll cover creating a Scala class that consists entirely of immutable values.
We’ll show how to use named parameters and default values to achieve something very much like the fluent builder for an immutable object in Java but with a fraction of the overhead.
Case classes are meant specifically for carrying data, so they come with some handy methods already implemented, like equals() and hashCode(), and they can be used with Scala’s pattern matching to easily pick them apart.
This makes them a good default choice for many data carrying uses.
In both instances, we’ll use Scala’s constructors to create objects.
Scala’s constructors don’t have the same shortcomings as the Java constructors we discussed earlier, because we can name parameters and provide them with default values.
This helps us avoid both the telescoping constructor problem and the problems involved with passing in several unnamed parameters and trying to remember which is which.
Finally, we’ll cover Scala tuples, which are a handy way to pass around small composite data structures without having to create a new class.
Clojure has support for creating new classes, but it’s intended to be used only for interop with Java.
Instead, it’s common to use plain old immutable maps to model aggregate data.
Coming from the Java world, it might seem like this is a bad idea, but since Clojure has excellent support for working with maps, it’s actually very convenient.
Using maps to model data allows us the full power of Clojure’s sequence library in manipulating that data, which is a very powerful.
Many libraries rely on inspecting data objects to perform operations on their data, such as XStream, which serializes data objects to XML, or Hibernate, which can generate SQL queries using them.
The second way to model data in Clojure is to use a record.
A record exposes a map-like interface; so you can still use the full power of Clojure’s sequence library on it, but records have a few advantages over maps.
In addition, records define a type that can participate in Clojure’s polymorphism.
To use the old objectoriented chestnut, it allows us to define a make-noise that will bark when passed a dog and meow when passed a cat.
In addition, records let us constrain the attributes that we can put into a data structure.
Generally, a good way to work in Clojure is to start off modeling your data using maps and then switch to records when you need the additional speed, you need to use polymorphism, or you just want to constrain the names of the attributes you’re handling.
In this section we’ll take a look at how to represent data in Java using a builder for immutable objects.
Then we’ll take a look at three ways of replacing them in Clojure: regular classes with immutable attributes, case classes, and tuples.
Finally, we’ll take a look at two ways of replacing them in Clojure: plain old maps and records.
In classic Java, we can use a fluent builder to create an immutable object using nice syntax.
To solve our problem, we create an ImmutablePerson that only has getters for its attributes.
Nested inside of that class, we create a Builder class, which lets us construct an ImmutablePerson.
When we want to create an ImmutablePerson, we don’t construct it directly; we create a new Builder, set the attributes we want to set, and then call build() to get an ImmutablePerson.
The downside is that we’ve got a whole lot of code for such a basic task.
Passing around aggregate data is one of the most basic things we do as programmers, so languages should give us a better way to do it.
We’ll take a look at three different ways of representing immutable data in Scala: immutable classes, case classes, and tuples.
Immutable classes are plain classes that only contain immutable attributes; case classes are a special kind of class intended to work with Scala’s pattern matching; and tuples are immutable data structures that let us group data together without defining a new class.
Immutable Classes Let’s start by looking at the Scala way to produce immutable objects.
All we need to do is define a class that defines some vals as constructor arguments, which will cause the passed-in values to be assigned to public vals.
Now we can create a Person using the constructor parameters positionally:
We can add a default value for parameters, which lets us omit them when using the named parameter form.
This lets us handle people who may not have a middle name:
This gives us a simple way of creating immutable objects in Scala, but it does have a few shortcomings.
If we want object equality, hash codes, or a nice representation when printed, we need to implement it ourselves.
Case classes give us all this out of the box and are designed to participate in Scala’s pattern matching.
They can’t, however, be extended, so they’re not suitable for all purposes.
Case Classes A case class is defined using case class, as shown below:
Now we can create a PersonCaseClass in the same ways we’d create a normal class, except we don’t have to use the new operator.
Here we create one using named parameters and by omitting the middle name:
We also get equals() and hashCode() for free with case classes.
Case classes are immutable, so we can’t modify them, but we can get the same effect by using the copy() method to create a new case class based on an existing one, as we do in the following REPL session:
Finally, case classes can be used with Scala’s pattern matching.
Here we use a pattern match to pick apart the sixth American president:
There’s one final common way to represent data in Scala: tuples.
Tuples let us represent a fixed-size record, but they don’t create a new type as classes and case classes do.
They’re handy for explorative development; you can use them to model your data during early phases when you’re not sure what it looks like and then switch to classes or case classes later.
Tuples To create a tuple, you enclose the values that it contains inside of parentheses, like so:
To get values back out, reference them by position, as we do below:
Finally, tuples can be easily used in pattern matching, just like case classes:
That covers the three main ways of working with immutable data in Scala.
Plain old immutable classes are handy when you’ve got more attributes than the twenty-two that a case class can handle, though this might suggest that it’s time to refine your data model or that your data objects need to have some methods on them.
Case classes are useful when you want their built-in equals(), hashCode(), and toString, or when you need to work with pattern matching.
Finally, tuples are great for explorative development; you can use them to simply model your data before switching to classes or case classes.
We’ll take a look at two ways to represent immutable data in Clojure.
The first is simply storing it in a map, and the second uses a record.
Maps are the humble data structure that we all know and love; records are a bit different.
They allow us to define a data type and constrain the attributes that they contain, but they still give us a map-like interface.
Maps Let’s start by taking a look at the simpler of the two options: using an immutable map.
All we need to do is create a map with keywords for keys and our data as values, as we do below:
We can get at attributes as we would with any map:
One benefit that may not be so obvious is that we can use the full set of operations that maps support, including the ones that treat maps as sequences.
For instance, if we wanted to uppercase all the parts of a name, we could do it with the following code:
In order to do something similar with objects and getters, we’d need to call all the appropriate getters.
That means we’ve taken a solution to a general problem, the problem of capitalizing all the attributes in a data structure full of strings, and reduced its generality to only capitalize the attributes of a particular type, which in turn means we need to reimplement that solution for every type of object.
Using immutable maps as one of the primary ways to carry data around has a few other advantages.
Creating them uses simple syntax, so you have no constraints on the attributes you can add to them.
Clojure maps aren’t as efficient as simple Java classes, and once you’ve got your data model more fleshed out, it may help to constrain the attributes you’re dealing with.
Most importantly, however, using plain maps makes it awkward for maps to be used with polymorphism, because using a map doesn’t define a new type.
Let’s take a look at another Clojure feature that solves these problems but still presents a map-like interface.
Records To demonstrate records, let’s borrow an old object-oriented example: creating cats and dogs.
To create our Cat and Dog types, we use the code below:
We can treat them as maps so that we get the full power mentioned above:
Earlier I said it was awkward to use maps when you want type-based polymorphism.
This is true, but Clojure is flexible enough that it’s merely awkward, not impossible.
We could encode the type in the map itself and use Clojure multimethods, as the code below shows:
In general, if you want polymorphism on types, it’s best to just use a protocol and save multimethods for fancier polymorphism, when you need the full power that comes with being able to define your own dispatch function.
And they can easily participate in polymorphism using Clojure’s protocols.
Here we define a protocol that has a single function, make-noise, and we create a NoisyCat and NoisyDog to take advantage of it:
Those are the two main ways to carry data around in Clojure.
The first, plain old maps, is a good place to start.
Once you’ve got your data model more nailed down, or if you want to take advantage of Clojure’s protocol polymorphism, you can switch over to a record.
There’s a basic tension between locking down your data structures and keeping them flexible.
Keeping them flexible helps during development time, while your data model is in flux, but locking them down can help to bring bugs to the surface earlier, which is important once your code is in production.
This is mirrored somewhat in the wider technical world with some of the debate surrounding traditional relational databases, which impose a strict schema, and some of the newer nonrelational ones, which have no schemas or have more relaxed schemas, with both sides claiming their approach is better.
In reality, both approaches are useful, depending on the situation.
Clojure and Scala give us the best of both worlds here by letting us keep our data structures flexible in the beginning (using maps in Clojure and tuples in Scala) and letting us lock them down as we understand our data better (using records in Clojure and classes or case classes in Scala)
To iterate through the elements of a sequence in order, without having to index into it.
An iterator is an object that allows us to iterate over all the objects in a sequence.
It does so by maintaining an internal bit of state that keeps track of where in the sequence the iterator is currently.
At its simplest, an implementation of Iterator just requires a method that returns the next item in the sequence, with some sentinel value returned when there are no more items.
Most implementations have a separate method to check to see if the iterator has any more items, rather than using a sentinel to check.
Some implementations of Iterator allow the underlying collection to be modified by removing the current item.
In this section, we’ll focus on replacing an iterator with a combination of higher-order functions and sequence comprehensions.
A sequence comprehension is a clever technique that lets us take one sequence and transform it into another in some sophisticated ways.
Many basic uses of Iterator can be replaced by simple higher-order functions.
For instance, summing a sequence can be done in Clojure using the reduce higher-order function.
Other, more complex uses can be handled with sequence comprehensions.
Sequence comprehensions provide a concise way to create a new sequence from an old one, including the ability to filter out unwanted values.
In this section we’ll stick with the uses of Iterator that can be expressed using a Java foreach loop.
Let’s start by looking at a grab bag of simple uses of Iterator that can be replaced with higher-order functions.
First we’ll look at identifying the vowels in a string, then we’ll take a look at prepending a list of names with "Hello, ", and finally we’ll sum up a sequence.
We’ll look at these examples first in an iterative style written in Java, and then we’ll collapse them into a more declarative style in Scala and Clojure.
To identify the set of vowels in a word, we iterate through the characters and check each character against the set of all vowels.
If it’s in the set of all vowels, we add it to vowelsInWorld and return it.
The code below, which assumes an isVowel() helper method, illustrates this solution:
There’s a higher-level pattern here: we’re filtering some type of element out of a sequence.
Here it’s vowels in a string, but it could be odd numbers, people named “Michael” or anything else.
We’ll exploit this higher-order pattern in our functional replacement, which uses the filter function.
Next up, let’s discuss prepending a list of names with the “Hello, ” string.
Here we take in a list of names, iterate through them, prepend “Hello, ” to each name, and add it to a new list.
We’re mapping an operation onto each item in a sequence, here prepending a word with the “Hello, ” string.
We’ll see how we can use the higher-order map function to do so.
Let’s examine one final problem: summing up a sequence of numbers.
In classic Java, we’d compute a sum by iterating through a list and adding each number to a sum variable, as in the code below:
This type of iteration is an example of another pattern, performing an operation on a sequence to reduce it to a single value.
We’ll take advantage of that pattern in our functional replacement using the reduce function and a closely related function known as fold.
Let’s take a look at the first of our examples, returning the set of vowels in a word.
In the functional world, this can be done in two steps: first we use filter() to filter all the vowels out of a word, and then we take that sequence and turn it into a set to remove any duplicates.
To do our filtering, we can take advantage of the fact that Scala sets can be called as predicate functions.
If the set contains the passed-in argument, it returns true; otherwise it returns false, as the code below shows:
Now we can use the isVowel() from above, along with filter() and toSet(), to get a set of vowels out of a string:
Here we can see it in action, filtering vowels out of a string:
Our next example—prepending a list of names with “Hello, ”—can be written by mapping a function that does the prepending over a sequence of strings.
Here, mapping just means that the function is applied to each element in a sequence and that a new sequence is returned with the result.
Here we map a function that prepends the string "Hello, " to each name in a sequence:
The Scala REPL inserts commas between elements in a sequence, so it’s putting an additional comma between each of our greetings.
We’re using an operation, in this case, addition, to take a sequence and reduce it to a single value.
In Scala, the simplest way to do this is to use the aptly named reduce method, which takes a single argument, a reducing function.
Here we create a reducing function that adds its arguments together, and we use it to sum a sequence:
That’s it—no iterating, no mutation, just a simple higher-order function!
Here we take advantage of that property of Clojure sets to define a vowel? predicate, which we can then use with filter to filter the vowels out of a sequence.
We then use Clojure’s set function to construct a new set from an existing sequence.
Now we can use it to filter out sets of vowels from a word:
Just like the Scala example, we simply use map to map a function that prepends "Hello, " to each name in a sequence of names.
We can use this to generate a set of greetings:
Finally, let’s look at how we’d sum a sequence in Clojure.
Just like Scala, we can use the reduce function, though we don’t have to create our own function to add integers together as we did in Scala: we can just use Clojure’s + function.
And here we are using it to sum a sequence:
Those unfamiliar with Clojure might find it a bit odd that the + is just another function that we can pass into reduce, but this is one of the strengths of Clojure and Lisps in general.
Many things that would be special operators in other languages are just functions in Clojure, which lets us use them as arguments to higher-order functions like reduce.
One note on reduce in Clojure and Scala: While we were able to use them the same way here, they’re actually somewhat different.
Scala’s reduce() operates over a sequence of some type, and it returns a single item of that type.
For instance, reducing a List of Int will return a single Int.
Clojure, on the other hand, allows you to return anything at all from its reduce function, including another collection of some sort! This is more general (and often very handy), and Scala supports this more general idea of reduction under a different name, foldLeft()
It’s usually easier and clearer in Scala to use reduce() when you truly are reducing a sequence of some type to a single instance of that type, and to use foldLeft() otherwise.
Both Scala and Clojure support a very handy feature called a sequence comprehension.
Sequence comprehensions give us a handy syntax that lets us do a few different things together.
Much like the map function, sequence comprehensions let us transform one sequence into another.
Sequence comprehensions also let us include a filtering step, and they provide a handy way to get at pieces of aggregate data, known as destructuring.
Let’s take a look at how we’d use sequence comprehensions to solve a delicious little problem.
We’ve got a list of people who asked to be notified when our new restaurant, The Lambda Bar and Grille, opens, and we’d like to send them an invitation to a grand-opening party.
We’ve got names and addresses, and we figure that people who live closest to the Lambda will be more likely to come, so we’d like to send invitations to them first.
Finally, we’d like to filter out people who live so far away that we’re entirely sure they won’t come.
We decide to solve the problem like so: we’ll put our customers into groups based on zip codes, and we’ll send invitations to the groups of people in zip codes closest to our restaurant first.
Additionally, we’ll constrain ourselves to a small group of close zip codes.
We’ll start, as always, with the iterative solution in Java, and then we’ll move onto functional ones using sequence comprehensions in Scala and Clojure.
In Java, we create a Person and an Address in the customary JavaBean format, and we create a method, peopleByZip(), that takes in a list of people, filters out the ones who don’t live close enough, and returns a map keyed off zip codes that contains lists of people in each zip code.
To do this we use a standard iterative solution with a couple of helper methods.
The first, addPerson(), adds a person to a list, creating the list if it doesn’t already exist, so we can handle the case where we come across the first person in a zip code.
The second, isCloseZip(), returns true if the zip is close enough to the Lambda Bar and Grille to get an invite to the party, and false otherwise.
To keep the example small, we’ve hard-coded just a couple of zip codes in there, but since we’ve factored that check out into its own method, it would be easy to change it to pull from some dynamic data source of zip codes we care about.
To solve the problem, we just iterate through the list of people.
For each person, we check to see if he or she has a close zip code, and if yes we add them to a map of lists of people keyed off of zip codes called closePeople.
When we’re all done with our iteration, we just return the map.
This is a fairly simple data transformation, but it takes quite a bit of doing in an imperative style since we need to muck about with adding elements to the new list, and we don’t have a first-class way of filtering elements from the existing one.
The more declarative sequence comprehensions help us bump up the level of abstraction here.
In Scala, we can use Scala’s syntax for sequence comprehensions, the for comprehension, to generate our greetings in a cleaner way.
We’ll use case classes for our Person and Address, and we’ll write a for comprehension that takes in a sequence of Person and produces a sequence of greetings.
For comprehensions are handy for this for a few reasons.
The first is that we can use Scala’s pattern-matching syntax inside of them, which gives us a concise way to pick apart a Person into a name and an address.
Second, for comprehensions let us include a filter directly in the comprehension itself, known as a guard, so we don’t need a separate if statement to filter out people with the wrong zip codes.
Finally, for comprehensions are intended to create new sequences, so there’s no need to have a temporary list to accumulate new values into; we simply return the value of the comprehension.
With a for comprehension, we’ll still use a helper isCloseZip() method, but we’ll use it as part of a guard in the for comprehension itself, and we’ll do away with the mutable list of greetings from the Java solution entirely, since the result we want is just the value of the for comprehension itself.
One thing that may not be obvious when using for comprehensions is how to deal with situations when we absolutely need side effects.
Since we’re programming in the functional style this should be fairly rare.
As we saw above, we don’t need a mutable list to generate our list of greetings.
One simple use of side effects that we still need in the functional world is printing to the console.
Here we’ve rewritten the example to just print the greetings to the console, rather than gathering them up into a sequence:
We’ve only touched on the basics of Scala’s for comprehensions here; they’re very powerful beasts.
They can be used with multiple sequences and multiple guards at the same time, among several other features, but the ones that we’ve covered here let us handle the most common cases where we’d use the Iterator pattern.
Clojure also has built-in sequence comprehensions using the for macro.
Just as in Scala, the primary point of a Clojure sequence comprehension is to take one sequence and transform it into another with built-in filtering.
Clojure’s sequence comprehensions also provide a handy way of pulling apart aggregate data with destructuring.
Since Clojure and Scala’s sequence comprehensions are similar, at least for this basic usage, the structure of the solution looks pretty much the same.
We’ve got a close-zip? function that takes advantage of Clojure’s handy set-asfunction feature, and a generate-greetings function that consists of a single for statement.
The for statement uses close-zip? to filter out people outside of the zips we care about, and then it generates a greeting to the people who are left.
Clojure also has a way to use a sequence comprehension-like syntax for side effects, though Clojure separates it out into a doseq macro.
Here we use doseq to print our list of greetings rather than gather them up:
Scala and Clojure’s sequence comprehensions are similar in some respects, though not all.
Scala’s for statement is generally used more pervasively, and often in ways that seem surprising to the uninitiated.
Also, while Scala’s pattern matching and Clojure’s destructuring have some similarity, both allow us to pick apart aggregate data structures; pattern matching in Scala is less flexible than Clojure’s destructuring.
Destructuring lets us pick apart arbitrary maps and vectors, while Scala’s pattern matching is confined to case classes and a few other constructs that are statically defined at compile time.
One nonobvious difference between Iterator and the solutions we covered in this chapter is that Iterator is fundamentally imperative because it relies on mutable state.
Every iterator has a bit of state inside it that keeps track of where the iterator is currently.
This can get you in trouble if you start passing iterators around and part of your program unexpectedly advances the iterator, affecting another part.
In contrast, the solutions we’ve gone over in this chapter rely on transforming one immutable sequence into another.
In fact, the sequence comprehensions we went over are both examples of a technique popularized by the highly functional language Haskell that is known as monadic transformations, which rely on a concept from category theory known as monads.
Explaining monads is a bit of a cottage industry among functional programmers and has inspired many a blog post attempting to explain monads by analogy to, among other things, burritos, elephants, writing desks, and Muppets.
We won’t put you through another such explanation here; it’s not necessary to understand monads to use sequence comprehensions, and neither Scala nor Clojure particularly emphasize the monadic nature of their respective comprehensions.
At a very high level though, one of the things monads do is provide a way to program in a very functional style by transforming immutable data in a pipeline rather than relying on mutable state.
To specify the outline of an algorithm, letting callers plug in some of the specifics.
The Template Method pattern consists of an abstract class that defines some operation, or set of operations, in terms of abstract suboperations.
Users of Template Method implement the abstract template class to provide implementation of the substeps.
To use it, extend the TemplateExample and implement the abstract suboperations.
For instance, to use Template Method for board games, create a Game template that defines the abstract set of steps it takes to play a board game (setUpBoard(), makeMove(), declareWinner(), and so on)
To implement any particular board game, extend the abstract Game class and implement the substeps as appropriate for a particular game.
Our functional replacement for Template Method will satisfy its intent, which is to create a skeleton for some algorithm and let callers plug in the details.
Instead of using classes to implement our suboperations, we’ll use higherorder functions; and instead of relying on subclassing, we’ll rely on function composition.
We’ll do so by passing the suboperations into a Function Builder and having it return a new function that does the full operation.
An outline of this approach in Scala looks like so:
This lets us program more directly, since we no longer need to define suboperations and subclasses.
As an example, let’s take a look at a template method that prints grade reports.
The first takes a list of grades in numeric form and translates them into letter form, and the second formats and prints the report.
Since those two steps can be done in many different ways, we’ll just specify the skeleton required to create a grade report, translate the grades first, and then format and print the report, and we’ll leave it up to individual implementations to specify exactly how the grades are translated and the report is printed.
The first translates to the full letter grades A, B, C, D, and F and prints a simple histogram.
The second adds plus and minus grades to some of the letters and prints a full list of grades.
The numToLetter() method specifies how to convert a single numeric grade into a letter grade, and printGradeReport() specifies how to format and print a grade report.
Both methods must be implemented by users of the template.
To get template implementations with different behaviors, the user of the Template class creates different subclasses with different implementations of numToLetter() and printGradeReport()
Instead of relying on inheritance, the Scala replacement for Template Method uses Function Builder to compose together suboperations.
We’ll also need a couple of different implementations of the numToLetter() and printGradeReport() functions so we can see this solution in action.
It takes numToLetter() and printGradeReport() as arguments and produces a new function that takes a Seq[Double] to represent a list of grades.
It then uses map() to convert each grade to a letter grade and passes the new list into printGradeReport()
Now let’s take a look at the functions we’ll need to convert to full letter grades and to print a histogram.
It uses a method named groupBy() to group grades together into a Map, which it then turns into a list of tuples of counts using the map() method.
Finally, it uses a for comprehension to print the histogram, as the code below shows:
Let’s take a look at this sample line by line, starting with the first line of printHistogram()’s body:
The groupBy() method takes in a function and uses it to group together all the elements of a sequence for which the function returns the same value.
Here we pass in the identify function, which just returns whatever was passed in so we can group together all grades that are the same.
The REPL output below shows us using this snippet to group together a vector of grades:
Next we take the map of grouped grades and use map() and toSeq() to turn it into a sequence of tuples, where the first element is the grade and the second element is the grade count.
By default, Scala sorts sequences of tuples by their first element, so this gives us a sorted sequence of grade counts.
The REPL output below shows us using this code snippet to get our sequence of grade counts:
Finally we use a for comprehension over the sequence of tuples to print up a histogram of grades, as the snippet below shows:
It can be used to repeat a string, as the following REPL output demonstrates:
Now if we want to change the way we do our grade conversion and report printing, we only need to create additional conversion and reporting functions.
Let’s see how to rewrite the Template Method example that converts to plus/minus grades and prints up a full list of them.
The second is the printAllGrades() method, which just prints a simple list of converted grades.
Next up, let’s take a look at how things look in Clojure.
Let’s take a look at the code for it first:
Converting a numeric grade to a full letter grade is just a matter of a simple cond expression, as we can see below:
Printing a histogram can be done much the way we did it in Scala, using groupby to group grades together, mapping a function over the grouped grades to get counts, and then using a sequence comprehension to print the final histogram.
The print-all-grades function simply uses a sequence comprehension to print each grade:
Let’s wrap up with some discussion on how the Template Method compares to its functional replacement.
Our functional replacement for Template Method fulfills the same intent but operates quite differently.
Instead of using subtypes to implement specific suboperations, we use functional composition and higher-order functions.
This mirrors the old object-oriented preference of composition over inheritance.
Even in the object-oriented world, I prefer to use the pattern described in.
Replacing Dependency Injection to inject suboperations into a class, rather than using Template Method and subclassing.
The biggest reason for this is that it helps to prevent code duplication.
For instance, in the example we used in this chapter, if we wanted a class that printed a histogram of plus/minus grades, we would have to either create a deeper inheritance hierarchy or cut and paste code from the existing implementations.
In a real system, this can get fragile very quickly.
Composition also does a better job of making an API explicit.
The Template Method class may expose protected helper methods that are used by framework code but shouldn’t be used by a client.
The only way to indicate this is with comments in the API documentation.
To define an algorithm in abstract terms so it can be implemented in several different ways, and to allow it to be injected into clients so it can be used across several different clients.
The first is an interface that represents some algorithm, such as a bit of validation logic or a sorting routine.
The second is one or more implementations of that interface; these are the strategy classes themselves.
For instance, we may have several different ways we want to validate a set of data input from a form on a website, and we may want to use that validation code in several places.
We could create a Validator interface with a validate() method to serve as our strategy object, along with several implementations that could be injected into our code at the appropriate spots.
Still, this suggests a straightforward replacement for Strategy in the functional world.
To replace the strategy classes, we use higher-order functions that implement the needed algorithms.
This avoids the need to create and apply interfaces for different strategy implementations.
From there, it’s straightforward to pass our strategy functions around and use them where needed.
One common use of Strategy is to create different algorithms that can be used to validate the same set of data.
Let’s take a look at an example of using Strategy to do just that.
We’ll implement two different validation strategies for a person that contain a first, middle, and last name.
The first strategy will consider the person valid if he or she has a first name, the second will only consider the person valid if all three names are set.
On top of that, we’ll look at some simple client code that collects valid people together.
In Java, we need a PersonValidator interface, which our two validation strategies, FirstNameValidator and FullNameValidator, will implement.
The validators themselves are straightforward; they return true if they consider the person valid and false otherwise.
The validators can then be composed in the PersonCollector class, which will collect People objects that pass validation.
This works fine, but it involves spreading our logic across several classes for no particularly good reason.
Let’s see how we can simplify Strategy using functional techniques.
In Scala, there’s no need for the PersonValidator interface we saw in the Java examples.
Instead, we’ll just use plain old functions to do our validation.
To carry a person around, we’ll rely on a case class with attributes for each part of a person’s name.
Finally, instead of using a full-on class for the person.
This is a pretty standard case class, but notice how we’re using Option[String] to represent the names instead of just String, since this case class represents a person that may have parts of the name missing:
Now let’s take a look at our first name validator, a function called isFirstNameValid()
As the code below shows, we use the isDefined() method on Scala’s Option, which returns true if the Option contains Some and returns false otherwise to see whether the person has a first name:
Here, we use a Scala match statement to pick apart a Person, and then we ensure that each name is there using isDefined()
Finally, our person collector, a function aptly named personCollector(), takes in a validation function and produces another function that’s responsible for collecting valid people.
It does so by running a passed-in person through the validation function.
It then appends it to an immutable vector and stores a reference to the new vector in the validPeople var if it passes validation.
Let’s take a look at our validators and person-collector at work, starting with creating a person-collector that considers single names valid and one that only considers full names valid:
As we can see, the two collectors work as they should, delegating to the validation functions that were passed in when they were created.
In Clojure, we’ll solve our person-collecting problem in a similar way to Scala, using functions for the validators and a higher-order function that takes in a validator and produces a person-collecting function.
To represent the people, we’ll use good old Clojure maps.
Since Clojure is a dynamic language and doesn’t have Scala’s Option typing, we’ll use nil to represent the lack of a name.
It checks to see if the :first-name of the person is not nil and returns true if so; otherwise it returns false.
The full-name-valid? function pulls out all three names and returns true only if they’re all not nil:
Finally, let’s take a look at our person-collector, which takes in a validation function and produces a collector function.
This works almost exactly like the Scala version, the main difference being that we need to use an atom to store a reference to our immutable vector in an atom.
Before we wrap up, let’s see our Clojure person collection in action, starting by defining the collector functions as we do below:
And we can run it through our collectors, starting with the collector that only requires a first name for the person to be valid:
Then we finish up with the collector that requires the full name for the person to be valid:
Both work as expected, validating the passed-in name before storing it if valid and then returning the full set of valid names.
Both are ways to inject some bit of custom code into a larger framework or algorithm.
Strategy does so using composition, and Template Method does so using inheritance.
We replaced both patterns with ones based on functional composition.
Though both Clojure and Scala have language features that allow us to build hierarchies, we’ve replaced both Template Method and Strategy with patterns based on functional composition.
This leads to simpler solutions to common problems, mirroring the old object-oriented preference to favor composition over inheritance.
To avoid scattering null checks throughout our code by encapsulating the action taken for null references into a surrogate null object.
A common way to represent the lack of a value in Java is to use a null reference.
This leads to a lot of code that looks like so:
This style leads to scattering null handling logic throughout our code, often repeating it.
A common solution to this is to create a singleton null object that has the same interface as our real objects but implements our default behavior.
We can then use this object in place of null references.
We can avoid scattering null checks throughout our code, which keeps our code clean and easier to read.
We can centralize logic that deals with handling the absence of a value.
Pervasive use of the pattern means that your program probably won’t fail fast.
You may generate a null object due to a bug and not know until much later in the program’s execution, which makes it much harder to track down the source of the bug.
In Java, I generally use Null Object judiciously when I know that there’s a good reason why I may not have a value for something and use null checks elsewhere.
For instance, let’s imagine we’re writing part of a system that looks up a person by a generated, unique ID.
If the IDs are closely related to the system we’re writing and we know that every lookup should succeed and return a person, I’d stick with using null references.
This way, if something goes wrong and we don’t have a person, we fail fast and don’t pass the problem on.
However, if the IDs aren’t closely related to our program, I’d probably use Null Object.
Say, for instance, that the IDs are generated by some other system and imported into ours via a batch process, which means that there’s some latency between when the ID is created and when it becomes available to our system.
In this case, handling a missing ID would be part of our program’s normal operation, and I’d use Null Object to keep the code clean and avoid extraneous null checks.
In Scala, we’ll take advantage of static typing and Option typing to replace null object references.
In Clojure, we’ll primarily focus on Clojure’s treatment of nil, but we’ll also touch on Clojure’s optional static typing system, which provides us with an Option much like Scala’s.
We have null references in Scala just as we do in Java; however, it’s not common to use them.
Instead we can take advantage of the type system to replace both null references and Null Object.
The first, Option, lets us indicate that we may not have a value in a type-safe manner.
The second, Either, lets us provide a value when we’ve got one and a default or error value when we don’t.
Option types are containers, much like a Map or a Vector, except they can only hold one element at most.
Option has two important subtypes: Some, which carries a value, and the singleton object None, which does not.
In the following code, we create a Some[String] that carries the value "foo" and a reference to None:
Now we can work with our Option instances in a variety of ways.
The getOrElse() method is called with a single argument, a default value.
When called on an instance of Some, the carried value is returned; when called on None the default value is returned.
When working with Option, it’s cleanest to treat a value as another container type.
For example, if we need to do something to a value inside an Option, we can use our old friend map(), as in the following code:
We’ll examine some more-sophisticated ways of working with Option in the code samples.
One final note on Option: In its simplest form, it can be used much as we’d use a null check in Java, though there are more powerful ways to use it.
However, even in this simplest form, there’s one major difference.
Option is part of the type system, so if we use it consistently we know exactly in which parts of our code we may have to deal with the lack of a value or a default value.
Everywhere else we can write code safe in the knowledge that we’ll have a value.
In Clojure, we don’t have the Option typing that Scala’s static type system provides us.
Instead, we’ve got nil, which is equivalent to Java’s null at the bytecode level.
However, Clojure provides several convenient features that make it much cleaner to deal with the lack of a value using nil and that give us many of the same benefits we get with Null Object.
First up, nil is treated the same as false in Clojure.
Combined with a pervasive use of expressions, this makes it much simpler to do a nil check in Clojure than it is to check for null in Java, as the following code demonstrates:
Second, the functions that we use to get values of our Clojure’s composite data structures provide a way to get a default value if the element we’re trying.
Here we use the get method to try to retrieve the value for :foo from an empty map, and we get back our passed-in default value instead:
The lack of a value for a key is distinct from a key that has the value of nil, as this code demonstrates:
We’ll start by looking at how we’d use Null Object as a default when we don’t get back a value from a map lookup.
In this example, we’ll have a map full of people keyed off of an ID.
If we don’t find a person for a given ID, we need to return a default person with the name “John Doe.”
In classic Java, we’ll create a Person interface with two subclasses, RealPerson and NullPerson.
The first, RealPerson, allows us to set a first and last name, while NullPerson has them hardcoded to "John" and "Doe"
If we get a null back when we try to get a person by ID, we return an instance of NullPerson; otherwise we use the RealPerson we got out of the map.
Let’s see how we can use Scala’s Option to eliminate the explicit null check we need to do in Java.
In Scala, the get() on Map doesn’t return a value directly.
If the key exists, the value is returned wrapped in a Some, otherwise a None is returned.
When we try to fetch either of them using get(), we get back a String wrapped in a Some.
We could work with the Option type directly, but Scala provides a nice shorthand that lets us get back a default value directly from a map, getOrElse()
In the following REPL output, we use it to attempt to fetch the value for the key 3 from the map.
Since it’s not there, we get back our default value instead.
Now let’s see how we can use this handy feature to implement our personfetching example.
Here we’re using a trait as the base type for our people, and we’re using case classes for the RealPerson and NullPerson.
We can then use an instance of NullPerson as the default value in our lookup.
Let’s define some test data so we can see this approach at work:
Now if we use fetchPerson() on a key that exists, it’s returned; otherwise our default person is returned:
Now let’s take a look at how we can accomplish this in Clojure.
When we try to look up a nonexistent key from a map in Clojure, nil is returned.
Clojure provides another way to look up keys from a map, the get function, which lets us provide an optional default value.
The following REPL snippet shows a simple example of get in action.
To write our person lookup example in Clojure, all we need to do is define a default null-person.
We then pass it into get as a default value when we try to do our lookup, as the following code and REPL output demonstrates:
The code in this example deals with a basic use of Null Object as a default value at lookup time.
Next up, let’s take a look at how we’d handle working with Null Object and its replacements when the time comes to modify them.
Let’s take a look at our person example from a different angle.
This time, instead of looking up a person that may not exist, we want to create a person only if we’ve got a valid first and last name.
If we have both a first and last name available to use, we’ll use a RealPerson; otherwise we’ll use a NullPerson.
To do this, we write a buildPerson() that takes a firstName and a lastName.
If either is null, we return a NullPerson; otherwise we return a RealPerson built with the passed-in names.
This approach allows us to minimize the surface area of our code where we need to deal with null, which helps cut down on surprise null pointers.
Now let’s see how we can accomplish the same in Scala without needing to introduce an extraneous null object.
Our Scala approach to this problem will take advantage of Option instead of creating a special Null Object type.
The firstName and lastName we pass into buildPerson() are Option[String]s, and we return an Option[Person]
If both firstName and lastName are Some[String], then we return a Some[Person]; otherwise we return a None.
The right way to do this in Scala is to treat the Options as we would treat any other container, such as a Map or a Vector.
Earlier we saw a simple example of using the map() method on an instance of Some.
Let’s look at how we’d use Scala’s most powerful sequence manipulation tool, the sequence comprehensions we introduced in Sample Code: Sequence Comprehensions, on page 77, to manipulate Option types.
In the following snippet, we define a simple vector and a few option types:
As we can see in the following code, manipulating a Some looks much like manipulating a Vector with a single value in it:
The real power of using a for comprehension to work with Option comes in when we’re working with multiple Options at a time.
We can use multiple generators, one for each option, to get at the values in each.
In the following code, we use this technique to pull the strings out of someFoo and someBar and put them into a tuple, which we then yield:
When working with options in this fashion, if any of the generators produces a None, then the value of the entire expression is a None.
This gives us a clean syntax for working with Some and None:
We can now apply this to our person-building example pretty simply.
We use two generators in our for comprehensions, one for the firstName and one for the lastName.
The for comprehension wraps that up inside of an Option, and we use getOrElse() to get at it or use a default.
Let’s finish up the example by seeing how to handle person-building in Clojure.
In Clojure, our person-building example boils down to a simple nil check.
If they’re both not-nil, we use them to create a person; otherwise we create a default person.
Clojure’s treatment of nil as a “falsey” value makes this convenient to do, but otherwise it’s very similar to our Java approach.
Here it produces a real person and a default person:
Let’s take one last look at handling nothing by examining a case in which we have many parts of our code that want to deal with the lack of a value in the same way.
The idiomatic approach to handling the lack of a value in Clojure versus Scala is very different.
The difference comes down to Scala’s static type system and Clojure’s dynamic one.
Scala’s static type system and type parameters make the Option type possible.
The tradeoffs that Scala and Clojure make here mirror the general tradeoffs between static and dynamic typing.
With Scala’s approach, the compiler helps to ensure that we’re properly handling nothing at compile time, though we have to be careful not to let Java’s null creep into our Scala code.
With Clojure’s approach, we’ve got the possibility for null pointers just about anywhere, just as in Java.
We need to be more careful that we’re handling them appropriately, or we risk runtime errors.
My preference is to take care of all my nothing handling at the outermost layer of my code, whether I’m using Scala’s Option typing or the null/nil that Java and Clojure share.
For instance, if I’m querying a database for a person who may or may not exist, I prefer to check for his/her existence only once:
Then I use the techniques outlined in this pattern to create a default person if necessary.
This allows the rest of my code to avoid doing null checks or to deal with Option typing.
I’ve found that Scala’s approach to Option typing makes it much easier to write programs in this style, because it forces us to explicitly deal with the lack of a value whenever we might not have one and to assume that we’ll have a value everywhere else.
To add behavior to an individual object rather than to an entire class of objects—this allows us to change the behavior of an existing class.
Decorator is useful when we’ve got an existing class that we need to add some behavior to but we can’t change the existing class.
We may want to introduce a breaking change, but we can’t change every other part of the system where the class is used.
Or the class may be part of a library that we can’t, or don’t want to, modify.
It starts with an interface with at least one concrete implementation.
This implementation is the class that we can’t or don’t want to change.
We then implement the interface with an abstract decorator class, which gets an instance of our existing, concrete class composed into it.
Our abstract decorator class can itself have several implementations, which tweak the behavior of the existing class using composition, as shown in this figure:
This gives us some ability to add or modify behavior on existing classes, but we’re mostly limited to small tweaks since we rely on the base behavior of the composed class.
The essence of Decorator is wrapping an existing class with a new one so that the new class can tweak the behavior of the existing one.
In the functional world, one simple replacement is to create a higher-order function that takes in the existing function and returns a new, wrapped function.
The wrapped function does its job and then delegates to the existing function.
For instance, we could create a wrapWithLogger() function that wraps up an existing function with a bit of logging, returning a new function.
Let’s take a look at using Decorator with a basic four-function calculator.
The calculator has four operations, add(), subtract(), multiply(), and divide()
To demonstrate Decorator, we’ll take a basic calculator and decorate it so that it logs out the calculation it’s performing to the console.
In Java, our solution consists of an interface and two concrete classes.
The Calculator interface is implemented by both CalculatorImp and LoggingCalculator.
The LoggingCalculator class serves as our decorator and needs a CalculatorImpl composed into it to do its job.
An outline of this approach can be found in the following image:
The LoggingCalculator class delegates to the composed CalculatorImpl and then logs the calculation to the console.
In Scala, our calculator is just a collection of four functions.
To keep things simple, we’ll constrain ourselves to integer operations, since implementing generic numeric functions in Scala is a bit involved.
To wrap our calculator functions in logging code, we use makeLogger()
This is a higher-order function that takes in a calculator function and returns a new function that runs the original calculator function and prints the result to the console before returning it.
To use makeLogger(), we run our original calculator functions through it and assign the results into new vals, as the following code shows:
Now we can use our printing calculator function to do some arithmetic and print the results:
Let’s take a look at our calculator solution in Clojure.
The structure of our Clojure solution is similar to the Scala one, the main difference being that our Clojure solution isn’t constrained to integers since Clojure is dynamically typed.
Next we need a make-logger higher-order function to wrap our calculator functions up with logging code:
Finally, we can create some logging calculator functions and use them to do some logging math:
It’s no accident that the Scala and Clojure solutions to the calculator problem are so similar: they both rely only on basic higher-order functions, which are similar across both languages.
To encapsulate an action to be performed on a data structure in a way that allows the addition of new operations to the data structure without having to modify it.
A common sticking point in large, long-lived programs is how to extend a data type.
First, we may want to add new operations to existing implementations of the data type.
Second, we may want to add new implementations of the data type.
We’d like to be able to do this without recompiling the original source, indeed, possibly without even having access to it.
This is a problem that’s as old as programming itself, and it’s now known as the expression problem.
For example, consider Java’s Collection as a sample data type.
The Collection interface defines many methods, or operations, and has many implementations.
In a perfect world, we’d be able to easily add both new operations to Collection as well as new implementations of Collection.
In object-oriented languages, however, it’s only easy to do the latter.
We can create a new implementation of Collection by implementing the interface.
If we want to add new operations to Collection that work with all the existing Collection implementation, we’re out of luck.
In Java, we often get around this by creating a class full of static utility methods, rather than by adding the operations directly to the data type.
One such library for Collection is the Apache foundation’s CollectionUtils.
Visitor is another partial solution to this sort of problem.
It allows us to add new operations to an existing data type and is often used with tree-structured data.
Visitor allows us to fairly easily add new operations to an existing data type, but it makes adding new implementations of the data type difficult.
The Visitor class diagram (shown in the following figure) shows the main pieces of the Visitor pattern.
Our data type here is the DataElement class, which has two implementations.
Instead of implementing operations directly on the subclasses of DataElement, we create an accept() method that takes a Visitor and calls visit(), passing itself in.
This inverts the normal object-oriented constraint that it’s easy to add new implementations of a data type but difficult to add new operations.
If we want to add a new operation, we just need to create a new visitor and write code such that it knows how to visit each existing concrete element.
To do so, we’d need to modify all of the existing visitors to know how to visit the new DataElement implementation.
If those Visitor classes are outside of our control, it may be impossible!
The Visitor pattern makes it possible to add new operations to an object-oriented data type but difficult, or impossible, to add new implementations of the type.
It’s easy to add a new operation on some data type by writing a new function that operates on it, but it’s difficult to add new data types to an existing operation.
In our replacements, we’ll examine a few different ways to deal with this extensibility problem in Scala and Clojure.
In part, this is because Scala is statically typed while.
This means that Scala has a harder problem to solve in that it attempts to perform its extensions while preserving static type safety.
The other difference is that Scala’s take on polymorphism is an extension of the traditional object-oriented model, which uses a hierarchy of subclasses.
Clojure takes a novel view and provides polymorphism in a more ad hoc manner.
Since polymorphism is intimately bound up with extensibility, this affects the overall shape of the solutions.
Since Scala is a hybrid language, extending existing code requires us to dip into its object-oriented features, especially its type system.
First we’ll look at a method of extending the operations in an existing library that uses Scala’s implicit conversion system.
This allows us to add new operations to existing libraries.
Second we’ll look at a solution that takes advantage of Scala’s mix-in inheritance and traits, which allows us to easily add both new operations and new implementations to a data type.
In Clojure we’ll take a look at the language’s unique take on polymorphism.
These allow us to specify data types and the operations performed on them independently and to extend datatypes with both new implementations and new operations while taking advantage of the JVMs highly optimized method dispatch.
These allow us to provide our own dispatch function, which lets us dispatch a method call however we please.
They’re more flexible than protocols but slower, since they require an additional function call to the user-provided dispatch function.
The Scala and Clojure solutions we examine aren’t exactly equivalent, but they both provide flexible ways to extend existing code.
In this example, we’ll look at a Person type and see how we can extend it to have both new implementations and operations.
This doesn’t replace the full Visitor pattern, but it’s a simpler example of the sorts of problems that Visitor touches on.
The code that we’ll look at here is a basic example of extending an existing library without wrapping the original objects.
In Java, it would be easy to create new implementations of a Person type, assuming the original libraries’ authors defined an interface for it.
We can’t just create a subinterface of Person with new methods, as that could no longer be used in place of a plain Person.
Wrapping Person in a new class is also out for the same reason.
Java doesn’t have a good story for extending an existing type to have new operations, so we often end up faking it by creating classes full of static utility methods that operate on the type.
Scala and Clojure give us more flexibility to extend along both dimensions.
The trait specifies methods to get a person’s first name, last name, house number, and street.
In addition, there’s a method to get the person’s full name, as the following code shows:
Now let’s create an implementation of our Person type, SimplePerson.
We’ll take advantage of the fact that Scala will automatically create methods that expose the attributes passed into a constructor.
The only method we need to implement by hand is fullName(), as the following code snippet shows:
Now we can create a SimplePerson and call the fullName() method:
What if we want to extend the Person type to have another operation, fullAddress()? One way to do so would be to simply create a new subtype with the new operation, but then we couldn’t use that new type where a Person is needed.
In Scala a better way is to define an implicit conversion that converts from a Person to a new class with the fullAddress() method.
An implicit conversion changes from one type to another depending on context.
Most languages have a certain set of explicit conversions, or casts, built in.
For instance, if you use the + operator on an int and a String in Java, the int will be converted to a String and the two will be concatenated.
One way to do so is by using an implicit class.
An implicit class exposes its constructor as a candidate for implicit conversions.
The following code snippet creates an implicit class that converts from a Person to an ExtendedPerson with a fullAddress():
Now when we try to call fullAddress() on a Person, the Scala compiler will realize that the Person type has no such method.
It will then search for an implicit conversion from a Person to a type that does and find it in the ExtendedPerson class.
The compiler will then construct an ExtendedPerson by passing the Person into its primary constructor and call fullAddress() on it, as the following REPL output demonstrates:
Now that we’ve seen the trick that allows us to simulate adding new methods to an existing type, the hard part is done.
Adding a new implementation of the type is as simple as creating a new implementation of the original Person trait.
Let’s take a look at a Person implementation called ComplexPerson that uses separate objects for its name and its address:
This means we were able to extend a data type with both a new operation and a new implementation.
Let’s take a look at our extensible persons example in Clojure.
We’ll start by defining a protocol with a single operation in it, extract-name.
This operation is intended to extract a full name out of a person and is defined in the following code snippet:
Now we can create a Clojure record, SimplePerson, using defrecord.
This creates a data type with several fields on it:
We can create a new instance of a SimplePerson using the ->SimplePerson factory function, as we do in the following snippet:
Once created, we can get at fields in the data type as if it were a map with keywords for keys.
In the following snippet, we get the first name out of our simple person instance:
Notice how we defined our data type and the set of operations independently? To hook the two together, we can use extend-type to have our SimplePerson implement the NameExtractor protocol, as we do in the following snippet:
Now we can call extract-name on a SimplePerson and have it extract the person’s full name:
Now let’s see how to create a new type, ComplexPerson, which represents its name and address as an embedded map.
We’ll use a version of defrecord that allows us to extend the type to a protocol at the same time we create it.
This is just a convenience; the record and protocol that we’ve created are still their own entities:
Now we can create a ComplexPerson and extract its full name:
To add a new operation or set of operations to our existing types, we only need to create a new protocol and extend the types.
In the following snippet, we create a protocol that allows us to extract an address from a person:
Now we can extend our existing types to conform to the new protocol, as we do in the following code:
As we can see from the following REPL output, both of our datatypes now conform to the new protocol:
While we’ve used Scala’s implicit conversions and Clojure protocols to achieve a similar end here, they’re not the same.
In Scala, the operations we saw were methods defined on classes, which are part of a type.
Scala’s implicit conversion technique allows us to implicitly convert from one type to another, which makes it look as if we can add operations to an existing type.
Clojure’s protocols, on the other hand, define sets of operations and types completely independently via protocols and records.
We can then extend any record with any number of protocols, which allows us to easily extend an existing solution both with new operations and new types.
We’ll start off by defining two shapes, a circle and a rectangle, and an operation that calculates their perimeters.
Then we’ll show how we can independently add new shapes that work with the existing perimeter operation and new operations that work with our existing shapes.
Finally, we’ll show how to combine both types of extensions.
In Java, this is a problem that’s impossible to solve well.
Extending the shape type to have additional implementations is easy.
If we want to extend Shape so that it has new implementations, it’s a bit more difficult, but we can use Visitor as demonstrated in the Visitor Classes diagram.
However, if we go this route, it’s now difficult to have new implementations because we’d have to modify all of the existing Visitors.
In Java, we need to decide at the outset whether we want to add new operations over our Shape or whether we want new implementations of it.
In Scala, we use a simplified version of a technique introduced in a paper written by Scala’s designer, Martin Odersky.
We’ll create a trait, Shape, to serve as the base for all of our shapes.
We’ll start off with a single method, perimeter(), and two implementations, Circle and Rectangle.
To perform our extension magic, we’ll use some advanced features of Scala’s type system.
First, we’ll take advantage of the fact that we can use Scala’s traits as modules.
At each step, we’ll package our code in a top-level trait separate from the one we’re using to represent Shape.
This allows us to bundle sets of data types and operations together and to extend those bundles later on using Scala’s mix-in inheritance.
Then we can have a new type extend many different traits, an ability we take advantage of to combine independent extensions.
Let’s dig into the code, starting with our initial Shape trait and the first two implementations:
Outside of the top-level PerimeterShapes trait, this is a pretty straightforward declaration of a Shape trait and a couple of implementations.
To use our shape code we can extend an object with the top-level trait.
This adds our Shape trait and its implementations to the object.
We can now use them directly or easily import them into the REPL, as we do in the following code:
Now we can import our shapes into the REPL and try them out, like in the following snippet:
Extending our Shape with new operations is what’s difficult in most purely object-oriented languages, so let’s tackle that first.
Inside of AreaShapes we extend our initial Shape class to have an area() method, and we create a new Circle and a new Rectangle, which implement area()
First we create our top-level trait AreaShapes, which extends PerimeterShapes.
This lets us easily refer to and extend the classes and trait inside of AreaShapes:
Next we create a new Shape trait inside of AreaShapes and have it extend the old one inside of PerimeterShapes:
We need to refer to the Shape class in PerimeterShapes as super.Shape to differentiate it from the one we just created in AreaShapes.
To so we first extend our old Circle and Rectangle classes, and then we mix in our new Shape trait, which has area() on it.
Finally, we implement the area() on our new Circle and Rectangle, as shown in the following snippet:
Now we can create some sample shapes and see both perimeter() and area() in action:
That covers the hard part, extending Shape with a new operation.
We’ll extend Shape to have a new implementation by creating a Square class.
Inside, we create a new Square implementation of our original trait class.
The first piece of our extension is in the following code:
Inside this trait, we extend the Square we just created to also have an area() method:
Now we can add a Square to our test shapes and see the full set of shapes and operations in action, as we do in the following code:
Now we’ve successfully added both new implementations of Shape and new operations over it, and we’ve done so in a typesafe manner!
Our Clojure solution relies on multimethods, which let us specify an arbitrary dispatch function.
This doesn’t specify any implementations of the method; rather, it contains a dispatch function.
In the following snippet we create a multimethod named test-multimethod.
The dispatch function is a function of one argument, and it returns that argument untouched.
Method definitions look much like function definitions, except that they also contain a dispatching value, which corresponds to the values returned from the dispatch function.
In the following snippet, we define two implementations of test-multimethod.
The first expects a dispatch value of :foo, and the second, :bar.
When the multimethod is called, the dispatch function is first called, and then Clojure dispatches the call to the method with the matching dispatch value.
Since our dispatch function returns its input, we call it with the desired dispatch values.
Now that we’ve seen a basic example of multimethods in action, let’s dig a bit deeper in.
The dispatch function expects a map that represents our shape.
One of the keys in the map is :shape-name, which the dispatch function extracts as our dispatch value.
Our perimeter multimethod is defined below, along with implementations for the circle and the rectangle:
To add new operations, we create a new multimethod that handles the existing dispatch values.
In the following snippet, we add support for an area operation:
Now we can calculate an area for our shapes as well:
To add a new shape into the set of shapes we can handle across both the perimeter and area operations, we add new implementations of our multimethods that handle the appropriate dispatch values.
Let’s add a square to our vector of test shapes:
And we can verify that our operations work on squares as well:
We’ve only scratched the surface of what multimethods can do.
Since we can specify an arbitrary dispatch function, we can dispatch on just about anything.
Clojure also provides a way to make multimethods work with user-defined hierarchies, much like class hierarchies in object-oriented languages.
However, even the simple usage of multimethods we just saw is enough to replace the interesting aspects of the Visitor pattern.
Scala has a much harder problem to solve here, since it maintains static type safety while allowing for extensions both to implementations of a data type and the operations performed on it.
Since Clojure is dynamically typed, it has no such requirement.
Our Visitor replacements are a great example of the tradeoffs between an expressive statically typed language like Scala and a dynamically typed language like Clojure.
We had to expend more effort in Scala, and our solutions aren’t quite as straightforward as the Clojure solutions.
However, if we try to perform some operation on a type that can’t handle it in Clojure, it’s a runtime rather than a compile-time problem.
To compose objects together using an external configuration or code, rather than having an object instantiate its own dependencies—this allows us to easily inject different dependency implementations into an object and provides a centralized place to understand what dependencies a given object has.
Objects are the primary unit of composition in the object-oriented world.
In its simplest form, all that’s involved in Dependency Injection is to inject an object’s dependencies through a constructor or setter.
For instance, the following class outlines a movie service that’s capable of returning a user’s favorite movies.
It depends on a favorites service to pull back a list of favorite movies and a movie DAO to fetch details about individual movies:
When it’s constructed, the MovieService class needs to have its dependencies passed in.
It makes it easy to change the implementation for a given dependency, which is especially handy for swapping out a real dependency with a stub in a unit test.
With appropriate container support, dependency injection can also make it easier to declaratively specify the overall shape of a system, as each component has its dependencies injected into it in a configuration file or in a bit of configuration code.
There’s less of a need for a Dependency Injection–like pattern when programming in a more functional style.
Since this involves composing functions much as Dependency Injection composes classes, we get some of the benefits for free just from functional composition.
However, simple functional composition doesn’t solve all of the problems Dependency Injection does.
This is especially true in Scala because it’s a hybrid language, and larger bodies of code are generally organized into objects.
We can even use familiar Java frameworks like Spring or Guice.
However, we can achieve many of the same goals without the need for any framework.
We’ll take a look at a Scala pattern called the Cake pattern.
This pattern uses Scala traits and self-type annotations to accomplish the same sort of composition and structure that we get with Dependency Injection without the need for a container.
The unit of injection in Clojure is the function, since Clojure is not object oriented.
For the most part, this means that the problems we solve with Dependency Injection in an object-oriented language don’t exist in Clojure, as we can naturally compose functions together.
However, one use for Dependency Injection does need a bit of special treatment in Clojure.
To stub out functions for testing purposes, we can use a macro named with-redfs, which allows us to temporarily replace a function with a stub.
There we created a movie service that allows us to do several movie-related actions.
Each video is associated with a movie and needs to be decorated with details related to that movie, such as the movie’s title.
To accomplish this, we’ve got a top-level movie service that depends on a movie DAO to get movie details and on a favorites service to fetch favorites for a given user.
In Java, our top-level MovieService is sketched out in the following class.
We use Dependency Injection to inject a FavoritesService and a MovieDao via a constructor:
In a full program, we’d then use a framework to wire up MovieService’s dependencies.
We have quite a few ways to do this, ranging from XML configuration files to Java configuration classes to annotations that automatically wire dependencies in.
All of these share one common trait: they need an external framework to be effective.
Here we’ll examine Scala and Clojure options that have no such limitation.
Now we’ll take a look at an example of Scala’s Cake pattern.
The rough idea is that we’ll encapsulate the dependencies we want to inject inside of toplevel traits, which represent our injectable components.
Instead of instantiating dependencies directly inside of the trait, we create abstract vals that will hold references to them when we wire everything up.
We’ll then use Scala’s self-type annotation and mixin inheritance to specify wiring in a typesafe manner.
Finally, we use a simple Scala object as a component registry.
We mix all of our dependencies into the container object and instantiate them, holding references to them in the abstract vals mentioned previously.
As we mentioned before, it doesn’t require an outside container to use.
Let’s start off with a look at the data we’ll be operating over.
We’ve got three case classes, a Movie, a Video, and a DecoratedMovie, which represents a movie decorated with a video about it.
Now let’s define some traits as interfaces for our dependencies, FavoritesService and MovieDao.
We’ll nest these traits inside of another set of traits that represent the injectable components.
We’ll see why this is necessary later in the example.
Next up, we’ve got our implementations of the components introduced previously.
Here we’ll stub out the MovieDao and FavoritesService to return static responses by implementing the interfaces.
Note that we need to extend the component traits we’ve wrapped them in as well.
Now let’s take a look at MovieServiceImpl, which depends on the FavoritesService and MovieDao defined previously.
Let’s take a closer look at this bit by bit.
This is part of the Scala magic that makes the Cake pattern typesafe.
Next up are the explicit vals that we’ll store references to our dependencies in:
Finally, we’ve got the object that serves as our component registry, ComponentRegistry.
The registry extends implementations of all of our dependencies and instantiates them, storing references to them in the abstract vals we previously defined:
Now we can pull a full wired-up MovieService out of the registry when needed:
Earlier I claimed that this wiring preserves static type safety.
However, this will get us another compiler error, which starts as follows:
Instead, we pass functions directly into other functions as needed.
However, in Clojure, we generally only do this sort of direct injection when we want the user of the function to have control over the passed-in dependencies.
We tend not to need it to define the overall shape of our programs.
Instead, programs in Clojure and other Lisps are generally organized as a series of layered, domain-specific languages.
While Dependency Injection is largely concerned with the organization of programs as a whole, one specific area in which it’s especially helpful is injecting stubbed-out dependencies into tests.
In Java, we can just take our MovieService and manually inject stubs or mocks into it using constructor injection.
Another option is to use the dependency injection container to instantiate a set of test dependencies.
The best approach depends on what sort of tests we’re currently writing.
For unit tests, it’s generally simpler to just manually inject individual mocks.
For larger integration-style tests, I prefer to go with the full-container approach.
With Scala’s Cake pattern, we can easily created mocked out versions of our dependencies.
Now we only need to mix in and instantiate the stubbed components rather than the real ones, and then our test movie service is ready to use:
However, since we don’t always structure whole Clojure programs by passing in every dependency as a higher-order function, we often need an alternative method for stubbing out test dependencies.
We can use with-redefs to temporarily redefine those dependencies, as we demonstrate below:
We need to use it here because laziness and with-redefs have a subtle interaction that can be confusing.
Without forcing the sequence to be realized, it won’t be fully realized until the REPL attempts to print it.
By that time, the rebound function bindings will have reverted to their original bindings.
As you might guess, replacing function definitions on the fly can be quite dangerous, so this is best saved only for test code.
Functional programming has its own set of patterns that have evolved out of the functional style.
Another theme in these patterns is the use of higher-order functions as a primary unit of composition.
This dovetails nicely with the first theme, immutability and transformation of immutable data.
One final theme we’ll explore is the ability of functional languages to be adapted to create little languages that solve particular problems.
This type of programming has spread well outside the functional style, but it started with the Lisp tradition that Clojure carries on.
Let’s take a look at our first pattern, Tail Recursion.
To repeat a computation without using mutable state and without overflowing the stack.
For example, let’s examine a trivial problem, writing a function that will calculate the sum from one up to an arbitrary number, inclusive.
The code below does just that, but it requires both i and sum to be mutable:
In its place, we can use recursion, which does not require immutability.
Recursion has its own problems, though; in particular, each recursive call will lead to another frame on the program’s call stack.
To get around that, we can use a particular form of recursion called tail recursion, which can be optimized to use a single frame on the stack, a process known as tail call optimization or TCO.
Let’s think about how we’d write the sum() as a recursive function, sumRecursive()
First, we need to decide when our recursion should stop and start.
Since we’re summing together all numbers stopping at some arbitrary number, it makes sense to work down from that number and stop at zero.
Next we need to figure out what to do to perform the actual computation.
In this case, we take the number we’re currently working on and add it to the results of calling tailRecursive() with that number minus one.
Eventually, we get down to our base case of zero, at which point the stack unwinds, returning.
Each recursive call adds a frame to the stack, which means this solution takes memory proportional to the size of the sequence we’re summing, as shown in the following figure.
An illustration of the stack during normal recursive calls—each recursive call adds a call to the stack; these frames represent memory that cannot be.
The ultimate cause for exploding stack use is that each time we make a recursive call, we need the result of that call to finish the computation we’re doing in the current call.
This means that the runtime has no choice but to store the intermediate results on the stack.
If we were to make sure that the recursive call was the last thing that happens in each branch of the function, known as the tail position, this would no longer be the case.
Doing so requires us to take the intermediate values that were formerly stored on the stack and pass them through the call chain.
Once we rewrite the function to be tail recursive, it’s possible to use TCO to run it in only a single stack frame, as shown in this figure.
With TCO, recursive calls in the tail position don’t generate a new stack frame.
Instead, each call uses the existing stack frame, removing whatever data.
Unfortunately, the JVM doesn’t support TCO directly, so Scala and Clojure need to use some tricks to compile their tail recursive calls down to the same bytecode used for iteration.
In Clojure’s case, this is done by providing two special forms, loop and recur, instead of using general purpose function calls.
In Scala’s case, the Scala compiler will attempt to translate tail recursive calls into iteration behind the scenes, and Scala provides an annotation, @tailrec, that can be placed on functions that are meant to be used in a tail recursive manner.
If the function is called recursively without being in the tail position, the compiler will generate an error.
Let’s take a look at a recursive solution to a simple problem.
We’ve got a sequence of first names and a sequence of last names, and we want to put them together to make people.
To solve this, we need to go through both sequences in lock step.
We’ll assume that some other part of the program has verified that the two sequences are of the same size.
At each step in the recursion, we’ll take the first element in both sequences and put them together to form a full name.
We’ll then pass the rest of each sequence onto the next recursive call along with a sequence of the people we’ve formed so far.
The first thing we’ll need is a Scala case class to represent our people.
Here we’ve got one with a first and a last name:
The first is a function named makePeople, which takes in two sequences, firstNames and lastNames.
The second is a helper function nested inside of makePeople, which adds an additional argument used to pass the list of people through recursive calls.
Let’s take a look at the whole function before we break it down into smaller parts:
This just says that makePeople takes two Seqs of String.
Since we don’t specify a return type, the compiler will infer it from the function body.
Next up, let’s look at the signature of the helper function.
This function is responsible for the actual tail recursive calls.
The helper function is annotated with a @tailrec annotation, which makes the compiler generate an error if it’s called recursively but not tail recursively.
The function signature simply adds an additional argument, the people vector, which will accumulate results through recursive calls.
Notice that we specified a return type here, though we generally omit it in our Scala examples.
This is because the compiler can’t infer types for recursively called functions.
If the firstNames sequence is empty, we return the list of people we’ve built up.
Otherwise, we pick the first first name and the first last name off of their respective sequences, create a Person out of them, and call the helper function again with the tail of the two sequences and the new person appended to the list of people:
Finally, we simply call helper with the sequences of names and an empty Vector to hold our people:
One closing note on the syntax: using some of Scala’s object-oriented features, namely methods, would let us cut out some of the verbosity that comes along with a recursive function definition.
Since we’re sticking mainly to the functional bits of Scala in this book, we’re using functions for most of the examples rather than methods.
Methods can often be used as higher-order functions in Scala, but it can sometimes be awkward to do so.
In Clojure, tail recursive calls are never optimized, so even a tail recursive call will end up consuming a stack frame.
Instead of providing TCO, Clojure gives us two forms, loop and recur.
The loop form defines a recursion point, and the keyword recur jumps back to it, passing it new values.
In practice, this looks almost exactly like defining a private helper function does, so the form of our solution is very similar to the Scala solution, though.
The first interesting bit of code here is the loop declaration.
Here, we define our recursion point and the values we’ll start our recursion at: the passed-in sequences of first and last names and an empty vector we’ll use to accumulate people as we recur.
The code snippet first-names first-names last-names last-names people [] might look a little funny, but all it’s doing is initializing the first-names and last-names that we’re defining in the loop to be the values that were passed into the function and the people to an empty vector.
The bulk of the example is in the if expression.
If the sequence of first names still has items in it, then we take the first item from each sequence, create a map to represent the person, and conj it onto our people accumulator.
Once we’ve conjed the new person onto the people vector, we use recur to jump back to the recursion point we defined with loop.
This is analogous to the recursive call that we made in the Scala example.
If we don’t jump back, we know that we’ve gone through the sequences of names, and we return the people we’ve constructed.
It may not be immediately apparent why the test in the if expression above works.
It’s because the seq of an empty collection is nil, which evaluates to false, while the seq of any other collection yields a nonempty sequence.
Using nil as the base case for a recursion when you’re dealing with sequences is common in Clojure.
In fact, the Scala and Clojure compilers will compile their respective ways of handling tail recursion down to the same sort of bytecode that iteration in Java would.
The main advantage of tail recursion over iteration is simply that it eliminates a source of mutability in the language, which is why it’s so popular in the functional world.
I personally prefer tail recursion over iteration for a couple of other minor reasons.
The first is that it eliminates an extra index variable.
The second is that it makes it explicit exactly what data structures are being operated on and what data structures are being generated, because they’re both passed as arguments through the call chain.
In an iterative solution, if we were trying to operate on two sequences in lock step and generate another data structure, they would all just be mixed in with the body of a function that may be doing other things.
I’ve found that using tail recursion over iteration acts as a nice forcing factor to structure our functions well, since all of the data we’re operating on must be passed through the call chain, and it’s hard to do that if you’ve got more than a few pieces of data.
Since tail recursion is equivalent to iteration, it’s really a fairly low-level operation.
There’s generally some higher-level, more-declarative way to solve a problem than using tail recursion.
For instance, here’s a shorter version of the solution to our person-making example that takes advantage of some higher-order functions in Clojure:
Which solution to use is a matter of preference, but experienced functional programmers tend to prefer the shorter, more-declarative solutions.
They’re easier for the experienced functional programmer to read at a glance.
The downside to these solutions is that they’re harder for the novice to grok, since they may require knowledge of many higher-order library functions.
Whenever I’m about to write a solution that requires tail recursion, I like to comb the API docs for higher-order functions, or a combination of higherorder functions, that do what I want.
If I can’t find a higher-order function that works, or if the solution I come up with involves many higher-order functions combined in Byzantine ways, then I fall back to tail recursion.
To use mutually recursive functions to express certain algorithms, such as walking tree-like data structures, recursive descent parsing, and state machine manipulations.
However, some of the more complex problems require solutions where functions can call each other recursively.
For instance, finite state machines are a great way of modeling many classes of problems, and mutual recursion is a great way to program them.
Network protocols, many physical systems like vending machines and elevators, and parsing semistructured text can all be done with state machines.
In this pattern, we’ll look at some problems that can be solved cleanly using mutual recursion.
Since the JVM doesn’t support tail recursive optimization, Scala and Clojure have to use a neat trick to support practical mutual recursion, just as they did with normal tail recursion, to avoid running out of stack space.
Instead of making mutually recursive calls directly, we return a function that would make the desired call, and we let the compiler or runtime take care of the rest.
Scala’s support for trampolining hides a lot of the details of this and provides us with both a tailcall() method to make mutually recursive calls and a done() method to call when we’re done with the recursion.
To prove it, let’s take a quick look at the “Hello, World” for mutual recursion, a mathematically pretty but horribly inefficient way of telling if a number is even or odd, before we get into more real-world examples.
Here’s how it works: we need two functions, isEven() and isOdd()
The isEven() function checks to see if n is zero and, if so, it returns true.
The isOdd() method checks to see if n is zero and if so returns false.
That works fine for small numbers, but what if we try it with a larger one?
As we can see, each mutually recursive call consumes a stack frame, so this causes our stack to overflow! Let’s see how to fix that using Scala’s trampoline.
The first is a done() function, which is used to return the final result from the recursive calls.
The second is a tailcall() function, which is used to make the recursive calls.
In addition, the results returned by the tail recursive functions are wrapped in a TailRec type rather than being returned directly.
To get them out at the end, we can call result() on the final TailRec instance.
Here’s our even/odd code, rewritten to take advantage of Scala’s trampolining:
This time, there’s no stack overflow with big numbers, though if you try with a big enough number, you should expect to wait a very long time, since this algorithm’s runtime is linearly proportional to the size of the number!
In this example, we’ll use Mutual Recursion to build a simple state machine that takes a sequence of transitions between the different phases of matter—liquid, solid, vapor, and plasma—and verifies that the sequence is valid.
For instance, it’s possible to go from solid to liquid, but not from solid to plasma.
Each state in the machine is represented by a function, and the transitions are represented by a sequence of transition names, like condensation and vaporization.
A state function picks the first transition off of the sequence and, if it’s valid, calls the function that gets it to where it should transition, passing it the remainder of the transitions.
If the transition isn’t valid, we stop and return false.
For example, if we’re in the solid state and the transition we see is melting, then we call the liquid function.
If it’s condensation, which isn’t a valid transition out of the solid state, then we immediately return false.
Before we jump into the code, let’s take a look at a picture of the phases-ofmatter state machine.
The nodes in this graph represent the functions we’ll need to model this state machine using Mutual Recursion, and the edges represent the transitions that those functions will operate on.
Let’s take a look at the code, starting with Scala.
Our Scala solution relies on four functions, one for each phase of matter: plasma(), vapor(), liquid(), and solid()
In addition, we’ll need a set of case objects to represent the transitions: Ionization, Deinonizaton, Vaporization, and so forth.
Each of the four functions takes a single argument and a List of transitions, and each uses Scala’s pattern matching to destructure it.
If the list is Nil, then we know we’ve reached the end successfully and we call done(), passing in true.
Otherwise, we check the first transition in the list to see if it’s valid.
If so, we transition to the state it indicates and pass the remainder of the transitions.
If the first transition isn’t valid, we call done, passing in false.
Let’s look at the code, starting with the case objects to represent our transitions.
They’re pretty straightforward; each transition is its own object, and they all inherit from a Transition class.
Now let’s take a look at the meat of the example, the functions that represent our phases of matter.
As promised, there are four: plasma(), vapor(), liquid(), and solid()
We’ve already described how they work at a high level, so let’s pick apart one of them, vapor(), in detail, starting with its signature:
As we can see, it just takes in a List of Transitions named transitions and takes pattern matches on it.
Instead of returning a Boolean directly, it returns a TailRec of Boolean, so we can take advantage of Scala’s support for trampolining.
Moving on to the first case clause in the match expression, we see that it calls done to return true if the list is empty, or Nil.
This is the base case of the recursion; if we get here it means we’ve successfully processed all the transitions originally in the sequence.
These use pattern matching to pick off the head of the sequence if it’s a valid transition and call the function to transition to the appropriate state, passing the rest of the transitions:
If we fall through to here, we know we haven’t processed all the transitions and the transition we saw wasn’t valid, so we call done() and pass in false.
Let’s take a look at it in action, first with a valid list starting from the solid state:
Next we have an invalid list starting from the liquid state:
This wraps up our first look at Mutual Recursion in Scala.
The Clojure code is similar to the Scala code, at least at a high level.
We’ve got plasma, vapor, liquid, and solid functions, each of which takes a sequence of transitions.
We use Clojure’s destructuring to pick apart the sequence into the current transition, which we bind to transition and to the rest of the transitions in resttransitions.
If transition is nil, we know we’ve reached the end successfully and we return true.
Otherwise we check to see if it’s a valid transition, and, if so, we transition to the appropriate phase.
Notice how there are no calls to done or tailcall like there are in the Scala version? Instead of using tailcall, we just return a function that will make the call we want to make.
In this case, we’re using Clojure’s shorthand for anonymous functions to do so.
When we actually want to start the chain of mutually recursive calls, we pass the function we want to call into trampoline, along with its arguments:
This returns true for the valid sequence and false for the invalid one, just as we’d expect.
Before we leave this example, I’d like to talk a little bit about Nil in Scala and nil in Clojure.
The code we wrote looked fairly similar, but there’s a subtle difference between the two nils that’s worth mentioning.
In Scala, Nil is just a synonym for the empty list, as we can see if we enter it into the Scala REPL:
In Clojure, nil just means “nothing”: it means that we don’t have a value, and it’s distinct from the empty list.
Various functional languages have treated nil differently over the years, so whenever you come across a new one it’s always worth taking a minute to understand just what the language means by nil.
Mutual Recursion can be pretty handy, but usually only in specific circumstances.
State machines are one of these circumstances; they’re actually very useful little beasts.
Unfortunately, most developers just remember them from their undergraduate computer science years, where they had to prove the equivalence between finite state machines and regular expressions, which is interesting but of no use to most developers.
State machines have been a bit more popular in recent years, though.
They’re a big part of the actor model, a model for concurrent and distributed programming, that’s used by Scala’s Akka library and by Erlang, another functional language.
Ruby has a clever gem for creating them, aptly named state_machine.
Another thing that’s worth noting is that the trampoline we saw here, in both Scala and Clojure, is just one way of doing Mutual Recursion.
It’s only necessary because the JVM doesn’t implement tail call optimization directly.
To manipulate a sequence (list, vector, and so on) declaratively using filter, map, and reduce to produce a new one—this is a powerful, high-level way of doing many sequence manipulations that would otherwise be verbose.
The way we manipulate sequences in a procedural language is more closely related to the way a computer works than to the way humans think.
Iteration is a step above the dreaded goto statement, and it’s intended to be easily translated into machine code more than it’s intended to be easy to use.
Filter-Map-Reduce gives us a more declarative way to do many sequence manipulations.
Instead of writing code that reorders or alters the elements in a sequence by working its way iteratively through them, element by element, we can work at a higher level by using a filter function to select the elements we care about: map to transform each element and reduce, sometimes known as fold, to combine the results.
Filter-Map-Reduce replaces many, though not all, iterative algorithms used by object-oriented programmers with declarative code.
The main advantage to Filter-Map-Reduce over iteration is code clarity.
A well-written Filter-Map-Reduce takes a fraction of the code that the iterative equivalent takes.
It can often be read at a glance, like prose, by an experienced practitioner, while the iterative solution requires parsing at least one loop and a conditional.
One downside is that not all iteration can be replaced with Filter-Map-Reduce.
Another is that it may sometimes be difficult or unclear how to create a sequence that lends itself to Filter-Map-Reduce.
In these cases, one of the patterns in the list of Related Patterns, on page 158, may be a better fit.
The implementation of Filter-Map-Reduce combines filter, map, and reduce, though not always in that order.
Filter-Map-Reduce in Scala is very similar to the Clojure implementation.
We start with a filter function to select prices greater than twenty dollars:
You can also use named functions if that’s more your style, though I prefer the anonymous function version here:
Let’s create a function calculate-discount that uses Filter-Map-Reduce to calculate a total discount.
For the sake of example, we’ll use a vector of doubles to represent our prices.
We need to filter first so that only prices greater than twenty dollars remain, like this:
Then we need to take the filtered prices and multiply them by 0.10 to get ten percent of each, using map:
Finally, we need to combine those results using reduce and addition:
There’s a trick to reading Lisp code that lets experienced Lispers read this at a glance but which frustrates the uninitiated.
To read this easily, you need to work from the inside out.
Start with the filter function, move on to map, and finally to reduce.
In prose, this would be, “Filter the prices so that only those greater than twenty remain, multiply the remaining prices by a tenth, and add them together.” With a little practice, reading this sort of code is not only natural, but since it’s at a much higher level and closer to natural language, it’s much quicker than the equivalent iterative solution.
We can make a slight modification to the pattern by naming the map and filter functions, as shown in the code below:
This makes the pattern read more like prose at the expense of some extra code.
When the map and filter functions are one-offs, as they are here, I prefer the original version with anonymous functions, but both styles are common.
The Filter-Map-Reduce pattern relies on declarative data manipulation, which is higher level than iterative solutions and often higher level than explicitly recursive ones.
It’s much like the difference between using SQL to generate a report from data in a relational database versus iterating over the lines in a flat file with the same data.
A well-written SQL version will generally be shorter and clearer, since it’s using a language created specifically for manipulating data.
One other thing to note is how we built our solutions from the bottom up, starting by creating our map, reduce, and filter functions in the REPL and then combining them.
The ability to experiment in the REPL and build up programs through exploration is extremely powerful, and we’ll see many more examples of it in functional patterns.
To chain a sequence of computations together—this allows us to work cleanly with immutable data without storing lots of temporary results.
Sending some bit of data through a set of operations is a useful technique.
Since we can’t mutate a data structure, we need to send an immutable one through a series of transformations if we want to make more than a single change.
Another reason we chain operations is because it leads to succinct code.
Other times we chain method invocations to avoid creating noisy temporary values.
In the code below we get a String value out of a List and uppercase it in one shot:
This style of programming is even more powerful in the functional world, where we have higher-order functions.
For example, here we’ve got a snippet of Scala code that creates initials from a name:
It does so by calling split() on the name, turning it into an array, then mapping functions over it that uppercase the strings and pick out the first character in each.
Let’s take a look at a sample that involves several chained function calls.
The objective is to write the code such that when we read it we can easily trace the flow of data from one step to the next.
We’ll take a vector of videos that represent a person’s video-viewing history, and we’ll calculate the total time spent watching cat videos.
To do so, we’ll need to pick only the cat videos out of the vector, get their length, and finally add them together.
For our Scala solution, we’ll represent videos as a case class with a title, video type, and length.
The code to define this class and populate some test data follows:
To calculate the total time spent watching cat videos, we filter out videos where the video_type is equal to "cat", extract the length field from the remaining videos, and then sum those lengths.
Now we can apply catTime() to our test data to get the total amount of time spent on cat videos:
This solution reads nicely from top to bottom, almost like prose.
It does so without needing extra variables or any mutation, so it’s ideal in the functional world.
Let’s take a look at our cat-viewing problem in Clojure.
As before, we’ll filter the vector of videos and extract their lengths.
To sum up the sequence of lengths, we’ll use apply and the + function.
To understand this code, start with the filter function, move onto map, and then up to apply.
One option would be to name the intermediate results using let to make things easier to understand.
These macros can be used to thread a piece of data through a series of function calls.
The -> macro threads an expression through a series of forms, inserting it as the second item in each form.
For instance, in the following snippet we use -> to thread an integer through two subtractions:
If we use ->> we get a different result, as the following code snippet shows:
Now that we’ve seen the threading operators, we can use ->> to make our original catTime read from top to bottom.
One limitation of the threading macros is that if we want to use them to chain function calls, the piece of data we’re passing through the chain of function calls must be consistently in the first or last position.
A common use for Chain of Operations is that we need to perform multiple operations on values inside of some container type.
This is especially common in statically typed languages like Scala.
For instance, we may have a series of Option values that we want to combine into a single value, returning None if any of them are None.
There are several ways to do so, but the most concise relies on using a for comprehension to pick out the values and yield a result.
We came across sequence comprehensions in Sample Code: Sequence Comprehensions, on page 77, as a replacement for Iterator.
Let’s take a look at a sequence comprehension that operates over two vectors, each with a single integer.
We’ll use it to add the values in the vectors together.
From there, it’s only a short hop to using for with Option.
In the following code we define a couple of optional values:
Now we can add them together as we did with the values out of our vectors.
One advantage is that we don’t have to call get() or pattern match to pull values out of Option.
The power of this approach becomes more apparent when we add a None into the mix:
A Chain of Operations, each of which might yield a None, is common in Scala.
Let’s take a look at an example that goes through a series of operations to retrieve a user’s list of favorite videos on a movie website.
To get the list of videos, we first need to look up a user by ID, then we need to look up the list of favorite videos by user.
Finally, we need to look up the list of videos associated with that movie, such as cast interviews, trailers, and perhaps a full-length video of the movie itself.
We’ll start out by creating a couple of classes to represent a User and a Movie:
Now we’ll define a set of methods to fetch a user, a favorite movie, and the list of videos for that movie.
Each function returns None if it can’t find a response for its input.
For this simple example we’ll do so using hardcoded values, but in real life this would likely involve a lookup from a database or service:
Now we can write a function to get a user’s favorite videos by chaining together calls to the functions we previously defined inside of a for statement:
If we call it with a user who doesn’t exist, the whole chain will return None instead:
Since Clojure isn’t statically typed, it doesn’t have anything like Scala’s Option as a core part of the language.
However, Clojure’s sequence comprehensions do work much like Scala’s for other container types.
For instance, we can use for to pick out their contents and add them together, as we did in our Scala example.
If one of our vectors is the empty vector, then for will result in an empty sequence.
Even though Clojure’s sequence comprehension works much the same as Scala’s, the lack of static typing and the Option type means that the sort of chaining we saw in Scala isn’t idiomatic.
Instead we generally rely on chaining together functions with explicit null checks.
The flexibility of Lisp makes it possible to add on even something as fundamental as a static type checker into the language as a library.
Just such a library is currently under development in the core.typed library,1 which provides optional static typing.
As this library gains maturity, the type of chaining we saw in the Scala examples may become more and more common.
The examples we saw in Sample Code: Chaining Using Sequence Comprehensions, on page 162, are examples of the sequence or list monad.
While we didn’t define exactly what a monad is, we did show a basic example of the sort of.
They make it natural to chain together operations on a container type while operating on the data inside of the container.
In the programming world, monads are most commonly known as a way to get IO and other nonpure features into a purely functional language.
From the examples we saw above, it may not be immediately apparent what monads have to do with IO in a purely functional language.
Since neither Scala nor Clojure make use of monads in this way, we won’t go into it in detail here.
The general reason, however, is that the monadic container type can carry along some extra information through the call chain.
For instance, a monad to do IO would gather up all of the IO done through the Chain of Operations and then hand it off to a runtime when done.
The runtime would then be responsible for performing the IO.
To create a function that itself creates functions, allowing us to synthesize behaviors on the fly.
Sometimes we’ve got a function that performs a useful action, and we need a function that performs some other, related action.
We might have a vowel? predicate that returns true when a vowel is passed in and need a consonant? that does the same for consonants.
Other times, we’ve got some data that we need to turn into an action.
We might have a discount percentage and need a function that can apply that discount to a set of items.
With Function Builder, we write a function that takes our data or function (though, as we’ve seen, the distinction between functions and data is blurry) and uses it to create a new function.
To use Function Builder, we write a higher-order function that returns a function.
For example, to create a consonant? predicate from a vowel? predicate, we create a new function that calls vowel? and negates the result.
To create odd? from even?, we create a function that calls even? and negates the result.
To create dead? from alive?, we create a function that calls dead? and negates the result.
We can encode it with a Function Builder implementation named negate.
The negate function takes in a function and returns a new one that calls the passed-in function and negates the result.
Another common use for Function Builder is when we’ve got a piece of static data we need to use as the basis for some action.
For instance, we could convert a static percentage to a function that calculates percentages by writing a function that takes in the percentage and returns a function of one.
This function takes in a number to calculate a percentage of and uses the percentage stored in its closure to do so.
We’ll see several examples of both flavors of Function Builder a bit later on.
One way to use Function Builder is to create functions out of static data.
This lets us take a bit of data—a noun—and turn it into an action—a verb.
Let’s look at a couple of examples, starting with a function that takes a percentage and creates a function that calculates discounted prices based on those percentages.
It then creates a function that uses discountPercentage to calculate a discount.
The simplest way to use discountedPrice() is to have it create an anonymous function, which we call directly.
If we need to use the discount function more than once, we can name it.
Here we do so and use it to calculate discounted totals on a couple of vectors of items:
In Clojure This example works much the same in Clojure.
The only interesting difference is that we can use Clojure’s preconditions to ensure that the discount is in the valid range.
We can create a discounted price and call it as an anonymous function:
As advertised, trying to create a discount outside the acceptable range throws an exception:
And if we want to name our discount function to use it multiple times, we can do so:
The discount calculator is a fairly simple example; we’ll take a look at one that’s a bit more involved in the next section.
Let’s take a look at a more involved implementation of Function Builder.
The problem we’re trying to solve is this: we’ve got a data structure consisting of maps nested inside each other, and we want to create functions that help us pick out values, possibly from deeply nested parts.
In a way, this is writing a very simple declarative language to pick values out of deeply nested maps.
This is a lot like how XPath lets us select an arbitrary element from a deeply nested XML structure, or how a CSS selector lets us do the same with HTML.
Our solution starts with creating a function, selector, which takes a path to the data we’re looking for.
For instance, if we’ve got a map that represents a person, which contains a name key whose value is another map, which contains a first key whose value is the first name, we want to be able to create a selector for the first name like this: selector('name, 'first)
This sort of structure is extremely handy when working with structured data like XML or JSON.
The data can be parsed into a nested structure, and this type of Function Builder can help pick it apart.
In Scala The Scala version of selector creates functions that can pick values out of deeply nested maps, as described previously.
The selectors that it creates will return Some(Any) if it can find the nested value; otherwise it returns None.
To create a selector, we need to pass in several Symbols corresponding to the keys in the path we want to select.
Since this is all we need to pass into selector, we can use Scala’s support for varargs instead of passing in an explicit list; this means that creating a selector to pick a street name from a person’s address looks like this:
Once created, a map is passed into the selector, and it attempts to select a value based on the path it was given when it was created by recursively walking through the map.
This is a slightly tricky bit of code, so let’s look at the whole thing and then break it down into smaller parts:
This says that selector takes a variable number of Symbol arguments and returns a function.
The function it returns itself takes a map from Symbol to Any and returns an Option[Any]
The first line simply checks to make sure that the path has at least one element and throws an exception if it doesn’t:
The meat of the function is a nested, recursive helper function.
This says that selectorHelper takes a sequence of Symbols as a path and a data structure that consists of a map from Symbol to Any.
It returns an Option[Any], which represents the final value we’re trying to find with the selector.
In the above example, this would be the name of a person’s street.
This happens when we reach the end of the path.
We find the value we’re looking for and return it.
The get() method returns None if the value doesn’t exist:
The largest piece of code contains the tail recursive call.
Here, we get the current piece of the data structure.
If it exists, then we call the helper function recursively with the remainder of the path and the data structure we just picked out.
If it doesn’t exist, or if it doesn’t have the proper type, we return None:
Finally, here is the last line, which just returns a function that calls selectorHelper with the appropriate arguments:
Let’s take a closer look at how we can use selector, starting with a very simple example, a map that has a single key-value pair:
Of course the real power is only apparent when we start working with nested data structures, like so:
If the selector doesn’t match anything, a None is returned:
In Clojure The Clojure version of selector is much simpler than the Scala one.
In part, this is because Clojure is dynamically typed, so we don’t have to worry about the type system as we did in Scala.
In addition, Clojure has a handy function called get-in, which is tailor-made to pick values out of deeply nested maps.
Let’s take a quick look at get-in before we dig into the code.
The get-in function takes a nested map as its first argument and a sequence that represents the path to the value you’re looking for.
Here’s an example of using it to pick a street name from a nested map:
We’ve just got to add a validator to ensure that the path isn’t empty and use varargs for the path.
Using it is just as easy as the Scala version.
Here we pick out a person name from a flat map:
And here we pick out a street name from a more deeply nested one:
Before we move on, here’s a quick note on the relative complexity of the Scala and Clojure versions of this example.
The fact that Clojure has get-in, which does almost exactly what we want to do, helps make the Clojure version much more concise.
The other factor is that Clojure is a dynamically typed language.
Since the nested maps can hold values of any type, this takes some type system gymnastics to handle in Scala, which is statically typed.
In Clojure, using maps to hold data like this is very idiomatic.
In Scala, it’s more common to use classes or case classes.
However, for this sort of very dynamic problem, I much prefer just keeping things in a map.
Using a map means we can manipulate the data structure with all the built-in tools for manipulation maps and collections.
Since functions in the functional world are themselves pieces of data that can be manipulated, it’s common to use Function Builder to transform one function into another.
This can be done very simply by just creating a new function that manipulates the return value of another function.
For instance, if we have a function isVowel and we want a function isNotVowel, we can simply have it delegate to isVowel and negate the result.
This creates a complementary function, as the Scala code shows:
In this example, we’ll take a closer look at two other ways to create functions from existing functions: function composition and partial function application.
Function composition lets us take multiple functions and chain them together.
Partial function application lets us take one function and some of.
These are two of the most generally useful ways of creating functions from functions.
Function composition is a way to chain function invocations together.
Composing a list of functions together gives us a new function that invokes the first function, passes its output to the next, which passes it to the next, and so on until a result is returned.
With the Decorator pattern, multiple decorators, each of which does one part of some task, are chained together.
It’s possible to use function composition by simply chaining together functions by hand, but since this is such a common task, functional languages provide first class support for it.
Clojure and Scala are no exception here, so let’s take a look at it.
In Scala In Scala, we can compose functions together with the compose operator.
As a simple example, let’s define three functions, appendA, appendB, and appendC, which append the strings "a", "b", and "c", respectively, as the code shows:
Now if we want a function that appends all three letters, we can define it like so using function composition:
As the name suggests, this appends the letters c, b, and a, in that order.
It’s equivalent to writing a function that takes an argument, passes it into appendC(), takes the returned value and passes it into appendB(), and finally passes that returned value into appendA():
This is a trivial example, but it illustrates an important thing about function composition, which is the order in which the composed functions are called.
The last function in the composition chain is called first, and the first function is called last, which is why c is the first letter appended to our string.
One common situation that comes up in web application frameworks is the need to pass an HTTP request through a series of user-defined chunks of code.
Filter chains allow application code to do anything that needs to be done before request handling, like decrypting and decompressing the request, checking authentication credentials, logging to a request log, and so forth.
Let’s sketch out how we’d do this using function composition.
For the purpose of this example, we’ll keep it simple and stick to a map of request headers and a string request body:
Each filter is a function that takes in an HttpRequest, does something, and returns an HttpRequest.
For this simple example, we’re returning the same HttpRequest; but if the filter needed to modify or add something to the request, it could do so by creating a new HttpRequest with its modifications.
Here are a couple of example filters—the first mimics checking an Authorization header and adding a user principal to the request if it’s valid, and the second mimics logging out a request fingerprint for troubleshooting:
Finally, we need a function that takes a sequence of filters and composes them together.
We can do this by simply reducing the composition function over the sequence:
Let’s watch it work by composing the sample filters into a single filter chain and running a test HttpRequest through it:
As we can see, the filter chain properly runs the HttpRequest through each filter in the chain, which adds a user principal to the request and logs our fingerprint to the console.
In Clojure The easiest way to do function composition in Clojure is to use comp.
Here we are using it to compose together the string appenders:
In Clojure we’ll model the HTTP request itself, as well as the headers, as a map.
Our sample filter functions pick keys out of a map and use nil instead of None to represent missing values.
Here they are, along with the function builder, compose-filters, to compose them into a filter chain:
And here’s that filter chain in action, running through the filters, performing them, and finally returning the HTTP request:
Function composition is a very general operation, and we’ve only touched on a few uses of it here.
Any time you find yourself calling the same set of functions in the same order multiple times, or you have a dynamically generated.
While function composition takes multiple functions and chains them together, partially applying a function takes one function and a subset of the arguments that that function takes and returns a new function.
The new function has fewer arguments than the original and keeps track of the subset that was passed in when the partially applied function was created so it can use them later when it gets the rest of the arguments.
In Scala Partial function application is another functional feature that’s important enough to warrant first-class support in Scala.
The way it works is that you call a function and replace the arguments you don’t currently have values for with underscores.
For example, if we’ve got a function that adds two integers together and we want a function that adds 42 to a single integer, we could create it like this:
Creating partially applied functions is simple, but spotting when to use them can be a bit tough.
Say we’ve got a function that calculates income tax by state, and we want to create functions that let us calculate the income tax for a particular state.
We can use a partially applied function to do it, like so:
In Clojure Partially applying functions in Clojure is similar to how it’s done in Scala, but there is one twist.
To keep its syntax simple, Clojure only allows for the arguments that the function is being partially applied to, to come at the start of the argument list.
For example, we could still write add-forty-two, much as we did in Scala, as this code shows:
But to write ny-tax and pa-tax, we’d have to swap the arguments to tax-for-state around, like this:
Partially applied functions are very simple to use, but I often find it a bit tricky to know when to use them.
I usually catch myself calling the same function over and over again, with a subset of the arguments remaining the same.
Then a light bulb goes off and I realize I can clean that up a bit by using a partially applied function.
In this section, we’ve covered some of the more general ways to use Function Builder, but these are by no means the only ways.
The Clojure and Scala libraries contain many other examples, since this is an extremely common pattern in the functional world.
While most of the Clojure and Scala examples were very similar, the examples in Map Key Selector, on page 170, differed drastically.
In part, this is because Clojure has an extremely handy get-in function that does almost exactly what we need; however, a large part of the difference was caused by Scala’s type system.
Since Scala is statically typed, we had to specify types for the contents of the maps that we dealt with.
Internal nodes were themselves Maps, while leaf nodes could be anything at all.
This led to the slight bit of type system gymnastics we had to do in the Scala version.
This is a general trade-off between dynamic and static typing.
Even with a powerful type system like Scala’s, there’s still a cost to static typing in terms of the complexity it can add and in just understanding how the type system works.
The trade-off is that we can catch many errors at compile time that would otherwise become runtime errors with a dynamic type system.
To cache the results of a pure function call to avoid performing the same computation more than once.
Since pure functions always return the same value for given arguments, it’s possible to replace a pure function call with cached results.
We can do this manually by writing a function that keeps track of its previous arguments.
When it’s called, it first checks its cache to see if it has already been called with the passed-in arguments.
Some languages provide first-class support for Memoization using higher-order functions.
Clojure, for instance, has a function called memoize that takes a function and returns a new one that will cache results.
Scala doesn’t have a built-in memoization function, so we’ll use a simple manual implementation.
One use for Memoization is as a simple cache for expensive or time-consuming functions, especially when the function is called multiple times with the same argument.
In this example, we’ll simulate the time-consuming operation by having it sleep the thread.
Let’s get started with a look at our simulated expensive function call.
As an example, we’re using a lookup by ID from some (presumably slow) datastore.
To fake it out here, we sleep the thread for a second before returning a value from a static map.
We also print the ID we’re looking up to the console to demonstrate when the function is being executed:
Just as we’d expect, the lengthy function is executed each time we call it, as we can see from the console output:
Now let’s take a look at a simple memoized version of expensiveLookup()
The new function first checks its cache to see if it has results from a previous function call.
Otherwise it calls the expensive lookup and caches the results before returning them.
As we can see from the following REPL output, the expensive function is only called the first time for a given argument.
One quirk with this example is in the last line:
This allows us to wrap the cache up in a closure so that only the function has a reference to it.
If we needed another cache, we could create it like so:
Our Scala solution is a bit clumsy since we’ve done it manually for a single, specific case, but it serves as a good model for how memoization works behind the scenes.
Let’s take a look at how we can use Clojure’s memoize function to solve the same problem.
In Clojure, we’ll start with a similar simulated expensive function.
Instead, we’ll use Clojure’s memoize function to automatically return a memoized version of the function, as this code shows:
As we can see from the following REPL output, it behaves similarly to the Scala version and only performs the expensive operation once:
Behind the scenes, the memoize function creates a new function that’s much like the manual example we saw in Scala that uses a map as a cache.
One use of Memoization we didn’t cover here is in solving dynamic programming problems, which is one of its original uses.
The formula for calculating the nth Fibonacci number adds together the previous two numbers in the sequence.
A simple Clojure function to calculate a Fibonacci number using this definition follows:
The nice thing about this function is that it mirrors the mathematical definition.
However, it needs to recursively compute its subparts repeatedly, so its performance is terrible for even moderately large numbers.
If we memoize the function, as we do in the following code, then the subparts are cached and the function can perform reasonably well:
Running the two functions shows the drastic difference in performance:
Dynamic programming problems are rich and fascinating; however, they only pop up in a limited number of domains.
I’ve generally seen memoization used as a simple, convenient cache for expensive or long-lived operations rather than as a dynamic programming tool.
To create a sequence whose members are computed only when needed—this allows us to easily stream results from a computation and to work with infinitely long sequences.
We often deal with elements of a sequence one at a time.
Since this is so, we generally don’t need to have the entire sequence realized before we start processing it.
For instance, we may wish to stream lines of a file off of disk and process them without ever holding the entire file in memory.
Lazy Sequence does so by only creating an element in a sequence when it’s asked for.
In the file-reading example, the lines are only read off of disk when asked for, and they can be garbage-collected when we’re done processing them, though we need to take a bit of care to ensure that they are.
When we create an element, we call that realizing the element.
Lazy Sequence also lets us create an extremely useful abstraction: an infinitely long sequence.
This may not seem useful at first blush, but since the entire sequence isn’t realized at once, we can work with the beginning of the sequence and defer creation of the rest.
This allows us to create, say, an infinitely long string of pseudorandom numbers of which we realize only a portion.
Let’s start with a couple of simple examples from the built-in library.
In the first example, we’ll show how to work with an infinitely long list of integers.
An instance of Lazy Sequence before and after the third element has been realized.
In the second, we’ll show how to use Lazy Sequence to generate a series of random test data.
Let’s get started with a dive into the Scala code.
Scala’s has built-in support for Lazy Sequence in its Stream library.
Perhaps the simplest thing we can do with a lazy sequence is to create an infinite sequence of all integers.
Scala’s Stream library has a method that does just that, called from()
According to the ScalaDoc, it will “create an infinite stream starting at start and incrementing by step.”
Here, we use from() to create a sequence of all integers, starting at 0:
This may seem a strange thing to do, but we can use another method, take(), to work with the first few numbers in the sequence.
Here we’re using it to take the first five integers from our infinitely long list and then print them:
Let’s take a look at a slightly fancier instance of Lazy Sequence that uses another method in Scala’s Sequence library.
The continually() method creates an infinitely long sequence by repeatedly evaluating the expression passed into here.
Let’s use this to create an infinitely long sequence of pseudorandom numbers.
To do so, we create a new random number generator in the val generate, and then we pass generate.nextInt in the continually() method, as illustrated in the following code:
We can now take a few random numbers from our infinite list:
If we want a few more random numbers, we can use take() again with a larger number:
The first five values were realized when we originally printed aFewRandoms, the sixth only once we printed aFewMoreRandoms.
Lazy Sequence is built into Clojure as well, but it’s not focused in a single library.
Clojure’s normal range function, for instance, works with Lazy Sequence.
The following code generates a list of all the positive integers that fit into an Integer:
We can then use the take function to take a few integers from the start of our long list:
To generate our list of random integers, we can use Clojure’s repeatedly function.
This takes a function of one argument and repeats it an infinite number of times, as the following code shows:
If we want some more, we use take with a bigger argument.
Again, the first five random integers won’t be recomputed, they’ll be pulled from a memoized cache:
Scala and Clojure’s treatments of Lazy Sequence have a few key differences.
Most of Clojure’s sequence-handling functions are lazy, but they recognize the sequence in chunks of thirty-two.
If we take a single number from a lazy sequence of integers, Clojure will recognize the first thirty-two integers even though we only asked for one.
We can see this if we add a side effect into the lazy sequence generation.
Here, we can see that take recognizes thirty-two integers, even though it only returns the first one:
Another, more subtle difference comes into play when using Lazy Sequence in the REPL.
When the Scala REPL comes across an instance of Lazy Sequence in the form of a Stream, it does not attempt to realize the whole thing.
This is easiest to see when we’ve got an obvious side effect.
In the following Scala code, we use continually() to print "hello" to the console and store a reference to the produced Stream in printHellos.
As we can see, the first "hello" is printed when we call continually, which indicates that the method realizes the first element in the stream:
If we now call take() on printHellos, we don’t get any further "hello"s printed to the console, which means the REPL isn’t trying to realize the returned Stream.
If we want to force the remainder of our "hello"s to be realized, we can use any method that iterates over Stream, or we can just use the force():
This isn’t something you generally need to do, but it’s important to understand when the elements of Lazy Sequence are realized.
In contrast, Clojure’s REPL will attempt to realize an instance of Lazy Sequence; however, defining an instance of Lazy Sequence may not realize the first element! Here we define a print-hellos much like the Scala version.
However, if we take five elements, the REPL evaluating the resulting instance of Lazy Sequence will force it to print to the console.
It also highlights something to watch out for when using Lazy Sequence.
Since you can create infinite sequences, we need to ensure that we don’t attempt to realize an entire infinite sequence at once.
In our first example, we looked at a couple of higher-order functions that let us create an instance of Lazy Sequence.
Now let’s take a look at how we’d make one from scratch.
The example we’ll use here is a lazy sequence that lets us go through a set of paged data.
In our simple example, we’ll simulate the paged data with a local function call, though in a real program this would probably come from an external source such as a web service.
Let’s get started with a look at the Scala code.
Our Scala solution has two parts: the sequence itself, pagedSequence, and a method to generate some sample paged data, getPage()
However, instead of passing our sequence through the call stack, we add to it in each recursive call using the #:: operator.
The following code is the full solution to our paged data problem:
Let’s dig into pagedSequence a bit more, starting with the #:: operator, which allows us to prepend a value to a Stream.
Here we use it to append the strings "foo" and "bar" to a new Stream:
We can get at the head and tail of our Stream, just as we could with other sequences:
Let’s take a closer look at the heart of our solution in the following code snippet:
If we match a Some, then we know that we got back a valid page.
We prepend it to our sequence and then recursively call the method generating the sequence, passing in the next page we’re trying to fetch.
If we get a None, we know we’ve gone through all our pages, and we append the empty stream, Stream.Empty, to our lazy sequence.
Now we can work with pagedSequence just like we worked with some of the sequences we saw in the previous example.
Here we take two pages from the sequence, starting at the first element:
Here we force the whole thing to be realized, which is safe since this sequence, while lazy, isn’t infinite:
Now let’s take a look at how to do it in Clojure.
In Clojure, we can construct an instance of Lazy Sequence from scratch using lazy-sequence and add to it with cons, as shown in the following snippet:
We can then use recursive function calls to build up useful sequences.
To write our paged sequence example in Clojure, we first define a get-page function to mock up our paged data.
The core of our solution is in the paged-sequence function.
The paged-sequence function is called with the start page, and it recursively builds up a lazy sequence by fetching that page, appending it to the sequence, and then calling itself with the number of the next page.
Now we can work with our lazy sequence like any other.
If we call paged-sequence in the REPL, we get the entire sequence:
If we use take, we can get a portion of it:
This can give us a very clean way of working with streaming data.
Holding on to the head of a lazy sequence will keep the entire sequence in memory.
In Scala, it’s easy to accidentally do this simply by assigning our lazy sequence into a val, as we do in the following code:
If we try to force the sequence more than once, we can see that the second time uses the cached copy, as the following REPL output demonstrates:
If we don’t want to hold on to the head of the sequence, we can use def instead of val, as we do in the following code:
This forces the sequence to be realized fresh each time it’s forced and does not hold onto the head:
Holding on to the head of a sequence by accident is really no more mysterious than holding on to a reference to any object when you don’t mean to, but it can be surprising if you’re not watching out for it.
Programming with performant, immutable data on machines that are built out of fundamentally mutable components, like main memory and disk, is almost magical.
A whole host of technology has contributed to making it possible, especially on the JVM.
Growing processor power and memory sizes make it increasingly unnecessary to squeeze every last drop of performance out of a machine.
Small, transient objects are cheap to create and to destroy, thanks to the JVM’s excellent generational garbage collector.
Both Scala and Clojure use extremely clever data structures that allow immutable collections to share state.
This obviates the need to copy the entire collection when one piece of it is changed, which means collections have a reasonable memory footprint and can be modified fairly quickly.
Even the clever data structures Clojure and Scala use may take up more memory than their mutable counterparts, and they perform somewhat worse.
The benefits of immutable data, which greatly ease not only concurrent programming but also ease programming large systems in general, often outweigh the costs.
However, sometimes you really do need that extra performance, usually in a tight loop in a part of the program that is frequently called.
Focused Mutability shows how to use mutable data in these situations by creating functions that take in some immutable data structures, operate on mutable data inside of the function, and then return another immutable data structure.
This lets us get more performance without letting mutability muck up our programs, since we’re confining it inside a function, where nothing else can see it.
One consideration we need to make when using Focused Mutability is what the cost of translating a mutable data structure into an immutable one is.
Clojure provides first-class support here with a feature called transients.
Transients let us take an immutable data structure, convert it into a mutable one in constant time, and then convert it back into an immutable one when we’re done with it, also in constant time.
In Scala, it’s a bit trickier, since there’s no first-class support for something like Clojure’s transients.
We have to use the mutable versions of Scala’s data structures and then convert them into immutable ones using conversion methods on the collections library.
Let’s start off with a look at a very simple sample, adding a range of numbers to an indexed sequence.
This isn’t a particularly useful thing to do in practice, but it’s a very simple example, which makes it easy to do some basic performance analysis.
For this example, we’ll compare the time it takes to add a million elements to a mutable indexed sequence and then translate it into an immutable one with the amount of time it takes to build up the immutable sequence directly.
This involves some microbenchmarking, so we’ll do several trial runs of each test to try to spot outliers caused by garbage collection, caching issues, and so on.
This certainly isn’t a perfect way to perform a microbenchmark, but it’s good enough so that we can get a feel for which solutions are faster and by how much.
In Scala, we’ll compare the results of adding elements to an immutable Vector directly to the results of adding them to a mutable ArrayBuffer and then converting it into an immutable Vector.
In addition to our test functions, which add elements to a Vector and an ArrayBuffer, we’ll need a bit of infrastructure code to help out with timing and test runs.
The following code defines a function, testImmutable(), which appends count elements to an immutable Vector and updates a reference to point at the new vector each time a new element is appended:
Now let’s take a look at testMutable(), which is similar except that it appends elements to a mutable ArrayBuffer, which is a bit like a Java ArrayList.
Now we just need a way of getting timing information from runs of our test functions.
We’ll time runs by recording system time before the test run and after.
Instead of embedding this in the test functions themselves, we’ll create a higher-order function that can do the timing, time(), and another one, timeRuns(), that will run multiple tests at a time.
With the pieces in place, we can run some tests.
Let’s try five test runs with a count of one million against our immutable version:
Now let’s give it a shot with our mutable version, which only converts to an immutable data structure when modifications are done:
While your mileage may vary somewhat depending on your machine, on your JVM version, on your garbage collection tuning, and so forth, this basic microbenchmark suggests that the mutable version is generally faster than the immutable one, as we’d expect.
Clojure has built-in support for Focused Mutability through a feature named transients.
Transients allow us to magically transform an immutable data structure into a mutable one.
To use it, the immutable data structure is passed into the transient! form.
For example, this would get us a transient, mutable vector, (def t (transient []))
As the name suggests, transients are supposed to be, well, transient, but in a very different way than the transient keyword in Java means.
Transients in Clojure are transient in the sense that you use them briefly inside a function and then transform them back into an immutable data structure before passing them around.
Transients can be appended to with a special version of conj called conj!
Using an exclamation point for operations on mutable data is an old Lisp convention meant to convey that you’re about to do something exciting and dangerous!
Let’s take a look at our basic Focused Mutability example, which has been rewritten to use Clojure’s transients.
In Clojure, we’ll build up our sequence of numbers with a recursive function that passes a vector through the call chain and conjes a single number to the vector in each call.
Our mutable version looks almost identical; the only difference is that we create a transient vector using transient to be modified internal to the function.
Then we convert it back to an immutable data structure with persistent! when done, as the code shows:
Clojure has a built-in time function that’s much like the one we wrote for Scala, but we still need a way of running multiple trials in one shot.
Now we can put our Clojure solution through its paces.
These times are fairly similar to the Scala times, which isn’t surprising since Scala’s immutable data structures and Clojure’s immutable data structures are based on the same set of techniques.
Comparing the shortest and longest runs of both versions gives us a speedup of about 1.5 times for the mutable version, which isn’t too shabby.
A bit of digging into these examples with a profiling tool reveals that the culprit here is indeed a major garbage collection that ran during those samples and not the others.
The effects of garbage collection on this example might be reduced with tuning, but that, alas, would be a book in itself!
Let’s take a look at an example with a bit more weight.
Here, we’ll process a stream of events that represent purchases.
Each event contains a store number, a customer number, and an item number.
Our processing will be straightforward; we’ll organize the stream of events into a map keyed off of the store number so that we can sort purchases by store.
In addition to the processing code itself, we’ll need a simple way of generating test data.
Our Scala solution starts with a Purchase case class to hold on to our purchases.
We’ll also need a sequence of test purchases, as well as the immutable and mutable versions of our test functions.
In both cases, we’ll go through our test purchases in a for comprehension, pull out the store number from the purchase, and add it to a list of other purchases from that store, which we’ll then put into a map keyed off of by store number.
For timing, we’ll reuse the same code from the above example.
Let’s start with the Purchase class, a straightforward case class:
Generating our test data can be done with an infinitely long lazy sequence, from which we’ll take as many samples as we need.
If we wanted to take, say, five items from our infinite sequence, we do so with take(), like this:
This function takes the number of test purchases, obtains the test purchases from our infinite sequence of test data, and adds them to a map indexed by store, as described earlier.
To add a new purchase to the map, we pull the store number out of the purchase and attempt to get any existing purchases for that store from the map.
If they exist, we add the new purchase to the existing list and create a new map with the updated key.
Our mutable version is quite similar to the immutable version, except that we modify a mutable map and then turn it into an immutable one when done, as this code shows:
So how do these two solutions perform? Let’s take a look by running it over 500,000 samples, starting with the immutable version first:
As we can see, the mutable version is only a tiny bit faster.
A bit of profiling reveals that this is largely because much of the time in the example was spent generating test data, and not manipulating the map.
If we were reading the events off the filesystem or over the network, this overhead would be even greater, and the difference between the two solutions even smaller! On the other hand, even a tiny amount of time shaved off of each event processing may end up mattering if the data set is big enough.
Our Clojure solution is fairly similar to the Scala one.
The first uses a normal, immutable map, and the second a mutable, transient one.
Let’s get started with a look at the code that lets us generate test data.
We can use a function named repeatedly, which, as the name suggests, calls the function multiple times and uses the results to create a lazy sequence.
Outside of that, we just need a function to create the test purchases themselves.
We’ll use reduce to turn a sequence of purchases into a map indexed by store number.
Just as in the Scala example, we’ll use take to take a finite number of test purchases from our infinite sequence of them.
Then we’ll reduce over that sequence, building up our map of purchases indexed by store number.
As before, we need to handle the case when we first see the store number, which we can do by passing in a default empty list to get.
Since Clojure has handy-dandy transients, the mutable solution looks very similar, save that we need to transform our map to and from a transient and that we need to use assoc! to add to it, as the code shows:
Now let’s give it a whirl, starting with the mutable version:
As we can see, the differences are fairly minimal, but the mutable version is a bit faster.
It’s the sort of thing that the old advice to avoid premature optimization is all about.
As we’ve seen from this chapter, Scala and Clojure’s immutable data structures perform very well—not much worse than their mutable counterparts! If you’re modifying several immutable data structures in one go and if you’re doing it for large amounts of data, you’re likely to see a significant improvement.
However, immutable data structures should be the default—they’re usually plenty fast.
Before using Focused Mutability or any small-scale performance optimization, it’s a good idea to profile your application and make sure you’re optimizing in the right place; otherwise, you might find that you’re spending time optimizing a section of code that is rarely called, which will have little effect on the overall performance of the program.
Using the right control flow abstraction for the job can help us write clearer code.
For instance, Ruby includes an unless operator, which can be used to do something unless a conditional is true.
Good Ruby code uses this operator over if and the not operator, since it’s clearer to read.
No language has every useful control flow abstraction built in, though.
Functional programming languages give us a way to create our own using higher-order functions.
For instance, to create a control flow structure that executes a piece of code n times and prints out the average time for the runs, we can write a function that takes another function and invokes it n times.
However, just using higher-order functions leaves us with a verbose syntax for our custom control flow.
In Clojure we can use the macro system, and in Scala we’ve got a bag of tricks that include blocks and by name parameters.
Let’s start off with a look at a basic custom control structure, choose, which chooses between three different options.
We’ll explore two different implementations: the first will use higher-order functions and the second will explore how we can improve on our first solution by providing some syntactic sugar.
It then executes the corresponding function, as the following code shows:
It works as we’d expect; however, the need to wrap our actions up in functions is cumbersome.
A better syntax would be if we could just pass naked expressions into the choose(), as we do in the following imaginary REPL session:
Let’s see how to make this syntax real, starting with a very simple case.
In the following REPL output, we define a test() function with a single argument, expression.
The body of the function just attempts to execute the expression.
We then call test() with the single argument println("hello, world")
It appears that this works and our expression is evaluated, since "hello, world" is printed to the console.
But what happens if we try to execute our expression twice? Let’s find out in the following REPL snippet:
The string "hello, world" is only printed to the console once! This is because Scala will, by default, evaluate an expression at the time it’s passed into a function and then pass in the value of the evaluated expression.
This is known as pass by value, and it’s usually what we want and expect.
For instance, in the following example, it prevents the expression from being evaluated twice:
However, this is the opposite of what we need when writing custom control structures.
Scala gives us an alternative calling semantic called pass by name.
Using pass by name means that we pass a name for the expression into the function rather than the evaluated value of the expression.
We can then refer to that name inside the function body to have it be evaluated on demand.
To make a function argument pass by name rather than by value, we can use => after the parameter name and before the type annotation.
The following REPL snippet rewrites our test function to use pass-by-name calling:
Now that we understand the difference between pass by value and pass by name, we can write a simplerChoose() function that takes naked expressions.
Now we can use our naked expression syntax, as in the following REPL output:
Clojure’s approach to custom control flow is quite different and involves its powerful macro system.
Let’s start off our Clojure sample with a look at a simple version of choose that relies on higher-order functions.
We take three functions and an integer indicating which one to run, as the following code shows:
To use it, we pass in our integer and function arguments:
However, we’d like to avoid the need to wrap our actions up into functions and instead write code that looks like the following REPL session:
To see how we can get there, we’ll need to take a short detour into one of Clojure’s most powerful features, its macro system.
Along the way, we’ll answer the age-old question of why Lisp has such a different syntax.
Clojure Macros Macros are a form of metaprogramming: they are pieces of code that transform other pieces of code.
This concept has surprising depth in Clojure and other Lisps.
One way to cut down on verbosity is to create a skeletal Java class with nothing but attributes in it, and then write code to generate the builder based on those attributes.
A block diagram of this approach is described in the following figure:
Here, the builder creator is a piece of code that’s responsible for taking in a skeletal Java class with nothing but attributes and producing a builder based on it.
This is much like the support that IDEs have to generate getters and setters.
To do so, the builder creator needs some understanding of the input Java code.
For such a simple task, the builder creator can just treat the file as text and read the input file line by line, figuring out which lines correspond to variable declarations as it goes.
However, what if we needed to manipulate our input Java code in a more complex way? Say we wanted to modify certain methods to log out the time they were invoked.
This would be difficult to do: how do we know when a method starts and ends if we’re just going through the file line by line?
The difficulty is that our simple code generator is treating the Java file as plain text.
Complicated language applications like compilers will go through a series of passes to generate an abstract syntax tree or AST.
The following diagram is a simplified representation of this process.
The AST represents code at a more abstract level in terms of things like methods and classes, rather than as simple text data.
For instance, a Java compiler written in Java might have Method and VariableDefinition classes as parts of its AST, among other things.
This makes the AST representation of code the most convenient representation to manipulate programmatically.
The syntax of Clojure is defined in terms of core Clojure data structures, like lists and vectors.
For instance, let’s take a close look at a humble function definition:
This is just a list with four elements in it.
The first is the symbol defn, the second is the symbol say-hello, the third is a vector, and the fourth is another list.
When Clojure evaluates a list, it assumes that the first element is something that can be called, like a function, a macro, or a compiler built-in, and it assumes that the rest of the list is made of arguments.
Other than that, it’s just a list like any other! We can see this by using a single quote, which turns off evaluation on the form it’s applied to.
In the following snippet we take the first element from two lists—the first list is a list of four integers, the second is the function definition we just introduced:
Since Clojure code is just Clojure data, it’s very easy to write code to manipulate it.
Clojure’s macro system provides a convenient hook to do this manipulation at compile time, as the figure shows.
Let’s dig into this process in a bit more depth.
In Clojure, the process of going from a sequence of characters to data structures is called reading, as described in the first box in the diagram.
Instead of being some magic hidden away inside of the compiler, it’s a facility that’s available to the programmer.
Some forms are available that will read from various sources, such as files or strings.
Here, we use the string version of read to read a vector from a string and take its first element:
The read form has a partner, eval, as shown in the second step of the diagram.
In the following snippet, we use eval to evaluate a def after we’ve read it in from a string:
You may have seen eval in languages like Ruby or Javascript; however, there’s a crucial difference between that eval and the one Clojure has.
In Clojure and other Lisps, eval operates on data structures that have been read in, rather than on strings.
This means it’s possible to do much more sophisticated manipulations, since we don’t have to build up our code using raw string manipulation.
The macroexpansion step as described in the diagram provides a convenient hook for us to do exactly this.
A macro is just a function with a few key differences.
A macro is run before compile time, and it returns the code to be compiled.
This gives us a formal, built-in way of doing the sort of manipulations we introduced in our Java builder-generator thought experiment.
In addition, a few other Clojure features help us build macros by controlling evaluation.
Together, these features let us build up code templates for use in macros.
Syntax quote turns evaluation off inside the form it’s applied to, and it expands any symbol name out to be fully qualified by its namespace.
Unquote, as the name suggests, lets us turn evaluation back on inside a syntax quote.
In the following snippet, we use syntax quote and unquote together.
Now that we’ve introduced macros, let’s see how we can use them to simplify choose.
The simplerChoose macro takes in a number and three forms, and it returns a cond expression that evaluates the appropriate form.
Before running it, we can use macroexpand-1 to see what code the macro generates, as we do in the following REPL session:
As we can see, the macro expands out to a cond statement, as we’d expect.
Now if we run it, it works as we’d expect, without the need to wrap our actions up in functions!
Clojure’s macro system is one of its most powerful features, and it explains why Clojure has the syntax it does.
In order for the magic to work, Clojure code has to be written in terms of simple Clojure data structures, a property known as homoiconicity.
Let’s take a look at a more involved instance of Customized Control Flow.
Here we’ll create a custom control abstraction that executes an expression a given number of times and returns the average time of the executions.
The first, timeRun(), takes an expression, runs it, and returns the time it took.
The second, avgTime(), takes an expression and a number of times to evaluate it and then returns the average time it took.
As advertised, this gives us a way to get the average runtime for a statement:
Let’s break this down a bit more using the REPL.
If we substitute some expressions in by hand, we can see this generates a sequence of run times.
The underscore in the for binding indicates that we don’t actually care about what the values of the Range expression are bound to, since we’re just using it to run our statement a set number of times:
From there, we use sum() to calculate the sum off all runtimes, and we divide by the number of runs to get the average:
One other interesting element of this solution is how we pass a by-name parameter through two different functions.
The toTime parameter is passed into avgTime(), and from there into timeRun()
The ability to chain together calls using by-name parameters is important because it lets us break up the code for more complicated instances of Customized Control Flow.
In Clojure, our solution consists of a macro, avg-time, and a function, time-run.
The avg-time macro generates code that uses time-run to time runs of the passedin statement and then calculate its average.
Here, we use it to calculate the average time for a test statement:
Let’s dig into how time-run works in a bit more detail, starting with a Clojure feature we introduce in this sample: automatic generated symbols, or gensyms.
To avoid accidental variable capture in macros, whenever we need a symbol in our generated code, we need to generate a unique symbol.
The way we do this in Clojure is to append a symbol name with a hash sign when we use one inside of a syntax quote.
As the snippet below shows, Clojure will expand the gensym out to a fairly unique symbol:
The second one might seem a little strange, since we’re just using underscore to indicate that we don’t care about the values in range, just as we did in Scala.
If we don’t make it a generated symbol, Clojure will qualify the symbol in the current namespace, but making it a gensym causes Clojure to generate a unique symbol for it.
The following syntax-quoted let statement serves as a template for the code that the macro will generate.
As we can see, the meat of the solution is a for statement that wraps the expression in to-time in a function and runs it through time-run the requested number of times:
To test this out, we can use macroexpand-1 to look at the code it generates, as we do in the following REPL session:
Since all the symbols are either gensyms or are fully qualified by their namespace, this can be a bit hard to read! If I’m having trouble understanding how a macro works, I like to manually convert the output from macroexpand-1 into the code that I’d write by hand.
To do this, you generally just need to remove the namespaces from fully qualified symbols and the generated part of gensyms.
As you can see, this cleaned-up output is much simpler to understand.
I’ve also found that the process of going through the generated code by hand will help any bugs in the macro to surface.
Both Scala and Clojure let us create customized control flow abstractions, but the way they go about doing so is very different.
The trick is that we can control when those statements are evaluated using by-name parameters.
In Clojure we use the macro system, which takes advantage of Clojure’s homoiconic nature.
Macros are a compile-time concern rather than a runtime one.
As we saw, they allow us to fairly easily write code that writes code by using syntax quote as a template for the code we want to produce.
Clojure’s approach is more general, but that’s only possible because of Clojure’s homoiconicity.
In order to approximate Clojure-style macros in a nonhomoiconic language like Scala, the language would have to provide hooks into the compiler that let a programmer manipulate ASTs and other compiler artifacts.
This is a difficult task, but Scala does have experimental support for this sort of compile time macro in Scala 1.10
Using this style of macro is more difficult than using a Clojure-style macro, since it requires some knowledge of compiler internals.
Since Scala macros are experimental, and since Scala provides other ways to implement Customized Control Flow, we won’t cover them here.
To create a miniature programming language tailored to solve a specific problem.
Domain-Specific Language is a very common pattern that has two broad classes: external DSL and internal DSL.
An external DSL is a full-blown programming language with its own syntax and compiler.
It’s not intended for general use; rather, it solves some targeted problems.
For instance, SQL is an instance of Domain-Specific Language targeted at data manipulation.
On the other hand, we’ve got internal DSLs, also known as embedded languages.
These instances of the pattern piggyback on some general-purpose language and live within the constraints of the host language’s syntax.
We’re trying to create a language that lets us express solutions to problems in a way that is closer to the domain at hand.
This results in less code and clearer solutions than those created in a general-purpose language.
It also often allows people who aren’t software developers to solve some domain problems.
In this section, we’ll look at building internal DSLs in Scala and Clojure.
The techniques we’ll use to build a DSL are very different in these two languages, but the intent remains the same.
The current crop of Scala DSLs rely on Scala’s flexible syntax and several other Scala tricks.
The Scala DSL we examine here will take advantage of several of Scala’s advanced abilities.
First off, we’ll see Scala’s ability to use methods in the postfix and infix positions.
These appear to let us add new behavior to existing types.
Finally, we’ll use a Scala companion object as a factory for the class it’s paired up with.
Internal DSLs are an old Lisp technique that Clojure carries on.
In Clojure and other Lisps, the line between Domain-Specific Language and frameworks or APIs is very blurry.
Good Clojure code is often structured as layers of DSLs, one on top of the other, each of which is good at solving a problem on a particular layer of the system.
For example, one possible layered system for building web applications in Clojure starts with a library called Ring.
This provides an abstraction over HTTP, turning HTTP requests into Clojure maps.
On top of that, we can use a DSL named Compojure to route HTTP requests to handler functions.
Finally, we can use a DSL named Enlive to create templates for our pages.
Clojure’s DSLs are generally built around a core set of higher-order functions, with macros providing syntactic sugar on top.
This is the approach we’ll use for the Clojure DSL we examine here.
I sometimes find myself cutting and pasting from a shell into a REPL when programming in Scala and Clojure.
Let’s take a look at a simple DSL to make this more natural by letting us run shell commands directly in a REPL.
In addition to running commands, we’ll want to capture their exit status, standard output, and standard error.
Finally, we’ll want to pipe commands together, just as we can in a normal shell.
The end goal of this example is to be able to run shell commands in a natural way inside of a Scala REPL.
For individual commands, we’d like to be able to run them like this:
And we’d like to run pipes of commands like so:
Let’s take our first step on our shell DSL journey by examining what we want a command to return.
We need to be able to inspect a shell command’s status code and both its standard output and error streams.
In the following code, we packaged those pieces of information together into a case class named CommandResult:
The ProcessBuilder class constructor takes a variable number of string arguments, representing the command to run and its arguments.
In the following REPL snippet, we create a ProcessBuilder that will allow us to run ls -la :
To run the process, we call start() on the ProcessBuilder we just created.
This returns a Process object that gives us a handle on the running process:
The Process object gives us access to all the information we need, but output from standard out and standard error are inside of InputStream objects rather than inside strings.
We can use the fromInputStream() on Scala’s Source object to pick them out, as we demonstrate in the following code:
The Command takes a list of strings representing the command and its arguments and uses it to construct a ProcessBuilder.
It then runs the process, waits for it to complete, and picks out the completed process’s output streams and status code.
To make Command classes a bit easier to construct, we add a factory method that takes a string and splits it into Command’s companion object:
As the following REPL session demonstrates, this gets us a bit closer to our desired syntax for running a single command:
We’ll create a conversion that turns a String into a CommandString with a run() method.
A CommandString turns the String it’s converting into a Command that its run() method calls.
Now we’ve got our desired syntax for running single commands, as we demonstrate with the following REPL output:
The approach we’ll take is to collect our piped command strings into a vector and run them once we’ve constructed the full chain of pipes.
Let’s start off by examining the extensions we need to make to CommandString.
Remember, we’d like to be able to run a pipe of commands like so: "ls -la" pipe "grep build" run.
This means we need to add a pipe() method, which takes a single string argument, to our CommandString implicit conversion.
When it’s called, it’ll take the string it’s converted to a CommandString and the argument it was passed, and it’ll stuff them both into a Vector.
Now our conversion will convert "ls -la" pipe "grep build" into a vector with both shell commands in it.
The next step is to add another implicit conversion that converts a Vector[String] into a CommandVector, much as we’ve already done for individual strings.
The CommandVector class had a run() and a pipe() method.
The pipe() method adds a new command to the Vector of commands and returns it, and the run() method knows how to go through the commands and run them, piping the output from one to the next.
The code for CommandVector and a new factory method on the Command companion object used by CommandVector follows:
Now we’ve got our full DSL, pipes and all! In the following REPL session, we use it to run some piped commands:
First, it takes advantage of Scala’s ability to use methods as postfix operators.
This is easy to misuse, so Scala 2.10 generates a warning when you do so, and it will be disabled by default in a future version of Scala.
Second is a simple DSL, suitable for basic use at a Scala REPL.
In Clojure, our DSL will consist of a command function that creates a function that executes a shell command.
Then we’ll create a pipe function that allows us to pipe several commands together using function composition.
Finally, we’ll create two macros, def-command and def-pipe, to make it easy to name pipes and commands.
Before we jump into the main DSL code, let’s take a look at how we’ll interact with the shell.
As we can see, the output of the function is a map consisting of the status code for the process and whatever the process wrote to its standard out and standard error streams as a string:
This isn’t very easy to read, so let’s create a function that’ll print it in a way that’s easier to read before returning the output map.
We can now use sh to run ls -a and get readable output:
Let’s move on to the first piece of our DSL, command function.
This function takes the command we want to execute as a string, splits it on whitespace to get a sequence of command parts, and then uses apply to apply the sh function to the sequence.
Finally, it runs the returned output through our print-output function, wraps everything up in a higher-order function, and returns it.
Now if we run a function returned by command, it’ll run the shell command it encapsulates:
If we want to name the command, we can do so using def:
Now that we can run an individual command, let’s take a look at what it’ll take to pipe them together.
A pipe in a Unix shell pipes the output from one command to the input of another.
Since the output of a command here is captured in a string, all we need is a way to use that string as input to another command.
The sh function allows us to do so with the :in option:
Let’s modify our command function to take the output map from another command and use its standard output string as input.
To do so, we’ll add a second arity to command that expects to be passed an output map.
The command function destructures the map to pluck out its output and passes it into sh as input.
Now we can define another command, like the following one that greps for the word README:
Then we can pass the output of our ls command into it, and the ls output will be piped into grep.
Each command will print its output to standard out, as the following REPL session shows:
With our modified command function, we can create a pipe of commands by composing together several commands with comp.
If we want to write the commands in the same order as we would in a shell, we just need to reverse the sequence of commands before we compose them, as we do in the following pipe implementation:
Now we can create a pipe of commands, as we do in the following REPL session:
This has the same effect as running the ls command and passing its output into grep-readme:
Now that we can define commands and pipes, let’s use macros to add some syntactic sugar to make things easier.
This macro takes a name and a command string and defines a function that executes the command string.
Now we can define a command and name it with a single macro invocation, as we do in the following REPL output:
Now let’s do the same for our piped commands as we did for single commands with the def-pipe macro.
This macro takes a command name and a variable number of command strings, turns each command string into a command, and finally creates a pipe with the given name.
Now we can create a pipe in one shot, as we do below:
Scala uses a flexible syntax and a variety of tricks.
In fact, most of the Clojure language itself is written as a set of Clojure functions and macros! Advanced Scala DSL writers may bang up against the limitations of Scala’s current approach.
However, as noted in the Discussion, on page 217, they’re much harder to implement and use without the simple syntax and homoiconicity available in Clojure and other languages in the Lisp family.
The End That wraps up our look at patterns in functional programming.
Hopefully now you see how functional programming tools can help you write shorter and clearer code and how immutable data can remove large sources of error from your programs.
I hope you’ve also gotten a taste for both Scala and Clojure.
Even though they both include functional features, they’re quite different from each other.
By seeing examples written in both Scala and Clojure, you’ve been exposed to a wide range of functional techniques.
Most of all, I hope you can apply what you’ve learned in this book to make your day-to-day programming experience better.
You want to explore functional programming, but are put off by the academic feel (tell me about monads just one more time)
You know you need concurrent applications, but also know these are almost impossible to get right.
Meet Elixir, a functional, concurrent language built on the rock-solid Erlang VM.
Elixir’s pragmatic syntax and built-in support for metaprogramming will make you productive and keep you interested for the long haul.
This book is the introduction to Elixir for experienced programmers.
A multi-user game, web site, cloud application, or networked database can have thousands of users all interacting at the same time.
In this second edition of the bestselling Programming Erlang, you’ll learn how to write parallel programs that scale effortlessly on multicore systems.
The Joy of Math and Healthy Programming Rediscover the joy and fascinating weirdness of pure mathematics, and learn how to take a healthier approach to programming.
Mathematics is beautiful—and it can be fun and exciting as well as practical.
Good Math is your guide to some of the most intriguing topics from two thousand years of mathematics: from Egyptian fractions to Turing machines; from the real meaning of numbers to proof trees, group symmetry, and mechanical computation.
If you’ve ever wondered what lay beyond the proofs you struggled to complete in high school geometry, or what limits the capabilities of the computer on your desk, this is the book for you.
To keep doing what you love, you need to maintain your own systems, not just the ones you write code for.
Regular exercise and proper nutrition help you learn, remember, concentrate, and be creative—skills critical to doing your job well.
Learn how to change your work habits, master exercises that make working at a computer more comfortable, and develop a plan to keep fit, healthy, and sharp for years to come.
This book is intended only as an informative guide for those wishing to know more about health issues.
In no way is this book intended to replace, countermand, or conflict with the advice given to you by your own healthcare provider including Physician, Nurse Practitioner, Physician Assistant, Registered Dietician, and other licensed professionals.
Seven Databases, Seven Languages There’s so much new to learn with the latest crop of NoSQL databases.
And instead of learning a language a year, how about seven?
Data is getting bigger and more complex by the day, and so are your choices in handling it.
From traditional RDBMS to newer NoSQL approaches, Seven Databases in Seven Weeks takes you on a tour of some of the hottest open source databases today.
Tate’s Seven Languages in Seven Weeks, this book goes beyond your basic tutorial to explore the essential concepts at the core of each technology.
You should learn a programming language every year, as recommended by The Pragmatic Programmer.
Whether or not your favorite language is on that list, you’ll broaden your perspective of programming by examining these languages side-by-side.
You’ll learn something new from each, and best of all, you’ll learn how to learn a language quickly.
The titles continue the well-known Pragmatic Programmer style and continue to garner awards and rave reviews.
As development gets more and more difficult, the Pragmatic Programmers will be there with more titles and products to help you stay on top of your game.
Register for Updates http://pragprog.com/updates Be notified when updates and new books become available.
Join the Community http://pragprog.com/community Read our weblogs, join our online discussions, participate in our mailing list, interact with our wiki, and benefit from the experience of other Pragmatic Programmers.
New and Noteworthy http://pragprog.com/news Check out the latest pragmatic developments, new titles and other offerings.
Buy the Book If you liked this eBook, perhaps you'd like to have a paper copy of the book.
