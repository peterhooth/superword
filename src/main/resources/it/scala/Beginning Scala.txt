It has forever changed the way that I approach software design and development.
Yikes, you say, I don’t want something that’s going to break my brain.
The cool thing about Scala is that you can dip your little toe in the water and see how Scala feels.
As you’ll see in Beginning Scala, you can code Scala just as you code Java, except you’ll have less boilerplate code.
I’ll show you how you can wade into Scala up to your knees and start using Scala’s XML literals to dynamically create XML to pass data around your application.
This built-in XML support allows you to write complex web applications easily and efficiently, because you can process XML using the same constructs you use for other data sequences.
I’ll show you how this allows you to transform XML into data structures and objects with no fuss.
You can then go a little deeper into Scala and use immutable data structures and pass functions around (although functions are implemented as anonymous inner classes, so you’re really not that far from Java)
If you’re feeling wicked adventurous, you can join me in dabbling with Scala’s powerful type system.
You’ll spend less time writing boilerplate code and more time thinking about and writing the logic of your application.
Please join me in exploring the power, simplicity, and beauty of Scala.
Learn the powerful Scala functional-object language in a fun, interactive way.
No part of this work may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or by any information storage or retrieval system, without the prior written permission of the copyright owner and the publisher.
Rather than use a trademark symbol with every occurrence of a trademarked name, we use the names only in an editorial fashion and to the benefit of the trademark owner, with no intention of infringement of the trademark.
Apress and friends of ED books may be purchased in bulk for academic, corporate, or promotional use.
For more information, reference our Special Bulk Sales–eBook Licensing web page at http://www.apress.com/info/bulksales.
The information in this book is distributed on an “as is” basis, without warranty.
Although every precaution has been taken in the preparation of this work, neither the author(s) nor Apress shall have any liability to any person or entity with respect to any loss or damage caused or alleged to be caused directly or indirectly by the information contained in this work.
The source code for this book is available to readers at http://www.apress.com.
A curious attribute of the Scala programming language is that it expends a lot of expressive power in order to make the life of casual programmers simpler.
For instance, Scala provides sophisticated type parametrization and traits so that more advanced programmers can design libraries which are at the same time general and easy to use.
Casual users can profit from these libraries long before they discover the full power of Scala’s abstraction constructs.
The language design avoids the temptation of simply defining some handy primitives in the syntax, even if these primitives would be useful many times to many users.
Instead of fixed primitives, the language design tries very hard to provide general construction principles, with which users can then define their own fundamental constructs, at no loss in syntactic convenience.
This idea ranges from simple things, such as being able to define your own numeric data types, to full-blown domain-specific APIs such as Scala’s support for concurrent actors.
It leverages the full expressive power of Scala to provide a framework that’s at the same time simple to use, powerful, and secure.
David has been one of the earliest adopters of Scala.
He has become a crystallization point for many important developments in the Scala community.
He fostered the vibrant Lift community, organized the first Scala Lift Off conference in 2008, and promoted the adoption of Scala in many important industrial applications.
His experience puts him in a unique position to explain the language thoroughly and competently.
At the same time, David is a great communicator, and he has always the needs of beginners to the language in mind.
This book shows these two traits of his very well.
Written by an expert user of the language, it puts the focus on what’s important for a beginner.
It moves you swiftly from simple examples to more complete applications, explaining both language and core libraries.
It manages to show that Scala is, fundamentally, a pretty simple language to pick up, and at the same time a language with few limits if you want to progress.
I hope you’ll enjoy reading it as much as I did.
He wrote the first real-time spreadsheet, Mesa, and the world’s highestperformance spreadsheet engine, Integer.
Since 1996, David has been using and devising web development tools.
David was CTO and VPE at Cenzic, a web application security company.
David has also developed numerous commercial projects in Ruby on Rails.
Lift is an expressive and elegant framework for writing web applications.
Lift stresses the importance of security, maintainability, scalability, and performance, while allowing for high levels of developer productivity.
Lift open source software is licensed under an Apache 2.0 license.
Studying computer science at Indiana University hooked him on Scheme and functional programming.
The launch of the Macintosh in 1984 introduced him to objects via Smalltalk, Object Pascal, and MacApp.
He later discovered objectfunctional programming in OCaml, and is thrilled to find a language as powerful as Scala for the JVM.
Paul is a former contributing editor for MacTutor Magazine, served as a technical reviewer for Paradigms of.
I’d like to thank a lot of people for the opportunity to write Beginning Scala.
My dad gave me the encouragement to seek and share knowledge.
My wife, Annette, and my kids have been great through the process, cheering me on and hugging me when I needed it.
Martin Odersky’s amazing balance between theory and reality make Scala possible, and the people he has attracted into the community are brilliant.
The Lift committers and community make me smile and make me think and make me code.
Gary Cornell had faith in me as an author, although he mistimed it by eight years.
Finally, Steve Anglin and the Apress team have been a total pleasure to work with, and they carry on Gary’s vision of Apress as the author’s publisher.
Ouch! That hurts my brain! Stop making me think differently.
This different way of solving the problem has some benefits.
I felt that way after my first year of law school.
I felt that way for a while when I began coding Scala.
What’s this Option thingy? Give me back my null! How do you get the fifth element from a Seq? On and on it went.
Day after day of head-splitting paradigm changing and breaking 30 years of coding habits, I am somewhat at peace with the Scala way of coding.
Yes, my coding habits were borne out of 6800 machine code coding.
That’s all you’ve got when you’ve got an accumulator, a program counter, and an index register.
After more than two years of coding Scala, I’ve come to understand that the Scala idioms are really better.
I see that it’s more important for me to take small elements and compose them together into complex systems.
I understand that if a method always returns the same output given the same input, I can safely glue that function together with other functions into a very complex structure.
I understand that explicit looping in my code is a distraction from the business logic that is buried in the code.
My path was hard, and I hope yours will be easier.
The first step in writing Scala is not being afraid of the fact that Scala’s going to warp your brain.
The next step in writing Scala is accepting that your code is going to look like Java, Ruby, Python, whatever code for a while.
It will take you time and effort and more time to code Scala using the idioms in this book.
It will take you time to design code that fits into Scala paradigms and to discover and devise paradigms of your own.
It will take time but hopefully less time than it took me.
It’s my attempt to show you a different way of thinking about and writing code.
I hope that you’ll enjoy our journey through Scala together.
I hope that by the end of this book you’ll have a new perspective on coding.
I hope that you’ll be writing better code and fewer lines of code yet be happier about the code that you’re writing.
Stick that little toe in the Scala waters and see if they feel as good for you as they have for me.
Who This Book Is For This book is for folks with some programming background who want to dip their little toe into Scala, check the temperature, and perhaps wade in some more.
How This Book Is Structured Chapters 1–3 are meant to give you a basic grounding in Scala syntax and Scala idioms.
Chapters 4–6 tour key Scala features: functions, pattern matching, and Actors.
Chapter 7 is a deep dive into Scala’s type system.
Chapter 8 rolls the pieces together with an exploration of Scala’s parser combinator library.
Chapter 9 discusses bringing Scala into your organization and building teams around Scala coding.
Downloading the Code The source code for this book is available to readers at www.apress.com in the Source Code section of this book’s home page.
Please feel free to visit the Apress web site and download all the code there.
You can also check for errata and find related titles from Apress.
Contacting the Author David blogs Scala at http://scala-blogs.org and rants about things on his personal blog at http://blog.lostlake.org.
But David can most often be found on the Lift user group, http://groups.google.com/group/liftweb/
In this chapter, I’ll discuss my journey learning Scala as well as where Scala comes from, how to install it, and the Scala community.
Over the years, I’ve had a couple of “Oh my!” reactions to computer languages.
In 1996, when I first found Java, it was a revelation.
I no longer had to worry about freeing memory, and Java had a sane and normal exception-handling mechanism.
Overnight, 70 percent of the defects in my programs went away.
Scala can call any Java code, subclass any Java class, and implement any Java interface.
Java code can call into Scala code if the Scala code subclasses a Java class or implements a Java interface.
There are features of Scala that cannot be accessed from Java, including traits with defined methods, classes and methods that have names illegal in Java, and Scala’s advanced types.
The JVM’s overall performance improved with HotSpot, and by JDK 1.3, Java application code was as fast as C++ application code.
Java programs could run for weeks, months, and in some cases, years without restarting.2
Integer, a pure Java spreadsheet that I wrote, performed as well as Excel in Sun benchmarks on a single-processor machine.
Integer outperformed Excel by significant margins on symmetric multiprocessing (SMP) machines.
Sam Pullara benchmarked Java’s String classes against Objective-C’s NSString classes and found that Java outperformed native code by a wide margin.
I agree that a hyper-tuned C or C++ program can outperform a Java program and that Java programs require 100 percent more RAM to perform as well as their C or C++ counterparts, but for any moderately complex project that is not at the operating system kernel level, a JVM program will outperform a C or C++ program.
Java stagnated in syntax, and web frameworks built on Java became increasingly top-heavy.
It took more and more lines of Java, XML, and other pieces of glue to express simple concepts such as fields and to generate HTML forms from those fields.
I used Java on most projects but became increasingly disillusioned with it.
I found these to be welcome additions at the conceptual level, but at the coding level I could no longer use a simple text editor.
I started searching for a way to express the code in my brain in a simpler, more direct way.
Ruby allowed me to express concepts in far fewer lines of code.
Rails was so much easier to use than Spring MVC, Hibernate, and the other “streamlined” Java web frameworks.
With Ruby and Rails, I got to express a lot more of.
The web site http://dogscape.com ran for 13 months between restarts.
I had to restart the Java process when I needed to upgrade the OS.
It was similar to the liberation I felt when I moved from C++ to Java.
But I found the ugly underbelly of Ruby and Rails.
Ruby’s runtime was so slow and flakey that I was embarrassed to deliver Ruby-based projects to my clients.
I had to do my prototypes in Ruby and then port the code over to Java.
As my Ruby and Rails projects grew beyond a few thousand lines of code and as I added team members to my projects, the challenges of dynamic languages became apparent.
We were spending more than half our coding time writing tests, and much of the productivity gains we saw were lost in test writing.
Most of the tests would have been unnecessary in Java because most of them were geared toward making sure that we’d updated the callers when we refactored code by changing method names or parameter counts.
Also, I found that working on teams where there were mind melds between two to four team members, things went well in Ruby, but as we tried to bring new members onto the team, the mental connections were hard to transmit to new team members.
I went looking for a new language and development environment.
In November 2006, I found this combination and a whole lot more in Scala.
Martin has a team dedicated to maintaining Scala as well as researching ways to mature the language.
Beyond being an academic project, Scala is fast and concise, and it has even more type-safety features than does Java.
Scala compiles down to Java bytecode, runs fast on the JVM, and is interoperable with Java code.
When I first found Scala, I couldn’t believe its claims of performance and Java compatibility.
But as I pushed on Scala, I found that it was stable.
As I pushed on Scala, I found that it was fast.
As I pushed on Scala, I found that it worked perfectly with all the Java libraries that I threw at it.
But most importantly, Scala taught me to program and reason about programming differently.
I stopped thinking in terms of allocating buffers, structs, and objects, and of changing those pieces of memory.
Instead, I learned to think about most of my programs as transforming input to output.
This change in thinking has lead to lower defect rates, more modular code, and more testable code.
Scala has also given me the tools to write smaller, more modular units of code and assemble them together into a whole that is maintainable, yet far more complex than anything that I could write in Java or Ruby for that matter.
After more than two years of writing and loving Scala, the only regrets that I have are that I didn’t learn Lisp in college or take any programming language theory courses in grad school.3 Each morning that I sit down at the keyboard and start coding Scala, I get a feeling of calm, peace, and power.
I know that I’m going to have another day of taking the ideas in my head and reducing them to a running computer program that will be fast and low in defects.
So, please join me in exploring the Scala programming language.
Most of the book will be oriented to writing simple code.
I find that most of my work is done in this mode.
We’ll do a little exploration of Scala’s type system and component architecture, but I find that I use those Scala features rarely, when I’m in “library writer” mode.
Scala provides tools for me as an architect that allow me to specify complex relationships between types and classes and ultimately lets me reason about my code.
Working with these tools requires a lot of thinking on my part, and often when I’m working in this mode, I will produce seven lines of code in a day and feel very proud of it.
In this mode, I worry about view bounds, covariance and contravariance, implicit conversions, and so on.
However, most of my coding time is spent in library consumer mode.
In this mode, my code looks a whole lot like Ruby or Python code.
I spit out hundreds of lines of code a day, and I know the type system is there to back me up so my tests focus on the logic, not the mechanics, of my code.
Chapter 7 will touch on some of the library-producer coding features of Scala.
I’ll be writing a lot of code like this (although perhaps a bit more practical) throughout this book.
While I’ve been programming professionally for 30 years or more, it’s only in the last two years that I’ve come to appreciate recursion and the other things that were part of Lisp from the beginning.
Odersky and his team balance between working with Scala as research into how to make programming languages better for all programmers and working with Scala as a tool for commercial software development.4 They deliver timely updates to Scala along with rapid bug fixes and excellent support.
Scala is open source software available under a BSD-like license.
They began doing computer science research and programming language development targeted to the JVM.
Odersky and Wadler conspired on a language called Pizza that compiled to Java bytecode and had generics, first-class functions, and pattern matching.
He and his team started using Scala as a teaching language at EPFL.
Martin Odersky is the core of the Scala group, but he’s attracted some extremely talented individuals5 who have contributed significantly to Scala over the years.
Lex Spoon (http://www.lexspoon.org/), who has written much of the Scala internals.
Burak Emir (http://burak.emir.googlepages.com/), who built Scala’s XML support and has done a lot of work on Scala’s pattern matching.
Further, Burak has served as my guide and mentor in learning Scala.
Adriaan Moors (http://www.cs.kuleuven.be/~adriaan/), who visited Martin’s group for a number of months and provided enhancements to Scala’s type system and Scala’s parser combinator.
Philipp Haller (http://lamp.epfl.ch/~phaller/), who wrote Scala’s Actor support and has always been eager and excellent at adding features to Actors necessary for my work.
Martin provides the gravity to draw in some excellent brains into the building of Scala, but Martin is committed to Scala as a commercial language while satisfying the research needs of his team.
As of this writing, Scala is at version 2.7.3 and has matured significantly.
More than half a dozen people have earned PhDs based on their Scala-based research.
Scala is in production at some of the largest and best-known companies in the world, including SAP and Twitter.
Installing Scala In order to run Scala, you must have Java 1.5 or greater installed on your computer.
If you are running Mac OS X, you already have the Java Development Kit (JDK) on your machine.
If you’re running Linux or Solaris, please consult with your distribution’s Java installation instructions.
First, you must set the JAVA_HOME environment variable and add the JDK’s bin directory to your PATH variable.
In both, now select the Advanced tab and click the Environment Variables button.
Set the Variable Name to JAVA_HOME and the Variable Value to the place that you installed the JDK.
Next, select the PATH variable and click the Edit button.
Move the cursor to the beginning of the Variable Value and type %JAVA_HOME%\bin; before the rest of the line.
Click the Start button and select Run…; in the dialog, type cmd and click the OK button.
A DOS window should appear with a prompt that looks like the following:
Next, test to see that the Java compiler is installed.
Save this file to the Desktop or some other place that you can find it.
Once complete, you need to create the SCALA_HOME environment variable and add Scala to your PATH variable.
By default, the JDK is installed on Mac OS X 10.4 and greater.
Open a terminal window and change directories to the location where you downloaded the Scala installer.
The Scala Community The Scala community is a wide-ranging, rich, and vibrant group of people.
It’s a warm and welcoming place for newbies, but it also offers academically rigorous debate and lots of ideas from the cutting edge of computer science made practical.
There are lots of cool people from lots of different backgrounds in the Scala community.
They actively participate in the community, answering questions from newbies and from seasoned folks about Scala basics, design choices, and more.
There’s a cohort of extremely skilled and experienced functional programming gurus, including David MacIver.
James Iry is another highly skilled functional programming guru who has a magic touch when it comes to explaining complex Scala concepts to just about anyone.
Jon Pretty and Jamie Webb of Sygneca provide consulting services and a ton of backbone for the Scala list and Scala community.
You may hear from Jorge Ortiz who, like James, is great at explaining complex Scala.
The list of Scala mailing lists managed by EPFL (Martin’s group) can be found at http://www.scala-lang.org/node/199
This list is for discussing Scala, asking questions, and making observations.
It’s a great place for intermediate and advanced Scala developers to exchange ideas and information.
The Scala User list is oriented toward newbies, and it’s a great place for folks to learn about Scala by seeing the kind of questions that other newbies have about the language.
The Scala Debate list is a place for seasoned Scala folks to discuss the language, make suggestions, and conspire to move Scala forward.
Note that this list is a hard-core, no-holds-barred discussion of Scala that sees some minor flame wars occasionally break out among the mathematically inclined.
If you venture into this forum, keep in mind that it does, from time to time, devolve into discussion that is not kind and gentle and that often the discussion is indecipherable for those of us who do not have a PhD in mathematics.
If this is the kind of discussion that is interesting to you, please check out Lambda the Ultimate at.
LtU provides a forum for a broad spectrum of programming language theory (PLT) discussions.6
While I’m the lead developer for Lift, we’re not going to focus much on web development in this book, but if you’re a web developer, I’d love it if you’d join the Lift community.
Those are the main mailing lists in the Scala community.
As you explore with Scala, please join the online discussion and share your questions and thoughts.
Summary You’ve learned a little about what attracted me to Scala, a little about where Scala comes from, and you’ve installed Scala.
Now it’s time to explore Scala and see whether it resonates with you the same.
Paul Snively, the technical editor of this book, is an editor on LtU.
It’s a pleasure and an honor to have him participate in this project.
If you dive deep into PLT, I hope you find Paul to be a compass and a beacon as I do.
We’re going to get our hands dirty with Scala code in this chapter.
We’ll write some Scala code, starting with the ubiquitous “Hello World,” and moving on to more complex Scala programs.
This will give your eyes and brain an idea of what Scala code looks like.
Next, we’re going to take a long and boring tour of Scala’s syntax.
Finally, we’re going to see some options for running (and compiling) Scala programs.
Scala at the Command Line and Scala Scripts Scala offers different ways to run programs:
You can run them interactively at a REPL (read-eval-print loop) command line.
You can compile your Scala programs into class files that can be combined into JAR files, just as in Java.
Scala’s flexibility allows you to choose the environment that’s best for you.
When I’m exploring a new construct or library, I want instant feedback.
I want to type a couple of lines of code and see what happens.
Scala’s REPL gives me the immediacy and interactivity that I need when I’m exploring.
To start Scala’s REPL, open a command prompt or terminal and type scala.
You can start typing things and see how they’re evaluated in Scala, for example:
Most of the examples in this book are done at the Scala REPL.
If your program grows beyond the few lines in the REPL, you can start building Scala scripts.
In fact, when you run your script, Scala wraps the entire file into the main method of a class, compiles the code, and calls the generated main method.
All you have to do is put valid Scala code in a file.
You can access the command-line arguments in your script with the argv variable, which is an Array[String]
You can compile Scala programs just as you compile Java programs, and the results are JVM class files that can be packaged into JAR files.
The Scala compiler requires that source files contain one or more class, trait, or object definitions.
To compile Scala source files into class files, type the following:
You can also compile using the fast Scala compiler, fsc:
This results in much faster compilation times, but if you’re on a machine with limited RAM, you might not want to keep the compilation process alive.
If you are working on medium-sized to large projects, you probably use some sort of build tool such as Ant or Maven.
There are Scala plug-ins for both Ant and Maven, so you can integrate Scala code into existing Java projects with very little effort and no requirement of using new build tools.1
Your First Scala Programs In this section, we’re going to write a couple of basic Scala programs.
These programs will give you a sense of Scala’s flavor and get you acquainted with running Scala programs.
Open up your favorite text editor: Emacs, vi, TextMate, whatever.
Create a new file called HelloWorld.scala and place the following line in it:
Open a terminal window or command prompt and change into the directory where the file is and type scala HelloWorld.scala.
You can join the Scala tools mailing list at http://www.scala-lang.org/node/199
In Scala, you can write simple programs that look and feel like scripts that you would write in Ruby or Python.
In this case, you’re calling the println method with the string constant Hello World!
Because println is used so frequently, it’s part of Scala’s Predef, the predefined stuff that’s automatically part of every program.
This is like the java.lang package that is automatically imported in every Java program.
You can run the code by typing scala Print1.scala in the terminal.
You can nest expressions in a for comprehension (the fancy Scala name for the for statement)
There are many more uses of the for comprehension that we’ll cover later in the book.
The next program will read all the lines from the input and sum each line that contains a valid integer.
This program introduces you to a substantial number of Scala’s concepts, including passing functions as parameters, Scala’s type system, immutable data structures, and more.
It’s a bit of a dive into the deep end, so let’s go.
Create a file called Sum.scala containing the code in Listing 2-1
The import scala.io._ code imports all the classes from the scala.io package.
Coming from Javaland, it takes a little getting used to, but it’ll soon make sense.
Next, we define the toInt method, which takes a single parameter called in.
The method name follows, along with the method’s parameter list.
In this case, the toInt method takes one parameter: in, whose type declaration follows it rather than precedes it.
In some cases, the Scala compiler can figure out or infer the type of a variable or the return type of a method.
You need to declare the parameter types for a Scala method, but we may omit the return type if the.
In general, if the return type is not immediately obvious, it’s an act of kindness and good citizenship to your fellow programmers and your future self to declare the return type.
What’s Option and what are those funky square brackets around Int? Option is a container that holds one or zero things.
If it holds zero elements, it’s None, which is a singleton, which means that only one instance of None.
The funky square brackets denote the type of thing that’s held by the Option.
In Scala, everything is an instance of a class, even Int, Char, Boolean, and the other JVM primitive types.
The Scala compiler puts primitive types in instance boxes (boxing) only when necessary.
The result is that you can treat all classes uniformly in Scala, but if your primitive data does not require boxing, you’ll see the same program performance you see using primitives in Java.
If your primitive does require boxing, the Scala compiler does all the boxing and unboxing for you, and it even does null testing when it unboxes—nice and.
So, Option[Int] is a container that holds zero or one Int value.3 Using Option is one of.
How? You can apply your business logic over all the elements in the Option.
If the Option is None, then you apply your logic over zero elements.
If the Option is Some, then you apply your business logic over one element.
Option can be used and nested in the for comprehension.
When I’m writing code, I return Option from any method that, based on business logic, might return some value or might return none.
In this case, converting a String to an Int might succeed if the String can be parsed or might fail if the String cannot be parsed into an Int.
If the String cannot be parsed, it is not something that’s worthy of an exception because it’s not an exceptional situation.
It is merely a calculation that has no legal value, thus it makes sense to return None if the String cannot be parsed.
This mechanism also avoids the Java patchwork of sometimes returning null when there’s no legal value to return and sometimes throwing an exception.
Speaking of exceptions, that’s exactly what Integer.parseInt does when it cannot parse the String into an Int.
If the Integer.parseInt method succeeds, a new instance of Some will be created and returned from the toInt method.
There’s no explicit return statement as the last expression evaluated in the method is its return value.
Option[Int] is a “variant type” or “sum type” with None as one variant and Some[Int] as the other.
Neither None nor Some[Int] is the same as Int, but if you’re working with an Option[Int] that happens to be of the variant Some[Int] then you can extract the actual Int from it by calling the get method.
If Integer.parseInt throws an exception, it will be caught by the catch block.
In Scala, there’s a single catch and a series of patterns to match the exception.
Pattern matching is a language-level Scala construct, and it’s uniformly applied across the language.
To summarize: toInt takes a String and attempts to convert it to an Int.
We don’t declare the return type for sum because the compiler can figure it out and the method is short enough that a quick glance at the code shows us that the return type is an Int.
A Seq is a trait (which is like a Java interface) that is inherited by many different collections classes.
A Seq is a supertrait to Array, List, and other sequential collections.
A trait has all the features of the Java interface construct.
If you are familiar with Ruby, traits are similar to Ruby’s mixins.
Traits cannot take constructor parameters, but other than that they behave like classes.
This gives you the ability to have something that approaches multiple inheritance without the diamond problem (http://en.wikipedia.org/wiki/ Diamond_problem)
The first line of the sum method transforms the Seq[String] to Seq[Int] and assigns the result to a val named ints:
This maps and flattens each element by calling the toInt method for each String in the sequence.
The result is that each String from the Seq[String] that can be converted to an Int is put in the ints collection.
In Scala, you can declare variables as assign-once or assign-many.
Assign-once Scala variables are the same as Java’s final variables.
Assign-multiple variables in Scala are the same as Java variables and are identified with the var keyword.
Because I’m not changing the value of ints after I set it, I chose the val keyword.
I use val in my programs unless there’s a compelling reason to use var, because the fewer things that can change, the fewer defects that can creep into my code.
Another fancy thing that we’ve done is create a function that calls the toInt method and passes it to the flatMap method.
In our example, we defined a function that takes a single parameter, s, and calls toInt with that parameter.
We pass this function as the parameter to flatMap, and the compiler infers that s is a String.
Thus, an anonymous function is created, and an instance of that function is passed to the flatMap method.
Additionally, Scala sees that the return type of toInt is an Option[Int], so it infers that the ints variable has the type Seq[Int]
It takes the result and applies the function to the result and the next value in the sequence repeatedly until there are no more elements in the sequence.
In math, sum, prod, min, max, and so on can be implemented easily with foldLeft.
In this case, we defined a simple function that takes two parameters, a and b, and returns the sum of those parameters.
We did not have to declare the types of a or b, because the Scala compiler infers that they are both Ints.
The foldLeft line is the last expression in the method, and the sum method returns its results.
Its type is Source, a source of input, which wraps the JVM’s System.in InputStream.
In this case, we didn’t have to do anything fancy to access a Java class.
We used it just as we might have from a Java program.
The next line gets the lines from our source and collects them into a Seq[String]:
Finally, we print a message on the console with the sum of the lines with parsible integers on them:
When you’re done, press Ctrl-D (Unix/Linux/Mac OS X) or Ctrl-C (Windows), and the program will display the sum of the numbers.
Great, you’ve written a Scala program that makes use of many of Scala’s features including function passing, immutable data structures, and type inference.
Basic Scala Syntax Scala, like Java, is a C-derivative language, and many familiar C syntactic constructs are visible in Scala.
The biggest syntactic difference between Scala and Java is that the ; line end character is optional.
There are other differences, but they should be pretty understandable and self-explanatory.
In this section, I’ll review the parts of Scala’s syntax that you’ll need for the rest of the book.
Scala has all the same constants as Java, with the same memory footprint and precision.
Scala also supports multilined Strings that start and end with triple quotes:
Java and Scala convention dictates that package names are the reversed domain name of the code owner.
For example, the packages in the Lift Web Framework (http://liftweb.net) begin with net.liftweb.
Typically, the package also contains a descriptive name for the module.
The package declaration is the first non-comment line in the source file:
Scala packages can be imported so that they can be referenced in the current compilation scope.
The following statement imports the contents of the scala.xml package:
Import statements are made in the scope of prior imports.
Finally, you can import a class or object and rename it.
Scala’s object model allows you to model any Java class.
Everything you can do with a Java class you can do with a Scala class.
Scala’s class declaration syntax and rules are different from and, in my opinion, more flexible than Java’s.
It’s common to declare far more classes in a Scala program than in a Java program.
Scala removes Java’s constraint of one public class per file.
You can put as many classes in a file as you want, and you can name the file whatever you want.
Your IDE will help you navigate from class to file.4
In Scala, everything has public access level unless otherwise declared.
You can define the public Foo class that has no methods:
If the constructor or method takes zero parameters, you can omit the parameter list.
To create an instance of Foo, you can type the following:
To define the Bar class that takes a single constructor parameter, name, which is a String:
The declaration of Scala classes is syntactically more lightweight than Java’s declarations.
Classes with constructors, properties, and so on can be declared in a single line of code.
Classes in Scala are often used to enforce type safety.
For example, you might return an instance of Name rather than String.
As we explore more about Scala, you’ll see why Scala programs often group many class definitions into a single source file.
To define Baz with a constructor that tests name and throws an exception if name is null:
The Java interface defines a set of methods that must be implemented on all classes that implement the interface.
Traits can do everything that interfaces can do, but they can also include method implementations.
This comes in very handy because you don’t have to create complex class hierarchies in order to avoid duplicating code.
You just write the code in the trait, and every class that implements the trait gets those methods.
To define the Cat trait, which requires that any extending classes implement the meow method:
To define the FuzzyCat trait that extends Cat and implements the meow method:
And to define the Yep class that extends FuzzyCat and OtherThing:
Using the REPL, let’s see what happens when we call the meow and hello methods on a Yep instance:
Scala does not allow you to declare static methods or variables, but it does support an alternative model for singletons called objects.
If you declare something as an object, only one instance of it exists in the scope in which it was declared.
An object will be instantiated the first time it is accessed.
A Scala object can exist at the package scope, and it replaces Java’s static methods and variables.
The advantage of Scala’s object over Java’s static mechanism is that a Scala object is an instance of a class and can be passed as a parameter to methods.
You declare a singleton object with the object keyword instead of the class or trait keyword:
Let’s access our objects and show how the Dude and Dude2 objects can be passed into a method that takes a Yep as a parameter:
The previous example demonstrates that the meow method is invoked on the Dude object and the Dude2 object.
The objects were passed as a parameter into the twoMeows method just like any other instance.
You can embed an object in a class, trait, or object.
One instance of the object is created for each instance of the enclosing scope.
Thus, each HasYep instance will have a single myYep that will be created when it is accessed:
Classes, objects, and traits can have inner classes, objects, and traits, which have special access to private methods, variables, and so on:
I need to take a brief digression back to the import statement.
For example, we can import something inside a class body:
Scala’s import statement can also import the methods of an object so that those methods can be used without explicit reference to the object that owns them.
Combining local scope import and importing objects allows you to fine-tune where the objects and their associated methods are imported.
In Scala, everything (except a method) is an instance of a class.
This means that Java primitives such as int are treated as instances by the Scala compiler.
This is done at the compilation level, but the bytecode is optimized so that adding two Ints in Scala results in the same bytecode and performance as adding two ints in Java.
On the other hand, in Scala, Int has methods including hashCode and toString.
The Scala compiler will put primitive types in a box when they are being passed to something that expects an Any, such as putting an Int in a HashMap.
In keeping with the naming convention that all classes have uppercase letters at the beginning of their name, Scala representations of JVM primitives are called Int, Long, Double, Float, Boolean, Char, Short, and Byte.
Scala also has an object representation of Java’s void called Unit, which is also a subclass of AnyVal.
You can explicitly return Unit from a method with the () singleton (yep, you read that right, an open and a close parenthesis)
This makes the None singleton that we encountered in our sum.scala program possible.
None is an Option[Nothing], which means its get method returns a Nothing.
Any is the root of the Scala class hierarchy, like Object is the root of the Java class hierarchy.
But, because of Nothing, primitives, and so on, Scala needed a root class that is underneath Object.
AnyVal is the root of Scala’s objectification of the JVM’s primitives.
AnyRef means the same thing as Java’s Object but has a few extra compiler-managed.
If you want to do a reference comparison in Scala, use the eq method.
Scala method declarations have the def keyword, the method name, parameters, optional return type, the = keyword, and the method body.
Type inferencing is powerful and useful, but please use it carefully.
Any time that it’s not immediately obvious what the return type is, declare it explicitly.
The parameter name must be followed by the parameter’s type:
You can pass the type of a parameter or the return type as a parameter.
The following code takes a parameter p and a type parameter T and returns a List of T.
Thus, if you pass an Int, you’ll get a List[Int], and if you pass a String, you’ll get a List[String]
For the most part, the type inferencer will calculate the type parameters so you don’t have to explicitly pass them.
And the last parameter in the list may be repeated—a variable-length argument.
If the last parameter is a variable-length argument, it is a Seq of the type of the variable-length argument, so in this case the as parameter is a Seq[Int]:
In this case, the types that are passed in must be Number or a subclass of Number:
Methods can be declared within any code scope, except at the top level, where classes, traits, and objects are declared.
In this example, the readAll method is defined inside the scope of the readLines method.
Thus, the readAll method has access to the variables br and ret because these variables are within the scope of the readLines method.
The readAll method calls a method on br, and it updates ret, even though these variables are not explicitly passed to readAll.
As we go through more examples in subsequent chapters, we’ll see how being able to use methods within methods and being able to access to all the variables in scope comes in very handy.
Note that we’ll see the case construct in the “Basic Pattern Matching” section later in the chapter.
Methods that override declared methods must include the override modifier.
Methods that override abstract methods may include the override modifier.
Methods that take no parameters and variables can be accessed the same way, and a val can override a def in a superclass.
This principle of uniform access turns out to be very useful.
Variables are declared like methods but start with the val, var, or lazy val keyword.
You would use a lazy val if the variable may not be used and the cost of calculating it is very long.
As a matter of style, I write my code with val variables unless there is a compelling reason to use a var.
Given that mutability leads to unexpected defects, minimizing mutability in code minimizes mutability-related defects.
In general, I don’t declare variable types unless it’s not obvious what the variable type is.
If a code block or method returns a Tuple, the Tuple can be assigned to a val variable.
This comes in handy when defining val variables, and the logic required to compute the value is non-trivial.
In Java, all method invocations are call-by-reference or call-by-value (for primitive types)
What this means is that the parameter’s value, or reference in the case of an AnyRef, is placed on the stack and passed to the callee.
Scala gives you an additional mechanism for passing parameters to methods (and functions): call-by-name, which passes a code block to the callee.
Each time the callee accesses the parameter, the code block is executed and the value is calculated.
Call-by-name allows you to pass parameters that might take a long.
For example, in a call to the logger you can use callby-name, and the express to print is only calculated if it’s going to be logged.
Call-by-name also allows you to create flow of control structures such as while, doWhile, and so on.
We declare a nano method, which prints a message and returns the current time with nano-second resolution:
Next we declare the delayed method, which takes a call-by-name parameter by putting the => symbol between the variable name and the type.
Let’s see what happens when we call delayed with nano as a parameter:
This indicates that delayed is entered before the call to nano and that nano is called twice.
This is the way Java programmers expect code to work.
Scala provides a number of syntactic variations for invoking methods.
But if a method does not take any parameters, the ending parentheses are optional:
This allows methods without parameters methods to appear as properties or fields on the target instance.
Methods that take a single parameter can be invoked just as in Java:
But methods that take a single parameter can be invoked without dots or parentheses:
Because Scala allows method names to contain symbols such as +, -, *, and ?, Scala’s dotless method notation creates a syntactically neutral way of invoking methods that are hard-coded operators in Java.
Finally, you invoke multiparameter methods in Scala just as in Java:
If a Scala method takes a type parameter, typically, the type parameter will be inferred by the compiler, but you can also explicitly pass the type parameter:
Scala is a functional language, which means that you can pass functions to methods and return them from methods and functions.
A function is a block of code that takes parameters and returns a value.
Given that Scala is constrained by the Java Virtual Machine, it cannot pass a pointer to an arbitrary block of code, so Scala implements functions as anonymous inner classes that have a particular interface.
When you pass a function, you’re just passing an object with a certain trait (interface)
The trait that defines functions that take one parameter and return a value is.
All functions have an apply method, which is the method that applies, or invokes, the.
Thus, you can define a method that takes a function and invokes the function with the parameter 42:
If an object has an apply method, you can invoke that method without explicitly calling apply by putting the parameter list just after the object:
This makes your code look good, and it makes it look like a function is being passed and invoked.
The Scala compiler has lots more syntactic sugar related to functions and other common constructs.
Scala has a shorthand for describing functions, so the following two descriptions are the same:
The latter conveys a lot more directly that the parameter is a function that takes an Int and returns a String:
The syntactic sugar for the apply method works on any class that has an apply method:
If a class has an update method, Scala also adds sugar to the update method.
An update method that takes two parameters will be called when the compiler parses an assignment:
Scala’s Array and HashMap classes use update for setting values.
This mechanism provides a way for your classes to have the same features as Scala library classes.
The update mechanism works with different parameter counts from one on up:
And it helps deliver on the interoperability promise with Java: knowing what the sugar translates to can help in developing Java code that plays nicely with Scala and in adapting Java libraries that may lack source code.
Scala has a mechanism for creating classes that have the common stuff filled in.
Most of the time, when I define a class, I have to write the toString, hashCode, and equals methods.5
Scala provides the case class mechanism for filling in these blanks as well as support for pattern matching.
A case class provides the same facilities as a normal class, but the compiler generates toString, hashCode, and equals methods (which you can override)
Case classes can be instantiated without the use of the new statement.
By default, all the parameters in the case class’s constructor become properties on the case class.
You can create an instance of Stuff without a new (you can use new if you want):
If you want to write your own class that does the same thing as a case class, it would look like the following:
Case classes also come in handy for pattern matching, a topic we’ll explore in the next subsection.
Scala’s pattern matching allows you to construct very complex tests in very little code.
Pattern matching is like Java’s switch statement, but you can test against almost anything, and you can even assign pieces of the matched value to variables.
Like everything in Scala, pattern matching is an expression, so it results in a value that may be assigned or returned.
The most basic pattern matching is like Java’s switch, except there is no break in each case.
This example matches the number against a constant, but with a default:
In this case, we are matching against a Stuff instance with name == David and age == 45 in a declarative form:
And we can extract the age field into the howOld variable:
We can place a guard between the pattern and the => that adds further testing that cannot be described declaratively.
In this case, we’ll extract the age, and if it’s less than 30, the result will be “young David”, otherwise the result will be “old David”:
Pattern matching can also test whether the input is an instance of a given class and do the casting if it is:
It may seem strange that we’re covering simple flow of control statements late in this section.
It turns out that while is used very rarely in Scala code.
The result of if and while expressions is always Unit.
The result of if/else is based on the type of each part of the expression.
Like Java, an if expression may have a multiline code block:
In practice, using recursion, a method calling itself, provides more readable code and enforces the concept of transforming input to output rather than changing, mutating, variables.
Recursive methods can be as efficient as a while loop.6
At first blush, Scala’s for comprehension looks a lot like Java’s for loop.
The basic form implements flow of control, executing the body one time for each value:
You don’t have multiple for comprehensions nested in order to have nested expressions, thus there’s an entire iteration of the inner variable, j, for each value of the outer variable, i.
And the guards can be part of the expression nesting:
I primarily use the for comprehension to transform a collection or set of collections into a new collection.
If the yield keyword introduces the for comprehension’s body, the for comprehension returns a collection rather than simply calling the code block.
And the nesting rules and guards work the same way:
We’ve explored a little bit of the syntax of the for comprehension.
In Chapter 3, we’ll see how it can be used with a variety of collections to provide powerful, syntactically pleasing, concise data transformations.
This makes it possible to wrap a call in a try/catch and assign a default value if the call fails.
Second, the exception is pattern matched in the catch block rather than having separate.
Here’s an example of calling Integer.parseInt and defaulting to 0 if an exception is thrown:
To synchronize based on an instance, call the instance’s synchronized method with a code block:
A single-line comment is started with // and continues to the end of the line:
In this section, we’ll compare and contrast these popular languages.
Everything in each language is an instance of a class.
In Java, there are primitives and statics that are outside of the OO model.
In Scala and Ruby, all operations on entities are via method calls.
In Java, operators are treated differently and are not method calls.
You can define a method that takes a function that transforms an Int to an Int:
At the language level, it’s very convenient and easy on the brain and the design to have everything be uniform.
The Scala compiler optimizes operations on JVM primitives such that the performance of Scala code is nearly identical to the performance of Java code.
An interface is a contract that specifies the methods an implementing class must have.
Parameters to a method call may be specifically defined as classes or interfaces.
Interfaces provide a powerful mechanism for defining the contract that a given class must implement, requiring that a parameter to a method implement particular methods without specifying.
This is the basis for dependency injection, using mocks in testing, and other abstraction patterns.
Traits are a great way of implementing methods once and mixing those methods into all the classes that extend the trait.
Ruby has mixins, which are collections of methods that can be mixed into any class.
Because Ruby does not have static typing and there is no way to declare the types of method parameters, there’s no reason way to use mixins to define a contract like interfaces.
Ruby mixins provide a mechanism for composing code into classes but not a mechanism for defining or enforcing parameter types.
In Java, a class can have static methods and data.
In this way, there is a single point of access to the method, and there’s no need to instantiate a class in order to access static methods.
Static variables provide global access to the data across the JVM.
Scala provides a similar mechanism in the form of objects.
In this way, it’s possible to have globally shared state.
However, objects adhere to Scala’s uniform OO model, and objects are instances of classes rather than some class-level constant.
Ruby has a singleton mixin that provides the singleton pattern in Ruby programs.
There is one instance of a class object per class in Ruby.
You can add methods and properties to class objects, and those become globally available without instantiating an instance of the class.
The Java construct to pass units of computation as parameters to methods is anonymous inner classes.
The use of anonymous inner classes was popularized with the Swing UI libraries.
In Swing, most UI events are handled by interfaces that have one or two methods on them.
The programmer passes the handlers by instantiating an anonymous inner class that has access to the private data of the enclosing class.
Scala functions implement a uniform API with the apply method being the thing that’s invoked.
The syntax for creating functions in Scala is much more economical than the three or four lines of boilerplate for creating anonymous inner classes in Java.
Additionally, the rules for accessing variables in the local scope are more flexible in Scala.
In Java, an anonymous inner class can only access final variables.
Ruby has a collection of overlapping features that allow passing blocks, Procs, and lambdas as parameters to methods.
These constructs have subtle differences in Ruby, but at their core, they are chunks of code that reference variables in the scope that they were created.
Ruby also parses blocks such that block of code that are passed as parameters in method calls are syntactically identical to code blocks in while and if statements.
Scala has much in common with Ruby in terms of an object model and function passing.
Scala has much in common with Java in terms of uniform access to the same code libraries and static typing.
It’s my opinion that Scala has taken the best of both Java and Ruby and blended these things together in a very cohesive whole.
Summary We’ve covered a lot of ground in this chapter.
We looked at how to build and run Scala programs.
We walked through a bunch of Scala programs that demonstrated various.
We did an overview of Scala’s syntax and basic constructs.
In the next chapter, we’re going to explore a bunch of Scala’s data types that allow you to write powerful programs in very few lines of code with very few bugs.
In this chapter, we’re going to explore Scala’s collections classes and how to use them.
Most Scala collection classes are immutable, meaning that once they are instantiated, the instances cannot be changed.
The conjunction of collections being immutable and providing powerful iteration features leads to more concise, higher-performance code that does extremely well in multicore, multithreaded concurrency situations.
Thinking Immutably In Java, the most commonly used types are immutable.
In Java, String, int, long, double, and boolean are all immutable data types.
You don’t have to synchronize access to a String, even if it is shared by many threads, because there’s no chance that it will be modified while another thread is accessing it.
You don’t have to keep a private copy of a String in case another method modifies it out from under you.
When you pass String and other immutable types around in a Java program, you don’t have to be defensive about using the instance.
You can store it without fear that another method or thread will toLowerCase it.
Using immutable data structures means less defensive programming, fewer defects, and, in most cases, better performance.
So, you ask, why doesn’t Java have a lot more immutable data structures?
There are two ends of the programming spectrum: the how end and the what end.
Assembly language is at the far end of the how part of the spectrum.
When you program in assembly language, you direct the CPU to move bytes around memory, perform arithmetic operations and tests, and change the program counter.
Spreadsheets are far at the what end of the spectrum.
Spreadsheets contain formulas that define the relationship between cells (so we tell the computer what we want to do)
The order of evaluating the cells, the cells that are calculated based on changes in other cells, and so on, are not specified by the user but are inferred by the spreadsheet engine based on the relationships among the cells (the computer does the how part for us)
In a C program, one always thinks about changing memory.
In a spreadsheet (which is a program; Excel is the most popular programming language in the world), one thinks about altering input (changing nonformula cells) and seeing the output (what is recalculated)
Java evolved from imperative roots and spouted mostly mutable data structures in its standard libraries.
The number of mutable classes in java.util.* far outnumber the immutable classes.
By default, variables in Java are mutable, and you have to explicitly declare them as final if you want them to be assign-once.
Despite that I’ve written a couple of commercial spreadsheets,1 and should have understood the benefits of the functional “what” approach, until I spent a lot of time with Scala, I did not think about immutable data structures.
So, why doesn’t Java have more immutable data structures? Because it’s not obvious that Java needs them until you code with them for a while, and very few Java developers I know spent a lot of time with Lisp, ML, or Haskell.
With a good garbage collector like the one in the JVM, immutable data structures tend to perform better than mutable data structures.
For example, Scala’s List, which is an immutable linked list, tends to perform better than Java’s ArrayList using real-world data.
ArrayList pre-allocates an internal array of 10 slots to put items in.
If you store only two or three items in the ArrayList, seven or eight slots are wasted.
If you exceed the default 10 slots, there’s an O(n) copy operation to move the references from the old array to the new array.
Contrast this with Scala’s List, which is a linked list.
The only memory consumed for storing items is the number of items being stored.
If you have hundreds of items or if you’re going to do random access on the collection, an Array is a better way to store data.
But, most real-world applications are moving two to five items around in a collection and accessing them in order.
Immutable data structures are part of the formula for more stable applications.
As you start thinking about immutable data structures, you also start reducing the amount of state that is floating around in your application.
There will be fewer things that can be changed or mutated.
Your methods will rely less and less on setting global state or changing the state of parameters, and your methods will become more and more transformative.
OS/2 and the Integer multiuser spreadsheet engine for the JVM.
These methods are much easier to test using automated test tools such as ScalaCheck.
One common failure mode for mutable state programs is that a new team member changes program state in an unpredictable way.
There may be some setters that create state for an object.
It’s implied (and probably quite logically) that once the object is handed off to the “do work” method and goes beyond a certain barrier, its setters are not to be called.
But along comes a developer who doesn’t know about the implied barrier and uses a setter that causes some program logic to fail.
At this point, you may be resisting and saying, “Ten million Java, C++, C, and C# developers can’t be wrong.” I thought that way when I first started coding in Scala.
But I set some goals for myself to learn and understand immutability.
Over time, I came to appreciate that many of the defects that I was used to dealing with in Javaland and Rubyland went away as I used more and more immutable data structures and worked to isolate the state in my application from the logic of my application.
Those containers can be sequenced, linear sets of items (e.g., List):
They may be indexed items where the index is a zero-based Int (e.g., Array) or any other type (e.g., Map)
The collections may have an arbitrary number of elements or be bounded to zero or one element (e.g., Option)
Lazy collections have elements that may not consume memory until they are accessed (e.g., Range)
The nifty thing about Ranges is that the actual elements in the Range are not instantiated until they are accessed.
So we can create a Range for all positive Integers but take only the first five elements.
This code runs without consuming many gigabytes of RAM because only the elements that are needed are created.
Collections may be mutable (the contents of the reference can change) or immutable (the thing that a reference refers to is never changed)
In this chapter, we’ll be focusing on List, Option, and Map.
These immutable data structures form the backbone of most of the programs I write.
That means it’s a sequential list of any type, including Java’s primitives (Int, Float, Double, Boolean, Char) because Scala takes care of boxing (turning primitives into objects) for you.
Internally, List is made up of a “cons” cell (the scala.:: class [yes, that’s two colons]) with a tail that refers to another cons cell or the Nil object.
The previous code creates three cons cells, each with an Int in it.
Anything that looks like an operator with a : (colon) as the first character is evaluated right to left.
Thus, the previous code is evaluated just like the following:
The expression on the left of the :: is the head, and the expression on the right is the tail.
To create a List using ::, we must always put a List on the right side.
That means that the right-most element has to be a List, and in this case, we’re using an empty List, Nil.
We can also create a List using the List object’s apply method (which is defined as def apply[T](param: T*): List[T], which translates to “the apply method of type T takes zero or more parameters of type T and returns a List of type T”):
The type inferencer is pretty good at figuring out the type of the List, but sometimes you need to help it along:
If you want to prepend an item to the head of the List, you can use ::, which actually creates a new cons cell with the old list as the tail:
Note that the list referred to by the variable x is unchanged, but a new List is created with a new head and the old tail.
You can also merge two lists to form a new List.
This operation is O(n) where n is the number of elements in the first List:
The power of List and other collections in Scala come when you mix functions with the collection operators.
Let’s say we want to find all the odd numbers in a List.
The filter method iterates over the collection and applies the function, in this case, an anonymous function, to each of the elements.
If the function returns true, the element is included in the resulting collection.
If the function returns false, the element is not included in the resulting collection.
The resulting collection is the same type of collection that filter was invoked on.
If you invoke filter on a List[Int], you get a List[Int]
If you invoke filter on an Array[String], you get an Array[String] back.
There’s a corresponding remove method, which removes elements that match the test function:
We can also write a method called isOdd and pass the isOdd method as a parameter (Scala will promote the method to a function):
In this case, we’re converting a String to a List[Char] using the toList method and filtering the numbers.
The Scala compiler promotes the isDigit static method on Character to a function, thus demonstrating interoperability with Java and that Scala methods are not magic.
Another useful method for picking the right elements out of a List is takeWhile, which returns all the elements until it encounters an element that causes the function to return false.
For example, let’s get all the characters up to the first space in a String:
I grew up writing machine code and later assembly language.
When I wrote this code, I was telling the machine exactly what to do: load this register with this value, test the value, branch if some condition was met, and so on.
I directed the steps that the CPU took in order to perform my task.
In Excel, we describe how to solve some problem using the formula functions and cell addresses, and it’s up to Excel to determine what cells need to be recalculated and the order for the recalculation.
Imperative coding describes, as we saw earlier, the “how.” Writing functions describing the “what”—the goal to be achieved—and allowing the computer to figure out the “how” is termed functional programming.
Scala allows you to express code in a way that’s further toward the functional end of the coding spectrum.
Let’s do a little exploring of the differences between the two.
Let’s compare filter in Scala to the Java implementation shown in Listing 3-1
In this code, the logic gets lost in the boilerplate.
When you first write the previous code, you know what the intent is.
If you didn’t comment your code with // filtering the odd array elements, you, or someone who picks up the code in a year or two, will have to puzzle about the meaning of the loop.
The filter logic is buried in the middle of the code.
As the complexity of your code increases and the time between writing and maintaining a particular module increases, removing boilerplate while maintaining visible business logic makes code easier to maintain and decreases defects.
Let’s look at the takeWhile Java translation in Listing 3-2
Once again, one line in Scala expresses what takes many lines in Java.
This example also demonstrates the mental shift that is common in imperative code.
In one line in the loop, we mutate or change the res variable.
In the next line, in the else, we have the break flow of control statement.
Your brain has to think about two distinct concepts: “what variable is being mutated” and “what’s the next statement the program is going to execute” all rolled into two lines.
When I was programming in Java, I never gave constructs like this a second thought.
After programming in Ruby and Scala, I find that thinking about “what’s happening to my data” and “what’s the flow of control in my program” at the same time is very challenging.
My brain has morphed into thinking about “what is business logic for transforming input to output?” I find this focuses me on the business logic task at hand.
As we continue to explore transformations, let’s look at other ways to transform a List.
The map method on List (and Seq), transforms each element of a collection based on a function.
For example, if we have a List[String] and want to convert it to all lowercase:
The number of elements in the returned collection is the same as the number of elements in the original collection, but the types may be different.
If the function passed into map returns a different type, then the resulting collection is a collection of the type returned from the function.
For example, we can take a List[String] and calculate the length of each String, which will result in a List[Int]:
We can transform our Strings to lowercase, to a List of their length, and we can.
For example, if we have a database query that returns records of type Person defined as having a first method that returns a String containing the person’s first name, we can create a List of the first names of the people in the List:
Or, if we’re writing a web app, we can create an <li> (an HTML list element) containing the first name of each Person in our List:
List also has a sort method, which takes a function that compares the two parameters.
Now we can write the code shown in Listing 3-3 to find all the valid Person records, sort by age, and return the first names.
While sometimes you may do complex logic like this in the database, other times you may have a collection of records in memory and you need to perform different transformations on those records.
While we can still discern the intent of the Java code, it requires mentally filtering out the boilerplate loops and looking inside them.
You have to look past the how in order to understand the what.
On the other hand, even the Scala beginner should be able to read the lines in the Scala code to understand the meaning.
We even see a hint of functional programming in the Java code with the construction of Comparator, which consumes four lines of code rather than Scala’s one line of code.
Interestingly, under the covers, Scala is creating anonymous inner classes for each of the functions and passing them to filter, map, and sort.
Just as it makes sense in Java not to have lots of sorting routines floating around code, so there’s a set of sort methods (and other helper methods) on Arrays, Scala puts the looping constructs into map, filter, and so on as well so that your code contains more logic and less boilerplate.
For example, if we want to find the biggest number in a List[Int]:
Because Scala’s if expression works like Java’s ternary operator, the if in the previous code returns a if it’s longer than b.
This is correct behavior as there is no way to apply the function on the members of the List as a Nil List has no elements.
The return type of the function and the return type of foldLeft must be the same type as the seed.
We can generate the product of the List the same way:
But because the return type of foldLeft is the type of the seed, not the type of the List, we can figure out the total length of a List[String]:
I find that sometimes I need to work with more than one collection at a time.
We have nested map invocations, and that results in a List[List[Int]]
In other cases, we want the results in a single List[Int]
In order to nest the map operations but flatten the results of nested operations, we use the flatMap method:
So far, we’ve written a bunch of code that manipulates collections without explicit looping.
By passing functions, that is, logic, to methods that control the looping, we let the library writers define the looping, and we define the logic in our app.
However, syntactically, nested map, flatMap, and filter can get ugly.
Scala provides the for comprehension, which provides syntactically pleasing nesting of map, flatMap, and filter.
We can convert the nested statements from the previous example into a syntactically pleasing statement:
The for comprehension is not a looping construct but is a syntactic construct that the compiler reduces to map, flatMap, and filter.
The for comprehension can be used with any class, including user-generated classes, that implement map, flatMap, filter, and foreach.
This means you can create your own classes that work with the for comprehension.
Lists also work well with Scala’s pattern matching and recursive programming.
For this example, pattern matching is a lot like Java’s switch statement, but it can be used to compare things that are more complex than Ints, and Scala’s pattern matching allows you to match some elements and extract, or capture, others into variables.
The pattern-matching syntax is the same as List construction syntax.
Our example will convert a List[Char] of Roman numerals to their Arabic numeral equivalent.
The code matches the List to a series of patterns.
You can see exactly how Scala turns patterns into code by typing scalac -print FileName.scala.
This will cause the Scala compiler to emit desugared code that looks strangely like Java code.
Without explicit looping or length testing or explicit branching logic, we’ve written a concise, readable method.
Scala’s List and other sequential collections provide powerful ways to define business logic in a concise, maintainable way.
In the next section, we’re going to explore Tuples, which are fixed-length collections where each element can be a different type.
Have you ever written a method that returns two or three values? Let’s write a method that takes a List[Double] and returns the count, the sum, and the sum of squares returned in a three-element Tuple, a Tuple3[Int, Double, Double]:
The sumSq method takes a List[Double] as input and returns a Tuple3[Int, Double, Double]
The compiler will treat a collection of elements in parenthesis as a Tuple.
Using Scala’s pattern matching, we can make the code a little more readable:
Pairs appear in code very frequently, including name/value pairs for creating Maps.
Keys are unique in the Map, but values need not be unique.
This means that you can pass an instance of Map to another thread, and that thread can access the Map without synchronizing.
The performance of Scala’s immutable Map is indistinguishable from the performance of Java’s HashMap.
We create a new Map by passing a set of Pair[Int, String] to the Map object’s apply method.
Note that we created a var p rather than a val p.
This is because the Map is immutable, so when we alter the contents on the Map, we have to assign the new Map back to p.
In order to update p, we have to assign the new Map back to p:
What happens when we ask for an element that doesn’t exist?
If you try to get an element that’s not in the Map, you get an exception.
So far, we haven’t seen much in Scala that results in exceptions being thrown, but it makes logical sense.
Java’s Map classes handle this situation by returning null, which has two drawbacks.
First, you have to null-test the result of every Map access.
Second, it means you can’t store a null in a Map.
Scala has a kinder and gentler mechanism for dealing with this situation.
The get() method on Map returns an Option (Some or None) that contains the result:
You can return a default value if the key is not found:
Wait, you say, p.get isn’t a function, it’s a method, but you didn’t include the parameter.
Scala is very cool, because if it’s expecting a function with parameters of a particular type and you pass a method that takes those parameters, Scala will promote the method with its missing parameters to a function.
We can test the Map to see whether it contains a particular key:
We get a collection of keys from our Map and use reduceLeft to find the largest key:
And we can use reduceLeft on the collection of values to find the largest String:
We can test whether any of the values contains the letter “z”:
You can also add a bunch of elements to a Map using the ++ method:
And you can remove a bunch of keys with the -- method:
This means we can use methods including map, filter, and foldLeft.
One of the tricky parts of using Java’s immutable collections is iterating over the collection and simultaneously removing elements.
In my code, I have to create an accumulator for the keys I’m going to remove, loop over the collection, find all the keys to remove, and then iterate over the collection of keys to remove and remove them from the collection.
Not only that, but I frequently forget how brittle Hashtable is and inevitably forget this sequence and get some nasty runtime errors.
But there’s a simpler way to remove unwanted elements from a Map:
Pretty cool, huh? Map has a filter method that works just like List’s filter method.
The kv variable is a Pair representing the key/value pair.
The filter method tests each key/ value pair by calling the function and constructs a new Map that contains only the elements that passed the filter test.
Let’s finish up our exploration of some of Scala’s immutable data types by examining Option.
Option[T] provides a container for zero or one element of a given type.
There is a single instance of None in your Scala program, so it’s kind of like null.
But None has methods on it, so you can invoke map, flatMap, filter, foreach, and so on no matter whether you have Some or None.
Let’s say we have a method that retrieves a record from the database based on a primary key:
The method will return Some[Person] if the record is found but None if the record is not found.
We can then build a method that returns the age from the primary key:
If the record is found in the database, ageFromKey will return Some[Int], otherwise it will return None.
For example, let’s say we have a Map that contains parameters passed as part of a web request and a couple of helper methods.
We define a method that wraps an operation in a try/catch block.
If the operation succeeds, we wrap the result in a Some instance, otherwise return None.
We define methods that convert String to Int or Boolean.
If the String can be converted, Some will be returned, otherwise None will be returned.
With these helpers, we can define our method that converts from the parameters to a Person instance.
In my code, any method that can logically fail (e.g., looking something up in a Map, converting a String to an Int) returns an Option.
It is up to the calling code to determine what to do.
Let’s compare this to the Java implementation shown in Listing 3-7
This increases the number of lines of code and reduces the readibility.
This makes it more difficult to understand under what conditions the code will continue to flow.
At a glance, it’s difficult to determine the conditions under which the method will return non-null.
For example, if the parameter name that maps to “age” used to be called “years”, we can express the code as ageStr <- p.get("age") orElse p.get("years")
You can chain orElse just like chaining || in the if conditional.
The right side of the orElse expression will be evaluated only if the left side is None.
You can retrieve the contents of an Option with the get method:
But be careful, because if the Option is None, an exception will be raised:
Like Map, Option has a getOrElse method that returns a default value if the contents are undefined:
Option is a very useful class for passing or returning values that may or may not be defined.
Because Option has map, flatMap, filter, and foreach methods, it can be used in for comprehensions.
Option provides a great way to avoid null problems and has methods that work conveniently with other Scala collections.
We’ve seen some of Scala’s foundation collection classes and the methods that allow for simple and powerful manipulation of these collections.
These classes form the basis for much of my development.
For web development, XML is a very important mechanism for data exchange.
Scala’s immutable collections form the basis for Scala’s XML support.
This means you can cache XML without worrying about copying it so it’s not modified out from under you.
In this section, we’ll explore creating XML, parsing XML, and mutating XML.
I’m covering XML in this chapter because it’s an immutable data structure and because Scala treats XML as a collection on Nodes, so it gives us a chance to explore some more of the cool collections stuff we’ve been working on.
Scala has XML literals built into the language syntax, just like Java has String literals built in.
Scala represents XML as a Seq[Node], and Node is a superclass of NodeSeq, which is a subclass of Seq[Node]
That means all the collections methods that we’ve been exploring are available on XML collections including map, flatMap, filter, and foreach.
This also means that XML can be used in for comprehensions.
We can define a len method that takes a Seq of any type and returns the length:
Or we can call it with the XML variable x we defined previously:
The ability to dynamically create XML in Scala is far more powerful than the ability to dynamically create Strings.
Scala code can be embedded in any attribute or element body to dynamically render XML.
For example, let’s define a method that returns the current milliseconds as a String:
We can call the now method from the attribute definition to add a time attribute:
Attributes can be defined with Scala expressions of type String, NodeSeq, and Option[NodeSeq]
If the Option is None, the attribute will not be included in the resulting XML, but if the Option is Some, then the attribute will be included.
Let’s define a method that tests Long for being odd:
We define the oddTime method, which will return Some[NodeSeq] if the time is odd and return None if it’s even:
And we can see that the time attribute is only included when the time is odd:
You can also generate tags, text, cdata, and so on from Scala code:
If your embedded Scala code returns a NodeSeq, the NodeSeq will be embedded directly.
If your Scala expression returns anything else, that thing will be converted to a scala.xml.Text node by calling toString on the thing.
Using map, we can convert from a given type to XML that’s embedded:
One thing to be careful about is making sure your if expressions have an else.
The type of an if expression without an else is Unit, which converts to an empty String:
So you don’t have to worry about escaping XML characters.
This is generally the right thing, but if you’re trying to embed a script in your XML, it might not be the right thing:
You can use PCData to embed unescaped characters in your XML:
Because the XML data structures are immutable, they can be shared and cached without concern that another thread or method may change the XML.
As a side note, when I do browser-side HTML manipulation, I always have to be concerned about inserting some nodes into other nodes because the insertion causes parent node references to be changed.
This means that if I had inserted the nodes elsewhere, they’ll be unceremoniously removed from the old place to be inserted into the new place.
This means I have to copy the entire node structure each time I do an insert, which is an O(n) operation.
With Scala’s immutable XML data structures, I only have to change from the insertion point to the root node, an O(log n) operation.
Now that we’ve seen how to create XML in Scala, let’s see how to parse and manipulate XML.
Creating XML in Scala is done at the language level.
The compiler needed to be changed to support XML literals.
Parsing XML in Scala is all done at the library level.
Let’s explore XML parsing in combination with Scala’s collection support.
Next, let’s find all the <a> tags in the document:
The \\ (double backslash) operator finds all the tags with the given label in the document.
The \ (single backslash) operator finds all the tags with the given label that are direct children of the current tag.
Also, if the first character of the query String is an @, the query is performed against the attributes in the tag.
Let’s find all the <a> tags that refer to external resources:
Perhaps the code is easier to read in a for comprehension:
In combination with Scala’s collection methods, we can do more fun stuff with XML.
We can traverse the XML and sum the contents of particular tags.
Scala’s XML parsing library provides a simple yet powerful way to traverse XML.
Combined with XML’s collection methods, it’s very easy and concise to convert XML data to object representations.
Transforming flat data structures such as List or Map is pretty easy: you just take each element from the collection and return a transformed value.
A transformation may return many nodes for each transformed node.
In order to deal with these complexities, Scala provides a set of classes to help with XML transformation.
That means only the nodes that are changed and the direct path from the changed nodes to the root node are changed.
This is far more efficient than the O(n) cost of copying an entire XML data structure if modifying the structure will cause unexpected results.
In order to transform XML, we need to create a rewrite rule.
In this case, if the XML element contains the attribute instruction with the value remove, the node will be removed from the transformed XML.
Next, let’s define a rule that removes the elements that have the remove instruction:
The RewriteRule overrides the transform method and pattern matches against an element that contains the remove instruction.
If the pattern is matched, an empty node is returned.
The rule transformer applied our removeIt rule to the input and transformed this to the output.
The method creates a new element with the same attributes, but removes the instruction attribute.
It also transforms the child nodes and appends a child node.
We can run the transformation with both of the RewriteRules:
In this section, we’ve explored creating, parsing, and rewriting XML.
Scala’s awesome XML support makes it super-simple to write complex web-based applications.
You can create Atom or RSS feeds in just a few lines that transform database records into the appropriate XML.
You can parse incoming XML using the same constructs you use for other data sequences, which makes transformation from XML into data structures and objects easy and fast.
In this chapter, we’ve explored Scala’s immutable data types and the power and simplicity that they afford you.
Next, let’s see how we can use the immutable data structures in a highly concurrent situation.
While simple data structures such as multithreaded queues or mailboxes are easy to write and relatively low in defects, most Java programs don’t lend themselves to such simple abstractions.
This is due in large part to passing around mutable data structures.
Any data structure that can be changed without creating a new reference is a potential defect in a multithreaded application.
The problem is exacerbated by the transitory nature of thread-related defects: it’s hard to test for them.
One can synchronize everything, but this often leads to deadlocks because two threads are locking resources that depend on each other.
Another strategy is to copy everything that’s passed to a thread.
This strategy uses memory and CPU to work around the threading issue.
Every time a resource is needed by a thread, the resource is copied for the thread’s use.
This means each Array, Hashtable, and so on that’s requested by a given thread is copied.
Create a file called Multics.scala and put the code from Listing 3-8 in it.
We’ll go through the code line by line after the listing.
Let’s go through the Multics code and see how it works.
Then we define a type, MT, that’s a Map[String, Int]
We use TreeHashMap as it has better characteristics for high write concurrency than Scala’s default immutable Map.
This code creates a new thread and starts it running the repeatEvery code.
The body code prints the clashCnt and the sum of the values of all the info items.
We can access the Map contained by info without synchronization because the Map is immutable, and we know it’s not going to change out from under us.
The doSet method takes a function that creates a new Map from the old Map.
This increments the count in info associated with this thread.
If the thread’s local count doesn’t match what’s in info, there was a concurrency problem, so we throw an exception.
This creates a new thread setting the run method to the function, f, and starts the thread.
This is an example of passing a block of code as a parameter.
It reads the old value, passes it to the update function, and then tries to do an atomic set.
If the atomic set succeeds (the old value has not changed during the update), then the set was successful because the mutation was done on the most recent version of the data.
If compareAndSet fails, it increments the clashCnt and tries again.
Both are call-by-name, which means that each time they’re referenced in the body of repeatEvery, the code from the call site will be executed.
This code repeats until an exception is thrown or the program terminates.
Because len is call-by-name, the code that defines len will be executed each loop.
If an exception is thrown, it will be caught and reported, and the program will terminate.
To run the code, save the file, type scalac Multics.scala to compile and scala Multics to run the program.
Summary In this chapter, we explored using Scala’s immutable data structures to create powerful, flexible code that works well in multithreaded code.
We saw how the methods of Scala’s List class allow us to transform Lists and how the transformations highlight the business logic without the need for a lot of boilerplate.
Scala’s Tuples are syntactically pleasing and type-safe, and they make passing and returning things like name/value pairs super-simple and super-easy.
Immutable Maps provide the same advanced ability to transform as Lists but in a convenient name/value form.
The Option class is a great alternative to Java’s overuse of null, and you can make very syntactically pleasing constructs with the for comprehension.
We went on to see Scala’s XML support, which is built on top of the immutability and manipulation constructs for Lists.
More important, we covered many of the basic constructs that you need to build Scala programs.
We saw how functional, or transformation, code can be simultaneously more concise, more safe, and more performant than imperative code.
In the next chapter, we’re going to dive deep into passing functions as parameters.
We saw Scala functions in action in the last chapter.
Passing functions to map and filter allowed us to write code that was more readable and understandable.
The looping was done in the method, allowing our application code to be cleaner and easier to maintain.
In this chapter, we’ll explore functions in more depth and learn about how functions allow us to encapsulate business logic and separate it from the imperative flow of control statements.
We’ll write our own control structures, including looping and automatic JDBC connection closers that will lead to cleaner, better code.
You can do anything to a function that you would do to an instance.
We can create a function and assign it to a variable:
In this section, we’re going to explore the basics of creating and managing function objects.
Functions are passed to methods and other functions just as with any other parameter.
Let’s define the w42 method that takes as a parameter a function that takes an Int and returns a String.
We can call the w42 method with the function variable that we declared in the last section:
Let’s define a method, fm, that takes an Int and returns a String and see the various ways to pass this method as a function to the w42 method.
We can create a function to pass to w42 by declaring the parameter i and its type, Int, and call fm with i:
But the Scala type inferencer can figure out that we’re passing Int => String, so there’s no reason to declare i’s type:
We can further shorten things by passing fm and partially applying it.
Partial application happens when we supply some but not all of the parameters required for the method or function.
Or, we can just pass fm as if it were a variable, and the Scala compiler figures it out:
Despite the syntactic differences, the same function is being passed to w42 in each of the last four examples.
In fact, the desugared code looks just like passing an anonymous inner class to in Java:
You can pass functions that are multiline blocks of code.
In this case, we’re creating a range and then converting the range to a comma-separated String with Seq’s mkString method.
In Scala, everything except a method is an instance; therefore methods are not instances.
Methods are attached to instances and can be invoked on instances.
Functions are instances that implement a FunctionNN trait, where NN is the number of parameters the function takes.
However, at compile time, there is plenty of syntactic sugar that makes the number of characters required to create a function very, very small.
Scala traces its roots to functional languages including ML and Haskell.
In these languages, a function that takes two Ints and returns a String is the same as a function that takes an Int and returns a function that takes an Int and returns a String.
Haskell makes it easy to create a new function by applying the first parameter to a function that will return a new function that can then be passed around or applied.
This is called partial application because some of the parameters are passed to the function rather than all the parameters being applied to the function.
Scala requires a separate syntax to automatically generate partially applied functions.
In Scala, we can build partially applied functions out of methods:
In the previous code, we’ve turned a method that takes two Int parameters into a function that supplies the first parameter, in this case 42, but that needs a second Int parameter to fulfill the requirements for the application of plus.
In this case, p is a partial application of plus, and we can complete the application by supplying an Int to p.
It turns out that partial application of functions is a common thing.
It allows you to build up functions based on values in a given scope and allows for better code reuse.
And we call methods defined this way with the following syntax:
At this point, you may be thinking that this syntax is not particularly pleasing.
As they say in late-night TV ads, “But wait, there’s more!” With this syntax, you can pass code blocks as parameters separately from other parameters.
We’ll see more of this when we create control structures.
It also allows you to easily promote a method to a partially applied function very easily:
You can also create a function by partially applying a method and converting this into a function:
Type parameters define the type of other parameters or of the method’s return value.
The parameter and return types of a function must be defined when the function is created.
We saw some type parameters in Chapter 2 when we saw how the return type of the function passed to map alters the type of the returned List.
We can define a method, t42, which takes a type parameter, T, and a function that takes an Int and returns a T.
But, if we pass in a function that returns an Int, t42 returns an Int:
And we can pass in a function that returns a List[Int]:
In the previous examples, we did not have to explicitly define the type parameter because the type inferencer figured it out for us.
Functions are bound to the variables in the scope in which the function is created.
This can come in very handy as it allows you to carry state around with them.
For example, let’s create a variable, foo, and assign it a value:
Next, let’s create a function that takes a function that references the variable:
First, let’s define the var strs which is a List[String]:
Next, let’s create a function that takes a String and returns a String but has the side effect of modifying the strs variable by prepending s to the list:
The side effect of calling strF is to update strs.
Is this a local magical phenomenon or does it always work? Let’s see:
Functions are instances, which means that whatever you can do with an instance, you can do with a function.
Let’s create a function, bf, which takes an Int and returns a function:
We’ve got an Array[Int => Int], otherwise known as an array of functions that will convert an Int to an Int.
Let’s get the first element in the array and apply it to 1:
The first element of the array was the 1 applied to the bf function.
It’s theoretically cool that functions are instances that can be manipulated like any other instance.
There are practical uses of putting functions in Maps and Lists.
Functions represent blocks of code—instructions on how to do something that is within a particular.
The ability to bind functions to events, such as the user clicking a button on a screen, which may occur in the future, provides a powerful way to build interactive, event-based applications.
For example, if a button is clicked, perform a particular action.
Creating a callback in web applications is a particularly difficult task unless you’ve got powerful tools like the ones Scala gives you.
Let’s create a method that generates a random String that will serve as a globally unique identifier (GUID):
We need not flesh it out, but we can assume that it contains JavaScript commands that can be run in the browser:
Next, let’s create a Map to associate the GUID with a function that will generate some JavaScript:
Finally, we can create a method that registers the function and generates an HTML <button/>
When the button is clicked in the browser, an Ajax call will be made to the server, the function will be invoked, and the resulting JavaScript will be returned to the browser.
When the user clicks the button, an Ajax HTTP request is generated with the GUID.
The servlet looks up the GUID in the Map, and if the GUID is found, the function is invoked, and the resulting JavaScript is returned to the browser.
This code is a simplified version of what is done in the Lift Web Framework (http:// liftweb.net)
This code demonstrates a practical way that Scala and Lift abstract away the HTTP request/response cycle by associating a function with a client-side event.
The developer writing code using this style gets to spend more brain cycles on the business logic of what to do when the user clicks the button and far fewer cycles worrying about the plumbing of servicing an HTTP request.
So far, we’ve created simple functions and manipulated the function instances.
But for now, let’s see the difference between interpreting a series of commands and “compiling” a function that interprets them.
In our grammar, we have expressions, which can be constant values or named variables.
Expressions can also be addition or multiplication of other expressions.
Here’s a collection of case classes that describes our grammar (recall that we covered case classes in Chapter 2):
We use pattern matching to determine what to do based on the case class.
If expr is an Add, we extract the left and right parameters, which are themselves Exprs.
We call calc to calculate the value of the left and right parameters and add the results.
If expr is Val, we simply extract the value and return it.
If expr is Var, we extract the name and return the lookup of the name in the vars Map.
We can turn this from a method call into a function.
Having a function allows us to pass around the logic that the expression represents.
It also means that we don’t have to interpret the tree of Exprs each time.
Let’s see how we can compose a function based on the Expr.
The buildCalc method returns a function that can be passed to other functions.
Also, the JVM can optimize the composed functions so that they perform better than the interpreted version.
The performance of the composed function is better because there is no overhead associated with pattern matching each element.
The function is evaluated by repeatedly calling the function’s apply method.
Thus, the cost of each node is one or two method dispatches rather than the cost of the pattern matching.
Let’s turn to other ways that functions can help us improve performance and readability.
Call-by-Name, Call-by-Value, and General Laziness In Java programs, when you call a method with parameters, the value of the parameters.
However, there are some cases when we want to parameters to be optionally evaluated or repeatedly evaluated.
There’s no syntactic difference to the caller for call-by-name parameters.
It’s very computationally costly to calculate log messages simply to discard them if the message is not going to be logged.
In Scala, we can define a log method that takes the thing to log as call-by-name:
The Scala version passes "The value is "+value as a function that is evaluated each time it is accessed in the log method.
The log method will access it only if the log message is going to be printed.
Your code is cleaner because you don’t have to repeatedly test the log level, but it performs as well as the previous Java code that has the inline test.
In order to make something call-by-name, just put => before the type.
So, foo(s: String) is call-by-reference, and foo(s: => String) is call-by-name.
You may be wondering how the code could possibly perform as well if a function object is being created and handed off to the log method.
In the JVM, the cost of creating an object that never escapes the current thread and is very short-lived is zero or very near zero.
The JVM may also inline the log method such that the test is performed without an actual method call.
The result is that your code will run as quickly with the Scala code as it will with the Java code that has the repeated test for log level.
The first use of call-by-name is passing an expression that takes a long time to evaluate that may not be evaluated.
The second use for call-by-name is the situation where we want to evaluate the expression many times in the target method, for example, if we want to evaluate an expression until some condition is met.
That condition could be until the expression returns false or until the expression returns null.
For example, we could collect all the Strings returned from an expression until we encounter a null:
Each time the call-by-name parameter, expr, is accessed, it is applied.
If it is passed as a parameter that is also call-by-name, it will be passed without evaluation.
In the previous code, we pattern match against the application of expr.
If it’s null, we return an empty List, a Nil.
If it’s not null, we return a List that is the current String and the result of allStrings(expr)
In the next section, we’ll use it to build complex control structures.
Build Your Own Control Structures In this section, we’ll use call-by-name variables and functions to create our own control structures.
Scala has very limited control structures: try/catch/finally, if/else, and while.
Most languages have a plethora of control structures including for, foreach, and so on.
This provides a convenient mechanism to make sure that files, database connections, TCP/IP connections, and so on are closed without having to write a try/finally block for each thing you want to close.
Scala does not have a using statement, but we can write one.
I’ll show you all the code and then step through the pieces:
The B type parameter is much like what we’ve seen in the past: it can be any type.
A can be an instance of any class as long as that class has a close method on it.
Scala allows you to define types based on their structure rather than their class.
The param parameter is one of these A ducks that has a close method.
The f parameter is something that takes the A and transforms it to a B.
It wraps the function application in a try/finally block and makes sure that param is closed before the method returns.
The next control statement we’ll build is something that loops as long as a test is true.
In each iteration, the method will collect the output of a pass-by-name value and append it to the list accumulator.
First, let’s import ListBuffer so we can accumulate the results:
It takes test as a call-by-name parameter and block, the code block, as a call-by-name parameter.
As long as the test results is true, the result of block will be appended to the ret accumulator.
Finally, the accumulator is converted to a List and returned.
In this section we’ll apply the new control structures, using and bmap, to the real-world problem of performing a JDBC query, collecting the results, and closing the Statement and ResultSet.
First, we’ll write the code in Java and then see how it gets cleaner and more maintainable in Scala.
The class has a static method that queries the database for all of the person records.
In a single line, we define the class, its constructor, and its fields.
Next, let’s define a method, findPeople, that will take a JDBC connection and return a List[Person]
The code creates a Statement, executes a query on that Statement, and as long as there are more rows available on the ResultSet, a Person will be created.
The method will close the ResultSet and Statement, and it will return the List[Person]
With all the boilerplate of try/finally, and so on, the Java code is much longer and more difficult to read.
More important, if the developer forgets to write the try/finally block, the ResultSet or Statement may not be closed correctly, causing a hard-to-diagnose issue where the database runs out of resources.
While this is something that can be caught in a code review, it’s easier to have it built into the control structures.
In this example, we’ve used the generic control structures, using and bmap, to work with JDBC.
In any case, Scala gives you the tools to make your code more concise, more understandable, and easier to maintain.
Summary In this chapter, we explored creating and manipulating functions in Scala.
In Chapter 3, we saw how passing functions to Scala library methods such as List.map and List.filter provided mechanisms for writing clear, understandable code with far less boilerplate than is required in Java code.
We explored how to write the same kind of code so that you can abstract away the boilerplate of closing resources and collecting the calculations in loops.
In the next chapter, we’re going to explore pattern matching, another cornerstone of the functional style of programming.
We’ll learn how to construct complex logic in a declarative format and how patterns are functions.
So far, we’ve explored some of the basic functional cornerstones of Scala: immutable data types and the passing of functions as parameters.
At first glance, pattern matching looks like Java’s switch statement.
However, pattern matching provides a powerful tool for declaring business logic in a concise and maintainable way.
Scala blends traditional functional programming pattern matching with object-oriented concepts to provide a very powerful mechanism for writing programs.
In this chapter, we’re going to explore the basics of pattern matching.
Then we’re going to see how Scala’s case classes bridge between object-oriented data encapsulation and function decomposition.
Next, we’ll see how Scala’s pattern-matching constructs become functions that can be passed around and composed.
Finally, we’ll see how pattern matching provides a flexible alternative to the visitor pattern.
Basic Pattern Matching Pattern matching, at its core, is a very complex set of if/else expressions and looks a lot like Java’s switch statement.
Let’s start with a very simple example: calculating Fibonacci numbers:
There is little difference between the Scala and Java versions.
Note that there’s no break statement between cases in Scala, where you need break or return at the end of the case in Java.
Note also that the last case in Scala assigns the default value to the variable n.
Pattern matching in Scala is also an expression that returns a value.
In Scala, we can have multiple tests on a single line:
However, Scala allows guards to be placed in patterns to test for particular conditions that cannot be tested in the pattern declaration itself.
Thus, we can write our Fibonacci calculator to return 0 if a negative number is passed in:
The test extracts the value into the variable n and tests n to see whether it’s zero or negative and returns 0 in that case.
Guards are very helpful as the amount of logic gets more complex.
Note that the case statements are evaluated in the order that they appear in the code.
Under the hood, the compiler may optimize the pattern1 and minimize the number of tests, cache test results, and even cache guard results.
A huge thanks to David MacIver for improving Scala’s pattern-matching code.
If you’re curious about how the Scala compiler expands a pattern into code, you can use the -print option in the Scala compiler.
Patterns can match across different types in the same statement:
The previous code introduces the _ as a wildcard pattern.
This is consistent with Scala’s use of the underscore as a wildcard in other contexts.
Pattern matching is a very powerful way to avoid explicit casting.
In Java, there is a separation between the instanceof test and the casting operation.
This often results in bugs when a block of test/cast code is copied and pasted.
There’s no compiler check that the instanceof test matches the cast, and it’s not uncommon to have a mismatch between the test and the cast in Java code that’s been copied and pasted.
Let’s write a method that tests an incoming Object to see whether it’s a String, an Integer, or something else.
Depending on what type it is, different actions will be performed.
The same code in Scala is shorter, and there’s no explicit casting.
If it is a String, the parameter is cast into a String and assigned to the s variable, and the expression on the right of the => is returned.
Note that if the parameter is null, it will not match any pattern that compares to a type.
On the next line, the parameter is tested as an Int.
If it is an Int, the parameter is cast to an Int, assigned to i, and the guard is tested.
If the Int is a natural number (greater than zero), “Natural Int” will be returned.
In this way, Scala pattern matching replaces Java’s test/cast paradigm.
I find that it’s very, very rare that I do explicit testing and casting in Scala.
They are classes that get toString, hashCode, and equals methods automatically.
It turns out that they also get properties and extractors.
Case classes also have properties and can be constructed without using new.
You may use new to create a person as well:
Each of the Person instances has properties that correspond to the constructor parameters:
By default, the properties are read-only, and the case class is immutable.
How, you ask, does it work with pattern matching? Pattern matching against case classes is syntactically pleasing and very powerful.
If the valid field is true, the age is extracted and compared against a guard.
If the guard succeeds, the Person’s name is returned, otherwise None is returned.
Scala’s List collection is implemented as a linked list where the head of the list is called a cons cell.2 It contains a reference to its contents and another reference to the tail of the list, which may be another cons cell or the Nil object.
Lists are immutable, so the same tail can be shared by many different heads.
In Scala, the cons cell is represented by the :: case class.
Perhaps you have just said, “Ah hah!” Creating a List is Scala is as simple as this:
By keeping the creation method, ::, and the case class name the same, we can construct and pattern match Lists in a syntactically pleasing way.
And as we’ve just seen, case classes can be used in pattern matching to either compare or extract values.
This holds for Lists as well and leads to some very pleasing syntax.
The naming of the cons cell traces its roots back to Lisp and came from the act of constructing a list.
One constructs a list by linking a cons cell to the head of the list.
Then we can extract the head (x) and tail (rest) of the List in pattern matching.
We can start off using pattern matching to sum up all the odd Ints in a List[Int]
The next case extracts the first element from the list and tests it to see whether it’s odd.
If it is, we add it to the sum of the rest of the odd numbers in the list.
The default case is to ignore the first element of the list (a match with the _ wildcard) and return the sum of the odd numbers in the rest of the list.
Extracting the head of a list is useful, but when pattern matching against List, we can match against any number of elements in the List.
In this example, we will replace any number of contiguous identical items with just one instance of that item:
Let’s run the code and see that it does what we expect:
Pattern matching can match against constants as well as extract information.
Say we have a List[String] and we want to implement a rule that says that we discard the element preceding the “ignore” String.
In this case, we’ll use pattern matching to test as well as extract:
If the second element in the List is "ignore" then return the ignore.
Let’s compare this code to Java code that does the same thing.
In the Scala code, the pattern matching takes care of length testing and other plumbing.
Additionally, because the Scala code is recursive, there’s no need for explicit looping or for setting up the accumulator.
Looking at the Java code, there’s a lot of boilerplate.
In fact, when I wrote the example, I got this test wrong; it wasn’t until I ran the code that I discovered the problem.
We’ve seen how to use pattern matching and Lists with extraction and equality testing.
We can also use the class test/cast mechanism to find all the Strings in a List[Any]:
However, the paradigmatic way of filtering a List[Any] into a List of a particular type is by using a pattern as a function.
We’ll see this in the “Pattern Matching As Functions” section.
In this section, we’ve explored how to do pattern matching.
It may seem that List is a special construct in Scala, but there’s nothing special about List in Scala.
Case classes can contain other case classes, and the pattern matching can be nested.
Let’s create a method that returns the name of someone who is older or has a spouse who is older:
Scala’s case classes give you a lot of flexibility for pattern matching, extracting values, nesting patterns, and so on.
You can express a lot of logic in pattern declarations.
Further, patterns are easy for people to read and understand, which makes code maintenance easier.
And because Scala is statically typed, the compiler will help detect some code problems.
The next couple of paragraphs get into some gnarly parts of Scala.
Let’s write our own class that is nearly as syntactically pleasing as Scala’s List.
We will rely on a couple of syntactic features in Scala.
The first is that Scala methods and classes can have operator characters as class names.
The second is that methods that have a colon as their last character are evaluated right to left, rather than left to right.
Using these two features of Scala, let’s define our own MList class that has the same patternmatching beauty as Scala’s List class.
The code in this section must be compiled because there are circular class references.
It has a type of +T, which is part of Scala’s type system, and it means that subclasses of MList have a covariant type.3 Covariant means that T in subclasses of MList can be the same class or a superclass of T.
MList contains a single method, ?:, which is also the class name of the linked list cons cell.
Also, note that B, which is the type of the parameter, relates to T using the >: type relationship operator.
This means that B must be the same class or a superclass of T.
So, if you’ve got an MList[String] and you add an Int cell, the MList’s type becomes the class that’s the superclass of both: Any.
If you have an MList[Number] and you add an Int, the list is still MList[Number]
Nothing is the subclass of every other class.4 Because MList is covariant, MList[Nothing] can serve as a member of every MList.
If we’ve got MNil and we call the ?: method with a String, because the superclass of the two is String, we add a String cell to MNil resulting in an MList[String]
The cons cell holds the node and links to the tail of the list.
The class name of the cons cell is ?:, which is the method name on MList that adds a new cell at the head of the list.
The case class name ?: is the same as the method name ?: to unify the syntax of creating and pattern matching against the MList.
Finally, let’s see how our new MList class looks in pattern matching:
So, this demonstrates that there’s no internal magic to support Scala’s List class in pattern matching.
You can write your own classes that are as syntactically pleasing as.
Pattern Matching As Functions Scala patterns are syntactic elements of the language when used with the match operator.
However, you can also pass pattern matching as a parameter to other methods.
So a pattern can be passed to any method that takes a single parameter function.
Because patterns are functions and functions are instances, patterns are instances.
In addition to passing them as parameters, they can also be stored for later use.
In addition to Function1’s apply method, PartialFunction has an isDefinedAt method so that you can test to see whether a pattern matches a given value.
If you try to apply a PartialFunction that’s not defined for the value, a MatchError will be raised.
If you’re building a web application, you might have particular URLs that need special handling while others get handled in the default manner.
So, if the partial function exceptions (the pattern) matches the request req according to the isDefinedAt method, then we allow the request to be handled by the exceptions function.
We can call handleRequest and handle any “api” requests by a separate handler:
Partial functions can be composed into a single function using the orElse method.5 So, we can define a couple of partial functions:
Technically, combining multiple partial functions using orElse is not functional composition.
A roomful of wicked smart functional developers at LShift (http://lshift.com) were unable to come up with a good name other than “functional smooshing.”
In this way, Scala gives you a very nice, declarative way of handling complex filtering tasks.
Partial functions can match on data and can be passed around like any other instances in Scala.
Partial functions replace a lot of the XML configuration files in Java because pattern matching gives you the same declarative facilities as a configuration file, but they are type-safe, high-performance, and they can have guards and generally take advantage of any method in your code.
Object-Oriented and Functional Tensions At this point, the hard-core object-oriented designer folks may be somewhat unhappy about Scala case class’s exposure of lots of internal information.
But in fact, most of the Java classes we define have getters and setters, so there is data exposed in OOP.
But there is a tension between the amount of internal state that’s exposed in our program and the amount of state that’s hidden.
In this section, we’ll explore OOP and functional programming (FP) patterns for data hiding and exposure.
Another tension in OOP is how to define methods on class and interface hierarchies.
Where does a method definition belong? What happens when a library is deployed but it’s necessary to add new functionality to subclasses? How do we retrofit the defined-in-stone.
If we have a collection of shapes that derive from the common trait OShape that has an area method on it, our object definitions would look something like the following if we used a traditional OOP approach:
In the pattern-matching example, all of the logic for calculating area is located in the same method, but the fact that the method exists is not obvious from looking at the Shape trait.
So far, the OOP methodology seems to be the right answer because it makes obvious what shapes can do.
However, if we have a shape library and we want to calculate the perimeter of each of the shapes, there’s a benefit to pattern matching:
In this case, the open data makes implementing the perimeter method possible.
With the OOP implementation, we would have to expose data to make the perimeter method possible to implement.
More broadly, it’s rare that the designer of an object hierarchy implements all the methods that a library consumer is going to need.
The visitor pattern is a design pattern that allows you to add functionality to a class hierarchy after the hierarchy is already defined.
So, first the code, and then a walkthrough of the code:
The library author has to think about extensibility and implement the visitor pattern.
Note also that the class hierarchy is fixed in the visitor because the visitor has to implement an interface that defines all the possible classes that the visitor can handle:
Each element derives from a trait that creates a contract, which requires that the class implement the accept method:
That’s a lot of boilerplate.8 Additionally, it violates the data-hiding principles of OOP because the visitor has to access some of the data in each element that it visits.
Here is where a unityped language such as Ruby or Python has a material advantage over a static language such as Java.
In Ruby, you don’t need all the boilerplate, and the class hierarchy is not fixed at the time the OCarVisitor interface is defined.
The code is cleaner because there’s no boilerplate accept method.
Let’s see what we do when we want to traverse the object hierarchy:
More generally, Burak Emir, one of Scala’s authors, wrote an excellent paper on the intersection of pattern matching and object-oriented design.
Summary In this chapter, we explored pattern matching and saw how pattern matching provides powerful declarative syntax for expressing complex logic.
Pattern matching provides an excellent and type-safe alternative to Java’s test/cast paradigm.
Pattern matching used with case classes and extraction provides a powerful way to traverse object hierarchies and is an excellent alternative to the visitor pattern.
And because patterns are functions and objects, they can be passed as parameters and used wherever functions are used.
They take advantage of Scala’s flexible syntax, interoperability with Java libraries, and pattern matching to provide awesome power and flexibility for building multicore-friendly applications.
Java introduced the synchronized keyword, which provided language-level concurrency management.
Coming from C++, built-in language-level concurrency had the benefits of a unified model, so each project or module had the same concurrency mechanism and there was no need to roll your own.
You lock an object for exclusive use on a given thread, and the JVM assures you that the object will not be locked by another thread.
Furthermore, because the JVM assures you that you can enter the lock multiple times on the same thread and at the bytecode level, you know that the lock will be released no matter how your application unwinds the stack.1
In practical use, Java’s synchronized mechanism is fraught with peril.
The granularity at which you lock objects is a very tough call.
If you lock too coarsely, then you wind up with a single-threaded application, because in practical terms the global lock will be asserted by the first thread that needs the given high-level object.
If your granularity is too fine, there’s a high likelihood of deadlocks, as locks are asserted by different threads on mutually interdependent objects.
As a practical matter, when you code Java, you never know when something is going to be synchronized.
Even if your team defines a set of concurrency and synchronization patterns that work, enforcing the model is non-trivial, and often the only time the defects will be detected is during high-load production situations.
There has to be a better way, and in fact there is.
The Actor model of concurrency offers a different and generally superior mechanism for doing multithreaded and multicore coding.
A Different Approach to Concurrency: Look Ma, No Locks The Actor model provides an alternative mechanism for dealing with concurrency and more generally, the listener pattern, event handling, and many of the other things we associate with object-oriented programming.
Actors are threadless, stackless units of execution that process messages (events) serially.
At this point, Actors sound a lot like OOP message sending and encapsulation, and it turns out this is the case.
The Actor message-passing semantics grew out of Hewitt’s review of Smalltalk.
Scheme had an early implementation of Actors.4 Today, the best-known Actor implementation is Erlang, which provides a very powerful distributed Actor mechanism.
Smalltalk, Objective-C, Ruby, JavaScript, and Python are unityped or duck-typed languages.5 Instances in each of those languages is of the same type.
You can send any message or invoke any method on any instance.
The ability for an instance to process a method or message is determined at runtime.
Scala, on the other hand, is a statically typed language where the class of every instance is known at compile time and the availability of a method on a given instance can be verified at compile time.
Like instances in duck-typed languages, Actors process messages at runtime, and there’s no compile-time checking to see whether the Actor can process a particular message.
Messages are delivered to an Actor’s mailbox, and the Actor processes the mailbox by removing the first message from the mailbox that the Actor can currently process.
If the Actor cannot process any messages currently in the mailbox, the Actor is suspended until the state of the mailbox changes.
The Actor will only process one message at a time.
Multiple messages can show up in the Actor’s mailbox while the Actor is processing a message.
Because the Actor does not expose state and can only be modified or queried via messages, and because messages are processed serially, there’s no reason to assert locks on internal Actor state.
Thus, Actors are lockless at the application level, yet thread-safe.
Defining an Actor To send a message to an Actor, you use the ! (bang) method.
Thus actor ! msg is the syntax for sending a message to an Actor.
Actors are implemented as a library, and there’s no specific support for Actors in the Scala compiler.
As we wrote our own List class, you could write your own Actor library.
First, you define the messages that an Actor can receive, and second you define the Actor itself.
Actors can receive any message that can be pattern matched in Scala.
The following are legal messages, but we haven’t defined the Actor’s message handling, so we don’t know what, if anything, these messages do.
I find that except for the most trivial Actor code, I like to use case classes to define messages to an Actor.
This allows me to change the parameters that a particular message accepts, and the compiler will flag places in the code where the messages is used.
This means that the messages themselves are type-safe, even if the Actor itself is unityped.6
To define an Actor, you subclass from Actor and implement the act method.
Most of my Actors place the react method inside the loop method:
This Actor will accept any message and print the message on the console.
The loop method loops on its content, the react method.
The react method defines how the Actor will process an incoming message.
Philip Wadler refers to duck-typed languages as “unityped,” which seems to me to be very descriptive.
If you choose not to use the loop method, you have to explicitly loop at the end of each message.
Note the requirement to call act at the end of each handler.
If you forget to call act, your Actor stops handling messages.
In my experience, 40 percent of my Actor-related defects came from forgetting to call act at the end of my handler.
So, you may ask, why isn’t loop the default construct?
Erlang does not support objects or any concept of mutable private fields, so Erlang Actors must carry all state on the stack and must explicitly and recursively call the handler with the current state.
First, let’s look at an Actor that counts the number of messages it has received.
But if we want to write the Actor with no mutable state, it would look like the following:
In this code, the NoState class has no explicitly mutable state, but the state is kept on the stack and passed back into run for each message processed.
Personally, I prefer to keep state in private instance variables in my Actor.
I find that it reduces bugs and allows for more flexible composition of traits into an Actor.
I’ll have more on composition as we travel through this chapter.
To create an Actor, we have to instantiate it and then start it:
Forgetting to start an Actor is one of the other common Actor-related defect patterns in my code.
This is very helpful if you have a singleton in your application that does something, like being a central chat server:
Implementing a Listener The listener pattern is a very common design pattern.
Let’s look at two listener implementations to demonstrate Actors and the power and flexibility of asynchronous messaging.
This code is a traditional implementation that has a subtle bug in it.
We’ll parse through the code after seeing the whole listing.
Next let’s define the class that sends events to those listeners:
Finally, let’s define a concrete class that implements the listener.
For some reason, when the listener gets a changed message and the count is too low, the listener will access the object again:
D’oh! This is one of the perils of synchronous messaging.
If we run this code, we’ll get a stack overflow because the listener is mutating the model during the event processing.
Even if the increment of count was in the right place in the access() method, listeners that were called subsequent to FooListener would be called with descending rather than ascending count values.
Let’s look at the same code written using the Actor paradigm.
First, here’s the whole code in Listing 6-2, and then we’ll see the dissection.
First, we import a few things and define our messages:
The big difference is that there are no synchronizations, and everything is private except the event handler, act (explained in the next paragraph)
The act method defines what the Actor will do with messages in its mailbox.
What this means is that the Actor will use the same pattern to test messages over and over again.
It is possible to change the messages that the Actor responds to, but in this case, we’ll just react to the two messages, Add and Access.
The Add message adds who to the List of listeners.
The Access message results in a call to the private access method.
The access method calls the notifyListeners method and then increments count.
The notifyListeners method sends each member of the listeners List a Changed message.
The AFooListener’s constructor code registers the instance as a listener on the afoo instance by sending an Add message to afoo:
Our Actor event handler receives the Changed message and invokes the private changed method.
The changed method sends an Access message to eventFrom if the count is less than 10:
The message handling is asynchronous, so we’ll never run out of stack space, because the mutating.
You’ll also see that the synchronization is gone from the classes.
We’ve exchanged a little extra syntax and type-safety for a different and in many ways more powerful concurrency mechanism.7
Thus, the compiler does not check to see whether the particular message that you are sending to an Actor is one that the Actor can or could process.
They know about their state, but unless you’re a listener, you have no clue about their state.
It’s possible to send a message to an Actor and synchronously wait for a reply:
We can also send the message and wait for a reply.
If the reply comes within the timeout period, the method returns Some(response), otherwise the method returns None:
It’s much like getters in standard OOP, except it is heavier-weight both in terms of syntax and execution speed.
In general, if you keep most of the state in your Actor in immutable data structures and the query messages return all or substantially all of the state as a single request, then the overhead is incurred less frequently than repeatedly.
Additionally, the difference in the calling syntax triggers something in my brain that says, “This call may time out, so make sure you’re testing the return value.” This is an important value of the syntactic differences between object method invocation and Actor message sending.
The difference says to the developer, “Calculate the costs of invocation and probability of failure differently than for a normal method invocation.” Additionally, during code reviews, it’s much easier to see where Actors are being accessed.
Beyond the Basics So far, we’ve seen the basics of creating Actors, sending messages to Actors, and receiving replies from Actors.
In this section, we’re going to explore how Actors can change the messages they process depending on their state.
This will lead us to a couple of ways to do transactions with Actors.
Finally, we’ll talk about how exception handling in Actors differs from normal exception processing.
We’ve been writing the react part of the Actor as a pattern to match.
One of the things we learned is that Scala turns patterns into partial functions.
Unsurprisingly, the react method takes a PartialFunction as a parameter.
Because PartialFunctions are instances, we can do anything with them that we can with other instances.
This means that we can dynamically compose the PartialFunction that we’re going to pass to.
This gives us the ability to build an OOP hierarchy that defines how our Actor is going to react to messages.8 We’ll cover the basics in this section and dive in more deeply later in the chapter.
The way we’ve been writing our react calls, we’ve hard-coded the partial function, but that’s unnecessary.
We can calculate the behavior based on the current state of the Actor.
We’ll implement a chat server that will not allow listeners until there are at least three chats.
The Scala team adopted Erlang’s Actor model into Scala, which is a hybrid OOP/FP language.
Using Scala’s unique partial-function composing, we are able to build an inheritance mechanism on top of the Actors.
Yes, what was, will be again, or “there ain’t nothin’ new under the sun.”
First we define the messages that the ChatServer3 will accept or send:
Instead of defining the parameter to react, we’ll call the calcReact method:
It is the same no matter what is the state of the Actor.
The second, mgt, is empty if the number of chats is less than three.
However, if the number of chats is greater than or equal to three, we allow listeners to register and deregister themselves.
This is an example of changing the behavior of the Actor on a message-by-message basis.
The mechanism of composing the partial function for react based on the current state can be generalized into a protocol handler that accepts and processes messages based on the current Actor state.
Next, let’s turn our attention to implementing transactions using Actors.
Atomic means that if the transaction succeeds, all the rows affected by the transaction are changed at the same instant in the view of other transactions.
Consistent means that all of the rows will be updated if the transaction succeeds.
Isolated means that until the transaction is committed, no other transactions in the system see any updated rows.
Durable means that the transaction is written to media, disk, before the commit is done.
In this section, I’m going to build a transaction system that is ACI but not D.
Actors provide a great mechanism for multithreaded processing without explicit synchronization.
Using synchronization, we can implement atomic updates by synchronizing the target of our updates and then performing updates on that target.
Because Actors cannot be synchronized, we have to figure out another mechanism for performing atomic updates.9 Because it’s possible to pass functions as messages to Actors, we can define messages that contain functions that perform atomic updates.
Let’s build a simple example for an inventory Actor (see Listing 6-4)
An atomic update is an update that guarantees that the state of the thing being updated will not change between the time the values for calculating the update are retrieved from the thing and the time the update is applied.
It takes the name of the item to update and a function that performs the update.
That means while the Actor is processing Update, it cannot process any other message.
But Update contains code in the form of a function.
The function is processed in the scope of the Actor, but it does not have access.
Thus, the message is processed atomically and is thread-safe because the function is applied on the thread that’s doing the processing the Update message.
Atomic updates are useful, but they do not tell the whole story.
We need to be able to have exclusive access to one or more Actor’s state for an operation that spans both of the Actors.
It turns out that we can use the same techniques of immutable data structures and stateful message processing to build Actors that support transactions (see Listing 6-5)
The TIMEOUT message will be useful for staying in the transaction boundary for a certain period of time.
The XAction messages allow us to define the transactional boundaries.
The service variable defines how we’re going to service incoming requests.
By default, requests will be handled with the normal handler, but if we’re in a transaction, the handler can be changed.
This looks just like our previous example, Listing 6-4, except this time, we have the BeginXAction message.
This message calls the begin method with the transaction ID.
We now capture the current state of the Actor—both the info and the mechanism for servicing incoming messages:
Next, we build up a partial function that will service incoming requests.
If there’s a TIMEOUT, we roll back the transaction by replacing the current state with the state at the beginning of the transaction:
If we get a Pair that contains the current transaction ID and the RollbackXAction message, we roll back the transaction:
If we get a Pair that contains the current transaction ID and the CommitXAction message, we commit the transaction by reverting to the old servicing mechanism and leaving the data the way it was mutated by the current transaction:
If we get any other message and it has the correct transaction ID and can be handled by the normal message handler, we pass it on to the normal message handler:
Finally, we set the servicing mechanism to the new partial function:
If we are outside of the transaction boundary, we process the message the normal way with react.
This will process messages the same way as react, except if no message matching the pattern is received in 500 milliseconds, the Actor is sent a TIMEOUT message.
This allows us to terminate our transaction automatically if there’s no activity on the transaction in a 500 millisecond period.
Any messages received outside the transaction will be left in the Actor’s mailbox and will be processed after the transaction is complete.
Let’s create accounts for two people, dpp and archer, and put funds into the checking and savings accounts.
Let’s define a variable that keeps track of our transaction IDs:
Next, let’s define a method that will transactionally transfer money between accounts for a single Actor as long as there are sufficient funds:
If the account has sufficient balances, then we debit one account and credit the other account and commit the transaction.
If we don’t get the balance within 500 milliseconds or there’s not sufficient funds, roll back the transaction.
Let’s test out the transactional transfer and see whether it works by trying to transfer $700 from savings to checking twice.
The first transaction should succeed, but the second should fail.
Next, let’s define a method that transfers money between two accounts on two separate Actors.
Once again, there must be sufficient funds for the transfer, or the transaction will be rolled back.
Note that the second balance is not used, but the result indicates that we’re in the transaction for both the Actors.
We’re going to create the destination account before debiting the source account.
This will demonstrate that rolling back the transaction works correctly.
We’ve defined the ability to transactionally transfer money between accounts on two different Actors.
The console confirms that the transfer did not take place:
They can be modeled like coarse-grained objects, yet they have built-in concurrency support.
The message handling, including the mailbox and flexibility of react, allows you to dynamically control which messages are handled by the Actor given the current state of the Actor.
Combined with Scala’s built-in support for immutable collections, it’s very easy to build transactional support for Actors.
Finally, Actor messaging is syntactically lightweight enough to encourage Actor use while at the same time offering the cue to the developer that the cost of passing the message is higher than a method invocation.
In the next subsection, we’ll see how to compose an Actor out of a series of traits.
So far in this chapter, we’ve built Actors as monoliths.
However, as Scala is a hybrid OOP/FP language, we’re going to combine Scala’s OOP and FP sides to create Actors by composing traits.
Scala’s traits are like Java’s interfaces, but traits can contain methods as well as define them.
We are going to build two generic traits and compose them together into a specific Actor to provide chat server functionality that we’ve built in a monolithic fashion earlier in the chapter.
How many listener implementations have you written in your life? Lots, probably.
Why not build a generic listener and then compose it with a trait that contains business logic into a single Actor? This foreshadows some of the exciting stuff we’re going to do in the next chapter, but let’s get to writing the code (see Listing 6-6)
We define a generic trait called Buildable that has a single handler method.
The handler method has the signature that we need to pass to the react method in an Actor, and the implementation is to return a partial function that will match nothing.
This is analogous to a blank method in a class that you expect to be overloaded.
Your subclass can implement functionality, and when they call super, there is no additional work done.
We define the ListenerMgt trait that extends Buildable, has private state and implements the updateListeners method, and requires the updateMessage method to be implemented:
We implement the handler method by composing the superclass’s handler with this class’s message handler:
Any class that mixes this trait in must implement the updateMessage method:
Now, let’s implement a trait, GetMgt, which will respond to the GetInfo message with the result of the updateMessage call:
Finally, let’s create a Chat server that composes the ListenerMgt and GetMgt traits into an Actor and then adds Chat-specific functionality:
The composition of Actor with ListenerMgt with GetMgt builds a class that has all of these traits combined.
During the composition, ListenerMgt becomes the superclass of GetMgt, so GetMgt’s super.handler call will invoke ListenerMgt’s handler method.
This allows us to chain the calls to handler and compose the PartialFunction that we pass to react.
We add in the Chat-specific PartialFunction, and we’ve got a complete Chat server.
This is a simple example of composing an Actor out of generic pieces.
The generic pieces can be combined into a single Actor class that provides specific business logic as well as the more generic functionality of listeners and so on.
Actors provide an alternative model for concurrency that feels to me a whole lot like coarse-grained OOP.
Philipp Haller is a member of Martin Odersky’s group and is primarily responsible for Scala’s Actor design and implementation.
If Actors seem like a good tool in your software tool chest, please dig deeper, because there is a lot more good stuff to Actors.
Up to now, we’ve been focusing on what I call the library-consumer coding.
We’ve been writing code that consumes the libraries provided by Scala.
Scala has a more complex side based on its type system and traits.
In the next chapter, we’re going to go where there be dragons and explore the kind of gnarly stuff that library authors use to make sure the programs that library consumers write are type-safe and concise.
Please put on your thinking cap and your hip waders, and let’s do some hard-core Scala.
So far, we’ve explored Scala from what I consider the “library-consumer” perspective.
For the most part, when I’m consuming libraries, I don’t worry about complex types, composing many traits into a class, or some of the other powerful features of Scala.
Well, I’m worried about the transformation of input to output, happily mapping Lists, and filtering Seqs.
When I’m coding in this mode, I’m not reasoning about my types, but I’m confident that Scala will make sure I don’t do anything horribly wrong and that as long as my logic is sound, my code will work.
When I’m in this mode, I’m writing code the same way I write Ruby code: I’m looking to get something to work and get some work done.
There are other times when I am designing libraries for other folks to consume.
I do this for the Lift Web Framework and for my consulting projects.
In this case, I spend a lot more time making sure that the constraints are in place for writing correct code.
It takes a lot of time for me to reason about the constraints and then to reduce them to code.
When I’m in this mode, I write fewer lines of code, but they are more descriptive.
You may be asking, “Why not always code in this mode?” It’s because most problems are not solved by coding in this mode.
Most of my coding tasks are some variant of, “Here’s some user input, and it should be tested this way, and if it’s valid then it should update state and send the following events.” Reasoning about types is hard and slow work for me.
Choosing implicit conversions and designing domain-specific languages (DSLs) takes time, thought, and deliberation.
Using types, especially when type inferencing makes them invisible, is simple and doesn’t take a lot of thought away from the task at hand.
Well-defined types and type interactions will stay out of the library consumer’s way but guard against program errors.
Similarly, a well-defined DSL will make expressing program logic faster and easier to maintain.
Scala is unique among the languages I’ve used in that it gives a different set of tools and powers to different team members.
Scala’s traits, type system, flexible syntax, and implicit conversions give amazingly powerful tools to architects and library designers to build libraries that are simultaneously easy and safe to use.
Safety means that tests can focus on the logic of code, not calling conventions.
We’ve seen some examples of the safety of using Option instead of null testing.
Being able to reason about the safety by making sure that things have the correct types is very powerful.
It also means that the library consumers can focus on their business logic without worrying about declaring lots of fancy types or other distractions.
Library consumers don’t have to program defensively, because they can trust the correctness of parameters and of return values.
This chapter is a deep dive into the language features that make Scala different from Java.
These are tools that I use when I design code bases for other people to consume.
These tools let me write code that I can reason is correct, so when I go to write application code, I can be sure that my code is correct if my logic is correct.
I can write logic-oriented tests rather than tests that try to fool my code and make sure that I’m guarding against.
You’re probably thinking, “But Java is a statically typed language, doesn’t it give me all the safety that Scala does?” The answer to that is no.
Take a look at the following code and spot the problem:
This is legal Java code, and here’s what happens when we run the code:
Among enthusiasts of other statically typed languages with rich type systems (Standard ML, Haskell, OCaml) the “architect style” is often referred to as “typeful programming,” referring exactly to this distinction between “going with the type inference flow” and “using the type system deliberately to encode important invariants.”
This is because a String is a subclass of Object, so if the array was read-only, the assignment would make sense.
The modification that we’ve demonstrated shows one of Java’s “type-unsafety” features.
We’ll discuss why this happened and the very complex topic of invariant, covariant, and contravariant types later in this chapter.
Let’s start looking at how Scala makes the architect’s job easier and makes the coder’s job easier.
Library Pimping, Implicit Conversions, and Vampires We’ve seen a little bit of stuff so far that looks like magic.
You may be wondering how a Java class that is final could have additional methods on it.
If you have an instance of a particular type, and you need another type, and there’s an implicit conversion in scope, Scala will call the implicit method to perform the conversion.
For example, some date-related methods take Long, and some take java.util.Date.
We create a method that calculates the number of days based on a Long containing a millisecond count:
We can calculate the number of days by passing a Long to the method:
However, if we try to pass a Date into the method, we—correctly—get an error:
And this allows us to call millisToDays with a Date instance:
So having to type the following could get very old:
This is why implicit conversion is built into the Java compiler and why it’s part of the standard Scala Predef.2
The implicit conversion gets us halfway to adding methods to a final class.
The second half of the journey is that the Scala compiler will look to a possible implicit conversion from the type you have to a type with the method that you’re invoking.
The Scala compiler will insert code to call the implicit conversion and then call the method on the resulting instance.
The ability to add new methods to existing classes has a lot of value for making code more readable and expressive.
More importantly, implicit conversions make it possible to define DSLs in Scala.
As a library producer, we can create syntactically pleasing ways of expressing concepts in a type-safe way.
Let’s look at the code in Listing 7-1 and then break it down.
The Predef is the stuff that the compiler imports by default.
We import java.util.Date because we’re going to make use of it.
We define a class that takes a Long as a parameter and has a series of methods that convert the Long into a TimeSpanBuilder represented by the length.
Let’s define a bunch of helper methods (called from TimeSpanBuilder) that convert to the correct number of milliseconds.
Next, we define a bunch of implicit methods that convert from Int or Long into a TimeSpanBuilder.
This allows the methods such as minutes or days on TimeSpanBuilder to appear to be part of Int and Long.4
And we define a helper method that gets the current time in milliseconds:
We define the TimeSpan class that represents a span of time.
We can do math with other TimeSpans or convert this TimeSpan into a Date by calling the later or ago methods.
TimeSpan extends the Ordered trait so that we can compare and sort TimeSpans.
We compare this TimeSpan to another to satisfy the requirements of the Ordered trait:
Next, we define a companion object that has an implicit method that will convert a TimeSpan into a Long.
We’ll go into more depth about implicit scoping rules in the next subsection, but briefly, if there is an object with the same name as a class, that object is considered a companion object.
If there are any implicit conversions defined in the companion object, they will be consulted if an instance of the class needs to be converted.
We define an implicit conversion from TimeSpan to Long in the companion object.
This will result in TimeSpan instances being automatically converted to Long if the TimeSpan is assigned to a Long variable or passed as a parameter that requires a Long.
We have to define separate implicit conversions for Int and Long because the Scala compiler will not automatically chain implicit conversions.
To Scala, Int and Long are different types, but it will convert Int to Long because of the implicit conversion in Predef.
We can define TimeSpan instances with simple syntax like 3 days.
TimeSpans can be converted to Dates with the later and ago methods.
But it would be helpful to add addition and subtraction of TimeSpans to Date instances.
First, we define a DateMath class that has + and - methods that take a TimeSpan as a parameter.
With all the 50 or so lines of code written, let’s see how it works.
So, we’ve defined a nice DSL for time spans, and it converts itself to Long when necessary.
Early in my Scala coding career, I put the following implicit into a library:
I just passed them around, and they were converted from an Option to their underlying type.
I mean, really, how often did we get a None anyway? Heh! Boy, did that lead to a lot of bugs.
And when I removed the implicit, I had 150 code changes to make.
They are very powerful and very dangerous, and I only invite them into my program’s scope when there is a very good reason.5 Using implicits to convert to a class that has a particular method is a good reason.
The Int and Long to TimeSpanBuilder implicits are unlikely to cause a problem, so it’s safe to invite them into your code.
They are dangerous and can be kept out of your code if you don’t invite them in.
The Scala compiler will consider an implicit in the current scope if.
The implicit is defined in the current class or in a superclass.
The implicit is defined in a trait or supertrait, or is mixed into the current class or a superclass.
The implicit is defined on the companion object of the current target class.
The implicit is available on an object that has been imported into the current scope.
When designing libraries, be careful about defining implicits, and make sure they are in as narrow a scope as is reasonable.
When consuming libraries, make sure the implicits defined in the objects are narrow enough and are not going to cause problems like getting stuff from every Option.
Implicit conversions and library pimping is very helpful when building DSLs.
In the last chapter, we explored a little about composing traits together.
Traits: Interfaces on Steroids We’ve talked a little about traits.
They have all the attributes of Java’s interfaces, but they can contain implemented methods.
So, Scala’s traits provide a contract that a class must fulfill, and they may provide some of that fulfillment.
This comes in handy because it means that implementations for shared methods exist in a single place, on the trait, rather than being scattered across your code base.
It can be mixed into any class, and that class will have the methods implemented on it.
First, let’s define a ChangeEvent that takes a type parameter of the type of thing that’s changed:
Next, let’s define our Listener trait that takes the parameter, T, of the type that we’re mixing the Listener into:
Next, we define that the type of this in the trait is the type of the thing we’ve mixed Listener into.
We don’t know what T is when we define the trait, but we’ll know when the trait is mixed into a class.
At that time, the type of T will be resolved, and we’ll know what the type of this is.
We define a type, ChangeHandler, which is a structural type.6 It is any class that has a changed method that takes as its parameter a ChangeEvent[T with Listener[T]]
This means that any instance that has this method signature can register a listener without implementing a particular interface or trait.7
We’ll create a Foo class that extends the Listener and add functionality to Foo that demonstrates change events:
We define some private state, _count, a read-only count property, and an inc method that increments the count and notifies the listeners:
Next, let’s test out the Foo class in the REPL:
We define an instance that’s capable of listening for ChangeEvent[Foo] events:
Let’s see what happens when we call the inc method:
We’ve just encapsulated a bunch of generic listener functionality in our Listener trait.
We have a single place in our code base that defines listener behavior.
The code is isolated, so each developer who has to implement a listener doesn’t have to start from scratch.
It means that if we want to add functionality to our listener, for example logging each change, we can do so in one place rather than in each place that we implement a listener.
One of the big challenges with developing a class hierarchy when you are constrained by single inheritance is figuring out what things should be base classes and where things should go in the class hierarchy.
If we’re modeling living things, how do you model things with legs when that can include any animal? Should there be LeggedAnimals and LeglessAnimals? But then, how do you deal with Mammals and Reptiles? Maybe we can make HasLegs an interface, but then I can give a Plant legs.
Additionally, traits can have rules about what kind of classes and other traits they can be mixed into.
Further, you can declare method parameters that are a consolidation of types, for example:
Only instances of classes that extend Baz, Blarg, and FruitBat may be passed into this method.
But Animal is a class, so what does it mean for a trait to.
Thus, we’ve defined that only animals have legs, but any type of animal can have legs.
We define the rules of the self type with this: HasWings =>
The compiler will flag an error if this trait is not mixed into a class that also extends HasWings.
So, we can use self types to define the rules for what classes a given trait can be mixed into.8
Self types can also be used to discover at compile time what class a trait has been mixed into.
Some animals know their name, and if they do, we can ask their name:
So, a Dog is a Mammal that has legs and knows its name:
Some animals, cats, and children come to mind who know their own name but will sometimes ignore their name:
Now we can define a Cat class that has legs, knows its name, and ignores its name except at dinner time:
A Person is a Mammal with legs and knows its name:
A Biker is a Person but may only be added to an Athlete:
First, let’s try to create a Dog that’s also a Biker:
Cool, the compiler enforced our rule about Bikers needing to be Persons.
Please note that we can compose together different traits as part of the object creation.
So, archer is an instance of a class that is a subclass of Dog that implements Athlete, Runner, and Male.
The Scala compiler automatically creates this new, anonymous class for you.
What happens if we try to send Annette on a bike ride?
The method requires a Biker, and Annette is not a Biker.
However, just as we can compose a class out of traits, we can require that a class implement more than one trait in order to be the parameter to a method:
The charityRun method can only be called with a parameter that is a subclass of Person and also implements the Runner trait.
What if we try to call the method with a Runner that is not a Person?
The womensRun method may only be called with a parameter that’s both a Runner and a Female:
We’ve modeled things in a way that you cannot model with Java.
Scala’s compositional rules are very powerful tools for defining very complex class hierarchies and for specifying the rules for composing classes as well as the rules for passing parameters into methods.
In this way, we can make sure that the charityRun method can only be called with valid parameters rather than testing for parameter correctness at runtime and throwing an exception if the parameter is not correct.
This increased modeling flexibility combined with enhanced type safety gives the architect another tool to help developers write correct code.
Types—It’s Beyond Generic We’ve seen how Scala allows complex modeling and compile-time type checking that allows us to build complex class hierarchies.
What about things that make a developer’s life easier? What about things that make a developer, a library consumer, think that Scala is as easy and flexible as a scripting language? In this section, we’re going to write a database abstraction layer that allows a developer to define a table mapping simply as follows:
And the compiler will flag an error on a query such as this:
Thus, the library consumer gets the benefits of type safety along with very lightweight syntax for defining the mapping to the table and for defining queries.
Let’s look at the entire listing for the Query Builder (Listing 7-3)
After that, we’ll slice and dice it to understand how it works from the library-producer standpoint and see how it makes a library consumer’s life easier.
Let’s put on our architect hat and get our hands dirty with some of Scala’s types.
First, let’s import some stuff that will be helpful later:
We’re going to define a generic trait that will define the mapping to the column in a particular table.
The first parameter is the type of the Table that the column is part of.
The second type parameter, T, is the type of the column itself.
The column must define a default value of its type, its name, and a method to convert a JDBC ResultSet into the value of the column’s type and put the column into a PreparedStatement.
Next, we define the trait that holds the table itself.
The Table trait takes a type parameter that is the type of the class that is implementing the trait.
This type, MyType, will also be applied to fields and queries so that we can make sure that the only fields that are specified in queries to a particular table instance are fields defined by that table.
We’re also extending SuperTuple, which is a builder of Tuples that have extra type information.
A concrete instance of this trait must define the name of the database table.
And the instances must also define the type of the columns.
This does not give a lot of type safety standing on its own, because lots and lots of classes subclass from Product.
However, you’ll see how we make sure the type defined here ties to the actual fields, and the compiler will make sure that things are defined correctly.
Next, the implementer must specify the columns in the database.
We just defined ColumnTypes, so the type that columns returns must check with the types we defined in ColumnTypes.
Further, the only way to construct a FieldType is via the SuperTuple building mechanism that we mixed into this trait.
The IntColumn is a column that holds an Int, has a default value, and can convert itself to and from JDBC.
And we now define column representations for Long, String, and Date:
Now, let’s see how we define a method that can handle a query.
The find method takes two parameters: the columns to return and the query parameters.
That means it’s one of those nifty Tuples that can be constructed by chaining fields together with the ~
That means that the cols parameter is composed of fields that represent columns in the current table.
The return type is the ReturnType type on FieldProduct, which will be the column types.
We’re going to define the find method, which builds a query and sends it to the database.
FieldProduct has a dependent type called ReturnType, but that type is not stable; it is variable depending on the FT type parameter.
Put a List of the By instance into the by variable.
With a JDBC connection, we prepare a PreparedStatement and bind the query parameters to the ? in the WHERE clause.
We execute the PreparedStatement and for each row in the ResultSet build a Tuple to return.
We define a series of control structures for running queries.
QueryParams are type-safe in that they can only contain fields defined in the Table that we’re passing them to.
The column’s TableType equals the OrderBy’s TableType, thus we can only use columns from the table that we’re running the query on.
Marking a trait or class sealed means that all classes that implement that trait must be defined in this file, ensuring that subclasses don’t sneak into our code.
We define two case objects, Ascending and Descending, which implement the trait.
There’s also an implicit parameter, f, which converts an instance of PT into an instance of T.
First, when we construct an instance of By, the compiler will look for an implicit conversion in the current scope that turns a PT into a T.
If one cannot be found, the compiler will flag an error.
Second, within the scope of the By, any time you have a PT and you need a T, the compiler will apply the function.
The net result of this is that you can pass an Int as a parameter to a query where the column is a Long, and the compiler won’t complain.
We have to define subclasses of Tuples with two to four places that include extra type information that we used in Table.
We mix FieldProduct into each of the Tuples so that they contain extra information about the types as well as column information.
You may ask, “Why not use a List or some such?” Each element in the List has the same type, where each element in a Tuple has its own information, and because we’re tying the types together in Table to ensure that the columns we define have the correct type, we need to know the type of each column.
It’s sealed so that we know that other implementation or subclasses will not sneak into our code.
Harking back to Chapter 3, Lists and Tuples are different.
Lists contain a variable number of elements, all of the same type.
Tuples contain a fixed number of elements, each of which may be a different type.
This is our library consumer code that we will write to consume the Library trait.
For all the heavy slogging and boilerplate in SuperTuple, we get something very nice and pleasant, something that’s simple and understandable.
We define the MyTable class and then the MyTable object.
We need to do this because the type of the object MyTable is not known until the object is fully declared.
There is an exception to this requirement when defining classes.10 So we have to go through two steps to define our MyTable object.
The type inferencer does the right thing and knows that the return type is a Tuple2[(Int, String)]
Pretty neat, huh? We’ve got the type safety of Scala with very readable library consumer code.
But how type-safe is it? Let’s define a second table and see what happens when we try to mix things up.
Will the compiler let us build a query partially from MyTable and MT2? No.
Next, let’s see what happens if we try to pass an Int where we expect a String.
In this section, we’ve seen how Scala’s type system provides us a very powerful mechanism for defining the rules for passing parameters.
We were able to go through a lot of work to create a library that was complex underneath but simple to use.
Let’s go on to see a little more about how types and class hierarchies work in Scala.
It defines the rules by which parameterized types can be passed as parameters.
In the beginning of the chapter, we showed how passing a String[] (Java notation) to a method expecting an Object[] can cause problems.
Java allows you to pass an array of something to a method expecting an array of something’s superclass.
If you can pass a String to a method expecting an Object, why can’t you pass an Array[String] (Scala notation) to a method expecting an Array[Object]? Because Array is mutable: it can be written to in addition to being read from, so a method that takes an Array[Object] may modify the Array by inserting something that cannot be inserted into an Array[String]
Defining the type variance for type parameters allows you to control how parameterized types can be passed to methods.
Type parameters can be individually marked as covariant or contravariant and are by default invariant.
This means that you can only pass an Array[String] to foo(a: Array[String]) and that you can only pass an Array[Object] to bar(a: Array[Object])
This ensures that what is read from or written to the array is something of the correct type.
So, for anything that’s mutable, the type parameter should be invariant.
You do this by doing nothing with the type parameter.
Because the add method expects an Int to come out of Holder and puts an Int back into the Holder, the type of the Holder must be invariant.
That does not mean that invariant containers lose their ability to hold subclasses of their declared type.
We call the round method, and let’s see what we get out the other side:
We put in a Number and got back a Number.
Integer is a subclass of Number, so we can put a Integer or a Double into the Holder[Number]
We preserve the ability to use class hierarchies with invariant type parameters.
Let’s finally see what happens when we try to pass a Holder[Double] into round.
So, invariant type parameters protect us when we have mutable data structures like arrays.
Covariant parameter types are designated with a + before the type parameter.
Scala’s List is defined as List[+T], which means that it’s covariant on type T.
List is covariant because if you pass a List[String] to a method that expects a List[Any], then every element of the List satisfies the requirement that is an Any and we cannot change the contents of the List.
Once an instance of Getable is created, it cannot change, so we can mark its type, T, as covariant.
Yes, the covariance works the way we expect it to.
I guess that means that contravariance is good for write-only classes.
So, if covariance allows us to pass List[String] to a method that expects List[Any], what good is contravariance? Let’s first look at a write-only class, Putable:
Okay, so we can call a method that expects a Putable[String] with a Putable[AnyRef] because we are guaranteed to call the put method with a String, which is a subclass of AnyRef.
Standing alone, this is not particularly valuable, but if we have a class that does something with input that results in output, the value of contravariance becomes obvious.
Calling something that expects at least any AnyRef with a String is legal and valid.
But the return value can be covariant because we expect to get back a Number, so if we get an Integer, a subclass of Number, we’re okay.
We’ll define DS with a contravariant In type and a covariant Out type:
Let’s create an instance that will convert Any into an Int:
We define check, a method that takes a DS[String, Any]:
The invariant type was mutable, so it both returned and was called with a particular type.
We created a convariant type which was an immutable holder of a value.
Finally, we created a transformer that had contravariant input and covariant output.
That’s right, Scala’s FunctionN traits have contravariant parameters and covariant results.
Inputs to transformations should be contravariant, and outputs from transformations should be covariant.
In very few pages, we’ve covered a very complex topic.
Let’s go have some fun watching dragons and other monsters kill bunnies.
As a library producer, we want to write code that makes it super-simple for library consumers to express their logic.
Our example will build the rabbit in the immutable world of Scala and use functions for transformation rather than method_missing magic that Why uses in his example.
Our object hierarchy contains Creatures of which the Rabbit is a subclass and Monster is a subclass.
In Why’s example, only Rabbit could fight any of the Monsters, but our Monsters will be able to fight each other.
We can see what happens when the Dragon uses its tail:
With a poignant wave and a little more flair than usual, let’s sashay down the stairs to our Scala implementation.
Please glance through it in one big blob (Listing 7-4), and then we’ll parse through it.
First, we create a random number helper because we don’t want every battle to come out the same:
These declarations will allow the compiler to enforce what kind of weapons can be mixed into our characters.
Further, the self type BaseType with Creature[BaseType] will ensure that the Creature is mixed into its BaseType.
Our Creature, be it Rabbit, Monster, or something else, is going to fight with another Creature.
We want to use Scala’s type system to define what our type is, Us, and what another Creature’s type is, Them, even though every participant in our battles is going to be a subclass of Creature.
This allows us a lot of flexibility in terms of defining who can use one of our weapons, Us, and who we are fighting against, Them.
We use Scala’s dependent types to define the types Us and Them and use those types in a fair number of places.
This means that Creature implementations are type-safe such that a Dragon cannot sneak into a Rabbit’s method, which takes an Us parameter.
It allows the compiler to enforce weapon usage as well.
And finally, the setLife method that creates a new instance of the specific Creature with its life updated.
Each Creature is immutable, so we must create a new instance rather than mutating the Creature in place.
I originally defined Type Them = Creature[_] in the Creature trait, but the result was that the compiler found more than one path to certain implicit conversions.
Is the creature dead? Scala allows you to have symbols as well as letters and numbers in method names, but in order to mix symbols and letters and numbers, you have to separate the symbols with the underscore.
An instance of Weapon defines a turn or a whole battle tilDeath between Us and Them.
The Weapon takes a function, turn, that transforms instances of Us and Them based on particular rules.
For example, our Rabbit has three bombs that he can throw.
Each time the Rabbit throws a bomb, we have to update the Rabbit to have fewer bombs.
We define the transformation rule, and the Weapon instance applies the transformation rule to an instance of our enemy, Them, once or until one of the participants is dead.
This gives you the ability to repeat the battle until.
If we want to battle tilDeath, we call this method, which will return a new Weapon instance with the _tilDeath flag set.
The public apply method takes a Them parameter and calls the private apply method with the instance of the Creature that created the Weapon and Them.
The private method (callable from anything in the Creature scope) takes instances of Us and Them and pits them together in doBattle.
If either of the participants dies, it prints a message.
Finally, it returns a (Us, Them) with Rebattle, which is the (Us, Them) Tuple contains a Rebattle trait.
Rebattle allows you to chain (apply) another Weapon instance type safely such that the result is another (Us, Them) with Rebattle.
This means our Rabbit can throw a bomb in the first turn and then use a sword in the next.
However, our Rabbit cannot use the Dragon’s tail as a weapon.
If either participant is dead, we don’t try to battle any more.
Otherwise, if we’re not repeating, we apply Us and Them to our turn transformation once and return the result.
The Rebattle trait can only be mixed into a Tuple2[Us, Them]
Its apply method applies the Us and Them instances to the Weapon.
The result is yet another (Us, Them) with Rebattle, which can be used for application of yet another weapon.
Typically, the turn function passed to Weapon will call round to do the actual fighting.
If the opponent did not die, Us is attacked by Them.
Every Creature has its claws, >*<, as a Weapon, but we can, and will, give other creatures other Weapons.
Why’s Dwemthy’s Array example demonstrated Ruby’s metaprogramming by creating a subclass of Ruby’s Array class and using method_missing to forward method calls intended for a particular monster to the first monster in the Array.
In Scala, when our hero battles on Dwemthy’s Stairs, we use Scala’s implicits to convert a Seq[Creature[_]] into a Creature suitable for application of a Weapon.
It contains the definition on Them, which is any Creature.
We define an implicit method that will convert a Seq[Them] into a Them.
When the compiler encounters a method that needs a Them, a Creature[_], but has a Seq[Them], it will call Creature.fromSeq to perform the conversion.
It’s got a head, the current Creature, and tail, the rest of the Creatures.
The setLife method transforms the Creature to an instance with an updated life field by creating a new instance of CreatureCons with an.
If the Creature at the head dies, we promote the first Creature in the tail to the head.
Note that we had to manually write each of the methods, rather than using Ruby’s metaprogramming to forward the missing methods to the head item.
It’s a Creature[Rabbit] with life, bombs, and fixed charisma, strength, and weapon.
Next, we define a Monster trait, which is a Creature[Monster]
It gets its name from its class and some regular expression magic.
We create a new Monster instance by creating an instance of DupMonster with updated life and the same everything else.
Let’s define some weapons that a Monster, and only a Monster, can have.
Not dead this time, let’s try again by applying the >*< weapon again:
Let’s go back to the result of the first Dragon vs.
So, Scala’s type safety has saved us from dragons using bombs.
Next, let’s see how our hero does tossing bombs at all the monsters on Dwemthy’s stairs.
Compared to the Ruby code, the library parts of the Scala code were more complex.
We had to do a lot of work to make sure our types were correct.
We also had to do a fair amount of work to support immutability in our Creatures and Weapons.19
On the other hand, the result was much more powerful than the Ruby version.
If we had to write tests for our Ruby code to test what the Scala compiler assures us of, we’d need a lot more lines of code.
For example, we can be sure that our Rabbit could not wield an Axe.
To get this assurance in Ruby, we’d have to write a test that makes sure that invoking |^ on a Rabbit fails.
Our Scala version ensures that only the Weapons defined for a given Creature can be used by that Creature, something that would require a lot of runtime reflection in Ruby.
The end user code is pretty much the same between the Scala and Ruby code.
The definition of Rabbit and the various Monsters is similar lines of code and similar readability to the Ruby code.
So, we’ve seen that as a library producer, our life is more challenging.
Summary Wow, that was an awful lot of material to cover in a single chapter.
We saw how Scala’s implicit conversions lead to very simple and concise DSLs.
We saw how Scala’s traits can be composed into very powerful classes.
You can even do dependency injection without external libraries using Scala’s traits.21 We saw how complex concepts such as covariance and contravariance lead to safe and powerful ways to use type parameters.
We could have avoided some of that by using the JVM’s proxy-generation facilities.
Types and Programming Languages is intended for computer science grad students who are thinking about designing new programming languages.
Finally, we saw how some extra thought and work as the library producer leads to easy-touse and type-safe libraries that allow the library consumers to write code that’s as concise and easy to read as scripting language code but that’s got the compiler making sure that dragons don’t use bombs that are meant for use by rabbits.
In the next chapter, we’re going to roll many of Scala’s concepts together by building parsers using Scala’s parser combinator library.
We’re going to be library consumers and experience how easy it is to use a well-written Scala library.
We’ve covered a lot of ground so far, but most of the examples have been one or two lines of code.
Sure, the control structures are helpful, and of course most of our programming projects pit dragons and bunnies in battle, but one of the biggest challenges we face is dealing with real-world data.
If we’re lucky, the real-world data will be well formed in XML.
Sometimes we’re handed a spec for a wire format or a text file format and told to “deal with it.” Good news: Scala is very good at helping you deal with it.
Scala comes with a parser combinator library that makes writing parsers simple.
Furthermore, because your parser is written in Scala, there’s a single compilation step, and you get all the benefits of Scala’s type safety.
In this chapter, we’re going to explore combinators and Scala’s parser combinatory library.
Higher-Order Functions and Combinators You may be wondering why something so mundane as parsing input comes this late in the book.
Why have we gone through Chapter 7 just to deal with parsing? Scala’s parser combinator library gives us a view of a powerful DSL, and it has its roots in a lot of computer science and mathematics.
Let’s look at higher-order functions (functions that take functions as parameters), then at how higher-order functions can be combined to yield powerful functionality.
These are functions, or methods, that take functions as parameters.
In this example, we’ve composed a function, addDouble, out of two other functions, plus1 and twice.
We can even compose functions dynamically based on user input.
Combinators allow you to combine small functions into big functions.
In the case of the parser combinator library, you can combine small functions that match individual characters or small groups of characters into bigger functions that can parse complex documents.
So, you have input that is a Seq[Char] (sequence of characters), and you want to parse the stream, which will either contain t, r, u, e or f, a, l, s, e—true or false.
The ~ method is called “and then,” so we can read the first part as t and then r and then u and then e.
So we combine the functions together with the ~ method into one bigger function.
We keep doing this with each successive ~ method invocation.
The | operator also takes two of these combinated function thingies and combines them into a single function thingy that will test the first clause, true, and if that succeeds, its value is returned, but if it does not succeed, then the second clause, false, is tried.
So, we can combine these Parser instances with each other into other Parser instances using operators like “and then,” “or else,” and so on.
We can combine little Parsers into big Parsers using logic and thus construct complex grammars out of little building blocks.
Let’s use a little bit of Scala’s implicit functionality to make the definition of our grammar easier.
Scala’s parser combinator library has implicit conversions from Char into Parser[Char], so we can write.
As in the rest of this book, here I’m dealing with the practicalities of combinators.
There is a lot of theory and math behind combinators.
But, there’s still a question of what these Parsers return when we pass a Seq[Char] into them.
Or put another way, we want to get a Boolean true or false when we pass our input into them.
That’s what we want, but the compiler complains that it doesn’t know how to convert the combined Parser into a Boolean.
So, let’s add a little bit of code to tell the Parser how to convert its result into a Boolean.
But we can also use the characters that are part of the pattern to create the value returned when the input is applied to the function using the ^^ method.
Note that we combined the positiveDigit Parser with elem('0') into a Parser that accepts all digits.
Let’s make this into a Parser that converts the digits into a Long:
We create a Parser that matches a positiveDigit and then zero or more digits using rep(digit)
The ^^ method on Parser causes the conversion function to be applied if the predicate succeeds.
In this example, I was explicit about the types, but the type inferencer will get it right.
The type inferencer will infer the correct return type, Parser[Char]
Let’s tighten up the example a little by only accepting rest if it’s fewer than 18 digits so we don’t overflow the Long:
In this case, we’ve used the ^? method to connect the predicate to the conversion.
In order for the Parser to succeed, we need to satisfy the predicate, and the partial function passed to ^? must be defined for the result of the predicate.
In this case, the partial function will be satisfied if the length of rest is fewer than 18 characters.
We’ve also changed from a method to a lazy val.
This is because the method does not do the parsing; rather, the method combines smaller Parsers into a single Parser.
This building of the Parser need only happen once, and the resulting Parser can be used over and over, even simultaneously on multiple threads.
With the basics under our belt, let’s put our parser mojo to use.
The Calculator Parser In this section, we’re going to using the parser combinator to build a four-function calculator.
You’ll see how easy it is to describe what we want to build, create a Parser for it, and then make sure the Parser returns the correct things.
But first, let’s define a utility trait that will allow us to more easily run the Parsers from the Scala REPL.
The RunParser trait can be mixed into any Parser and adds a run method.
The RunParser trait can be mixed into a class that extends RegexParsers.
A sum expression is a product expression followed by zero or more + or symbols followed by a product expression.
A product expression is a factor followed by zero or more * or / symbols followed by another factor.
This means that the precedence of production expressions is higher than the precedence of sum expressions.
Finally, we define a factor as a number or parentheses around a sum expression.
Our English and BNF descriptions of what we wanted to parse correspond very closely to our Scala code.
Furthermore, our parse correctly parses valid input and rejects input with errors in it.
Next, let’s turn the results into something that performs the calculations.
Our Parser doesn’t change, but we add a function to convert the parsed items into a Double.
First comes Listing 8-1, and then we’ll comb through the code.
First we import the appropriate classes and then get down to business:
The rep method results in a List of whatever is parsed by the parameter of rep.
When we match the + ~> prodExpr, we convert this into a function that adds the two numbers.
This method matches both items but only passes the stuff on the right to the converter function.
We’ve got a prodExpr, which is a Parser[Double] and then a Parser[List[Double => Double]], and we need to convert this into a Parser[Double]
Next, we define factor, which is either a number or parentheses around a sumExpr.
Because sumExpr, prodExpr, and factor reference each other and, thus, are recursive, we must define the type of at least one of the three vals so the type inferencer can do its work.
Calc mixes in RunParser, so we have to define the abstract RootType type and the root method.
We’ve defined the conversions from the Strings and List to Doubles.
In this section, we’ve converted from BNF description of the grammar to a running application using Scala’s parser combinator library.
In the next section, we’re going to tackle something more complex.
In this section, we’re going to follow the ECMAScript spec to build our Parser: we’re going to copy and paste the spec into our Scala code and literally code our Parser to the.
The only new concept in this Parser is the regular-expression Parser.
The RegexParsers trait has an implicit conversion from a regular expression to a Parser[String]
If the input matches the regular expression, the matching string will be returned by the Parser.
The .r at the end of the String converts the String into a regular expression.
A string literal is zero or more characters enclosed in single or double quotes.
SourceCharacter but not single-quote ' or backslash \ or LineTerminator.
Let’s see how the Parser does with various JSON input:
Let’s see what we can layer on top of the JSON Parser.
Twitter JSON Parsing JSON is great for storing and transmitting dynamically typed information, but Scala is a statically typed language.
It would be great to be able to convert the dynamic stuff parsed from JSON data into statically typed Scala.
As an example, we’re going to use some of the.
Twitter APIs that return Twitter’s public timeline.6 We’ll request the data in JSON format, parse it, and then run the parsed data through a conversion to create Scala instances that represent the Twitter data.
In order to use Scala’s for comprehension to safely and easily extract data from the result of the JSON parsing, we’re going to write a helper trait, SafeMap, which does type-safe testing and casting.
SafeMap has an is method that takes an implicit parameter, man, which is a Manifest representing the type T.
The Scala compiler correctly builds the Manifest and passes it to the method.7 We use the Manifest to get the class for T and do testing.
First we have the code in Listing 8-3 and then a dissection.
Manifest is an experimental feature introduced in Scala 2.7.2, but it’s so very useful that I’m including it in the book.
When the Java Virtual Machine was introduced in 1996, the Java language did not include generics.
You had to manually cast each element of ArrayList into the class that you wanted.
This avoided the manual cast because the compiler did the casting for you.
They were an experimental, undocumented feature, but they are very, very useful.
They allow a method implicitly to take a Manifest as a parameter for each type parameter passed to the method.
The Manifest contains information including the type that is to be erased when the bytecode is rendered.
Thus, the Manifest allows us to reify the erased type.8
We will use this feature in our SafeMap trait to do syntactically pleasing, type-safe casting.
First, we define a SafeMap trait that we can mix into any class or object and make use of type-safe access to Maps.
It has a single method, is, which takes an implicit Manifest as a parameter and tests to see whether the class of in is assignable from the class contained by the Manifest and accessed using the erasure method.
SafeMapC is a class that contains a method that gets the key and uses SafeCast to ensure that the key is of the class we want to cast it to.
First, let’s look Listing 8-4, and then we’ll work through it.
We define a basic trait that all of Twitter-related classes extend:
The structure of the class is based on the definition of the Status in the API document.
In order to convert from the JSON data, we need to extract each field and build up all the parameters necessary to construct a TwitterStatus.
Using is and sGet from SafeMap along with the for comprehension, we extract the data from the JSON data and create a type-safe TwitterStatus instance.
The fromList method extracts a series of TwitterStatus instances from a List of JSON data.
We define the TwitterUser class the same way we defined TwitterStatus.
Let’s use the REPL to see how well it works.
We’ve layered our Twitter-specific code on top of the JSON Parser in a way that allows us to parse Twitter-related data.
We were able to convert a ParseResult that returned JSON data into a ParseResult that returns Twitter data just by mapping the JSON data into Twitter data.
Summary Scala’s parser combinator library demonstrates the flexibility of Scala’s syntax, the usefulness of implicit conversions, and the power of functional composition.
The parser combinator is an excellent example of a domain-specific language.
The domain is parsing text, and the syntax is nearly one-for-one with BNF.
We were able to create the JSON Parser by taking the ECMAScript spec and translate it directly into Scala code.
This library also gives you some idea of the kind of domain-specific languages you can create using Scala.
On a practical level, using a single language—Scala—for defining your Parser rather than using a tool like ANTLR9 means that you and your team use a single language for describing your system.
This means that you edit code in a single language and take advantage of the type safety of the language.
In the next chapter, we’ll explore how you can integrate Scala into your projects, better build teams and divide work using Scala, and take advantage of the power of Scala without losing the infrastructure that you’ve built around Java.
We’ve discussed the Scala language and developed a whole bunch of idioms for building applications using Scala.
We’ve explored how Scala can be used by different team members in different ways.
We’ve seen how Scala allows you to compose fine-grained pieces of code together into complex systems that work well together.
No matter how good Scala is in the abstract, it’s only valuable if it can help your organization produce better and more maintainable code, faster.
The good news is that Scala compiles down to JVM bytecode and works great with existing Java libraries.
If you’re working at a Java shop, the cost of using Scala on some projects is minimal.
You can test Scala with your existing Java test tools.
You store compiled Scala code in JAR and WAR files, so it looks and feels to the rest of your organization like what they’re used to, Java bytecode.
The operational characteristic of Scala code on web servers is indistinguishable from the operational characteristics of Java code.
In this chapter, we’re going to explore the practicalities of integrating Scala into your project and perhaps your organization.
We’ll look at testing Scala code, potential changes to team structure, best practices to look for during code reviews, and selling Scala into your organization.
Testing: Behavior-Driven Development So far, we’ve talked a lot about the type of testing that Scala code does not need.
You do not need to write tests that catch type errors or test that method names exist.
You use Scala’s type system and strong typing to ensure that your code is well formed and valid.
That does not mean that your logic is correct; therefore you need to write tests to ensure that the logic of your program is correct.
I find that Behavior-Driven Development (BDD) provides the best way to write tests because business people can read and understand BDD, and BDD tests tend to be higher-level and focus on the logic, not the mechanics, of code.
Scala can be tested using existing Java frameworks including JUnit.
However, there are better ways to test Scala code, and these better ways play nicely with JUnit and other Java testing frameworks.
That means you get a better way to write Scala tests, but they run the same old ways.
In this section, I’m going to give a brief overview of two Scala test frameworks: Specs and ScalaTest.
For example, here’s a Specs definition for testing some of Lift’s utility classes:
Specs provides a lot of different matchers that allow you to test Strings by testing them against a regular expression:
Specs integrates with JUnit so that you can use your existing testing infrastructure to run Specs tests.
The BoxSpecsTest can be run with your JUnit runner of choice.
Scala is a functional language, and many of your tests can stress functions without having the set-up complex state.
It generates random input based on rules and tests your method against the random input.
For example, this will test 500 e-mail addresses against the pattern:
Specs test can be read by and often written by business users of your code.
This is important because the more transparent the tests, the more likely your application will perform the way that business people expect it to, and when that happens, you get fewer tickets filed and more time to write new, cool code … or drink a beer.
Scala’s software ecosystem is rich, and there’s more than one excellent testing framework.
Bill has taken a slightly more Java-flavored approach in ScalaTest but also offers the BDD goodness that Specs has.
This looks to me like a more pleasant version of the kind of tests that I’d write in JUnit.
In fact, ScalaTest has excellent integration with JUnit, so you can use JUnit as your test runner.
ScalaTest wraps ScalaCheck just as Specs does, and you can write BDD-style tests using ScalaTest as well:
ScalaTest and Specs both offer integration with Ant and Maven, so you can integrate your tests into your existing Java build environment.
With both tools, you can describe tests for your business logic in simple, readable, powerful ways and run those tests using your existing build and test infrastructure.
In this way, Scala integrates very well into your organization.
This means that integrating Scala into an existing Java-oriented workflow is simple and painless.
In this section, I’m going to do a quick survey of the tools available for building, testing, and packaging Scala apps, and that includes apps that contain Scala, Java, JRuby, and so on.
Basically, these tools convert source code to bytecode and stuff that bytecode into JAR and WAR files.
The order I’ve chosen is most verbose to least verbose.
Maven will figure out what dependencies are necessary to resolve in order to achieve a goal.
Maven may need to download a JAR file in order to resolve a dependency.
Maven will go to different repositories, including well-known repositories of open source code, in order to download dependencies.
Maven also determines what code to run in order to resolve a dependency in order to reach a goal.
For example, if the goal is jetty:run (run the web application inside a Jetty container), Maven will download the JARs that your code depends on, compile your source code, package your code into a WAR directory layout, download the Jetty runtime, and then invoke Jetty.
With Maven, you only worry about your own code and defining its dependencies, and Maven takes care of the rest.
There are test goals for JUnit, TestNG, and so on.
Every Apache JVM-related open source project publishes its JARs to the central Maven repository, as do most other open source projects.
Others disagree because Maven is opaque in how it resolves dependencies; Maven “downloads the entire Internet” (all your dependencies and those dependencies’ dependencies, and so on) the first time you build; Maven is challenging when debugging failures; and Maven’s XML verbosity is overly verbose.
The good news is that Maven is very powerful, and as my project has more dependencies, Maven will take care of downloading them and getting them right.
This also means that I don’t have to have a bunch of JAR files in my source repository.
The bad news is that the Maven pom.xml is a big hairy mess.
Ant is to Java build tools as make is to Unix build tools.
It’s good enough to get most jobs done and bad enough for everyone to complain about it.
Scala itself uses Ant as its build system, and the Scala Ant plug-in has been very stable for a very long time.
Here’s an Ant build script for a generic Scala project:
Ant scripts are marginally shorter than Maven scripts, but they do not do any dependency management.
Ant scripts are about the compilation and packaging tasks, and that’s it.7 But there’s a Scala task for Ant, and Ant works well with Scala.
Now, if you want the power of Maven with a very concise and amazingly readable syntax, you want Buildr.8 Buildr is a JVM-targeted build tool written in Ruby.
I asked Alex Boisvert, a Buildr committer, to convert the previous Maven Project Object Model (POM) file into Buildr, and he came back with the following for build.yml:
So, if you want concise, readable build files, Buildr is a great tool.
It works with Java, Groovy, Scala, and most other things JVM-related, and it’s a top-level Apache project, so it’s got a track record and a community around it.
There are a couple of other build tools gestating in the Scala world.
Simple Build Tool (sbt, http://code.google.com/p/simple-build-tool/) is a Scala-based build tool that focuses on dependency management.
Brian Clapper is also working on a Scala build tool that has the syntactic DSLishness of Buildr without the dependence on Ruby.
You can read more about Brian’s build tool at http://brizzled.
Team Structure With the infrastructure pieces of test and build tools, the next step for Scala adoption is getting the people in your organization to start coding in Scala.
If the individuals on your team have repeated good experiences with Scala, they’ll have every reason and incentive to work harder with Scala.
If individuals have a bad initial experience, they will resist Scala, and you’ll never see the benefits of Scala translated into tangible code.
In this section, I’ll make some recommendations for introducing Scala to your team.
Introducing a new team member into a Scala project and helping that team member be successful in his first few weeks is critical.
As you plan to bring team members on board, I recommend looking at each member’s strengths and weaknesses.
Create a series of tasks that each team member can succeed with.
Each task should take one to three days to complete and be subject to feedback.
You might ask a team member to augment existing Specs or ScalaTest-based tests.
This gives familiarity with Scala’s syntax and some exposure to Scala’s flexibility.
You might give a developer the task to manually serialize and deserialize objects to and from XML.
This will give the developer an exposure to XML and immutability.
You might give the developer the task of adding concrete methods to one or two traits or interfaces that are commonly used.
You might ask them to write simple servlets or do other things demonstrating interoperability with Java.
I strongly recommend pairing a new-to-Scala team member with someone who has a little bit of experience.
If you are bringing more than one developer onto your project at once, you might also want to have a 30-minute meeting toward the end of the day every day or three times a week.
The goal of the meeting is to have a single developer share with the other developers “one cool thing about Scala and one sucky thing about Scala.” This format gives the developer a chance to brag about something cool and share this knowledge with the team.
It also gives each developer a chance to complain about things.
Perhaps the complaint will be met with a solution from another team member, or perhaps the complaint will be met with collective nodding and grumbling.
The complaining will happen one way or another, and giving it a shared outlet channels the complaints into.
For example, when Twitter started using Scala, they created the Graceless Failures blog (http://www.gracelessfailures.com/)
This serves as a way to share Scala experiences, good and bad, with the community.
No matter what the specifics of adding team members are, I strongly recommend that Scala adoption be positioned to the whole team as a way to write code more successfully.
Acknowledge the problems of Scala’s youth, which include weaker tools, less documentation, and so on.
But help your team members stay focused on what they can achieve with Scala in spite of the challenges of learning a new language and using a new tools chain.
As they have small successes and the values of concise code, immutability, powerful type systems, type inferencing, and so on show up as revised coding idioms, they will move into a self-reinforcing cycle of learning more, getting better, and getting better results.
When they walk into a meeting and say, “I don’t know how I could ever go back to Java,” then you know they’re hooked and that you’ve succeeded in bringing them on board.
I’ve consulted for a lot of companies over the years.
I often see a sad thing happen: the very best coders become architects.
It’s a pay raise and often a death sentence for those who love to get their hands dirty with code.
The architects get to attend meetings, write on white boards, do a few UML diagrams, and do code reviews.
While some architects like this kind of work, others pine for the days of code slinging.
There is good news for those architects who like to code: Scala offers you a chance to get your hands dirty, because you can express a lot of complex coding rules using Scala’s type system.
You can be the architect, go to meetings, and use Scala rather than UML to express high-level concepts and complex relationships; and best of all, you don’t have to worry about round trips because all the code is Scala.
So, let’s see how different team members fit into different parts of a project with Scala.
A senior developer with a good sense of the business domain and the coding conventions may do well to design domain-specific languages for use by other team members.
DSLs deliver value because they allow the program to more closely match the language that business people use to describe solutions in a given domain.
As we’ve seen with Scala’s parser combinator library as well as Specs, Scala makes it easy to create code that corresponds to the language a human would use to describe the answer to a problem.
Putting senior developers on projects to design DSLs allows them to model the language of solutions beyond OOP’s “is a” and “has a” to relations and actions that object can take on each other.
Junior developers and folks more comfortable with scripting languages (Ruby, Python, Groovy) are well suited to be library consumers.
They can assemble applications out of the DSLs created by the senior developers based on the rules and structures defined by the architects.
These developers should have a coding experience that is not dissimilar from that of writing Ruby or Python code.
At the same time, the junior developers who have grown up with Java have the comfort of Scala’s static type system.
Business people should be able to view the code written using the DSLs as well as the BDD-style tests and understand how the system works.
It should be a goal to have business people involved from time to time in code reviews.
If your business people understand the code, and they should if the DSLs are well crafted, they will be able to give direct feedback as to the program reflecting the business rules.
Best Practices It took me a long time, more than 18 months, until I felt like I was good at Scala.
Most programming languages come easily to me, but Scala was not just a programming language; it was a new way of thinking and reasoning about programming.
Perhaps if I had taken Lisp courses in college or had formal training in ML-derived languages, Scala’s learning curve would not have been so bad for me.
That did not deter me from trying to write Scala code, nor did it deter me from working on the Lift Web Framework.
The first step in writing Scala is not being afraid of the fact that Scala’s going to warp your brain.
The next step in writing Scala is accepting that your code is going to look like Java, Ruby, Python, whatever code for a while.
It will take you time and effort and more time to code Scala using the idioms in this book.
It will take you time to design code that fits into Scala paradigms and to discover and devise paradigms of your own.
In this section, I’m going to talk about coding activities and questions and styles that you can apply to your code as well as suggest to team members when you’re doing code reviews on this code.
So, write that Java-style code in Scala and then apply the concepts below and see how your code changes and how your thought patterns change.
The first thing to do is ban null from any of your code.
You should never return null from a method, ever, ever, ever.
If you are calling Java libraries that may return null or throw an exception because of input problems, convert these to Options.
In the case of uninitialized instance variables, either assign a default value that is not null or, if there’s a code path where the.
If there’s no logical value that can be returned from a method given legal input, the return type should be Option.
The get method should never be called on an Option.
Instead, Options should be unpacked using map/flatMap, the for comprehension, or pattern matching.
The first benefit using Option is the obvious avoidance of null pointer exceptions.
The use of Option and the transformative nature of mapping Options leads to a different style of approaching your code.
The impact of repeatedly using immutable data structures will move your brain toward the functional side.
Data structures in Java are instantiated, set, and passed along to other methods.
The first thing to do is use immutable collections classes by default.
If you choose to use a mutable collections class, make a comment in your code as to why you chose mutability.
For example, in a method where you are building a List, using ListBuffer is more efficient, but don’t return the ListBuffer, return the List.
This is like using a StringBuilder in Java but ultimately returning a String.
So, use immutable collections by default, and use mutable data structures with a justification.
Use vals by default, and only use vars if there is a good reason that is justified by a comment.
In your methods, use val unless there’s going to be a significant performance hit.
Let’s look at a mutable implementation of a method that consumes all the lines from a BufferedReader:
The above code is readable but uses a couple of vars.
Let’s rewrite the code without vars and see how we can use tail recursion to give us a while loop:
We defined the doRead method, which reads a line of input.
If the line is null, we return the accumulated List.
If the line is non-null, we call doRead with the accumulated List.
The Scala compiler will optimize the tail call into a while loop, and there will only be one stack frame created no matter how many lines are read.
The last line of read2 calls doRead with Nil as the seed value for the accumulator.
Using vals in your code makes you think about alternative, immutable, functional code.
This small example demonstrates that removing vars leads to refactoring.
The new coding patterns lead to a shift in your approach.
This shift in approach will yield transformative code that has fewer defects and is easier to maintain.
See whether you can code methods in a single line.
If not a single line, see whether you can code them in a single statement.
If you keep methods short, then the logic in each method is more obvious when you or someone else looks at the code.
Let’s see how the previous code can be made into single statements:
When I code Scala, I try not to have a curly brace around my method body.
If I can’t write my code this way, I have to justify to myself why my method should exceed a single statement.
Keeping methods short allows you to encapsulate a single piece of logic in a method and have methods that build upon each other.
It also allows you to easily understand the logic in the method.
In the beginning, you can write your Scala code as you would your Java code.
While you can argue that this is too terse, we can refactor another way:
Either of the refactoring choices you make, the business logic of your code is a lot more visible.
The refactoring also moves you toward thinking about the transformations in your code rather than the looping constructs in your code.
In the previous example, we composed filterValid and sortPeopleByAge into a single function.
However, the composition of the two functions results in code that reads like what it does.
This makes testing easier and makes the code more readable.
Next we compose a new function by chaining the two functions together.
Functional composition is a later stage Scala-ism, but it results naturally from making methods into single statements.
In Chapter 7, we explored how Scala’s traits can be composed into powerful, flexible classes that are more type-safe than Java classes.
As you evolve your Scala coding skills and begin to refactor classes rather than methods, start looking for common methods across your interfaces and traits.
Soon, you’ll likely find that many of your classes have little in them other than the logic that is specific to that class and the vals that are needed to evaluate that logic.
Once you reach this level in your coding, you will likely find that your traits are polymorphic, that your traits represent logic that can be applied to a contained type, and then you can feel secure that your mind has completely warped into thinking Scala.
Once you’re thinking Scala or thinking that you’re thinking Scala, you might want to go.
The next section provides some talking points for selling Scala.
It gives you the benefits of my experience selling new technologies in organizations.
Please keep in mind that “because it’s cool” is not a justification for an organization to adopt a new technology.
However, it’s pretty safe to say that most organizations want to make their developers happier and more productive, and Scala provides a great way to achieve those goals.
Selling Scala in Your Organization So, you’re convinced that Scala is the right language for writing code.
You’ve done a few Skunk Works projects and gotten a few team members on board with Scala.
There will likely be people in your organization who oppose change and are fearful of new things.
In this section, I’m going to talk about techniques you might try and arguments you might use to get Scala into your organization.
One interesting technique that I’ve heard about for selling an organization on Scala is to start asking people to write tests using Specs rather than JUnit or TestNG.
Because this is not “production code,” there’s less organizational resistance to this idea.
Further, because tests are not production code, the operations guys don’t have to worry about tests in Scala.
There’s no credible argument that somehow Scala-based tests would fail to execute correctly.
So, propose that you and a couple of team members write BDD tests in Scala.
The tests will run just fine alongside your existing Java tests with the existing test harnesses.
But you’ll give other developers a chance to use Scala, and you’ll give the business people and management folks a chance to see the readability differences between the Java-based tests and the Scala-based tests.
Such projects often have a short life span and are viewed as disposable.
If you succeed and then leave the company, the worst case is that the whole thing gets thrown away and rewritten in Java or something else.
Pitching Scala for the back-end project should be a pretty simple sell, and ultimately it gives you the opportunity to show your coworkers and management the benefits of Scala while easing their concerns about how Scala runs and integrates with Java code.
I’ve been a user of leading-edge technology for my whole career.
It’s only been in the last few years that developers have discovered the AppKit for OS X and iPhone development.
I was an early user of WebLogic and ran the first Java-only high-volume site on the Internet.
I was the one who led the charge for using Java.
I have been an early adopter of a lot of technologies that are now part of the mainstream.10
It is possible that someone who wants to block the adoption of something new will escalate the issue to the CEO or even the board level.
I had an interesting dinner with a board member one time because a team member escalated up to the board the decision to move to .NET and managed code.
One board member had written some Commodore 64 code back in the day but was a business and deal guy.
More than half the meal was spent explaining garbage collection, with the board member insisting that reference counting was really the only sure way to do managed memory.
The important thing for you is to be prepared to answer any question about Scala.
To be fair, I’ve had my share of bad calls, too.
On the other hand, if you say, “Scala has complete IDE support, so it will work with our existing tool chain,” it’s likely that you will lose credibility because as of this writing, Scala IDE support is not on par with Java IDE support.
Some people will raise the specter of the “operational characteristics” of Scala code.
Because Scala code compiles down to JVM bytecode, the operational characteristics of Scala code are no different than Java code, and stack traces in Scala or mixed Scala and Java code look just like stack traces in Java code.
Over the last 18 months, as I’ve sold a lot of Scala, I’ve received a lot of questions.
Q: If you build this project in Scala and/or Lift, who else can maintain it? A: The Scala and Lift communities have thousands of members, are growing, and contain a number of people actively seeking Scala- and Lift-related jobs and consulting.
Q: What does Lift give us? A: A much faster time to market with collaborative applications than anything else out there.
Q: Why not use Rails, which has great developer productivity? A: Rails is great from person-to-computer applications, but when you’re building a chat app or something that’s person-to-person collaborative, Lift’s Comet11 support is much more effective than that of Rails.
Plus, if you have to scale your app to hundreds of users simultaneously using your app, you can do it on a single box with Lift, because the JVM gives great operational benefits.
Q: Why not write it in Java to get the operational benefits of Java? A: Prototyping is hard.
Until you know what you want, you need to be agile.
Choose one of those to do prototyping, and then port to Java if there’s a reason to.
The same guy who wrote the program (javac) that converts Java to JVM bytecode wrote the program that converts Scala to JVM bytecode.
There’s no one on this planet who could make a more compatible language than Martin Odersky.
My experience with building Buy a Feature and other Innovation Games for Enthiosys has yielded a lot of useful data.
Buy a Feature went through prototyping, revisions, and all the normal growth that software goes through.
Yeah, it still needs more, but that’s the nature of software versions.
Bringing the new developers on board was not materially different than when I hired a bunch of Java developers and asked them to write C# code.
There are new tools, new idioms, new libraries, but the learning curve was fairly smooth.
One of the customers of Buy a Feature wanted it integrated into their larger, Java-powered web portal along with two other systems.
The customer asked, “Where’s the Scala part?” I answered, “It’s in this JAR file.” He said, “But I looked at the bytecode and it’s just Java.” I answered, “It’s Scala, but it compiles down to Java bytecode, and it runs in a Java debugger, and you can’t tell the difference.” He said, “You’re right.”
So to this customer’s JVM, the Scala and Lift code looks, smells, and tastes just like Java code.
Okay, but with each set of people I talk to, I hear a similar variation about the “operational risks” of using Scala.
So, find a Ruby programmer who knows some Java libraries, or find a Java programmer who’s done some moonlighting with Rails or Python or JavaScript, and you’ve got a developer who can pick up Scala in a week and be very productive with Scala in two months.
Even with the limitation of weak IDE support, head-to-head people can write Scala code two to ten times faster than they can write Java code, and maintaining Scala code is much easier because of Scala’s strong type system and code conciseness.
You can make the assertion that at the operational level, Scala code and Java code are indistinguishable.
I wrote a Scala program and compiled it with -g:vars (put all the symbols in the class file), started the program under jdb (the Java Debugger) and set a break point.
My code worked without any fancy footwork inside of the standard Java Debugger.
The text of the line that I was on and the variables in the local scope were all there, just as if it was a Java program.
Scala code looks and smells and tastes to the JVM just like Java code.
A long time ago, when Java was Oak and it was being designed as a way to distribute untrusted code into set-top boxes (and later browsers), the rules defining how a program executed and what were the means of the instruction set (bytecodes) was super-important.
For example, the casting operation in Java compiles down to a bytecode that checks that the class can actually be cast to the right thing and the verifier ensures that there’s no code path that could put an unchecked value into a variable.
Put another way, there’s no way to write verifiable bytecode that can put a reference to a non-String into a variable that’s defined as a String.
It’s not just at the compiler level but at the actual Virtual Machine level that object typing is enforced.
Put another way, there was only one thing you could write in Java bytecode that you could not write in Java source code (it has to do with calling super in a constructor)
One of the things that inner classes introduced was access to private instance variables by the inner class.
This was done without violating the JVM’s enforcement of the privacy of private variables by creating accessor methods that were compiler-enforced (but not JVM-enforced) ways for the anonymous classes to access private variables.
But the horse was out of the barn at this point anyway, because 1.1 brought us reflection, and private was no longer private.
If we were writing code for an untrusted world, we’d care a lot more about the semantics of the source code being enforced by the execution environment.
So, there have been no new JVM instructions since Java was released.
The JVM is perhaps the best-specified piece of software this side of ADA-based military projects.
The information that a class file needs to provide to the JVM for line numbers, variable names, and so on, is very clearly specified.
Because the JVM has a limited instruction set and the type of each item on the stack and of each instance variable in a class is known and verified when the class loads, the debugging information works for anything that compiles down to Java bytecode and has semantics of named local variables and named instance variables.
Scala shares these semantics with Java, and that’s why the Scala compiler can compile bytecode that has the appropriate debugging information so that it “just works” with jdb.
And, just to be clear, jdb uses the standard, well-documented interface into the JVM to do debugging, and every other IDE for the JVM uses this same interface.
That means that an IDE that compiles Scala can also hook into the JVM and debug Scala.
The Scala compiler generates bytecode that is nearly identical to the Java compiler.
In fact, that you can decompile Scala code and wind up with readable Java code, with the exception of certain constructor operations.
To the JVM, Scala code and Java code are indistinguishable.
The only difference is that there’s a single extra library file to support Scala.
Now, in most software projects, you don’t have CEOs and board members and everybody’s grandmother asking what libraries you’re using.
In fact, in every project I’ve stepped into, there have been at least two libraries that the senior developers did not add but somehow got introduced into the mix.
I believe in library audits to make sure there’s no license violations in the library mix.
So, in the normal course of business, libraries are added to projects all the time.
I can tell you to a 100 percent degree of certainty that there are libraries in that mix that will not pass the “Is the company that supports them going to be around in five years?” test.
Sure, memcached will be around in five years, and most of the memcached clients will not.
Making the choice to use Scala should be a deliberate, deliberated, well-reasoned choice.
It has to do with developer productivity, both to build the initial product and to maintain the product through a two-to-five-year life cycle.
Recruiting team members who can do Scala may be a challenge.
Standardizing on a development environment may be a challenge as the Scala IDE support is immature.
But there’s always emacs, vi, jEdit and TextMate, which work just fine.
These are all people challenges and all localized to recruiting and development and management thereof.
The only rational parts of the debate are the trade-off between recruiting and organizing the team and the benefits to be gained from Scala.
Bottom line: to anyone other than the folks with hands in the code and the folks who have to recruit and manage them, “For all you know, it’s just another Java library.”
If Scala looks like Java to the JVM, why shouldn’t a company stick with Java? Put another way, if there’s nothing that can be written in Scala that can’t be written in Java, why use Scala? These are important questions, and they are the kind of strategic questions that you will need to answer when selling Scala into your organization.
Excellent default libraries for doing concurrent programming (immutable data structures and Actors)
So when I’m coding in Scala, I know that the previous method invocation is going to send an asynchronous message to my gameBoard.
It’s got the benefits of Hungarian Notation12 without the verbosity or ugliness.
This call syntax also means that the new programmer isn’t going to put a call like this inside a loop.
How many times have we all seen the junior developer put a remote method invocation (RMI) call inside a loop and wonder why performance sucks?
This means that I can pass an immutable data structure to other threads, and they can use that data without synchronization.
There’s no need to worry about concurrent access to data because the data is not going to change out from under you.
Scala’s Actor library (which is implemented entirely as a library and has no compiler support) sits on top of Doug Lea’s Fork-Join library.
It turns out that this model works very, very well for games and for asynchronous browser-based applications.
Yes, a fair number of Python game applications are based on the Twisted event library.
It turns out that the event-based semantics are very similar for both Actors and Twisted, so it’s no surprise that they are both choices for multiplayer games.
There’s a French company building a massive multiplayer online game [MMO] in Scala.
They only consume stack/thread resources when there’s a message for the Actor to process.
This is very handy as you can have millions of Actors hanging out waiting to do something, and they only consume.
Additionally, it’s possible to write a custom scheduler so that you can have all one million Actors processing messages, but they only consume a bounded number of threads.
Finally, Scala’s pattern matching provides a powerful way to compose event handlers (even dynamically)
So, there’s nothing I can do in Scala that I can’t do in Java, with enough time.
There’s nothing I can do in Java that I can’t do in C.
However, Scala lends itself to much more developer- and machine-efficient patterns.
In fact, Scala gives me the coding efficiency and flexibility that I had with Ruby along with the type safety and performance characteristics of Java and the JVM.
Buy a Feature contains 15,000 Scala lines of code (LoC) and represents about one manyear of effort.
So, if I were to tell you that two people wrote 2,300 Java classes in a year or two, you’d tell me I was nuts.
But the fact is that the complexity embodied in the simple statement represents the complexity associated with many Java classes.
Scala is to Java as C++ is to assembly language.
In Scala, I can concisely express far more business logic, that is also far more type-safe, in a single line than in Java.
This means that the developer productivity is much higher in Scala than in Java.
That means that state change on the server side is immediately pushed to the browser.
Lift’s Comet support makes chat applications, multiuser games, and other browser-based applications trivial to write.
Here’s the entire code required to write a multi-user chat application in Lift:
There’s nothing magic about Lift’s Comet support, but it would be much harder to do in Java.
Lift has CometActors, which represent server-side state in a section of browser real estate.
The real estate is demarcated by a <span> with a GUID.
All Lift pages are rendered using Scala’s built-in XML support.
After the render phase, but before the page is streamed to the browser, Lift looks through the page to see whether the page contains HTML that points to any CometActors.
If yes, Lift rewrites the XML and inserts JavaScript to do Comet-style long polling.
After the page is loaded, the browser opens an XMLHTTPRequest to the server with the GUIDs of all the Comet components on the page along with the version number of each of the Comet components.
The server receives the request and creates an Actor for each GUID, and each Actor registers itself as a listener with the appropriate Comet component.
The registration includes the version number of the component as contained by the browser.
If the servlet is running in Jetty or a Servlet 3.0 container, Lift automatically invokes the container’s “continuation” mechanism so that the pending request is consuming no threads.
It is consuming an NIO socket, and it’s also consuming one Actor per Comet component on the page.
When the Comet component receives the listener registration, it compares the version number with the current version number.
If they differ, the Comet component immediately sends the Actor a message containing the diffs between the version that the Actor/ browser has and the current version of the Comet component.
If the version number is current, the Comet component does nothing.
If the Comet component receives a message and updates itself, it notifies the listener of the diff between the old version and the new version of the component.
During the “no changes” phase, the only system resources being consumed are memory and an NIO connection.
When the Actor receives an update from the Comet component or after 110 seconds, the Actor creates a response to the Ajax request.
It then invokes the continuation and sends the response to the browser (either JavaScript containing commands to perform the diffs or a Noop)
The browser executes the JavaScript, waits 100 milliseconds, and restarts the process.
In fact, there is a Comet library that sits on top of Jetty and Dojo that has the same scaling characteristics.
However, the amount of code to implement this scheme in Scala contains roughly the same number of characters as the above description.
I’m sure that would not be the case in Java.
Summary Designing and building complex computer software is a very serious thing.
Our livelihoods, and increasingly our whole society, depend on the stability and flexibility of our interconnected computer systems.
Our cars and our banks and our grocery stores and our hospitals and our police departments all work better because they are interconnected by computer systems.
In this book, I’ve taken a very lighthearted approach to introducing you to the Scala programming language.
I’ve approached the daunting task of learning a new language and possibly a new set of programming patterns in a fun way.
I hope that you have enjoyed the journey and are already thinking about new ways to reason about designing software and writing code.
I want to end this journey by talking a bit about architecture.
Architecture is very important in overall system performance and team performance.
Scala has a lot of the tools that allow for much better architectural decisions.
It’s kind of a Zen and the Art of Motorcycle Maintenance thing—you use the patterns that your language.
Scala makes it easier for coders to implement architecturally solid designs than does Java or Ruby.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
Created PDF documents can be opened with Acrobat and Adobe Reader 6.0 and later.
