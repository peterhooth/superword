Over 80 recipes to maintain, secure, communicate, test, build, and improve the software development process with Jenkins.
No part of this book may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, without the prior written permission of the publisher, except in the case of brief quotations embedded in critical articles or reviews.
Every effort has been made in the preparation of this book to ensure the accuracy of the information presented.
However, the information contained in this book is sold without warranty, either express or implied.
Neither the author, nor Packt Publishing, and its dealers and distributors will be held liable for any damages caused or alleged to be caused directly or indirectly by this book.
Packt Publishing has endeavored to provide trademark information about all of the companies and products mentioned in this book by the appropriate use of capitals.
However, Packt Publishing cannot guarantee the accuracy of this information.
Alan has a degree, two Master's, and a teaching qualification.
He has also co-authored two books about Sakai (http://sakaiproject.org)—a highly successful open source learning management platform used by many millions of students around the world.
In previous incarnations, Alan was a technical writer, an Internet/Linux course writer, a product line development officer, and a teacher.
He likes to get his hands dirty with the building and gluing of systems.
He remains agile by ruining various development and acceptance environments.
Yes, you may pretend you don't know me, but you do.
Finally, I would like to warmly thank the Packt Publishing team, whose consistent behind the scenes effort improved the quality of this book.
Alex Blewitt is a technical architect, working at an investment bank in London.
He has recently won an Eclipse Community Award at EclipseCon 2012 for his involvement with the Eclipse platform over the last decade.
He also writes for InfoQ and has presented at many conferences.
In addition to being an expert in Java, he also develops for the iOS platform, and when the weather's nice, he goes flying.
His blog is at http://alblue.bandlem.com, and he can be reached via @alblue on Twitter.
Florent Delannoy is a French software engineer, now living in New Zealand after graduating with honors from a MSc in Lyon.
Passionate about open source, clean code, and high quality software, he is currently working on one of New Zealand's largest domestic websites with Catalyst I.T.
I would like to thank my family for their support and my colleagues at Catalyst for providing an amazingly talented, open, and supportive workplace.
After spending a number of years running his own web agency, managing the development team, and working for Smith Electric Vehicles on developing its web-based vehicle telematics platform, he currently serves as head developer for an ambitious new start-up: leading the development team and managing the software development processes.
Other publications in which Michael has been involved include Mobile Web Development and Drupal for Education and E-Learning, both of which he acted as technical reviewer for.
Do you need instant solutions to your IT questions? PacktLib is Packt's online digital book library.
Here, you can access, read, and search across Packt's entire library of books.
Why Subscribe? f Fully searchable across every book published by Packt.
Preface Jenkins is a Java-based Continuous Integration (CI) server that supports the discovery of defects early in the software cycle.
Thanks to over 400 plugins, Jenkins communicates with many types of systems, building and triggering a wide variety of tests.
Defects do not only occur in the code but also appear in the naming conventions, documentation, how the software is designed, build scripts, the process of deploying the software to servers, and so on.
Continuous integration forces the defects to emerge early, rather than waiting for software to be fully produced.
If defects are caught in the later stages of the software development lifecycle, the process will be more expensive.
The cost of repair radically increases as soon as the bugs escape to production.
Effective use of a CI server, such as Jenkins, could be the difference between enjoying a holiday and working unplanned hours to heroically save the day.
As you can imagine, in my day job as a Senior Developer with aspirations to Quality Assurance, I like long boring days, at least for mission-critical production environments.
Jenkins can automate the building of software regularly, and trigger tests pulling in the results and failing based on defined criteria.
Failing early through build failure lowers the costs, increases confidence in the software produced, and has the potential to morph subjective processes into an aggressive metrics-based process that the development team feels is unbiased.
Jenkins can use Amazon services or an Application Service Provider (ASP), such as CloudBees (http://www.cloudbees.com/)
Jenkins plugin framework has clear interfaces that are easy to extend.
The framework uses Xstream for persisting configuration information as XML (http://xstream.codehaus.org/) and Jelly for the creation of parts of the GUI (http://commons.apache.org/jelly/)
Many administrators like to use Ant, Bash, or Perl scripts.
There is also a highly stable long-term support release for the more conservative.
Jenkins is not just a continual integration server but also a vibrant and highly active community.
First, read the postings, and as you get to understand what is needed, participate in the discussions.
Consistently reading the lists will generate many opportunities to collaborate.
What this book covers Chapter 1, Maintaining Jenkins, describes common maintenance tasks, such as backing up and monitoring.
Chapter 2, Enhancing Security, details how to secure Jenkins and the value of enabling Single Sign On (SSO)
Chapter 3, Building Software, explores the relationship between Jenkins builds and the Maven pom.xml file.
Chapter 4, Communicating Through Jenkins, reviews effective communication strategies for different target audiences, from developers and project managers to the wider public.
Chapter 5, Using Metrics to Improve Quality, explores the use of source code metrics.
Chapter 6, Testing Remotely, details approaches to set up and run remote stress and functional tests.
Chapter 7, Exploring Plugins, reviews a series of interesting plugins and shows how easy it is to create your first plugin.
Appendix, Processes That Improve Quality, discusses how the recipes in this book support quality processes.
What you need for this book This book assumes you have a running an instance of Jenkins.
In order to run the recipes provided in the book, you need to have the following software:
There are numerous ways to install Jenkins: as a Windows service, using the repository management features of Linux such as apt and yum, using Java Web Start, or running directly from a WAR file.
It is up to you to choose the approach that you feel is most comfortable.
However, you could run Jenkins from a WAR file using HTTPS from the command line, pointing to a custom directory.
If any experiments go astray, then you can simply point to another directory and start fresh.
To use this approach, first set the environment variable JENKINS_HOME to the directory you wish Jenkins to run under.
The http port is turned off by setting httpPort=-1, and the terminal will display logging information.
For a more advanced recipe describing how to set up a virtual image under VirtualBox with Jenkins, you can use the Using a sacrificial Jenkins instance recipe in Chapter 1, Maintaining Jenkins.
Who this book is for This book is for Java developers, software architects, technical project managers, build managers, and development or QA engineers.
A basic understanding of the Software Development Life Cycle, some elementary web development knowledge, and basic application server concepts are expected to be known.
Conventions In this book, you will find a number of styles of text that distinguish between different kinds of information.
Here are some examples of these styles and an explanation of their meaning.
Code words in text are shown as follows: "On the host OS, create a directory named workspacej."
When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:
Words that you see on the screen, in menus or dialog boxes for example, appear in the text like this: "Within the VirtualBox, right-click on the Ubuntu image, selecting properties."
Warnings or important notes appear in a box like this.
Let us know what you think about this book—what you liked or may have disliked.
Reader feedback is important for us to develop titles that you really get the most out of.
Customer support Now that you are the proud owner of a Packt book, we have a number of things to help you to get the most from your purchase.
Downloading the example code You can download the example code files for all Packt books you have purchased from your account at http://www.packtpub.com.
If you purchased this book elsewhere, you can visit http://www.packtpub.com/support and register to have the files e-mailed directly to you.
Errata Although we have taken every care to ensure the accuracy of our content, mistakes do happen.
If you find a mistake in one of our books—maybe a mistake in the text or the code—we would be grateful if you would report this to us.
By doing so, you can save other readers from frustration and help us improve subsequent versions of this book.
If you find any errata, please report them by visiting http://www.packtpub.com/support, selecting your book, clicking on the errata submission form link, and entering the details of your errata.
Once your errata are verified, your submission will be accepted and the errata will be uploaded to our website, or added to any list of existing errata, under the Errata section of that title.
Piracy Piracy of copyright material on the Internet is an ongoing problem across all media.
At Packt, we take the protection of our copyright and licenses very seriously.
If you come across any illegal copies of our works, in any form, on the Internet, please provide us with the location address or website name immediately so that we can pursue a remedy.
We appreciate your help in protecting our authors and our ability to bring you valuable content.
This chapter provides recipes that help you to maintain the health of your Jenkins server.
Introduction Jenkins is feature-rich and is vastly extendable through plugins.
Jenkins talks with numerous external systems, and its Jobs work with many diverse technologies.
Proper maintenance lowers the risk of failures, a few of which are listed as follows:
In this situation, it is easy for you to accidentally add new versions of the plugins with new defects.
There have been a number of times when the plugin suddenly stopped working, while it was being upgraded.
To combat the risk of plugin exceptions, consider using a sacrificial Jenkins instance before releasing to a critical system.
Disc costs have decreased tremendously, but disk usage equates to longer backup times and more communication from the slave to the master.
To minimize the risk of disk overflowing, you will need to consider your backup and restore policy and the associated build retention policy expressed in the advanced options of Jobs.
Consider using well-defined locations for your scripts, and a scripts repository managed through a plugin.
The pace of adoption of Jenkins within an organization can be breathtaking.
Without a consistent policy, your teams will introduce lots of plugins and lots of ways of performing the same work.
Conventions improve the consistency and readability of Jobs and thus decrease the maintenance.
The recipes in this chapter are designed to address the risks mentioned.
If you have comments or improvements, feel free to contact me through my Packt Publishing e-mail address, or it would even be better if you still add tutorials to the Jenkins community wiki.
Using a sacrificial Jenkins instance Continuous Integration (CI) servers are critical in the creation of deterministic release cycles.
Any long-term instability in the CI server will reflect in the milestones of your project plans.
Incremental upgrading is addictive and mostly straightforward, but should be seen in the light of the Jenkins wider role.
Before the release of plugins into the world of your main development cycle, it is worth aggressively deploying to a sacrificial Jenkins instance, and then sitting back and letting the system run the Jobs.
This gives you enough time to react to any minor defects found.
There are many ways to set up a sacrificial instance.
One is to use a virtual image of Ubuntu and share the workspace with the Host server (the server that the virtual machine runs on)
This is excellent for short-term experiments that have a high risk of failure.
This may include your home desktop or a hard core server.
You can also test one version of Jenkins against different workspaces, with different plugin combinations.
The community manages support of the enterprise through the release of a long-term supported version of Jenkins.
This stable release version is older than the newest version and thus misses out on some of the newer features.
This recipe details the use of VirtualBox (http://www.virtualbox.org/), an open source virtual image player with a guest Debian OS image.
The virtual image will mount a directory on the host server.
When the guest OS is restarted, it will automatically run against the shared directory.
Throughout the rest of this book, recipes will be cited using Ubuntu as the example OS.
Getting ready You will need to download and install VirtualBox.
Note that the newer images will be available at the time of reading.
Feel free to try the most modern version; it is probable that the recipes might still work.
Browse and select the unpacked VDI image by clicking on the folder icon.
Start the virtual image by clicking on the Start icon.
Log in to the guest OS with username and password as Ubuntu reverse.
Update the OS in case of security patches (this may take some time depending on bandwidth): apt-get update.
Within the VirtualBox, right-click on the Ubuntu image, selecting properties.
Update the Folder Path to point to the directory that you have previously created.
In the following screenshot, the folder was created under my home directory.
On the Guest OS, run a web browser, and visit http://localhost:8080
You will see a locally running instance of Jenkins, ready for your experiments.
Your recipe first installs a virtual image of Ubuntu, changes the password so that it is harder for others to log in, and updates the guest OS for security patches.
The Jenkins repository is added to the list of known repositories in the Guest OS.
The key is used to verify that the packages, which are automatically downloaded, belong to a repository that you have agreed to trust.
Once the trust is enabled, you can install through standard package management the most current version of Jenkins, and aggressively update it later.
You need to install the additional code called guest additions so that VirtualBox can share folders from the host.
Warning: If you forget to add the DKMS module, then sharing folders will fail without any visual warning.
Next, you added a shared folder to the guest OS from the VirtualBox GUI, and finally you had restarted VirtualBox and the guest OS to guarantee that the system was in a fully-configured and correctly initialized state.
There are a number of options for configuring VirtualBox with networking.
Backing up and restoring A core task for the smooth running of Jenkins is the scheduled backing up of its workspace.
Not necessarily backing up all the artifacts, but at least the Jenkins configuration and the testing history are recorded by individual plugins.
There are a wide range of stories on this subject.
My favorite (and I won't name the well-known company involved) is the one in which somewhere in the early 70S, a company brought a very expensive piece of software and a tape backup facility to back up all the marketing results being harvested through their mainframes.
Every night, a tape needed to be moved into a specific slot.
For a year, the worker would professionally fulfill the task.
One day, a failure occurred and a backup was required.
The reason was that the worker also needed to press the record button every night, but this was not part of the tasks assigned to him.
There was a failure to regularly test the restore process.
Hence, learning the lessons of history, this recipe describes both backup and restore.
The rapid evolution of plugins, and the validity of recipes Plugins improve aggressively, and you may need to update them weekly.
But, it's quite likely that extra options will be added, increasing the variables that you input in the GUI.
Therefore, the screen grabs shown in this book may be slightly different from the most modern version, but the recipes should remain intact.
Getting ready Create a directory with read, write permissions for Jenkins, and install the ThinBackup plugin.
Murphy as a friend You should assume the worst for all of the recipes in this book: aliens attacking, coffee on motherboard, cat eats cable, cable eats cat.
Please make sure that you are using a sacrificial Jenkins instance.
Click on the ThinBackup link in the Manage Jenkins page.
Click on the link to Settings by the Toolset icon.
A select box restore backup form will be shown with the dates of the backups.
Differential backups contain only files that have been modified since the last full backup.
The plugin looks at the last modified date to work out which files need to be backed up.
The process can sometimes go wrong if another process changes the last modified date, without actually changing the content of the files.
As we are cleaning up the differentials through the option Clean up differential backups, we will get to around 54 full backups, roughly a year of archives before cleaning up the oldest.
Backup build results were selected, as we assume that we are doing the cleaning within the Job.
Under these conditions, the build results should not take much space.
However, in case of misconfiguration, you should monitor the archive for disc usage.
Cleaning up differential backups saves you doing the clean-up work by hand.
Moving old backups to ZIP files saves space, but might temporarily slow down your Jenkins server.
Restore is a question of returning to the restore menu and choosing the date.
I can't repeat this enough; you should practice a restore occasionally to avoid embarrassment.
Full backups are the safest as they restore to a known state.
Therefore, don't generate too many differential backups between full backups; that's a false economy.
Here are a couple more points for you to think about.
Checking for permission errors If there are permission issues, the plugin fails silently.
Testing exclude patterns The following Perl script will allow you to test the exclude pattern.
The script will print a list of the excluded files.
You can download the example code files for all Packt books you have purchased from your account at http://www.packtpub.com.
If you purchased this book elsewhere, you can visit http://www.packtpub.
You can find the documentation for the standard Perl module file at:
You may be wondering about the XML files at the top level of the Jenkins workspace.
Each individual Job configuration is contained in a sub-directory with the same name as the Job.
The Job-specific configuration is then stored in config.xml within the sub-directory.
There is a similar situation for the user's directory with one sub-directory per user, with the user information stored in its own config.xml file.
Under a controlled situation, where all the Jenkins servers in your infrastructure have the same plugins and version levels, it is possible for you to test on one sacrificial machine and then push the configuration files to all the other machines.
You can then restart the servers with the Command-Line Interface (CLI)
This recipe familiarizes you with the main XML configuration structure and provides hints about the plugin API, based on the details of the XML.
Getting ready You will need a fresh install of Jenkins with security enabled.
You will not find it unless you have installed the thinBackup plugin.
Replay the recipe Back up and Restoring, and look again.
Jenkins uses Xstream (http://xstream.codehaus.org/) to persist its configuration into a readable XML format.
The XML files in the workspace are configuration files for plugins, tasks, and an assortment of other persisted information.
Security settings and global configuration are set here and reflect changes made through the GUI.
Plugins use the same structure, and the XML values correspond to member values in underlying plugin classes.
The GUI itself is created from XML through the Jelly framework (http://commons.apache.org/jelly/)
By restarting the server, you should be certain that any configuration changes are picked up during the initialization phase.
Turning off security When you are testing new security features, it is easy to lock yourself out of Jenkins.
To get around this problem, modify useSecurity to false in config.xml, and restart Jenkins.
Finding JavaDoc for custom plugin extensions The following line of code is the first line of the thin plugin configuration file thinBackup.
Plugins can extend the functionality of Jenkins, and there may be useful methods exposed for administrative Groovy scripts.
The effects of adding garbage Jenkins is great at recognizing rubbish configuration as long as it is recognizable as a valid XML fragment.
For example, add the following line of code to config.xml:
When you reload the configuration, you will see the following error at the top of the manage Jenkins screen:
Pressing the Manage button will return you to a detailed page of the debug information, including the opportunity to reconcile the data.
From this, you can notice that Jenkins is developer-friendly when reading corrupted configuration that it does not understand.
Reporting overall disc usage Organizations have their own way of dealing with increasing disc usage.
Policy ranges from no policy, depending on ad-hoc human interactions, to the most state of the art software with central reporting facilities.
Most organizations sit between these two extremes with mostly ad-hoc intervention, with some automatic reporting for the more crucial systems.
With minimal effort, you can make Jenkins report disc usage from the GUI, and periodically run Groovy scripts that trigger helpful events.
This recipe highlights the disk usage plugin and uses the recipe as a vehicle to discuss the cost of keeping archives stored within the Jenkins workspace.
The disc usage plugin is the strongest in combination with an early warning system that notifies you when soft or hard disc limits are reached.
The recipe: A Job to warn of disc usage violations through log parsing details a solution.
Both the recipes show that configuring Jenkins requires little effort.
The power of Jenkins is that you can build complex responses out of a series of simple steps and scripts.
Getting ready You will need to install the disc usage plugin.
Press the Disk usage link under the Manage Jenkins page.
After clicking on the Disk Usage link, Jenkins displays a page with each project and the builds and Workspace disc usage summary.
Click on the top of the table to sort the workspace by file usage.
The question is what are you going to do with the information.
It is easy for you to forget a tick box in a build, perhaps an advanced option is enabled where it should not be.
Advanced options can at times be problematic, as they are not displayed directly in the GUI.
You will need to hit the advanced button first, before reviewing.
On a Friday afternoon, this might be one step too far.
Advanced options include artifact retention choices, which you will need to correctly configure to avoid overwhelming disc usage.
In the previous example, the workspace for the Sakai CLE is 2GB.
The size is to do with the Job having its own local Maven repository, as defined by the advanced option Use a private Maven repository.
In this case, there is nothing to be done, as trunk pulls in snapshot JARs, which might cause instability for other projects.
The simple act of being able to sort disc usage points the offending Jobs out to you, ready for further inspection of their advanced configuration.
If you are keeping a large set of artifacts, it is an indicator of a failure of purpose of your use of Jenkins.
Jenkins is the engine that pushes a product through its life cycle.
For example, when a job builds snapshots every day, then you should be pushing the snapshots out to where developers find them most useful.
That is not Jenkins but a Maven repository or a repository manager such as Artifactory (http://www.jfrog.com/products.php), Apache Archiva (http://archiva.apache.org/) or Nexus (http://nexus.sonatype.org/)
These repository managers have significant advantages over dumping to disc.
If you build and use the repository manager as a mirror, then the repository manager will cache the dependencies, and when Job Y asks for the same artifact, the download will be local.
With these considerations in mind, if you are seeing a build-up of artifacts in Jenkins, where they are less accessible and beneficial than deployed to a repository, consider this a signal for the need to upgrade your infrastructure.
Retention policy Jenkins can be a significant consumer of disk space.
In the Job configuration, you can decide to either keep artifacts or remove them automatically after a given period of time.
The issue with removing artifacts is that you will also remove the results from any automatic testing.
Luckily, there is a simple trick for you to avoid this.
When configuring a Job, click on Discard Old Builds, and then the Advanced checkbox, define the Max # of builds to keep with the artifacts.
The artifacts are then removed after the number of builds specified, but the logs and results are kept.
This has one important consequence; you have now allowed the reporting plugins to keep displaying a history of tests even though you have removed the other more disc consuming artifacts.
Scenario: You have been asked to clean up the code removing depreciated Java methods across all the source contained under a Jenkins Jobs; that is a lot of code.
If you miss some residue defects, then you will want the Jenkins build to fail.
What you need is a flexible log parser that can fail or warn about issues found in the build output.
To the rescue: This recipe describes how you can configure a log parsing plugin that spots unwanted patterns in the console output and fails Jobs.
Getting ready You will need to install the Log Parser Plugin as mentioned at:
Create the log_rules directory owned by Jenkins, under the Jenkins workspace.
Add the file named depreciated.rule to the log_rules directory with one line: error /DEPRECATED/
Create a Job with a source code that gives deprecated warnings on compilation.
In the following example, you are using the Roster tool from the Sakai project:
Maven Version: 2.2.1 (or whatever your label is for this version)
Check the Console output (build log) parsing box in the Post-build Actions section of your Job.
Click on the Parsed Console Output link in the left-hand menu.
You will now be able to see the parsed errors.
The global configuration page allows you to add files, each with a set of parsing rules.
The rule file you used is composed of one line: error /DEPRECATED/
If the pattern DEPRECATED (a case-sensitive test) is found in the console output, then the plugin considers this as an error, and the build fails.
More lines to test can be added to the file.
The source code pulled in from Sakai (http://www.sakaiproject.org) contains deprecated method and triggers the pattern.
The rules file has the distinct .rules extension in case you want to write an exclude rule during backups.
Once the plugin is installed, you can choose a Job between the rule files previously created.
This plugin empowers you to periodically scan for the obvious link and adapt to the new circumstances.
You should consider sweeping systematically through a series of rule files failing suspect builds, until a full clean-up to in-house style has taken place.
Two other examples of the common log patterns that are an issue, but do not normally fail a build are:
Luckily, the process will leave a warning in the console output.
A Job to warn about the disc usage violations through log parsing.
The disk usage plugin is unlikely to fulfill all of your disc maintenance requirements.
This recipe will show how you can strengthen disc monitoring by adding a custom Perl script to warn about the disc usage violations.
The script will generate two alerts: a hard error when the disc usage is above an acceptable level, and a softer warning when the disc is getting near to that limit.
Using Perl is typical for a Jenkins Job, as Jenkins plays well and adapts to most environments.
You can expect Perl, Bash, Ant, Maven, and a full range of scripts and binding code to be used in the battle to get the work done.
Getting ready If you have not already done so, create a directory owned by Jenkins under the Jenkins workspace named log_rules.
Also, make sure that the Perl scripting language is installed on your computer and is accessible by Jenkins.
Activestate provides a decent Perl distribution for MAC and Windows (http://www.activestate.com/downloads)
Visit the Manage configuration page for Jenkins, and add a description as DISC_ USAGE to the Console Output section.
Add the following Perl script to a location of choice named disc_limits.pl, making sure that the Jenkins user can read the file.
Modify the $content variable to point to the Jenkins workspace.
Under the build section, add the build Step / Execute Shell.
Check the Console output (build log) parsing in the Post-build Actions section.
Under build history on the left-hand, select the trend link.
You can now view trend reports and see a timeline of success and failure.
The Perl script expects two command-line inputs: hard and soft limits.
The hard limit is the value in bytes that the disc utilization under the $content directory should not exceed.
The soft limit is a smaller value in bytes that triggers a warning rather than an error.
The warning gives the administrators time to clean up before the hard limit is reached.
The Perl script transverses the Jenkins workspace and counts the size of all the files.
The script calls the method size_summary for each file or directory underneath the workspace.
If the hard limit is less than the content size, then the script generates the log output [HARD_LIMIT ERROR]
The parsing rules will pick this up and fail the build.
If the soft limit is reached, then the script will generate the output [SOFT_LIMIT WARN]
The plugin will spot this due to the rule warn /SOFT_LIMIT/, and then signal a Job warn.
You can now utilize all of the installed features at your disposal.
The Job can be scheduled, e-mails can be sent out on failure.
You can also tweet, add entries to Google calendar, trigger extra events, for example disc-cleaning builds, and so on.
You are mostly limited by your imagination and 21st century technologies.
If you are a Jenkins administrator, then it is your role to keep an eye on the ebb and flow of the build activity within your infrastructure.
Builds can occasionally freeze or break due to non-coding reasons.
If a build fails, and this is related to infrastructural issues, then you will need to be warned quickly.
Chapter 5, Communicating Through Jenkins is dedicated to the different approaches for different audiences.
From e-mail, Twitter, and speaking servers, you can choose a wide range of prods, kicks, shouts, and pings.
I could even imagine a Google summer of code project with a remotely controlled buggy moving to the sleeping administrator and then toting.
This recipe is one of the more pleasant ways for you to be reached.
You will pull in the Jenkins RSS feeds using a Firefox add-on.
This allows you to view the build process, while going about your everyday business.
Getting ready You will need Firefox 5 or later installed on your computer and an account on at least one Jenkins instance, with a history of running Jobs.
A plug for the developers If you like the add-on and want more features in the future, then it is enlightened in the  self-interest to donate a few bucks at the add-on author's website.
Select the Firefox tab at the top-left hand side of the browser.
In the Search box (top-right) with the title Search all add-ons, search for Jenkins.
Click on the Install button for the Jenkins Build monitor.
Select the Firefox tab at the top left-hand side of the browser.
Now, at the bottom right-hand side of Firefox, you will see a small Jenkins icon.
Add a recognizable, but short, name for your Jenkins instance.
Add a URL using the following structure for Feed URL: http://host:port/rssAll e.g.: http://localhost:8080/rssAll.
Plugin test Server of the Feed URL(s) displayed, and a health icon.
If you hover your mouse over the name, then a more detailed status information will be displayed.
Jenkins provides RSS feeds to make its status information accessible to a wide variety of tools.
The Firefox add-on polls the configured feed and displays the information in a digestible format.
To configure for a specific crucial Job, you will need to use the following structure: http://host:port/job/job name/rssAll.
To view only the build failures, replace rssAll with rssFailed.
To view only the last build, replace rssAll with rssLatest.
If security is enabled on your Jenkins instances, then most of your RSS feeds will be password-protected.
To add a password, you will need to modify the Feed URL to the following structure:
Warning The negative aspect of using this add-on is that any Feed URL password is displayed in plain text during editing.
Monitoring through JavaMelody JavaMelody (http://code.google.com/p/javamelody/) is an open source project that provides comprehensive monitoring.
The Jenkins plugin monitors both the Master instance of Jenkins and also its nodes.
The plugin provides a detailed wealth of the important information.
You can view the evolution charts ranging from a day or weeks to months of the main quantities, such as the CPU or the memory.
Evolution charts are very good at pinpointing the scheduled Jobs that are resource-hungry.
JavaMelody allows you to keep a pulse on the incremental degradation of resources.
It eases the writing of reports by exporting statistics in a PDF format.
Containing over 25 years of human effort, JavaMelody is feature-rich.
If you find this plugin useful, consider contributing back to either the plugin or the core JavaMelody project.
Getting ready You will need to have installed the JavaMelody plugin.
Read the online help at the URL http://host:port/monitoring?resource=help/help.html, where the host and port point to your server.
Review the monitoring of the node processes directly, by visiting http://host:port/monitoring/nodes.
JavaMelody has the advantage of running as the Jenkins user and can gain access to all the relevant metrics.
Its main disadvantage is that it runs as part of the server and will stop monitoring as soon as there is a failure.
Because of this disadvantage, you should consider JavaMelody as part of the monitoring solution and not the whole.
This section explores the relationship between these issues and the measurements exposed in the plugin.
Troubleshooting with JavaMelody – memory Your Jenkins server can at times have memory issues due to greedy builds, leaky plugins, or some hidden complexity in the infrastructure.
JavaMelody has a comprehensive range of memory measurements, including a heap dump and a memory histogram.
The Java virtual machine divides the memory into various areas, and to clean up, it removes objects that have no references to other objects.
Garbage collection can be CPU-intensive when it is busy, and the nearer you get to full memory, the busier the garbage collection becomes.
To an external monitoring agent ,this looks like a CPU spike that is often difficult to track down.
Just because the garbage collector manages memory, it is also a fallacy to believe that there is no potential for memory leakage in Java.
Memory can be held too long by many common practices, such as custom caches or calls to native libraries.
Slow-burning memory leaks will show up as gentle slopes on the memory-related evolution graphs.
If you suspect that you have a memory leak, then you can get the plugin to force a full garbage collection through the link Execute the garbage collector.
If it is not a memory leak, then the gentle slope will abruptly fall.
Memory issues can also express themselves as large CPU spikes as the garbage collector frantically tries to clean up, but can barely clean enough space.
The garbage collector can also pause the application while comprehensively looking for no longer referenced objects, and cause large response times for web browser requests.
This can be seen through the mean and max times under the Statistics labeled http - 1 day.
Troubleshooting with JavaMelody - painful Jobs You should consider the following points:
If you have scheduled the tasks, keep the heaviest ones separate in time.
Time separation not only evens out load, but also makes finding the problematic build easier through the observation of the evolution charts of JavaMelody.
Also consider spatial separation; if a given node or a labeled set of nodes show problematic issues, then start switching around machine location of Jobs, and view their individual performance characteristics through http://host:port/monitoring/nodes.
A common gotcha is to add the memory to the server, but forget to update the init scripts to allow Jenkins to use more memory.
Programming errors can also be the cause of the frustration.
Don't forget to review JavaMelody's report on the Statistic system error log and Statistic http system errors.
These will show up as periodic patterns in the evolution charts.
Each plugin is simple to configure, but their usefulness to you will grow quicker than the maintenance costs of adding extra plugins.
Keeping a track of the script glue There are negative implications for backing up and especially restoring if maintenance scripts are scattered across the infrastructure.
It is better to keep your scripts in one place, and then run them remotely through the nodes.
Consider placing your scripts under the Master Jenkins home directory.
It would be even better for the community if you can share the lesssensitive scripts online.
Your organization can reap the benefits; the scripts will then get some significant peer review and improvements.
In this recipe, we explore the use of the Scriptler plugin to manage your scripts locally and download useful scripts from an online catalog.
Click on the link on the left-hand side of Remote Script catalogs.
Click on the icon of the floppy disk for getThreadDump.
If the script is not available, then choose another script of your choice.
If the script fails with a message startup failed, then please add a new line between entry.key and for, and the script will then function correctly.
To write a new Groovy script or to upload the one that you have on your local system, click on the Add a new Script link on the left-hand side.
This plugin allows you to easily manage your Groovy scripts, and enforces a standard place for all Jenkins administrators to keep their code, making it easier for you to plan backups and indirectly share knowledge.
The plugin creates a directory named scriptler under the Jenkins workspace and persists the meta information about the files that you have created in the scriptler.xml file.
All the local scripts are contained in the sub-directory scripts.
If enough people use this plugin, then the list of online scripts will radically increase the process of generating a significant library of reusable code.
Therefore, if you have interesting Groovy scripts, then upload them.
You will need to create a new account the first time to log in at: http://scriptlerweb.appspot.com/login.gtpl.
Uploading your scripts allows people to vote on them and to send you feedback.
The free peer review can only improve your scripting skills and increase your recognition in a wider community.
Tasks include moving the Jenkins instances on and offline, triggering builds and running Groovy scripts.
This makes for easy scripting of the most common chores.
In this recipe, you will log on to a Jenkins instance and run a Groovy script that looks for files greater than a certain size, and log off.
You can imagine chaining a second script to the first, to remove the large files found.
At the time of writing this chapter, the interactive Groovy shell was not working from the CLI.
Look at the online help: java -jar _jenkins-cli.jar -s http://host   help.
The command-line output will now mention all the oversize files.
The CLI allows you to work from the command line and perform standard tasks.
Wrapping the CLI in a shell script, such as bash, allows you to script maintenance tasks a large number of Jenkins instances at the same time.
In this case, it reviews X thousand files for oversized artifacts, saving you time that you can better spend on more interesting tasks.
Before performing any commands, you need to first authenticate through the login command.
At the time of writing, there were some issues with the key approach.
Feel free to resort back to the method used in this recipe, which has proven to work stably, though less securely.
The CLI is easily-extendable, and therefore over time, the CLI's command list increases.
It is therefore important that you occasionally check the in-built help.
Global modifications of Jobs with Groovy Jenkins is not only a continuous integration server but also a rich framework with an exposed internal structure available from within the script console.
You can programmatically iterate through the Jobs, plugins, node configuration, and a variety of rich objects.
As the number of Jobs increase, you will notice that scripting becomes more valuable.
For example, imagine that you need to increase custom memory settings across 100 Jobs.
This recipe is a representative example: You will run a script that iterates through all Jobs.
The script then finds one specific Job by its name, and then updates the description of that Job with a random number.
Getting ready Log in to Jenkins with an administrative account.
Within the Manage Jenkins page, click on the Script console link.
Cut and paste the following script into the text area input.
Run the script a second time, and you will notice that the random number in the description has now changed.
If you have no slave instances on your Jenkins master, then no results are returned.
Otherwise, the output will look similar to the following screenshot:
Jenkins has a rich framework, which is exposed to the script console.
The second script iterates through instances of slave objects (http://javadoc.jenkins-ci.org/hudson/slaves/SlaveComputer.htm)
Signaling the need to archive Each development team is unique.
In many organizations, there are one-off tasks that need to be done periodically, for example at the end of each year.
This recipe details a script that checks for the last successful run of any Job, and if the year is different to the current year, then a warning is set at the beginning of the Jobs description.
Thus, hinting to you it is time to perform some action, such as archiving and then deleting.
However, for high value actions, it is worth forcing interceding, letting the Groovy scripts focus your attention.
Getting ready Log in to Jenkins with an administrative account.
Within the Manage Jenkins page, click on the Script console link, and run the following script:
Any project that had its last successful build in another year than this will have the word [ARCHIVE] in red, added at the start of its description.
A warning string is defined, and the current date is stored in now.
Each Job in Jenkins is programmatically iterated through the for statement.
Jenkins has a class to store information about the running of builds.
The current year is compared with the year of the last successful build, and if they are different and the warning string has not already been added to the front of the Job description, then the description is updated.
Javadoc You will find the Job API mentioned at http://javadoc.jenkinsci.org/hudson/model/Job.html and the Run information at http://javadoc.jenkins-ci.org/hudson/model/Run.html.
Before writing your own code, you should review what already exists.
With 300 plugins, Jenkins has a large, freely-available, and openly licensed example code base.
Although in this case the standard API was used, it is well worth reviewing the plugin code base.
If you find any defects while reviewing the plugin code base, please contribute to the community through patches and bug reports.
Introduction In this chapter, we will discuss the security of Jenkins, taking into account that it can live in a rich variety of infrastructures.
The only perfectly secure system is the system that does not exist.
For real services, you will need to pay attention to the different surfaces available to attack.
The primary surfaces of Jenkins are its web-based graphical user interface and its trust relationships with its slave nodes.
A counterbalance is that the developers using the Jenkins frameworks apply well-proven technologies, such as Xstream (http://xstream.codehaus.org/) for configuration persistence and Jelly (http://commons.apache.org/jelly/) for rendering the GUI.
This use of well-known frameworks minimizes the number of lines of supporting code, and the code that is used is well tested, limiting the scope of vulnerabilities.
Another positive is that Jenkins code is freely available for review, and the core community keeps a vigilant eye.
It is unlikely that anyone contributing to a code would deliberately add defects or unexpected license headers.
The first half of this chapter is devoted to the Jenkins environment.
In the second half, you will see how Jenkins fits into the wider infrastructure.
This is useful for when you want to link from Jenkins to other password-protected services such as an organization's internal wiki or code browser.
Just as importantly, CAS can connect behind the scenes to multiple types of authentication providers, such as LDAP, databases, textfiles, and an increasing number of other methods.
This indirectly allows Jenkins to use many logon protocols on top of the ones its plugins already provide.
Security advisories There is an e-mail list and RSS feed for Jenkins-related security advisories.
The purpose of OWASP is to make application security visible.
The Jenkins administrator can do this by default, through the Job description.
It is easy to get the scripts wrong by misconfiguration.
It is quite possible that there is a rare mistake with the storage of passwords in plain text.
It can be a hassle and involves extra costs to obtain a trusted certificate.
You might be tempted to not implement TLS, leaving your packets open.
Jenkins has a large set of plugins written by a motivated, diffuse, and hardworking community.
It is possible, due to the large churn of code, that security defects are inadvertently added.
Examples include leaving passwords in plain text in configuration files or using unsafe rendering that does not remove suspicious JavaScript.
You can find the first type of defect by reviewing the configuration files manually.
The second type is accessible to a wider audience, and thus is more readily crackable.
There are helpful cheat sheets available on the Internet (http://ha.ckers.org/xss.html)
The effort is tedious; automated tests can cover more ground and be scheduled as part of a Jenkins Job.
They publish this document and a wide range of books through http://lulu.com.
At lulu.com, you have free access to the PDF versions of OWASP's documents or you can buy cheap on-demand printed versions.
Getting ready Penetration tests have the potential to damage a running application.
Make sure that you have a backed up copy of your Jenkins workspace; you might have to reinstall.
Please also turn off any enabled security within Jenkins; this allows w3af to freely roam the security surface.
Warning: The Debian package for w3af is older and more unstable than the SourceForge package for Linux.
Therefore, please do not use the apt-get and yum methods of installation, but rather use the downloaded package from SourceForge.
Under the Target: address window, fill in http://localhost:8080/, changing the hostname to suit your environment.
At the end of the scan, the Stop button will change to Clear.
Wait until the scan has finished, and review the results in the Results tab.
It is a pluggable framework with extensions written for different types of attacks.
The profiles define which plugins and their associated configurations you are going to use in the penetration test.
You first attack using the OWASP_TOP10 profile, and then attack again with a fuller set of plugins.
Depending on the plugin, security issues that do not exist are occasionally flagged.
You will need to verify by hand any issues mentioned.
At the time of writing, no significant defects were found using this approach.
However, the tool pointed out slow links and generated server-side exceptions.
This is the sort of information you would want to note in the bug reports.
Here are a few more things for you to review:
Target practice with Webgoat The top ten list of security defects can at times seem difficult to understand.
Webgoat is well documented, with a hints system and links to video tutorials; it leaves little room for misunderstanding the attacks.
More tools of the trade w3af is a powerful tool but works better in conjunction with other tools, including:
If your system stays up, you know that it has reached a minimal level of stability.
Jenkins is flexible so that you can call a wide range of tools through scripts running in Jobs, including the security tools mentioned.
Finding 500 errors and XSS attacks in Jenkins through fuzzing.
This recipe describes using a fuzzer to find server-side errors and XSS attacks in your Jenkins servers.
Cross Site Scripting attacks are currently one of the more popular forms of attack (http://en.wikipedia.org/wiki/Cross-site_scripting)
The attack involves injecting script fragments into the client's browser so that the script runs as if it comes from a trusted website.
For example, once you have logged in to an application, it is probable that your session ID is stored in a cookie.
The injected script might read the value in the cookie and then send the information to another server ready for an attempt at reuse.
A fuzzer discovers the links on the site it is attacking and the form variables that exist within the site's web pages.
For the web pages discovered, it repeatedly sends input based on historic attacks and lots of minor variations.
If responses are returned with the same random strings sent, then the fuzzer knows it has found an evil URL.
Getting ready Back up your sacrificial Jenkins server and turn off its security.
Expect the application to be unstable by the end of the attack.
You will need the Python programming language installed on your computer.
To download and install Wapiti, you will need to follow the instructions found at http://www.ict-romulus.
If you are attacking your local machine from your local machine, then you can afford to turn off its networking.
The attack will stay in the Loopback network driver, and no packets should escape to the Internet.
Within the src directory of Wapiti, run the following command:
A number of server-side errors will be reported to the console.
You can confirm that the URL is causing an error by using your favorite web browser to visit the URL mentioned.
You will have to be selective for version 2.2.1 on Ubuntu Linux, as this causes Wapiti to crash or time out.
To load Wapiti in specific modules, use the -m option.
The exec module is very good at finding 500 errors in Jenkins.
This is mostly due to unexpected input that Jenkins does not handle well.
However, if you start to see errors associated with resources such as files or database services, you should give the issues higher priority and send in bug reports.
In this case, we don't want to create work for the plugin manager.
If we do, it will then generate a lot of requests to an innocent external service.
In the second run of Wapiti, you also used the permanentxss module, which finds a bona fide XSS attack through the editing of descriptions.
You will be eliminating this issue in the next recipe, Improving security via small configuration changes.
Fuzzers are good at covering a large portion of an application's URL space, triggering errors that would be costly, in terms of time, to search out.
Consider automating through a Jenkins job as a part of a project's QA process.
This recipe describes modest configuration changes that strengthen the default security settings of Jenkins.
The reconfiguration includes removing the ability to add JavaScript or HTML tags to descriptions, masking passwords in console output, and adding a one-time random number, which makes it more difficult for a form input to be forged.
The combination of tweaks strengthens the security of Jenkins considerably.
When you next visit the job, you will see an alert box pop up.
Click on the Mask passwords tickbox and add the following variables:
Add an Execute shell build with the following Command: echo This is MyPassword $MyPassword.
Forgery exploits, making sure the Default Crumb Issuer is selected.
The escaped HTML plugin takes its input from your Job description and escapes any tags by parsing the text through a Jenkins utility class.
This action not only removes the risk of running unsolicited JavaScript, but also removes some flexibility for you as the administrator of the Job.
You can no longer add formatting tags, such as font.
The Mask Passwords plugin removes the password from the screen or the console, replacing each character of the password with the letter "x", thus avoiding accidental reading.
You should also always keep this plugin turned on, unless you find undocumented side effects or need to debug a Job.
A script at that location then tries to make your browser perform an action (such as delete a Job) by making your web browser visit a known URL within Jenkins.
Jenkins, thinking that the browser is doing your bidding, then complies with the request.
Once the nonce feature is turned on, Jenkins avoids CSRF by generating a random one-time number called a nonce that is returned as part of the request.
The number is not easily known and is also invalidated after a short window of time, limiting the risk of replay attacks.
This is because Jenkins makes it easy to get the work done and can talk through plugins with a multitude of infrastructure.
This implies that in many organizations, the number of administrators increases rapidly as the service organically grows.
Think about turning on the HTML escaping early, before the group of administrators get used to the flexibility of being able to add arbitrary tags.
Consider occasionally replaying the recipe Finding 500 errors and XSS attacks in Jenkins through fuzzing to verify the removal of this source of potential XSS attacks.
Looking at the Jenkins user through Groovy Groovy scripts run as the user jenkins.
This recipe highlights the power of, and danger to, the Jenkins application.
Getting ready Log in to your sacrificial Jenkins instance as an administrator.
For a typical *NIX system, it will be similar to this:
The script you have run is not as benign as it first seems.
Groovy scripts can do anything the jenkins user has the power to do.
The file's location is passed in as a string input.
If the file does not exist, that is also mentioned.
It is trivial for you to add a more detailed set of locations.
The existence of files clearly defines the type of OS being used and the structure of the disc partitioning.
The passwords are hidden in a shadow password file, safely out of reach.
However, the usernames and whether the username has a real login account (not /bin/false) suggest accounts to try and crack using dictionary attacks.
You can save the configuration effort if you generate a private and public key for Jenkins.
This allows a script to run with a user's permission, without needing a password logon.
It is typically used by Jenkins to control its slave nodes.
Retrieving the keys through a Groovy script represents further dangers to the wider infrastructure.
If any plugin stores passwords, in plain or decipherable text, then you can capture and parse the plugin's XML configuration files.
Not only can you read files but also change permissions and write over binaries, making the attack harder to find and more aggressive.
The best approach to limiting risk is to limit the number of logon accounts that have the power to run Groovy scripts in the Script console and to periodically review the audit log.
Limiting administrator accounts is made easier by using a matrix-based strategy, where you can decide the rights of each user or group.
A refinement on this is a Project-based matrix strategy, where you can choose permissions per job.
However, the Project-based matrix strategy costs you considerably more administration.
Warning: Since version 1.430 of Jenkins, there are extra permissions exposed to the matrix-based security strategy, to decide which group or user can run Groovy scripts.
It speeds up debugging if you can see who the last person running the job was and what their changes were.
This recipe ensures that you have auditing enabled and that a set of audit logs are created that contain a substantial history of events rather than the meager log size defined by default.
Getting ready Install the Audit Trail plugin from the following location:
The output from the log recorder is filtered via the URL patterns to log, as seen in the Jenkins configuration screen.
You will find that the logfile format is more readable than most, with a date/time stamp at the beginning, a description of what is happening in the middle of the log, and the user who acted, at the end.
It is now clear who has done what and when.
The advantage of this plugin is that you get to see who has made those crucial changes.
The disadvantage is that it adds an icon to a potentially full GUI, leaving less room for other features.
Missing Audit Logs For a security officer, it helps to be mildly paranoid.
If your audit logs suddenly go missing, it may well be a sign that a cracker wishes to cover their trail.
This is also true if one file goes missing, or there is a gap in time of the audit.
Even if this is caused by issues with configuration or a damaged file system, you should investigate.
Missing logs should trigger a wider review of the server in question.
At the very least, the audit plugin(s) is not behaving as expected.
Consider adding a small reporting script for these highly valued logs.
For example, consider modifying the recipe in Chapter 3, Building Software, to parse the logfile and make metrics that are then displayed graphically.
This enables you to view, over time, the ebb and flow of your team's work.
Of course, the data can be faked, but that would require effort.
Swatch You can imagine a situation where you do not want Groovy scripts to be run by certain users and want to be e-mailed in case of their unwanted actions.
If a pattern is found, it reacts with an e-mail or by executing commands.
It is used in many organizations to display user information to the world.
Because LDAP is a common Enterprise service, Jenkins may also encounter LDAP while running integration tests, as a part of the built-in applications testing infrastructure.
This recipe shows you how to quickly install an OpenLDAP (http://www.openldap.org/) server named slapd and then add organizations, users, and groups via LDAP Data Interchange Format (LDIF)—a simple text format for storing LDAP records (http://en.wikipedia.org/wiki/LDAP_Data_Interchange_Format)
Getting ready This recipe assumes that you are running a modern Debian-based Linux operating system, such as Ubuntu.
Distinguished name (dn) is a unique identifier per record and is structured so objects reside in an organizational tree structure.
ObjectClasses such as organizational unit define a set of required and optional attributes.
In the case of the organizational unit, the attribute ou is required.
This is useful for bundling attributes that define a purpose, such as creating an organizational structure belonging to a group or having an e-mail account.
To use another account, you will need to change the value of the –D option mentioned in step 2 of the recipe.
The default dn of the admin account may vary depending on which version of slapd you have installed.
The LDIF creates an organizational structure with three organizational units:
The list of attributes the record must have is defined by the objectClass inetOrgPerson.
The user is added to the group via adding the member attribute pointing to the dn of the user.
Jenkins looks for the username and to which groups the user belongs.
In Jenkins, you can define which projects a user can configure, based on their group information.
Therefore, you should consider adding groups that match your Jenkins Job structures such as development, acceptance, and also a group for those needing global powers.
What is not covered by this LDIF example is the adding of objectClasses and Access Control Lists (ACLs)
If the required attributes do not exist in a record or are of the wrong type, then LDAP will reject the data.
Sometimes, it's necessary to add new objectClasses; you can do this with graphical tools.
The recipe Administering OpenLDAP has an example of one such tool.
For information on this complex subject area, please review http://www.openldap.
You can also review the man entry on your OpenLDAP server from the command line—man slapd.access.
For many Enterprise applications, provisioning occurs during the first login of the user.
For example, a directory with content could be made, a user added to an e-mail distribution list, an Access Control List modified, or an e-mail sent to the marketing department.
This recipe will show you how to use two scripts—one to log in through LDAP and perform example provisioning, and the other to return the list of groups a user belongs to.
Getting ready You need to have installed the Perl and the Net::LDAP modules.
The file login.pl pulls in the username and password from the environment variables U and P.
The script then tries to self bind the user to a calculated unique LDAP record.
For example, the distinguished name of the user tester1 is:
Self binding happens when you search for your own LDAP record and at the same time authenticate as yourself.
This approach has the advantage of allowing your application to test a password's authenticity without using a global administration account.
If authentication fails, an exit code of 1 is returned.
If the file does not already exist, it is created.
A simple HTML file is created during the provisioning process.
This is just an example; you can do a lot more, from sending e-mail reminders to full account provisioning across the breadth of your organization.
The group.pl script simply returns two groups that include every user, guest, and many more.
Later, if you want to send e-mails out about the maintenance of services, you can use an LDAP query to collect e-mail addresses via the all group.
You can route mail, create login accounts, and so on.
At the University of Amsterdam, we use a custom schema so that user records have an attribute for the counting down of records.
A scheduled task performs an LDAP search on the counter and then decreases the counter by one.
The task notes when the counter reaches certain numbers and then performs actions, such as sending out e-mail warnings.
You can imagine using this method in conjunction with a custom login script.
Once a consultant logs in to Jenkins for the first time, they are given a certain period of grace before their LDAP record is moved to a to be ignored branch.
Security best practices dictate that you should limit the rights of individual users to the level that they require.
In this strategy, you can assign individual users or groups different permissions on a job-by-job basis.
The recipe uses custom realm scripts to allow you to log in with any name and a password whose length is greater than five characters and to place the test users in their own unique group.
This will allow you to test out the Project-based Matrix strategy.
Getting ready You will need to install the Script Realm plugin and also have Perl installed with the URI module (http://search.cpan.org/dist/URI/URI/Escape.pm)
The URI module is included in modern Perl distributions, so in most situations, the script will work out of the box.
Tick the Authenticate via custom script checkbox and add the following details:
Try to log in as adm_alan with a password less than five characters.
Log in as adm_alan with any password greater than five characters.
Add the group grp_proj_tester, with full rights (that is, all tickboxes checked)
The group script allows us to log in as arbitrary users and view their permissions.
In the Project-based Matrix strategy, the permissions per user or group are defined at two levels:
This is where you should define your global accounts for system-wide administration.
The global accounts can gain extra permissions per project but cannot lose permissions.
In this recipe, you logged in with a global account, adm_alan, that behaved as a root admin.
Using the per-project permissions, you can not only limit the powers of individual users but also shape which projects they view.
This feature is particularly useful for Jenkins masters that have a wealth of jobs.
My own custom security flaw I expect you have already spotted this.
The username input, as defined by the U variable, has not been checked for malicious content.
Later on, if an arbitrary plugin displays the username as part of a custom view, then if the plugin does not safely escape, the username is run in the end user's browser.
This example shows how easy it is to get security wrong.
You are better off using well-known and trusted libraries when you can.
For Perl, there are numerous excellent articles on this subject, including the following one:
Static code review, tainting, and untainting Static code review is the name for tools that read code that is not running and review for known code defects of this.
A number of these generic tools can review your code for security defects.
One of the approaches taken is to consider input tainted if it comes from an external source, such as the Internet or directly from input from files.
To untaint, the input has to first be passed through a regular expression and unwanted input safely escaped, removed, and/or reported.
Administering OpenLDAP This recipe is a quick start to LDAP administration.
It details how you can add or delete user records from the command line and highlights the use of an example LDAP browser.
These skills are useful for maintaining an LDAP server for use in integration tests or for Jenkins account administration.
Getting ready To try this out, you will need Perl installed with the Net::LDAP modules.
For example, for a Debian distribution, you should install the libnet-ldap-perl package (http://ldap.perl.org)
You will also need to install the LDAP browser—JXplorer (http://jxplorer.org/)
Select the Schema tab, and then select the objectClass account.
Disconnect from the anonymous account by selecting File | Disconnect.
Reconnect as the admin account by selecting File | Connect:
In the Table Editor, add the value 1021 XT to the postalCode.
Select the LDIF menu option, at the top of the screen, and select Export Subtree.
Click on the OK button and write the name of the file that you are going to export to the LDIF.
In the recipe, you have performed a range of tasks.
First, you have used an LDIF file to add two users.
This is a typical event for an LDAP administrator in a small organization.
You can keep the LDIF file and then make minor modifications to add or delete users, groups, and so on.
Next, you have viewed the directory structure anonymously through an LDAP browser, in this case, JXplorer.
JXplorer runs on a wide range of operating systems and is open source.
Your actions indicate that LDAP is an Enterprise directory service, where things are supposed to be found even by anonymous users.
The fact that pages render fast in JXplorer indicates that LDAP is a read-optimized database that returns search results efficiently.
Using an LDAP browser generally gets more frustrating as the number of objects to render increases.
For example, at the University of Amsterdam, there are more than 60,000 student records under one branch.
Under these circumstances, you are forced to use command-line tools or be very careful with search filters.
Being able to view objectClasses, knowing which attributes are optional and that you may use and which attributes are required and that you must use, helps you to optimize your records.
Next, you bind (perform some action) as an admin user and manipulate the tester1 record.
For small organizations, this is an efficient means of administration.
Exporting the record to LDIF allows you to use the record as a template for further importing of records.
This gives you a lot of flexibility for large-scale generation, modification, and deletion of records, by changing just a few variables.
The use of these types of scripts is typical for the provisioning of integration tests.
The script binds once, as the admin account, and then loops through a number of records using $counter as a part of the calculation of the distinguished name of each record.
The delete() method is called for each record, and any errors generated will be printed out.
Configuring the LDAP plugin LDAP is the standard for Enterprise directory services.
This recipe explains how to attach Jenkins to your test LDAP server.
Getting ready This recipe assumes that you have performed the Installing OpenLDAP with a test user and group recipe.
The test LDAP server supports anonymous binding—you can search the server without authenticating.
However, some servers are configured to enforce specific information security policies.
For example, your policy might enforce being able anonymously to verify that a user's record exists, but you may not be able to retrieve specific attributes, such as their e-mail or postal address.
Anonymous binding simplifies configuration, otherwise you will need to add account details for a user in LDAP with the rights to perform the searches.
This account, having great LDAP powers, should never be shared and can present a chink in your security armor.
When you log in to an instance of the Java class, hudson.
Here are a few more things for you to think about:
The difference between misconfiguration and bad credentials While configuring the LDAP plugin for the first time, your authentication process might fail due to misconfiguration.
Searching Applications retrieve information from LDAP in a number of ways:
This approach works only for information that is exposed to the world.
However, the LDAP server can limit the search queries to specific IP addresses as well.
The application will then be dependent on the attributes that your organization is prepared to disclose.
If the information security policy changes, the risk is that your application might break accidently.
However, it is not always clear in the logging whether the application is behind these actions.
If the LDAP server has an account-locking policy, it is simple for a cracker to lock out the application.
In reality, the approach chosen is defined by the already defined Access Control policy of your Enterprise directory service.
It is possible, though unlikely, that occasionally passwords are being stored in plain text in the XML configuration files in the workspace directory or plugins directory.
Every time you install a new plugin that requires a power user's account, you should double check the related configuration file.
If you see a plain textfile, you should write a bug report attaching a patch to the report.
It is designed as a campus-wide solution and, as such, is easy to install and relatively simple to configure to meet your specific infrastructural requirements.
This is made for a much more pleasant user interaction across the range of applications used by a typical Jenkins user during their day.
Yale CAS has helper libraries in Java and PHP that make integration of third-party applications straightforward.
In this recipe, you will install the complete version of a CAS server running from within a Tomcat 7 server.
This recipe is more detailed than the rest in this chapter, and it is quite easy to misconfigure.
To help, the modified configuration files mentioned in this recipe will be downloadable from the Packt website.
This recipe was written with version 3.4.8, but it should work for earlier or later versions, with little modification.
The recipe assumes that the installed Tomcat server is initially turned off.
As the user that Tomcat will run under, create a self-signed certificate via: keytool -genkey -alias tomcat -keyalg RSA.
Note: If keytool is not found on your PATH, you might have to fill in the full location to the bin directory of your Java folder.
Underneath the commented-out code, add the configuration information for LDAP:
If you see a page similar to the following, congratulations, you now have a running SSO!
The protocol you choose is TLS, which is a more modern and secure version of SSL.
Next, you generate a certificate and place it in the Tomcat user's certificate store, ready for Tomcat to use.
Your certificate store might contain many certificates; the alias tomcat uniquely identifies the appropriate certificate.
Within the downloaded CAS package, there are two CAS WAR files.
The larger WAR file contains the libraries for all the authentication handlers, including the required LDAP handler.
The default setup allows you to log in with the same values for username and password.
For example, a bad username or password will generate an error similar to the following:
Backend authentication Yale CAS has a wide range of backend authentication handlers, and it is straightforward for a Java developer to write his own.
Note: Using well-supported third-party frameworks, such as JAAS and JDBC implementations, you can connect to a much wider set of services than mentioned in the table.
This allows you to pull in other authentication mechanisms, such as Kerberos.
Trusted Is used to offload some of the authentication to an Apache server or another CAS server.
Generic A set of small generic handlers, such as a handler to accept a user from a list or from a file.
An alternative installation recipe using ESUP CAS The ESUP consortium also provides a repackaged version of CAS, which includes additional ease-of-use features, including an out of the box demonstration version.
However, the ESUP version of the CAS server lags behind the most current version.
If you want to compare the two versions, you can find the ESUP installation documentation at http://esup-casgeneric.
The ESUP package is easier to install and configure than this recipe, however, it includes an older version of CAS.
Trusting LDAP SSL Having SSL enabled on your test LDAP server avoids sniffable passwords being sent over the wire, but you will need to get the CAS server to trust the certificate of the LDAP server.
Please note that, your JVM needs to trust the certificate of your SSL enabled LDAP server or CAS will refuse to connect to your LDAP server.
Enabling SSO in Jenkins In this recipe, you will enable CAS in Jenkins through the use of the Cas1 plugin.
For the CAS protocol to work, you will also need to build a trust relationship between Jenkins and the CAS server.
The Jenkins plugin trusts the certificate of the CAS server.
Getting ready To try this out, you will need to have installed a CAS server, as described in the recipe Installing a CAS server.
In the address bar, you will see a Tomcat icon on the left-hand side.
Click on the icon, and a security pop-up dialog will appear.
Choose a location for your public certificate to be stored.
The CAS plugin cannot verify the client's credentials unless it trusts the CAS server certificate.
If the certificate is generated by a well-known trusted authority, their root certificates are most likely already in the default keystore (cacerts)
However, in the CAS installation recipe, you had created a self-signed certificate.
Note that you left the the Roles Validation script blank.
This implies that your matrix-based strategies will have to rely on users being given specific permissions rather than groups defined by a customized CAS server.
Congratulations, you have a working SSO in which Jenkins can play its part seamlessly with a large array of other applications and authentication services.
Introduction This chapter reviews the relationship between Jenkins and Maven builds and also a small amount of scripting with Groovy and Ant.
However, it is also important that you clearly define the boundaries between the Jenkins plugins and the Maven build files.
A lack of separation will make you unnecessarily dependent on Jenkins.
If you know that you will always run your builds through Jenkins, then you can afford to place some of the core work in the Jenkins plugins, gaining interesting extra functionality.
However, if you want to always be able to build, test, and deploy directly, then you will need to keep the details in the pom.xml.
You will have to judge the balance in where you add the configuration.
It is easy to have the feature creep as you use more of the Jenkins plugin's feature set.
The UI is easier to configure than writing a long pom.xml.
It is also simpler for you to use Jenkins for most of the common tasks, such as transporting artifacts, communicating, and plotting the trends of tests.
You can configure to transfer files or add a section of the pom.xml, as follows:
Remembering the dependencies on specific JARs and versions which the Maven plugin uses at times feels like magic.
Later in the chapter, you will be given the chance to run Groovy scripts with AntBuilder.
Each approach is viable, and the use depends more on your preferences rather than one choice.
You can use this feature to signal, for example, to the QA team that they need to test the build or system administrators to pick up the artifacts and deploy.
Other plugins can also be triggered by promotion, including the SSH plugin.
You should keep the running time of a Job to a minimum and offset heavier Jobs to nodes.
Heavy Jobs tend to be clustered around document generation or testing.
Keep It Simple Stupid (KISS) biases the decision towards a larger, single file.
To save page space, only the essential details will be shown.
You can download the full examples from the Packt Publishing website.
You will need to install this version on your Jenkins server, giving it the label 2.2.1
To generate a basic template for a Maven project, you have two choices.
Or you can start off with a simple pom.xml file, as shown in the following code:
The template looks simple, but is only part of a larger effective pom.xml.
It is combined with the default values that reside hidden in Maven.
To view the expanded version, you will need to run the following command:
Unless otherwise stated, the fragments mentioned in the recipes should be inserted into the template, just before the </project> tag, updating your groupID, artifactID, and version values to your own taste.
In the previous chapters, you used recipes that copied the files into the workspace.
You will need to install the plugin, ensuring that the files have the correct permissions, so that the Jenkins user can copy.
In Linux, consider placing the files beneath the Jenkins home directory: /var/lib/Jenkins.
Jenkins has many plugins that create views of the test results generated by builds.
This is great for plotting the history of the standard result types, such as JUnit, FindBugs, JMeter, and NCSS.
However, despite the wealth of options, there may come a time when you will need to plot custom results.
Scenario: You want to know the history of how many hits or misses are generated in your custom cache during integration testing.
Plotting over builds will give you an indicator of whether the code change is improving or degrading performance.
In this recipe, a simple Perl script will generate random cache results.
In the Post-build Actions section, select the Plot build data checkbox.
Add a Data series file hits.properties with Data series legend label Hits.
At the bottom of the Configuration page, click on the Save button.
The Perl script generates two property files: hits and misses.
The plot plugin then reads values out of the property YVALUE.
The two property files are read by the plot plugin.
The plugin keeps track of the history and their values displayed in a trend graph values.
You will have to experiment with the different graphic types to find the optimum plot for your custom measurements.
There are currently two other data formats that you can use: XML and CSV.
However, until the online help clearly explains the structures used, I would recommend staying with the properties format.
Perl was chosen for its coding brevity and because it is platform-agnostic.
The script could have also been written in Groovy and run from within a Maven project.
You can see a Groovy example in the Running Groovy scripts through Maven recipe.
If you choose the right graph type, you can generate beautiful plots.
If you want to add these custom graphs to your reports, you will need to save them.
You can do so by right-clicking on the image in your browser.
You can generate an image by visiting the following URL: http://host/job/JobName/plot/getPlot?index=n&width=x&height=y.
The width and height define the size of the plot.
To discover the index, visit the plots link, examine the Jump to select box, and minus one from the highest Plot number.
To generate a graph in a PNG format having dimensions of 800x600 based on the Job in this recipe, you would use a URL similar to the following:
To download the image without logging in yourself, you can also use the scriptable authentication method mentioned in the recipe Remotely triggering Jobs.
The ability to run Groovy scripts in builds allows you to consistently use one scripting language in Maven and Jenkins.
Maven can execute the Groovy source code from within the build file, at another file location, or from a remote web server.
Maintainability of scripting For later re-use, consider centralizing your Groovy code outside the build files.
In the Build section, add a build step for Invoke top-level Maven targets.
If your system is on a *NIX box, then similar output will be seen to the following: OS Type Linux.
On a Windows system, with Jenkins properly configured, the script will fail with the following message: Sorry, Not a UNIX box.
You can execute the gmaven-plugin multiple times during a build.
In the example, the phase verify is the trigger point.
To enable the Groovy plugin to find the imported classes outside its core features, you will need to add an element in the <classpath>
The import statement works as the dependency is mentioned in the <classpath> tag.
The fail method allows the Groovy script to fail the build.
In this case, when you are not running the build on a *NIX OS, then most times you will want your builds to be OS-agnostic.
However, during integration testing, you may want to use a specific OS to perform functional tests with a specific web browser.
The check will stop the build in case your tests find themselves on the wrong node.
Once you are satisfied with your Groovy code, consider compiling the code into the underlying Java byte code.
Here are a number of tips that you might find useful.
Keeping track of warnings It is important to review your log files, not only on failure but also for the warns.
The platform encoding warning states that the files will be copied using the default platform encoding.
If you change the servers and the default encoding on the server is different, then the results of the copying may also be different.
For consistency, it is better to enforce a specific coding by adding the lines:
Please update your template file to take this into account.
The JAR warning is because we are only running a script and have no content to make a JAR.
If you had called the script in an earlier phase than the packaging of the JAR, you would not have triggered the warning.
Where's my source? There are two other ways to point to Groovy scripts to be executed.
The first is to point to the file system, for example:
The other approach is to connect to a web server through a URL similar to the following:
Using a web server to store Groovy scripts adds an extra dependency to the infrastructure.
However, it is also great for centralizing code in an SCM with web access.
It is coarsely grained for building with pre and post build support.
Maven is much more refined, having 21 phases as trigger points.
Goals bundle phases, for example, for the site goal there are four phases: pre-site, site, post-site, and site-deploy, all of which will be called in order by mvn site or directly by using the syntax mvn site:phase.
The idea is to chain together a series of lightweight Jobs.
You should farm out any heavy Jobs, such as integration tests or a large amount of JavaDoc generation, to a slave node.
You should also separate by time to even load and aid in diagnosing issues.
You will find the Maven phases mentioned in components.xml under the line:
For site generation, the <reporting> tag surrounds the majority of the configuration.
The plugins configured under reporting generate useful information, whose results are saved under the target/site directory.
There are a number of plugins that pick up the generated results and then plot their history.
Jenkins plugins, in general, do not perform the tests, but consume the results.
The Groovy plugin is useful in all the phases as it is not specialized to any specific task, such as packaging or deployment.
It gives you a uniform approach to reacting to situations that are outside the common functionality of Maven.
Manipulating environmental variables This recipe shows you how to pass variables from Jenkins to your build Job and how different variables are overwritten.
It also describes one way of failing the build if crucial information has not been correctly passed.
The Envinject plugin was chosen for this recipe as it is reported to work with nodes and offers a wide range of property injection options.
Create a pom.xml file that is readable by Jenkins, with the following contents:
Create a file named my.properties and place it in the same directory as the pom.
Create a blank free-style Job with the Job name ch3.environment.
In the Build section, add a build step for Invoke top-level Maven targets.
Inject the values in my.properties, by clicking on the Prepare an environment for the job (near the top of the Job configuration page)
In the Build section for Invoke top-level Maven targets, click on the Advanced button.
In the newly expanded section, add an extra property name.from.
The Envinject plugin is useful for injecting properties into builds.
The first time when it is run without the variable name.
The second time when it is run with the variable defined, the Jenkins job succeeds.
The project instance is a model of the XML configuration that you can programmatically access.
Your Maven goal will fail if the property does not exist.
However, you cannot get to the property by using the environment call System.getenv()
It is well worth learning the various options, they are:
It is good to keep your environment as clean as possible, as it will aid you in debugging later.
This is useful if you want to detect specific details of the running environment and configure your build accordingly.
This variable contains information about which event triggered the job.
To choose between property files, you will need to set a variable in the plugin configuration, and call it as part of the Jenkins Job.
If you use a relative path to the properties file, then the file can reside in your Revision control system.
If you use a full path, then the property file can be stored on the Jenkins server.
The second option is preferable if sensitive passwords, such as for database connections, are included.
Jenkins has the ability to ask for variables when you run a Job manually.
At the build time, you can choose your property files by selecting from a choice of property file locations.
Running AntBuilder through Groovy in Maven Jenkins interacts with an audience with a wide technological background.
There are many developers who became proficient in Ant scripting before moving on to using Maven.
Developers may be happier with writing an Ant task than editing a pom.xml file.
There are mission-critical Ant scripts that still run in a significant proportion of organizations.
The Groovy approach makes sense for the Jenkins administrators who use Groovy as part of their tasks.
Groovy, being a first-class programming language, has a wide range of control structures that are hard to replicate in Ant.
You can partially do this by using the Antcontrib library (http://ant-contrib.sourceforge.net)
However, Groovy, being a mature programming language, is much more expressive.
This recipe details how you can run two Maven pom's involving Groovy and Ant.
The first pom shows you how to run the simplest of the Ant tasks within Groovy, and the second performs an Ant contrib task to secure copy files from a large number of computers.
Change the values of groupId, artifactId, version, and name to suit your preferences.
Change the values of groupId, artifactId, version, and name to suit your preferences.
To make it work, you will have to configure it to point to the files on real servers.
Groovy runs basic Ant tasks without the need of extra dependencies.
An AntBuilder instance (http://Groovy.codehaus.org/Using+Ant+Libraries+with+AntBuilder) is created, and then the Ant echo task is called.
Under the bonnet, Groovy calls the Java classes that Ant uses to perform the echo command.
Within the echo command, a date is printed by directly creating an anonymous object, for example:
You configured the pom.xml to fire off the Groovy scripts in two phases: the test phase and then later in the verify phase.
The test phase occurs before the generation of a JAR file, and thus avoids creating a warning about an empty JAR.
As the name suggests, this phase is useful for testing before packaging.
The second example script highlights the strength of combining Groovy with Ant.
The SCP task (http://Ant.apache.org/manual/Tasks/scp.html) is run a large number of times across many servers.
The script first asks for the USERNAME and password, avoiding storage on your file system or your revision control system.
Creating custom property files on the fly allows you to pass on information from one Jenkins Job to another.
You can create property files through AntBuilder using the echo task.
The first echo command sets append to false so that every time a build occurs, a new properties file is created.
You can remove the second append attribute as the default value is set to true.
You write HTML, such as pages, with extra tags interspersed with Java coding into a text file.
If you do this in a running web application, then the code recompiles on the next page call.
This process supports Rapid Application Development (RAD), but the risk is that developers make messy and hard-to-read JSP code that is difficult to maintain.
It would be nice if Jenkins could display metrics about the code to defend the quality.
The user will perceive this as a slow loading of the page, and this may deter them from future visits.
To avoid this situation, you can compile the JSP page during the build process, and place the compiled code in the WEB-INF/classes directory or packaged in the WEB-INF/lib directory of your web app.
This approach has the advantage of a faster first page load.
A secondary advantage of having a compiled source code is that you can run a number of statistic code review tools over the code base and obtain testability metrics.
This generates the testing data that is ready for Jenkins plugins to display.
The compiled code will work with the Jetty server, which is often used for integration tests.
Warning: The JSP mentioned in this recipe is deliberately insecure, ready for testing later in this book.
Create a war project from a Maven archetype by typing the following command:
Create a WAR file by using the command mvn package.
The build will now fail with an understandable error message similar to the following:
The Maven plugin seeing the index.jsp page compiles it into a class with the name jsp.
The plugin then defines the class as a servlet in WEB-INF/web.xml with a mapping to /index.jsp.
For example, if you deploy the .war file generated by this recipe to a Tomcat 7 server, it will fail to deploy properly.
This is because different servers have different assumptions about how the JSP code is compiled and which libraries they depend on to run.
For Tomcat, you will need to tweak the compiler used and the Maven plugin dependencies.
Eclipse templates for JSP pages Eclipse is a popular open source IDE for Java developers (http://www.eclipse.org/)
If you are using Eclipse with its default template for the JSP pages, then your pages may fail to compile.
This is because the default compiler does not like the meta information mentioned before the <html> tag.
Simply remove the lines before compiling, or change the JSP compiler that you use.
Configuring Jetty for integration tests Jenkins plugins that keep a history of tests are normally consumers of the data generated within Maven builds.
For Maven to automatically run integration, performance, or functional tests, it will need to hit a live test server.
However, the server will be run as part of a Jenkins Job, consuming the potentially scarce resources.
This will limit the number of parallel executors that Jenkins can run, decreasing the maximum throughput of Jobs.
This recipe runs the web application developed in the recipe named Failing Jenkins Jobs based on JSP syntax errors, tying Jetty into integration testing by bringing the server up just before tests are run, and then shutting down afterwards.
Two Jetty connectors are defined for HTTP and for the secure TLS traffic.
To create a port to telnet, the shutdown command is also defined.
Getting ready Follow the recipe Failing Jenkins Jobs based on JSP syntax errors, generating a .war file.
Add the following XML fragment just before </plugins> tag within the pom.xml file.
After passing through the warnings about the self-signed certificate, you will see the web application working.
You will now see the server starting up, and then stopping.
In the generate-resources phase, Maven uses the keytool plugin to create a self-signed certificate.
The certificate is stored in a Java key store with a known password and alias.
If the Common Name (CN) is not correctly set in your certificate, then your web browser will complain about the certificate.
These ports are chosen as they are above port 1023, so that you do not need administrative rights to run the build.
The port numbers also avoid the ports used by Jenkins.
Both the Jetty and Keytool plugin use the keystore tag to define the location of the key store.
Every time they encounter a new version of the certificate, they will need to accept, in their web browser, the certificate as a security exception.
You can achieve it with this recipe by removing the key generation and pointing the keystore tag to a known file location.
The generated .war file is pointed to by the webapp tag, and Jetty runs the application.
If you know that your build works well with a specific version of a Maven, then this defends against unwanted changes.
For example, the Jetty plugin used in this recipe is held at version 8.0.0.M0
Another advantage is that if the plugin version is too old, then the plugin will be pulled out of the central plugin repository.
When you next clean up your local repository, this will break your build.
This is what you want, as this clearly signals the need to review and then upgrade.
Looking at license violations with RATs This recipe describes how to search any Job in Jenkins for license violations.
You can search for license violations by running a RAT JAR file directly, with a contributed ANT task or through Maven.
In this recipe, you will be running directly through a .jar file.
The report output goes to the console, ready for Jenkins plugins like the log parser plugin to process the information.
Set Check-out Strategy to Use 'svn update' as much as possible.
Under the Post steps section, check Run only if build succeeds.
Add a Post-build step for Execute Shell (we assume that you are running a NIX system)
Add the following text to the Execute Shell text area, replacing the jar version with the correct value.
The RATs source code is compiled and run twice: the first time to print the help out, and the second time to check the license headers.
The code base is changing, and over time it expects the number of options to increase.
You will find the most up-to-date information by running help.
The –e option excludes certain file name patterns from review.
In a complex project, expect a long list of exclusions.
You can use it to keep your source code license headers up to date.
To format your source code, you would then run the following command:
Change the values of groupId, artifactId, version, and name to suit your preferences.
Under the Post Steps section, invoke the top-level Maven targets:
POM: full path to your RATs pom file, for example:
Background information: Sakai is a Learning Management System (LMS) that is used daily by millions of students.
The excludes exclude the target directory and any other directory.
The includes override specific file types under the src directory.
Depending on the type of frameworks used in your projects, the range of includes will change.
For information on customizing RATs for specific license types, visit:
Multiple approaches and anti-patterns There were multiple approaches to configuring the Jenkins Job.
You could avoid copying the RATs report file by fixing its location in the Maven plugins configuration.
You should also consider splitting into two Jobs, and then pointing the RATs Job at the source codes workspace.
The last approach is a best practice, as it cleanly separates the testing.
Snapshots Unlike fixed versions of artifacts, snapshots have no guarantee that their details will not vary over time.
Snapshots are useful if you want to test the latest and greatest features.
However, for the most maintainable code, it is much better to use fixed versions.
To defend the base-level stability, consider writing a Job that triggers a small Groovy script inside a pom.xml to visit all your projects.
The script needs to search for the word SNAPSHOT in the version tag, and then write a recognizable warning for the Post-build Groovy plugin to pick up, and if necessary, fail the Job.
Using this approach, you can incrementally tighten the boundaries, giving developers time to improve their builds.
The setter plugin allows you to gather information out of the build log and add it as a description to a build's history.
This is useful as it allows you later to quickly assess the historic cause of the issue, without drilling down into the console output.
You can now see the details immediately in the trend report without needing to review all the build results separately.
The setter plugin uses the Regex expressions to scrape the descriptions.
Change the values of groupId, artifactId, version, and name to suit your preferences.
Tick Set build Description, and add the following values to the expanded options.
Description for failed builds: The big head says failure: "\1"
Run the Job a number of times, and review the build history.
You will see that the description of each build varies.
The Groovy code is called as part of the install goal.
The code either fails the Job with the pattern MySevere Issue or prints the output to the build with the pattern Great stuff happens because.
As a Post-build action, the description setter plugin is triggered.
On success of the build, it looks for the pattern Great stuff happens because: (.*)
The same is true for the failed build, apart from some extra text that is added before the expansion of "\1"
You defined this in the configuration of Description for failed builds.
It is possible to have more variables than just \1 by expanding the regex expressions.
The token macro plugin allows the macros to be defined in the text, which are then expanded by calling a utility method.
This approach of using utility plugins simplifies the plugin creation and supports consistency.
Reacting to the generated data with the Post-build Groovy plugin.
Build information is sometimes left obscure in log files or reports that are difficult for Jenkins to expose.
This recipe will show you one approach of pulling those details into Jenkins.
The Post-build Groovy plugin allows you to run Groovy scripts after the build has run.
Since the plugin runs within Jenkins, it has a programmatic access to services, such as being able to read console input or change a builds summary page.
This recipe uses a Groovy script within a Maven pom.xml file to output a file to the console.
The console input is then picked up by the Groovy code from the plugin, and vital statistics is displayed in the build history.
Getting ready Follow the recipe Reviewing license violations from within Maven.
Update the pom.xml file by adding the following XML fragment just before the </
Make sure that the select box If the script fails: is set to Do Nothing.
In the Build History, you will see results similar to the following screenshot:
The RATs licensing report is saved to the location target/rat.txt.
The Groovy code then reads the RATs file and prints it out to the console, ready to be picked up by the Post-build plugin.
You could have done all the work in the Post-build plugin, but you might later want to re-use the build.
After the build is finished, the Post-build Groovy plugin runs.
A number of Jenkins services are visible to the plugin:
Any line with the pattern Unknown Licenses at the end of the line will be matched with anything before that stored in matcher.group(1)
It sets the title string to the number of Unknown licenses.
An image that already exists in Jenkins is added with the title.
Pulling information into a report by searching for a regular pattern is called scraping.
The stability of scraping relies on a consistent pattern being generated in the RATs report.
If you change the version of the RAT's plugin, the pattern might change and break your report.
When possible, it is more maintainable for you to use the stable data sources, such as XML files, which have a well-defined syntax.
Jenkins has a remote API, which allows you to enable, disable, run, delete Jobs, and change configuration.
To get the most up-to-date details, you will need to review http://yourhost/job/Name_of_Job/api/
Where yourhost is the location of your Jenkins server, and the Name_of_Job is the name of a Job that exists on your server.
This recipe details how you can trigger build remotely by using security tokens.
This will allow you to run other Jobs from within your Maven.
Getting ready This recipe expects Jenkins security to be turned on so that you have to log in as a user.
It also assumes that you have a modern version of wget (http://www.gnu.org/s/wget/) installed.
Under the Build Triggers section, check Trigger builds remotely (e.g., from scripts)
From a terminal console, run wget to log in, and run the Job remotely.
Check the Jenkins Job to verify that it has run.
From a terminal console, run wget to log in, and run the Job.
Warning: There are two obvious security issues in this recipe: Short tokens are easy to guess.
The HTTP protocol can be packet sniffed by a third party.
To run a Job, you need to authenticate as a user and then obtain permission to run the specific Job.
This is achieved through apiTokens, which you should consider as passwords.
The first is build, which runs the build without passing parameters.
The wget tool does the heavy lifting, otherwise you would have had to write some tricky Groovy code.
We have chosen simplicity and OS dependence for the sake of a short recipe running an executable risk, making your build OS-specific.
The executable will depend on how the underlying environment has been set up.
However, sometimes you will need to make compromises to avoid complexity.
You can find the equivalent Java code at the following URL:
There are some excellent comments from the community at the end of the page.
Remotely generating Jobs There is also a project that allows you to remotely create Jenkins Jobs through Maven (http://evgeny-goldin.com/wiki/maven-jenkins-plugin)
The advantage of this approach is its ability to enforce consistency and re-use between Jobs.
You can use one parameter to choose Jenkins server and populate.
It can consume the results of the tests generated by builds.
Maven has a goal for site generation, where within the pom.xml file, many of the Maven testing plugins are configured.
When run, a Jenkins Maven 2/3 software project Job does a number of things.
It notes when a site is generated and creates a shortcut icon in the Jobs home page.
This is a highly-visible icon that you can link with content.
You can gain fine-grained control of Maven site generation by triggering the Groovy scripts that structure sites in different Maven phases.
In this recipe, you will use Groovy to generate a dynamic site menu that has different menu links, depending on a random choice made in the script.
A second script then generates a fresh results page, per site generation.
These actions are useful if you want to expose your own custom test results.
The recipe Reporting alternative code metrics in Jenkins describes how you can plot custom results in Jenkins, enhancing the user's experience further.
Warning: This recipe works in version 2.2.1 of Maven or earlier.
Maven 3 has a slightly different approach to site generation.
You will use this plugin to copy the files mentioned in this recipe into the Jenkins workspace.
Create the file named site_xml.Groovy within the same directory as your pom.
Under the Build Environment section, tick Copy data to workspace.
Add to Path to folder: the path to the directory where you have placed the files.
Run the job a number of times, reviewing the generated site.
On the right-hand side, you should see a menu section named My super project.
For half of the runs, there will be a sub-menu link named Key Performance Indicators.
Two Groovy scripts are run in two different phases of the site goal.
Maven uses this to create an additional menu structure on the left-hand side of the index page.
The second Groovy script generates a page of random results.
This is the file that the Maven site generation plugin uses to define the left-hand side of a sites menu.
After the build script is run, Jenkins sees that a site sits in the conventional place and adds an icon to the Job.
Warning: At the time of writing, only Maven 2/3 project jobs sense the existence of generated sites and publish the site icon.
Searching for example site generation configuration Sometimes, there can be arbitrary XML magic in configuring site generation.
One of the ways to learn quickly is to use a software code search engine.
For example, try searching for the term <reporting>, using the Koders search engine (http://www.koders.com)
You don't want to break the legacy configuration, as that would cause unnecessary maintenance work.
For example, it will complain if you forget to add a version number for any of your dependencies or plugins.
Introduction This chapter explores communication through Jenkins, recognizing that there are different target audiences.
Its home page displays the status of all the jobs, allowing you to make quick decisions.
You can easily set up multiple views, prioritizing information naturally.
Jenkins, with its hoard of plugins, notifies you by e-mail, Twitter, and Google services.
It shouts at you through mobile devices, radiates information as you walk past big screens, and fires at you with USB sponge missile launchers.
The primary audience is developers, but don't forget the wider audience that wants to use the software being developed.
This chapter includes recipes to help you reach this wider audience.
When creating a coherent communication strategy, there are many Jenkins-specific details to configure.
Here are a few that will be considered in this chapter:
Jenkins has many plugins; you should select a few that suit the team's ethos.
You can cheaply generate a corporate look and feel by adding your own stylesheets and JavaScript.
You can use this to add custom content and provision resources such as home pages, which will enhance the corporate look and feel.
The front page is used by the audience to quickly decide which job to select for review.
Plugins expand the choice of view types and optimize information digestion.
This potentially avoids the need to look further, thereby saving precious time.
If you place a monitor by watering holes such as receptions or coffee machines, passersby will absorb the ebb and the flow of job status changes.
The view sublimely hints at the professionalism of your company and the stability of your product's roadmap.
Consider connecting your Jenkins pages to Google Analytics or Piwik, an open source analytics application.
Subversion repository From this chapter onwards, you will need a Subversion repository.
This will allow you to use Jenkins in the most natural way possible.
If you do not already have a repository, there are a number of free or semi-free services you can sign up for on the Internet, for example, http://www.strawdogs.co.uk/09/20/6-free-svn-project-hosting-services/
This recipe modifies the Jenkins look and feel through the themes plugin.
The Simple Theme plugin is a page decorator; it decorates each page with extra HTML tags.
The plugin allows you to upload a stylesheet and JavaScript file.
Each Jenkins page is then decorated with HTML tags that use the URLs to pull in your uploaded files.
Although straightforward, when properly crafted, the visual effects are powerful.
Download an icon and add it to the userContent directory, renaming the icon to camera.png.
Under the Theme section, fill in the location of the CSS and JavaScript files:
Return to the Jenkins home page, and review your work.
The JavaScript writes a heading near the top of the generated pages with id='test'
The Cascading Style Sheet, having a rule triggered through the CSS locator #test, adds the camera icon to the background.
The picture's dimensions are not properly tailored for the top of the screen; they are trimmed by the browser.
This is a problem you can solve later by experimenting.
The second CSS rule is triggered for main-table, which is a part of the standard front page generated by Jenkins.
On visiting other parts of Jenkins, you will notice that the camera icon looks out of context and is oversized.
You will need time to modify the CSS and JavaScript to generate better effects.
With care and custom code, you can skin Jenkins to fit your corporate image.
There are quirks in the support for the various CSS standards between browser types and versions.
Here are a few more things for you to consider:
Included JavaScript library frameworks Jenkins uses the YUI library (http://developer.yahoo.com/yui/)
You can also consider adding your favorite JavaScript library to the Jenkins /scripts directory through a WAR overlay (see the next recipe)
If your Jenkins deployment is maintained by only a few administrators, you can most likely trust everyone to add JavaScript that has no harmful side effects.
However, if you have a large set of administrators, who use a wide range of Java libraries, your maintenance and security risks increase rapidly.
Please consider your security policy, at least adding an audit plugin to keep track of actions.
This recipe describes how to overlay the content onto the Jenkins WAR file.
With a WAR overlay, you can change the Jenkins look and feel ready for corporate branding and content provisioning of home pages, among others.
The basic example of adding your own custom favicon.ico (the icon in your web browser's address bar) is used.
Jenkins keeps its versions as dependencies in a Maven repository.
You can use Maven to pull in the WAR file, expand it, add content, and then repackage.
This enables you to provision resources, such as images, home pages, the icon in the address bar called a favicon, robots.txt (which affects how search engines look through your content), and so on.
Be careful—using a WAR overlay will work cheaply if the structure and the graphical content of Jenkins do not radically change over time.
However, if the overlay does break the structure, you might not spot this until you perform detailed functional tests.
You can also consider minimal changes through a WAR overlay, perhaps only changing favicon.ico, adding images and userContent, and then using the Simple Theme plugin (see the previous recipe) to do the styling.
In your top-level directory, run the following command: mvn package.
Jenkins has its WAR files exposed through a central Maven repository.
This allows you to pull in specific versions of Jenkins through standard Maven dependency management.
It expects to find the content to overlay at either src/main/ webapp or src/main/resources.
The context.xml file defines certain behaviors for a web application, such as database settings.
In this example, the setting logEffectiveWebXML is asking Tomcat to log specific information on startup of the application (http://tomcat.apache.org/tomcat7.0-doc/config/context.html)
The file is placed in the META-INF directory, because Tomcat picks up the settings here without the need of a server restart.
You used the same version number in the name of the final overlayed WAR as the original Jenkins WAR version.
It makes it easier to spot if the Jenkins version changes.
This again highlights that using conventions aids readability and decreases the opportunity for mistakes.
When deploying from your acceptance environment to production, you should remove the version number.
The Jenkins WAR file is pulled in as a dependency of type—war and scope—runtime.
The runtime scope indicates that the dependency is not required for compilation but is for execution.
Avoiding work To limit maintenance efforts, it is better to install extra content rather than replace content that might be used elsewhere or by third-party plugins.
There are a lot of details that you need to cover if you wish to fully modify the look and feel of Jenkins.
Which types of content can you replace? The Jenkins server deploys into two main locations:
To gain a fuller understanding of the content, review the directory structure.
A useful command in Linux is the tree command—it displays the directory structure.
For the Jenkins Ubuntu workspace, using the following command generates a tree view of the workspace:
If you are running Jenkins from the command line, then the option for placing the webapp is webroot.
Search engines and robots.txt If you are adding your own custom content, such as user home pages, company contact information, or product details, consider modifying the top-level file—robots.txt.
You can find the full details of the structure of the robots.txt file at http://www.w3.org/TR/html4/appendix/notes.html#h-B.4.1.1
It is an open question if all web crawlers will honor the intent.
Generating a home page The user's home page is a great place to express your organization's identity.
You can create a consistent look and feel that expresses your team's spirit.
This recipe will explore the manipulation of home pages found under the /user/userid directory and configured by the user through the Jenkins /me folder path.
You can configure Jenkins with a number of authentication strategies; the choice will affect how you create a user.
One example is to use Project-based Matrix tactics, which were detailed in the Reviewing Project-based Matrix tactics via a custom script recipe in Chapter 2, Enhancing Security.
Note: If the image is no longer available, choose another.
Log in to your sacrificial Jenkins server as fakeuser, and visit its configuration page at http://localhost:8080/user/fakeuser/configure.
Note: You will now be able to use this known URL whenever you want to display your Avatar.
If you click on the link, the HELLO WORLD content will appear or disappear.
Log in as fakeuser2 with the same password as fakeuser.
The Avatar plugin allows you to upload an image to Jenkins.
You can reuse the image with the Simple Theme plugin to add content without using a WAR overlay.
There is a vast number of public domain and open source images freely available.
Before generating your own content, it is worth reviewing resources on the Internet.
If you create content, consider donating to an open source archive such as http://archive.org.
Unless you filter the description (see the recipe Exposing information through build descriptions in Chapter 3, Building Software) for HTML tags and JavaScript, you can use custom JavaScript or CSS animations to add eye candy to your personalized Jenkins.
By copying to another directory and slightly modifying the config.xml file, you have created a new user account.
The format is readable and easy to structure into a template for the creation of yet more accounts.
By using the WAR overlay recipe and adding extra /user/username directories containing customized config.xml files, you can control Jenkins user populations, for example, from a central provisioning script or at the first login attempt, using a custom authorization script (see Using the Script realm authentication for provisioning in Chapter 2, Enhancing Security)
You can set the initial password to a known value or keep it blank.
An empty password only makes sense if the time from creation of the user to the first login is very short.
You should consider this a bad practice; a problem waiting to happen.
A number of plugins also store their configuration in the same config.xml.
As you increase the number of plugins in your Jenkins server, which is natural as you get to know the product, you will need to occasionally review the completeness of your template.
Creating HTML reports The left-hand menu of jobs on the front page is valuable real estate.
This recipe describes how you can add a link from a custom HTML report to the menu, getting the report more quickly noticed.
We assume that you have a Subversion repository with the Packt code committed.
Under the Post-build Actions section, check Publish HTML reports, adding the following details:
Your Subversion repo contains an index.html file, which is pulled into the workspace of the job.
The plugin works as advertised and adds a link pointing to the HTML report.
This allows your audience to efficiently find your custom-generated information.
It is possible that, when you update a stylesheet in an application, you do not see the changes in your browser until you have cleaned your browser cache.
Jenkins gets around this latency issue in a clever way.
It uses a URL with a unique number that changes with each Jenkins version.
For example, for the css directory you have two URLs:
Note: The unique number changes per version, so you will need to update the URL with each upgrade.
This website has a fixed URL inside the Jenkins job that you can point at with the My HTML Report link.
This brings within easy reach documentation such as test results.
Efficient use of views Jenkins' addictive ease lends itself to creating a large number of jobs.
This increases the volume of information exposed to the developers.
Jenkins needs to avoid chaos by utilizing the browser space efficiently.
In this recipe, you will use the DropDown toolbar plugin.
This plugin removes the tab views and replaces them with one select-box.
You will also be shown how to provision lots of jobs quickly, using a simple HTML form generated by a script.
Warning: In this recipe, you will be creating a large number of views, which you may want to delete later.
If you are using a VirtualBox image, consider cloning the image and deleting after you have finished.
Cut and paste the following Perl Script into an executable file named create.pl:
Create an HTML file from the output of the Perl Script, for example:
In a web browser, as an administrator, log in to Jenkins.
This is your template job, which will be copied into many other jobs.
Visit the front page of Jenkins, and verify that the jobs have been created and are based on the Template1 job.
Create a large number of views with a random selection of jobs.
Once you have logged in to Jenkins as an administrator, you can create jobs.
You can do this through the GUI or by sending POST information.
The POST variables you used were name, for the name of the new job, and from, with the name of your template job.
To change the hostname and port number, you will have to update the $host variable found in the Perl script.
To increase the number of form entries, you can change the value of the $end variable.
When you install plugins, the number of potential actions also increases.
This means that you can activate a lot of actions through the HTML forms similar to this recipe.
You will discover in Chapter 7, Exploring Plugins that writing binding code to Stapler requires minimal effort.
In the previous recipe, you discovered that you can save horizontal tab space using the DropDown ViewsTabBar plugin.
In this recipe, you will use the Dashboard view plugin to condense the use of the horizontal space.
The Dashboard view plugin allows you to configure areas of a view, to display specific functionality, for example, a grid view of the jobs or an area of the view that shows the subset of jobs failing.
Note: The developers have made the dashboard easily extensible, so expect more choices later.
Either create a few jobs by hand, or use the HTML form that provisioned jobs in the previous recipe.
As a Jenkins administrator, log in to the home page of your Jenkins instance.
Create a new view by clicking on the + sign in the second tab, at the top of the screen.
Under the Jobs sections, select a few of your fake jobs.
In the left-hand menu, click on the link Edit View.
In the Dashboard Portlets section of the view, select the following:
At the bottom of the configuration screen, press the OK button.
Note: You can expand or contract the areas of functionality with the arrow icon.
During the dashboard configuration, you choose the Jobs Grid and the unstable Jobs Portlets.
Other dashboard Portlets include a jobs list, latest builds, slave statistics, test statistics (chart or grid), test trend chart, and so on.
The Jobs Grid portlet saves spaces compared to the other views, as the density of jobs displayed is high.
Warning: If you are also using the many views tab (see the previous recipe), there is a little glitch.
When you click on the Dashboard tag, the original set of views is displayed, rather than the select-box.
The Dashboard plugin provides a framework for other plugin developers to create dashboard views.
Making noise with HTML5 browsers This recipe describes how to send a custom sound to a Jenkins user's browser when an event, such as a successful build, occurs.
Not only is this good for the developers who enjoy being shouted at, sang to by famous actors, and so on, but also for the system administrators who are looking for a computer in a large server farm.
Make sure that you have a compliant web browser installed, say a current version of Firefox or Chrome.
Select the Job creation link, found on the Jenkins home page.
On success, your browser will play the sound in the EXPLODE.wav file.
Edit your job so that it fails, for example, by adding a non-existent source code repository.
On failure, your web browser will play the doh.wav file.
You have successfully configured your job to play different sounds based on success or failure of the build.
You can refine how the plugin reacts further by configuring which event transitions will trigger a sound.
For example, if the previous build result was a failure and the current build result is a success.
This is defined in the For previous build result set of checkboxes.
It adds the following JavaScript that asynchronously polls for new sounds.
Your browser is doing the majority of the work, freeing server resources.
The Sound plugin also allows you to stream arbitrary sounds to connected web browsers.
Not only is this useful for practical jokes and motivational speeches directed at your distributed team, you can also perform useful actions such as a ten-minute warning alert before restarting a server.
You can find some decent sound collections at http://www.archive.org/details/ opensource_audio.
For example, you can find a copy of the One Laptop per Child music library at http://www.archive.org/details/OpenPathMusic44V2
First, add the sound somewhere on the Internet where it can be found.
To play the sound on any connected web browser, you will need to visit the following address (replacing localhost:8080 with your own address):
An eXtreme view for reception areas Agile projects emphasize the role of communication over the need to document.
Information radiators have two main characteristics: they change over time and the data presented is easy to digest.
The eXtreme Feedback plugin is one example of an information radiator.
If the layout is formatted consistently and displayed on a large monitor, it is ideal for the task.
Consider this also as a positive advertisement of your development process that you can display behind your reception desk, or in a well-frequented social area such as near the coffee machine or project room.
In this recipe, you will add the eXtreme Feedback plugin and modify its appearance, through the HTML tags in the description.
Optimizing the view depends on the monitors used and the distance from the monitor that the audience will view.
The results deliver a beautifully rendered view of the dynamics of your software process.
You can see that the information area is easier to digest than the other projects.
This highlights the need to write consistent descriptions that follow in-house conventions, under a certain length to fit naturally on the screen.
A longer, more descriptive name of a job helps the viewer understand the job's context better.
Information radiators are fun and take a rich variety of shapes and forms.
From different views displayed in large monitors, to USB sponge missile firing, and abuse from voices of famous actors (see the Making noise with HTML5 browsers recipe)
A number of example electronic projects in Jenkins that are worth exploring are:
Mobile presentation using Google Calendar Jenkins plugins can push build history to different well-known social media services.
Two of the main services are Google Calendar (used in agendas) and Twitter.
Modern Android or IOS mobile devices have preinstalled applications for both these services, lowering the barrier to adoption.
In this recipe, we will configure Jenkins to work with Google Calendar.
Make sure you have a test user account for Gmail.
It describes how to add your calendar to a web page.
Cut and paste the supplied code to an empty HTML page.
You will now see the build's success has been published.
By creating a calendar in Google and using just three configuration settings, you have exposed selected Jenkins jobs to Google Calendar.
With the same amount of configuration, you can connect most modern smartphones and tablets to the calendar.
After restarting the Jenkins server, visit the plugin configuration /configure.
If you need to change content for local needs, it is much better to work with the community, adding to the Jenkins SCM, so everyone can see and improve.
You will be told immediately that your content is not internationalized.
It needs to be translated into the languages that Jenkins supports natively.
Luckily, at the bottom of every Jenkins page, there is a link that volunteers can use to upload translations.
The translation effort requires minimal start-up effort and is an easy way to start with an open source project.
Tweeting the world Open source code is malleable; you can download, modify, commit, and review the code and form your own judgment on its quality.
The Twitter channel is great for managers to see a history of success and failures, as they try and form an opinion about whether the roadmap of the product is realistic.
Most modern social devices, such as Android or IOS mobile devices, have Twitter apps built in.
Sakai is an Open Source Learning Management System used by millions of students around the world, including the University of Amsterdam for whom I work.
Sakai uses Jenkins to build its various sub-projects; see @sakaibuilds.
Getting ready Install the Twitter plugin (http://wiki.hudson-ci.org/display/HUDSON/ Twitter+Plugin) and download auth.jar from the same wiki page.
Open the following URL and grant access to your account:
Log in to twitter.com and follow the link mentioned in your output (starting with http://api), copying the PIN number.
You will now see two tokens that you need as configuration in Jenkins, with command-line output similar to:
OAuth is an authentication protocol that allows users to approve applications to act on their behalf, without sharing their password.
You need to be able to provide credentials so that your plugin can send tweets.
The plugin uses out of band agreements, known as oob.
To create the credentials, you needed to fill in a PIN number at the appropriate moment.
You then added the returned token information to the plugin, enabling encryption so that tweeting could commence.
You configured the plugin to supply as much information as possible in the tweet.
The URL to the build information is a tiny URL, which saves space to make the tweet as mobile-friendly as possible.
Almost all modern smartphones have an app for Twitter; however, if you want to compare with a freely available one, then UberSocial (http://ubersocial.com/) is a good alternative.
You can also configure the Ubuntu desktop and most NIX desktops to receive tweets through Gwibber (http://gwibber.com)
Mobile apps for Android and iOS There are a number of rich mobile apps for the notification of Jenkins job statuses.
This recipe points you to their home pages so that you can select your favorite.
Getting ready You will need a Jenkins instance reachable from the Internet, or you can use http://ci.jenkins-ci.org/, an excellent example of best practices.
Review the Jenkins URL; if it is pointing to localhost, change it so that your server links can be reached from the Internet.
Visit the following app pages, and if compatible, install and use them:
On your mobile device, search for Google Apps Marketplace or iTunes, and install any new Jenkins apps that are free and have positive user recommendations.
Most of the apps pull in information using the RSS feeds from Jenkins, such as /rssLatest and /rssFailed, and then load the linked pages through a mobile web browser.
Unless the Jenkins URL is properly configured, the links will break and 404-Page Not Found errors will be returned by your browser.
You will soon notice that there is a delicate balance between the refresh rate of your app potentially generating too many notifications, versus receiving timely information.
The JenkinsMobi application runs in both Android and IOS operating systems.
This choice allowed the app writers to add a wide range of features, making it arguably the most compelling app in the collection.
Here are a few more things for you to consider:
This left much of the third-party Hudson code either less supported or rebranded to Jenkins.
However, Hudson and Jenkins have a large common base, including the content of the RSS feeds.
For older Android versions, such as Android 1.6, you will not see any Jenkins apps in Google Apps Marketplace.
VirtualBox and the Android-x86 project There are a number of options for running Android apps.
The easiest is to download them through Google Apps Marketplace onto a mobile device.
However, if you want to play with Android apps in a sandbox on your PC, consider downloading the Android SDK (http://developer.android.com/sdk/index.html), and use an emulator and a tool such as adb (http://developer.android.com/guide/developing/ tools/adb.html) to upload and install apps.
A significant advantage of this approach is the raw speed of the Android OS and the ability to save the virtual machine in a specific state.
However, you will not always get Google Apps Marketplace preinstalled.
You will either have to find the .apk file for a particular app, yourself, or add other marketplaces, such as SlideME (http://m.slideme.org)
Not only is it an emulator but it also provides a cloud service to move apps from your mobile device into and out of the emulation.
However, if you do choose to use this emulator, please thoroughly review the license you agree to during installation.
BlueStacks wishes to obtain detailed information about your system to help improve their product.
If you have a policy of pushing your build history or other information, such as home pages, to the public, then you will want to know viewer habits.
With Google Analytics, you can watch in real time as visitors arrive at your site.
The detailed reporting mentions things such as overall volume of traffic, browser types, if mobile apps are hitting your site, entry points, country origins, and so on.
This is particularly useful as your product reaches key points in its roadmap and you want to gain insight in customer interest.
In this recipe, you will create a Google Analytics account and configure tracking in Jenkins.
Warning: If you are not the owner of your Jenkins URL, please ask for permission first, before creating a Google Analytics profile.
Fill in the following details on the Create New Account page:
Website's URL: This will be same as the Jenkins URL on the /configure screen of Jenkins.
Time zone: Select the correct value from the drop-down box.
Set the User Agreement—Your country or territory to the correct value.
Check the Terms and conditions box—Yes, I agree to the above terms and conditions.
The tracking status states the following: Tracking Not Installed The Google Analytics tracking code has not been detected on your website's home page.
For Analytics to function, you or your web administrator must add the code to each page of your website.
Open a second browser and log in to Jenkins as an administrator.
Visit the home page of Jenkins so that tracking is triggered.
Return to Google Analytics; you should still be on the Tracking code tab.
You will now see that the warning about tracking not installed has disappeared.
The plugin decorates each Jenkins page with a JavaScript page tracker, which includes domain and Profile ID.
The JavaScript is kept fresh by being pulled in from the Google Analytics hosts.
Google Analytics has the ability to drill into the details of your web usage thoroughly.
Consider browsing Jenkins and reviewing the traffic generated through the real-time reporting feature.
The open source version of Google Analytics is Piwik (http://piwik.org/)
This has the advantage of keeping your usage data local and under your control.
As you would expect, the Piwik plugin is a page decorator injecting similar JavaScript as the Google Analytics plugin.
Some of the build files and code have deliberate mistakes, such as bad naming conventions, poor coding structures, or platform-specific encoding.
These defects exist to give Jenkins a target to fire tests against.
Introduction This chapter explores the use of Jenkins plugins to display code metrics and fail builds.
If you decide the success and failure criteria before a project starts, then this will remove a degree of subjective debate from release meetings.
To save money and improve quality, you need to remove defects as early as possible in the software lifecycle.
Another key benefit is that once you have added tests, it is trivial to develop similar tests for other projects.
Using TDD, you write tests that fail first, and then build the functionality needed to pass the tests.
With BDD, the project team writes the description of tests in terms of behavior.
The wider audience has more influence on the details of the implementation.
Regression tests increase confidence that you have not broken the code while refactoring the software.
The more coverage of code by tests, the more confidence.
The recipe Looking for "smelly" code through code coverage shows you how to measure coverage.
You will also find recipes on static code review through PMD and FindBugs.
Static means that you can look at the code without running it.
It is relatively easy to write new bug detection rules using the PMD rules designer.
FindBugs scans the compiled .class files; you can review the application .jar files directly.
In this chapter, you will use FindBugs to search for security defects and PMD to search for design rule violations.
Also mentioned in this chapter is the use of Java classes with known defects.
We will use the classes to check the value of the testing tools.
This is a similar approach to benchmarks for virus checkers, where virus checkers parse files with known virus signatures.
The advantage of injecting known defects is that you get to understand the rules that are violated.
This is a great way to not only collect real defects found in your projects but also to characterize and reuse real defects.
Consider adding your own classes to projects to see if the QA process picks up the defects.
Good documentation and source code structure aids in the maintainability and readability of your code.
There are other plugins, specific to a given tool, for example, PMD or FindBugs plugins.
The individual plugin reports can be displayed through the Portlets dashboard plugin, which was discussed in the Saving screen space with the Dashboard plugin recipe, Chapter 4, Communicating Through Jenkins.
Jenkins is not limited to testing Java; a number of the plugins, such as sloccount or the DRY plugin (spots duplication of code), are language-agnostic.
There is even specific support for NUnit testing in .NET or compilation to other languages.
If you are missing specific functionality, then you can always build your own Jenkins plugin as detailed in Chapter 7, Exploring Plugins.
In the last recipe of this chapter, you will link Jenkins projects to Sonar reports.
Sonar is a specialized tool that collects software metrics and breaks them down into an understandable report.
It uses a wide range of metrics, including the results of tools such as FindBugs and PMD mentioned in this chapter.
Consider using Jenkins for an early warning and to spot obvious defects, such as a bad commit.
When dealing with multi-module Maven projects, the Maven plugins generate a series of results.
The Maven 2/3 project type rigidly assumes that the results are stored in conventional locations, but this does not always happen consistently.
With freestyle projects, you can explicitly tell the Jenkins plugins where to find the results using regular expressions that are consistent with Ant filesets (http://ant.apache.org/manual/Types/fileset.html)
One way to gain insight into the value of a project is to count the number of lines of code in the project, and divide the count between code languages.
Install sloccount on the Jenkins instance as mentioned at http://www.dwheeler.com/sloccount.
If you are running on a Debian OS, the following installation command will work:
For details on how to install sloccount on other systems, please review http://www.dwheeler.com/sloccount/sloccount.html.
Within the Build section, select Execute shell from Add build step.
Add the following command to it: /usr/bin/sloccount –duplicates –wide –details.
In the Post-build Actions section, check Publish SLOCCount analysis results, adding sloccount.sc to the text input SLOCCount reports.
The Jenkins plugin converts the results generated by sloccount into detailed information.
The report is divided into a three-tabbed table summed and sorted by files, folders, and languages.
From this information, you can estimate the degree of effort it would take to recreate the project from scratch.
The description of the Job includes a small amount of JavaScript pointing to Ohloh.net, a trusted third-party service.
Ohloh allows you to add widgets to your web page with statistics.
Ohloh is a well-known service with well-described privacy rules (http://www.ohloh.net/ about/privacy)
However, if you do not have complete trust in the reputation of a thirdparty service, then don't link in through a Jenkins description.
Information about the Sakai Learning Management System can be found by visiting http://www.ohloh.net/p/3551
The shortenedURL service is one small part of this whole.
The combined statistics allows visitors to gain a better understanding of the wider context.
Software cost estimation Sloccount uses the COCOMO model (http://en.wikipedia.org/wiki/COCOMO) to estimate the cost of projects.
You will not see this in the Jenkins report, but you can generate the estimated costs if you run sloccount from the command line.
The element that changes the most over time is personcost (in dollars)
You can change the value with the command-line argument personcost.
Goodbye Google code search, hello Koders.com Google has announced that it has closed its source code search engine.
Luckily, koders.com, another viable search engine, announced that it will provide coverage of the code bases described at ohloh.net.
Between koders.com and ohloh.net, you will be able to review a significant selection of open source projects.
This recipe uses Cobertura (http://cobertura.sourceforge.net/) to find the code that is not covered by unit tests.
With consistent practice, writing unit tests will become as difficult as writing debugging information to stdout.
Most popular Java-specific IDE's have built-in support for running unit tests.
If your code does not have regression tests, the code is more likely to break during refactoring.
Measuring code coverage can be used to search for hotspots of non-tested code.
Test the code coverage of the unmodified project with the following command:
Review the output from Maven, and it will look similar to the following:
Review the Maven output, noticing that println from within the Dicey constructor is also included.
Your project now has the code coverage, and you can see which lines of code have not yet been called.
Under the build section for Goals and Options, set the value to clean cobertura: cobertura.
The HTML report allows you to quickly review the code status from the command line.
The XML report is needed for parsing by the Jenkins plugin.
You had placed the plugin configuration in the build section rather than the reporting section to avoid having to run the site goal with its extra phases.
The free-style project was used so that the cobertura plugin picks up multiple XML reports.
The clean goal removes all target directories including any previously compiled and instrumented code.
The testApp unit test called the constructor for the Dicey class.
This mimics a dice and chooses between two branches of an if statement.
The cobertura report allows you to zoom in to the source code and discover which choice was made.
If you refactor the code, you will not have unit tests in these areas to spot when the code accidentally changes behavior.
The report is also good at spotting the code of greater complexity than its surroundings.
The more complex the code, the harder it is to understand, and the easier it is to introduce mistakes (http://www.ibm.com/developerworks/java/library/jcq01316/index.html?ca=drs)
An alternative open source tool to Cobertura is emma: http://emma.sourceforge.
In Maven, you do not have to add any configuration to pom.xml.
You simply need to run the goals clean emma:emma package, and point the Jenkins plugin at the results.
Activating more PMD rulesets PMD has rules for capturing particular bugs.
For example, there is a ruleset with a theme about Android programming another for code size or design.
The main risk is that the extra rules generate a lot of false positives, making it difficult to see real defects.
The benefit is that you will capture a wider range of defects, some of which are costly if they get to production.
Test your project with the following command: mvn clean site.
This is due to the extra rules added to pom.xml.
Within the build section for Goals and options, set the value to clean site.
To generate a trend, you will need to run the Job twice.
The Maven PMD plugin tested a wide range of rulesets.
By downloading the binary package from the PMD website, you can find the paths of the rulesets by listing the contents of the pmd.jar file.
Under a *NIX system, the command to do this is:
You had added a standard candle, a Java class with known defects that trigger PMD warnings.
For example, there are multiple defects in the following two lines of code:
Placing the literal first returns false when myString is null.
There is an issue with the lack of braces around the if statement.
The same counts for the lack of a command to run when the if statement is triggered.
Another trivial example is hardcoding infrastructural details into your source; for example, passwords, IP addresses, and usernames.
It is far better to move the details out into property files that reside only on the deployment server.
The following line tests PMD for its ability to find this type of defect:
Both FindBugs and PMD have their own set of bug pattern detectors.
It is, therefore, worth running both the tools to capture the widest range of defects.
A couple of other static code review tools you may be interested in are QJPro (http://qjpro.sourceforge.net/) and Jlint (http://jlint.sourceforge.net/)
Out of the box, PMD tests for a sensible set of bug defects, however, each project is different, and you will need to tweak.
Throttling down PMD rulesets You can find the current PMD rulesets at http://pmd.sourceforge.net/rules/index.html.
It is important to understand the meaning of the rulesets, and shape the Maven configuration to include only the useful ones.
If you do not do this, then for a medium-sized project, the report will include thousands of violations, hiding the real defects.
The report will then take time to render in your web browser.
Consider enabling a long list of rules only if you want to use the volume as an indicator of project maturity.
To throttle down, exclude parts of your code, and systematically clean up the areas reported.
The "don't repeat yourself" principle Cut-and-paste programming, cloning, and then modifying code makes for a refactoring nightmare.
If the code is not properly encapsulated, it is easy to have slightly different pieces scattered across your code base.
If you then want to remove known defects, it will require extra effort.
However, the PMD plugin does not pick up the results (stored in cpd.xml)
If you have downloaded the PMD binary from its website (http://sourceforge.net/projects/pmd/files/pmd/), then in the bin directory is cpdgui.
It is a Java swing application that allows you to explore your source code for duplications.
Creating custom PMD rules PMD has two extra features when compared to other static code review tools.
The first is the cpdgui tool, which allows you to look for the code that has been cut-and-pasted from part of the code base to another.
The second, and the one that we will explore in this recipe, is the ability to design custom bug discovery rules for Java source code using Xpath.
Visit the PMD bin directory, and verify that you have the startup scripts designer.sh and designer.bat.
Depending on your operating system, run pmd designer using either the startup script bin/designer.sh or bin/designer.bat.
Under the Actions menu option at the top of the screen, select Create rule XML, and add the following values:
Rule msg: If we see a PASSWORD we should flag.
Within the build section for Goals and Options, set the value to clean pmd:pmd.
The designer tool enables you to write Xpath rules and tests your rules against a source code example.
For readability, it is important that the source code you test against contains only the essential details.
To bundle the XML rules together, you have to add the rules as part of a <ruleset> tag.
The Maven PMD plugin has the ability to read the rulesets from within its classpath, on the local file system or through the http protocol from a remote server.
If you build up a set of rules, then you should pull all the rules into one project for ease of management.
You can also create your own custom ruleset based on already existing rules, pulling out your favorite bug detection patterns.
This is achieved by the <rule> tag with a ref pointing to the known rule; for example, the following pulls out the DuplicateImports rule from the imports.xml ruleset:
The rule generated in this recipe tested for variables with the name PASSWORD.
I have seen the rule trigger a number of times in real projects.
The PMD home page is a great place to learn about what is possible with the Xpath rules.
It contains descriptions and details of the rulesets; for example, for the logging rules, review http://pmd.sourceforge.net/rules/logging-java.html.
It would be efficient if static code review tools could make recommendations about how to fix the code.
However, that is a little dangerous as the detectors are not always accurate.
As an experiment, I have written a small Perl script to first repair the literals and also discard some wasting of resources.
The code is a "Proof Of Concept", and thus is not guaranteed to work correctly.
Finding bugs with FindBugs It is easy to get lost in the volume of defects found by static code review tools.
Another Quality Assurance attack pattern is to clean up the defects package by package, concentrating developer time on the most used features.
This recipe will show you how to generate and report defects found by FindBugs for specific packages.
Within the build section for Goals and options, set the value to clean compile findBugs:findBugs.
Under the Build settings section, check Publish FindBugs analysis results.
A handy feature of the FindBugs report is that for each warning you can view the offending code.
In this recipe, you have created a standard Maven project and added a Java file with known defects.
The line in the standard candle with guess==answer is a typical programming defect.
Two references to objects are being compared rather than the values of their Strings.
As the guess object was created on the previous line, the result will always be false.
These sorts of defects can appear as subtle problems in programs.
The JVM caches Strings, and occasionally two apparently different objects are actually the same object.
FindBugs is popular among developers and has plugins for a number of popular IDEs.
Its results are often used as part of wider reporting by other tools.
The FindBugs Eclipse plugin The automatic install location for the Eclipse plugin is http://findbugs.cs.umd.edu/eclipse.
By default, the FindBugs Eclipse plugin has a limited number of rules enabled.
To increase the set tested, you will need to go to the Preferences menu option under Window, selecting FindBugs from the left-hand menu.
On the right-hand side, you will see the Reported (Visible) bug categories under Reporter Configuration.
The Xradar and Maven dashboards There are alternative Maven plugin dashboards for the accumulation of generated software metrics.
You will need to connect it to its own database.
Xradar and QALab are other, arguably less popular, examples of dashboards.
Enabling extra FindBugs rules FindBugs has a wide range of auxiliary bug pattern detectors.
This recipe details how to add the extra bug detectors to FindBugs from the fb-contrib project and use the detectors to capture known defects.
Getting ready It is assumed that you have followed the previous recipe, Finding bugs with FindBugs.
You will be using the recipe's Maven project as a starting point.
Under the Source Code Management section, check the Subversion radio box, adding the URL to your code for the Repository URL.
When the Job is finished building, review the FindBugs Warnings link.
The Java language has a number of subtle boundary cases that are difficult to understand until explained by real examples.
An excellent way to capture knowledge is to write examples yourself, when you see issues in your code.
Injecting standard candles is a natural way of testing your team's knowledge and makes for target practice during the QA process.
The FindBugs project generated some of their detectors, based on the content of Java puzzlers, Joshua Bloch and Neal Gafter (http://www.javapuzzlers.com/)
To include external detectors, you added an extra line to FindBugs' Maven configuration:
It is worth visiting SourceForge to check for the most up-to-date version of the detectors.
Currently, it is not possible to use Maven's dependency management to pull in the detectors through from a repository, though this might change.
In this recipe, you have added a Java class to trigger the new bug detection rules.
The antipattern is the unnecessary line with the creation of the answer object before the return.
It is more succinct to return the object anonymously, for example:
Finding security defects with FindBugs In this recipe, you will use FindBugs to discover a security flaw in a Java Server Page and some more security defects in a defective Java class.
Getting ready Either follow the recipe Failing Jenkins Jobs based on JSP syntax errors, Chapter 3, Building Software, or use the provided project downloadable from the Packt website.
Under the Source Code Management section, check the Subversion radio box, adding your subversion repository location in the Repository URL text input.
Beneath the Build section for Goals and options, set the value to clean package findbugs:findbugs.
When the Job has completed, review the link FindBugs Warning.
However, the link fails to find the location of the source code.
JSP's are first translated from text into Java source code and then compiled.
The original JSP project has a massive security flaw—it trusts input from the Internet.
Parsing the input with white lists of allowed tokens is one approach to diminishing the risk.
The messages are displayed because you had turned them on in the configuration with the following option:
The FindBugs plugin has not been implemented to understand the location of JSP files.
When clicking on a link to the source code, the plugin will look in the wrong place.
A temporary solution is to copy the JSP file to the location the Jenkins plugin expects.
The line number location reported by FindBugs also does not make sense.
It is pointing to the line in the .java file that is generated from the .jsp file, and not directly the JSP file.
Despite these limitations, FindBugs discovers useful information about JSP defects.
From the command line, you can configure it to scan JSP files only with the option –jsponly; see http://pmd.sourceforge.net/jspsupport.html.
Although FindBugs has rules that sit under the category security, there are other bug detectors that find security-related defects.
The first is a recursive loop that will keep calling the same method from within itself:
Perhaps the programmer intended to use a counter to force an exit after 99 loops, but the code to do this does not exist.
The end result, if this method is called, is that it will keep calling itself until the memory reserved for the stack is consumed and the application fails.
If an attacker knows how to reach this code, they can bring down the related application, a Denial Of Service attack.
The other attack captured in the standard candle is the ability to change the content within an array that appears to be immutable.
It is true that the reference to the array cannot be changed, but the internal references to the array elements can.
In the example, a motivated cracker, having access to the internal objects, is able to change the READ permissions to READ/WRITE permissions.
To prevent this situation, consider making a defensive copy of the original array passing the copy to the calling method.
Verifying HTML validity This recipe tells you how to use Jenkins to test HTML pages for validity against HTML and CSS standards.
The unified validator will check your web pages for correctness against a number of aggregated services.
Within the build section, add a build step by selecting Unicorn Validator.
For the Site to validate input, add a URL to a site that you are allowed to test.
For the properties file content, you will see content similar to YVALUE=2
In the Post-build Actions section, check Plot build data, and add the following details:
Verify that Load data from properties file radio box is checked.
The Unicon validation plugin uses the validation service at W3C to generate a report on the URL you configure.
The returned report is processed by the plugin, and absolute counts of the defects are taken.
The summation is then placed in the property file, where the values are then picked up by the plotting plugin (see the recipe Plotting alternative code metrics in Jenkins in Chapter 3, Building Software)
If you see a sudden surge in the warnings, then review the HTML pages for repetitive defects.
It is quite difficult to obtain a decent code coverage from unit testing.
This is especially true for larger projects where there are a number of teams with varying practices.
You can increase your automatic testing coverage of web applications considerably by using tools that visit as many links in your application as possible.
This includes HTML validators, link checkers, search engine crawlers, and security tools.
Consider setting up a range of tools to hit your applications during integration testing, remembering to parse the logfiles for unexpected errors.
You can automate log parsing using the recipe Deliberately failing builds through log parsing, Chapter 1, Maintaining Jenkins.
Reporting with JavaNCSS JavaNCSS (http://javancss.codehaus.org/) is a software metrics tool that calculates two types of information.
The first are totals for number of source code lines in a package that are active, commented, or JavaDoc related.
The second type calculates the complexity of code, based on how many different decision branches exist.
The Jenkins JavaNCSS plugin ignores the complexity calculation and focuses on the more understandable line counts.
Under the build section for the Goals and options type, clean javancss:report.
Review the top-level pom.xml configuration in the Workspace; for example:
The Job pulled in source code from Sakai's subversion repository.
The project is a multi-module with the API separated from the implementation.
JavaNCSS needs no compiled classes or modifications to the Maven pom.xml.
The Job ran a Maven goal, publishing the report through the JavaNCSS Jenkins plugin.
Reviewing the report, it's observed that the implementation has many more numbers of lines of active code relative to other packages.
Documentation of APIs is vital for the reuse of the code by other developers.
The abbreviations in the summary table have the following meanings:
This is not fully indicative, as most modern IDEs generate classes using boilerplate templates.
Therefore, you can have a lot of JavaDoc generated of poor quality, creating misleading results.
The build summary displays information about changes (deltas) between the current and the last Jobs; for example:
Within the summary, the + character signals that code has been added and the – character that the code has been deleted.
If you see a large influx of code, but a lower than usual influx of JavaDoc, then either the code is auto-generated or is more likely being rushed to market.
When you get used to the implications of the relatively simple summary of JavaNCSS, consider adding JDepend to your safety net of code metrics.
One of the most important metrics that JDepend generates is that of cyclic dependency.
If class A is dependent on class B, and in turn, class B is dependent on class A, then that is a cyclic dependency.
When there is such a dependency, it indicates that there is an increased risk of something going wrong, such as a fight for a resource, an infinite loop, or synchronization issues.
Refactoring may be needed to eliminate the lack of clear responsibilities.
Checking style using an external pom.xml If you just want to check the code style for the quality of its documentation without changing its source, then inject your own pom.xml file.
This recipe shows you how to do this for checkstyle.
Checkstyle is a tool that mostly checks documentation against well-defined standards, such as the Sun coding conventions.
Create a new directory in your subversion repository for this recipes code.
Under the Source Code Management section, check Subversion, add your subversion repository URL to Repository URL, and the value ./OVERRIDE to Local module directory (optional)
In the Pre-Steps section, for the Add pre-build step, select the option Execute shell.
Run the Job a number of times, and review the output.
The profile2 tool is used by many millions of users around the world within the Sakai Learning Management System (http://sakaiproject.org)
It is a social hub for managing what others can see of your account details.
The project divides the code between implementation, API, and model.
In this recipe, you had created a replacement pom.xml file.
You did not need to copy any of the dependencies from the original pom.xml, as checkstyle does not need compiled code to do its calculations.
However, the location of the modules was needed for it to know where to look for the code.
The injected pom.xml file is pulled into its own repository in the Jenkins workspace by configuring the Local module directory (optional) option.
This avoids the injected code being overwritten when Jenkins pulls in the profile2 source code.
The job then copies the injected pom.xml file to the main workspace directory so that it can find the modules in the correct relative location.
Checkstyle was not configured in detail in pom.xml, because we were only interested in the overall trend.
However, if you want to zoom in to the details, checkstyle can be configured to generate results based on specific metric, such as the complexity of Boolean expressions or the Non Commenting Source Statements (NCSS)—http://checkstyle.sourceforge.
You can view the statistics from most quality-measuring tools remotely by using the Jenkins XML API.
For example, a URL similar to the following will work in the case of this recipe:
The returned results for this recipe look similar to the following:
To obtain the data remotely, you will need to authenticate.
For information on how to perform remote authentication, review the Remotely triggering Jobs recipe, Chapter 3, Building Software.
Faking checkstyle results This recipe details how you can forge checkstyle reports.
The benefit of this method, when compared to custom plotting, is the more logical test results location in Jenkins.
Getting ready If you have not already done so, install checkstyle and create a new directory in your subversion repository for the code.
Create a Perl script file named generate_data.pl with the following content:
Run the Job a number of times, and review the results and trend.
The details report is linked to the correct line number in an HTML version of the source code.
The plugins used in this chapter store their information in XML files.
We chose the simplest XML structure to fake the results.
The Jenkins plugin opens the file found at this location so that it can display it as source code.
You may not have to force your results into a fake format.
It is a utility plugin that supports the conversion of the results from different regression test frameworks.
The plugin translates the different result types into a standardized JUnit format.
Integrating Jenkins with Sonar Sonar is a rapidly evolving application for reporting quality metrics and finding code hotspots.
This recipe details how, through a Jenkins plugin, to generate code metrics and push them directly to a Sonar database.
You can run directly from within the bin directory, by selecting the OS directory underneath.
Within the Build Triggers section, verify that no build triggers are selected.
Under the Build section for Goals and options, add clean install.
Click on the Sonar link, and review the newly generated report.
The default Sonar instance is pre-configured with an in-memory database.
The Jenkins plugin already knows the default configuration and requires little extra configuration.
The Jenkins Sonar plugin does not need you to reconfigure your pom.xml.
The Jenkins plugin handles all the details itself for generating results.
The Job first ran Maven to clean out the old compiled code from the workspace, and then ran the install goal, which compiles the code as part of one of its phases.
The Jenkins Sonar plugin then makes direct contact with the Sonar database and adds the previously generated results.
You can now see the results in the Sonar application.
Sonar is a dedicated application for measuring software quality metrics.
Features, such as its ability to point out hotspots of suspicious code, a visually appealing report dashboard, ease of configuration, and detailed control of inspection rules to view, currently differentiate it from Jenkins.
Sonar plugins It is easy to expand the features of Sonar by adding extra plugins.
You can find the official set mentioned at the following URL:
The plugins include a number of equivalent features to the ones you can find in Jenkins.
This is where code coverage is used to defend the quality of a project.
Aggregating results using the Violations plugin The Jenkins Violations plugin accepts the results from a range of quality metrics tools and combines them into a unified report.
This plugin is the nearest equivalent to Sonar within Jenkins.
Before deciding if you need an extra application in your infrastructure, it is worth reviewing to see if it fulfills your quality metrics needs.
Introduction By the end of this chapter, you will have ran performance and functional tests against web applications and web services.
The first is the deployment of a war file through Jenkins to an application server.
The second is the creation of multiple slave nodes, ready to move the hard work of testing away from the master node.
Remote testing through Jenkins considerably increases the number of dependencies in your infrastructure, and thus the maintenance effort.
Remote testing is problem domain-specific, decreasing the size of the audience that can write tests.
This chapter emphasizes the need to make test writing accessible to a large audience.
Embracing the largest possible audience improves the chances that the tests defend the intent of the application.
Having a wiki-like language to express and change tests on the fly gives functional administrators, consultants, and the end users a place to express their needs.
You will be shown how to run Fitnesse tests through Jenkins.
Fitnesse is also a framework where you can extend Java interfaces to create new testing types.
There are a number of fixtures available, including ones for database testing, running tools from the command line, and functional testing of web applications.
It can also be used to functionally test through the use of assertions.
JMeter has a GUI that allows you to build test plans.
The test plans are then stored in an XML format.
JMeter is very efficient, and one instance is normally enough to hit your infrastructure hard.
However, for super high load scenarios, JMeter can trigger an array of JMeter instances.
With Selenium IDE, you can record your actions within Firefox, saving them in an HTML format to replay later.
It is common to use Jenkins slaves with different OSs and browser types to run the tests.
Selenium RC is a proxy that controls the web browser.
In contrast, the Webdriver framework uses native API calls to control the web browser.
You can even run the HtmlUnit framework, removing the dependency of a real web browser.
This enables OS-independent testing, but removes the ability to test for browser-specific dependencies.
The tool can read Web Service Definition Language (WSDL) files publicized by web services, using the information to generate the skeleton for functional tests.
Deploying a WAR file from Jenkins to Tomcat The three main approaches to deploying web applications for integration tests are as follows:
The applications database is normally in-memory, and the data stored is not persisted past the end of the Job.
This saves cleaning up and eliminates unnecessary dependency on the infrastructure.
This normally happens at night when no one is using the infrastructure, hence the name.
The advantage of this approach are a distributed team that knows exactly when and at which fixed web address a new build exists.
First, package the web application in Jenkins, and then deploy it to an application server.
It is now ready for testing by a second Jenkins Job.
The disadvantage of this approach is that you are replacing an application on the fly, and the host server might not always respond stably.
In this recipe, you will be using the Deploy plugin to deploy a war file to a remote Tomcat 7 server.
This plugin can deploy across a range of server types and version ranges including Tomcat, GlassFish, and JBoss.
Create a Maven project for a simple WAR file using the following command line:
Under the Source Code Management section, check the subversion radio box, adding your own subversion repository URL to Repository URL.
In the Build section, add clean package for Goals and options.
In the Post-build Actions section, check Deploy war/ear to a container, adding the following configuration:
At the time of writing, the deploy plugin deploys to the following server types and versions:
In this recipe, Jenkins packages a simple WAR file and deploys to a Tomcat 7 instance.
By default, Tomcat listens on port 8080, as does Jenkins.
By editing conf/server.xml, the port was moved to 38887, avoiding conflict.
In fact, the new user has more powers than is needed for deployment.
The user has the power to review the JMX data for monitoring.
When deploying in production, use an SSL connection to avoid sending passwords unencrypted over the wire.
On startup, the Tomcat logs mention that the Apache Tomcat Native library is missing.
INFO: The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.
The library improves the performance, and it is based on Apache Portable Runtime Projects effort (http://apr.apache.org/)
Creating multiple Jenkins nodes Testing is a heavy weight process.
If you want to scale your services, then you will need to plan to offset most of the work to other nodes.
One evolutionary path for Jenkins in an organization is to start off with one Jenkins master.
As the number of Jobs increases, we need to push off the heavier Jobs, such as testing, to slaves.
This leaves the master the lighter and more specialized work of aggregating the results.
It is Ubuntu-specific, allowing Jenkins to install, configure, and command the slave through SSH.
Getting ready In Jenkins, install the multi slave config plugin.
You will also need to have a test instance of Ubuntu as described in the recipe Using a sacrificial Jenkins instance, Chapter 1, Maintaining Jenkins.
From the command line of the sacrificial Jenkins instance, create the user jenkinsunix-nodex.
Generate a private key and a public certificate for Jenkins with an empty passphrase:
Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.
Add unix-node01 to Create slaves by names separated with space.
Select for Launch method Launch slave agents on Unix machines via SSH, adding the following details:
In this recipe, you have deployed one node locally to a *NIX box.
The account is provisioned with the public key of the Jenkins user for easier administration.
Jenkins can now use ssh and scp without a password.
The Multi slave config plugin takes the drudgery out of deploying slave nodes.
It allows you to copy from one template slave and deploys a number of nodes.
Jenkins can run nodes in a number of different ways.
One alternative is to install Cygwin (http://www.cygwin.com/) with SSH daemon on Windows.
If you want to have your UNIX scripts running in Windows under Cygwin, consider installing the Cygpath plugin.
The configured node has three labels assigned: unix, dumb, and functional.
When creating a new Job, checking the setting Restrict where this project can be run and adding one of the labels will ensure that the Job is run on a node with that label.
The Master calculates which node to run a Job based on a priority list.
Unless otherwise configured, Jobs created when there was only a master will still run on the master.
Consistency breeds reliability: When deploying more than one Jenkins node, it saves effort if you are consistent with the structure of their environments.
Consider using a virtual environment starting from the same basic set of images.
CloudBees (http://www.cloudbees.com) is one example of a commercial service centered on deployment of virtual instances.
This will decrease the amount of effort in writing the client-side code.
You can set the port number of the daemon through the Jenkins management web page, or leave the port number to float.
Jenkins publishes the port number using header information for X-SSH-Endpoint.
To see for yourself, telnet into Jenkins and Get the login page.
For example, for *NIX systems from the command line, try the following:
Testing with Fitnesse Fitnesse (http://fitnesse.org) is a fully-integrated standalone wiki, and acceptance-testing framework.
Writing tests in a wiki language widens the audience of potential test writers and decreases the initial efforts in learning a new framework.
If a test passes, the table row is displayed in green.
The tests can be surrounded by wiki content delivering context information, such as user stories, at the same location as the tests.
You can also consider creating mock-ups of your web applications in Fitnesse next to the tests, and point the tests at those mock-ups.
This recipe describes how to run Fitnesse remotely and displays the results within Jenkins.
Getting ready Download the latest stable Fitnesse JAR from http://fitnesse.org/FrontPage.
Create the directories fit/logs, and place in the fit directory fitnesse.jar.
Run the Fitnesse help from the command line, and review the options.
Run Fitnesse from the command line, and review the startup output.
Depending on your computer, the tests may take a few minutes to complete.
You will need to log on as user tester with the password as test.
Log in to Jenkins, and create a freestyle software project named ch6.remote.
Check the option Fitnesse instance is already running, and add the following details:
Review the latest job by clicking on the link FitNesse Results.
Fitnesse has a built-in set of acceptance tests, which it uses to check itself for regressions.
By default, there is no security enabled on Fitnesse pages.
In this recipe, a username and password were defined during startup.
However, we did not take this further, and defined the security permissions on the page.
To activate, you will need to go to the properties link on the left-hand side of a page, and check the security permission for secure-test.
You can also authenticate through a list of users in a text file or Kerberos/Active Directory.
Consider applying security in depth: Adding IP restrictions through a firewall on the Fitnesse server creates an extra layer of defense.
For example, you can place an Apache server in front of the wiki, and enabling SSL/TLS ensures encrypted passwords.
Unfortunately, at the time of writing, the last release was in 2006, so do not expect any software updates soon.
It is possible to write your own testing types known as fixtures, and call the new test types through Fitnesse tables.
This allows Jenkins to run alternative tests than the ones available.
This recipe shows you how to integrate Functional tests using an HtmlUnit fixture.
The same approach can be used for other fixtures as well.
Getting ready This recipe assumes that you have already performed testing with the Fitnesse recipe.
At the bottom of the page, add the text ThisIsMyPageTest.
It fails because of the extra debugging information sent with the results, confusing the Jenkins plugin parser.
Run the Jenkins Job again; the results will now be parsed.
By placing the downloaded libraries in the Fitnesse lib directory, you are making them accessible.
You then defined the classpath and location of the fixture in the root page, allowing the fixture to be loaded at the startup.
Next, you created the link using wiki camelcase notation to the non-existent ThisIsMyPageTest page.
First, you needed to import the fixture whose library path was defined in the root page.
Next, some example descriptive wiki content was added to show that you can create a story without affecting the tests.
The first row of the table, !|HtmlFixture|, defines which fixture to use.
Print commands, such as Print Cookies or Print Response Headers, return information that is useful for building tests.
If you are not sure of a list of acceptable commands, then deliberately make a syntax error and the commands will be returned as results.
The Has Text command is an assertion and will fail if the login is not found in the text of the returned page.
By focusing on a specific element and then Set Value, you can add input to a form.
During testing, if you want to display the returned content for a particular request, then you need three columns instead; for example, the first row with three columns displays the returned page, and the second row with two columns does not.
Returning HTML pages as part of the results adds extra information to the results that the Jenkins plugin needs to parse.
Therefore, in step 19, you removed the extra columns, ensuring reliable parsing.
Full documentation for this fixture can be found at http://htmlfixtureim.
Fitnesse has the potential to increase the vocabulary of remote tests that Jenkins can perform.
A few interesting fixtures to review are listed as follows:
Running Selenium IDE tests Selenium IDE allows you to record your clicks within web pages and replay them in Firefox.
This recipe shows you how to replay the tests automatically using Maven and then Jenkins.
It uses an in-memory X server Xvfb (http://en.wikipedia.org/wiki/Xvfb) so that Firefox can be run on an otherwise headless server.
Maven runs the tests using Selenium RC, which then acts as a proxy between the tests and the browser.
Although we record with Firefox, you can run the tests with the other browser types as well.
To install Xvfb in a Debian Linux environment, run sudo apt-get install xvfb.
Run the Maven project from the command line, verifying that the build succeeds.
Run mvn clean, and then commit the project to your subversion repository.
In the global section (at the top of the configuration page), check Prepare an environment for the job, adding DISPLAY=:20 for Properties Content.
Add the text target/results to the input for Selenium test results location.
Check Set build result state to failure if an exception occurred while parsing results file.
A primitive Selenium IDE test suite was created comprising two HTML pages.
The first TestSuite.xhtml defines the suite having HTML links to the tests.
The test hits the login page for your local Jenkins and verifies that the login text is present.
The default configuration is for Xvfb to accept input on DISPLAY 20:
Maven assumes that the Xvfb binary is installed and does not try to download it as a dependency.
In a complex Jenkins environment, it is this type of dependency that is the most likely to fail.
There has to be a significant advantage to automatic functional testing to offset the increased maintenance effort.
The option Multiwindow is set to true as the tests run in their own Firefox window.
The option Background is set to true so that Maven runs the tests in the background.
The Jenkins Job sets the DISPLAY variable to 20 so that Firefox renders within Xvfb.
It then runs the Maven Job, generating the results page.
Two ways to increase the reliability of your automatic functional tests are:
However, you will then lose the ability to perform cross-browser checks.
Similar to Selenium RC, Webdriver can be run against a number of different browser types.
The next recipe will showcase using unit testing with Webdriver and HtmlUnit.
On my development Jenkins Ubuntu server, the Job running this recipe broke.
The reason was that the dependencies in the Maven plugin for Selenium did not like the newer version of Firefox that was installed by an auto-update script.
The resolution to the problem was to install the binary for Firefox 3.63 under the Jenkins home directory, and point directly at the binary in pom.xml, replacing:
Another cause of issues is the need to create a custom profile for Firefox that includes helper plugins to stop pop ups or the rejection of self-signed certificates.
An alternative to using Firefox as a browser is Chrome.
In the Maven pom.xml file, you will have to change the browser to *chrome.
Unit tests are a natural way for programmers to defend their code against regressions.
Writing unit tests should be as easy as writing print statements.
JUnit (http://www.junit.org/) is a popular unit test framework for Java; TestNG (http://testng.org/doc/index.html) is another.
This recipe uses Webdriver and HtmlUnit in combination with TestNG to write simple and automated functional tests.
Using HtmlUnit instead of a real browser makes for stable OS agnostic tests, which, although does not test browser compatibility, can spot the majority of functional failures.
Under Modules/Repository URL, add the location of your local subversion repository.
In the Build section for Goals and options, add clean verify.
After a successful build, you will see a link to Latest Test Results, which details the functional tests.
Maven uses the failsafe plugin (http://maven.apache.org/plugins/mavenfailsafe-plugin) to run integration tests.
The plugin does not fail a build if its integrationtest phase contains failures.
If you are going to use a real browser, then you will need to define their Maven dependencies.
For further details on how the failsafe plugin works with the TestNG framework, see http://maven.apache.org/plugins/maven-failsafe-plugin/examples/ testng.html.
The Java class uses annotations to define in which part of the unit testing cycle the code will be called.
BeforeSuite calls the creation of the Webdriver instance at the start of the suite of tests.
AfterSuite closes down the driver after the tests have run.
The test visits the Google page and verifies the existence of the title.
HtmlUnit notices some errors in the stylesheet and JavaScript of the returned Google page and resources; however, the assertion succeeds.
The main weakness of the example tests is the failure to separate the assertions from the navigation of web pages.
The test assertions are then run in separate classes, comparing the members of the Page objects returned with expected values.
An excellent framework in Groovy that supports the Page Object architecture is Geb (http://www.gebish.org/)
A picture can save a thousand words of descriptive text.
The most significant limitation is that screenshooting does not work with the HtmlUnit driver: http://code.google.com/p/selenium/issues/detail?id=1361
Creating JMeter test plans JMeter (http://jmeter.apache.org) is an open source tool for stress testing.
It allows you to visually create a test plan, and hammer systems based on that plan.
JMeter can make many types of requests known as samplers.
It can sample HTTP, LDAP, databases, use scripts, and much more.
In this recipe, you will write a test plan for hitting web pages whose URLs are defined in a textfile.
In the next recipe, Reporting JMeter test plans, you will configure Jenkins to run JMeter test plans.
JMeter is a Java application, so will run on any system that has Java correctly installed.
The GUI will start up with a new test plan.
This is important if you want to keep a track through cookies between requests.
For example, if a thread logs in to a Tomcat server, then the unique Jsessionid needs to be stored for each thread.
This is great for debugging, but should be removed later.
A common mistake is to assume that a thread is equivalent to a user.
The main difference is that threads can respond faster than an average user.
If you do not add delay factors in the request, then you can really hammer your applications with a few threads.
For example, a delay of 25 seconds per click is typical for the online systems at the University of Amsterdam.
If you are looking to coax out multi-threading issues in your applications, then use a random delay element rather than a constant delay.
This is also a better simulation of a typical user interaction.
Consider storing User-Agents and other browser headers in a textfile, and then picking the values up for HTTP requests through the CSV Data Set Config element.
This is useful if resources returned to your web browser, such as JavaScript or images, depend on the UserAgents.
JMeter can then loop through the User-Agents, asserting that the resources exist.
Reporting JMeter performance metrics In this recipe, you will be shown how to configure Jenkins to run a JMeter test plan, and then collect and report the results.
The passing of variables from an Ant script to JMeter will also be explained.
Getting ready It is assumed that you have run through the last recipe, Creating JMeter test plans.
Within the Build section, add the build step Invoke Ant.
Press Advanced in the new Invoke Ant sub-section, adding the following for properties: Jvarg=-Xmx512m desc= This is the first iteration in a performance test environment – Driven by Jenkins.
Run the Job a couple of times, and review the results found under the Performance trend link.
The JAR file is installed as part of the standard JMeter distribution.
Any JMeter test plan found under the plans directory will be run.
Moving the test plan from the examples directory to the plans directory activates it.
The Jenkins Job runs the Ant script, which in turn runs the JMeter test plans and aggregates the results.
The Jenkins performance plugin then parses the results, creating a report.
You can run it on a given port on your local machine, setting the proxy preferences in your web browser to match.
The recorded JMeter elements will then give you a good idea of the parameters sent in the captured requests.
An alternative is BadBoy (http://www.badboysoftware.biz/docs/jmeter.htm), which has its own built-in web browser.
It allows you to record your actions in a similar way to Selenium IDE, and then save to a JMeter plan.
Functional testing using JMeter assertions This recipe will show you how to use JMeter assertions in combination with a Jenkins Job.
JMeter can test the responses to its HTTP requests and other samplers with assertions.
This allows JMeter to fail Jenkins builds based on a range of JMeter tests.
This approach is especially important when starting from an HTML mockup of a web application, whose underlying code is changing rapidly.
The test plan logs in and out of your local instance of Jenkins, checking size, duration, and text found in the login response.
Getting ready We assume that you have already performed the Creating JMeter test plans and Reporting JMeter performance metrics recipes.
The recipe requires the creation of a user tester1 in Jenkins.
Remember to delete the test user once it is no longer needed.
Create a user in Jenkins named tester1 with password testtest.
Save the Test plan and commit to your local subversion repository.
Any JMeter test plan found under the plans directory is called during the running of the Jenkins Job.
You created a new test plan with two HTTP request samplers.
The response contains a cookie with a valid session ID, which is stored in the cookie manager.
Three assertion elements were also added as children under the HTTP request login sampler.
If any of the assertions fail, then the HTTP request result fails.
In Jenkins, you can configure the Job to fail or to warn, based on definable thresholds.
If the response takes too long, then you have a performance regression that you want to check further.
The JMeter element can also parse text against regular patterns.
A rough rule of thumb is that approximately 10 percent of the membership of a site is logged to an application in the busiest hour of the year.
The understanding of usage patterns is also important; the less you know about how your system is going to be used, the larger a safety margin you will have to build in.
It is not uncommon to plan for a 100 percent extra capacity.
The extra capacity may well be the difference between you going on a holiday or not.
To expand its load creation capabilities, JMeter has the ability to run a number of JMeter slave nodes.
Enabling Sakai web services Sakai CLE is an application used by many hundreds of universities around the world.
Based on more than a million lines of Java code, Sakai CLE allows students to interact with online course and project sites.
In this recipe, you will enable web services and write your own simple ping service.
In the next recipe, you will write tests for these services.
Getting ready You can find links to the newest downloads under http://sakaiporject.org.http:// sakaiproject.org.
Log in as user admin with the password as admin.
To verify that the REST services are available, visit http://localhost:39955/ direct.
The Sakai package is self-contained with its own database and Tomcat server.
You updated it to allow the use of web services from anywhere.
To avoid port conflict with your local Jenkins server, the Tomcat conf/server.xml file was modified.
You will find the REST services underneath the /direct URL.
Entitybroker takes care of supplying the services information in the right format.
To view who Sakai thinks you currently are in an XML format, visit http://localhost:399955/direct/user/current.xml, and to view the JSON format, replace current.xml with current.json.
The SOAP services are based on the Apache AXIS framework (http://axis.apache.org/ axis/)
To create a new SOAP-based web service, you can drop a text file in the webapps/ sakai-axis directory with the extension .jws.
Apache AXIS compiles the code on the fly the first time it is called.
This allows for rapid application development, as any modifications to the text files are seen immediately by the caller.
The class name is the same as the filename with the .jws extension removed.
If you visit http://localhost:39955/sakai-axis/SakaiScript.jws?wsdl, you will notice that the youCantSeeMe method is not publicized; that is because it has a private scope.
Most of the interesting web services require logging in to Sakai through /sakai-axis/ SakaiLogin.jws using the method login, passing the username and password as strings.
The returned string is a GUID (a long random string of letters and numbers) that is needed to pass to other methods as evidence of authentication.
To log out at the end of the transaction, use the method logout, passing to it the GUID.
Sakai CLE is not only a learning management system but also a framework that makes developing new tools straightforward.
Another related product is Sakai Open Academic Environment (OAE), which is also mentioned at http://sakaiproject.org.
Sakai OAE builds on the strengths of Sakai CLE and works well with Sakai CLE using the hybrid mode.
Writing test plans with SoapUI SoapUI (http://www.soapui.org/) is a tool that allows the efficient writing of functional, performance, and security tests, mostly for web services.
In this recipe, you will be using SoapUI to create a basic functional test against the Sakai SOAP web service created in the last recipe.
Getting ready As described in the previous recipe, we assume that you have Sakai CLE running on port 39955 with the PingTest service available.
To download and install SoapUI, visit http://www.soapui.org/Getting-Started/, following the installation instructions.
For the Linux package to work with Ubuntu 11.10, you may have to uncomment the following line in the SoapUI startup script:
Click on the + icon next to Test Steps (1)
At the top of the editor, click on the Add assertion icon.
Add for content Insecure answer =>?, and click on OK.
SoapUI takes the drudge work out of making test suites for SOAP services.
SoapUI used the PingTest WSDL file to discover the details of the service.
The file contains information on the location, and allowable parameters are used with the PingTest service.
From the WSDL file, SoapUI created a basic test for the Ping and Pong services.
You added an assertion under the Ping service, checking that the text Insecure answer =>? does not exist in the SOAP response.
SoapUI has a wide range of assertions that it can enforce, including checking for Xpath or Xquery matches and checking for status codes or assertions tested by custom scripts.
Finally, the project was saved in XML format, ready for reuse in a Maven project in the next recipe.
A WSDL file is an XML file that supports the discovery of services.
SoapUI does a lot more than functional tests for web services.
Another important feature is its ability to build mock services from WSDL files.
This allows the building of tests locally while the web services are still being developed.
Reporting SoapUI test results In this recipe, you will be creating a Maven project that runs the SoapUI test created in the last recipe.
Run both the Enabling Sakai web services and Writing test plans with SoapUI recipes.
You will now have Sakai CLE running and a SoapUI test plan ready to use.
In the Build section, under Goals and options, add clean test.
In the Post-build Actions section, check Publish testing tools result report.
JunitReport set to true tells the plugin to create a JUnit report.
This option is useful during the debugging phase and should be set on unless you have severe disk space constraints.
Therefore, even without assertions, using the autogeneration feature of SoapUI allows you to quickly generate a scaffold that ensures that all services are running.
You can always add assertions later as the project develops.
The xUnit plugin allows you to pull in many types of unit test including the JUnit ones created from the Maven project.
The custom reports option is yet another way of pulling in your own custom data and displaying their historic trends within Jenkins.
It works by parsing the XML results found by the plugin with a custom stylesheet.
This gives you a great deal of flexibility to add your own custom results.
The Ping service is dangerous as it does not filter the input, and the input is reflected back through the output.
Many web applications use web services to load the content into a page, avoiding reloading the full page.
A typical example is when you type in a search term and alternative suggestions are shown on the fly.
With a little social engineering magic, a victim will end up sending a request including scripting to the web service.
On returning the response, the script is run in the client browser.
This bypasses the intent of the same origin policy (http://en.wikipedia.org/wiki/Same_origin_policy)
This is known as a non-persistent attack, as the script is not persisted to storage.
Web services are more difficult to test than web pages for XSS attacks.
Luckily, SoapUI simplifies the testing process to a manageable level.
You can find an introductory tutorial on SoapUI security tests at http://www.soapui.org/Security/working-withsecurity-tests.html.
The first is to show a number of interesting plugins.
If you are not a programmer, then feel free to skip the how plugins work discussion.
It is likely that there are plugins already available that meet or nearly meet your needs.
Jenkins is not only a Continuous Integration Server but also a platform to create extra functionality.
Once a few concepts are learned, a programmer can adapt the available plugins to his/her organization's needs.
If you see a feature that is missing, it is normally easier to adapt an existing one than to write from scratch.
The tutorial gives relevant background information on the infrastructure you use daily.
There is a large amount of information available on plugins.
To keep up with these changes, you will need to regularly review the available section of the Jenkins plugin manager.
Under the careful watch of the community, the code is likely to be improved.
However, as the number of plugins you use expands, the likelihood of an inadvertent configuration error increases.
Stapler for the binding of the Java classes to the URL space.
Personalizing Jenkins This recipe highlights two plugins that improve the user experience: the green balls plugin and the favorites plugin.
At times, there can be subtle cultural differences expressed in the way Jenkins looks.
One example is when a build succeeds, a blue ball is shown as the icon.
However, many Jenkins users naturally associate the green from traffic lights as the signal to go further.
The favorites plugin allows you select your favorite projects and display an icon in a view to highlight your picks.
Build the Job a number of times, reviewing the build history.
You will now see green balls instead of the usual blue.
To create a new view, click on the + icon.
Under the Job Filters section, check Use a regular expression to include jobs into the view.
In the Columns section, make sure you have three columns: Name, Status, and Favorite.
By clicking on the star icon, you can select/ deselect your favorite projects.
However, one limitation is that it does not currently affect the standard list view, which still displays blue balls.
The favorites plugin allows you to select which project interests you the most and displays that as a favorites icon.
This reminds you that the project needs some immediate action.
If you are interested in working with the community, then these plugins are examples that you could add extra features to.
The opposite of a favorite project, at least temporarily, is a project whose build has failed.
Once the claims plugin is installed, you will be able to find a tickbox in the Post-Build Actions section of a Job for Allow broken build claiming.
Once enabled, if a build fails, you can claim a specific build, adding a note about your motivation.
Within the Jenkins home page, there is now a link to a log that keeps a summary of all the claimed builds.
A project manager can now read a quick overview of issues.
The log is a direct link to the team members who deal with current issues.
The next recipe, Testing and then promoting, will signal further, allowing you to incorporate complex workflows.
Testing and then promoting You do not want the QA team to review a packaged application until it has been automatically tested.
An icon is set next to a specific build to remind the team to perform an action.
The difference between the promotion and the favorites plugin mentioned in the last recipe is that the promotion plugin can be triggered automatically based on a variety of automated actions.
Actions include the running of scripts or the verification of the status of other up or downstream jobs.
In this recipe, you will be writing two simple Jobs.
The first Job will trigger the second Job, and if the second Job is successful, then the first Job will be promoted.
This is the core of a realistic QA process – the testing Job promoting the packaging Job.
Near the top of the configuration page, check Promote builds when....
Promoted builds is similar to the favorites plugin, but with automation of workflow.
You can promote depending on job(s) triggered by the creation of artifacts.
This is a typical workflow when you want a Job tested for baseline quality before being picked up and reviewed.
The plugin has enough configuration options to make it malleable to most workflows.
Another example, for a typical development, acceptance, or production infrastructure, is that you do not want an artifice to be deployed to production before development and acceptance have also been promoted.
The way to configure this is to have a series of Jobs with the last promotion to production, depending on the promotion of upstream development and acceptance jobs.
If you want to add human intervention, then check Only when manually approved in Jobs configuration and add a list of approvers.
As its name suggests, the plugin simplifies the configuration and works well with a large subset of QA workflows.
Simplifying the configuration eases the effort of explaining, allowing use by a wider audience.
You can configure the different types of promotion within the main Jenkins configuration page.
The option tells Jenkins to keep the artifacts from the build for all time.
If used as part of an incremental build process, you will end up consuming a lot of disk space.
There is a simple choice available through a link on the left-hand side of the build.
This feature allows you to add a series of players into the promotion process.
Warning: When the final promotion occurs, for example, when you set the promotion to Generally Available (GA), the promotion is locked and can no longer be demoted.
The ability of a user to promote depends upon the permissions granted to them.
For example, if you are using matrix-based security, then you will need to update its table before you can see an extra option in the configuration page of the Job.
Fun with pinning JS Games This recipe shows you how to pin a Jenkins plugin.
Pinning a plugin stops you from being able to update its version within the Jenkins plugin manager.
Now that the boss has gone, life is not always about code quality.
To let off pressure, consider allowing access to your team to relaxation with the JS Games plugin.
Checkout and review the tag  jsgames-0.2 with the commands: :
Review the front page of Jenkins; you will see a link to JS Games.
Click on the link and you will have the choice of two games: Mario Kart and Tetris.
As a Jenkins administrator, visit the Manage Plugins section, and click on the installed tab (http://localhost:8080/pluginManager/installed)
The output will be similar to the following: ant                             ant.jpi.
Pinning a plugin stops a Jenkins administrator from updating to a new version of a plugin.
To pin a plugin, you need to create a file in the plugins directory with the same name as the plugin ending with the extension pinned.
Roughly every week, a new version of Jenkins is released with bug fixes and feature updates.
This leads to delivering improvements quickly to the market, but also leads to failures at times.
Pinning a plugin implies that you can stop a plugin from being accidentally updated until you have had time to assess the stability and value of the newer version.
Pinning is a tool to maintain the production server stability.
The source code includes a top-level pom.xml to control the Maven build process.
The GUI is associated with the plugin you see when you interact in Jenkins; for example, the link to JS Games.
Looking at the GUI Samples plugin This recipe describes how to run a Jenkins test server through Maven.
In the test server, you will get to see the example GUI plugin.
The GUI plugin demonstrates a number of tag elements that you can use later in your own plugins.
Getting ready Create a directory to keep the results of this recipe.
In the recipe directory, add pom.xml with the following content:
If the server is still running, press Ctrl + C.
The server will now run and generate a SEVERE error from the console.
At the bottom of the page, review the version number of Jenkins.
For development purposes, the ability to run a test server from Maven is great.
You can change your code, compile, package, and then view it on a local instance of Jenkins, without worrying about configuring or damaging a real server.
You do not have to worry too much about security, because the test server only runs as long as you are testing.
The goal hpi:run tries to package and then deploy a plugin called Startup.
However, the package is not available, so it logs a complaint and then faithfully runs a Jenkins server.
The version number of the Jenkins server is the same as the version number defined in the pom.
To avoid hitting the same port as your local instance of Jenkins, you set the jetty.port option.
Once Jenkins is running, visiting the GUI example plugin will show you many different GUI elements written in the Jelly language.
These elements will later come in handy for programming your own plugins.
Jenkins uses Stapler to bind any relevant classes found in src/main/java.
You can find the Jenkins workspace in the work folder.
Any configuration changes you make on the test server are persisted here.
To have a fresh start, you will need to delete the directory by hand.
For all the recipes in this chapter, we will pin the Jenkins version at 1.449
The Jenkins WAR file and test WAR file take about 120 MB of your local Maven repository.
Multiply this number by the number of versions of Jenkins used, and you can quickly fill up GBs of disk space.
Feel free to update to the newest and greatest Jenkins version; the examples in this chapter should still work.
In case of difficulty, you can always return to the known safe number.
Behind the scenes, Maven does a lot of heavy lifting.
The pom.xml file defines the repository http://maven.glassfish.org/content/groups/public/ to pull in the dependencies.
The version number is in sync with the version number of Jenkins that Maven runs.
To discover which version numbers are acceptable, visit the following URL:
This recipe reviews the inner workings of the file system scm plugin.
This plugin allows you to place the code in a local directory that is then picked up in a build.
Getting ready Create a directory named ready for the code in this recipe.
First, you modified the plugin's pom.xml file, updating the version of the test Jenkins server.
For each Java class, you can configure its GUI representation through an associated config.
The location of the help files are defined in config.jelly with the attribute help in the entry Jelly tag:
The src/main/webapps directory provides a stable Jenkins URL /plugin/name_of_ plugin for static content, such as images, stylesheets, and JavaScript files.
Plugins generally ship with two types of Jelly files: global.jelly and config.jelly.
Data is persisted in XML files using the Xstream framework.
Adding a banner to Job descriptions Scenario: Your company has a public-facing Jenkins instance.
The owner does not want the project owners to write unescaped tagging in the descriptions of projects.
However, the owner does want to put a company banner at the bottom of each description.
You have 15 minutes to sort out the problem before the management starts buying in unnecessary advice.
This recipe shows you how to modify the markup plugin to add a banner to all the descriptions.
In the top-level directory of the project, try to create the plugin by using the command mvn install.
Install the plugin by visiting the Advanced tab under the plugin Manager (http://localhost:8080/pluginManager/advanced)
Visit the Jenkins configuration page (http://localhost:8080/configure), and review the markup formatters.
The build fails due to failed tests (which is a good thing)
Delete the escaped markup plugin from the Jenkins plugin directory and the expanded version in the same directory.
You will now see an updated description of the plugin.
In Jenkins, as an administrator, visit the configure page at http://localhost:8080/configure.
Within the Jobs main page, you will now see the banner.
The markup plugin escapes the tags in descriptions so that arbitrary scripting actions cannot be injected.
In this recipe, we adapted the plugin to escape a project's description, and then added a banner.
Then, you modified the source to include a banner at the end of a Job's description.
The plugin was redeployed to a sacrificial test instance that was ready for review.
You could have also used the mvn hpi:run goal to run Jenkins through Maven.
There are multiple ways to deploy, including dumping the plugin directly into the Jenkins plugin directory.
Which of the deployment methods you decide to use is a matter of taste.
You updated the file to accurately describe the new banner feature.
In Jenkins, extension points are Java interfaces or abstract classes that model a part of the Jenkins functionality.
The markup plugin had minimal changes made to it to suite our purposes.
The @Override annotation tells the compiler to override the method.
In this case, we overrode the translate method and used a utility class to filter the markup string using a Jenkins utility method.
At the end of the resulting string, the banner string was added and passed to the Java writer.
The writer is then passed back to the calling method.
The text inside the selectbox (see step 19) of the plugin is defined in the getDisplayName() method of the DescriptorImpl class.
Conclusion: Writing a new plugin, and understanding the Jenkins object model takes more effort than copying a plugin that works and then tweaking it.
The amount of code change needed to add the banner feature to an already existing plugin was minimal.
However, for the hardcore programmer, the best source of details is reviewing the code.
Examples include JavaDoc (http://javadoc.jenkins-ci.org/) and the built-in code completion facilities of IDEs, such as Eclipse.
If you import the Jenkins plugin project into Eclipse as a Maven project, then the newest versions of Eclipse will sort out the dependencies for you, enabling code completion during the editing of files.
In a rapidly-moving project such as Jenkins, there is sometimes a lag between when a feature is added and when it is documented.
Code completion in combination with well-written JavaDoc eases a developer's learning curve.
Creating a RootAction plugin Before building your own plugin, it is worth seeing if you can adapt another's.
In the Fun with pinning JS Games recipe, the plugin created a link on the front page.
In this recipe, we shall use the elements of the plugin to create a link in the Jenkins home page.
Getting ready Create a directory to store your source code.
In the src/main/webapp directory, add a PNG file named myicon.png.
Click on the Root Action Example link; your browser is now sent to the main website of the University of Amsterdam (http://www.uva.nl)
It is used to add links to the main menu in Jenkins.
The link name is defined in the getDisplayName method, the location of an icon in the getIconFileName method, and the URL to link to in getUrlName.
The location of the details in the Jenkins Wiki are calculated as a fixed URL (http://wiki.jenkins-ci.org/display/JENKINS/) with the plugin name, after that with the spaces in the name replaced with + symbols.
Exporting data The job exporter plugin creates a property file with a list of project-related properties.
This is a handy glue for when you want Jenkins to pass the information from one job to another.
In the build section, add a build step export runtime parameters.
In the build History for the Job within the console output, you will see output similar to the following: Started by user Alan Mark Berg.
The Job exporter plugin gives Jenkins the ability to export Job-related information into a properties file that can later be picked up for re-use by other Jobs.
The plugin uses a number of these methods to discover the information that is later outputted to a properties file.
While reviewing the plugin code, you can find interesting tricks ready for re-use in your own plugin.
The plugin discovered the environment variables by using the following method:
EnvVars even has a method to get the environment variables from remote Jenkins nodes.
You can also find a list of all environment variables defined for Jenkins in the Jenkins Management area under system info (http://localhost:8080/systemInfo)
Triggering events on startup Often when a server starts up, you will want to have a clean-up action performed.
For example, running a Job that sends an e-mail to all of the Jenkins admins warning them of the startup event.
Return to the project page; you will notice that a Job has been triggered.
You will see an output similar to the following: Started due to Jenkins startup.
This is useful for administrative tasks, such as reviewing the file system.
The string is outputted to the console as part of the logging.
In this recipe, the URL trigger plugin will trigger a build if a web page changes its content.
There will be times when standard plugins cannot be triggered by your system of choice.
In most situations, the system to which you want to connect to has its own web interface.
If the application does not, then you can still set up a web page, which changes when the application needs a reaction from Jenkins.
In the Build Triggers section, check the [URLTrigger] - Poll with a URL checkbox.
Select Monitor a change of the content from Add a content nature.
On the right-hand side, there is a link to URLTrigger Log.
You will now see the log information update once a minute with content similar to the following: Polling for the job ch7.plugin.url.
Delete the Job, as we don't want to poll Google every minute.
You configured the plugin to visit google.com once a minute, and downloaded and compared the Google page for changes.
A schedule of once a minute is aggressive; consider using similar time intervals as for your SCM repositories, for example, once every five minutes.
As there are subtle differences in each Google page returned, the trigger is activated.
The URLTrigger plugin can also be used for JSON and text or XML responses.
You get to see examples of this when you load a local file into your web browser.
Changes in the local file system cannot be monitored by this plugin.
If you reconfigure the Job to point at the location file:///, you will get the following error message:
You will have to use the file system SCM plugin instead.
Reviewing three ListView plugins The information radiated out by the front page of Jenkins is important.
The initial perception of the quality of your projects is likely to be judged by this initial encounter.
In this recipe, we will review the Last Success, Last Failure, and Last Duration columns that you can add to the list view.
In the next recipe, you will be shown how to write a plugin for your own column in the list view.
Install the source code locally in a directory of choice.
On the Main Page, press the + tab next to the All tab.
You will be returned to the main page with the LAST list view showing.
The Last Success Version column now has data with a link to the build's history.
Add the description for the build "This is my great description"
Return to the LAST list view by clicking on LAST in the breadcrumb displayed at the top of the page.
The three plugins perform similar functions; the only difference is a slight variation in the details of the columns.
The details are useful for making quick decision about projects.
You can give the casual viewer an oversight into the last significant action in the project without them diving down into the source code.
When a build succeeds, add a meaningful description to the build, such as "Updated core libraries to work with modern browsers"
This exposure of information through the correct use of descriptions saves a significant amount of clicking.
Each one of these new columns allows you to better understand the state of the project or perform actions efficiently.
This is useful if you want to compare the system-monitoring information with the melody plugin.
This is especially useful if your organization has an in-house style guide where the code needs to reach a specific level of code coverage.
This adds a feeling of activity to the front page.
Creating my first ListView plugin In this final recipe, you will create your first custom ListView plugin.
This allows you to add an extra column to the standard list view with a column with comments.
The code for the content of the column is a placeholder, just waiting for you to replace with your own brilliant experiments.
Getting ready Create a directory that is ready for the code.
In the src/main/resources directory, add the plugin description index.jelly file with the following content:
On the main Jenkins page, http://localhost:8090, you will now have a view with the column called My Fake Column [Default]
If you change the preferred language of your web browser to Aragonese [an], then the column will now be called My Fake Column [an]
In this recipe, a basic ListView plugin was created with the following structure:
The method getFakeComment expects an input of type Job and returns a String.
This method is used to populate the entries in the column.
The % sign tells Jelly to look in different properties files depending on the value on the Language settings returned by the web browser.
If the web browser returns a language that does not have its own properties file, then Jelly defaults to columnHeader.
It is the default name for the instance of the object.
The returned string is placed in the variable comment and then displayed inside a <td> tag.
The core is entirely in the MIT license, so are the most infrastructure code (that runs the project itself), and many plugins.
We encourage hosted plugins to use the same MIT license, to simplify the story for users, but plugins are free to choose their own licenses, so long as it's OSI-approved open-source license.
You can find the list of approved OSI licenses at http://opensource.org/licenses/ alphabetical.
The majority of plugins have a License.txt file in their top-level directory with an MIT license (http://en.wikipedia.org/wiki/MIT_License)
It has a structure, which is similar to the following:
Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
Quality Assurance requires the expert to pay attention to a wide range of details.
Rather than being purely technical, many of these details relate to human behavior.
Avoiding group think It is easy to be perfect on paper, defining the importance of a solid set of JavaDocs and unit tests.
However, the real world on its best days is chaotic.
Project momentum, motivated by the need to deliver, is an elusive force to push back against.
If the team has the wrong collective attitude, then as a Quality Assurance professional, it is much harder to inject the hard-learnt realism.
Quality Assurance is not only about finding and capturing defects as early as possible but also about injecting the objective criteria for success or failure into the different phases of a project's cycle.
Obviously, if the code fails to compile, then the product should not go to acceptance and then production.
Less obviously, are the rules around code coverage of unit tests worth defending in release-management meetings?
Try getting the whole team involved at the start of the project before any coding has taken place, and agree on the metrics that fail a build.
One approach is to compare a small successful project to a small failed project.
If there is a disagreement later, then the debate is about the processes and numbers rather than personality.
If you see automated testing as a software project and apply well-known principles, then you will save on maintenance costs and increase the reliability of tests.
The Don't Repeat Yourself (DRY) principle is a great example.
Under time pressure, it is tempting to cut-and-paste similar tests from one area of the code base to another—DON'T.
Projects evolve bending the shape of the code base, and the tests need to be re-usable to adapt to that change.
One concrete example discussed briefly in Chapter 6, Testing Remotely is the use of page objects with Selenium Webdriver.
If you separate the code into pages, then when the workflow between pages changes, most of the testing code remains intact.
The Keep It Simple Stupid (KISS) principle implies keeping every aspect of the project as simple as possible.
For example, it is possible to use real browsers for automated functional tests or use the HtmlUnit framework to simulate a browser.
These extra chores decrease the reliability of running a Jenkins Job, but do increase the value of the tests.
For larger projects, the extra effort is worth the cost.
Consider if you need a standalone integration server or if you can get away with using a Jetty server called during the integration goal in Maven.
For an example recipe, see the Configuring Jetty for integration tests recipe in Chapter 3, Building Software.
Offsetting work to Jenkins nodes Jenkins usage can grow virally in an organization.
Testing and JavaDoc generation takes up a lot of system resources.
A master Jenkins is best used to report back quickly on Jobs distributed across a range of Jenkins nodes.
This approach makes it easier to analyze where the failure lies in the infrastructure.
Learning from history Teams tend to have their own coding habits.
If a project fails because of the quality of the code, try and work out which code metrics would have stopped the code from reaching production or which mistakes are seen repeatedly; a few examples include the following:
By the end of the week, a programmer may have their minds focused elsewhere than the code.
A small subset of programmers have their code quality affected, consistently injecting more defects towards the tail end of their roster.
Consider scheduling a weekly Jenkins Job that has harsher thresholds for quality metrics pushing back near the time of least attention.
For some teams with a strong sense of code quality, this is also a sign of extra vigilance.
For other less-disciplined teams, this could be a naive push towards destruction.
If a project fails and QA is overwhelmed due to a surge of code changes, then look at setting up a warning Jenkins Job based on the commit velocity.
It is possible that there is consistent underachievement within a project.
However, for a secondary defense, consider setting thresholds on static code review reports from FindBugs and PMD.
If a particular developer is not following the accepted practice, then builds will fail with great regularity.
When the GUI diverges from the planned workflow, Jenkins will start shouting.
However, if there is no clear chain of documented responsibility, then it is difficult to pin down who needs the learning opportunity.
One approach is to structure the workflow in Jenkins through a series of connected jobs, and use the promoted builds plugin to make sure the right group verifies at the right point.
This methodology is also good for reminding the team of the short-term tasks.
Test frameworks are emerging In the past few years, there has been a lot of improvement in test automation.
Static code review is being used more thoroughly for security.
Sonar is an all-encompassing reporter of project quality, and new frameworks are emerging to improve on the old.
Sonar will evolve faster than the full range of Jenkins quality metrics plugins.
Consider using Jenkins plugins for early warnings of negative quality changes and Sonar for the in-depth reporting.
Static code review tools are getting better at finding security defects.
Expect significantly improved tools over time, possibly just by updating the version of your current tools.
You could search for defects to remove and then send patches back to the codes communities.
Expect more kinds of cloud, such as integrations, around Jenkins.
Starve QA/ integration servers A few hundred years ago, coal miners would die because of the build-up of methane in the mines.
To give an early warning of this situation, canary birds were brought into the mines.
Being more sensitive, the birds would faint first, giving the miners enough time to escape.
Consider doing the same for your integration servers; deliberately starve them of resources.
If they fall over, you will have enough time to review before watching the explosion in production.
And there's always more There are always more points to consider.
The easier it is to write tests, the more likely the tests reflect user behavior.
Look for new Jenkins plugins that support tools that lower the learning curve.
Warning: Before adding defects, make sure that the team has agreed to the process or you might be getting angry e-mails late in the night.
Not only is this good for security testing, but also boundary testing.
If your server returns an unexpected error, then use this to trigger a more thorough review.
Fuzzers and link crawlers are a cheap way to increase the code coverage of your tests.
You can cover more testing surface if you use a data-driven testing approach.
For example, when writing JMeter test plans, you can use the CSV configuration element to read in variables from textfiles.
This allows JMeter to pull out parameters, such as hostname and loop, through a series of hostnames.
Final comments The combination of Jenkins with aggressive automated testing acts as a solid safety net around coding projects.
Jenkins can pay attention to many of the details and shout loudly when violations occur.
Each project is different, and there are many ways to structure the workflow.
Luckily, with over 400 plugins, Jenkins is flexible enough to adapt to even the most obscure infrastructures.
If you do not have the exact plugin that you want, then it is straightforward for a Java programmer to adapt or create their own.
Without a thriving open source Jenkins community, none of this would be possible.
Jenkins is yet another positive example of the open source mentality working in practice.
About Packt Publishing Packt, pronounced 'packed', published its first book "Mastering phpMyAdmin for Effective MySQL Management" in April 2004 and subsequently continued to specialize in publishing highly focused books on specific technologies and solutions.
Our books and publications share the experiences of your fellow IT professionals in adapting and customizing today's systems, applications, and frameworks.
Our solution based books give you the knowledge and power to customize the software and technologies you're using to get the job done.
Packt books are more specific and less general than the IT books you have seen in the past.
Our unique business model allows us to bring you more focused information, giving you more of what you need to know, and less of what you don't.
Packt is a modern, yet unique publishing company, which focuses on producing quality, cuttingedge books for communities of developers, administrators, and newbies alike.
This book is part of the Packt Open Source brand, home to books published on software built around Open Source licences, and offering information to anybody from advanced developers to budding web designers.
The Open Source brand also runs Packt's Open Source Royalty Scheme, by which Packt gives a royalty to each Open Source project about whose software a book is sold.
Writing for Packt We welcome all inquiries from people who are interested in authoring.
If your book idea is still at an early stage and you would like to discuss it first before writing a formal book proposal, contact us; one of our commissioning editors will get in touch with you.
We're not just looking for published authors; if you have strong technical skills but no writing experience, our experienced editors can help you develop a writing career, or simply get some additional reward for your expertise.
Create professional desktop rich-client Swing applications using the world's only modular Swing application framework.
Master a broad range of topics essential to have in your desktop application development toolkit, right from conceptualization to distribution.
Pursue an easy-to-follow sequential and tutorial approach that builds to a complete Swing application.
Implement engineering practices in your application development process with Apache Maven.
Over 70 highly focused practical recipes to maximize your output with NetBeans.
Learn how to deploy, debug, and test your software using NetBeans IDE.
Another title in Packt's Cookbook series giving clear, real-world solutions to common practical problems.
Develop professional enterprise Java EE applications quickly and easily with this popular IDE.
Use features of the popular NetBeans IDE to accelerate development of Java EE applications.
Develop JavaServer Pages (JSPs) to display both static and dynamic content in a web browser.
Appendix: Processes that Improve Quality Avoiding group think Considering test automation as a software project Offsetting work to Jenkins nodes Learning from history Test frameworks are emerging Starve QA/ integration servers And there's always more Final comments.
