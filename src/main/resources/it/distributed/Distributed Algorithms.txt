No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means--electronic, mechanical, photocopying, recording or otherwise--without the pior written permission of the publisher.
You may also complete your request on-line via the Elsevier homepage: http://www.elsevier.com by selecting "Customer Support" and then "Obtaining Permissions"
Distributed algorithms are algorithms designed to run on hardware consisting of many interconnected processors.
Pieces of a distributed algorithm run concurrently and independently, each with only a limited amount of information.
The algorithms are supposed to work correctly, even if the individual processors and communication channels operate at different speeds and even if some of the components fail.
For example, today's telephone systems, airline reservation systems, banking systems, global information systems, weather prediction systems, and aircraft and nuclear power plant control systems all depend critically on distributed algorithms.
Obviously, it is important that the algorithms run correctly and efficiently.
However, because the settings in which they run are so complicated, the design of such algorithms can be an extremely difficult task.
This book contains a comprehensive introduction to the field of distributed algorithms--a collection of the most significant algorithms and impossibility results, all presented in a simple automata-theoretic setting.
Mathematical proofs are given (or at least sketched) for virtually all of the results.
Altogether, this material provides an excellent foundation for a deep understanding of distributed algorithms.
This book has been written with several audiences in mind.
First, it is organized as a textbook for a first-year graduate computer science course, especially for students interested in computer systems, theory, or both.
It can also be used as a text for a short course for designers of distributed systems.
Finally, it is intended as a reference manual for designers, students, researchers, and anyone else interested in the field.
The book contains algorithms for many typical problems, including problems of consensus, communication, resource allocation, and synchronization, in several different system settings.
Several chapters are devoted to each type of system model; the first chapter in each group presents a formal model for that type of system, while the rest of the chapters contain the algorithms and impossibility results.
Throughout, the presentation is rigorous, yet it is firmly grounded in intuition.
Because this field is so large and active, this book does not attempt to cover everything.
The results that are included have been selected because they are the most fundamental.
These are not always the optimal results, in terms of the complexity measures; they are generally those that are simple and that illustrate important general methods of design or reasoning.
This book will make you familiar with many of the most important problems, algorithms, and impossibility results in the area of distributed computing.
You will be able to recognize the problems when they arise in practical settings, apply algorithms like the ones contained here to solve them, and invoke the impossibility results to argue that the problems are not solvable.
The book will also give you a good feeling for the various system models and their capabilities, so that youcan design new algorithms yourself (or even prove new impossibility results)
Finally, this book should convince you that it is feasible to reason carefully about distributed algorithms and systems: to model them formally, give precise specifications for their required behavior, prove rigorously that they satisfy their specifications, identify appropriate complexity measures, and analyze them according to these measures.
The only prerequisites for reading the book are knowledge of basic college-level discrete mathematics (including mathematical induction and asymptotic analysis), some programming skill, and reasonable familiarity with computer systems.
The sections about randomized algorithms also require knowledge of basic probability.
This book has been designed so that the material using the different models can be read fairly independently.
An outline of significant chapter dependencies is presented in Figure A.
For example, if you prefer to move quickly to the material on asynchronous networks, you can skip Chapters.
This book contains several sections whose titles are starred in the table of contents.
These sections contain material that is less fundamental or more advanced than the other sections.
You can omit these sections on a first reading without much harm.
Prel iminary versions of this book have been used for many years in an introductory graduate-level course at MIT, and for three years in a summer course for system designers in computer  software and applications companies.
This book contains enough material for a one-year course, so you will have to select material for shorter courses (but watch the chapter dependencies)
If you yourself are a researcher in this area, then you might want to supplement this book as a course text with more advanced or specialized results from the research literature in your favorite area.
In a one-week or two-week short course for system designers, you could cover the highlights of all the chapters, discussing key results and key proof ideas at a high level instead of presenting a lot of detail.
I would appreciate hearing about any errors that you find in the book, as well as receiving any other constructive suggestions you may have.
It is impossible to acknowledge all the people who contributed to the production of this book, since it is the product of many years of teaching and research, involving interactions with many, many students and research colleagues.
The book is the final version of the lecture notes for MIT's graduate course 6.852
The students in the many passes through this course suffered through my early attempts to organize the material.
Jennifer Welch and Rainer Gawlick also helped out as teaching assistants during other passes through the course.
Many students and colleagues contributed to my own understanding of the material by working with me on some of the results that appear here or by discussing other people's work.
Two of these people deserve special credit: my mentor Michael Fischer, for starting work with me in 1978 on what was then a small but promising-looking research area, and my student Mark Turtle, whose M.S.
Ajoy, Faith, and George, especially, suffered through the effort of teaching their classes from early versions of the book and provided many suggestions.
And I want to thank Joanne Talbot for her tireless work on formatting, drawing diagrams, preparing the bibliography, making endless copies, and more.
I also thank John Guttag, Paul Penfield, and others in the MIT EECS Department for arranging for me to have the free time that I needed to write.
Bruce Spatz at Morgan Kaufmann was, once again, encouraging and helpful to me in this daunting endeavor.
Last and most of all, I want to thank my unboundedly patient family, Dennis, Patrick, and Mary Lynch, for tolerating all my work on this book and taking care of absolutely everything else in the meantime.
Thanks especially to Dennis for cooking all those excellent seafood dinners (not to mention renovating both the bathroom and the laundry room) while I spent all my time at my computer!
The term distributed algorithms covers a large variety of concurrent algorithms used for a wide range of applications.
Originally, this term was used to refer to algorithms that were designed to run on many processors "distributed" over a large geographical area.
But over the years, the usage of this term has been broadened, so that it now includes algorithms that run on local area networks and even algorithms for shared memory multiprocessors.
This has happened because it has become recognized that the algorithms used in these various settings have a great deal in common.
An important  part of the job of building a system for any of these applications is the design, implementation, and analysis of distributed algorithms.
The algorithms that arise, and the problems that they are designed to solve, form the subject matter of the field of study covered in this book.
Some of the attr ibutes by which they differ include.
The interprocess communication (IPC) method: Distributed algorithms run on a collection of processors, which need to communicate somehow.
Some common methods of communication include accessing shared memory, sending point-to-point or broadcast messages (either over a long distance or local area network), and executing remote procedure calls.
The timing model: Several different assumptions can be made about the timing of events in the system, reflecting the different types of timing information that might be used by algorithms.
At the other extreme, they can be completely asynchronous, taking steps at arbitrary speeds and in arbitrary orders.
In between, there are a wide range of possible assumptions that can be grouped together under the designation partially synchronous; in all of these cases, processors have partial information about the timing of events.
For example, processors might have bounds on their relative speeds or might have access to approximately synchronized clocks.
The failure model: The hardware upon which an algorithm runs might be assumed to be completely reliable.
Or, the algorithm might need to tolerate some limited amount of faulty behavior.
Such faulty behavior can include processor failures: processors might just stop, with or without warning; might fail transiently; or might exhibit more severe Byzantine failures, where a failed processor can behave arbitrarily.
Faulty behavior can also include failures of the communication mechanisms, including message loss or duplication.
The problems addressed: Of course, the algorithms also differ in the problems that they are supposed to solve.
The typical problems that are considered are those that arise in the application areas mentioned above.
They include problems of resource allocation, communication, consensus among distributed processors, database concurrency control, deadlock detection, global snapshots, synchronization, and implementation of various types of objects.
Some kinds of concurrent algorithms, such as Parallel Random Access Machine (PRAM) algorithms and algorithms for fixed-connection networks (for example, arrays, trees, and hypercubes), are not covered in this book.
The algorithms presented here are distinguished within the larger class of concurrent algorithms by having a higher degree of uncertainty and more independence of activities.
Some of the types of uncertainty and independence that the algorithms in this book must contend with include.
Fortunately, not every algorithm has to contend with all of these types of uncertainty!
Because of all this uncertainty, the behavior of distributed algorithms is often quite difficult to understand.
Even though the code for an algorithm may be short, the fact that many processors execute the code in parallel, with steps interleaved in some undetermined way, implies that there are many different ways in which the algorithm can behave, even for the same inputs.
Thus, it is generally impossible to understand the algorithm by predicting exactly how it will execute.
This can be contrasted with other kinds of parallel algorithms such as PRAM algorithms, for which we can often predict exactly what the algorithm will do at every point in time.
For a distributed algorithm, instead of understanding everything about its behavior, the best that we usually can do is to understand certain selected properties of its behavior.
The study of distributed algorithms has developed over the past 15 years into a fairly coherent field.
The general style of work in this field is more or less as follows.
First, problems of significance in practical distributed computing are identified, and abstract versions of these problems, suitable for mathematical study, are defined.
These are described precisely and proved to solve the stated problems, and their complexity, according to various measures, is analyzed.
Designers of such algorithms typically try to minimize their complexity.
Also, impossibility results and lower bounds are proved, demonstrating limitations on what problems can be solved and with what costs.
Underlying all of this work are mathematical models for distributed systems.
But they are more than a mathematical theory: the problem statements can be used to formulate specifications for portions of real systems, the algorithms can (in many cases) be engineered for practical use, and the impossibility results can help to tell designers when to stop trying to build something.
All of these results, as well as the underlying mathematical models, can provide designers with assistance in understanding the systems they build.
This book contains a study of the field of distributed algorithms.
Because this field is so large and active, we cannot give an exhaustive study.
Since we have had to select, we have tried to choose the most fundamental results in the area, both theoretically and practically speaking.
These are not always the optimal results in terms of the complexity measures; instead, we have favored those that are simple and that illustrate important general methods of design or reasoning.
The results we present involve a small number of problems that are typical of this area, including leader election, network searching, spanning tree construction, distributed consensus, mutual exclusion, resource allocation, construction of objects, synchronization, global snapshots, and reliable communication.
We consider the same problems in several different system models.
One feature of this book is that we present all the algorithms, impossibility results, and lower bounds in terms of a more or less unified formal framework.
This framework consists of a small number of formal, automata-theoretic models for various types of distributed systems, together with some standard ways of reasoning about systems using the models.
It also allows flexibility, in that a variety of languages and logics could be used to describe and reason about algorithms in the same framework.
Using a formal framework permits a rigorous treatment of all the results.
A rigorous treatment is especially important in the area of distributed algorithms because of the many subtle complications that arise.
However, it is not clear how we could make a completely rigorous presentation both reasonably short and intuitively understandable.
In this book, we compromise and use a mixture of intuitive and rigorous reasoning.
We sometimes give precise descriptions of algorithms in terms of the formal models, sometimes English descriptions, and sometimes both.
The degree of rigor in correctness arguments for algorithms varies greatly: sometimes we give rather formal proofs and sometimes only intuitive sketches.
We hope, however, that we have provided enough tools for you to expand our intuitive sketches into formal proofs when you want to.
We generally present impossibility arguments rather rigorously, in terms of the formal models.
Because there are so many different settings and problems to consider, it.
We have chosen to organize it primarily according to the formal models-- in particular, according to those aspects of the models that seem to make the most difference in the results, and secondarily by abstract problem statements.
The deepest distinctions among the models seem to be based on timing assumptions, but IPC mechanisms and failure assumptions are also important  factors.
The synchronous model: This is the simplest model to describe, to program, and to reason about.
We assume that components take steps simultaneously, that is, that execution proceeds in synchronous rounds.
Of course, this is not what actually happens in most distributed systems, but the synchronous model can be useful anyway.
Understanding how to solve a problem in the synchronous model is often a useful intermediate step toward understanding how to solve it in more realistic models.
For example, it is sometimes possible for a real distributed system to "simulate" a synchronous system.
Also, impossibility results for the synchronous model carry over directly to less well-behaved models.
On the other hand, it is irapossible or inefficient to implement the synchronous model in many types of distributed systems.
The asynchronous model: Here we assume that the separate components take steps in an arbitrary order, at arbitrary relative speeds.
This model is also reasonably simple to describe, although there are a few subtleties, mainly involving liveness considerations.
It is harder to program than the synchronous model because of the extra uncertainty in the order of events.
However, the asynchronous model does allow the programmer to ignore specific timing considerations.
Since the asynchronous model assumes less about time than is guaranteed by typical distributed systems, algorithms designed for the asynchronous model are general and portable: they are guaranteed to run correctly in networks with arbitrary timing guarantees.
On the other hand, the asynchronous model sometimes does not provide enough power to solve problems emciently, or even to solve them at all.
The partially synchronous (timing-based) model: Here we assume some restrictions on the relative timing of events, but execution is not completely lock-step as it is in the synchronous model.
These models are the most realistic, but they are also the most difficult to program.
Algorithms designed using knowledge of the timing of events can be efficient, but they can also be fragile in that they will not run correctly if the timing assumptions are violated.
The next basis we use for classification is the IPC mechanism.
In this book, we consider both shared memory and message passing.
We present the shared memory model first, because it is more powerful and simpler to understand, and because many of the techniques and results for the shared memory setting can be adapted for use in the network setting.
Next, we organize the material according to the problem studied.
And finally, we study many of the problems under different failure assumptions.
You should see, as we present the same problems in a variety of different models, that apparently minor differences in assumptions can make a big difference in the results.
We have tried to make our presentation as modular as possible by composing algorithms to obtain other algorithms, by developing algorithms using levels of abstraction, and by transforming algorithms for one model into algorithms for other models.
This helps greatly to reduce the complexity of the ideas and allows us to accomplish more with less work.
The same kinds of modularity can serve the same purposes in practical distributed system design.
The specific topics that this book covers are as follows.
This material is isolated into separate chapters for easy reference.
You may prefer to skip some of the modelling material on the first reading, returning to it as needed for understanding the material in the succeeding "algorithm chapters." We have tried to construct the book so that the algorithm chapters can be read, and mostly understood, without too much formal modelling work.
The models we use are all based on state machines, often having an infinite number of states and usually having explicit names associated with their transitions.
A state machine can be used to model either a component of a distributed system or an entire distributed system.
Each state of the machine represents an instantaneous snapshot of the component or system, including such information as the state of the memory of each processor, the program counter for each running program, and the messages that are in transit in the communication system.
The transitions describe changes that occur in the system, such as the sending.
We present separate state machine models for synchronous networks, asynchronous systems, and timing-based systems.
One important  use of a formal model for distributed systems is as a basis for specification of the problems to be solved and verification of algorithm correctness.
Such specification and verification can be done using many stylized and ad hoc methods.
However, certain methods are used so frequently that we describe them explicitly in the modelling chapters.
These include the method of invariant assertions and the method of simulations.
An invariant assertion is a property that is true of all reachable states of a system.
Assertions are generally proved by induction on the number of steps in a system execution.
A simulation is a formal relationship between a pair of systems, one representing the problem to be solved and another representing the solution, or one representing a high-level, abstract solution and another a detailed solution.
It is a very simple model that just describes synchronized rounds of message exchange and computation.
Chapter 8 contains a general model for asynchronous systems, the input/output automaton (I//O automaton) model.
The name of the model refers to its explicit distinction between input and output transitions, that is, those communicated to the system by its environment and those communicated to the environment by the system.
In an I /O automaton, several transitions may be possible from any given state; for example, transitions involving different processors may be performed in any order.
Since the model allows so much flexibility in the order of transitions, a notion of liveness is included, allowing us to express the notion that certain transitions must eventually happen.
A useful feature of this model is that it has a parallel composition operation, which allows a combination of system components modelled as I /O automata also to be modelled as an I /O automaton.
Often, the correctness of a composed automaton can be proved in a modular fashion, based on proofs of the correctness of its components.
Finally, in Chapter 23, we present models for timing-based systems.
These models are, once again, state machines, but this time the states include information about timing, such as the current time and scheduled times for various.
These models allow us to describe typical constructs for timing-based systems, such as local clocks and timeouts.
The simplest model that we consider (that is, the one with the least uncertainty) is the synchronous network model, in which all the processors communicate and compute in synchronous rounds.
We do not consider synchronous shared memory algorithms, since these constitute a large subject of study in their own right (see the Bibliographic Notes at the end of this chapter)
In the network setting we assume that the processors are located at the nodes of a graph or digraph, G, and communicate with their neighbors using messages sent along the edges of G.
Next, in Chapter 4, we give a brief survey of basic algorithms used in more general networks.
Specifically, we describe some algorithms used to solve such fundamental problems as electing a leader, conducting a breadth-first search, finding shortest paths, finding a minimum spanning tree, and finding a maximal independent set of nodes.
Typical forms of uncertainty here are unknown UIDs and an unknown network graph.
These are problems in which a collection of distributed processors are required to reach a common decision, even if there are initial differences of opinion about what that decision ought to be.
Many different consensus problems arise in practice: for example, the processors could be monitoring separate altimeters on board an aircraft and could be attempting to reach agreement about the altitude.
The uncertainty that we consider here stems not only from differences in initial opinions, but also from failures, either of links or of processors.
In Chapter 5, we consider the case where links can fail by losing messages.
In Chapter 6, we consider two different types of processor failures: stopping failures, where faulty processors can, at some point, just stop executing their local protocols, and Byzantine failures, where faulty processors can exhibit completely arbitrary behavior (subject to the limitation that they cannot corrupt portions of the system to which they have no access)
We present bounds on the number of tolerable faults, on the time, and on the amount of communication.
Finally, in Chapter 7, we consider some extensions and variations on the basic consensus problems, including agreement on a small set of values rather than just a single value, approximate agreement on a real value, and distributed database commit.
A s y n c h r o n o u s  s h a r e d  m e m o r y  a l g o r i t h m s.
After warming up with synchronous algorithms (in which there is only a little uncertainty), we begin the more dimcult study of asynchronous algorithms.
Now we no longer assume that processors operate in lock-step synchrony, but rather that they can interleave their steps in an arbitrary order, with no bounds on individual processor speeds.
Typically, the interactions with the external world (via input and output events) are ongoing, rather than just involving an initial input and final output.
The results in this setting have a very different flavor from those for synchronous networks.
The first problem we consider, in Chapter 10, is that of mutual exclusion.
This is one of the most fundamental problems in the area of distributed algorithms, and historically the first problem to receive serious theoretical study.
Essentially, the problem involves managing access to a single, indivisible resource that can only support one user at a time.
Alternatively, it can be viewed as the problem of ensuring that certain portions of program code are executed within critical regions, where no two programs are permitted to be in critical regions at the same time.
This problem arises in both centralized and distributed operating systems.
Besides the basic uncertainty about the order of steps, there is also uncertainty about which users are going to request access to the resource, and when.
We present a series of shared memory mutual exclusion algorithms, starting with a classical algorithm invented by Dijkstra in 1965, and proceeding through.
Most of these results are based on shared memory that can only be accessed using read and write operations; for this read/wri te  shared memory model, we also present a lower bound on the number of shared variables that must be used.
In addition to presenting the algorithms and lower bounds, we also use the mutual exclusion problem as a case study to illustrate many concepts of general importance for asynchronous distributed algorithms.
These concepts include the general modelling methods; notions of atomicity, fairness, progress, and fault-tolerance; invariant assertion and simulation proofs; and time analysis techniques.
In Chapter 11, we discuss generalizations of the mutual exclusion problem to more complicated resource allocation problems; these involve more resources and have more elaborate requirements about their usage patterns.
For example, we consider the Dining Philosophers problem, a prototypical resource allocation problem involving allocation of pairwise shared resources in a ring of processors.
In Chapter 12, we reconsider consensus problems in the asynchronous shared memory model.
The main result of this chapter is the fundamental fact that a very basic consensus problem cannot be solved in this setting in the presence of faults, if the shared memory supports only read and write operations.
In contrast, stronger types of shared memory, such as read-modify-write memory, admit simple solutions to this problem.
Up to this point in the book, we assume that all accesses by processors to shared memory are instantaneous.
We define atomic objects and prove basic results showing how they can be used to construct systems; in particular, they can be used in place of shared variables.
We also consider several algorithms that implement powerful atomic objects using weaker primitives--ei ther shared variables or atomic objects of weaker types.
An interesting property that these algorithms have is wait-freedom, which means that any operation on the implemented object must complete regardless of the failure of other concurrent operations.
We show how to implement a snapshot atomic object using read/wri te  shared memory; a snapshot atomic object admits a snapshot operation that returns values for all the memory locations at once.
A s y n c h r o n o u s  n e t w o r k  a l g o r i t h m s.
In Chapters 15-22, we proceed to the study of algorithms that operate in asynchronous networks.
As for synchronous networks, the system is modelled as a graph or digraph with processors at the nodes and communication links on the edges, but now the system does not operate in rounds.
Now, messages can arrive at arbitrary times and the processors can take steps at arbitrary speeds.
The system components can be said to be more "loosely coupled" than they are in either the synchronous network setting or the asynchronous shared memory setting.
Thus, the amount of uncertainty in the model is again increased.
For example, we reconsider the problems of leader election, breadth-first search and shortest paths, broadcast and convergecast, and minimum spanning tree.
Although some of the algorithms carry over to the new setting with little change, most of them require significant modification.
In particular, it is rather difficult to extend the simple synchronous minimum spanning tree algorithm of Chapter 4 to the asynchronous setting.
Chapter 15 should convince you that the task of programming asynchronous networks is difficult.
This difficulty motivates the following four chapters, Chapters 16-19, where we introduce four techniques for simplifying the task.
These techniques are formulated as algorithm transformations that allow an asynchronous network to simulate simpler or more powerful models.
These transformations permit algorithms designed for the simpler or more powerful models to run in the more complex asynchronous network model.
The first technique, described in Chapter 16, is the introduction of a synchronizer.
A synchronizer is a system component that enables asynchronous networks (without failures) to simulate the synchronous networks of Chapters 24 (those without failures)
We give efficient implementations and contrast these implementations with a lower bound result that seems to say that any such simulation must be inefficient.
The apparent contradiction turns out to depend on the type of problem being solved.
The second technique, described in Chapter 17, is the simulation of the asynchronous shared memory model by the asynchronous network model.
This permits asynchronous shared memory algorithms such as those developed in Chapters 10-13 to be used in asynchronous networks.
The third technique, described in Chapter 18, is the assignment of consistent logical times to events in an asynchronous distributed network.
This technique can be used to allow an asynchronous network to simulate one in which the nodes have access to perfectly synchronized real-time clocks.
An important use of this capability is to allow an asynchronous network to simulate a centralized (nondistributed) state machine.
Chapter 19 contains our fourth technique, the monitoring of asynchronous network algorithms while they run.
This might be done, for example, for the purpose of debugging, for producing backup versions, or for detecting stable properties of the algorithm.
A stable property is one that, once it occurs, will persist forever; examples are system termination or deadlock.
It turns out that a fundamental primitive that helps in the detection of stable properties is the ability to produce a consistent global snapshot of the state of the distributed algorithm.
We show some ways in which such a snapshot can be produced and describe how a snapshot can be used to detect stable properties.
Having developed some powerful tools, we return to considering specific problems in the asynchronous network setting.
In Chapter 20, we revisit the problem of resource allocation.
For example, we show some ways of solving the mutual exclusion and Dining Philosophers problems in asynchronous networks.
In Chapter 21, we consider the problem of computing in an asynchronous network in the presence of stopping faults.
First, using a transformation developed in Chapter 17, we show that the impossibility result for consensus carries over from the shared memory setting to the network setting.
We then consider some ways around this inherent limitation; for instance, we give a randomized algorithm to solve consensus, show how to solve consensus using modules known as failure detectors, and show how to reach approximate agreement rather than exact agreement.
Data link protocols are designed to implement a reliable communication link in terms of unreliable underlying channels.
We begin by presenting the Alternating Bit protocol, a simple protocol that, in addition to being interesting in its own right, is also well known as a standard case study in the field of concurrent algorithm verification.
We also present a variety of other algorithms and impossibility results for this problem, for settings in which different types of failure behavior are considered for the underlying channels.
Partially synchronous models lie properly between synchronous and asynchronous models.
In partially synchronous models, we assume that processors have some knowledge of time, for example, access to real time or approximate real time, or some type of timeout facility.
Or, we might assume that processor step times and/or  message delivery times are between known upper and lower bounds.
Since partially synchronous systems have less uncertainty than asynchronous systems, you might think that they ought to be easier to program.
However, there are extra complications that arise from the t iming~for  example, algorithms are often designed so that their correctness depends crucially on timing assumptions.
Since partially synchronous distributed algorithms are a subject of current research, the results we present for this model are necessarily preliminary.
The major source for the material in this book is the research literature, especially the many papers presented in the Association for Computing Machinery's annual symposium on Principles of Distributed Computing (PODC)
Other symposia that contain a substantial number of papers in this area include the annual symposia on Foundations of Computer Science (FOCS), Theory of Computing (STOC), and Parallel Algorithms and Architectures (SPAA), and the annual Workshop on Distributed Algorithms (WDAG)
The results in these papers are presented in terms of a great many different models and at varying levels of rigor.
There have been a few previous attempts to collect and summarize some of the material in this area.
The chapter by Lamport and Lynch on distributed computing in the Handbook of Theoretical Computer Science [185] is a sketchy overview of some of the modelling and algorithmic ideas.
Another book, by Raynal and Helary [251], presents results on network synchronizers.
Chandy and Misra [69] present a substantial collection of distributed algorithms, in terms of the UNITY programming model.
Results about the P RAM model for synchronous shared memory systems are collected in a paper by Karp and Ramachandran [166]
Results about synchronous parallel algorithms for fixed-connection networks are collected in a book by Leighton [193]
Hadzilacos and Toueg [143] present results about the implementation of distributed systems based on communication systems with an atomic broadcast primitive.
A standard reference for these is the classical book by Harary [147]
The first part of this book consists of Chapters 2-7
These chapters contain algorithms and lower bound results for the synchronous network model, in which processors in a network take steps and exchange messages in synchronous rounds.
The first chapter in this part, Chapter 2, just presents our formal model for synchronous networks.
You can skip this chapter for now and return to it as you need to while reading the algorithm chapters, Chapters 3-7
Chapter 3 deals with the simple problem of electing a unique leader in a ring network.
Chapter 4 contains a survey of basic algorithms used in synchronous networks based on arbitrary graphs.
Finally, Chapter 7 contains extensions and variations of the basic consensus problems.
That is because all it has to accomplish is to present a simple computational model for synchronous network algorithms.
We present the model separately so that you can use this chapter as a convenient reference while reading Chapters 3-7
A synchronous network system consists of a collection of computing elements located at the nodes of a directed network graph.
In Chapter 1, we referred to these computing elements as "processors," which suggests that they are pieces of hardware.
It is often useful to think of them instead as logical software "processes," running on (but not identical to) the actual hardware processors.
The results that we present here make sense in either case.
We will use the convention of calling the computing elements "processes" from now on in the book.
In order to define a synchronous network system formally, we start with a directed graph G = (V,E)
We use the letter n to denote IVI, the number of nodes in the network digraph.
For each node i of G, we use the notation out-nbrsi to denote the "outgoing neighbors" of i, that is, those nodes to which there are edges from i in the digraph G, and in-nbrsi to denote the "incoming neighbors" of i, that is, those nodes from which there are edges to i in G.
We let distance(i, j) denote the length of the shortest directed path from i to j in G, if any exists; otherwise distance(i, j )  = oc.
We define diam, the diameter, to be the maximum distance(i, j) ,  taken over all pairs (i, j)
Associated with each node i E V, we have a process, which consists formally.
That is, each process has a set of states, among which is distinguished a subset of start  states.
This generality is important, since it permits us to model systems that include unbounded data structures such as counters.
The message-generation function specifies, for each state and outgoing neighbor, the message (if any) that process i sends to the indicated neighbor, starting from the given state.
The state-transition function specifies, for each state and collection of messages from all the incoming neighbors, the new state to which process i moves.
Associated with each edge (i, j )  in G, there is a channel, also known as a link, which is just a location that can, at any time, hold at most a single message in M.
Execution of the entire system begins with all the processes in arbitrary start states, and all channels empty.
Then the processes, in lock-step, repeatedly perform the following two steps:
Apply the message-generation function to the current state to generate the messages to be sent to all outgoing neighbors.
Apply the state-transition function to the current state and the incoming messages to obtain the new state.
The combination of the two steps is called a round.
Note that we do not, in general, place restrictions on the amount of computation a process does in order to compute the values of its message-generation and state-transition functions.
Also note that the model presented here is deterministic, in the sense that the message-generation function and the state-transition function are (single-valued) functions.
Thus, given a particular collection of start  states, the computation unfolds in a unique way.
So far, we have not made any provision for process halting.
It is easy, however, to distinguish some of the process states as halting states, and specify that no further activity can occur from these states.
That is, no messages are generated and the only state transition is a self-loop.
Note that these halting states do not play the same role in these systems as they do in traditional finitestate automata.
There, they generally serve as accepting states, which are used to determine which strings are in the language computed by the machine.
Here, they just  serve to halt the process; what the process computes must be determined according to some other convention.
The notion of accepting state is normally not used for distributed algorithms.
Occasionally, we will want to consider synchronous systems in which the processes might begin executing at different rounds.
We model this situation by augmenting the network graph to include a special environment node, having edges to all the ordinary nodes.
The job of the associated environment process is to send special wakeup messages to all the other processes.
Each start  state of each of the other processes is required to be quiescent, by which we mean that it does not cause any messages to be generated, and it can only change to a different state as the result of the receipt of a wakeup message from the environment or a non-null message from some other process.
Thus, a process can be awakened either directly, by a wakeup message from the environment, or indirectly, by a non-null message from another, previously awakened, process.
Sometimes we will want to consider the case where the underlying network graph is undirected.
We model this situation within the model we have already defined for directed graphs simply by considering a directed graph network with bidirectional edges between all pairs of neighbors.
In this case, we will use the notation nbrsi to denote the neighbors of i in the  graph.
We will consider various types of failures for synchronous systems, including both process failures and link (channel) failures.
A process can exhibit stopping failure simply by stopping somewhere in the middle of its execution.
This means that the process might succeed in putting only a subset of the messages it is supposed to produce into the message channels.
A process can also exhibit Byzantine failure, by which we mean that it can generate its next messages and next state in some arbitrary way, without necessarily following the rules specified by its message-generation and state-transition functions.
In terms of a model, a process might at tempt to place a message in a channel during Step 1, but the faulty link might not record the message.
We still have not provided any facility for modelling inputs and outputs.
We use the simple convention of encoding the inputs and outputs in the states.
In particular, inputs are placed in designated input variables in the start states; the fact that a process can have multiple start states is important  here, so that we can accommodate different possible inputs.
In fact, we normally assume that the only source of multiplicity of start states is the possibility of different input values in the input variables.
Outputs appear in designated output variables; each of these records the result of only the first write operation that is performed (i.e., it is a write-once variable)
Output  variables can be read any number of times, however.
In order to reason about the behavior of a synchronous network system, we need a formal notion of a system "execution."
A state assignment of a system is defined to be an assignment of a state to each process in the system.
Also, a message assignment is an assignment of a (possibly null) message to each channel.
An execution of the system is defined to be an infinite sequence.
We often refer to C~ as the state assignment that occurs at time r; that is, time r refers to the point just after r rounds have occurred.
The most important proof method for reasoning about synchronous systems involves proving invariant assertions.
An invariant assertion is a property of the system state (in particular, of the states of all the processes) that is true in.
We allow the number of completed rounds to be mentioned in assertions, so that we can make claims about the state after each.
Roughly speaking, the goal is to show that one synchronous algorithm A "implements" another synchronous algorithm B, in the sense of producing the same input /output  behavior.
The correspondence between A and B is expressed by an assertion relating the states.
As for invariant assertions, simulation relationships are generally proved by induction on the number of completed rounds.
Two measures of complexity are usually considered for synchronous distributed algorithms: time complexity and communication complexity.
The time complexity of a synchronous system is measured in terms of the number of rounds until all the required outputs are produced, or until the processes all halt.
If the system allows variable start times, the time complexity is measured from the first round in which a wakeup occurs, at any process.
The communication complexity is typically measured in terms of the total.
Occasionally, we will also take into account the number of bits in the messages.
The time measure is the more important  measure in practice, not only for synchronous distributed algorithms but for all distributed algorithms.
The communication complexity is mainly significant if it causes enough congestion to slow down processing.
This suggests that we might want to ignore it and just consider time complexity.
However, the impact of the communication load on the time complexity is not just a function of an individual distributed algorithm.
In a typical network, many distributed algorithms run simultaneously, sharing the same network bandwidth.
The message load added to a link by any single algorithm gets added to the total message load on that link, and thus contributes to the congestion seen by all the algorithms.
Since it is difficult to quantify the impact that any one algorithm's messages have on the time performance of other algorithms, we settle for simply analyzing (and attempting to minimize) the number of messages generated by individual algorithms.
Instead of requiring the processes to be deterministic, it is sometimes useful to allow them to make random choices, based on some given probability distributions.
Since the basic synchronous system model does not permit this, we augment the model by introducing a new random function in addition to the message-generation and transition functions, to represent the random choice steps.
Formally, we add a randi component to the automaton description for each node i; for each state s, randi(s) is a probability distribution over some subset of statesi.
Now in each round of execution, the random function randi is first used to pick new states, and the msgsi and transi functions are then applied as  u s u a l.
The formal notion of execution used in a randomized algorithm now includes not only state assignments and message assignments, but also information about random functions.
Specifically, an execution of the system is defined to be an infinite sequence.
D~ represents the new process states after the round r random choices.
Claims about what is computed by a randomized system are usually probabilistic, asserting that certain results are achieved with at least a certain probability.
When such a claim is made, the intention is generally that it is supposed.
To model the inputs and failure patterns, a fictitious entity called an adversary is usually assumed to control the choices of inputs and occurrences of failures, and the probabilistic claim asserts that the system behaves well in competition with any allowable adversary.
General treatment of these issues is beyond the scope of this book; we will just provide special case definitions as they are needed.
The general notion of a state machine model has its roots in the traditional finite-state automaton model.
The particular kind of state machine model defined here is extracted from numerous papers in distributed computing theory, for example, the Byzantine agreement paper by Fischer and Lynch [119]
In this chapter, we present the first problem to be solved using the synchronous model of Chapter 2: the problem of electing a unique leader process from among the processes in a network.
For starters, we consider the simple case where the network digraph is a ring.
This problem originally arose in the study of local area token ring networks.
In such a network, a single "token" circulates around the network, giving its current owner the sole right to initiate communication.
If two nodes in the network were to at tempt simultaneously to communicate, the communications could interfere with one another.
Sometimes, however, the token may be lost, and it becomes necessary for the processes to execute an algorithm to regenerate the lost token.
The processes associated with the nodes of G do not know their indices, nor those of their neighbors; we assume that the message-generation and transition functions are defined in terms of local, relative names for the neighbors.
However, we do assume that each process is able to distinguish its clockwise neighbor from its counterclockwise neighbor.
The requirement is that, eventually, exactly one process should output the decision that it is the leader, say by changing a special status component of its state to the value leader.
If it is unidirectional, then each edge is directed from a process to its clockwise neighbor, that.
The number n of nodes in the ring can be either known or unknown to the processes.
If it is known, it means that the processes only need to work correctly in rings of size n, and thus they can use the value n in their programs.
If it is unknown, it means that the processes are supposed to.
We assume that each process's UID is different from each other's in the ring, but that there is no constraint on which UIDs actually appear in the ring.
For instance, they do not have to be consecutive integers.
A first easy observation is that if all the processes are identical, then this problem cannot be solved at all in the given model.
This is so even if the ring is bidirectional and the ring size is known to the processes.
I f  all the processes in A are identical, then A does not solve the leader-election problem.
Suppose that there is such a system A that solves the leader-election problem.
We can assume without any loss of generality that each process of A has exactly one start  state.
This is so because if each process has more than one start  state, we could simply choose any one of the start  states and obtain a new solution in which each process has only one start  state.
It is s traightforward to verify, by induction on the number r of rounds that have been executed, that all the processes are in identical states immediately after r rounds.
Therefore, if any process ever reaches a state where its status is leader, then all the processes in A also reach such a state at the same time.
Theorem 3.1 implies that the only way to solve the leader-election problem is to break the symmetry somehow.
This is the assumption we make in the rest of this chapter.
The first solution we present is a fairly obvious one, which we call the L CR algorithm in honor of Le Lann, Chang, and Roberts,  from whose papers this.
The algorithm uses only unidirectional communication and does not rely on knowledge of the size of the ring.
In this algorithm, the process with the largest UID is the only one that outputs.
In order to make this intuit ion precise, we give a more careful description.
The message alphabet  M is exactly the set of UIDs.
For each i, the states in statesi consist of the following components:
The set of s tar t  states starti consists of the single state defined by the given initializations.
For each i, the message-generation function msgsi is defined as follows:
Chapter  2 that  we use the null  value as a placeholder indicating the absence.
So if the value of the send  component  is null, this msgi.
For each i, the t rans i t ion function transi is defined by the following pseudocode:
The first line of the transit ion function definition just cleans up the state from the effects of the preceding message delivery (if any)
The rest of the code contains the interesting work- - the  decision about whether to pass on or discard the incoming UID, or to accept it as permission to become the leader.
In this translation, each process state consists of a value for each of the variables, and the transitions are describable in terms.
Note that the entire block of code written for the transi function is supposed to be executed indivisibly, as part  of the processing for a single round.
How do we go about proving formally that the algorithm is correct? Correctness means that exactly one process eventually performs a leader output.
Here and in many other places in the book, we attach the subscript i to a state component name to indicate the instance of that state component belonging.
For example, we use the notation ui to denote the value of state component u of process i.
We generally omit the subscripts when writing the process code, however.
Note that Umax is the initial value of variable U/max , the variable u at process /max, by the initialization.
Also note that the values of the u variables never change (by the code), that they are all distinct (by assumption),  and that /max has the largest u value (by definition of/max)
By the code, it suffices to show the following invariant assertion:
A s s e r t i o n  3.3.1 Af ter  n rounds, s ta tus im .x -  leader.
The normal way to try to prove an invariant such as this one is by induction on the number of rounds.
But in order to do this, we need a preliminary invariant that says something about the situation after smaller numbers of rounds.
This assertion says that the maximum value appears in the send component at the position in the ring at distance r from.
It is straightforward to prove Assertion 3.3.2 by induction on r.
The inductive step is based on the fact that every node other than/max accepts the maximum value and places it into its send component, since Umax is greater than all the other values.
The key fact here is that process /max accepts Umax as a signal to set its status to leader.
A s s e r t i o n  3.3.3 For any r and any i, j ,  the following holds.
Again, it is straightforward to prove the assertion by induction; now the key fact used in the proof is that a non-maximum value does not get past/max.
This is because /max compares the incoming value with Um~x, and Umax is greater than all the other UIDs.
Halting and n o n - l e a d e r  o u t p u t s.
As written, the LCR algorithm never finishes its work, in the sense of all the processes reaching a halting state.
We can augment each process to include halting states, as described in Section 2.1
Then we can modify the algorithm by allowing the elected leader to initiate a special report message to be sent around the ring.
Any process that receives the report message can halt, after passing it on.
This strategy not only allows processes to halt, but could also be used to allow the non-leader processes to output nonleader.
Furthermore, by attaching the leader's index to the report message, this.
Note that it is also possible for each non-leader node to output non-leader immediately after it sees a UID greater than its own; however, this does not tell the non-leader nodes when to halt.
In general, halting is an important  property for a distributed algorithm to satisfy; however, it cannot always be achieved as easily as in this case.
The time complexity of the basic LCR algorithm is n rounds until a leader is announced, and the communication complexity is O (n 2) messages in the worst case.
The extra time needed for halting and for the non-leader announcements is only n rounds, and the extra communication is only n messages.
The preceding two remarks describe and analyze a general transformation, from any leader-election algorithm in which only the leader provides output and no process ever halts, to one in which the leader and the nonleaders all provide output and all processes halt.
The extra cost of obtaining the extra outputs and the halting is only n rounds and n messages.
This transformation works for any combination of our other assumptions.
Note that the LCR algorithm works without modification in the version of the synchronous model with variable start times.
See Section 2.1 for a description of this version of the model.
In the problem of electing a leader in a ring, the key difficulty is breaking symmetry.
Although the time complexity of the LCR algorithm is low, the number of messages used by the algorithm seems somewhat high, a total of O (n2)
This might not seem significant, because there is never more than one message on any link at any time.
However, in Chapter 2, we discussed why the number of messages is an interesting measure to try to minimize; this is because of the possible network.
In this section, we present an algorithm that lowers the communication complexity to O (n log n)
The first published algorithm to reduce the worst-case complexity to O (n log n) was that of Hirschberg and Sinclair, so we call this algorithm the HS algorithm.
Again, we assume that only the leader needs to perform an output,  though the transformation at the end of Section 3.3 implies that this restriction is not important.
Again, we assume that the ring size is unknown, but now we allow bidirectional communication.
As does the L C R  algorithm, the HS algorithm elects the process with the maximum UID.
Now every process, instead of sending its UID all the way around the ring as in the L C R  algorithm, sends it so that it travels some distance away, then turns around and comes back to the originating process.
In each phase l, process i sends out "tokens" containing its UID ui in both directions.
While a ui token is proceeding in the outbound direction, each other process j on ui's path compares ui with its own UID uj.
If ui = uj,  then it means that process j has received its own UID before the token has turned around, so process j elects itself as the leader.
All processes always relay all tokens in the inbound direction.
This time, the formalization requires some bookkeeping to ensure that tokens follow the proper trajectories.
For instance, flags are carried by the tokens indicating whether they are travelling outbound or inbound.
Also, hop counts are carried with the tokens to keep track of the distances they must travel in the outbound direction; this allows the processes to figure out when the directions of the tokens should be reversed.
Once the algorithm is formalized in this way, a correctness argument of the sort given for L CR can be provided.
For each i, the states in statesi consist of the following components:
The set of start states starti consists of the single state defined by the given initializations.
For each i, the message-generation function msgsi is defined as follows:
For each i, the transition function transi is defined by the following pseudocode:
As before, the first two lines just  clean up the state.
The  next two pieces of code describe the handl ing of ou tbound  tokens: tokens with UIDs tha t  are.
The next two pieces of code describe the handl ing of inbound tokens: they are simply relayed.
If process i receives both  of its own tokens back, then  it goes on to the next phase.
This is exact ly if it has not been "defeated" by another  process within dis tance 2/-1 in ei ther direction along the ring.
Then  the total  number  of messages sent out at phase 1 is bounded  by.
Again, the factor of 4 is derived from the fact tha t  the token is sent out in bo th  direct ions--c lockwise and counte rc lockwise - -and  tha t  each ou tbound  token must  tu rn  a round and return.
The  total  number  of phases tha t  are executed before a leader is elected and.
The final phase takes time n - - i t  is an incomplete phase, with tokens only travelling outbound.
Thus, the total time complexity of all but the final phase is at most.
The rest of the details are left as an exercise.
The HS algorithm works without modification in the version of the synchronous model with variable start times.
We next consider the question of whether it is possible to elect a leader with fewer than O (n log n) messages.
The answer to this problem, as we shall demonstrate shortly with an impossibility resu l t - -a  lower bound of f~(n log n) - - i s  negative.
That  result, however, is valid only in the case of algorithms that manipulate the UIDs using comparisons only.
In this section, we allow the UIDs to be positive integers and permit them to be manipulated by general arithmetic operations.
For this case, we give two algorithms, the TimeSlice algorithm and the VariableSpeeds algorithm, each of which uses only O (n) messages.
The existence of these algorithms implies that the lower bound of f~(n log n) cannot be proved for the general case.
The first of these algorithms uses the strong assumption that the ring size n is known to all the processes, but only assumes unidirectional communication.
In this setting, the following simple algorithm, which we call the TimeSlice algorithm, works.
Note that this algorithm uses synchrony in a deeper way than do the LCR and HS algorithms.
Namely, it uses the non-arrival of messages (i.e., the arrival of null messages) at certain rounds to convey information.
Each phase is devoted to the possible circulation, all the way around the ring, of a token carrying a particular UID.
As this token travels, all the other processes note that they have received it, which prevents them from electing themselves as leader or initiating the sending of a token at any later phase.
With this algorithm, the minimum UID U m i n  eventually gets all the way around, which causes its originating process to become elected.
If we prefer to elect the process with the maximum UID rather than the process with the minimum, we can simply let the minimum send a special message around after it is discovered in order to determine the maximum.
The good property of the TimeSlice algorithm is that the total number of messages is n.
Unfortunately, the time complexity is about n 9 U m i n ,  which is an unbounded number, even in a fixed-size ring.
This time complexity limits the practicality of the algorithm; it is only useful in practice for small ring networks in which UIDs are assigned from among the small positive integers.
The TimeSlice algorithm shows that O (n) messages are sufficient in the case of rings in which processes know n, the size of the ring.
But what if n is unknown? It turns out that in this case, also, there is an O (n) message algorithm, which we call the VariableSpeeds algorithm for reasons that will become apparent  in a moment.
Clearly, no one would even think of using this algorithm in practice! The VariableSpeeds algorithm is what we call a counterexample algorithm.
A counterexarnple algorithm is one whose main purpose is to show that a conjectured impossibility result is false.
Such an algorithm is generally not interesting by i tself--i t  is neither practical nor particularly elegant from a mathematical viewpoint.
VariableSpeeds algorithm: Each process i initiates a token, which travels around the ring, carrying.
Meanwhile, each process keeps track of the smallest UID it has seen and simply discards any token carrying an identifier that is larger than this smallest one.
If a token returns to its originator, the originator is elected.
As for the TimeSlice algorithm, the VariableSpeeds algorithm guarantees that the process with the minimum UID is elected.
The VariableSpeeds algorithm guarantees that by the time the token carrying the smallest identifier Umin gets all the way around the ring, the second smallest identifier could only get at most halfway around, the third smallest could only get at most a quarter of the way around, and in general, the kth smallest could only get at most ~ of the way around.
Therefore, up to the time of election, the token carrying Umin USeS more messages than all the others combined.
Since Umin uses exactly n messages, the total number of messages sent, up to the time of election, is less than 2n.
But also, note that by the time Umin gets all the way around the ring, all nodes know about this value, and so will refuse to send out any other tokens.
It follows that 2n is an upper bound on the total number of messages that are ever sent by the algorithm (including the time after the leader output)
Unlike the LCR and HS algorithms, the VariableSpeeds algorithms cannot be used "as is" in the version of the synchronous model with variable start times.
Define a process to be a starter if it receives a wakeup message strictly before (i.e., at an earlier round than) receiving any ordinary (non-null) messages.
Each starter i initiates a token to travel around the ring, carrying its UID ui; non-starters never initiate tokens.
Initially, this token travels "fast," at the rate of one transmission per round, getting passed along by all the non-starters that are awakened by the arrival of the token, just until it first arrives at a starter.
Meanwhile, each process keeps track of the smallest starter 's  UID that it has seen and discards any token carrying an identifier that is larger than this smallest one.
If a token returns to its originator, the originator is elected.
The modified VariableSpeeds algorithm ensures that the starter  process with the minimum UID is elected.
The messages involved in the initial fast transmission of tokens.
This takes at most n rounds from when the first process awakens.
This analysis is similar to that for the basic VariableSpeeds algorithm.
By the time the winning token gets all the way around the ring, the kth smallest starter 's  identifier could only get at most ~ of the way around.
Therefore, the total number of messages sent, up to the time of election, is less than 2n.
But by the time the winning token gets all the way around the ring, all nodes know about its value, and so will refuse to send out any other tokens; thus, 2n is an.
So far, we have presented several algorithms for leader election on a synchronous ring.
The LCR and HS algorithms are comparison based, and the latter achieves a communication complexity bound of O (n log n) messages and a time bound of O (n)
The TimeSlice and VariableSpeeds algorithms, on the other hand, are not comparison based, and use O (n) messages, but have a huge running time.
This lower bound holds even if we assume that communication is bidirectional and the ring size n is known to the processes.
The result of this section is based on the difficulty of breaking symmetry.
Recall the impossibility result in Theorem 3.1, which says that, because of symmetry, it is impossible to elect a leader in the absence of distinguishing information such as UIDs.
The main idea in the following argument is that a certain amount of symmetry  can arise even in the presence of UIDs.
In this case, the UIDs allow symmetry  to be broken, but it might require a large amount  of communication to do so.
Recall that we are assuming throughout  this chapter that the processes in the ring are all identical except for their UIDs.
Thus, the start  states of the processes are identical except for designated components that contain the process UID.
In general, we have not imposed any constraints on how the message-generation and transit ion functions can use the UID information.
We assume for the rest of this chapter (this section and the next) that there is only one start  state containing each UID.
As in the proof of Theorem 3.1, this assumption does not cause any loss of generality.
The advantage of this assumption is that it implies that the system (with a fixed assignment of UIDs) has exactly one execution.
This definition allows a process, for example, to store any of the various UIDs that it has encountered and to send them out in messages, possibly combined with other information.
A process can also compare the stored UIDs and use the results of these comparisons to make choices in the message-generation and state-transit ion functions.
These choices could involve, for example, whether or not to send a message to each of its neighbors, whether or not to elect itself the leader, whether or not to keep the stored UIDs, and so on.
The impor tant  fact is that all of the activity of a process depends only on the relative ranks of the UIDs it has encountered, rather than on their part icular values.
The following formal notion is used to describe the kind of symmetry  that can exist, even with VlDs.
Finally, we need a definition of what it means for process states to be the same, except for the part icular  choices of UIDs they contain.
We can now prove the key lemma for our lower bound, Lemma 3.5
It says that  processes that have order-equivalent k-neighborhoods behave in essentially the same way, until information has had a chance to propagate to the processes from outside the k-neighborhoods.
Let i and j be two processes in A that have order-equivalent sequences of UIDs in their k-neighborhoods.
Then, at any point after at most k active rounds, processes i and j are in corresponding states, with respect to the UID sequences in their k-neighborhoods.
Roughly speaking, the reason this is so is that if there are only three active rounds, there has not been any opportuni ty for information from outside the order-equivalent 3-neighborhoods to reach i and j.
We proceed by induction on the number r of rounds that have been performed in the execution.
For each r, we prove the lemma for all k.
By the definition of a comparison-based algorithm, the initial states of i and j are identical except for their own UIDs, and hence they are in corresponding initial states, with respect to their k-neighborhoods (for any k)
Fix k such that i and j have order-equivalent k-neighborhoods, and suppose that the first r rounds include at most k active rounds.
Since i and j have no new input, they make corresponding transitions and end up in corresponding states after round r.
So assume that either i or j receives a message at round r.
But this contradicts the assumption that either i or j receives a message at round r.
For similar reasons, j + 1 sends no message to j at round r.
Since i and j are in corresponding states after round r -  1, and receive corresponding messages, they remain in corresponding states, this time with respect to.
Lemma 3.5 tells us that many active rounds are necessary to break symmetry.
Specifically, we define the bit-reversal ring of size n as follows.
For values of n that are not powers of 2, there also always exist c-symmetric rings, though the general case requires a smaller constant c.
The proof of Theorem 3.7 involves a fairly complicated recursive construction.
It is not possible to produce the needed ring simply, say by starting with.
So we can assume, for any n, that we have a c-symmetric ring R of size n.
The following lemma states that if such a ring elects a leader, then it must have many active rounds.
Try to ignore the square root lower bound condition--it is just a technicality.
Note that for the bit-reversal ring, there is no need for the square root lower bound condition.
This is where the square root lower bound condition arises.
Suppose that A elects a leader, say process i, in at most k active rounds.
Since the ring is c-symmetric, there must be at least.
Thus, there is at least one other segment that is order equivalent to S; let j be the midpoint of that segment.
Now, by Lemma 3.5, i and j remain in equivalent states throughout the execution, up to the election point.
Then there is an execution of A in which ~ (n  log n) messages are sent by the time the leader is elected.
The ~(n log n) expression hides a fixed constant, independent of n.
Fix c to be the constant whose existence is asserted by Theorem 3.7, and use that theorem to obtain a c-symmetric ring R of size n.
By Lemma 3.5, at the point just before the r th  active round, the midpoints of all these segments are in corresponding states, so they all send messages.
The second term is O (n), so it suffices to show that the first term is ft(n log n)
For example, suppose that the time until leader election is bounded.
Then, if the total number of UIDs in the space of identifiers is sufficiently large--say, greater than some particular fast-growing function f (n, t ) ~ t h e n  there is a subset U of the identifiers on which it is possible to show that the algorithm behaves "like a comparison-based algorithm," at least through t rounds.
This implies that the lower bound for comparison carries over to the time-bounded algorithm using identifiers in U.
We give somewhat more detail, but our presentation is still just a sketch.
We will define the fast-growing function f ( n ,  t) using Ramsey's  Theorem, which is a kind of generalized Pigeonhole Principle.
In the statement of the theorem, an n-subset is just a subset with n elements, and a coloring just assigns a color to each set.
For every set S of size at least g(n, m, c), and any coloring of the n-subsets of S with at most c colors, there is some subset C of S of size m that has all of its n-subsets colored the same color.
We begin by putting each algorithm into a normal form, in which each state simply records, in LISP S-expression format, the initial UID plus all the messages ever received, and each non-null message contains the complete state of its sender.
Certain of these S-expressions are then designated as election states, in which the process is identified as having been elected as the leader.
If the original algorithm is a correct leader-election algorithm, then the new one (with the modified output convention) is also, and the communication complexity is the same.
Let A be any (not necessarily comparison-based) algorithm that elects a leader in rings of size n within time t and uses a UID space of size at least f ( n ,  t)
Then there is an execution of A in which f~(n log n) messages are sent by the time the leader is elected.
Without loss of generality, we only consider algorithms in normal form.
Since the algorithms involve only n processes and proceed for only t rounds, all the S-expressions that arise have at most n distinct arguments and at most t parenthesis depth.
Now for each algorithm A, we define an equivalence relation ----A on n-sets (i.e., sets of size n) of UIDs; roughly speaking, two n-sets will be said to be equivalent if they give rise to the same behavior for algorithm A.
S-expression of depth at most t over V, the corresponding S-expression over V ~ (generated by replacing each element of V with the same rank element within W) give rise to the same decisions, in algorithm A, about whether to send a message in each direction and about whether or not the process is elected as leader.
Because the S-expressions in the definition of the equivalence relation have at most n arguments  and at most t depth, there are only finitely many =A equivalence classes; in fact, there is an upper bound on the number of classes that  does not depend on the algorithm A, but only on n and t.
We describe a way of coloring n-sets of UIDs, so we can apply Ramsey's  Theorem.
Namely, we just associate a color with each =A equivalence class of n-sets, and color all the n-sets in that  class by that  color.
Take U to be the set consisting of the n smallest elements of C.
Then we claim that  the algorithm behaves exactly like a comparison algor i thm through t rounds, when UIDs are chosen from U.
That  is, every decision made by any process, about whether to send a message in either direction or about whether the process is a leader, depends only on the relative order of the arguments contained in the current state.
To see why this is so, fix any two subsets W and W ~ of U, of the same size--say m.
Since V and V ~ are colored the same color, the two S-expressions give rise to the same decisions about whether to send a message in each direction and about whether or not the process is elected as leader.
Since the algorithm behaves exactly like a comparison algorithm through t rounds, when UIDs are chosen from U, Theorem 3.9 yields the lower bound.
The LCR algorithm is derived from one developed by Le Lann.
The HS algorithm is due to Hirschberg and Sinclair [156]
The TimeSlice algorithm also seems to be folklore, but is similar to the election strategy used in the MIT token ring network.
Another construction of c-symmetric rings is carried out by Attiya, Snir, and Warmuth [27]
Ramsey's Theorem is a standard result of combinatorial theory, and is presented, for example, in the graph theory book of Berge [47]
Fill in more of the details for the inductive proof of correctness of the LCR algorithm.
Modify the LCR algorithm so that it also allows all the non-leader processes to output non-leader, and so that all the processes eventually halt.
Present the modified algorithm using the same style of "code" that we used for the LCR algorithm.
Show that the LCR algorithm still works correctly in the version of the synchronous model allowing variable start times.
Carry out a careful proof of correctness for the HS leader-election algorithm, using the invariant assertion style used for LCR.
Show that the HS algorithm still works correctly in the version of the synchronous model allowing variable start times.
Analyze the time and communication complexity of the modified algorithm, similarly to the way the original HS algorithm is analyzed in the book.
Consider modifying the HS algorithm so that the processes only send tokens in one direction rather than both.
Design a unidirectional leader-election algorithm that works with unknown ring size, and only uses O (n log n) messages in the worst case.
Give code for a state machine to express the TimeSlice leader-election algorithm.
Describe a variant of the TimeSlice algorithm that saves time at the expense of additional messages, by allowing some number k of UIDs instead of just one to circulate in each phase.
Prove the correctness of your algorithm and analyze its complexity.
Give code for a state machine to express the VariableSpeeds leader-election algorithm.
Show that the unmodified VariableSpeeds algorithm does not necessarily have the desired O (n) communication complexity if processes can wake up at different times.
Prove the best lower bound you can for the number of rounds required, in the worst case, to elect a leader in a ring of size n.
Consider the problem of electing a leader in a synchronous ring of size n, where n is known to all the processes and the processes have no UIDs.
Devise a randomized leader-election algorithm, that  is, one in which the processes can make random choices in addition to just following their code.
State carefully the properties tha t  your algori thm satisfies.
For example, is it absolutely guaranteed to elect a unique leader, or is there a small probabili ty that  it will fail to do this? Wha t  are the expected t ime and message complexities of your algorithm?
Consider a synchronous bidirectional ring of unknown size n, in which processes have UIDs.
Give upper and lower bounds on the number  of messages required by a comparison-based algorithm in which all the processes.
In this chapter, we consider a larger collection of problems in a larger class of synchronous networks.
In particular, we present algorithms for leader election, breadth-first search (BFS), finding shortest paths, finding a minimum spanning tree (MST), and finding a maximal independent set (MIS), in networks based on arbitrary graphs and digraphs.
The problem of leader election arises when a process must be selected to "take charge" of a network computation.
The problems of breadth-first search, finding shortest paths, and finding a minimum spanning tree are motivated by the need to build structures suitable for supporting efficient communication.
The problem of finding a maximal independent set arises from the problem of network resource allocation.
We will revisit many of these problems and algorithms later, in Chapter 15, in the context of asynchronous networks.
In this chapter, we consider an arbitrary, strongly connected network digraph G = (V, E) having n nodes.
Sometimes we will restrict attention to the case where all edges are bidirectional, i.e., where the graph is undirected.
We assume, as usual for synchronous systems, that the processes communicate only over the directed edges of the digraph.
The processes do not know their indices, nor those of their neighbors, but refer to their neighbors by local names.
We do assume that if a process i has the same process j for both an incoming and outgoing neighbor, then i knows that  the two processes are the same.
We start by reconsidering the problem of leader election, this time in a network based on an arbitrary strongly connected digraph.
We assume that the processes have unique identifiers (UIDs), chosen from some totally ordered space of identifiers; each process's UID is different from each other's in the network, but there is no constraint on which UIDs actually appear.
As in Chapter 3, the requirement is that, eventually, exactly one process should elect itself the leader, by changing a special status component of its state to the value leader.
As in Chapter 3, there are several versions of the problem:
It might also be required that all non-leader processes eventually output the fact that they are not the leader, by changing their status components to non-leader.
The number n of nodes and the diameter, diam, can be either known or unknown to the processes.
Or, an upper bound on these quantities might be known.
We give a simple algorithm that causes both leaders and non-leaders to identify themselves.
The algorithm just floods the maximum UID throughout the network, so we call it the FloodMax algorithm.
Every process maintains a record of the maximum UID it has seen so far (initially its own)
At each round, each process propagates this maximum on all of its outgoing edges.
After diam rounds, if the maximum value seen is the process's own UID, the process elects itself the leader; otherwise, it is a non-leader.
It is easy to see that FloodMax elects the process with the max imum UID.
More specifically, define/max to be the index of the process with the max imum.
The key to the proof of Assert ion 4.1.1 is the fact that  after r rounds, the maximum UID has reached every process that  is within distance r of/max, as measured.
In particular,  in view of the definition of the diameter  of the graph, Assert ion 4.1.2
To prove Assert ion 4.1.2, it is useful to have the following addit ional  auxiliary.
The FloodMax algorithm can be regarded as a kind of generalization of the LCR algorithm of Section 3.3, because the LCR algorithm also floods the maximum value throughout the (ring) network.
However, note that the LCR algorithm does not require any special knowledge about the network, such as its diameter.
In LCR, a process is elected simply when it receives its own UID in a message, rather than after a specified number of rounds as in FloodMax.
This strategy is particular to ring networks and does not work in general digraphs.
It is easy to see that the time until the leader is elected (and all other processes know that they are not the leader) is diam rounds.
Note that the algorithm also works correctly if the processes all know an upper bound d on the diameter rather than the diameter itself.
The complexity measures then increase so that they depend on d rather than diam.
There is a simple optimization 1 that can be used to decrease the communication complexity in many cases, although it does not decrease the order of magnitude in the worst case.
Namely, processes can send their max-uid values only when they first learn about them, not at every round.
The modification to the code for FloodMax is as follows.
OptFloodMax a l g o r i t h m :
It is easy to believe that this modification yields a correct algorithm.
How can we prove this formally? One way is to carry out another invariant assertion proof similar to the one for FloodMax.
However, this would involve repeating a lot of the work we have already done for the earlier proof.
Instead of starting from scratch, we give a proof based on relating the OptFloodMax algorithm formally to the FloodMax algorithm.
This is a simple example of the use of the simulation method for verifying the correctness of distributed algorithms.
It is enough to prove the following assertion, analogous to Assertion 4.1.1 in the proof for FloodMax.
We start  by proving a preliminary invariant that says that a process's new-info flag is always set to true whenever there is new information that the process is supposed to send at the next round.
More specifically, it says that if any outgoing neighbor of i does not know a UID at least as great as the maximum UID known by i, then i's new-info flag must be true.
The basis case, r = 0, is true because all the new-info flags are initialized to true.
For the inductive step, consider any particular processes i and j,  where j C out-nbrsi.
If max-uidi increases in round r, then new-infoi gets set to true, which suffices.
On the other hand, if max-uidi does not increase, then the inductive hypothesis implies that either max-uidj was already sufficiently large, or else new-infoi = true just before round r.
In the latter case, the new information is sent from i to j at round r, which causes rnax-uidj to become sufficiently large.
Now, to prove that OptFloodMax is correct, we imagine running it side by side with FloodMax, starting with the same UID assignment.
The heart of the proof is a simulation relation, which is just an invariant assertion that involves the states of both algorithms after the same number of rounds.
The proof of the simulation assertion, Assertion 4.1.7, is carried out by induction on r, just as for the usual sorts of assertions involving only a single algorithm.
The interesting part of the inductive step is showing that the max-uid values remain identical.
So consider any i, j ,  where j C out-nbrsi.
If new-infoi = true before round r, then i sends the same information to j in round r in OptFloodMax as it does in FloodMax.
On the other hand, if new-infoi = false before round r, then i sends nothing to j in round r in OptFloodMax, but sends max-uidi to j in round r in FloodMax.
It follows that i has the same effect on max-uidj in both algorithms.
Since this is true for all i and j,  it follows that the max-uid values remain identical in both algorithms.
The method we just used to prove the correctness of OptFloodMax is often useful for proving the correctness of "optimized" versions of distributed algorithms.
First, an inefficient but simple version of the algorithm is proved correct.
Then a more efficient but more complicated version of the algorithm is verified by proving a formal relationship between it and the simple algorithm.
For synchronous network algorithms, this relationship generally takes the form used above--an invariant involving the states of both algorithms after the same number of rounds.
A n o t h e r  i m p r o v e m e n t.
It is possible to reduce the number of messages in the FloodMax algorithm slightly further.
Namely, if a process i receives a new maximum from a process j that is both an incoming neighbor and an outgoing neighbor, that is, with which it has bidirectional communication, then i need not send a message in the direction of j at the next round.
It is possible to elect a leader in a general digraph network with UIDs, but in which no information about n or diam is available to the processes.
We suggest that you stop here and try to construct an algorithm to do this.
One possibility is to introduce an auxiliary protocol that allows each process to calculate the diameter of the network.
The next problem we consider is that of performing a breadth-first search (BFS) in a network based on an arbi t rary strongly connected directed graph having a distinguished source node.
More precisely, we consider how to establish a breadth-first spanning tree for the digraph.
The motivation for constructing such a tree comes from the desire to have a convenient structure to use as a basis for broadcast  communication.
The B FS tree minimizes the maximum communication time from the process at the distinguished node to all other processes in.
The BFS problem and its solutions are somewhat simpler in the case where all.
We define a directed spanning tree of a directed graph G = (V, E) to be a rooted tree that consists entirely of directed edges in E, all edges directed from parents to children in the tree, and that contains every vertex of G.
A directed spanning tree of G with root node i is breadth-first provided that each node at distance d from i in G appears at depth d in the tree (that is, at distance d from i in the tree)
For the BFS problem, we suppose that the network is strongly connected.
The output  should appear in a distr ibuted fashion: each process other than i0 should have a parent component that gets set to indicate the node that is its parent in the tree.
Processes are assumed to have UIDs but to have no knowledge of the size or diameter of the.
The basic idea for this algorithm is the same as for the s tandard sequential breadth-first search algorithm.
At any point during execution, there is some set of processes that is "marked," initially just i0
At any round, if an unmarked process receives a search message, it marks itself and chooses one of the processes from which the search has arrived as its parent.
At the first round after a process gets marked, it sends a search message to all of its outgoing neighbors.
It is not hard to see that the SynchBFS algorithm produces a BFS tree.
This invariant can, as usual, be proved by induction on the number of rounds.
Actually, this analysis can be refined a little, to the maximum distance from the.
The number of messages is just IEI - -a search message is t ransmit ted  exactly once on each directed edge.
As for the FloodMax algorithm, it is possible to reduce the number of messages slightly: a newly marked process need not send a search message in the direction of any process from which it has already received such a message.
The SynchBFS algorithm can easily be augmented to implement message broadcast.
Other processes continue to piggyback m on all their search messages as well.
Since the tree eventually spans all the nodes, message m is eventually delivered to all the processes.
In an important  variant of the BFS problem, it is required that each process learn not only who its parent in the tree is, but also who all of its children are.
In this case, it is necessary for each process receiving a search.
If bidirectional communication is allowed between all pairs of neighbors, that is, if the network graph is undirected, then there is no difficulty--and little extra cos t - - in  adding this extra communication.
However, since we are allowing pairs of neighbors with only unidirectional communication, some of the parent and non-parent messages may need to be sent via indirect routes.
For example, a parent or non-parent message could be sent via a new execution of SynchBFS, using piggybacking as above.
In order for such a message to be recognized by its intended recipient, the message should also carry the UID of the intended recipient (plus a local name by which the recipient knows the sender), which.
Note that many executions of these SynchBFS "subroutines" can go on in parallel.
In order to fit our formal model, in which at most one message can be sent on each link at each round, it may be necessary to combine many messages into one.
For a directed graph with unidirectional communication on some edges, in addition to outputt ing parent and child pointers, it may also be useful to have processes output  information about the shortest routes from children to their parents.
Even if some of the pairs of neighbors have unidirectional communication, the time to compute the tree plus child pointers is still only O (diam), because the extra BFS executions can all go on in parallel.
So the total number of communication bits is at most O (IEl2b)
How can the source process i0 tell when the construction of the tree has been completed? If each search message is answered with either a parent or non-parent message, then after any process has received responses for all of its search messages, it knows who all its children in the BFS tree are and knows.
So, starting from the leaves of the BFS tree, notification of completion can be "fanned in" to the source: each process can send notification of completion to its parent in the tree as soon as (a) it has received responses for all its search messages (so that it knows who its children are and knows that they have been marked), and (b) it has received notification of completion from all its children.
If unidirectional communication is allowed, then the total time, including notification of completion, is O (diam2)
The reason the behavior is quadratic is that the notification / \
Breadth-first search is one of the most basic building blocks for distributed algorithms.
We give some examples here of how the SynchBFS algorithm can be used or augmented to help in performing other tasks.
As we mentioned earlier, a message broadcast can be implemented along with the establishment of a BFS tree.
Another idea is first to produce a BFS tree with child pointers, as described above, and then to use the tree to conduct the broadcast.
The message need only be propagated along edges from parents to their children.
This allows the work of constructing the BFS tree to be reused, because many messages can be sent on the same tree.
Once the BFS tree has been constructed, the additional time to broadcast a single message is only O (diam), and the number of messages is only O (n)
Another application of BFS trees is the collection of information from throughout the network or, more generally, the computation of a function based on distributed inputs.
For example, consider the problem in which each process has a nonnegative integer input value and we want to find the sum of all the inputs in the network.
Using a B FS tree, this can be done easily (and emciently) as follows.
Starting from the leaves, "fan in" the results in a convergecast procedure, as follows.
Each leaf sends its value to its parent; each parent waits until it gets the values from all its children, adds them to its own input value, and then sends the sum to its own parent.
The sum calculated by the root of the BFS tree is the final answer.
Assuming that  the BFS tree has already been constructed, and assuming bidirectional communication on all tree edges, this scheme requires O (diam) t ime and O (n) messages.
The same scheme can be used to compute many other functions, for example, the maximum or minimum of the integer inputs.
What is required is that  the function be associative and commutative.
Using SynchBFS, an algorithm can be designed to elect a leader in a network with UIDs, even when the processes have no knowledge of n or diam.
Namely, all the processes can initiate breadth-first searches in parallel.
Each process i uses the tree thereby constructed and the global computat ion procedure just described to determine the maximum UID of any process in the network.
The process with the maximum UID then declares itself to be the leader, and all others announce that  they are not the leader.
If the graph is undirected, the time is O(diam) and the number of messages is O (diamlEI), again because at most IEI messages can be sent at each of the diam rounds.
The diameter of the network can be computed by having all processes initiate breadth-first searches in parallel.
Each process i uses the tree thereby constructed to determine max-disti, defined to be the maximum distance from i to any other process in the network.
Each process i then reuses its breadth-first tree for a global computat ion to discover the maximum of the max-dist values.
The diameter thus computed could be used, for example, in the leader-election algorithm FloodMax.
Again, we consider a strongly connected directed graph, with the possibility of unidirectional communication between some pairs of neighbors.
This time, however, we assume that each directed edge e = (i, j )  has an associated nonnegative real-valued weight, which we denote by weight(e) or weighti,j.
The weight of a path  is defined to be the sum of the weights on its edges.
The problem is to find a shortest path from a distinguished source node i0 in the digraph to each other node in the digraph, where a shortest path is defined to be a path with minimum weight.
A collection of shortest paths from i0 to all the other nodes in the digraph constitutes a subtree of the digraph, all of whose edges are oriented from parent to child.
The mixture of measures of weight and distance is unfortunate, but traditional.
As for breadth-first search, the motivation for constructing such a tree comes from the desire to have a convenient structure to use for broadcast communication.
The weights represent costs that may be associated with the traversal of edges, for instance, communication delay or a monetary charge.
A shortest paths tree minimizes the maximum worst-case cost of communicating with any process in the network.
We assume that  every process initially knows the weight of all its incident edges, or, more precisely, that the weight of an edge appears in special weight variables at both its endpoint processes.
We also assume that  each process knows the number n of nodes in the digraph.
We require that each process should determine its parent in a particular shortest paths tree, and also its distance (i.e., the total weight of its shortest path) from i0
If all edges are of equal weight, then a BFS tree is also a shortest paths tree.
Thus, in this case, a trivial modification of the simple SynchBFS tree construction can be made to produce the distance information as well as the parent pointers.
The case where weights can be unequal is more interesting.
One way to solve the problem is by the following algori thm--a version of the Bellman-Ford sequential shortest paths algorithm.
Bel lmanFord  a l g o r i t h m :
Each process i keeps track of dist, the shortest distance from i0 it knows so far, together with parent, the incoming neighbor that precedes i in a path whose weight is dist.
At each round, each process sends its dist to all its outgoing neighbors.
Then each process i updates its dist by a "relaxation step," in which it takes the minimum of its previous dist value and all the values distj + weightj,i, where j is an incoming neighbor.
If dist is changed, the parent component is also updated accordingly.
After n -  1 rounds, dist contains the shortest distance, and parent the parent in the shortest paths tree.
It is not hard to see that,  after n -  1 rounds, the dist values converge to the correct distances.
One way to argue the correctness of BellmanFord is to show (by induction on r) that the following is true after r rounds: Every process i has its dist and parent components corresponding to a shortest path among those paths from i0 to i consisting of at most r edges.
If there are no such paths, then dist = cc and parent is undefined.
You might suspect that by analogy with SynchBFS, the time complexity of BellmanFord is actually diam.
An example that indicates why this is not the case is shown in Figure 4.1
The BellmanFord algorithm also works using an upper bound on n in place of n itself.
If no such bound is known, it is possible to use techniques such as those described in Section 4.2 to discover one.
The next problem we consider is that of finding a minimum, or minimum-weight, spanning tree (MST) in an undirected graph network with weighted edges.
Again, the main use for such a tree is as a basis for broadcast communication.
A minimum-weight spanning tree minimizes the total cost for any source process to communicate with all the other processes in the network.
A spanning forest of an undirected graph G - (V, E) is a forest (i.e., a graph that is acyclic but not necessarily connected) that consists entirely of undirected edges in E and that contains every vertex of G.
A spanning tree of an undirected graph G is a spanning forest of G that is connected.
If there are weights associated with the undirected edges in E, then the weight of any subgraph of G (such as a spanning tree or spanning forest of G) is defined to be the sum of the weights of its edges.
Recall that we formalize the underlying undirected graph within our directed graph model as a directed graph having bidirectional edges between all pairs of neighbors.
As in Section 4.3, we assume that each directed edge e = (i, j )  has an associated nonnegative real-valued weight, weight(e) - weighti,j, only this time, we assume that for all i and j,  weighti,j - weightj, i.
We assume that every process initially knows the weight of all its incident edges, or, more precisely, that the weight of an edge appears in weight variables at both its endpoint processes.
We assume that the processes have UIDs and know n.
The problem is to find a minimum-weight (undirected) spanning tree for the entire network; specifically, each process is required to decide which of its incident edges are and which are not part of the minimum spanning tree.
All known MST algorithms, sequential as well as concurrent, are based on the same simple theory, which we describe in this subsection.
The basic strategy for constructing a minimum spanning tree involves starting with the trivial spanning forest consisting of n single nodes and repeatedly merging components along connecting edges until a spanning tree is produced.
In order to end up with a minimum spanning tree, it is important  that the merging occur only along certain selected edges--namely,  those that are minimum-weight outgoing edges of some component.
Justification for this method of selection is provided by the following lemma.
Then there is a spanning tree for G that includes Uj F_~j and e, and this tree is of min imum weight among all the spanning trees for G that include Uj Ej.
Suppose the claim is fa lse-- that  is, that there exists a spanning tree T that contains Uj Ej, does not contain e, and is of strictly smaller weight than any other spanning tree that contains Uj Ej and e.
Now consider the graph T ~ obtained by adding e to T.
By the choice of e, we know that weight(e') > weight(e)
Lemma 4.3 provides the justification for the following general strategy for constructing an MST.
General strategy for MST: Start with the trivial spanning forest that consists of n individual nodes and no edges.
Then repeatedly do the following: Select an arbitrary component C in the forest and an arbitrary outgoing edge e of C having minimum weight among the outgoing edges of C.
Combine C with the component at the other end of e, including edge e in the new combined component.
Lemma 4.3 can be used in an inductive proof to show that, at any stage in the construction, the forest is a subgraph of an MST.
Several well-known sequential MST algorithms are special cases of this general strategy.
For example, the Prim-Dijkstra algorithm begins by distinguishing one of the initial single-node components and repeatedly adds the minimum-weight outgoing edge from the current component, each time attaching a single new node until a complete spanning tree is obtained.
For another example, the Kruskal algorithm repeatedly adds the minimum-weight edge among all the edges that join two separate components in the current spanning forest, thus combining components until there is only one component, which is the final spanning tree.
In order to use this general strategy in a distributed setting, it would be nice to be able to extend the forest with several edges determined concurrently.
That is, each of several components could determine its minimum-weight outgoing edge independently, and then all of the determined edges could be added to the forest, thereby causing several combinations of components to occur all at once.
But Lemma 4.3 does not guarantee the correctness of this parallel strategy.
The three edges with weight 1 are the only outgoing edges.
If the components choose their minimum-weight outgoing edges as depicted by the arrows, a cycle would be created.
The cycle problem is avoidable, however, in the special case where all the edges have distinct weights.
The proof is similar to the proof of Lemma 4.3
Suppose that there are two distinct minimum-weight spanning trees, T and T ~, and let e be the minimum-weight edge that appears in only one of the two trees.
Now reconsider the general strategy for the case where the graph has distinct edge weights, and so, by Lemma 4.4, there is a unique MST.
In this case, at any stage of the construction, any component in the forest has exactly one minimum-weight outgoing edge (which we abbreviate, unpronounceably, as MWOE)
Lemma 4.3 implies that if we begin the stage with a forest, all of whose edges are in the unique MST, then all of the MWOEs, for all components, are also in the unique MST.
So we can add them all at once, without any danger of creating a cycle.
We present a distributed algorithm for constructing an MST in an arbitrary weighted undirected graph, following the general strategy described in the previous subsection.
Since components will be allowed to combine concurrently, we assume that edge weights are all distinct; near the end of this subsection, we will say how this assumption can be removed.
We call the algorithm SynchGHS because it is based on an asynchronous algorithm developed by Gallager, Humblet, and Spira.
We will present the asynchronous algorithm, called simply GHS, in Section 15.5
SynchGHS algorithm: The algorithm builds the components in "levels." For each k, the level k components constitute a spanning forest, where each level k component consists of a tree that is a subgraph of the MST.
Each level k component has at least 2 k nodes.
Every component, at every level, has a distinguished leader node.
The processes allow a fixed number of rounds, which is O (n), to complete each level.
The algorithm starts with level 0 components consisting of individual nodes and no edges.
Suppose inductively that the level k components have been determined (along with their leaders)
More specifically, suppose that each process knows the UID of the leader of its component; this UID is used as an identifier for the entire component.
Each process also knows which of its incident edges are in the component 's tree.
When all level k components have found their MWOEs, the components are combined along all these MWOEs to form the level k + 1 components.
This involves the leader of each level k component communicating with the component process adjacent to the MWOE, to tell it to mark the edge as being in the new tree; the process at the other end of the edge is also told to do the same thing.
Then a new leader is chosen for each level k + 1 component, as follows.
It can be shown that for each group of level k components that get combined into a single level k + 1 component, there is a unique edge e that is the common MWOE of two of the level k components in the group.
We let the new leader be the endpoint of e having the larger UID.
Note that this new leader can identify itself using only information available locally.
Finally, the UID of the new leader is propagated throughout the new component, using a broadcast.
Eventually, after some number of levels, the spanning forest consists of only a single component containing all the nodes in the network.
Then a new at tempt to find a MWOE will fail, because no process will find an outgoing edge.
When the leader learns this, it broadcasts a message saying that the algorithm is completed.
A key to the algorithm is the fact that, among each group of level k components that get combined, there is a unique (undirected) edge that is the common MWOE of both endpoint components.
A digraph is weakly connected if its undirected version, obtained by ignoring the directions of all the edges, is connected.
Lemma 4.5 Let G be a weakly connected digraph in which each node has exactly one outgoing edge.
Figure 4.3 shows an example of a graph in which each node has exactly one outgoing edge.
Because of the way G ~ was constructed, successive edges.
But this corresponds to an edge that is the common MWOE of both adjacent components.
Note first that the number of nodes in each level k component is at least 2 k.
This can be shown by induction, using the fact that at each level, each component is combined with at least one other component at the same level.
Therefore, the number of levels is at most log n.
Since each level takes time O (n), it follows that the time complexity of SynchGHS is O (n log n)
Each process marks its incident edges as "rejected" when they are found to lead to a node in the same component; thereafter, there is no need to test them again.
Also, at each level, the remaining candidate edges are tested one at a time, in order of increasing weight, just until the first one is found that leads outside the component (or until the candidate edges are exhausted)
With this improvement, the number of messages sent over tree edges is, as before, O (n log n)
We carry out an amortized analysis of the number of messages used for finding local minimum-weight edges.
Each edge gets tested and rejected at most once, for a total of O (IEI)
An edge that is tested and is found to be the local minimum-weight edge, but not the MWOE for the entire.
However, there is at most one such exploration originating at each node at each level, adding up to a total of O (n log n)
The total communication complexity is thus O (n log n + IEI)
Since each node marks both its incident edges that are in the MST and those that are not in the tree, there is no need for the final phase in which the leader notifies everyone that the algorithm is completed.
Each node can simply output the information about its adjacent edges as it is discovered.
Given arbitrary edge weights, we can derive a set of distinct edge identifiers using the UIDs.
Thus, (i, j)  and (j, i) have the same edge identifier.
A total ordering is defined among the edge identifiers, based on lexicographic order among the triples.
Since SynchGHS manipulates the weights using comparisons only, we can run it using the edge identifiers in place of the (real-valued) weights; the resulting execution will be the same as if SynchGHS were running with a set of unique weights satisfying the same ordering relationships.
We leave as an exercise the task of showing that this tree is in fact an MST for the original graph.
Once an MST (or any spanning tree) is known for a network based on an undirected graph, it is easy to elect a unique leader, provided UIDs are available.
Namely, the leaves of the spanning tree begin a convergecast along the paths of the tree; each internal node waits to hear from all but one of its neighbors before sending a message to its remaining neighbor.
If a node hears from all its neighbors without having itself sent out a message, it declares itself the leader.
Also, if two neighboring nodes get messages from each other at the same round, then one of them, say, the one with the larger UID, declares itself the leader.
The total additional complexity of this leader-election procedure (after the MST is constructed)is  just O (n) time and O (n) messages.
The final problem we consider in this chapter is that of finding a maximal independent set (MIS) of the nodes of an undirected graph.
A set of nodes is called an independent set if it contains no pair of neighboring nodes, and an independent set is said to be maximal if it cannot be increased to form a larger independent set by the addition of any other nodes.
Note that an undirected graph can have many different maximal independent sets.
We do not require the largest possible maximal independent se t - -any  will do.
The MIS problem can be motivated by problems of allocating shared resources to processes in a network.
The neighbors in the graph G might represent processes than cannot simultaneously perform some activity involving shared resources (for example, database access or radio broadcast)
We might wish to select a set of processes that could be allowed to act simultaneously; in order to avoid conflict, these processes should comprise an independent set in G.
Furthermore, for performance reasons, it is undesirable to block a process if none of its neighbors is active; thus, the chosen set of processes should be maximal.
An independent set I is maximal if any set I ~ that strictly contains I is not independent.
The goal is to compute a maximal independent set of G.
More specifically, each process whose index is in I should eventually output winner, that is, should set a special status component of its state to the value winner, and each process whose index is not in I should output loser.
We assume that n, the number of nodes, is known to all the processes.
It is not hard to show that in some graphs, the MIS problem cannot be solved if the processes are required to be deterministic.
The argument is similar to the one in the proof of Theorem 3.1
In this section, we present a simple solution that uses randomization to overcome this inherent limitation of deterministic systems.
To be precise, we note that the randomized algorithm actually solves a weaker problem than the one that is stated above, in that it will have a (probability zero) possibility of never terminating.
LubyMIS is based on the following iterative scheme, in which an arbitrary nonempty independent set is selected from the given graph G, the nodes in this set and all of their neighbors are removed from the graph, and the process is repeated.
If W is a subset of the nodes of a graph, then we use nbrs(W) to denote the set of neighbors of nodes in W.
Let graph be a record with fields nodes, edges, and nbrs, initialized to.
It is not hard to see that this scheme always produces a maximal independent set.
To see why it is independent, note that at each stage, the selected set I ~ is independent, and we explicitly discard from the remaining graph all neighbors of vertices that are put into I.
To see why it is maximal, note that the only nodes that are removed from consideration are neighbors of nodes that are put into I.
In this implementation it is possible, if the random choices are unlucky, that the set I ~ might be empty at some stages; those stages will be "useless," accomplishing nothing.
Provided the algorithm does not reach a point after which it keeps performing useless stages forever, we can simply ignore the useless stages and assert that LubyMIS correctly follows the general scheme.
We will, how3The induced subgraph of a graph G on a subset W of its nodes is defined to be the subgraph (W, E ' ) ,  where E '  is the set of edges of G that  connect nodes in W.
LubyMIS algorithm (informal): The algorithm works in stages, each consisting of three rounds.
Round 1: In the first round of a stage, the processes choose their respective vals and send them to their neighbors.
By the end of round 1, when all the val messages have been received, the winners-- that  is, the processes in F - -know who they are.
Round 2: In the second round, the winners notify their neighbors.
By the end of round 2, the losers--that is, the processes having neighbors in F - -know who they are.
Round 3: In the third round, each loser notifies its neighbors.
Then all the involved processes--the winners, the losers, and the losers' neighbors-remove the appropriate nodes and edges from the graph.
More precisely, this means the winners and losers discontinue participation after this stage, and the losers' neighbors remove all the edges that are incident on the newly removed nodes.
Note that LubyMIS still works correctly if, at some stages, some neighboring processes choose the same random values.
We have already argued that, provided that LubyMIS does not stall, executing useless stages forever, it will produce an MIS.
Now we claim that with probability one, the algorithm in fact does not stall.
More specifically, we claim that at any stage of the algorithm, the expected number of edges removed from the remaining graph is at least a constant fraction of the total number of remaining edges; this implies that there is a constant probability that at least a constant fraction of the edges is removed.
In turn, this implies that the expected number of rounds until termination is O (log n)
It also implies that, with probability one, the algorithm does in fact terminate.
The complete analysis of LubyMIS can be found in Luby's original paper; it involves substantial counting arguments about graphs.
We just state the main technical lemma without proof, and indicate how it is used to obtain the needed results.
For the next three lemmas, fix G = (V, E) and, for an arbitrary node i E V, define.
Using Lemma 4.6, we obtain the bound on the expected number of edges removed from the graph:
The algorithm ensures that every edge with at least one endpoint in nbrs(I') is removed.
It follows that the expected number of edges removed is at least.
This is because each vertex i has the indicated probability of having a neighbor in I'; if this is the case, then i is removed, which causes the deletion of all of.
The factor of overcounting of removed edges, since each edge has two endpoints that could cause its deletion.
We next plug in the bound from Lemma 4.6, concluding that the expected number of removed edges is at least.
Breaking this up according to which term of the min is less, this is equal to.
Now we expand the definition of sum(i) and also write d(i) as a trivial sum, obtaining.
Note that each undirected edge (i, j)  contributes two summation terms to the expression in parentheses, one for each direction; in each case, the sum of these two terms is greater than 1 So the total is at least IE [--]
The technique of randomization is used frequently in distributed algorithms.
For example, the leader-election and MIS problems cannot be solved in general graphs by deterministic processes without UIDs because of the impossibility of breaking symmetry.
Even when there are UIDs, randomization may allow symmetry to be broken faster.
One problem with randomized algorithms, however, is that their guarantees of correctness and/or performance might only hold with high probability, not with certainty.
In designing such algorithms, it is important to make sure that the crucial properties of the algorithm are guaranteed with certainty, not probabilistically.
For example, any execution of LubyMIS is guaranteed to produce an independent set, regardless of the outcomes of the random choices.
The performance, however, depends on the luckiness of the random choices.
There is even a (probability zero) possibility that all processes will repeatedly choose the same value, thereby stalling progress forever.
Whether or not these are serious drawbacks to the algorithm depends on the application for which it is used.
Afek and Gafni [6] have developed complexity bounds for leader election in complete synchronous networks.
The SynchBFS algorithm is based on the standard sequential breadth-first search algorithm appearing, for example, in [83]
The SynchGHS algorithm is a synchronized (and therefore considerably simplified) version of the well-known asynchronous MST algorithm developed by Gallager, Humblet, and Spira.
The LubyMIS algorithm and its analysis appear in a paper by Luby [200]
An example of a (probability zero) execution of a randomized algorithm in which the processes keep making the same choice appears in [271]
Fill in more details in the correctness proof for the FloodMax algorithm.
Consider the "further optimized" version of OptFloodMax described at the end of Section 4.1.3, which prevents processes from resending max-uid information to processes from which they have previously received the same information.
Do the same--parts  (a) and (b)--for the SynchBFS algorithm with child pointers.
Do the same--parts  (a) and (b)--for the SynchBFS algorithm with child pointers and notification of completion.
Consider the optimized version of SynchBFS described in Section 4.2.2, which prevents processes from sending search messages to processes from which they have previously received such messages.
Describe in detail an algorithm that extends SynchBFS to produce not only child pointers, but also information about shortest routes from children in the BFS tree to their parents.
This information should be distributed along those paths so that each process on a path knows the next process along the path.
Describe in detail an algorithm that extends SynchBFS to allow the source process i0 to broadcast a message to all other processes and obtain an acknowledgment that all processes have received it.
Your algorithm should use O (IEI) messages and O(diam) time.
Analyze the time and communication complexity of the global computation scheme, the leader-election scheme and the diameter computation scheme at the end of Section 4.2, assuming that communication is allowed to be unidirectional between some pairs of neighbors.
Devise the most efficient leader-election algorithm you can, for a strongly connected directed network in which the processes have UIDs but do not have any knowledge of the number of nodes in or diameter of the network.
Develop the most efficient algorithm you can for finding the total number of nodes in a strongly connected directed network in which the processes have UIDs.
Develop the most efficient algorithm you can for finding the total number of edges in a strongly connected directed network in which the processes have UIDs.
Develop the most efficient algorithm you can, for an arbitrary undirected graph network, to determine a minimum-height rooted spanning tree.
You may assume the processes have UIDs, but there is no distinguished leader node.
In the SynchGHS algorithm, show that it is not the case that O (diam) rounds are always sufficient to complete each level of the computation.
Show that the version of SynchGHS that uses edge identifiers in place of edge weights (described near the end of Section 4.4) in fact produces an MST.
Research Question: Come up with a better synchronous minimum spanning tree algorithm than SynchGHS--better in terms of the time complexity, the communication complexity, or both.
Give code for the convergecast algorithm outlined at the end of Section 4.4, which elects a leader given an arbitrary spanning tree of an undirected graph network.
Give the best upper and lower bounds you can for the problem of establishing an arbitrary spanning tree in an undirected graph network.
State carefully what assumptions you use about the processes' knowledge of the graph.
Assume that each process i can distinguish its left from its right and knows whether or not it is an endpoint.
Assume that each process i initially has a very large integer value vi and that it can hold in memory only a constant number of such values at any.
Design an algorithm to sort the values among the processes, that is, to cause each process i to return one output  value oi, where the multiset of outputs is equal to the multiset of inputs and ol _<
Try to design the most efficient algorithm you can both in terms of the number of messages and the number of rounds.
Prove that, under the assumptions given in Section 4.5, but assuming that the processes are deterministic rather than probabilistic, there are some graphs in which it is impossible to solve the MIS problem.
Find the largest class of graphs you can for which your impossibility result holds.
Suppose that LubyMIS is executed in a ring of size n.
Estimate the probability that any particular edge is removed from the graph in one iteration of the algorithm.
In this and the next two chapters, we study problems of reaching consensus in a distr ibuted network.
In such problems, each of the processes in the network begins with an initial value of a particular type and is supposed to eventually output  a value of that same type.
The outputs are required to be the s a m e the processes must agree--even though the inputs can be arbitrary.
There is generally a validity condition describing the output  values that are permit ted for each pat tern of inputs.
When there are no failures of system components, consensus problems are usually easy to solve, using a simple exchange of messages.
To make matters more interesting, the problems are usually considered in settings that include failures.
In this chapter, we consider basic consensus problems in the presence of communication failures, while in Chapter  6, we consider process failures.
Chapter  7 contains some variations on the basic problems, also in the presence of process failures.
For example, processes may at tempt  to reach agreement on whether to commit or abort  the results of a distr ibuted database transaction.
Or processes may try to agree on an estimate of an airplane's altitude based on the readings of multiple altimeters.
Or they may a t tempt  to agree on whether to classify a system component as faulty, given the results of separate diagnostic tests performed by separate processes.
The part icular consensus problem that we present in this chapter is called the coordinated attack problem; it is a fundamental problem of reaching consensus in a setting where messages may be lost.
We show that the problem can be solved by a randomized algorithm, with a certain (substantial) probability of error.
Moreover, that probability of error turns out to be unavoidable.
We begin with an informal (in fact, ambiguous) problem statement, in terms of a battlefield scenario.
Several generals are planning a coordinated attack from different directions, against a common objective.
They know that the only way the attack can succeed is if all the generals attack; if only some of the generals attack, their armies will be destroyed.
Each general has an initial opinion about whether his army is ready to attack.
Nearby generals can communicate, but only via messengers that travel on foot.
However, messengers can be lost or captured, and their messages may thus be lost.
Using only this unreliable means of communication, the generals must manage to agree on whether or not to attack.
We suppose that the "communication graph" of generals is undirected and connected, and that all of the generals know the graph.
We also assume that there is a known upper bound on the time it takes for a successful messenger to deliver a message.
If all the messengers are reliable, then all the generals can send messengers to all the other generals (possibly in several hops), saying whether or not they are willing to attack.
After a number of "rounds" equal to the diameter of the "communication graph," all the generals will have all of this information.
Then they can all apply a commonly agreed-upon rule to make the same decision about attacking: for example, they can decide to attack exactly if all the generals want to do so.
In a model in which messengers may be lost, this easy algorithm does not work.
It turns out that this is not just  a problem with this algorithm: we show that there is no algorithm that always solves this problem correctly.
The real computer science problem behind this description is the commit problem for distributed databases.
This problem involves a collection of processes that have participated in the processing of a database transaction.
A process will generally favor committing the transaction if all its local computation on behalf of that transaction has been successfully completed, and will favor aborting the transaction otherwise.
The processes are supposed to communicate and eventually to agree on one of the outcomes, commit or abort.
A g r e e m e n t :  No two processes decide on different values.
The validity requirement is just one possibil i ty--there are several useful alternatives.
The weak formulation is appropriate because our main focus in this chapter is on impossibility results.
It turns out that even this weak version of the problem is impossible to solve in any graph with two or more nodes.
We prove the impossibility result for the special case of two nodes connected.
We leave it as an exercise for you to show that impossibility for this case implies impossibility for any graph with two or more nodes.
Then there is no algorithm that solves the coordinated attack problem on  G.
Also without loss of generality, we may assume that both processes send.
Now let Ctl be the same as c~, except that all.
The edges represent messages that are delivered; messages sent but not delivered are simply not drawn.
Starting from c~1, we now construct a series of executions, each of them indistinguishable from its predecessor in the series with respect to one of the.
By the same reasoning as above, both processes are forced to decide 1 in this case.
Theorem 5.1 describes a fundamental limitation on the capabilities of dist r ibuted networks.
It suggests that there is little that can be done to solve basic consensus problems such as the distr ibuted database commit problem in the face of unreliable communication.
However, some versions of this problem must be solved in real systems.
In order to cope with the limitation of Theorem 5.1, it is necessary to strengthen the model or relax the problem requirements.
One approach is to make some probabilistic assumptions about the loss of messages, while keeping the processes deterministic.
Then we must allow for some possibility of violating the agreement and /or  validity condition.
We leave the development of an algorithm for this setting for an exercise.
A second approach is to allow the processes to use randomization, again allowing some.
In this section, we consider the coordinated attack problem in the setting where.
The goal is essentially the same as before, except that now we weaken the problem statement to allow for some probability of error.
Namely, we use the same validity condition as before, but weaken the agreement condition to allow a small probability e of disagreement.
As you will see, the achievable values of e are not small.
In formalizing this problem, we must be clear about the meaning of the probabilistic s ta tements- - the  situation is more complicated than it was for the MIS problem in Section 4.5
The complication is that the execution that is produced depends not only on the results of the random choices, but also on which messages are lost.
We do not want to assume that message losses are determined randomly.
Rather, we imagine that they are determined by some "adversary" that tries to make things as dimcult as possible for the algorithm; we evaluate the algorithm by considering its worst-case behavior over the class of all possible adversaries.
Formally, we define a communication pattern to be any subset of the set.
A good communication pattern represents the set of messages that are delivered in some execution: if (i, j, k) is in the communication pattern, then it means that a message sent by i to j at round k succeeds in getting delivered.
The notion of adversary that we use here is an arbitrary choice of.
For any particular adversary, any particular set of random choices made by the processes determines a unique execution.
Thus, for any particular adversary, the random choices made by the processes induce a probability distribution on the set of executions.
Using this probability distribution, we can express the probability of events such as the processes all agreeing.
To emphasize the role of the adversary, we use the notation Pr  B for the probability function induced by a given adversary B.
We now restate the coordinated attack problem in this probabilistic setting.
We do not require a termination condition, because we have already assumed that all processes decide within r rounds.
Our goals are to find an algori thm with the smallest possible value of c and to prove that no smaller value of e can be achieved.
For simplicity, we restrict attention in this and the following subsection to the special case of an n-node complete graph.
We leave the extensions to arbi t rary graphs as exercises.
For this special case, we present a simple algori thm that achieves e -  !
The algorithm is based on what processes know about each other's initial values and on what they know about each other's knowledge of the initial values, and so on.
We need some definitions to capture such notions of knowledge.
Recall from Chapter  2 that "time k" refers to the point in the execution just  after k rounds have occurred.
This ordering represents information flow between the various processes at various times.
The first case describes information flow at the same process.
The second case describes information flow from the sender to the receiver of a message.
The following lemma says that the information levels of different processes always remain within 1 of each other.
The  following l emma says that ,  in the case where all messages  are delivered, the informat ion level is equal  to the number  of rounds.
The  idea of the a lgor i thm,  which we call RandomAttack, is as follows:
Each  process  i keeps explicit  t rack  of its level, with respect  to the communica t ion  pa t t e rn  that  occurs in the execution,  in a variable level.
In addi t ion,  the initial values of all processes  are p iggybacked  on all messages.
The message a lphabe t  consists  of t r iples  of the form (L, V, k), where L is a vector  assigning an integer in [0, r] to each process  index, V is a vector.
The  variable level(j) is used to keep t rack  of the largest  level for process j that  is known ( through a chain of messages)  to process  i.
In the r andom  funct ion randi, we use random to indicate a r andom choice of an integer in [1, r], using the uniform dis t r ibut ion.
In this code, the third line sets the key component; it does not matter if it is set more than once, since all values of key that get passed around are the same.
The fifth line sets the val components for processes j -~ i, again with no danger of conflicting assignments.
The sixth line updates the level components for processes j =/: i; these are intended to contain the largest levels that i knows about, for all the other processes.
Next, i updates its own level component, setting it to be one more than the smallest level it knows about for any of the other processes.
Finally, if this is the last round r, then i decides according to the rule described earlier.
The key to the proof is just the claim that the algorithm correctly calculates the levels.
Now suppose that all processes start with 1 and all messages are delivered.
Then Lemma 5.3 and the fact that the algorithm correctly calculates the levels imply that for each i, level(i)i - r  at the point in round r where the decision is made.
Since all possible key values are less than or equal to r, 1 is the only possible decision value.
Example 5.2.2 Behavior of R a n d o m A t t a c k.
Consider the adversary B that  supplies input  1 for both processes, together with the good.
Using the ideas in the proof of Theorem 5.4, we can see that  RandomAttack satisfies s tronger validity conditions than we have so far claimed.
The second of these properties might be useful in some applications, such as warfare or dis tr ibuted database commit,  where it is considered desirable to favor the positive outcome.
If, for example, only a single message is lost, then the probabili ty of coordinated attack is guaranteed to be high, at least r -1
Now we show that it is not possible to do much better than the bound described in Theorem 5.4
Recall from the previous subsection that we are only considering n-node complete graphs.
In order to prove the theorem, we need one more definition.
If B is any adversary, 7 its communication pattern,  and i any process, then we define another adversary, prune(B, i)
Adversary prune(B, i) simply "prunes out" information that i does not hear about in B.
A triple (j, j ' ,  k) is in the communication pat tern of B'  exactly if it is in the communication pat tern of B and (j', k) _<~ (i, r)
The following lemma says that the pruned version of an adversary is sufficient to determine the probability distr ibution of outputs.
The proof of Theorem 5.5 is based on the following lemma.
But since there is at most probability e of disagreement, we have that.
But since there is at most probability e of disagreement, we have that.
Let B be the adversary for which all inputs are 1 and no messages are lost.
The coordinated attack problem was originated by Gray [142] in order to model the problem of distributed database commit.
The impossibility result for the deterministic version of the problem is also due to Gray [142]
The results on randomized coordinated attack are derived from work of Varghese and Lynch [281]
Show that a solution to the (deterministic) coordinated attack problem for any nontrivial connected graph implies a solution for the simple graph consisting of two processes connected by one edge.
Consider the following variant of the (deterministic) coordinated attack problem.
The termination and validity requirements are the same as those in Section 5.1
Consider the coordinated attack problem with link failures for the simple case of two processes connected by an edge.
As usual, we allow each process to send only one message per round.
For this setting, devise an algorithm that terminates in a fixed number r of rounds, has probability at most e of disagreement, and likewise has probability at most ~ of violating the validity condition.
For the setting described in the previous exercise, prove a lower bound on the size of the bound e that can be obtained.
RandomAttack algorithm correctly computes the level values, and correctly conveys the initial values and key.
For the RandomAttack algorithm, prove the stronger validity properties given at the end of Section 5.2.2
Generalize the randomized version of the coordinated attack problem to allow for probability c of violating the validity condition as welt as of violating the agreement condition.
Adjust the RandomAttack algorithm so that it achieves the smallest possible e for this modified problem statement.
Extend the RandomAttack algorithm and its analysis to arbitrary (not necessarily complete) undirected graphs.
Extend the lower bound result in Theorem 5.5 to arbitrary (not necessarily complete) undirected graphs.
What happens to the results of this chapter for the randomized setting, if the communication pattern determined by the adversary is not fixed in advance as we have assumed, but is determined on-line? More precisely, suppose that the adversary is an entity that is able to examine the entire execution up to the beginning of any round k, before deciding which round k messages will be delivered.
This time, we consider the case where processes, but not links, may fail.
Of course, it is more sensible to talk about failure of physical "processors" than of logical "processes," but to stay consistent with the terminology elsewhere in the book, we use the term process.
We investigate two failure models: the stopping failure model, where processes may simply stop without warning, and the Byzantine failure model, where faulty processes may exhibit completely unconstrained behavior.
Byzantine failures are intended to model any arbitrary type of processor malfunction, including, for example, failures of individual components within the processors.
The term Byzantine was first used for this type of failure in a landmark paper by Lamport, Pease, and Shostak, in which a consensus problem is formulated in terms of Byzantine generals.
As in the coordinated attack problem of Chapter 5, the Byzantine generals attempt to agree on whether or not to carry out an attack.
This time, however, the generals must worry not about lost messengers, but about the possible traitorous behavior of some generals.
The term Byzantine is intended as a pun-- the  battle scenario takes place in ancient Byzantium, and the behavior of some of the traitorous generals can only be described as "Byzantine."
In the particular consensus problem we consider in this chapter, which we call simply the agreement problem, the processes start with individual inputs from a particular value set V.
All the nonfaulty processes are required to produce outputs from the same value set V, subject to simple agreement and validity.
For validity, we assume that if all processes begin with the same value v, the only allowed decision value is v.
The agreement problem is a simplified version of a problem that originally arose in the development of on-board aircraft control systems.
In this problem, a collection of processors, each with access to a separate altimeter, and some of which may be faulty, at tempt to agree on the airplane's altitude.
Byzantine agreement algorithms have also been incorporated into the hardware of faulttolerant multiprocessor systems; there, they are used to help a small collection of processors to carry out identical computations, agreeing on the results of every step.
This redundancy allows the processors to tolerate the (Byzantine) failure of one processor.
Byzantine agreement algorithms are also useful in processor fault diagnosis, where they can permit a collection of processors to agree on which of their number have failed (and should therefore be replaced or ignored)
In both of our failure models, we will need to assume limitations on the frequency of occurrence of process(or) failures.
How should such limitations be expressed? In other work on analysis of systems with processor failures, these limitations often take the form of probability distributions governing the occurrences of failures.
Here, instead of using probabilities, we simply assume that the number of failures is bounded in advance, by a fixed number f.
This is a simple assumption to work with, since it avoids the complexities of reasoning about probabilistic failure occurrences.
In practice, this assumption may be realistic in the sense that it may be unlikely that more than f failures will occur.
However, we should keep in mind that the assumption is somewhat problematic: in most practical situations, if the number of failures is already large, then it is likely that more failures will occur.
Assuming a bound on the number of failures implies that failures are negatively correlated, whereas in practice, failures are usually independent or positively correlated.
After defining the agreement problem, for both stopping and Byzantine failures, we present a series of algorithms.
We then prove lower bounds on the number of processes needed to solve the problem for Byzantine failures, and on the number of rounds needed to solve the problem for either type of failure.
Each process starts with an input from a fixed value set V in a designated state component; we assume that, for each process, there is exactly one start state containing each input value.
The goal is for the processes to eventually output decisions from the set V, by setting special decision state components to values in V.
In this chapter, we assume that the links are perfectly reliable--all the messages that are sent are delivered.
We consider two kinds of process failures: stopping failures and Byzantine failures.
In the stopping failure model, at any point during the execution of the algorithm, a process might simply stop taking steps altogether.
In particular, a process might stop in the middle of a message-sending step; that is, at the round in which the process stops, only a subset of the messages the process is supposed to send might actually be sent.
In this case, we assume that  any subset of the messages might be sent.
A process might also stop after sending its messages for some round but before performing its transition for that round.
For the stopping failure model, the correctness conditions for the agreement problem are.
Validity: If all processes start with the same initial value v E V, then v is the only possible decision value.
In the Byzantine failure model, a process might fail not just by stopping, but by exhibiting arbitrary behavior.
This means that it might start in an arbitrary state, not necessarily one of its start states; might send arbitrary messages, not necessarily those specified by its msgs function; and might perform arbitrary state transitions, not necessarily those specified by its trans function.
As a technical but convenient special case, we even allow for the possibility that a Byzantine process behaves completely correctly.
The only limitation on the behavior of a failed process is that it can only affect the system components over which it is supposed to have control, namely, its own outgoing messages and its own state.
It cannot, for example, corrupt the state of another process, or modify or replace another process's messages.
For the Byzantine failure model, the agreement and validity conditions are slightly different from those for the stopping failure model:
Val idi ty-  If all nonfaulty processes start with the same initial value v E V, then v is the only possible decision value for a nonfaulty process.
The modified conditions reflect the fact that in the Byzantine model, it is impossible to impose any limitations on what the faulty processes might start.
We refer to the agreement problem for the Byzantine failure model as the Byzantine agreement problem.
Relationship between the stopping and  B y z a n t i n e  a g r e e m e n t  p roblems.
It is not quite the case that an algorithm that solves the Byzantine agreement automatically solves the agreement problem for stopping failures; the difference is that in the stopping case, we require that all the processes that decide, even those that subsequently fail, must agree.
If the agreement condition for the stopping failure case is replaced by the one for the Byzantine failure case, then the implication does hold.
Alternatively, if all the nonfaulty processes in the Byzantine algorithm always decide at the same round, then the algorithm also works for stopping failures.
An alternative validity condition that is sometimes used for the stopping failure model is as follows.
Validity: Any decision value for any process is the initial value of some process.
It is easy to see that this condition implies the validity condition we have already stated.
In this chapter, we use the weaker condition we gave earlier; this slightly weakens our claims about algorithms and slightly strengthens our impossibility results.
For the algorithms in this chapter, we will indicate explicitly whether or not this stronger validity condition is satisfied.
For the time complexity, we count the number of rounds until all the nonfaulty processes decide.
For the communication complexity, we count both the number of messages and number of bits of communication; in the stopping case, we base these counts on the messages sent by all processes, but in the Byzantine case, we only base it on the messages sent by nonfaulty processes.
This is because there is no way to provide nontrivial bounds on the communication sent by faulty processes in the Byzantine model.
In this section, we present algorithms for agreement in the stopping failure model, for the special case of a complete n-node graph.
We begin with a basic algorithm in which each process just repeatedly broadcasts the set of all values it has ever seen.
Exponential information gathering algorithms, though costly and somewhat complicated, extend to less well-behaved fault models.
In this and the following section, we use v0 to denote a prespecified default value in the input set V.
We also use b to denote an upper bound on the number of bits needed to represent any single value in V.
The agreement problem for stopping failures has a very simple algorithm, called FloodSet.
Processes just propagate all the values in V that they have ever seen and use a simple decision rule at the end.
Each process maintains a variable W containing a subset of V.
Initially, process i's variable W contains only i's initial value.
For each of f + 1 rounds, each process broadcasts W, then adds all the elements of the received sets to W.
After f + 1 rounds, process i applies the following decision rule.
If W is a singleton set, then i decides on the unique element of W; otherwise, i decides on the default value v0
In arguing the correctness of FloodSet, we use the notation Wi(r) to denote the value of variable W at process i after r rounds.
The first easy lemma says that if there is ever a round at which no process.
Suppose that no process fails at round r and let I be the set of processes.
Then, because every process in I sends its own W set to all other processes, at the end of round.
We next claim that if all the active processes have the same W sets after some particular round r, then the same is true after subsequent rounds.
Lamina 6.1 implies that Wi(r) - Wj(r) for all i and j that are active after r rounds.
For agreement, let i and j be any two processes that decide.
The decision rule then implies that i and j make the same decision.
The FloodSet algorithm shows that the agreement problem is solvable for process stopping failures.
This positive result should be contrasted with the impossibility results for the coordinated attack problem in a setting with communication failures.
OptFloodSet a l g o r i t h m :
The processes operate as in FloodSet, except that each process i broadcasts at most two values altogether.
If there are two or more new values at this round, then any one of these may be selected for broadcast.
The number  of bits of communicat ion is O (n2b)
We prove the correctness of OptFloodSet by relating it to FloodSet using a simulation relation (a similar s t ra tegy was used in Section 4.1.3 to prove correcthess of OptFloodMax by relating it to FloodMax)
This requires first filling in the details in the description of OptFloodSet, including explicit rounds, decision, and W variables as in FloodSet.
We use the notat ion Wi(r) and OWl(r),  respectively, to denote the values of Wi after r rounds of FloodSet and OptFloodSet, respectively.
The key pruning proper ty  of OptFloodSet is cap tured  by the following lemma.
Moreover, the same two conclusions hold in case i does not fail in the first r rounds, and does not send a round r + 1 message to j ,  but just because OptFloodMax does not specify that any such message is supposed to be sent.
Now we run OptFloodSet and FloodSet side by side, with the same inputs and same failure pat tern.
Tha t  is, the same processes fail at the same rounds in.
Moreover, if process i sends only some of its round r messages.
We give invariant assertions relating the states of the two algorithms.
The interesting thing to show is that the same decision is made by any process i at round f + 1 in the two algorithms.
Theorem 6.10 OptFloodSet solves the agreement problem for stopping failures.
There are other ways to reduce the communication complexity of FloodSet.
For example, recall that if V has a total ordering, the decision rule can be modified to simply choose the minimum value in W.
Then it is possible to modify the FloodSet algorithm so that each node just remembers and relays the minimum value it has seen so far, rather than all values.
It can be proved correct by a simulation relating it to FloodSet (with the modified decision rule)
This algorithm satisfies the stronger validity condition of Section 6.1
In this section, we present algorithms for agreement with stopping failures based on a strategy known as exponential information gathering (EIG)
In exponential information gathering algorithms, processes send and relay initial values for several rounds, recording the values they receive along various communication paths in a data structure called an EIG tree.
At the end, they use a commonly agreed-upon decision rule based on the values recorded in their trees.
The main reason we present this strategy here is that the same EIG tree data structure can be used for solving Byzantine agreement, as we show in Section 6.3.2
The stopping failure case provides a simple introduction to the use of this data structure.
A second reason for presenting this strategy for stopping failures is that simple stopping failure EIG algorithms can easily be adapted to solve the agreement problem for a restricted form of the Byzantine failure model known as the authenticated Byzantine failure model.
The basic data structure used by EIG algorithms is a labelled EIG tree T - Tn,$, whose paths from the root represent chains of processes along which initial values are propagated; all chains represented consist of distinct processes.
Each node in T is labelled by a string of process indices as follows.
The root is labelled by the empty string A, and each node with label i l.
In the EIG algorithm for stopping failures, which we call EIGStop, the processes simply relay values on all possible paths.
Each process maintains a copy of the EIG tree T - Tn,f.
In the course of the computation, the processes decorate the nodes of their trees with values in V or null, decorating all those at level k at the end of round k.
The root of process i's tree gets decorated with i's input value.
Also in process i's tree, if the node labelled by the string i l.
On the other hand, if the node labelled by the string i l.
After f + 1 rounds, the processes use their individual decorated trees to decide on a value in V, based on a commonly agreed-upon decision rule (described below)
In this algorithm description and in some others later on, it is convenient to pretend that each process i is able to send messages to itself in addition to the.
These  messages  are technical ly  not  p e r m i t t e d  in the model,  bu t  there is no h a r m.
EIGStop algorithm: For every s t r ing  x tha t  occurs  as a label of a node of T,  each process  has.
Variable val (x ) i s  used to hold the value with which the process  decorates  the node labelled x.
If a message with  value v E V arr ives  at i f rom j ,  then i sets its val(j) to v.
If no message with a value in V arr ives at i f rom j ,  then i sets val(j) to null.
If x j  is a level k node label in T,  where  x is a s t r ing of process  indices and j is a single index, and a message saying tha t  val(x) - v E V arr ives  at i f rom j ,  then i sets val(xj) to v.
If x j  is a level k node label and no message  with  a value in V for val(x) arr ives  at i f rom j ,  then i sets val(xj)  to null.
At the end of f + 1 rounds,  process  i applies a decision rule.
If W is a s ingleton set, then i decides on the unique element  of W; otherwise,  i.
It should not  be hard  to see tha t  the t rees  get decora ted  with the values we.
Also, if process  i 's  node labelled by the s t r ing i l.
Moreover, if process i 's node labelled by the string i l.
To see that EIGStop works correctly, we first give two lemmas that relate the values in the various trees.
The first lemma describes the initialization and the relationships between vals at different processes at adjacent levels in the trees.
If  x j  is a node label and val(xj)i - v  E V, then val(x)j - v.
I f  y is a node label, val(y)i - v C V,  and x j  is a prefix of y, then val(x)j  = V.
I f  v E V appears in the set of vals at process i, then there is some label y that does not contain i such that v = val(y)i.
For part  3, suppose to the contrary that v only appears as the val for labels.
But then part  1 implies that val(x)i = v, which contradicts the choice of y.
The next lemma provides the key to the agreement property.
Then Lemma 6.12 implies that v = val(x)i  for some label x that does not contain i.
This implies that val(xi) j  = v, so v E Wj.
Then because there are at most f faulty processes and all indices in.
Therefore, x has a prefix of the form yl, where y is a string.
Since process l is nonfaulty, it relays v to process j at round lyll.
This implies that some nonfaulty process index, in this case 1, must appear in the node label.
For validity, suppose that all the initial values are equal to v.
For agreement, let i and j be any two processes that decide.
Since decisions only occur at the end, this means that i and j are nonfaulty.
The decision rule then implies that i and j make the same decision.
Since EIGStop guarantees that the same set W of values appears in the trees of nonfaulty processes, various other decision rules would also work correctly.
For instance, if the value set V has a total ordering, then all processes could simply choose the minimum value in W.
As before, this has the advantage that it guarantees the stronger validity condition mentioned in Section 6.1
It is possible to reduce the amount of communication in the EIGStop algor i thm in much the same way as we did for FloodSet.
So again, it is plausible that the processes might need to broadcast  only the first two values they learn about.
The processes operate as in EIGStop, except that each process i broadcasts at most two values altogether.
Then i broadcasts the new value v, together with the label of any level r -  1 node x that is decorated with v.
If there are two or more possible choices of (x, v), then any one of these may be selected for broadcast.
As in EIGStop, let W be the set of non-null vals that decorate nodes of i's tree.
If W is a singleton set, then i decides on the unique element of W;
The correctness of OptEIGStop can be proved by relating it to EIGStop.
The proof is similar to the proof of correctness of OptFloodSet.
Alternatively, a correctness proof that relates OptEIGStop to OptFloodSet can be given.
Although the EIG algorithms described in this section are designed to tolerate stopping failures only, it happens that they can also tolerate some worse types of failures.
They cannot cope with the full difficulty of the Byzantine fault model, where processes can exhibit arbi t rary behavior.
However, they can cope with an interesting restriction on the Byzantine fault model in which processes have the extra power to authenticate their communications, based on the use of digital signatures.
A digital signature for process i is a t ransformation that i can apply to any of its outgoing messages in order to prove that the message really did originate at i.
No other process is able to generate i's signature without i's cooperation.
Digital signatures are a reasonable capability to assume in modern.
We do not provide a formal definition of the Byzantine model with authentica t ion-- in  fact, we do not know of a nice formal defini t ion--but  just describe it informally.
In this model, it is assumed that processes can use digital signatures to authenticate any of their outgoing messages.
In the literature, it is usually assumed that the initial values originate from some common source, which also signs them; here, we assume that each nonfaulty process starts in an initial state containing a single input value signed by the source, while each faulty process.
Faulty processes are permitted to send arbitrary messages and perform arbitrary state transitions; the only limitation is that they are unable to generate signatures of nonfaulty processes or of the source.
The correctness conditions to be satisfied in this model are the usual termination and agreement conditions for Byzantine agreement, plus the following validity condition:
Va l id i ty :  If all processes start with exactly one initial value v E V, signed by the source, then v is the only possible decision value for a nonfaulty process.
It is not difficult to see that the EIGStop and OptEIGStop algorithms, modified so that all messages are signed and only correctly signed messages are accepted, solve the agreement problem for the authenticated Byzantine failure model.
The proofs are similar to those given for the stopping failure model and are left as exercises.
This situation is different from what we saw for the stopping failure case, where there were no special requirements on the relationship between n and f.
This process bound reflects the added difficulty of the Byzantine fault model.
In fact, we will see in Section 6.7 that this bound is inherent.
There is a standard fault-tolerance technique known as triple-modular redundancy, in which a task is triplicated and the majority result accepted; you might think that this method could be used to solve Byzantine agreement for one faulty process, but you will see that it cannot.
Before presenting the E I G  Byzantine agreement algorithm, we give an idea of why the Byzantine agreement problem is more difficult than the agreement problem for stopping failures.
Specifically, we give an example suggesting (though not proving) that three processes cannot solve Byzantine agreement, if there is the possibility that even one of them might be faulty.
Suppose, for example, that they decide at the end of two rounds and that they operate in a particular, constrained manner: at the first round, each process simply broadcasts its initial value, while in the second round, each process reports to each other process what was told to it in the first round by the third process.
In the first round, all processes report their values truthfully.
This example does not constitute a proof that three processes cannot solve.
But it is possible to extend the example to more rounds.
We now give an EIG algorithm for Byzantine agreement, which we call EIGByz.
The EIGByz algorithm for n processes with f faults uses the same EIG tree data structure,  Tn,I, that is used in EIGStop.
Essentially the same propagation strategy is used as for EIGStop; the only difference is that a process that receives an "ill-formed" message corrects the information to make it look sensible.
The decision rule is quite different, however-- i t  is no longer the case that a process.
Now processes must  take some action to mask values tha t  arrive in false messages.
If a process i ever receives a message from another  process j tha t  is not of the specified form (e.g., it contains complete garbage or contains duplicate values for the same node in j ' s  tree), then i "throws away" the message, tha t  is, acts just  as if process j did not send it anything at tha t  round.
Then to determine its decision, process i works from the leaves up in its adjusted, decorated tree, decorating each node with an addit ional  newval, as follows.
For each non-leaf node labelled x, newval(x) is defined to be the newval held by a strict major i ty  of the children of node x, tha t  is, the element v C V such tha t newval(xj) = v for a major i ty  of the nodes of the form xj ,  provided tha t such a major i ty  exists.
If no major i ty  exists, process i sets ncwval(x) := v0
To show the correctness of EIGByz, we start  with some prel iminary assertions.
The first says tha t  all nonfaulty processes agree on the values relayed directly from nonfaulty processes.
I f  i, j ,  and k are all nonfaulty processes, with i ~ j ,  then val(x)i = val(x)j for every label x ending in k.
The next l emma asserts tha t  all nonfaulty processes agree on the newvals computed  for nodes whose labels end with nonfaulty process indices.
Suppose that x is a label ending with the index of a nonfaulty process.
Then there is a value v C V such that val(x)i = newval(x)i = v for all nonfaulty processes i.
Then also newva l (x ) i  - v for every nonfaulty process i, by the definition of newval  for leaves.
Then  Lemma 6.15 implies that all nonfaulty processes i have the same val(x)i;  call this value v.
We now claim that a major i ty  of the labels of children of node x end in.
This is t rue because the number  of children of x is exactly n -  r _> n -  f.
Since at most  f of the children have labels ending in indices of faulty processes, we have the needed majority.
It follows that  for any nonfaulty i, newva l (x l ) i  - v for a major i ty  of children xl  of node x.
Then  the major i ty  rule used in the a lgor i thm implies that.
If all nonfaulty processes begin with v, then all nonfaulty processes broadcas t  v at the first round, and therefore val ( j ) i  = v for all nonfaulty processes i and j.
Lemma 6.16 implies that  newva l ( j ) i  = v for all nonfaulty i and j.
Then the major i ty  rule used in the algori thm implies that  newval(,~)i = v for all nonfaulty i.
To show the agreement  property, we need two more definitions.
First ,  we say that  a subset C of the nodes of a rooted tree is a path covering provided that every path from the root to a leaf contains at least one node in C.
Second, consider any execution c~ of the E I G B g z  algorithm.
Notice that  Lemma 6.16 implies that  if i is nonfaulty, then for every x,  x i  is a.
Let C be the set of nodes of the form xi, where i is nonfaulty.
As observed just  above, all nodes in C are common.
It contains exactly f + 1 non-root nodes, and each such node ends with a distinct process index, by construction.
Since there are at most f faulty processes, there is some node on the path.
The following lemma shows how common nodes propagate up the tree.
Let x be any node label in the EIG tree.
If  there is a common path covering of the subtree rooted at x, then x is common.
By induction on tree labels, working from the leaves up.
If x itself is in C, then x is common.
Since x ~ C, C induces a common path covering.
Since xl was chosen to be an arbi t rary  child of x, all the children of x are common.
Then the definition of newval(x) implies that x is common.
We now tie the pieces together in the main correctness theorem.
The costs are the same as for the EIGStop  algorithm:
In addition, there is the new requirement that the number of processes be large.
As earlier, we pretend that each process can send messages to itself as well as to the other processes.
If, in the set of messages received at this round, there are > n -  f copies of a particular value v E V, then i sets y " -  v; otherwise y " -  null.
Also, i sets z equal to the non-nul l  value that occurs most often among the messages received by i at this round, with t i esbroken  arbitrarily; if all messages are.
If process i decides 1 in the subroutine and if z is defined, then the final decision of the algorithm.
Then i receives at least n - f  round 1 messages containing v.
But the total number of round 1 messages received by j is only n, so this is a contradiction.
To show validity, we must prove that if all nonfaulty processes start with the same initial value, v, then all nonfaulty processes decide v.
Then by the validity condition for the subroutine, some nonfaulty process i must begin the subroutine.
Then if j is any nonfaulty process, it must be that j also.
By Lemma 6.22, no value in V other than v is sent by any nonfaulty.
So process j receives no more than f round 2 messages containing values in V other than v (and these must be from faulty processes)
Since the subroutine's decision value is 1, this means that j decides v.
Since this argument  holds for any nonfaulty process j ,  agreement holds.
In the proof of the TurpinCoan algorithm, the limitation of f on the number of faulty processes is used to obtain claims about the similarity between the views of different processes in an execution.
This sort of argument  also appears in proofs for other consensus algorithms, for instance the approximate agreement algorithm in Section 7.2
The number of rounds is r + 2, where r is the number of rounds used by the binary Byzantine agreement subroutine.
The algori thm uses a mechanism known as consistent broadcast for all its communication.
This mechanism is a way of ensuring a certain amount  of coherence among the messages received by different processes.
Using consistent broadcast ,  a process i can broadcast a message of the form (re, i, r) at round r, and the message can be accepted by any of the processes (including i itself) at any subsequent round.
The consistent broadcast  mechanism is required to satisfy the following three conditions:
If nonfaulty process i does not broadcast  message (rn, i, r) in round r, then (rn, i, r) is never accepted by any nonfaulty process.
The first condition says that  nonfaulty processes '  broadcasts  are accepted quickly, while the second says that  no messages are ever falsely a t t r ibu ted  to nonfaulty processes.
The third condition says that  any message that  is accepted.
Suppose that  nonfaulty process i broadcas ts  message (m, i, r) at round r.
Then,  by the end of round r + 1, each nonfaulty process receives ( "echo", m, i, r) messages from at least n -  f processes and so accepts the message.
Then  no nonfaulty process ever accepts the message, because acceptance requires receipt of echo messages from at least n -  f > f processes.
The consistent broadcast  of a single message uses O (n 2) messages.
Now we describe a simple binary Byzantine agreement algori thm that  uses consistent broadcast  for all its communication.
PolyByz algorithm: The algori thm operates in f + 1 stages, where each stage consists of two rounds.
The messages that are sent (using consistent broadcast)  are all of the form (1, i, r), where i is a process index and r is an odd round number.
The conditions under which process i broadcasts  a message are as follows.
On the other hand, if all nonfaulty processes start with initial value 0, then no nonfaulty process ever broadcasts.
This is because the minimum number of acceptances needed to trigger a broadcast is f + 1, which is impossible to achieve without a prior broadcast by a nonfaulty process.
Let I be the set of nonfaulty processes among these; then.
If all the processes in I have initial values of 1, then they broadcast at round.
Then by property 1 of consistent broadcast, all nonfaulty processes accept messages from.
The number of bits in each message is O (log n), because messages contain process indices.
Thus, the total bit complexity is just O (n 3 log n)
Adding a consistent broadcast capability to the ordinary Byzantine model produces a model that is somewhat like the authenticated Byzantine failure model discussed informally in Section 6.2.4
For instance, consistent broadcast is just for broadcasting, not for sending individualized messages.
More significantly, consistent broadcast does not prevent a process i from broadcasting a message saying (falsely) that a nonfaulty process j has previously sent a particular message; the nonfaulty processes will all accept this message, even though its contents represent a false claim.
In the authenticated Byzantine failure model, the use of digital signatures allows processes to reject such messages immediately.
However, even though the models are somewhat different, the consistent broadcast capability is strong enough that it can be used to implement, in the ordinary Byzantine model, some algorithms designed for the authenticated Byzantine failure model.
We have presented algorithms to solve the agreement problem in a complete network graph, in the presence of stopping failures, and even in the presence of Byzantine failures.
You have probably noticed that these algorithms are quite costly.
In the rest of this chapter, we show that these high costs are not accidental.
The next two sections contain related results: Section 6.5 describes exactly the amount of connectivity that is needed in an incomplete network graph in order for Byzantine agreement to.
The final section of the chapter shows that the lower bound of f + 1 on the number of rounds is also necessary, even for the simple case of stopping failures.
This result is suggested by the example in Section 6.3.1, although that example does not constitute a proof.
We construct a new system S using two copies of A and show that S must exhibit contradictory behavior.
Specifically, we take two copies of each process in A and configure them into a single hexagonal system S.
We will not consider any faulty process behavior in S.
Remember that in the systems we consider as solutions for the Byzantine agreement problem, we assume that the processes all "know" the entire network graph.
In S, we do not assume that the processes know the entire (hexagonal) network graph, but rather that each process just has local names for its neighbors.
It does not know that there are duplicate copies of the nodes in the network.
The situation is similar to the one considered in Chapter 4, where each process only had local knowledge of its portion of the network graph.
In particular, notice that the network in S appears to each process just like the network in A.
System S is not required to exhibit any special type of behavior.
However, note that S with any particular input assignment does exhibit some well-defined behavior.
We will obtain a contradiction by showing that, for the particular input assignment indicated above, no such well-defined behavior is possible.
Although it is peculiar, it is an allowable behavior for a faulty process in A, under the assumptions for Byzantine faults.
By the correctness condit ions for Byzant ine  agreement,  processes.
Therefore, they decide on the same value in c~ also.
We now use Lemma 6.26 to show that Byzantine agreement is impossible with.
For the special case where n - 2, it is easy to see that the problem cannot be solved.
Then each must allow for the possibility that the other is faulty and decide on its own value, in order to ensure the validity property.
But if neither is faulty, this violates the agreement property.
Assume for the sake of contradiction that there is a solution A for Byzantine.
Each of the three processes in B will simulate approximately one-third of the processes of A.
We let each process i in B simulate the processes in Ii, as follows.
B; Each process i keeps track of the states of all the processes in Ii, assigns its own initial value to every member of Ii, and simulates the steps of all the processes in Ii as well as the messages between.
Messages from processes in Ii to processes in another subset are sent from process i to the process simulating.
If any simulated process in Ii decides on a value v, then i decides on the value v.
If there is more than one such value, then i can choose any such value.
We show that B correctly solves Byzantine agreement for three processes.
Designate the faulty processes of A to be exactly those that are simulated by faulty processes of B.
Fix any particular execution c~ of B with at most one.
Since A is assumed to solve Byzantine agreement for n processes with at most.
For termination, let i be a nonfaulty process of B.
Then i simulates at least one process, j ,  of A, and.
For validity, if all nonfaulty processes of B begin with a value v then all the.
Then v is the only decision value for a nonfaulty process in c~
For agreement, suppose i and j are nonfaulty processes of B.
We conclude that B solves the Byzantine agreement problem for three processes, tolerating one fault.
So far in this chapter, we have considered agreement problems only in complete graphs.
In this section, we consider the problem of Byzantine agreement in general network graphs.
We characterize exactly the graphs in which the problem is solvable.
First, if the network graph is a tree with at least three nodes, we cannot hope to solve the Byzantine agreement problem with even one faulty process, for any faulty process that is not a leaf could essentially "disconnect" the processes in one part of the tree from the processes in another.
The nonfaulty processes in different components would not even be able to communicate reliably, much less reach agreement.
Similarly, it should be plausible that if f nodes can disconnect the graph, then Byzantine agreement is impossible with f faulty processes.
To formalize this intuition, we use the following notion from graph theory.
The connectivity of a graph G, corm(G), is defined to be the minimum number of nodes whose removal results in either a disconnected graph or a trivial 1-node graph.
Graph G is said to be c-connected if conn(G) >_ c.
We use a classical theorem of graph theory known as Menger's Theorem.
Theorem 6.28 (Menger's Theorem) A graph G is c-connected if and only if every pair of nodes in G is connected by at least c node-disjoint paths.
Now we can characterize those graphs in which it is possible to solve Byzantine agreement with a given number of faults.
The characterization is in terms of both the number of nodes in the graph and the connectivity.
The proof of the impossibility part of the characterization uses methods similar to those used in Section 6.4 to prove the lower bound for the number of faulty processes.
Since there are at most f faulty processes, the messages received by j along a majority of these paths must be correct.
Once we have reliable communication between all pairs of nonfaulty processes, we can solve Byzantine agreement just by simulating any algorithm that solves the problem in an n-node complete graph.
The implementation given above for reliable communication is used in place of the point-to-point communication in the complete graph.
Of course, there is an increase in complexity, but that is not the issue here-- the algorithm still works correctly.
We simplify matters by only arguing the case where f - 1; we leave the (similar) argument for larger values of f for an exercise.
Then there are two nodes in G that either disconnect G or reduce it to one node.
But if they reduce it to one node, it means that G consists of only three nodes, and we already know that Byzantine agreement cannot be solved in a three-node graph in the presence of one fault.
So we can assume that the two nodes disconnect G.
We construct a system S by combining two copies of A.
As in the proof of Lemma 6.26, S with the given input assignment does exhibit some well-defined behavior.
Again, we will obtain a contradiction by showing that no such behavior is possible.
To these processes, it appears as if they are running in system A, in an execution Ct I in which process 4 is faulty.
By the correctness conditions for Byzantine agreement, these three processes must eventually decide in c~3, and their decisions must be the same.
As an example, in this section we show how this method can be used to prove impossibility for a weaker variant of the Byzantine agreement problem known as weak Byzantine agreement.
The only difference between the problem statement for weak Byzantine agreement and ordinary Byzantine agreement is in the validity condition.
Va l id i ty :  If there are no faulty processes and all processes start with the same initial value v C V, then v is the only possible decision value.
In the ordinary Byzantine agreement problem, if all the nonfaulty processes start with the same initial value v, then they must all decide v even i f  there are faul ty processes.
In weak Byzantine agreement, they are required to decide v only in the case where there are no failures.
Since the new problem statement is weaker than the old one, the algorithms we have described for ordinary Byzantine agreement also work for weak Byzantine agreement.
On the other hand, the impossibility results do not immediately carry over; it is plausible that more eMcient algorithms might exist for weak Byzantine agreement.
However, it turns out that (except for a tiny technicality)
The weak Byzantine agreement problem can be solved in an n-node network graph G, tolerating f faults, if and only if both the following hold:
The if direction follows from the existence of protocols for ordinary Byzantine agreement, as claimed in Theorem 6.29
This time, we have not bothered to include prime symbols or other distinguishing notation for the multiple copies of the same process of A.
It follows that all processes in S must reach the same decision in c~
At round 2, all processes in B except the two.
Informally speaking, this is because information does not have time to propagate to those processes from outside the block B.
But since process i decides 0 by the end of round r in.
We complete this chapter by showing that the agreement problem cannot be.
We will proceed by assuming that an f-round agreement algorithm exists and.
It is convenient for us to impose some restrictions on the assumed algorithm, none of which causes any loss of generality.
First, we assume that the network graph is completely connected; a fast algorithm for an incomplete graph could also be run in a complete graph, so there is certainly no loss of generality in this restriction.
We also assume that all processes that decide do so exactly at the end of round f ,  then immediately halt.
In this case, an algorithm for Byzantine agreement is necessarily an algorithm for stopping agreement (see the remark on the relationship between the two problems in Section 6.1)
So, for the purpose of obtaining an impossibility result, we can restrict attention to the stopping agreement problem only.
As for the coordinated attack problem in Chapter  5, it is convenient to carry out the proof using the notion of a communication pattern,  which is an indication of which processes send messages to which other processes at each round.
Specializing the previous definition to the case of a complete graph, we define a.
A communication pat tern does not describe the contents of messages, but only.
That  is, if process i fails to send any of its messages at round k, then it sends no messages at subsequent.
Third, because we consider executions with at most f failures, all the communication patterns that arise contain at most f faulty processes.
We define a process i to be faulty in a communication pat tern if some triple of the form (i, j, k), k < f ,  is missing from the pattern.
We say (in the rest of this chapter only) that a communication pat tern that satisfies these three restrictions is good.
Now we define a run to be a combination of.
This is similar to what we called an adversary in Section 5.2.1
For a particular agreement algorithm A, each run p defines a corresponding.
Namely, the initial states of the processes are defined by setting the input state components according to the input assignment.
But after any process fails to send a message, we stop applying its state-transition function.
A; we assume that A satisfies all the restrictions listed at the beginning of this section.
The idea is to construct a chain of executions of A, each with at most one.
Then, since any two consecutive executions look the same to some nonfaulty process, say i, process i must make the same decision in both executions; therefore, the two executions must have the same unique decision value.
It follows that every execution in the chain must have the same unique decision value, which contradicts the combination of properties (a) and (b)
We continue in this manner,  removing one message from process 1 at a.
Next, we replace process l ' s  messages one by.
Next,  we repeat  this construct ion for process 2, first removing its messages.
So we have cons t ruc ted  a chain from exec(po) to  exec(pn) satisfying proper ty (c)
So we have the needed chain, which gives a contradict ion.
Before moving to the general  case, we will do one more pre l iminary c a s e - - t h e.
Again suppose tha t  there is such an algori thm.
We construct  a chain with the same propert ies  (a), (b), (c) as in the previous proof, using a similar.
The  chain s tar ts  with exec(po), ends with exec(pn), and passes th rough  all the executions exec(pi) along the way.
Star t ing  wi th  exec(po), we want  to work toward killing process 1 at the beginning.
Now there is no problem in removing process l ' s  round 2 messages one by one.
This is because in round 2, i is able to tell all other  processes whether.
We solve this problem by using several steps to remove the round 1 message.
In the in te rmedia te  executions tha t  occur along the way, processes.
Then  we replace round 2 messages sent by i one by one, until  we obta in  an.
Then there is no n-process stoppingagreement algorithm that tolerates f faults, in which all nonfaulty processes always decide by the end of round f.
In the general proof, a longer chain is constructed, using f process.
We proceed more formally than we did in the proofs of Theorems 6.31
First,  if p and p~ are runs in both of which process i is nonfaulty, then we.
The heart of the proof of Theorem 6.33 is the following strong lemma, which says that it is possible to construct a chain between any two regular executions having the same input assignment.
Let p and p~ be two regular runs of A with the same input assignment.
We show this by proving the following parameter ized claim.
Let p and p~ be two regular runs of A with the same input assignment and with identical communication patterns through k rounds.
The proof of Claim 6.36 is by reverse induction on k, start ing with.
This case is trivial because the assumption that p and p~ have.
So we assume that at least one process fails at round k + 1 in p.
Let I be the set of processes that do so.
So we remove those messages one at a time, while keeping the runs otherwise unchanged.
For instance, consider the removal of a message from i to j ,  where i C I.
Now we extend Lemma 6.35 to apply to different input  assignments.
I f  p and p' are two regular runs of A, then p ~ p'
So we can assume without  loss of generality that  p and p' in the s ta tement  of the lemma are both failure-free.
If p and p' have the same input assignment,  then they are identical and there is nothing to prove.
Then define cr and a '  to be the runs that  are identical to p and p', respectively, except that  i fails right at the start.
Also, a ~ a ' ,  because a and a '  are.
Finally, suppose that p and p' differ in the input of more than one process.
Then we can construct a chain of failure-free runs, spanning from p to p', changing exactly one process's input at each step in the chain.
We already know that all regular runs are related by chains; now we consider the decision values.
Assuming that n > f ,  the termination and agreement properties imply that for every run p, there is a unique decision value, dec(p), that arises in exec(p)
The following lemma says that runs that are related by or ~ necessarily give rise to the same decision values.
If  p ~ p', then d e c ( p ) -  dec(J)
If  p ,.~ p', then d e c ( p ) -  dec(J)
This implies that process i decides on the same value in exec(p) and exec(p')
Suppose there is such an algorithm, A; we assume that A satisfies the restrictions listed at the beginning of the section.
Byzantine agreement problem also requires at least f + 1 rounds, under the.
The presentation in the second paper is in terms of attacking generals rather than processes.
It is the second paper that coined the term Byzantine for this fault model.
The algorithms in [237] use an exponential data structure similar to an EIG tree; the Byzantine agreement algorithm is similar to EIGByz, while the algorithm using authentication is similar to EIGStop.
The algorithms in [187] are very much the same but are formulated recursively.
Dolev and Strong [93] developed algorithms similar to FloodSet and OptFloodSet for Byzantine agreement in the case where authentication is available.
Dolev [94] considered the Byzantine agreement problem in graphs that are not necessarily completely connected.
He proved the connectivity bounds represented in Theorem 6.29, using explicit construction of scenarios.
Dolev, Reischuk, and Strong [99] developed algorithms with "early stopping" for certain favorable communication patterns.
Bar-Noy, Dolev, Dwork, and Strong defined the EIG tree data structure and presented the EIGByz algorithm in essentially the form given in this book [39]
However, the proofs presented in this book were developed by Fischer, Lynch, and Merritt [122]
The weak Byzantine agreement problem was defined by Lamport [178]
The first lower bound result for the number of rounds required to reach agreement was proved by Fischer and Lynch [119], for the case of Byzantine failures.
Another proof of this result was presented by Dwork and Moses [105]; their proof provides a finer analysis of the time requirements for different runs.
Feldman and Micali [113] obtained a constant time randomized solution using "secret-sharing" techniques.
A paper by Fischer [117] surveys much of the early work on the agreement problem.
These designs have been'used for safety-critical applications such as unmanned undersea vehicles, nuclear attack submarines, and nuclear power plant control.
Prove that any algorithm that solves the Byzantine agreement problem also solves the stopping agreement problem, if the validity condition for stopping failures is modified to require only that nonfaulty processes agree.
Prove that any algorithm that solves the Byzantine agreement problem, and in which all nonfaulty processes always decide at the same round, also solves the stopping agreement problem.
Suppose that instead of running for f + 1 rounds, the algorithm runs for only f rounds, with the same decision rule.
Describe a particular execution in which the correctness requirements are violated.
Extend the FloodSet algorithm, its correctness proof, and its analysis to arbitrary (not necessarily complete) connected graphs.
Consider the following simple algorithm for agreement with stopping failures, for a value domain V.
Each process maintains a variable min-val, originally set to its own initial value.
For each of f + 1 rounds, the processes all broadcast their min-vals, then each resets its rnin-val to the minimum of its old min-val and all the values it receives in messages.
Give code for this algorithm, and prove (either directly or via a simulation proof) that it works correctly.
Suppose that instead of running for f + 1 rounds, the algorithm only runs for f rounds, with the same decision rule.
Describe a particular execution in which the correctness requirements are violated.
In order to do this, it is convenient to first extend EIGStop by allowing each process i to broadcast all values at all rounds, not just values associated with nodes whose labels do not contain i.
It must be argued that this extension does not affect correctness.
Also, some details in the description of EIGStop must be filled in, for example, explicit rounds and decision variables, manipulated in the obvious ways.
Then FloodSet and the modified EIGStop can be run side by side, starting with the same set of initial values, and with failures occurring at the same processes at exactly the same times.
The heart of the proof should be the following simulation relation, which involves the states of both algorithms after the same number of rounds.
Be sure to include the statement and proof of any additional invariants of EIGStop that you need to establish the simulation.
Prove the correctness of OptEIGStop, in either of the following two ways:
Prove the correctness of the EIGStop and OptEIGStop algorithms for the authenticated Byzantine failure model.
Some key facts that can be used in the proof of EIGStop are expressed by the following assertion, analogous to the statement of Lemma 6.12:
Research Question: Define the authenticated Byzantine failure model formally and prove results about its power and limitations.
Give an example of an execution of EIGStop that shows that EIGStop does not solve the agreement problem for Byzantine faults.
Consider the EIGByz  algorithm with seven processes and three rounds.
Arbitrarily select two of the processes as faulty and provide random choices for the inputs of all processes and for the message values of the faulty processes.
Calculate all the information produced in the execution and verify that the correctness conditions are satisfied.
In the EIGByz  algorithm, show that not every node in the EIG tree need be common.
Construct explicit executions to show that the algorithm can give wrong results if it is run with.
What other pairs of thresholds would also allow the algorithm to work correctly?
Suppose we consider the TurpinCoan algorithm with two sets of faulty processes, F and G, rather than just one.
Processes in G are allowed to behave incorrectly during execution of the binary Byzantine agreement subroutine (and only then)
What  correctness conditions are guaranteed by the combined algorithm under these failure assumptions? Prove.
Design an algorithm that uses a subroutine for binary Byzantine agreement and solves multivalued Byzantine agreement.
The algorithm should improve on the TurpinCoan algorithm by only requiring one additional round rather than two.
Either give such an algorithm and prove its correctness, or argue why no such algorithm exists.
Design a polynomial communication algorithm for Byzantine agreement for a general input value set, without using a subroutine for binary Byzantine agreement.
Design a protocol for four processes in a completely connected graph that tolerates either one Byzantine fault or three stopping faults.
Byzantine agreement algorithms that run in the following network graphs?
Analyze the time, number of messages, and number of communication bits for the Byzantine agreement algorithm for general graphs, described in the proof of Theorem 6.29
Reconsider the proof that  Byzantine agreement cannot be reached in the graph in Figure 6.11
Why does this proof fail to extend to the graph in Figure 6.21?
Give a simple algorithm for weak Byzantine agreement in a network graph consisting of two nodes connected by a single link.
There are n processes in a fully connected network with no input values and with variable start  times.
That  is, each process begins in a quiescent state containing no information and from which it sends only null messages.
It does not change state until and unless it receives a special wakeup message from the outside or a non-null message from another process.
A process does not know the current round number when it awakens.
The model is similar to the one in Section 2.1, except that  we do not assume here that all processes must receive wakeup messages--only some arbitrary subset of the processes.
A g r e e m e n t :  If any nonfaulty process issues a fire signal at some round, then all nonfaulty processes issue a fire signal at that same round and no nonfaulty process issues a fire signal at any other round.
Va l id i ty :  If all nonfaulty processes receive wakeup messages, then all nonfaulty processes eventually fire; if no nonfaulty process receives a wakeup message, then no nonfaulty process ever fires.
Does Lemma 6.37 still hold if the runs are not required to be regular? Give a proof or a counterexample.
In Section 6.7, it is shown that stopping agreement tolerating f faults cannot be solved in f rounds.
The construction involves the construction of a long chain connecting the two runs in which all the processes are nonfaulty and have the same inputs.
Research Question: Obtain upper and lower bound results about the time required to solve the stopping agreement problem and/or  the Byzantine agreement problem, in general (not necessarily complete) network graphs.
In this chapter, we finish our study of synchronous distributed consensus by considering three other consensus problems: the k-agreement problem, the approximate agreement problem, and the distributed database commit problem.
The first problem we consider is the k-agreement problem, where k is some nonnegative integer.
But now, instead of requiring that all processes decide on exactly the same value, we insist only that they limit their decisions to a small number, k, of distinct values.
The original motivation for this problem was purely mathematical-- i t  is interesting to try to determine how the results of Chapter 6 change when the problem requirements are varied in this simple way.
But it is possible to imagine practical situations in which such an algorithm could be useful.
For example, consider the problem of allocating shareable resources, such as broadcast frequencies in a communication network.
It might be desirable for a number of processes to agree on a small number of frequencies to use for the broadcast of a large amount of data (say, a videotape)
Because the communication is by broadcast, any numbet of processes could receive the data using the same frequency.
In order to minimize the total communication load, it is preferable to keep the number k of frequencies that are used small.
In this section, we prove exactly matching upper and lower bounds o n t h e.
These bounds are given in terms of n, the number of processes; f ,  the number of failures tolerated; and k, the allowed number of decision values.
Each process starts with an input from a fixed set V and is supposed to eventually output a decision from the set V.
Again, we assume that for each process, there is exactly one start state containing each input value.
A g r e e m e n t :  There is a subset W of V, IWI = k, such that all decision values are in W.
Va l id i ty :  Any decision value for any process is the initial value of some process.
The agreement condition is the natural generalization of the agreement condition for the ordinary agreement problem.
For the results we present in this section, we consider the special case of a complete network graph only.
We also assume that V comes equipped with a total ordering.
We present a very simple algorithm, called FloodMin; in fact, it is exactly the algorithm sketched in Exercise 6.9, but it runs for a smaller number of rounds.
Thus, roughly speaking, allowing k decision values rather than just one divides the running time by k.
Each process maintains a variable rnin-val, originally set to its own initial value.
Compare its structure with that of FloodSet in Section 6.2.1
We argue correctness; the proof is similar to that for the FloodSet algorithm in Section 6.2.1
Let M(r)  denote the set of rnin-val values of active processes after r rounds.
We first observe that the set M(r)  can only decrease at successive times.
Then rn is the value of rnin-vali after r rounds, for some process i that is active after r rounds.
Then either rn = rnin-vali just before round r or else rn arrives at i in some round r message, say from j.
It follows that rn E M ( r -  1)
Let m be the maximum element of M(r) and let m'  -r m be any other element of M(r)
If i does not fail in round r, then every process receives a message containing m' from i at round r.
But this cannot occur, because some active process has m > m' as its min-val after r rounds.
But rn' was chosen to be any arbitrary element of M(r) other than the maximum, m.
Thus, for every element m'  -r m of M(r ) ,  there is some process that is active, has its min-val equal to rn' after r -  1 rounds, and fails during round r.
Suppose, to obtain a contradiction, that the number of distinct decision values is greater than k in a particular execution having at most f failures.
Then Lemma 7.2 implies that at least k processes fail in.
This yields a total number of failures that is at.
But this is strictly greater than f ,  which yields a contradiction.
As you might expect, the ideas of the proof are derived from those used for the proof of the lower bound for ordinary agreement, Theorem 6.33, but they are a good deal more advanced and more interesting.
In fact, they take us into the realm of algebraic topology.
For the remainder of this section, fix A to be an n-process algorithm that solves the k-agreement problem, tolerating the stopping failure of at most f processes.
Without loss of generality, we may assume that all processes that decide do so exactly at the end of round r and immediately halt.
We would like to extend this proof to other values of k.
Unfortunately, in the k-agreement problem, unlike in the ordinary agreement problem, the decision values in one execution do not determine the decision values in closely related executions.
For example, if executions a and a '  of an ordinary agreement algorithm are indistinguishable to nonfaulty process i, then not only must i's decision be the same in both, but also the decisions of all the other nonfaulty processes in both c~ and a '  must be the same as i's decision.
In a k-agreement algorithm, if a and a '  are indistinguishable to i, then i's decision is still guaranteed to be the same in both, but now the decisions of the other processes are not determined.
Even if a and a '  are indistinguishable to n -  1 processes, the decision value of the remaining process is not determined.
The key idea we use is to construct a k-dimensional collection of executions rather than a (one-dimensional) chain.
Adjacent executions in this collection are indistinguishable to designated nonfaulty processes.
We call the k-dimensional structure used to organize these executions the Bermuda Triangle (because any hypothetical k-agreement algorithm vanishes somewhere in its interior)
It consists of a large tr iangle " tr iangulated" into a collection of "tiny triangles."
Fortunately, such a generalization already exists in the field of algebraic topology: it is called a k-dimensional  simplex.
For example, a one-dimensional simplex is just  an edge, a two-dimensional  simplex is a triangle, and a three-dimensional  simplex is a te t rahedron.
Beyond three dimensions, the simplices are much harder  to imagine.
So, for an a rb i t ra ry  k, we star t  with a k-dimensional  simplex in k-dimensional Euclidean space.
This simplex contains a number  of grid points, which are the points in Euclidean space with integer coordinates.
The k-dimensional Bermuda Triangle, B, is obtained by t r iangulat ing this simplex with respect to these grid points, obtaining a collection of tiny k-dimensional  simplices.
For instance, in the case where k = 2, all executions.
Next, to each vertex in B, we assign the index of some process that  is nonfaulty in the execution assigned to that  vertex.
All the processes assigned to the corners of T are nonfaul ty in c~
This assignment  of executions and processes to vertices of B has some nice.
If x is on an external  edge of B, then in c~
Our ability to assign executions and indices to the vertices in the manner  just.
This is because the executions are assigned using a k-dimensional  generalization of the chain argument  in the proof of Theorem 6.33
The construct ion uses r process failures for each of the k dimensions.
After having assigned executions and indices to vertices, we "color" each.
The colors of the k + 1 corners of B are all different.
More generally, the color of each point on any external face (of any dimension) of B is the color of one of the corners of the face.
It turns out that colorings of this k-simplex with exactly these properties have been studied in the field of algebraic topology, under the name Sperner colorings.
But this contradicts the agreement condition for the k-agreement problem.
We use the definition of a communication pattern from Section 6.7
Now, we redefine a good communication pattern to be one in which k < r for all triples (i, j, k) and in which the missing triples are consistent with the stopping failure model.
That is, we use the first two conditions in the definition of a good communication pattern in Section 6.7, except that the upper bound for the number of rounds is now r instead of f.
For the moment, we do not limit the number of failures.
Based on this new definition of a good communication pattern, we define a run and define exec(p) for a run p in the same way as in Section 6.7
We also say that process i is silent after t rounds in a run if i sends no messages in any round numbered t + 1 or higher.
The Bermuda Triangle B is this simplex, together with the following triangulation into tiny simplices.
The tiny simplices are defined as follows: pick any grid point and walk one step in the positive direction along each dimension, in any order.
The k + 1 points visited by this walk define the vertices of a tiny simplex.
We do this by first augmenting runs by attaching tokens to some of the (process, round number) pairs (i, t) in the runs.
Such a token should be thought of as "giving permission" for process i to fail in round t or later.
Since each augmented run is constructed from a run, each augmented run.
We extend the notation exec(p), which was previously defined for runs, to the case where p is an augmented run.
In order to label the vertices of B with executions, we label them with k-runs.
We now define four operations on /-runs, each of which makes only minor.
Each operation can only remove or add a single triple, change the.
This operation removes the triple ( i , j , t )  (which represents  the round t message from i to j )  if it is there, and has no effect otherwise.
This operat ion adds the triple (i, j, t) if it is not already there and has no effect otherwise.
It can only be applied if i and j are both silent after t rounds and i is active after t -  1 rounds.
This operat ion changes process i 's input  value to v and has no effect if this input  value is a lready v.
It can only be applied if (i, t) has a token and if all failures have permission from other tokens.
It should be obvious from the definitions that  when any of these operations is applied to a n / - r u n ,  the result is also a n / - r u n.
It turns  out that  the sequences seq(v) can be const ructed so that  they are isomorphic for different v - - t h a t  is, they are the same except for the choice of v.
Now we can (finally) define the paramete r  N used in defining the size of B: N.
We will use several sequences seq(v) to label the vertices of B.
Then the k-run we assign to each vertex x of B will be obtained by "merging" the k 1-runs that.
The diagram does not depict all the ver t ices--only those labelled by failure-free k-runs.
Thus, the only interesting information we need to provide is the vector of input values for each depicted vertex.
In the interior of B, changes take place in both directions at the same.
To motivate the first condition, we reconsider the way that the merge operation is to be used.
Each av will be obtained by applying some prefix of seq(v) to T~_I.
At some point in this sequence, the input value for process i is changed from v -  1 to v.
If this has already happened in a~ then let us say that process i has "converted" in dimension v.
The second condition says that a message is missing in the new run p if and.
It is not hard to see that the merge of a sequence of l -runs is in fact a k-run.
We end this subsection by giving some close connections among the k-runs labelling the vertices of any single tiny simplex T in B.
The first lemma says that  any process that  is faulty in one of these k-runs must  have a token in all of them.
This is because the changes in each sequence seq are so gradual, in par t icular  because movement  of a token and removal of a triple occur in two separate  steps.
The second lemma limits the number  of total  failures in all of the runs.
Finally, we consider labelling vertices of T with process indices.
The final impor tan t  proper ty  of the k-runs labelling the vertices of T is that  if there is a local process labelling of T, then T is consistent with a single execution.
Then there is a run p with at most  f failures such that for all v, i~ is nonfaulty in p and exec(pv) and exec(p) are indistinguishable to process iv.
We define the initial value for each process i in p to be i 's initial value from any one of the p~
Likewise, we include (i, j, r),  where the recipient j is not one of the processes i~, exactly if it is in all the Pv.
Finally, (i, j, r),  where j - iv (for a specific v) is included exactly if it is in p~ (for the same v)
Lemma 7.6 suggests a way of doing this: for each vertex of.
B, we pick a process that  has no tokens in the corresponding k-run, in such a.
Lemma 7.6 then implies the needed compatibi l i ty  condition for each tiny simplex.
We define a global process labelling for B to be an assignment of processes to vertices of B such that  for every vertex x, the process assigned to x has no.
We begin the construct ion by associating a set live(p) of processes with each k-run p labelling a vertex of B and then choosing one process from.
Each set live(p) consists of exactly n -  rk processes.
The processes in live(p) are chosen from among those that  do not have tokens in p.
It contains exactly rk tokens; let tokens be the multiset of process indices describing the number  of tokens associated with each process.
We "flatten" the multiset  tokens to obtain a new multiset  newtokens with the same number of tokens, but  in which no more than one token is associated with.
Also, any process that has a token in tokens also has a token in newtokens.
Then we define live(p) to be all processes i such tha t  newtokens( i )  = O.
It is easy to see tha t  this definition of live satisfies the first two propert ies.
First ,  we note tha t , when we walk the vertices of T in order, if process i ever acquires a token, then.
Now we can prove the thi rd  proper ty  for the live sets.
Then L e m m a  7.7 implies tha t  i.
Since token placements  in adjacent  k-runs differ by at most  the movement  of.
Since i c livc(pv), the way the Flatten procedure works implies tha t  s < i.
If s _> i, then  the tokens tha t  s tar t  on processes smaller than  i would "overflow" in the Flatten procedure so tha t  one would end up on i.
Now we are ready to label the vertices of B with  process indices.
Namely, let plane(x)  - E i = l k  xi (mod k + 1)', we label x with the process having rank plane(x)  in live(p)
This choice is mot iva ted  by the following fact about  B:
Because the index for each vertex x is chosen from the set live(p), where p is the associated k-run, it must be that that index has no tokens in p.
We summarize what we know about the labellings we have produced:
We are nearly done! It remains only to state Sperner's Lemma (for the special case of the Bermuda Triangle) and to apply it to obtain a contradiction.
This will yield the lower bound on the number of rounds required to solve k-agreement.
A Sperner coloring of B assigns one of a set of k + 1 colors to each vertex of B so that.
The colors of the k + 1 corners of B are all different.
The color of each point on an external edge of B is the color of one of the corners at the endpoints of the edge.
More generally, the color of each interior point on an external face (of any dimension) of B is the color of one of the adjacent corners of B.
Given a vertex x labelled with run p and process i, color x with process.
Then there is no n-process algorithm for k-agreement that tolerates f faults, in which all nonfaulty processes always decide within L Zk J rounds.
Now we consider the approximate agreement problem in the presence of Byzantine failures.
In this problem, the processes start  with real-valued inputs and are supposed to eventually decide on real-valued outputs.
They are permit ted to send real-valued data in messages.
Instead of having to agree exactly, as in the ordinary agreement problem, this time the requirement is just that they agree to within a small positive real-valued tolerance c.
Va l id i t y :  Any decision value for a nonfaulty process is within the range of the initial values of the nonfaulty processes.
This problem arises, for example, in clock synchronization algorithms, where processes at tempt to maintain clock values that are close but do not necessarily agree exactly.
Many real distributed network algorithms work in the presence of approximately synchronized clocks, so approximate agreement on clock values is usually sufficient.
Here, we consider the approximate agreement problem in complete graphs only.
One way of solving the problem is by using an ordinary Byzantine agreement algorithm as a subroutine.
In the algorithm for process i, i begins by sending its message to all processes in round 1, then all processes use the received values as their inputs in a Byzantine agreement algorithm.
When these algorithms terminate, all nonfaulty processes have the same decision values for all processes.
To see that this works, note that if i is nonfaulty, then the validity condition for Byzantine agreement guarantees that the value obtained by all nonfaulty processes for i is i's actual input value.
Now we present a second solution, not using Byzantine agreement.
In contrast, the Byzantine agreement problem cannot be solved in asynchronous networks.
The second solution also has the property that it sometimes terminates in fewer than the number of rounds required for Byzantine agreement, depending on how far apart  the initial values of nonfaulty processes are.
For simplicity, we describe a nonterminating version of the algorithm, then discuss termination separately.
We need a little notation and terminology: First, if U is a finite multiset of.
Finally, if U is a nonempty  finite multiset of reals, then mean(U) is just  the mean of the elements in U.
We also say tha t  the range of a nonempty  finite multiset  of reals is the smallest interval containing all the elements, and the width of such a multiset  is the size of the range interval.
First, it broadcasts  its val value to all processes, including itself.
Then it collects all the values it has received at tha t  round into a multiset  W; if i does not receive a value from some other process, it simply picks some arbi t rary  default value to assign to tha t  process in the multiset,  thus ensuring tha t  I W I -  n.
Tha t  is, process i throws out the f smallest and f largest elements of W.
From what  is left, i selects only the smallest element and every f t h  element thereafter.
Finally, val is set to the average (mean) of the selected elements.
We claim tha t  at any round, all the nonfaulty processes' vals are in the range of the nonfaulty processes' vals just  prior to the round.
Then v is in the range of the nonfaulty processes' vals just before round r.
If Wi is the multiset  collected by process i at round r, then there are at most  f elements of W / t h a t  are not values sent by nonfaulty processes.
Then all the elements of reduce(Wi) are in the range of nonfaulty processes' vals just prior to round r.
As usual, sending to itself is simulated by a local transition.
Let Wi and Wi, be the respective multisets collected by processes i and i' in round r.
Since nonfaulty processes contribute the same value to both Wi and Wi,, we have that I W i -  Wi, I <- f.
We can show that removing a smallest element from both multisets does not increase the number of elements in the difference, and we can show the same for removing a largest element.
Using these two facts f times apiece yields the result.
Now we finish the proof of Lemma 7.17 by calculating the required bound.
But all of the values Uc, u c, Ul, and u~ are in the range of the nonfaulty processes' vals just  before round r, since all elements of reduce(Wi) and reduce(Wi,) are in.
So this last expression is less than or equal to c, as needed.
Namely, each nonfaulty process uses the range of all the values it receives at round 1 to compute a round number by which it is sure that the vals of any two nonfaulty processes will be at most e apart.
Any process i that reaches its computed round decides on its own current val.
After doing this, process i broadcasts its val with a special halting tag and then halts.
After any process j receives a val with a halting tag from i, it uses this val as its message from i, not only for the current round, but also for all future rounds (until j itself decides to halt, on the basis of j ' s  own computed round number)
Although nonfaulty processes might compute different round numbers, it should be clear that the smallest such estimate is correct.
Thus, at the time the first nonfaulty process halts, the range of vals is already sufficiently small.
At subsequent rounds, the range of vals of nonfaulty processes never increases, although there is no guarantee that it continues to decrease.
This is because faulty processes can send arbitrary values at round 1, which can cause the nonfaulty processes to compute arbitrarily large round numbers for termination.
The exercises discuss bounds on the number of processes and the connectivity needed to solve the approximate agreement problem.
We will revisit this problem in Chapter 21, in the asynchronous network setting.
In this, the final section on distributed consensus problems in synchronous systems, we present some of the key ideas about the distributed database commit problem.
As discussed in Section 5.1, the problem arises when a collection of processes participate in the processing of a database transaction.
After this processing, each process arrives at an initial "opinion" about whether the transaction ought to be committed (i.e., its results made permanent and released for the use of other transactions) or aborted (i.e., its results discarded)
A process will generally favor committing the transaction if all its local computation on behalf of that transaction has been successfully completed, and otherwise will favor aborting the transaction.
The processes are supposed to communicate and eventually agree on one of the outcomes, commit  or abort.
Solutions to this problem have been designed for real distributed networks, in which there can be a combination of process and link failures.
However, the results in Chapter 5 imply that there can be no solution in the case of unlimited link failures.
We consider a simplified version of the commit problem, for networks in which there is no message loss, but only process failures.
If you are interested in implementing the algorithms in this chapter in a real network, you will have to add other mechanisms, such as repeated retransmissions, to cope with lost messages.
The weak termination condition says that if there are no failures then all processes eventually decide.
The strong termination condition (also known as the non-blocking condition) says that all nonfaulty processes eventually decide.
Commit  algorithms that satisfy the strong termination condition are sometimes called non-blocking commit algorithms, while commit algorithms that satisfy the weak termination condition but not the strong one are sometimes called blocking commit algorithms.
Notice that our agreement condition is that no two processes decide on different values.
Thus, we do not allow even a failed process to decide differently from other processes.
We require this because, in practical uses of a commit protocol, a process might fail and later recover.
Suppose, for example, that a process i decides commit before it fails, and that later, other processes decide abort.
If process i recovers and retains its commit decision, then there would be an inconsistency.
The most important  difference between the commit problem and the coordinated attack problem is that we are here considering process failure and not link failure; there is also a difference in the validity condition.
The important  differences between the commit problem and the stopping agreement problem are, first, the particular choice of validity condition, and, second, the consideration of a weaker notion of termination.
Note that the proof of Theorem 6.33 still works with the commit validity conditions.
In the rest of this section, we give versions of two standard practical commit algorithms (for the simplified setting with only process faults)
The first, twophase commit, is a blocking algorithm, while the second, three-phase commit, is non-blocking.
We then give a simple lower bound on the number of messages needed to solve the problem, even if only weak termination is required.
The bes t -known practical commit  a lgor i thm is two-phase commit; without  any embell ishments,  this simple algori thm guarantees  only weak terminat ion.
See Figure 7.4 for an i l lustration of the communicat ion pa t te rn  used in the failurefree runs of TwoPhaseCornmit.
Agreement,  validity, and weak terminat ion are all easy to show.
However, TwoPhaseCornrnit does not satisfy the strong terminat ion condition, that  is, it is a blocking algorithm.
In practice, if process 1 fails, then the remaining processes usually carry out some sort of termination protocol among themselves and sometimes manage to decide.
For example, if process 1 fails but  some other process, i, has.
But  the terminat ion protocol cannot  succeed in all cases.
Usually, an extra round is added at the beginning, in which process 1 requests the commit or abort values from the other processes.
We do not need the extra round for our simplified model and problem statement.
The time bound for TwoPhaseCommit does not contradict this lower bound, because TwoPhaseCommit satisfies only the weak termination condition.
Now we describe the ThreePhaseCommit algorithm; this is an embellishment of the TwoPhaseCommit algorithm that guarantees strong termination.
The rest of the algorithm, needed to obtain the non-blocking property, is described afterward.
Process 1 collects all these values, plus its own initial value, into a vector.
If all positions in this vector are filled in with ls, then process 1 becomes ready but does not yet decide.
See Figure 7.5 for an illustration of the communication pat tern used in the failurefree runs of ThreePhaseCommit.
Before presenting the termination protocol, we analyze the situation after the first three rounds.
We classify the states of each process (failed or not) into four exclusive and exhaustive categories:
The key properties of ThreePhaseCommit are expressed by the following lemma.
Again, our round designation does not correspond exactly to the usual designation of phases for the three-phase commit protocol.
An extra request round is usually added at the beginning, as well as some explicit acknowledgments.
I f  any process's state is in decO, then no process is in dec1, and no nonfailed process is in ready.
I f  any process's state is in dec1, then no process is in decO, and no nonfailed process is in uncertain.
The most interesting part of the proof is the proof of the third condition.
Now we can prove that most of the conditions of interest hold after the first three rounds.
I f  process 1 has not failed, then all non-failed processes have decided.
The other half of the validity condition can be proved by inspection.
Finally, if process I has not failed, then we claim that every non-failed process has decided.
These three rounds alone are not enough to solve the non-blocking commit problem, however, because they do not guarantee strong termination.
But if process 1 fails, it is possible that the other processes might be left in an undecided state.
To take care of this case, the remaining processes must execute a termination protocol after the first three rounds.
The precise details can vary somewhat; we describe one possibility below.
Process 2 collects all these status values, plus its own status, into a vector.
Not all the positions in the vector need be filled in--process 2 just ignores those that are not.
Otherwise-- that  is, if the only values in the vector are uncertain and ready and there is at least one ready--process 2 becomes ready but does not yet decide.
If process 2 has (ever) decided, then it broadcasts its decision, in a decide message.
We first claim that the three properties listed in the statement of Lemma 7.22 hold after any number of rounds of the full ThreePhaseCommit algorithm, not just after three rounds as claimed.
This can be shown by induction on the number of rounds.
The other half of the validity condition is true, because if there are no failures, all processes decide within the first three rounds.
If all processes fail, then this property is vacuously true.
Then during the time when i is the coordinator, every nonfaulty process decides.
Of course, the stopping agreement algorithms yield a different validity condition, but it is possible to modify them slightly to achieve the commit validity condition.
So why are algorithms like ThreePhaseCommit considered better in practice?
The main reason is that the ThreePhaseCommit algorithm can be tailored to yield low complexity in the failure-free case.
Then it is possible to add a simple protocol whereby processes can detect that every process has decided and can then discontinue participation in the rest of the termination protocol.
With this addition, the entire algorithm requires only a small constant number of rounds and only O (n) messages.
We close this chapter (and Part  I) by considering the number of messages that must be sent in order to solve the commit problem.
ThreePhaseCommit uses somewhat more, but still O (n) if the algorithm is modified to.
We again use the definition of a communication pattern from Section 6.7
This time, we use a communication pat tern to describe the set of messages that are sent in a failure-free execution.
We do not assume, as we have done in the.
The key idea in the lower bound is stated in the following lemma.
Before proving Lemma 7.26, we give an example to show why it is.
By the validity and weak termination conditions, all processes must eventually decide 1 in a l.
But this violates the validity condition for c~, yielding a contradiction.
By the validity and weak terminat ion conditions, all processes must.
In order to complete the proof of Theorem 7.25, we must  s imply show that.
Let i be the single process that  we have assumed affects each.
Since i affects all n processes, 7 must  contain some message.
The k-agreement problem has usually been called the "k-set agreement problem" in the literature.
The problem was first introduced by Chaudhuri in [73] as a natural extension of the previously well-studied ordinary agreement problem.
Background for the algebraic topology used in the lower bound argument appears in Spanier's classical book on algebraic topology [266]
The work on approximate agreement is taken from a paper by Dolev, Lynch, Pinter, Stark, and Weihl [98]
The material on the commit problem, as well as the T w o P h a s e C o m m i t  and T h r e e P h a s e C o m m i t  algorithms, is taken from a book by Bernstein, Hadzilacos, and Goodman on database theory [50]
That  book goes much further than this one in discussing practical implementation issues for the protocols, including how to handle recovcry of failed processes.
The lower bound on the number of messages for commit is taken from work by Dwork and Skeen [106]
Give a good upper bound for the length of sequence seq(v), in the proof of Theorem 7.14
In order to do this, you will need to describe an explicit construction for the sequence.
Prove that the merge of a sequence of l-runs is in fact a k-run.
This involves showing that the conditions required in the definition of a run are satisfied, as well as the conditions involving the tokens.
Describe the Bermuda Triangle for these parameter values in detail, as well as its labelling with k-runs and process indices.
Consider the trivial algorithm A that works as follows: all processes exchange values once, and each chooses the minimum value it receives.
Can you locate a particular tiny simplex in which three different values are decided upon, for algorithm A?
Does the algorithm still solve the approximate agreement problem? Why or why not?
Prove that the approximate agreement problem can be solved in a network graph G, tolerating f Byzantine faults, if and only if both of the following hold:
Design an approximate agreement algorithm for the case of stopping failures.
Formulate a variant of the approximate agreement problem that uses a fixed number r of rounds and in which e is not predetermined.
After r rounds, the processes should output their final values.
The object is now to ensure the best possible agreement, expressed as an upper bound on the ratio of the width of the nonfaulty processes' final values to the width of the nonfaulty processes' initial values.
Hint: Use chain argument ideas similar to those used in the proof of Theorem 6.33
Write code for the complete ThreePhaseCommit algorithm (including the termination protocol)
Prove carefully that Lemma 7.22 extends to any number of rounds of ThreePhaseCommit.
Give a careful description of a modification to the ThreePhaseCommit algorithm that permits processes to decide and halt quickly in the failure-free case.
Your algorithm should use a small constant number of rounds and O (n) messages, in the failure-free case.
Chapter 6 that solves the commit problem with strong termination.
Research Question: Design an algorithm that solves the commit problem with strong termination.
Can you simultaneously obtain a worst-case numher of rounds that is n + k for some constant k, a small constant number of rounds for deciding and halting in the failure-free case, and a low communication complexity in the failure-free case?
Fill in all the details of the proof of Lemma 7.26
Design a non-blocking commit algorithm that uses the fewest messages you can manage, for failure-free runs.
Can you prove that this number of messages is optimal?
The second part consists of Chapters 8-22 and is, in fact, the bulk of the book.
These chapters make a major shift in computing paradigm, from the lockstep synchronous model studied in Chapters 2-7 to the asynchronous model, in which system components take steps at arbitrary speeds.
Like the synchronous model, the asynchronous model is not hard to describe.
The subtleties mainly involve liveness conditions, for example, requiring that each component keep getting chances to take steps.
It is, however, harder to program than the synchronous model because of the extra uncertainty in the order of events.
The asynchronous model assumes less about time than is actually guaranteed by typical distributed systems.
Thus, algorithms designed for the asynchronous model are general and portable, in that they are guaranteed to run correctly in networks with arbitrary timing behavior.
The first chapter in Part II, Chapter 8, presents a general model for asynchronous systems, the input/output automaton model.
You can skip this chapter for now if you like and refer back to it as needed.
The purpose of this chapter is to introduce a formal model for asynchronous computing, the input/output (I/O) automaton model.
This is a very general model, suitable for describing almost any type of asynchronous concurrent system, including the two types we will study in this book: asynchronous shared memory systems and asynchronous network systems.
By itself, the I /O automaton model has very little structure, which allows it to be used for modelling many different types of distributed systems.
Additional structure must be added to the basic model to enable it to describe particular types of asynchronous systems.
What the model does provide is a precise way of describing and reasoning about system components (e.g., processes or communication channels) that interact with each other and that operate at arbitrary relative speeds.
We begin with the definitions of an I /O automaton and its execution.
We then define a composition operation by which I /O automata can be combined to form a larger automaton representing a concurrent system.
We show that this composition operation has the nice properties that it should.
Then we introduce the important  notion of fairness, which specifies that all the components in a system get "fair" turns to perform steps every so often.
Fairness represents a limitation on the arbitrary relative speeds of system components-- i t  rules out the possibility that some components are permanently denied turns to take steps.
The rest of the chapter describes some conventions for specifying problems to be solved by systems described as I /O automata, as well as some proof methods that are useful for showing that the systems do in fact solve the problems.
This chapter is intended to be used as a reference for methods of modelling asynchronous sys tems--not  only the systems described in this book, but many others as well.
You need not read this chapter carefully at this point.
An I /O automaton models a distributed system component that  can interact with other system components.
It is a simple type of state machine in which the transitions are associated with named actions.
The actions are classified as either input, output, or internal.
The inputs and outputs  are used for communication with the automaton 's  environment, while the internal actions are visible only to the automaton itself.
The input actions are assumed not to be under the automaton 's  con t ro l~ they  just arrive from the outside--while the automaton itself specifies what output  and internal actions should be performed.
An example of a typical I /O automaton is a process in an asynchronous distributed system.
The interface of a typical process automaton with its environment is depicted in Figure 8.1
The automaton Pi is drawn as a circle, with incoming arrows labelled by input actions and outgoing arrows labelled by output actions.
The depicted automaton receives inputs of the form init(v)i from the outside world, which are supposed to represent the receipt of an input value v.
In order to reach a decision, process Pi may want to communicate with other processes using a message system.
Its interface to the message system consists of output actions of the form send(rn)i,j, which represents process Pi sending a message with contents m to process Pj, and input actions of the form receive(rn)j,i, which represents process Pi receiving a message with contents rn from process Pj.
When the automaton performs any of the indicated actions (or any internal action), it may also change state.
Another example of a typical I /O automaton is a FIFO message channel.
A typical channel automaton, named Ci,j, is depicted in Figure 8.2
In the usual way of describing a distributed system using I /O automata, a collection of process automata and channel automata are composed, matching outputs of one automaton with same-named inputs of other automata.
Thus, a sendi,j output performed by process Pi is identified with (i.e., performed together with) a sencli,j input performed by channel Ci,j.
The important  thing to note is that the various actions are performed one at a time, in an unpredictable order.
This is in contrast with synchronous systems, in which all the processes send messages at once and then all receive messages at once, at each round of computation.
An I/O automaton A, which we also call simply an automaton, consists of five components:
We use acts(A) as shorthand for acts(sig(A)), and similarly in(A), and so on.
We say that A is closed if it has no inputs, that is, if in(A) = O.
However, the signature allows for more general types of actions than just  the message-sending and message-receipt actions modelled in the synchronous case.
As for the set of process states in the synchrononous network model, the set of states need not be finite.
We call an element (s, 7r, s ' ) o f  trans(A) a transition, or step, of A.
Unlike in the synchronous model, the transit ions are not necessarily associated with the receipt of a collection of messages; they can be associated with arbi t rary actions.
If for a part icular state s and action 7r, A has some transit ion of the form.
Since every input action is required to be enabled in every state, automata  are said to be input-enabled.
The inputenabling assumption means that the automaton is not able to somehow "block" input actions from occurring.
This assumption means, for example, that a process has to be prepared to cope in some way with any possible message value when a message arrives.
We say that state s is quiescent if the only actions that are enabled in s are input actions.
You might think that the input-enabling property is too strong a restriction to impose on a general model, because many system components are designed to.
Or, we might require the system to detect the unexpected input and respond with an error message.
There are two major advantages of having the input-enabling property.
First, a serious source of errors in the development of system components is the failure to specify what the component does in the face of unexpected inputs.
Using a model that requires consideration of arbitrary inputs is helpful in eliminating such errors.
And second, use of input-enabling makes the basic theory of the model work out nicely; in particular, input-enabling makes it reasonable to use simple notions of external behavior for an automaton, based on sequences of external actions.
Theorem 8.4 is an example of a basic result that fails if we do not assume input-enabling.
The fifth component of the I /O automaton definition, the task partition tasks(A), should be thought of as an abstract description of "tasks," or "threads of control," within the automaton.
This partition is used to define fairness conditions on an execution of the automaton--condit ions that say that the automaton must continue, during its execution, to give fair turns to each of its tasks.
This is useful for modelling a system component that performs more than one job--for example, participating in an ongoing algorithm while at the same time periodically reporting status information to its environment.
It is also useful when several automata are composed to yield one larger automaton representing the entire system.
The partition is then used to specify that the automata being composed all continue to take steps in the composed system.
We will usually refer to the task-partit ion classes as just tasks.
We sometimes say that a task C is enabled in a state s; this is just a short way of saying that some action in C is enabled in s.
We give an example of a simple I /O automaton.
Here and in most of our descriptions of I /O automata, the transition relation is described in a preconditioneffect style.
This style groups together all the transitions that involve each particular type of action into a single piece of code.
The code specifies the conditions under which the action is permitted to occur, as a predicate on the pre-state s.
Then it describes the changes that occur as a result of the action, in the form of a simple program that is applied to s to yield s ~
The entire piece of code gets executed indivisibly, as a single transition.
This tends to make the translation from programs to I /O  automata  t ransparent ,  which makes it easier to reason formally about the automata.
As an example of an I /O  automaton, consider a communication channel automaton Ci,j.
The states, s ta tes (Ci , j ) ,  and the start  states, s tar t (Ci , j ) ,  are most conveniently described in terms of a list of state variables and their.
States: queue, a FIFO queue of elements of M, initially empty.
The transitions of Ci,j a r e  described by the following code:
This code should be self-explanatory: the send action is allowed to occur at any time and has the effect of adding the message to the end of queue, while the receive action can only occur when the message in question is at the front of queue, and has the effect of removing it.
The task partition, tasks(Ci , j ) ,  groups together all the receive actions into a single task.
That  is, the job of receiving (i.e., delivering) messages is thought of as a single task.
As a second example  of an I / O  au tomaton ,  consider  a process  aut o m a t o n  Pi.
This  a u t o m a t o n  has the ex terna l  interface descr ibed.
The  s ta tes  and s ta r t  s ta tes  are as follows:
Thus,  the i n i t  act ion causes Pi to fill in the des igna ted  value in its.
These  values can be u p d a t e d  any number  of.
The  task  par t i t ion ,  t a s k s ( P  i ) ,  contains  n tasks: one for all the.
Thus ,  sending on each channel  is r ega rded  as a single task,  as is.
Now we describe how an I /O  automaton A executes.
Note that if the sequence is finite, it must end with a state.
We denote the set of executions of A by execs(A)
A state is said to be reachable in A if it is the final state of a finite execution of A.
Sometimes we will be interested in observing only the external behavior of.
We denote the set of traces of A by traces (A)
The last two are allowed even though they contain messages that are.
This is because we have (so far) placed no restrictions on executions saying that enabled actions must occur.
In Section 8.3 we introduce fairness requirements, which allow us to express such restrictions.
In this section, we define the operation of composition and the operation of hiding output actions for I /O  automata.
The composition operation allows an automaton representing a complex system to be constructed by composing automata representing individual system components.
The composition identifies actions with the same name in different component automata.
We impose certain restrictions on the automata that may be composed.
First, since internal actions of an automaton A are intended to be unobservable by any other automaton B, we do not allow A to be composed with B unless the internal actions of A are disjoint from the actions of B.
Otherwise, A's performance of an internal action could force B to take a step.
Second, in order that the composition operation might satisfy nice properties (such as Theorem 8.4 below), we establish a convention that at most one component automaton "controls" the performance of any given action; that is, we do not allow A and B to be composed unless the sets of output actions of A and B are disjoint.
Third, we do not preclude the possibility of composing a countably infinite collection of automata,  but we do require in this case that each action must be an action of only finitely many of the component automata.
This latter restriction is needed because otherwise Theorem 8.3 (for example) fails.
The reason for allowing infinite composition is that I /O automata are used to model logical systems as well as physical systems.
A logical system can consist of a large number of logical components, intended to be implemented on a physical system with fewer components.
In fact, some logical systems allow components to be created dynamically, during execution~possibly infinitely many components over the course of an infinite execution.
For example, database systems can allow the creation of new transaction instances while the system is executing.
The way to model component creation using I /O automata is to imagine that all possible components that might ever be created arc actually present from the beginning but have special wakcup input actions that wake them up when they are supposed to be created.
With this modelling trick, the ordinary composition operator is adequate for describing the way the dynamically created components interact with the rest of the system.
But it is necessary to allow infinitely many components to be combined.
No action is contained in infinitely many sets acts(S i)
We say that a collection of automata  is compatible if their signatures are compatible.
When we compose a collection of automata,  output  actions of the components become output  actions of the composition, internal actions of the components become internal actions of the composition, and actions that are inputs to some components but outputs of none become input actions of the composition.
Thus, the states and start  states of the composition automaton are vectors of states and start  states, respectively, of the component automata.
The II notation in the definition of start(A) and states(A) refers to the ordinary Cartesian product, while the II notation in the definition of sig(A) refers to the composition operation just defined, for signatures.
Also, we are here using the notation si to denote the ith component of the state vector s.
Notice that since the automata Ai are input-enabled, so is their composition.
It follows that I-IicI Ai is actually an I /O automaton.
Notice that an action 7r that is an output of one component and an input of.
This is because we want to permit the possibility of further communication using 7r.
We would like to be able to think about this composition.
According to the way we have defined composition, A x B x C is actually isomorphic to (A x B) x C, the result of first composing A and B, then composing.
But if 7r were classified as internal in the composition A x B, then we no longer would have this modularity: the composition A x B could.
It is possible to "hide" actions that are used for communication between components, thereby preventing them from being used for further communication.
This is done using the hiding operation defined in Section 8.2.2 in addition to.
The resulting composition is a single automaton representing a distributed system.
The state of the system consists of a state for each.
A receive(v)i,j output  action, by which the first message in Ci,j is removed and simultaneously placed into Pj's variable val(i)j.
A decide(v)i output  action, by which Pi announces its current computed value.
A sample trace of this composition, for n - 2, where the value set V is N and where f is addition, is.
Of course, there are many other traces that can arise in executions of this composed system.
As in the chapters on the synchronous model, we use the convention of subscripting a variable by the index of the process at which the variable resides.
We close this subsection with three basic results that relate the executions.
The first says that an execution or trace of a composition "projects" to yield executions or.
The final theorem says that traces of component automata can also together to form a trace of the composition.
Theorem 8.3 implies that in order to show that a sequence is a trace of a system, it is enough to show that its projection on each individual system.
We now define an operation that  "hides" output  actions of an I /O automaton by reclassifying them as internal actions.
This prevents them from being used for further communication and means that  they are no longer included in traces.
In distr ibuted systems, we are usually interested only in those executions of a composition in which all components get fair turns to perform steps.
In this section, we define an appropriate notion of fairness for I /O automata.
Recall that  each I /O au tomaton  comes equipped with a part i t ion of its locally controlled actions; each equivalence class in the parti t ion represents some task that  the au tomaton  is supposed to perform.
Our notion of fairness is that  each task gets infinitely many opportunit ies to perform one of its actions.
Formally, an execution fragment c~ of an I /O automaton  A is said to be fair if the following conditions hold for each class C of tasks(A):
Here and elsewhere, we use the term event to denote the occurrence of an action in a sequence, for example, an execution or a trace.
We can understand the definition of fairness as saying that  infinitely often, each task (i.e., equivalence class) C is given a turn.
Whenever this happens, either an action of C gets performed or no action from C could possibly be performed since no such action is enabled.
We can think of a finite fair execution as an execution at the end of which the au tomaton  repeatedly gives turns to all the tasks in round-robin order, but never succeeds in performing any action since none are enabled in the final state.
We denote the set of fair executions of A by fairezecs(A)
In Example 8.1.3, the first execution given is fair, because no receive action is enabled in its final state.
The second is not fair, because it is finite and a receive action is enabled in the final state.
The third is also not fair, because it is infinite, contains no receive events, and has receive actions enabled at every point after the first step.
To further illustrate the fairness definition, consider the following Clock I /O  automaton,  representing a discrete clock.
In addition, if a request arrives, Clock responds (in a separate step) with the current value of the counter.
The following is the action sequence of an execution that is not fair:
In fact, Clock has no finite fair executions, since tick is always enabled.
We consider the fair executions of the system of three processes and.
In every fair execution, every message that is sent is eventually received.
Also, in every fair execution containing at least one initi event for each i, each process sends infinitely many messages to each other process and each process performs infinitely many decide steps.
On the other hand, in every fair execution that does not contain.
Note that fairness imposes no requirements on the occurrence of init events-- the  number of initi events involving each Pi can be finite (possibly zero) or infinite.
We close this section with a theorem that says that every finite execution (or trace) can be extended to a fair execution (or trace)
I f  a is a finite execution of A, then there is a fair execution of A that starts with a.
I f  a is a finite execution of A and/3 is any (finite or infinite) sequence of input actions of A, then there is a fair execution a.
Problems to be solved by I /O  automata normally have some type of input and output; we must model this somehow.
In the synchronous model, we generally modelled such input and output  in terms of special state variables, assuming that inputs are built into designated variables in the start  states and that outputs appear in designated write-once variables.
However, since I /O automata can have input and output actions, it is usually more natural to model inputs and outputs of systems directly, in terms of input and output actions.
I /O automata can be used not only to describe asynchronous systems precisely, but also to formulate and prove precise claims about what the systems do.
In this section, we describe some of the types of properties that are typically proved about asynchronous systems, as well as some of the methods that are typically used to prove them.
Whether the arguments are done using one of the typical methods or not, they can all be made rigorous using I /O automata.
The most fundamental type of property to be proved is an invariant assertion, or just invariant, for short.
In this book, we define an invariant assertion of an automaton A to be any property that is true of all reachable states of A.
Invariants are typically proved by induction on the number of steps in an execution leading to the state in question.
More generally, it is possible to prove invariants one (or a few) at a time, making use of the invariants previously proved when carrying out subsequent inductive proofs.
Recall that we also used invariant assertions to prove properties of synchronous algorithms.
In the synchronous setting, invariants are proved about the system state after an arbitrary number of rounds.
On the other hand, in the asynchronous setting, invariants are proved about the system state after an arbitrary number of steps.
Since the granularity of the reasoning is much smaller for asynchronous algorithms, the arguments are typically longer, more detailed, and more difficult.
An I /O automaton can be viewed as a "black box" from the point of view of a user.
What the user sees is just the traces of the automaton's executions (or fair executions)
Some of the properties to be proved about I /O automata are naturally formulated as properties of their traces or fair traces.
That  is, a t race proper ty  specifies both an external  interface and a set (in other words, a property)  of sequences observed at that  interface.
We write acts(P) as shor thand for acts(sig(P)), and similarly in(P), and so on.
In either case, the intuitive idea is that  every external  behavior that  can be produced by A is permi t ted  by proper ty  P.
Note that  we do not require the opposite inc lus ion- - tha t  every trace of P can actually be exhibi ted by A.
If fairtraces(A) C traces(P), then all of the resulting sequences must be included in the proper ty  P.
Since there is some ambigui ty  in what  we mean by an au tomaton  "satisfying a t race property," we will say explicitly what  we mean each time the issue arises.
We define a composi t ion operation for trace properties.
Then the composition P - 1-IicI Pi is the trace property such.
In this section, we define two important  special types of trace properties--safety properties and liveness properties, give two basic results about these types of properties, and indicate how such properties can be proved.
We say that a trace property P is a trace safety property, or a safety property for short, provided that P satisfies the following conditions.
A safety property is often interpreted as saying that some particular "bad" thing never happens.
We presume that, if something bad happens in a trace, then it happens as a result of some particular event in the trace; therefore, limitclosure is a reasonable condition to include in the definition.
Also, if nothing bad happens in a trace, then nothing bad happens in any prefix of the trace; thus, prefix-closure is reasonable.
Finally, nothing bad can happen before any events occur, that is, nothing bad happens in the empty  sequence A; therefore, nonemptiness is a reasonable condition.
Suppose sig(P) consists of inputs init(v), v E V and outputs decide(v), v E V.
Suppose traces(P) is the set of sequences of init and decide actions in which no decide(v) occurs without a preceding init(v) (for the same v)
For a given automaton A, the simplest to prove of these three statements is usually that the finite traces of A are all in traces(P)
This is usually proved by induction on the length of a finite execution generating the given trace.
The strategy is closely related to the strategy used to prove invariants.
In fact, by adding a state variable to A to keep track of the trace that has been generated so far, the safety property P can be reformulated as an invariant about the automaton's  state.
We say that a trace property P is a trace liveness property, or a liveness property for short, provided that every finite sequence over acts(P) has some extension in traces(P)
A liveness property is often informally understood as saying that some particular "good" thing eventually happens (though the formal definition includes more complicated statements than this)
We assume that no matter what has happened up to some point, it is still possible for the good occurrence to happen at some time in the future.
Suppose sig(P) consists of inputs init(v), v e V and outputs decide(v), v E V.
One often wants to prove that fairtraces(A) C_ traces(P) for some automaton A and liveness property P,  that is, that the fair traces of A all satisfy some liveness property.
Methods based on temporal logic work well in practice for proving such claims.
A temporal logic consists of a logical language containing symbols for temporal notions like "eventually" and "always," plus a set of proof rules for describing and verifying properties of executions.
Another method for proving liveness claims, which we call the progress function method, is specially designed for proving that some particular goal is eventually reached.
This method involves defining a "progress function" from states of the automaton to a well-founded set and showing that certain actions are guaranteed to continue to decrease the value of this function until the goal is reached.
The progress function method can be formalized using temporal logic.
In this book, we prove liveness properties informally; however, all our liveness arguments can be formalized using temporal  logic.
There are two simple theorems that describe basic connections between safety and liveness properties.
The first says that there are no nontrivial trace properties that are both safety and liveness properties.
Suppose that P is both a safety and a liveness property and let /3 be an arbi t rary  sequence of elements of acts(P)
Then since P is a safety p roper ty - - in  particular,  since traces(P) is prefix-closed--i t  must be that /3 E traces(P)
Thus, any finite sequence of elements of acts(P) must be in traces(P)
As shown in the previous paragraph,  each/3i is in traces(P)
Therefore, since P is a safety p roper ty - - in  particular,  since traces(P) is limitc losed-- i t  must be tha t /3  C traces(P)
The second theorem says that every trace property can be expressed as the intersection (or equivalently, the conjunction) of a safety property and a liveness property.
Let traces(S) be the prefix- and limit-closure of traces(P), that is, the smallest set of sequences over acts(P) that is prefix-closed and limit-closed and contains traces(P)
To see this, consider any finite sequence/3 of actions in acts(P)
In either case,/3 has an extension in traces(L), so that L is a liveness property.
So far, we have only defined safety and liveness properties for traces.
But analogous definitions can also be made for safety and liveness properties of executions, and the results are analogous to those for traces.
In future chapters, we will often classify properties of executions as safety or liveness properties.
In order to prove properties of a composed system of automata, it is often helpful to reason about the component automata individually.
In this section, we give some examples of this sort of "compositional" reasoning.
If  extsig(Ai) - sig(Pi) and traces(Ai) C traces(Pi) for every i, extsig(A) - sig(P) and traces(A) C_ traces(P)
If  extsig(Ai) - sig(Pi) and fairtraces(Ai) C traces(Pi) for every i, then e x t s i g ( A ) -  sig(P) and fairtraces(A) C traces(P)
Each process automaton Pi satisfies (in the sense of trace inclusion) a trace safety.
Also, each channel automaton Ci,j satisfies a trace safety property that asserts that the sequence of messages in receivei,j events is a prefix of the sequence of messages in sendi,j events.
Then it follows from Theorem 8.10 that the composed system satisfies the product trace safety property.
This means that in any trace of the combined system, the following hold:
For every i, any decidei event has a preceding init4 event.
Second, suppose that we want to show that a particular sequence of actions.
This typically arises if A is an abstract  system used as a problem specification.
Theorem 8.3 shows that, in order to do this, it is enough to show that the projection of the sequence on each of the system components is a trace of that component.
One strategy is to show that none of the components Ai is the first to violate P.
This strategy is useful, for example, when we want to show that a pair of components observe a "handshake protocol" between them, alternating signals from one to the other.
If we can show that neither component is the first to violate the handshake protocol, then we know that the protocol is observed.
Formally, we define the notion of an automaton "preserving" a safety property.
We say that A preserves P if for every finite sequence ~ of actions that does not include any internal actions of A, and every.
This says that A is not the first to violate P: as long as A's environment only provides inputs to A in such a way that the cumulative behavior satisfies P,  then A will only perform outputs such that the cumulative behavior satisfies P.
The key fact about preservation of safety properties is that if all the components in a composed system preserve a safety property, then so does the entire system.
Moreover, if the composed system is closed, then it actually satisfies the safety property.
If A is a closed automaton, A preserves P, and a c t s ( P ) =  ext(A), then traces(A) C_ traces ( P )
Let A be an automaton with output  a and input b, and B an automaton with output  b and input a.
Thus, A can perform a at the beginning and again each time it receives a b input.
If it receives two b inputs in a row before it has had a chance to respond with the next a, then A can only respond.
Effect: if e r r o r -  f a l s e  then.
Thus, B can only perform b once each time it receives an a input, as long as its environment does not submit two a's in a row.
If the environment does submit two a's in a row, then B sets an error flag, which allows it to output b's at any time.
It follows from Theorem 8.11 that every trace of the composition A x B is in traces(P)
In this section, we describe an important  proof strategy based on a hierarchy of automata.
This hierarchy represents a series of descriptions of a system or algorithm, at different levels of abstraction.
The process of moving through the series of abstractions, from the highest level to the lowest level, is known as successive refinement.
The top level may be nothing more than a problem specification written in the form of an automaton.
The next level is typically a very abstract representation of the system: it may be centralized rather than distributed, or have actions with large granularity, or have simple but inefficient data structures.
Lower levels in the hierarchy look more and more like the actual system or algorithm that will be used in practice: they may be more distributed, have actions with small granularity, and contain optimizations.
Because of all this extra detail, lower levels in the hierarchy are usually harder to understand than the higher levels.
The best way to prove properties of the lower-level automata is by relating these automata to automata at higher levels in the hierarchy, rather than by carrying out direct proofs from scratch.
For example, in Chapter 6, we first presented an algorithm (FloodSet) for agreement in the face of stopping failures that was liberal in its use of communication.
Then we presented an improved ("lower-level") version of the algorithm (OptFloodSet) in which many of the messages were pruned out; this yielded a smaller bound on communication.
The improved algorithm was verified using a simulation relation relating the states of the two algorithms.
The correctness proof involved showing, by induction on the number of rounds, that the simulation relation was preserved throughout the computation.
Essentially, this strategy involved running the two algorithms side by side, with the same inputs and failure pattern, and observing similarities between the two executions.
How can we extend the simulation method to asynchronous systems? The asynchronous model allows much more freedom than does the synchronous model, both in the order in which components take steps and in the state changes that accompany each action.
This makes it more difficult to determine which executions to compare.
It turns out that it is enough to obtain a one-way relationship.
We do this by defining a simulation relation between states of the two automata.
Specifically, let A and B be two I /O  automata  with the same external interface; we think of A as the lower-level automaton and B as the higher-level.
If s E start(A), then f (s) A start(B) ~ O.
If s is a reachable state of A, u E f (s)  is a reachable state of B, and (s, 7~, s') E trans(A), then there is an execution fragment c~ of B starting with u and ending with some u' E f ( s ' ) ,  such that t race (a ) -  trace(u)
The first condition, or start condition, asserts that any start  state of A has some corresponding start  state of B.
The second condition, or step condition, asserts that any step of A, and any state of B corresponding to the initial state of the step, have a corresponding sequence of steps of B.
This corresponding sequence can consist of one step, many steps, or even no steps, as long as the correspondence between the states is preserved and the external behavior is the same.
Theorem 8.12 /f  there is a simulation relation from A to B, then traces(A) C traces(B)
Proofs of correctness based on simulation relations are quite s tyl ized--so stylized.
As a simple example of a simulation proof, we show that two channel automata compose to implement another channel automaton.
Let C be the communication channel given in Example 8.1.1
Let D be the result of composing A and B and then hiding the pass actions.
Note that  C and D have the same external interface.
To see this, we define a simulation relation f from D to C.
Namely, if s is a state of D and u is a state of C, then we define.
To see that f is in fact a simulation relation, we must check the two conditions in the definition.
The start condition is trivial, because the initial states of A, B, and C are all the empty queue.
For the step condition, suppose that s is a state of D, u E f ( s )  is a state of C, and (s, 7r, s') E trans(D)
We consider cases, based on the type of action being performed.
Let the corresponding execution fragment of C consist of a single send(m) step.
The given step in D adds m to the end of s.B.queue, while the step in C adds m to the end of u.queue.
Let the corresponding execution fragment of C consist of a single receive(m) step.
The given step in D removes rn from the front of s.A.queue.
The correspondence between s and u implies that m is also at the front of u.queue, which implies that the receive(m) action is in fact enabled in u.
Then the step in C removes m from the front of u.queue.
Let the corresponding execution fragment of C consist of 0 steps.
Since the step of D does not affect the concatenation of the two queues, the state correspondence is preserved.
Simulations are sometimes also useful in helping to prove that liveness properties of B are satisfied by A.
The idea is that a simulation relation from A to B actually implies more than just trace inc lus ion~i t  implies a close correspondence, involving both traces and states, between each execution of A and some execution of B.
Such a strong correspondence, together with fairness assumptions for A, can sometimes be used to prove the needed liveness properties.
For example, here is one useful formal definition of a stronger correspondence between executions.
Let A and B be two I /O automata with the same input and output actions.
Theorem 8.13 can be used to prove a liveness property for A, assuming a.
Even though the I /O  automaton model is asynchronous, it has a natural  notion of time complexity.
For a given automaton A, we define upper time bounds for any subset of the equivalence classes in the task parti t ion tasks(A)
Specifically, for any task C, we may define a bound upperc, which can be either a positive real number or oc.
Then for any fair execution c~ of A, a real-valued time can.
From any point in c~, a task C can be enabled for time at most upperc before some action in C must occur.
Roughly speaking, this imposes an upper bound of upperc on the time between successive chances by task C to perform a step.
Notice that, for a given set of upperc bounds, there are many ways that.
The reason is that it takes at most time t~ for the last process that receives an init input to perform send events for all its neighbors.
Then it takes at most time d for all of these messages to be delivered, and then at most.
As in synchronous systems, it is sometimes useful to allow components in asynchronous systems to make random choices based on some given probability distributions.
In order to model such random choices, we augment the I /O  automaton.
An execution of probabilistic I /O automaton A is generated by means of a series of pairs of choices.
In each pair, a nondeterministic choice is made first, to determine the next transition (s, 7r, P),  and then a random choice is made, using P, to determine the next state.
The only restriction on the choices is that the nondeterministic choice of the next transition must be "fair," in the sense that all the executions generated by all possible sequences of random choices are fair executions (in the usual sense)of  the I /O automaton A/'(A)
As in the synchronous case, claims about what is computed by a randomized system are usually probabilistic.
When a claim is made, the intention is generally that it is supposed to hold for all inputs and all fair patterns of nondeterministic choices.
As in Chapter 5, a fictitious adversary is usually invented to describe these inputs and nondeterministic choices, and the automaton is required to behave well in competition with any adversary.
The I /O automaton model was originally developed in Tuttle's M.S.
Descriptions and proofs of algorithms modelled as I /O automata are sprinkled throughout the research literature on distributed algorithms; some representative examples appear in the work of Afek et al.
An example of the use of I /O automata to model systems with dynamic process creation is the framework for modelling database concurrency control algorithms presented in the book Atomic Transactions, by Lynch, Merritt, Weihl, and Fekete [207]
A good reference for temporal logic is the book by Manna and Pnueli [219]
Lamport 's  work on Temporal Logic of Actions (TLA) contains a useful temporal logic framework [184], plus a well-developed methodology for using the framework to verify algorithms.
The strategy of showing that a sequence projects to give traces of all the components of a composed system A, in order to prove that the sequence is in fact a trace of the entire system A, is used in [207]
There, the system A is an abstract specification of a database system that executes all transactions serially.
It is shown, by analyzing projections in this way, that certain sequences produced by database systems that execute the transactions concurrently are in fact traces of A.
This is the key to the correctness of these database systems.
The work on preservation of safety properties is derived from [218]
The value of the simulation method for verifying safety properties of asynchronous systems is now well established.
A fair number of proofs using simulations have been carried out with computer assistance and checking.
The modelling of randomized systems is derived from the work of Segala and Lynch [257]
General results about models for concurrent systems are well represented in the annual International Conference on Concurrency Theory (CONCUR)
Describe an execution in which m gets decided by all three processes.
Where are the compatibility conditions used? Where is the input-enabling condition used?
For each of the three automata A, B, and A x B, describe the sets of traces and fair traces.
The message channel is supposed to preserve the order of messages from the same alphabet.
Your automaton should actually exhibit all of the allowable external behaviors.
Be sure to give all the components of A: the signature, states, start  states, steps, and tasks.
For your automaton, give an example of each of the following: a fair execution, a fair trace, an execution that is not fair, and a trace that is not fair.
You do not need to show fairtraces (B) = fairtraces (A)--inclusion is enough.
I /O automaton B, also with a single task, that is "deterministic" in the sense that the following all hold:
You do not need to show fairtraces (B) = fairtraces (A)--inclusion is enough.
If these exercises can be solved with this stronger requirement, then solve them.
If P is a safety property, prove that the following three are equivalent statements about an I /O automaton A:
Formulate careful definitions of safety and liveness properties for executions, analogous to those for traces.
The next several chapters, Chapters 9-13, deal with algorithms for the asynchronous shared memory  model, in which processes take steps asynchronously and communicate via shared memory.
The first chapter in this part, Chapter 9, simply presents our formal model for asynchronous shared memory systems.
As before, skip it for now and use it as a reference.
Chapter 12 contains fundamental results on consensus in fault-prone asynchronous systems.
Finally, Chapter 13 contains a study of atomic objects--powerful abstract objects for programming distributed systems.
In this chapter, we give a formal model for asynchronous shared memory systerns.
This model is presented in terms of the general I /O automaton model for.
A shared memory system consists of a collection of communicating processes, as does a network system.
But this time, instead of sending and receiving messages over communication channels, the processes perform instantaneous operations on shared variables.
Informally speaking, an asynchronous shared memory system consists of a finite collection of processes interacting with each other by means of a finite collection.
The variables are used only for communication among the processes in the system.
However, so that the rest of the world can interact.
We model a shared memory system using I//O automata, in fact, using just.
However, that leads to some complications we would rather avoid in this book.
For instance, if each process and each variable were an I//O automaton and we combined them using.
But then the system would also have some executions in which these pairs of events are split.
This kind of behavior does not occur in the shared memory systems that we are trying to model.
One way out of this difficulty would be to consider a restricted subset of all the possible executions--those in which invocations and corresponding responses.
A second way out would be to model only the processes as.
We capture  the process and variable s t ructure  within au tomaton  A by means of.
As in the synchronous network model, we assume that  the processes in the.
Also suppose that  each shared variable x in the system has an associated set of values, valuesx, among which some are designated as the initial values, initialx.
Then each state in states(A) (the set of states of the system au tomaton  A) consists of a state in statesi for each process i, plus a value in values~ for each shared variable x.
Each state in start(A) consists of a state in start~ for each process i, plus a value in initialx for each shared variable x.
We assume that  each action in acts(A) is associated with one of the processes.
In addition, some of the internal actions in int(A) may be associated with a shared variable.
The input actions and ou tpu t  actions associated with process.
The internal actions of process i that  do not have an associated shared variable are used for local computat ion,  while the internal actions of i.
The set trans(A) of transitions has some locality restrictions, which model the process and shared variable structure of the system.
Then only the state of i can be involved in any 7r step.
Then only the state of i and the value of x can be involved in any 7r step.
The task par t i t ion  t a s k s ( A )  must  be consis tent  with the process  s t ructure:
In m a n y  cases that  we will consider,  there will be exact ly one.
Consider  a shared m e m o r y  sys tem A.
The  ou tpu t s  are of the form d e c i d e ( v ) i.
After process  i receives an i n i t ( v ) i  input ,  it accesses x.
Formally,  each set s ta tes i  consists  of local variables.
Effect: if x -- unknown then x := input output := x status := decide.
There is one task per process, which contains all the access and decide actions for that process.
It is not hard to see that in every fair execution c~ of A, any process that receives an init input eventually performs a decide output.
Moreover, every execution (fair or not, and with any number of init events occurring anywhere) satisfies the "agreement property" that no two processes decide on different values, and the "validity property" that every decision value is the initial value of some process.
We can formulate these correctness claims in terms of trace properties, according to the definition in Section 8.5.2
For example, let P be the trace property such that s i g ( P ) =  extsig(A) and traces(P) is the set of sequences/3 of actions in acts(P) satisfying the following conditions:
It is then possible to show that fairtraces(A) c_ traces(P)
Sometimes it is useful to model the environment of a system as an automaton also.
This provides an easy way to describe assumptions about the environment 's behavior.
For instance, in Example 9.1.1, we might like to specify that the environment submits exactly one initi input for each i, or maybe at least one for each i.
For shared memory systems that arise in practice, the environment can.
We describe an environment for the shared memory system A described in Example 9.1.1
The environment is a single I /O  automaton that is composed (using the composition operation for I /O  automata defined in Section 8.2.1) of one user automaton, Ui, for each process index i.
Tas ks: All local ly cont ro l led  act ions  are in one class.
Thus, Ui initially performs an initi action, then waits for a decision.
If the shared memory system produces a decision without a preceding initi or produces two decisions, then Ui sets an error flag, which allows it to output any number of inits at any time.
The presence of the dummyi action allows it also to choose not to perform outputs.
Of course, the given shared memory system is not supposed to cause such errors.
Moreover, the decide events satisfy appropriate agreement and validity conditions.
For any i,/3 contains exactly one initi event followed by exactly one decidei event.
We define a not ion of ind is t inguishabi l i ty  tha t  will be useful in some imposs ib i l i ty.
Then  we say tha t  s and s ~ are indistinguishable to process  i if the s ta te  of process i, the s ta te  of Ui, and the values of all the shared  var iables  are the same in s and.
In the general  definit ion we have given for shared  m e m o r y  sys tems,  we have not.
The  funct ion f says what  happens  when a given invocat ion arr ives  at the variable.
Note  tha t  a variable type  is not  an I / O.
Most  impor tan t ly ,  in a var iable  type,  the invocat ions and responses.
The definition we use here requires the variable to behave deterministically.
This could be generalized to allow nondeterminism, but we would rather avoid the complication here, since it is not needed for the results in this book.
Moreover, all the transitions involving x must be describable in terms of the invocations and responses allowed by the type.
Namely, each action involving x must be associated with some invocation a of the variable type.
Moreover, for each process i and each invocation a, the set of transitions involving i and a must be describable in.
In the code, we use the notation state4 to denote the state of process i.
This code means that the determination that variable x is to be accessed by process i using invocation a is made according to predicate p (which just involves the state of i)
If this access is to be performed, then the function f for the variable type is applied to the invocation a and the value of variable x to determine a response b and a new value for x.
In the descriptions of shared memory algorithms in this book, transitions.
However, theoretically, they could all be expressed in this style.
The most frequently used variable type in multiprocessors is one supporting only read and write operations.
A read/wri te  register comes equipped with an arbi t rary set V of values and an arbi t rary initial value v0 E V.
Note that  variable x in the sys tem of Example  9.1.1 cannot  be.
The s t a t u s  value a c c e s s  is.
Effect: decide( v ) i if x = unknown then Precondition:
The task  par t i t ion  again groups  together  all locally control led.
Al though this code is not  explicitly wr i t ten  in.
The invocations and responses will sometimes also include additional information such as the name of the register.
So x is a r ead /wr i t e  shared variable.
Notice that  when we rewrite the algori thm in this way, the agreement condition mentioned in Example  9.1.1 is no longer guaranteed.
Another  impor tan t  variable type allows the powerful read-modifywrite operation.
In one instantaneous read-modify-wri te  operat ion on a shared variable x, a process i can do all of the following:
It is not easy to implement  a general read-modify-wri te  operat ion.
As we have described it, it is not obvious that  read-modify-wri te.
One way to do this is to have a process.
The effect of the function h on the variable when it.
Formally, a read-modify-wri te  variable can have any set V of.
Its invocations are all the functions h, where h :  V ~ V.
That  is, it responds with the prior value and updates  its value based on the submit ted  function.
The particular hv submitted by a process uses the process's input as the value of v.
A return value of unknown causes output to be set to the value of input, while a return value of v c V causes output to be set to v.
Many of the variable types used in shared memory multiprocessors include restricted forms of read-modify-write, plus basic operations such as read and write.
Some popular restricted form of read-modifywrite include compare-and-swap, swap, test-and-set, and fetch-andadd operations.
That is, if the variable's value is equal to the first argument, u, then the operation resets it to the second argument, v; otherwise, the operation does not change the value of the variable.
In either case, the original value of the variable is returned.
The invocations for swap operations are of the form swap(u), u C V, and the responses are elements of V.
That is, the operation writes the input value u into the variable and returns the original variable value v.
The invocations for test-and-set operations are of the form testand-set, and the responses are elements of V.
That  is, the operat ion writes 1 into the variable and returns the.
Finally, the invocations for fetch-and-add operations are of the form fetch-and-add(u), u C V, and the responses are elements of V.
Tha t  is, the operation adds the input value u to the variable value.
Here, the v's are values in V, v0 is the initial value of the variable type, the.
Also, the traces of a type are the sequences of a's and b's tha t  are derived from executions of the type.
The following is a trace of a read /wr i te  variable type with V = N.
We finish this section by defining a simple composition operat ion for variable types.
This lets us regard a collection of separate variable types, each with its own operations, as a single variable type with several components,  and with.
The set V is the Cartesian product  of the value sets of the Ti.
The set of invocations is the union of the sets of invocations of the 7~
The set of responses is the union of the sets of responses of the 7i.
The function f operates "componentwise." That  is, consider f (a ,  w), where a is an invocation of ~
It returns b and sets the ith component of w to v.
When I is a finite set, we sometimes use the infix operation symbol x to denote composition.
We describe the composition of two read/wr i te  variable types Tz and.
You should think of x and y as the names of two registers.
Suppose the value sets are V~ and try, respectively, and the initial values are Vo,x and Vo,y.
We can only compose these two types if they are compatible.
So we disambiguate the invocations and responses of the two types by.
Its invocations are readx, read v, write(v)x, v C Vx, and write(v)y, v C try.
Then f is defined for w by f(readx, w) = (Vx, w), f(ready, w) - (Vy, w), f (write(v")~,  w) - (ackx, (v", v')), and f (wri te(v")y,  w) = (acky, (v, v"))
Thus, a read returns the indicated component of the vector, while a write updates the indicated component.
Such an upper bound allows us to prove upper bounds on the time required for events of interest to.
More precisely, we establish a time complexity measure for shared memory systems as a special case of the time complexity measure defined for general I /O  automata  in Section 8.6
Likewise, we measure the time between two events of interest by the supremum of the differences between the.
Note that our time measure does not take into account any overhead due to.
In multiprocessor settings where such contention is an issue, the time measure must be modified accordingly.
Other interesting measures of complexity for shared memory systems include.
The stopping failure of a process i in a shared memory system is modelled using.
More precisely, a stopi event can change only the state of process i, although we do not constrain these state changes.
We leave open the issue of whether later inputs to process i are ignored, or cause the.
Figure 9.3 depicts the architecture for an asynchronous shared memory system with stopping failures.
A probabilistic shared memory system is defined by specializing the general definition of a probabilistic I /O automaton in Section 8.8 to the case where the I /O.
There are no special references for the basic model described in this chapter.
Another model for shared memory systems was defined by Lynch and Fischer [216]; in that model, processes communicate by means of instantaneous accesses to shared variables, but not by means of external events.
Rudolph, and Snir [171] defined the various types of variables used in shared memory multiprocesssors.
Dwork, Herlihy, and Waarts [103] have suggested a time complexity measure that takes into account contention for shared memory access.
The formal modelling of probabilistic shared memory systems is derived from work by Lynch, Saias, and Segala [208]
Let A be the shared memory system described in Example 9.1.1
Your property should include mention of what can happen where there is more than one initi action for the same process i.
One way to do this is to reformulate Q as the intersection of a safety property S and a liveness property L.
The fact that A preserves S could be argued from the fact that traces(A) C traces(P)
If not, then give a counterexample and then state and prove the strongest claims you can for the system's behavior.
Research Question: Define an alternative model for shared memory systems by using I /O  automata  to model processes only, and by defining a new type of state machine (similar to the model for variable types) for shared variables.
Define an appropriate composition operation to combine "compatible" process and shared variable automata  into a single I /O  automaton to model the entire system.
What  modifications are needed to the results in subsequent chapters to fit them to your new definitions?
In this chapter, we begin the study of asynchronous algorithms.
Asynchronous algorithms are generally quite different from synchronous algorithms, since they must cope with the uncertainty imposed by asynchrony as well as the uncertainty caused by distribution.
In asynchronous networks, for example, process steps and message deliveries do not necessarily take place in lock-step synchrony; rather, they may happen in an arbitrary order.
Instead of moving immediately to the study of asynchronous network algorithms, we first study algorithms in the asynchronous shared memory setting.
The main reason we do this is that the setting is somewhat simpler.
But also, as you will see in Chapter 17, there are close connections between the asynchronous shared memory model and the asynchronous network model.
For instance, it is possible to translate algorithms written for the asynchronous shared memory model into versions that can run in asynchronous networks.
In this chapter and Chapter 11, we will not consider failures very much; asynchrony alone introduces enough interesting complications for now.
The problem we study here is the mutual ezclusion problem, a problem of managing access to a single indivisible resource (e.g., a printer) that can only support one user at a time.
Alternatively, it can be viewed as the problem of ensuring that certain portions of program code are executed within critical regions, where no two programs are permitted to be in critical regions at the same time.
It is not known which users are going to request the resource nor when they will do so.
This problem arises in both centralized and distributed operating systems.
We present several mutual exclusion algorithms for the read/wri te  shared memory model, starting with an early algorithm by Dijkstra.
Subsequent algorithms improve on Dijkstra's by guaranteeing fairness to the different users and by weakening the type of shared memory that is used.
Finally, we give a collection of upper and lower bound results for the case where the shared memory consists of stronger, read-modify-write shared variables.
The main reason for its length is that we are using it not just to present a collection of algorithms and impossibility results, but also to introduce many ideas that will be used in the rest of the book.
These include techniques for modelling shared memory systems and their environments, statements of correctness conditions for asynchronous algorithms (including safety, progress, and fairness conditions), proof techniques for asynchronous algorithms (including operational, invariant assertion, and simulation relation proofs), ways of defining and analyzing time complexity for asynchronous algorithms, and techniques for proving lower bounds.
Before we begin describing any algorithms, we describe the computation model we will use in this and the next three chapters.
The system is modelled as a collection of processes and shared variables, with interactions as depicted in Figure 10.1
Each process i is a kind of state machine, with a set statesi of states and a subset start4 of statesi indicating the start states, just as in the synchronous setting.
However, now process i also has labelled actions, describing the activities in which it participates.
These are classified as either input, output, or internal actions.
In Figure 10.1, the arrows entering and leaving the process circles represent the input and output actions of the various processes.
We further distinguish between two different kinds of internal actions: those that involve the shared memory and those that involve strictly local computation.
If an action involves the shared memory, we assume that it only involves one shared variable.
Unlike in the synchronous setting, there is no message-generation function, since there are no messages in this model.
All communication between the processes is via the shared memory.
We call these combinations of process states and variable values "automaton states" because, in the formal model of Chapter 9, the entire system is modelled as a single automaton.
Note that  trans is a relation rather than a func t ion- - for  convenience, we allow our model to include nondeterminism.
We assume that  input actions can always happen,  that  is, that  the system is.
In contrast ,  ou tput  and internal steps might  be enabled only in a subset of the states.
The set of t ransi t ions  has some "locality" restrictions.
First ,  for any transit ion that  does not involve the shared memory, only the state of the process that.
On the other hand, for a t rans i t ion  that.
We assume that the enabling of a shared memory action depends only on the process state and not on the value of the shared variable accessed.
However, the resulting changes to the process state and the variable value may depend also on the variable value.
The shared variable steps are usually constrained further, to be executions of operations of particular types, such as read and write.
A read step for variable x involves changing the process state, based on its previous state and the value in x; however, the value of variable x does not change.
A write step involves writing a designated value to a shared variable, overwriting whatever was there before; it may also change the process state.
We will mostly consider the model in which the variables are accessed using read and write operations, but we will also consider some more powerful operations such as read-modify-write.
The execution of an asynchronous shared memory system is very different from that of a synchronous system.
This time, processes are assumed to take steps one at a time, in an arbitrary order rather than in synchronized rounds.
This arbi t rary  order is the essence of the asynchronous model.
An execution may be a finite or an infinite sequence.
There is one important  exception to the arbitrariness in the order of process steps.
We do not want to allow a process to stop taking steps when it is supposed to be taking steps, that is, when the process is in a state in which some locally controlled action (i.e., a non-input action) is enabled.
Although input actions are always enabled, we do not assume that they ever occur.
For example, we might t ry to express it by saying: "If a process takes only finitely many steps, then its final state is one in which no locally controlled action is enabled." But this is not quite su i~c ien t~we might want also to rule out some situations in which a process takes infinitely many steps, but after some point, all the remaining steps are input steps.
We need to make sure that the process itself also gets turns to perform locally controlled actions.
So, we might t ry to express the needed condition by saying: "If a process takes only finitely many steps, then its final state is one in which no locally controlled action is enabled, and if a process takes infinitely many steps, then infinitely many of these steps are locally controlled steps." But again this is not quite r ight - -consider  the situation in which the process receives infinitely many inputs and performs no locally controlled actions, but in fact no locally controlled actions are enabled.
We account for all these possibilities in the following definition.
For each process i, we assume that one of the following holds:
We call this condition the fairness condition for this shared memory system.
In terms of the I /O  automaton definitions in Chapter  8, this amounts to grouping all the locally controlled actions of one process into one task.
The resource could be, for example, a printer or other output  device that requires exclusive access in order to ensure that the output  is.
Or it could be a database or other data structure that requires exclusive.
A user with access to the resource is modelled as being in a critical region, which is simply a designated subset of its states.
When a user is not involved in any way with the resource, it is said to be in the remainder region.
In order to gain admit tance to its critical region, a user executes a trying protocol, and after it is done with the resource, it executes an (often trivial) exit protocol.
This procedure can be repeated, so that each user follows a cycle, moving from its.
We consider mutual exclusion algorithms within the shared memory model.
The inputs to process i are the tryi action, which models a request by user Ui for access to the resource, and the exiti action, which models an announcement by user Ui that it is done with the resource.
The outputs  of process i are criti, which models the granting of the resource to Ui, and rerni, which tells Ui that it can continue with the rest of its work.
The external interface (formally, the external signature) of Ui is depicted in Figure 10.3
We think of each user Ui as executing some application program.
Then we require that Ui preserve the trace property defined by the set of sequences.
We use the definitions of trace property and preserves from Section 8.5.4
In executions of Ui that do observe the cyclic order of actions, we say that.
During this time, Ui should be thought of as being free to use the resource (although we do not model the resource explicitly)
Now we can state what it means for a shared memory system A to solve the.
Namely, the combination (formally, the composition) of A and the users must satisfy the following.
We say that a shared memory system A solves the mutual exclusion problem provided that it solves it for every collection of users.
Note that we have stated the correctness conditions in terms of the users'
Normally, the process states will also be classified according to their.
So we can equivalently state the correctness conditions in terms of process regions.
We will talk interchangeably about user regions and process regions in the rest of this.
Note that the progress condition assumes that the execution of the system is fair, that is, it assumes that all the processes (and users) continue taking steps.
If we did not assume this, then it would not be reasonable to require that cr i t or re in  outputs eventually be performed.
On the other hand, we do not need to assume fairness in order to require that the system guarantee well-formedness or mutual exclusion.
The difference is that the well-formedness and mutual exclusion conditions are s a f e t y  p r o p e r t i e s  (properties that say that particular "bad" things never happen), while the progress condition is a l i v e n e s s  p r o p e r t y (a property that says that some "good" thing eventually happens)
Still another equivalent way of presenting these correctness conditions is in terms of a t race  p r o p e r t y ,  as defined in Section 8.5.2
For example, we can define a trace property P,  where s i g ( P )  has all the try,  crit ,  exit ,  and.
Then an equivalent restatement of the mutual exclusion problem is the requiremenU that, for all combinations B of A with users, fairtraces(B) C_ traces(P)
Recall that the external actions of B are just the try, crit, exit, and rein actions.
Trace property P could also be split into two parts, a safety property encompassing the well-formedness and mutual exclusion conditions, and a liveness property for the progress condition.
According to the correctness conditions we have given, responsibility for the continuing progress of the entire system rests not only with the protocol, but with the users as well.
But if each user eventually returns the resource every time it receives it, then the progress condition implies that the entire system continues to make progress, repeatedly moving processes to new regions (unless all users remain in their remainder regions from some point on)
The progress condition we have stated does not imply that any particular requesting user ever succeeds in reaching its critical region.
Rather, it is a "global" notion of progress, saying only that some user reaches its critical region.
For instance, the following scenario does not violate the progress condition: Starting from an initial state, user U1 enters T.
Our progress condition does not guarantee that U1 ever reaches C.
There is one other cons t ra in t - -a  technical one- - tha t  we assume in this chapter: that a process within the shared memory system can have a locally controlled action enabled only when its user is in.
This says that a process can be actively engaged in.
This assumption is consistent with the view that each process is simply an agent for its corresponding user.
In practical settings, this assumption might or might not be reasonable.
In this setting, allowing a permanent process to manage access to the resource would cause extra context-switching, between the manager process and the user processes.
In a true multiprocessor environment, it is possible to avoid.
However, there will generally be many resources to be managed, and all the processors dedicated to managing resources would be unavailable for participation in other computational tasks.
In one step, a process can either read or write a single shared.
Thus, the two actions involving process i and register x are.
We finish this section with a simple lemma saying that processes cannot stop.
I f  process i is in its trying or exit region in state s, then some locally controlled action of process i is enabled in s.
Let c~ be a finite execution of B ending in s, and suppose for the sake of.
This follows from the fact that enabling of locally controlled actions is determined only by the local process state, plus the fact that well-formedness prevents inputs to process i while process i is in T or E.
Repeated use of the progress assumption, plus the fact that the users always return the resource, imply that process i must eventually.
The first mutual exclusion algorithm for the asynchronous read/wr i te  shared memory model was developed in 1965 by Edsger Dijkstra, based on a prior twoprocess solution by Dekker.
This algorithm is not the most elegant or efficient algorithm now available, nor does it satisfy the strongest conditions.
First, it is the earliest example we can find of an algorithm that we would categorize as "distributed." Second, it contains several interesting algorithmic ideas.
And third, it is a good example to use for illustrating some of the basic reasoning techniques for asynchronous shared memory algorithms.
We begin by presenting code for the algorithm in a traditional "pseudocode" style, similar to that used in the original paper by Dijkstra.
Although this code should make sense informally, it is probably not completely clear how it should be t ranslated into an instance of our model.
L: try i f lag(i):= 1 while  turn r i do.
In process i's first stage, it starts by setting its flag to 1 and then repeatedly checks the turn variable to see if t u r n -  i.
Once having seen t u r n -  i, process i moves on to the second stage.
This check of other processes'  flags can be done in any order.
If the check completes successfully, process i goes to its critical region; otherwise, it returns to the first stage.
Before we can prove anything about DijkstraME, we need to understand it.
First,  the state of each process should consist of the values of its local variables, as you would expect, plus some other information that is not represented explicitly in the code, including.
The unique start state of each process should consist of specified initial values for local variables, arbitrary values for temporary variables, and the program counter and the region designation indicating the remainder region.
The initial value for each shared variable is as specified.
The steps of the automaton should follow the code; however, there are some ambiguities in the code that need to be resolved in the automaton.
Although the code describes the changes to the local and shared variables, it does not say explicitly what happens to the implicit variables (the temporaries, program counter, and region designation)
For example, when a tryi action occurs, i's program counter should move to statement L in the code and i's region designation should become T.
The code also does not specify exactly which portions of the code comprise indivisible steps.
However, it is essential to know this in order to reason carefully about the algorithm.
For DijkstraME, the indivisible steps are the try, crit, exit, and rein steps at the user interface, plus individual writes to and reads from the shared variables, plus some local computation steps.
There is at least one minor subtlety: the test for whether flag(turn) = 0 does not require two separate reads--since turn was just read in the previous line, a local copy of turn can be used.
Rewriting in this way makes the code a good deal longer, but all the transitions are now described explicitly.
For readability, we arrange the pieces of code for the different actions in approximately the order in which they are supposed to be executed; however, note that this order has no significance in the formal model - -any  action is allowed to occur at any time when it is enabled.
The region designations R, T, C, and E are encoded into program counter values: R corresponds to rein; T corresponds to set-flag-i, test-turn, test-flag, set-turn, set-flag-2, check, and leave-try; C corresponds to crit; and E corresponds to reset and leave-exit.
A c t i o n s  of  i: Input :  Internal :
Effect: Precondi t ion: pc :=  set-flag-1 pc = set-turn.
Note that the new style makes it easy to express slight improvements; for instance, the set- turni  action can allow process i to go directly to the second stage, without retesting turn.
In this section we sketch a correctness proof for Dijks traME.
In the following section, Section 10.3.3, we give an alternative, more stylized proof of the mutual exclusion condition using invariant.
We give three lemmas showing that Di jk s t raME satisfies its requirements.
More precisely, we mean that in any execution of the combination (composition) of Di jk s t raME and any collection of users, the subsequence describing the.
By inspection of the code, it is easy to check that Di jk s t raME preserves well-formedness for each user.
Since, by assumption, the users also preserve wellformedness, Theorem 8.11 implies that the system produces only well-formed.
More precisely, we mean that in the combination of Di jk s t raME and any collection of users, there is no reachable state in which more than one user is in.
I j finds f l ag ( i )  :t 2 cri t j.
Assume that Ui and Uj, i r j, are simultaneously in region C in some reachable state.
By the code, both process i and process j perform set-flag-2 steps before entering their critical regions.
Then flag(i) remains equal to 2 from that point until process i leaves C, which must be after process j enters C, by the assumption that they both end up in C simultaneously.
But, during this time, process j must test flag(i) and find it unequal to 2, a contradiction.
The argument for the exit region is easy: If at any point in a fair execution, Ui is in the exit region, then process i keeps taking steps.
After at most two more of these steps, process i will perform a rerni action, sending Ui to its remainder region.
Suppose for the sake of contradiction that a is a fair execution that reaches a point where there is at least one user in T and no user in C, and suppose that after this point, no user ever enters C.
First, any process in E keeps taking steps, so after at most two steps, it must reach R.
So, after some point in c~, every process must be in T or R.
Second, since there are only finitely many processes in the system, after some point in c~, no new processes enter T.
Clearly, if turn is modified during c~1, it is changed to a contender's index.
Suppose not, that is, suppose the value of turn remains equal to the index of a non-contender throughout C~l.
If pc/ever reaches test-turn (i.e., the beginning of the while loop in the original code), then we claim that i will set turn to i.
Then it performs a testf lag(j)i  and finds f lag(j) = 0, since j is not a contender.
The only way it might not is if i succeeds in its checks of all the other processes' flags (in the second stage of the original code) and proceeds to leave-try.
But by assumption about c~1, we know that i does not reach C.
So it must be that some check must fail, taking i back to set-flag-i, from which it proceeds to test-turn.
So, i reaches test-turn and thereafter sets turn := i.
Since i is a contender, this is the needed contradiction.
Once turn is set to a contender's index, it is always thereafter equal to some contender's index, although the value of turn may change to the index of different contenders.
This is because it is possible for several processes to be simultaneously at set-turn.
Thus, turn will not be changed as a result of these tests.
Let c~2 be a suffix of C t l  in which the value of turn is stabilized at some contender's index, say i.
Next we claim that in c~2, any contender j -r i eventually ends up with its program counter looping forever between test-turn and test-flag.
That is, it winds up looping forever in the while loop.
This is because if it ever reaches check (in the second stage), then, since it doesn't  reach C, it must eventually return to set-flag-1
Note that this means that all contenders other than i have their flag variables equal to 1 throughout.
We conclude the argument by claiming that in c~3, process i (the one whose index is in turn) has nothing to stand in the way of its reaching C.
For example, if i performs test-turn, then i finds turn = i and so proceeds to set-flag-2
Then, since no other process has flag = 2, process i succeeds in all its checks and enters C.
See Figure 10.6 for a depiction of the successive suffixes that appear in this proof.
Although the arguments above are correct, they are rather intricate and ad hoc.
It would be nice to have some more systematic ways of carrying out such proofs.
In the following section, we give an alternative proof of the mutual exclusion condition, using invariant assertions.
In the synchronous network model, many of the neatest and most systematic proofs are based on invariant assertions about the state of the system after some number of rounds.
In the asynchronous setting, there is no notion of round, but invariants can still be used.
The method just has to be applied at a finer granularity, to verify claims about the system state after any number of individual.
Of course, it is usually harder to devise statements about the state of an asynchronous system after any number of steps than it is to devise statements about the state of a synchronous system after any number of rounds.
We now give an assertional proof of the mutual  exclusion condition for the.
We would like to prove this assert ion by induction on the number  of steps in.
But,  as usual, the given s ta tement  is not s trong enough to prove.
Then by Assert ion 10.3.2, ISil = ISjl = n.
Assert ion 10.3.2 can be proved easily by induction on the length of an execution.
The basis is t rue vacuously, since all the processes are in R in the initial.
The inductive step is a case analysis, considering all the types of.
In this case, the only steps that  could cause a violation are.
Recall that a system state is a combination of states of the users and processes plus values of the shared variables.
This is also proved by a simple induction on the length of an execution.
For the inductive step, the only events that could cause a violation of this s ta tement  are events that  cause.
The second fact says that  flag(i) = 2 when process i is at certain points in its code.
This is also proved by an easy induction on the length of an execution.
Now we can prove Assert ion 10.3.3, again by induction on the length of an.
The basis is easy because in the initial state, all sets Si are empty.
For the inductive step, the only event that could cause a violation is one that.
So consider the case where j gets added to Si as a result of a check(j)i event.
In this section, we prove an upper bound on the time from any point in an.
The first difficulty we face in proving such a bound is that it is not clear what.
Instead,  we just  assume that each step occurs at some point in real t ime.
We also assume an upper  bound of c on the max imum time that.
The constant involved in the big-O is independent of g, c, and n.
This proof is ad hoc and a little tricky, using ideas from the proof of the progress condition.
Suppose the lemma is false and consider an execution in which, at some point, process i is in T and no process is in C, and in which no process enters C for time at least k~n, for some particular large constant k.
Constant  k is chosen to be considerably bigger than the constants in the big-O terms in the following analysis.
First,  it is easy to see that the time elapsed from the starting point of the analysis until there is no process either in C or E is at most O (g)
Second, we claim that the additional time until process i performs a test-turni is at most O (~n)
This is because i can at worst spend this much time checking flags in the second stage before returning to set-flag-1
We know that it must re turn to set-flag-I, because otherwise it would go to C, which we have assumed does not happen this quickly.
Third, we claim that the additional time from when process i does test-turni until the value of turn is a contender index is at most O (~)
To see this, we need a rather annoying case analysis.
If at the time i does test-turni, turn already holds a contender index, then we are done, so suppose that this is not the case; specifically, suppose that turn = j ,  where j is not a contender.
If process i finds f lag(j)  = 0, then i sets turn to i, which is the index of a contender, and we are again done.
If turn has not changed in the interim, then turn is equal to the index of a contender (j) and we are done.
But if turn has changed in the interim, then it must have been set to the index of a contender.
Sixth and finally, within an additional time O (gn), j must succeed in entering C.
This contradicts the assumption that no process enters C within this amount of time.
I i i n T , no process in C.
The order of events in this proof, and the time bounds between them, are depicted in Figure 10.7
Although the DijkstraME algorithm guarantees mutual exclusion and progress, there are other desirable conditions that it does not guarantee.
It does not guarantee that the critical region is granted fairly to different users; for example, it allows one user to be repeatedly granted access to its critical region while other users trying to gain access are forever prevented from doing so.
Note that the kind of fairness we are talking about here is different from that discussed up to this point.
So far, we have been talking about fair execution of process steps (and user automata steps), whereas now we are talking about fair granting of the resource.
In order to distinguish these two types of fairness, we will call the fair execution of process steps and user automata steps low-level fairness, and the fair granting of the resource high-level fairness.
In practice, high-level fairness might not be critical; in many practical situations in which mutual exclusion is used, contention between users is sufficiently infrequent that a user can afford to wait until all conflicting users get their turns.
Such a variable is difficult and expensive to implement in many kinds of multiprocessor systems (as well as in nearly all message-passing systems)
Many mutual exclusion algorithms that improve upon DijkstraME in various ways have been designed.
In the rest of this chapter, we shall look at a representative collection of these algorithms.
Before proceeding to the algorithms, we define carefully what it means for a mutual exclusion algorithm to guarantee high-level fairness.
Depending upon the context in which the algorithm is used, different notions of high-level fairness may be appropriate; we define three notions.
Each of these properties is stated for a particular mutual exclusion algorithm A composed with a particular collection.
Note that the lockout-freedom condition, like the basic well-formedness, mutual exclusion, and progress conditions, can be expressed as a trace property.
Note that the value of b will typically be a function of t~ and c.
During this interval, any other user j ,  j :fi i, can only enter C at most a times.
However, in most algorithms, the exit regions are actually trivial.
We say that algorithm A is l o c k o u t - f r e e  provided that it guarantees lockoutfreedom for all collections of users.
I f  B has any finite bypass bound and is lockout-free for the exit region, then B is lockout-free.
Consider a low-level-fair execution of B in which all users always return the resource, and suppose that at some point in the execution, i is in T.
Assume for the sake of contradiction that i never enters C.
Lemma 10.1 implies that eventually i must perform a locally controlled action in that trying region, if it has not already done so.
Repeated use of the progress condition and of the assumption that users always return the resource together imply that infinitely many total region changes occur.
But then some process other than i enters C an infinite number of times while i remains in T, which violates the bypass bound.
I f  B has any time bound b (for both the trying and the exit region), then B is lockout-free.
Consider a low-level-fair execution of B in which all users always return the resource, and suppose that at some point in the execution, i is in T.
Associate times with the events in the execution in any monotone nondecreasing, unbounded way, so that the times for the steps of each process are at most.
The first improvements that we present are a trio of algorithms developed by Peterson, all of which guarantee lockout-freedom.
The first algorithm is for two processes only, but it demonstrates most of the basic ideas.
We start  with the two-process solution, which we call Peterson2P.
The code, in a tradit ional style, is given below.
But this time, process i immediately proceeds to set turn  : -  i.
It then waits to discover either that the other process's.
That  is, either the other process is not currently involved in the competit ion at all, or else the turn  variable has been reset by the other process since the most recent time when i set it.
Thus (and slightly strangely),  having the turn  variable set to the index of the other  process gives.
How can this program be t ranslated into a state machine in the formal model?
As before, we need to introduce a program counter, t emporary  variables, and a.
An ambiguity in the code that needs to be resolved is the.
For correctness, it is necessary that both checks be done repeatedly;
Here, the region designation R corresponds to rein; T corresponds to set-flag, set-turn, check-flag, check-turn, and leave-try; C corresponds to crit; and E corresponds to reset and leave-exit.
A c t i o n s  o f  i: Input :  Internal:
That  is, if i has won the competition, and if i is a competitor,  then the turn variable is set favorably for i, that is, set to the value i.
In the inductive step of the proof of Assertion 10.5.2, the key events to check are.
Suppose for the sake of contradiction that a is a low-level-fair execution that reaches a point where at least one of the processes, say i, is in T and neither process is in C, and suppose that after this point, neither process ever enters C.
First, if i is in T sometime after the given point in a,  then both processes must get stuck permanently in their check loops, since neither ever enters C.
But this cannot happen, since turn must stabilize to a value that is favorable to one of them.
On the other hand, suppose that i is never in T after the given point in c~
In this case, we can show that flag(i) eventually becomes and stays equal to 0, contradicting the assumption that i is stuck in its check loop.
The argument for the exit region is trivial; we consider the trying region.
We show the stronger condition of two-bounded bypass and invoke Theorem 10.8
Suppose the contrary, that is, that at some point in execution a, process i is in T after having performed set-flagi, and thereafter, while i remains in T, process i enters C three times.
But set-turni is only performed once during one of i's trying regions.
As for the analysis of DijkstraME, let t~ and c be upper bounds on process step time and critical section time, respectively.
You might want to reread our discussion at the beginning of Section 10.3.4 to be sure you.
Suppose the bound does not hold and consider an execution in which process i is in T at some point, but does not enter C for time at least.
First,  within time at most 3t~, process i performs check-flagi.
This can be seen by a case analysis, based on the various places where i might be in its t rying region.
Note that i cannot succeed in any of its checks during this time, because if it did, it would go to C within time O (t~), which we have assumed does not happen.
But the former case would again mean that i would reach C too soon, so the.
Now i performs check-flagi again, within additional time O (~)
This means that ~ has entered T again, after the resets.
Then either turn already has taken on the value i, or will do so within additional time t~
Then within at most another time O (t~), process i finds conditions favorable for it to enter C.
This contradicts the assumption that i does not enter C within this amount  of time.
Figure 10.8 shows the order of events in this proof and the time bounds between them.
At each successive competition, the algorithm ensures that there is at least one loser.
Orde r  of events  and t ime bounds  in the p roof  of T h e o r e m  10.14
In general, at most  n -  k processes can win at level k.
We call the a lgori thm P e t e r s o n N P.
That  is, either none of the other processes is currently involved in the level k competition, or else the turn(k) variable has been reset by some other process since i most recently set it.
As before, there are some ambiguities in the code that need to be resolved.
First, one of the conditions in the waitfor statement involves the flag variables for all the other processes.
In our model, these variables cannot all be checked simultaneously.
Rather, we intend that the variables be checked one at a time, and we regard the condition as satisfied if all the values seen during these checks are less than k.
Second, we need to specify some conditions on the order in which process i checks the various flag variables and the turn(k) variable, in the waitfor statement.
For simplicity, we assume that process i cycles through the.
Note the use of the local variable level to keep track of which competition the process is engaged in (or is ready to engage in) and the use of S to keep track.
A c t i o n s  of  i: Input: Internal:
Effect: if f l a g ( j ) <  level then.
I n  a n y  s y s t e m  s t a t e  of  P e t e r s o n N P ,  we s a y  t h a t  a p r o c e s s  i is a w i n n e r  at  level.
An impor tan t  difference is that  now the assert ion must  deal with intermediate stages in the process of.
I f  process i is a winner at level k and if any other process is a competitor at level k, then turn(k) r i.
The proof, by induction as usual, is left as an exercise.
The proof of Assert ion 10.5.5 is also an induction, but  not on the length of.
Then Assert ion 10.5.3 implies that  the value of turn(l) cannot  be the index of any of the processes, a contradict ion.
Suppose for the sake of contradict ion that the s ta tement  is false for.
Every winner at level k + 1 is also a winner.
But  every compet i tor at level k + 1 is a winner at level k, and so is in W.
In order to prove progress, it is enough to prove lockout-freedom (see Exercise 10.6)
And Theorem 10.9 implies that  lockout-freedom is in turn  implied by a time bound.
A time bound for the exit region is trivial; the following theorem gives a time bound for the t rying region.
Warning: We do not claim that  this bound is t i gh t - -we  leave it as an exercise to t ry  to t ighten i t - - b u t  any bound is enough to prove lockout-freedom.
Define T(0) to be the maximum time from when a process enters T until it enters C.
Then within addit ional  time T(k + 1), i enters C.
Thus, we need to solve the following recurrence for T(0):
See the following subsection, Section 10.5.3, for a more detailed solution for a similar recurrence.
Another  way to extend the basic Peterson2P algori thm to more processes is to use a version of the basic two-process a lgori thm as a building block in a tournament.
Each process engages in a series of log n competi t ions in order to obtain the resource.
We need some notat ion to name the various competit ions,  the roles played by the processes in all of the competi t ions,  and the set of potential  opponents that  all the processes can have in all the competit ions.
In particular,  the root is named by A, the empty  string.
In terms of the tournament tree, the processes in opponents(i, k) are those whose leaves are descendants of the opposite child of node comp(i, k), that is, of the child that is not an ancestor of i's leaf.
This  code is very much like that  of the PetersonNP algori thm.
The main difference is that  in each compet i t ion ,  the process  only checks the flags of its.
As in PetersonNP,  we assume that  a process checks its opponents  in any order, one at a time.
We only sketch the correctness  a rguments  for the Tournament  a lgor i thm briefly, since the ideas are so similar  to those for the PetersonNP and Peterson2P algori thms.
Firs t ,  the a lgor i thm should be rewri t ten  in precondit ion-effect  style, making.
The proof uses the same ideas as the invariant assert ion proofs.
This follows immediately from an invariant analogous to the second par t  of Assert ion 10.5.3
We must  s t rengthen it as before to include some information about  what  happens inside the waitfor loop, after the process has discovered that  some of its opponents have flag variables with values that  are strictly less than k.
In order to show progress and lockout-freedom, we prove a time bound.
Define T(0) to be the max imum time from when a process enters T until it enters C.
Then,  within addit ional  time T(k  + 1), i enters C.
Wi th in  another  T(k + 1), i enters C.
The Tournament algori thm does not guarantee  any bound on the number  of bypasses.
Meanwhile, process n -  1 enters the tournament  at its leaf, going much faster.
This is possible because we have not assumed any lower bound on process step times.
Note that there is no contradiction between unbounded bypass and a time upper bound.
No process is locked out for very long-- the  unbounded bypasses only occur because some processes operate very fast.
The mutual  exclusion algorithms we have studied so far use multi-writer shared registers (the turn variables) as well as single-writer shared registers (the flag variables)
Because multi-writer registers are often difficult to implement,  it is worth investigating algorithms that use only single-writer shared registers.
In this section and the next, we present two such algorithms.
The algorithm in Section 10.7 is also lockout-free, but it has the disadvantage of using unbounded size variables.
We call the first algorithm BurnsME, after Burns, its inventor.
The first two loops involve checking the flags of all processes with smaller indices, while the third loop involves checking the flags of all processes with larger indices.
If process i passes all the tests in all three loops, it proceeds to its critical region.
The proof is similar to the first (operational) proof that  DijkstraME satisfies mutual  exclusion (see Lemma 10.3)
Thus, if processes i and j are simultaneously in C, then assume that  i sets.
Then flag(i) keeps the value 1 until process i leaves C.
This check must  occur during the interval when the value of flag(i) = 1, which yields a contradiction.
Note that  the first for loop in the code is not needed for the mutual  exclusion condition.
For the t rying region, we assume for the sake of contradict ion that  a is a low-level-fair execution that reaches a point where there is at least one process in T and no process in C, and that  after this point, no process ever enters C.
Arguing similarly to the way we did in the proof of Lemma 10.4, we can assume without  loss of generali ty that every process is in T or R and that  no process changes region, in a.
Now we part i t ion the contenders into two sets: those that  ever reach label M and those that  never do.
Call the first set P and the second set Q.
Let O~1 be a suffix of a in which all processes in P are in the final for loop, after label M.
We claim tha t  there is at least one process in P.
Specifically, the process with the smallest index among all the contenders is not blocked from reaching label M.
Let i be the largest index of a process in P.
This is because each t ime j executes one of the first two for loops, it discovers the presence of a smaller index contender and returns to L.
In this section we present the Bakery algorithm for mutual  exclusion.
It works somewhat  the way a bakery does, where customers draw tickets when they enter and are served in the order of their ticket numbers.
The Bakery algori thm only uses s ingle-wri ter /mult i - reader  shared registers.
In fact, it also works using a weaker form of register known as a safe register, in which the registers are allowed to provide arbi t rary  responses to reads tha t  are performed concurrently with writes.
The Bakery algori thm guarantees lockout-freedom and a good t ime bound.
It guarantees bounded bypass and also a related cond i t i on~ i t  is "FIFO after a wait-free doorway" (to be defined below)
An unat t rac t ive  proper ty  of the Bakery algori thm is tha t  it uses unbounded size registers.
We remark tha t  the code given here can be simplified i f we are only interested in the usual sort of registers (and not weaker types of registers such as safe registers)
In the Bakery algorithm, the first part of the trying region, until the point where process i sets choosing(i) := 0, is designated as the doorway.
While in the doorway, process i chooses a number that is greater than all the numbers that it reads for the other processes.
It reads the other processes' numbers one at a time, in any order, then writes its own number.
While it is reading and choosing numbers, i makes sure that choosing(i) = 1, as a signal to the other processes.
Note that it is possible for two processes to be in the doorway at the same time, which can cause them to choose the same number.
This comparison is done lexicographically, thus breaking ties in favor of the process.
In the rest of the trying region, the process waits for the other processes to.
If i is in C and j is in ( r  - D) U C, then (number(i), i) < (number(j), j)
We give an operational proof, since it can be extended more easily to the safe register case.
Fix some point s in an execution in which i is in C and j is in ( T D) tJ C.
Process i must read choosing(j) = 0 in its first waitfor loop, prior to entering.
But since j is in (T - D) tJ C at point s, j must pass through the choosing region at some point.
Then the correct number(i) is chosen before j starts choosing, ensuring that j sees the correct number(i) when it chooses.
Therefore, at point s, we have number(j) > number(i), which SOt:tCiCC S.
Then whenever i reads j ' s  number in its second waitfor loop, it gets the correct number(j) But since i decides to enter C anyhow, it must be that (number(i), i) < (number(j),j)
Suppose that, in some reachable state, two processes, i and j ,  are both in C.
Then eventually a point is reached after which all processes are in T or R, and no new region changes occur.
By the code, all of the processes in T eventually complete the doorway and reach T -  D.
Then the process with the lowest (number, index) pair is not blocked from reaching C.
Consider a particular process i in T and suppose it never reaches C.
Process i eventually completes the doorway and reaches T -  D.
Thereafter, any new process that enters the doorway sees i's latest number and so chooses a higher number.
Thus, since i doesn't  reach C, none of these new processes reach C either, since each is blocked by the test of number(i) in its second wait loop.
But repeated use of Lemma 10.26 implies that there must be continuing progress, including infinitely many crit events, which contradicts the fact that all new entrants to the trying region are blocked.
This is not so easy to show; we just give a brief sketch and leave the details for an exercise.
First, it only takes time O (nt~) for process i to complete the doorway; we must bound the length of the time interval I that i spends in T -  D.
Let P be the set of other processes already in T at the moment i enters T -  D.
Then only processes in P can enter C before i does, and each of these can only do so once.
The Bakery algorithm guarantees a highlevel-fairness condition that is somewhat stronger than lockout-freedom.
Namely, if process i completes the doorway before j enters T, then j cannot enter C before i does.
Note that the algorithm is not actually FIFO based on the time of entry.
It would not be useful just to claim that an algorithm was "FIFO after a doorway," because there are no constraints on where the doorway might end.
If the doorway ended right at the entrance to C, then this claim is completely trivial.
However, the doorway in the Bakery algorithm has an interesting property: it is wait-free, which means that a process is guaranteed eventually to complete it, if that process continues to take steps, regardless of whether any other processes continue to do so.
We have presented several mutual exclusion algorithms that use read/wr i te shared memory.
One thing that all the algori thms have in common, though, is that they all use at least n shared variables.
Also, the impossibility result holds regardless of the size of the shared variables (as measured by the number of values they can take o n ) ~ t h e y  can be as small as a single bit or even unbounded in size.
This result represents a fundamental limitation on the power of shared memory systems.
First, as in Section 9.3, we say that two system.
Second, we define a system state s to be idle if all processes are in their remainder regions in s.
In the proof, we consider a fixed collection of user automata.
Namely, we assume that each user Ui is the most nondeterministic poss ible-- that  it is able to perform its try and exit outputs at any time, subject only to the well-formedness.
Res t r ic t ing  a t tent ion  to this collection of users does not  cause any.
We leave it for an exercise to show that ,  for each i, there is in fact a.
The first is that  a process  running  on its own.
Then there is an execution fragment 2 starting from state s and involving.
Formally, the progress  condi t ion is applied to a low-level-fair execut ion containing s in which i enters T.
As an easy consequence,  we have that  a process running  on its own from a.
Let s and s I be reachable system states that are indistinguishable to process i and suppose that s ~ is an idle state.
Then there is an execution fragment starting from state s and involving steps.
The second basic fact is that  any process  that  reaches C on its own must.
Suppose that s is a reachable system state in which process i is in the remainder region.
Then, along the way, i must write some shared variable.
This is just an execution that starts in an arbitrary state, not necessarily an initial state of the algorithm.
Let s' denote the state at the end of C~l.
Since process i does not write any shared variable, the only differences between s and s' are in the states of process i and.
Repea ted  use of the progress condition implies that  there is an execution.
Since s j s' for every j # i, there is also such an execution fragment  s tar t ing from s'
Execution c~ begins with a finite execution fragment  leading to reachable state s, then continues with Ctl, thus letting i into C with no shared variable writes.
It finishes by letting another process go to C without any steps of i, s tar t ing from s'
This violates the mutual exclusion condition, because two processes are in C at the end of a.
By Lemma 10.29, i can reach C on its own, s tar t ing from an initial (idle) system state of A.
Then Lemma 10.31 implies that  i must  write some shared variable along the way.
Since this holds for every process i, and since each shared variable has only a single writer,  there must  be at least n shared variables.
But notice that  even the algori thms that  we have presented that  use mult i-writer registers (like the DijkstraME and Peterson algori thms) require at least n variables.
In this subsection, we extend Theorem 10.32 to the case of mult i-writer registers.
To give the intuit ion for the proof, we star t  by proving two special cases.
We first show impossibi l i ty  for two processes and one variable, then for three.
But  this yields two processes in C, contradict ing the mutual.
Moreover,  we claim that  along the way process  2 must.
Now we cons t ruc t  a counte rexample  execut ion a (see Figure  10.12)
But  we are not yet done, because we still need the resulting state to be indist inguishable to process 3 from some idle state.
So we continue; from the point where process 2 covers y, we resume process.
We claim that  c~ has all the properties we want.
The proof for the general case is a natural  extension of the.
Suppose that s is a reachable system state in which process i is in the remainder region.
Then, along the way, i must write some shared variable that is not covered by any other process in s.
The main difference is that  now we must  ensure that the execution fragment involving the other.
Using the inductive hypothesis,  we obtain a state t l  that  is.
Let S l be the first of these two covering.
Also, let s~ be the idle state that  was constructed to.
Now consider what happens if we run process k + 1 alone from system state.
Lemma 10.30 implies that there is an execution fragment start ing from s' and involving steps of process n only, in which process n reaches C.
Lemma 10.36 implies that in this execution fragment, process n must write some shared variable that is not covered in s'
We emphasize again that Theorem 10.33 holds regardless of the size of the shared variables: they can even be unbounded in size.
Moreover, no high-levelfairness assumption is needed; the progress condition is the only liveness assumption that is needed for this impossibility result.
In this final section, we consider mutual exclusion using read-modify-write shared memory.
That  is, a process is able, in one instantaneous step, to access a shared variable and to use the variable value and the process state to determine a new variable value and a new process state.
You might think that considering the mutual exclusion problem in the readmodify-write model is a trivial exercise, because this model is so powerful.
The read-modify-write model provides fair exclusive access to each shared var iable- each process gets fair turns to access the variable, and when it does so, it can perform an arbi t rary computat ion before the variable is released.
This is very close to what is required of a fair mutual exclusion algorithm, namely, fair exclusive access to the critical region.
It almost seems as though we are assuming a solution to the very problem we are trying to solve.
Indeed, having such a powerful form of shared memory does simplify the situation considerably, but it does not make all the difficulties disappear.
Along with a collection of algorithms, we shall present some nontrivial lower bound.
We consider the basic mutual exclusion problem first, then consider what.
For the rest of this section, we assume that the shared memory system only.
This does not cause any loss of generality in the read-modify-write model, because several read-modify-write variables could be combined into a single mult ipart  read-modify-write variable, anyway.
To see how different the read-modify-write model is from the read/wr i te  model, consider the following trivial one-variable algorithm, TrivialME.
In this algorithm, the shared variable x has value 1 exactly if the resource has been granted to some process.
It is straightforward to see that the TrivialME algorithm solves the mutual exclusion problem.
A c t i o n s  o f  i: Input :
The processes maintain a queue of process indices, initially empty, in the shared variable.
A process that enters T adds its index to the end of the queue; a process that finds itself at the beginning of the queue goes to C; and when a process leaves C, it deletes itself from the queue.
A c t i o n s  o f  i: Input :
It should be easy to see that  Q u e u e M E  guarantees  well-formedness, mutual.
This  implies that  Q u e u e M E  guarantees bounded bypass  (with a bound of 1)
The Q u e u e M E  algor i thm is simple and is also fast, at least according to our.
It would be bet ter  to reduce the size of the shared.
Can we solve the problem with a variable that takes on a number of values that is linear in n? What  about a constant number of values?
For example, we may use an algorithm based on issuing "tickets" to the critical region.
A c t i o n s  o f  i: Input :
The proof of the following theorem appears  in Section 10.9.4
Can we do bet ter  than n2? The following theorem gives a simple lower bound.
Suppose that A is an n-process mutual  exclusion algori thm guaranteeing bounded bypass, with a bypass bound of a.
We proceed by contradiction: we construct  an execution in which some.
Define si to be the system state and vi the value of the shared variable after.
So assume the contrary, that  is, that  vi - vj for some part icular  i and j , k.
This follows from the progress assumpt ion (which only applies in low-level-fair executions)
The same steps can be applied after c~j, again yielding an execution in which the same process enters C infinitely many times.
Jus t  running a sufficiently large port ion of this execution is enough to cause process j to be bypassed more than a times by some other process, which is the needed contradiction.
The construct ion is i l lustrated in Figure 10.14
In fact, the algorithm only needs n + k values, for a small constant k.
We call this algorithm the BufferMainME algorithm, for reasons that will become apparent  in a moment.
BufferMainME algorithm: The basic idea of the BufferMainME algorithm is as follows.
The trying region is divided into two pieces, called the buffer region and the main region.
When processes enter the trying region, they go into the buffer; no order information is maintained among the processes in the buffer.
At some time, when the main region is empty, all processes in the buffer go to the main region, thereby emptying the buffer.
From the main region, processes go one at a time, in an arbi t rary order, to the critical region.
Implementing this idea requires some communication mechanisms, so that processes can discover when they should change regions.
We will design a solution that centralizes system control in the supervisor process: the supervisor keeps track of when processes should change regions and informs them accordingly.
Afterward, we will describe how to remove the need for the special supervisor process.
The supervisor maintains local variables buffer-count and main-count, counts of the numbers of processes that it has heard about that are in the buffer and main regions.
When a process enters the trying region, it increments the count component of the shared variable to inform the supervisor that some new process has entered and then waits in the buffer.
It moves them, one at a time, by putting enter-main messages in the message component of the shared variable.
Then the supervisor moves processes from the main region to the critical region, by putting enter-cr i t  messages in the message component of the shared variables.
The first process in the buffer that sees this message picks it.
The first process in the main region that sees this message picks it up and proceeds to the critical region.
Now we outline how we can avoid the two separate components in the shared variable.
Note that the variable is being used for two purposes: recording the number of newly entered processes and communicating control messages.
We will now "time-share" the variable, allowing it to serve both purposes, but not at the same time.
The variable will at any point have a value that is either a count or a control message, but not both.
Note that, in the algorithm described so far, control-message communication proceeds according to a single sequential "thread of control," as.
Then (because there are only finitely many processes that can enter the system), the system would eventually reach a stable state.
The result is a mutual exclusion algorithm with bounded bypass that uses n + 6 values of the shared variable, assuming the availability of a dedicated supervisor process.
Now we modify this algorithm so that it works in the model we have been s tudying- - tha t  is, without a dedicated supervisor process.
The idea is to allow the processes to cooperate in a distr ibuted simulation of the supervisot.
The simulation has to be distributed,  since there is no process that is guaranteed to be available at all times.
The processes simply take turns performing the simulation; in particular,  whenever a process is in the critical region, it will be the process responsible for the supervisor simulation.
The main difficulty of this simulation is that a process leaving C must pass the responsibility for the supervisor simulation on to the next process.
We must use the shared variable for this new type of communication, as well as for the other two types of communication we have already discussed; again, we time-share.
One last detail: Sometimes, when a process leaves C, there will be no other.
In such a case, it means that there is no other process in the trying region.
Theorem 10.42 The BufferMainME algorithm solves the mutual exclusion problem, guaranteeing bounded bypass, using a single read-modify-write shared variable with only n + k values (for some small constant k)
For the weaker requirement of lockout-freedom, the proof does not work.
In fact, the result of Theorem 10.41 does not hold for lockout-freedom.
As in the BufferMainME algorithm, each incoming process increments a count in the shared variable, but this.
The count is absorbed by a (simulated) supervisor, as before.
If these hidden processes take no further steps, the rest of the system will proceed as if the hidden processes were still in R.
However, in a low-level-fair execution, the hidden processes will take further steps and so can make their presence known.
The executive sends special sleep messages to (an arbi t rary set of) ~ processes in the buffer, to put them to sleep for a while.
Then, having removed ~ processes from the competition, the executive reenters the system, incrementing the count on.
When the executive reaches C, it takes care of the sleepers by sending them wakeup messages and telling the supervisor about them.
Again, we must time-share the variable for these new types of communication, now with a slightly more complicated priority scheme.
We finish this subsection with a lower bound of approximately x/~ on the.
This bound is not n tight with respect to the g + k upper bound, but the proof does contain an.
Then the number of distinct values the variable can take on in reachable states of A is at least k.
Again, we assume that the users are the most nondeterministic possible.
The formal argument is similar to the one used for Lemma 10.31
We now construct  a bad execution to derive a contradiction.
Such a state must  exist since the variable can assume only finitely many.
The key idea to remember in the proof of Theorem 10.44 is the construction of bad low-level-fair executions by splicing together execution fragments.
Also, note that Theorem 10.44 implies what might at first seem to be a paradox.
Namely, there is a nontrivial inherent cost to solving lockout-free mutual exclusion, even though our model already contains something very close to what is needed-- fa i r exclusive access to a shared variable for arbi t rary computation.
We close this section by outlining a correctness proof for the TicketME algor i thm presented in the previous section.
Our proof uses the simulation method described in Section 8.5.5
We have already used the simulation method to show correctness of several a lgori thms--for  example, OptFloodSet--in the synchronous model; however, this is our first interesting use of this method for asynchronous algorithms.
We would like to prove that the TicketME algorithm guarantees the same correctness conditions as the QueueME algorithm: well-formedness, mutual  exclusion, progress, and FIFO behavior with respect to the first locally controlled event in T.
It turns out that a good way to understand the TicketME algorithm is to relate it, not to QueueME, but to a new Infinite TicketME algorithm that is just like TicketME except that it uses an infinite sequence of tickets rather than counting modulo n.
Then TicketME can be seen as a reduced-complexity version of Infinite TicketME.
I n f i n i t e  T i c k e t M E  a l g o r i t h m :
It is easy to show that  I n f i n i t e T i c k e t M E  satisfies all the properties claimed.
Then we can show the correctness of T i c k e t M E  by relating it formally.
Some invariants for Inf ini te  T i c k e t M E  are useful.
The next step is to define a simulation relation f between the system states.
This correspondence is simple: we define (s, u) C f.
We use dot notat ion below to indicate the value of a given.
More precisely, we define T and I to be the T i c k e t M E  and Inf ini te  T i c k e t M E  systems, respectively, each modified slightly so that  all the actions are classified as external.
We show that  f is a simulation relation from T to I.
If s is an initial state of T, then f ( s )  contains an initial state of I.
The two conditions given above are s t ra ightforward to prove.
For the first condition, that  is, the s tar t  condition, a s tar t  state s of T consists of the unique s tar t  state of the T i c k e t M E  algori thm and a rb i t ra ry  s tar t  states for the users.
It is easy to see that  the unique s tar t  state of the Inf ini te  T i c k e t M E  algor i thm, together with the same star t  states for the users, is in f ( s )
The second condition, that  is, the step condition, is proved by a case analysis, according to the type of action being performed.
Any locally controlled actions of the users are mimicked exactly.
The only interesting case is an action of the form testi, where a process i makes a decision, based on whether ticketi = granted, about whether it should proceed to C.
We must  verify that  the two algori thms do not.
That  is, the danger is that  incrementing ticket values modulo.
Then the fact that u C f ( s )  implies that u.ticketi - u.granted mod n.
How does Lemma 10.46 help to prove the correctness of TicketME?
The well-formedness, mutual exclusion, and FIFO conditions can all be expressed as properties of traces (when all the actions are included, as they are here)
So the fact that these three conditions hold for I.
This implies that TicketME guarantees the well-formedness, mutual exclusion, and FIFO conditions.
The progress condition is different from the other three conditions in that it is supposed to.
To show that this condition carries over from Infinite TicketME to TicketME, we would like to know that fairtraces(T) C_ fairtraces(I)
It turns out that the simulation relation f can also be used to help prove this inclusion.
The key idea is that a simulation relation actually implies more than just inclusion of sets of t races- - i t  really establishes a close correspondence between.
See Section 8.5.5 for a formal definition of such a correspondence.
We obtain such a strong correspondence here because all actions of T and I are external.
There are two ways in which it might fail to be fair.
Again, the correspondence implies that the same thing happens in c~, violating the fairness of  Ct.
Since the progress condition can be expressed as a property of fair traces (when all the actions are included, as they are here), this implies that the progress condition carries over from InfiniteTicketME to TicketME.
The DijkstraME algorithm appeared in a short note by Dijkstra [90]
It extended a previous two-process algorithm by Dekker to an arbitrary number of processes.
Before these results, it was not even clear that the problem could be solved with only read/write shared memory.
The assertional proof that DijkstraME satisfies the mutual exclusion condition is adapted from a paper by Goldman and Lynch on shared memory modelling [141]
Our Tournament algorithm is simpler and easier to prove correct than the tournament algorithm in [242]; however, it has the disadvantage that it uses multi-writer variables, while the original requires only single-writer variables.
A later paper by Lamport [180] contains additional improved mutual exclusion algorithms.
The lower bound on the number of registers required for solving the mutual exclusion problem is due to Burns and Lynch [63]
The results on bounded bypass and lockout-free mutual exclusion with read-modify-write shared memory all appear in a paper by Burns, Fischer, Jackson, Lynch, and Peterson [62]
These results build on earlier work by Cremers and Hibbard [84]; in particular, the BufferMainME algorithm is based.
Another result in [62], not discussed in this n values of chapter, says that lockout-free mutual  exclusion requires at least.
That is, they cannot retain any memory of prior executions of the algorithm.
Cremers and Hibbard [85] also designed an n + k algori thm to achieve FIFO access to the critical region, using read-modify-write shared memory.
A good source for information about temporal  logic, which can be used to formalize the liveness proofs in this chapter and elsewhere in this book, is the book by Manna and Pnueli [219]
A book by Raynal  [249] contains descriptions of many mutual  exclusion algorithms, for both the asynchronous shared memory and asynchronous network models.
Consider yet another way of defining the mutual  exclusion problem, this one in terms of the traces of the shared memory system A alone, rather than in terms of the combination of A and the users.
That  is, define a trace property Q such that traces(Q) is the set of sequences/3 of try, crit, exit, and rein actions that satisfy the following three conditions:
If at some point in /3, some process's last event is try and no process's last event is crit, then there is a later crit event.
If at some point in/3, some process's last event is exit, then there is a later rein event.
Describe a fair execution of the DijkstraME algorithm in which a part icular process is locked out.
Show that the second phase of the DijkstraME algorithm (where the flag is raised to 2 and the other processes'  flags are tested) is needed to solve the problem correctly.
Consider the t iming analysis for DijkstraME, for the time from a point where some user is in T and no user is in C until a point where some user enters C.
Try to make kl and k2 as small as possible.
The lockout-freedom condition makes sense for those algorithms that guarantee well-formedness, but not necessarily mutual  exclusion or progress.
Prove carefully that if an algorithm guarantees well-formedness and is lockout-free (for all collections of users), then it also guarantees progress (for all collections of users)
Modify the processes in the Peterson2P algorithm so that they do not necessarily perform check-flag and check-turn in strict alternation, but according to some looser discipline.
Make sure your resulting algori thm is still a lockout-free mutual  exclusion algorithm.
Prove the correctness of your modified algorithm and analyze its time complexity.
Prove the correctness of your algorithm, preferably using invariant assertions.
Hint: If you get stuck, you might want to consider the two-process solution in [242]
Reconsider the time bound proved in Theorem 10.16, for the PetersonNP algorithm.
Is it tight? Either exhibit an execution in which the exponential behavior described there is actually realized, or else give a finer analysis with a smaller complexity bound.
Does the PetersonNP algorithm guarantee bounded bypass? Prove that it does or give a counterexample.
This problem allows k processes to coexist inside the critical region at the same time.
Formally, the mutual exclusion condition is modified to forbid more than k users to be in C at once.
The progress condition for the trying region is also modified, to say that if there is at least one user in T and at most k -  1 users are in C, then some user eventually enters C.
In terms of this rewrite, define the notions of "winner" and "competitor" carefully.
Hint: Strengthen it to include some information about what happens when a process is inside the waitfor loop, after the process has discovered that some of its opponents have flag variables strictly less than k.
Then prove the strengthened invariant together with the original one by induction.
Complete the proof that the Tournament algorithm guarantees mutual exclusion.
What  happens to the behavior of the BurnsME algorithm if the second for loop is removed? Either prove that it still solves the mutual exclusion problem or exhibit a counterexample execution.
Give an assertional proof showing that the BurnsME algorithm satisfies the mutual exclusion condition.
Exhibit a low-level-fair execution of the BurnsME algorithm in which some process is locked out.
Carry out a time analysis for the progress condition, for the BurnsME algorithm.
That  is, assume that c and t~ are upper bounds on critical region time and process step time, and consider the time from when there is some process in T and no process in C until some process enters C.
Try to get your bounds in (a) and (b) to be as close as possible.
Describe an execution of the Bakery algorithm in which the values taken on by the number registers are unbounded.
Why does the Bakery algorithm fail if the integers are replaced by the integers mod b, for some very large value of b? Describe a specific counterexample execution.
While doing this, t ry to generalize the algorithm slightly by allowing as much nondeterminism in the order of actions as you can.
Give an assertional proof of the mutual  exclusion condition for the generalized algorithm.
Prove that the Bakery algorithm works correctly even in the following much weaker model.
Suppose that reads and writes are no longer instantaneous, but have duration.
Suppose that the shared registers are only guaranteed to be safe, that is, to yield the correct value only in the absence of concurrent reading and writing.
In the event that a read overlaps any write, any value might be returned by the read.
Does Burns 's  mutual  exclusion algorithm work if the shared registers are all safe registers (as defined in Exercise 10.24)? Why or why not?
Fill in the details for the complexity analysis of the Bakery algorithm, sketched at the end of Section 10.7
Research Question" How are the results in Section 10.8 affected if, instead of the mutual exclusion problem, we consider"
Programmers at the Flaky Computer Corporation have designed the following algorithm for n-process mutual exclusion.
Does this protocol satisfy the two claimed conditions? Either prove that it does or give explicit counterexample executions to show that it doesn't.
Research Question: Consider a generalization of the progress condition to the k-concurrent progress condition, which only requires progress if there are never more than k users concurrently outside of R:
Give the best upper and lower bounds you can on the number of shared read/wri te  variables needed to achieve well-formedness, mutual exclusion, and k-concurrent progress.
Design a good mutual exclusion algorithm for a read/wri te  shared memory model that is a little different from the model used in this chapter.
You should begin by identifying and proving key system invariants and then use these to prove the mutual exclusion condition.
Progress can then be proved using an argument by contradiction, as usual.
The FIFO condition can use an ad hoc operational argument.
In the Bakery algorithm, it is not possible to reduce the unbounded ticket values by counting modulo any integer; however, this trick works for the TicketME algorithm.
Hint: You might try to relate this to the version with a supervisor, using a simulation proof.
Design a new algorithm that solves mutual exclusion using a single readmodify-write shared variable, and is FIFO (with respect to the first locally controlled step in the trying region)
Try to minimize the number of values taken on by the shared variable.
Hint: n + k is achievable, for a small constant k.
Show that the Executive algorithm does not guarantee bounded bypass.
Research Question: Write code for the Executive algorithm and argue its correctness.
Can its proof be based formally on the correctness of the BufferMainME algorithm? Can a simulation proof be used?
Your analysis should be based on the underlying I /O automata rather than the code.
Why doesn't the idea of the Executive algorithm generalize to allow the n values? variable to have only.
Carry out all the details of the proof of Lemma 10.46
Research Question: Redo all the proofs of liveness conditions (progress and lockout-freedom) in this chapter using a formal temporal logic.
In Chapter  10, we considered the mutual exclusion problem, an abstract  resourceallocation problem involving access by concurrent users to a single unshareable resource.
In this chapter, we generalize the problem to include many resources.
This generalization is useful for modelling application programs that require several resources for their execution, for example, a printer.
We do not consider (except in some general definitions and some exercises) the possibility that a user might be willing to accept alternative combinations of resources.
We do not consider the possibility that resources might be shared.
For example, individual data objects in a database can be thought of as resources to be allocated to database transactions.
In this case, some sharing is typically permitted; for example, two transactions that need only to read an object can be allowed concurrent access to the object.
Our last solution is a randomized protocol - -our  first.
In this section, we begin by giving some ways of specifying conflict relationships among users.
Then we describe how to use such specifications to define resourceallocation problems.
There are two different ways of looking at the mutual exclusion problem: as the problem of allocating an explicitly represented resource or as the problem of ensuring that only one user at a time is in its critical region.
Thus, we define both explicit resource specifications and exclusion specifications as alternative ways of describing conflict relationships among users.
An explicit resource specification Tt for n users consists of.
The intention is that the resources in Ri should be those that user Ui needs to perform its work.
We say that two users Ui and Uj conflict with respect to a given explicit resource specification if they require some common resource, that is, if R~ N Rj r O.
On the other hand, an exclusion specification does not mention resources at.
Rather, the specification is given in terms of a collection $ of "bad sets"
A "bad set" is a set of indices of users that  are not allowed to perform their work simultaneously.
There is one restriction on exclusion specifications: the collection of bad sets is required to be closed under superset.
That  is, if a particular bad set E of users belongs to an exclusion specification g, then any superset of E also belongs to $
Note that  any explicit resource specification gives rise to an exclusion specification that  is equivalent in that  it permits the same combinations of users to execute simultaneously.
This exclusion specification consists of exactly those sets of users that  include at least two users with overlapping resource requirements.
However, it is not the case that  every exclusion specification has a corresponding explicit resource specification.
To be specific, consider a fixed exclusion specification g (which could be derived from an explicit resource specification)
Again, users cycle through their remainder (R), trying (T), critical (C), and exit (E) regions, as depicted in Figure 10.2
A sequence of interactions between Ui and the shared memory system is wellformed for user i if it respects this cyclic order.
The well-formedness condition on the composed system is as before.
The mutual exclusion condition is now replaced by the more general exclusion condition.
The progress condition for the trying region is weaker than one might like in the present setting.
We do not know a good way of stating such a condition, for arbi t rary.
However, for explicit resource specifications, we can at least state the following condition.
If an algorithm in the model of this chapter guarantees well-formedness and lockout-freedom, then it also guarantees progress.
As we did for similar properties in Chapter 10, we can express the well-formedness, exclusion, progress, independent progress, and lockoutfreedom conditions equivalently in terms of trace properties.
Each of these trace properties P has a signature consisting of try, crit, exit, and rein outputs (and no inputs)
The external actions of the combined system are also exactly these actions, and the requirement in each case is that the fair traces of the combined system are all in traces (P)
As in Chapter 10, we assume in this chapter that a process within the shared memory system can have a locally controlled action enabled only when its user is in the trying or exit region.
Thus, the processes can only be actively engaged in executing the protocol while there are active requests.
It is usually formulated in terms of an explicit resource specification.
Traditionally, the problem is described in terms of the following informal scenario.
There are n philosophers (users) seated around a table, usually thinking (i.e., in R)
Between each pair of philosophers is a single fork (resource)
From time to time, any philosopher might become hungry (i.e., enter T) and attempt to eat (i.e., to enter C)
In order to eat, the philosopher needs exclusive use of the two adjacent forks.
After eating, the philosopher relinquishes the two forks (i.e., performs an exit protocol E) and resumes thinking (R)
For each philosopher Pi, we label the forks to the right (counterclockwise) and left (clockwise) by f ( i )  and f ( i  + 1), respectively.
In our formal model, there is one user and one agent process for each philosopher.
As usual, the user decides when to request and return the resources, and the agent process performs the algorithm.
All the solutions we consider in this chapter are of a particular form: there is exactly one read-modify-write shared variable associated with each resource, accessible only by the processes whose users require the corresponding resource.
The architecture for solutions to the Dining Philosophers problem in this restricted form is depicted in Figure 11.2
Notice that the diagram is very similar to the one in Figure 11.1; the new diagram includes the users Ui and relabels the processes by their indices.
Note that each process i accesses fork variables f ( i )  and f ( i  + 1)
An interesting class of candidate Dining Philosophers algorithms is the class of symmetric algorithms.
An algorithm in the given framework is said to be.
As for the leader-election problem in Chapter  3, it is not hard to see that the Dining Philosophers problem cannot be solved in the symmetric case.
The argument is essentially the same as the one for Theorem 3.1:
Assume for the purpose of contradiction that there is a symmetric algorithm for n processes, say A.
Consider an execution c~ of A that begins with all processes in the same process state and all shared variables with the same initial value.
Moreover, all nondeterministic choices are resolved in the same way.
Then it is straightforward to show, by induction on the number r of roundrobin "rounds," that all processes are again in the same state and all variables have the same value, after r rounds.
But the progress property says that some process eventually enters C.
This implies that all other processes also enter C at the same round.
Each process, upon entering the trying region, waits first for its right fork and then for its left fork.
When a process exits C, it puts down both forks before returning to R.
The formal code follows; right and left are local names used by process i to denote the indices i and i + 1 (for its two forks), respectively.
A c t i o n s  o f  i: Input: Internal:
Effect: f (left) := false if f (left) = false then pc := leave-exit.
It should be clear that  W r o n g D P  does guaran tee  well-formedness.
Consider an execution in which all of the processes enter their trying regions, one after the other.
At this point, each process is ready to try to obtain its left fork.
But since all forks have already been picked up, no process can do so.
The system is now deadlocked--there is no way that any further progress can be made.
Theorem 11.2 implies that it is necessary to break the symmetry of a ring network in order to solve the Dining Philosophers problem.
The processes could use different programs, or the same program but different initial states or unique identifiers.
In the rest of this chapter, we will illustrate some of these approaches.
In this section, we present a (correct) Dining Philosophers algorithm that we call the RightLeftDP algorithm.
In addition to satisfying the basic required properties, this algorithm also guarantees lockout-freedom.
It also has a good worst-case time bound: a constant, independent of the size of the ring.
The way the RightLeftDP algorithm breaks symmetry is by having processes classified into two categories, which we call "right" and "left." The two types of processes execute slightly different programs, with their category indicating which adjacent fork to seek first.
It is certainly desirable, in a distributed system, to have time performance that is independent of the size of the system.
But how can such a small time bound be achieved?
The RightLeftDP algorithm is one of a general class of algorithms in which processes proceed sequentially, waiting first for one fork and then for the other.
In such algorithms, we must be careful about the order in which the forks are sought.
For example, if all processes seek their right forks first, then there is the possibility of deadlock as in the WrongDP algorithm.
There are other orders that do not admit the possibility of deadlock but still allow for executions with very poor time performance.
In particular, some orders can lead to the establishment of long waiting chains of processes, each waiting for a resource held by the process ahead of it in the chain.
Process 4 obtains its right fork, then waits for its left fork.
Process 3 obtains its right fork, then waits for its left fork.
Process 2 obtains its right fork, then waits for its left fork.
Solid arrows indicate possession of the fork, while dotted arrows indicate waiting.
Notice that the processes in a waiting chain must  enter the critical region sequentially.
Thus, for any algorithm of this general type, the worst-case time for a trying process to enter the critical region is at least proportional to the maximum length of a waiting chain that can be produced.
In order to obtain a small time bound, then, we must guarantee a small bound on the maximum.
This queue is designed to hold the indices of processes wanting the fork, in the order in which they begin trying to get it.
Since there are only two processes that can request each fork, a length 2 queue suffices.
For simplicity, we assume here that the number of processes in the ring is even.
There is a simple modification, left for an exercise, that works in the case of an odd number of processes.
There are two different programs: one for the processes with odd indices and one for those with even indices.
The basic strategy is very simple: oddnumbered processes seek their right fork first and even-numbered processes seek their left fork first.
A process seeks a fork by putting its index at the end of that fork's queue.
The process obtains the fork when its index reaches the front of that fork's queue.
When a process exits C, it returns both forks by removing its index from their queues before entering R.
A c t i o n s  o f  i: Input:  Internal:
For  the  t ime  b o u n d ,  we a s s u m e  as before  t ha t  t~ is an  u p p e r  b o u n d  on  the.
I n  R i g h t L e f t D P ,  the t i m e  f r o m  w h e n  a p a r t i c u l a r  process  i e n t e r s.
The key idea is that  a fork between two processes is either the first fork for both  or the second fork for both.
Define T to be the max imum time from when any process i enters the t rying region until that  process enters the critical region.
As an auxiliary quantity,  we define S to be the maximum time from when any process i obtains its first fork until that  process enters the critical region.
Formally, we say that  process i obtains its first fork at the event where i becomes first on the queue for that  fork.
This could be either a step of i or a step of the neighbor with which i shares the fork.
We star t  by bounding T in terms of S.
With in  time g, it performs a test event rr to t ry  to get its first fork.
If it obtains the fork immediately,  then within addit ional  time S, process i enters the critical region.
This  is a total  time of at most  g + S.
Otherwise,  the neighbor with which i shares the fork, say j ,  has the fork when rr occurs.
As mentioned above, this fork must  also be j ' s  first fork.
Hence the addit ional  time until j releases this fork is at most  S + c + t7 (enough time for j to reach the critical region, leave the critical region, and release its first fork)
At the instant  j releases the fork, process i obtains it; this is because of the way.
Then,  within addit ional  time S, i reaches the critical region.
Consider a process i that  has just  obtained its first fork (i.e., has become first on the queue for that  fork)
With in  time g, it discovers this fact, and within an addit ional  time t~, it performs a test action on its second fork.
If it obtains this second fork immediately,  then, within an addit ional  time g, it goes to the critical region, for a total  time of at most  3g.
Otherwise,  the neighbor with which i shares the fork has it, and it is also the neighbor 's  second fork.
From the point after the neighbor releases the fork, it is at most  time g until process i discovers it and an addit ional  time t~ until process i enters the critical region.
Since it is easy to see that the algorithm also satisfies the independent progress condition, we obtain.
So, the RightLeftDP algorithm breaks symmetry  by distinguishing the oddand even-numbered processes.
Depending on the environment in which this algorithm is to be run, it might or might not be reasonable to assume that processes have this knowledge.
For instance, if it is to be run in a distr ibuted network (as we consider in Chapter  17), then an additional protocol may be needed for determining this pari ty information and communicating it to all the processes.
The generalization still has the virtue of having a time bound that is independent of the number of processes.
However, the bound is not very smal l - - there  is still room for performance improvement.
We continue to assume that each resource has an associated shared variable, shared by all processes that require that resource.
As in RightLeftDP, we assume that the variable contains a FIFO queue to record who is waiting for the resource.
As in RightLeftDP, each process waits for its required resources one at a time.
To avoid deadlock, however, we assume that the resources are totally ordered and allow each process to obtain its needed resources in order, according to this total order ing--smalles t  to largest.
It is not hard to see that hierarchical resource allocation guarantees progress.
Although hierarchical resource allocation guarantees progress and lockoutfreedom, the time performance of this strategy is not very good, in general.
The only upper limit on the length of waiting chains is the total number n of processes, leading to time performance that is at least proportional to n.
What  we would like is a "good" total ordering of resources, one that produces as small a time bound as possible.
A reasonable strategy is to try to minimize the length of the waiting chains that are produced.
Suppose we are given a particular explicit resource specification T4, with universal resource set R and individual process resource requirements Ri.
To construct a good total ordering, we first construct the resource graph for this specification.
The nodes of this graph represent the resources, and there is an edge from one node to another exactly if there is some process that uses both associated resources.
For the Dining Philosophers problem with six nodes, the resource graph is as in Figure 11.4
Next, we color the nodes of the graph in such a way that adjacent nodes have different colors.
We do not consider the problem of how to obtain a small number of colors.
Actually obtaining the minimum number is an NP-complete problem, but for our purposes here, a small number of colors will do.
Now we totally order the colors in an arbitrary way.
This induces a partial order on the resources, where r(i) < r(j) if and only if the color of r(i) is ordered ahead of the color of r(j)
Although this is only a partial order, note that it totally orders the resources needed by any single process.
Coloring a l g o r i t h m :
Each process seeks its resources in increasing order according to the total ordering constructed above, based on coloring.
A process seeks a resource by putting its index at the end of that resource's queue.
The process obtains the resource when its index reaches the front of that resource's queue.
When a process exits C, it returns all of its resources by removing its index from their queues.
Since any two resources needed by the same process are ordered with respect to each other (i.e., are colored differently), an equivalent description of Coloring is that every process seeks its resources in increasing order according to the.
Notice that, in the special case of the Dining Philosophers problem for an even-sized ring, the Coloring algorithm reduces to the RightLeftDP algorithm.
In the Coloring algorithm, the maximum length of a waiting chain is at most equal to the number of distinct colors.
This is because if a process i waits for a resource held by a process j ,  then j may be waiting only for a resource of a "larger" color.
The interesting property to verify for the Coloring algorithm is a time bound that is independent of the total numbers of processes and resources.
As usual, we let g be an upper bound on process step time and c an upper bound on critical region time.
Also let k be the total number of colors used to color the resources and let rn be the maximum number of processes that require any single resource.
We show that the worst-case time bound is O(mkc + krnkg)
We can interpret this as saying that the time depends only on "local" parameters,  since the number of colors and the number of users per resource need not depend on the size of the system.
But note that this bound is not as small as one might l ike-- instead of being proportional to the maximum length of a waiting chain, that is, proportional to k, it is exponential in k.
Then the time from when any particular process i enters T until it enters C is O(mkc + krnk f)
We wish to bound T, the worse-case time from entry to the trying region until entry to the critical region.
From when a process enters the trying region, it is at most time t~ until its index is placed on some resource queue.
We bound the T( i , j )  by setting up recurrence equations as we did for the RightLe~DP algorithm.
The base case is when a process is first on the queue for a resource with the highest color:
This allows time for the process to discover it is first on the queue and then to go to the critical region.
This gives the process time to discover it is first on the queue and then either proceed to the critical region or get on another queue, necessarily of a highercolored resource.
The last case is when a process is in some position other than the first, on some queue.
This allows time for the predecessor of the process on the queue to reach its critical region, then finish the critical region, then release all of its < k resources (which will move the original process to the first position on the given queue), and then time for the process, now in position 1, to reach the critical region.
It turns out that there are some executions of the Coloring algorithm with time performance that is close to this exponential bound.
We leave it as an exercise for you to find such executions.
Of course, it would be nice to cut down the time bound from exponential to linear in the number of colors, but that would require a different algorithm.
In this algorithm, all processes are identical; the symmetry is broken by the use of randomization.
We have several points we hope to make by presenting this algorithm.
First, it demonstrates that randomized algorithms can be used in the asynchronous setting as well as the synchronous setting, and that they sometimes can accomplish things that cannot be accomplished by nonrandomized algorithms.
For example, the LehmannRabin algorithm can solve the Dining Philosophers problem even though the processes are identical, whereas Theorem 11.2 implies that this cannot be done by any nonrandomized algorithm.
Actually, we should be careful when we say that this algorithm "solves the Dining Philosophers problem": the correctness conditions satisfied are not exactly those specified earlier, in that the progress condition only holds with probability 1, and not with absolute certainty.
Second, we show how meaningful probabilistic claims can be made for randomized asynchronous systems.
It is not obvious how to do this, because a randomized algorithm does not by itself give rise to a probability distribution on executions.
For instance, the order in which processes take steps in an asynchronous algorithm is rather arbitrary, not determined randomly.
This order must be determined somehow in order to define a probability distribution.
Third, we demonstrate a Markov-style analysis technique for proving probabilistic time bound properties.
Such properties can in turn be used to prove probabilistic liveness properties.
Because the processes are identical, they are assumed to know their forks by local names.
As before, we assume that each process knows its forks by the local names f (right) and f (left)
Thus, a t rying process i executes a loop, in each i teration a t tempt ing  to obtain both of its forks.
In each iteration, it chooses a first fork randomly and waits as long as necessary to obtain it.
After obtaining its first fork, it does not wait indefinitely for the second fork.
Rather,  it just  checks once to see if the second fork is available.
If it is, then process i obtains it and proceeds to C.
If not, then process i gives up on this iteration, puts its first fork down, and proceeds to t ry  again in the next iteration.
A c t i o n s  o f  i: I n p u t :  I n t e r n a l :
Formally, the object described by this code is a probabilistic I//O automaton, as defined in Section 8.8
The random choice steps are exactly the flip steps; instead of a new state, each of these steps has a probability distr ibution containing.
Note that system execution two possible next states, each with probability ~
The nondeterministic choices determine which process takes the next step and thereby determine what the next step is, whereas the probabilistic.
It is easy to see that the L e h m a n n R a b i n  algorithm guarantees well-formedness, exclusion, and independent progress; there is no probability involved in any of these claims.
Formally, they are claims about the nonde termin i s t i c  version of the system, as defined in Section 8.8
Consider an execution a of L e h m a n n R a b i n  in which the processes take steps in round-robin order and always make the same random choices.
Note that c~ is a fair execution (of the nondeterministic version of the system)
Actually, rather than just proving progress with probability 1, we will prove a stronger probabilistic t ime bound.
The probability 1 progress condition can then be proved by repeated application of this claim.
In order to make claims about the probability of certain events, we need a probability distribution on executions.
The nondeterministic choices must be resolved in order to obtain a purely probabilistic system.
In fact, we would like to claim that the system has the desired property regardless of how the nondeterministic choices are resolved.
It is useful to imagine that the nondeterministic choices are under the control of an adversary.
We allow the adversary to select arbitrary processes, as long as it allows fair turns to each process that is in its trying or exit region.
In fact, since we are proving probabilistic time bound statements, we allow the adversary to choose not only which process takes the next step, but also the time at which that step occurs.
The time decisions are subject to an upper bound of t~ on process step time and an upper bound of c on critical region time, plus the requirement that, if the execution is infinite, the time must pass to infinity.
To obtain the strongest result, we want to allow the adversary to be as powerful as possible; thus, we assume that, when making its decisions about who takes the next step and when, it has complete knowledge of the past execution, including information about process states and past random choices.
Formally, an adversary A is a function mapping finite executions to (process, time) pairs, indicating the next process to take a step and the time at which the step is to be taken.
For each particular sequence D of random draws, there is a unique timed execution exec(A, D) generated by adversary A with random choices given by D.
The adversary is restricted so that all timed executions in exec(A, D) have the fairness and timing properties described in the previous paragraph.
A fixed adversary A determines a probability distribution on the set of timed executions of the algorithm.
This probability distribution on the sequences D induces a probability distribution on the timed executions exec(A, D)
Now we have enough machinery to prove the progress property.
We let F,  W, S, D, and L denote the sets of process states where pc = flip, wait, second, drop, and leave-try, respectively; these five sets of states partition the trying region T.
Now we define the sets of system states that we will need in the auxiliary claims.
The last set, G, is the set of "good" states, in which two processes are in a situation where, with high likelihood, one will soon obtain both its forks.
The two situations allowed by are depicted in Figure 11.6
A rough intuition is that in a good configuration, two neighboring processes have a high probability of having a common second fork.
If they have a common second fork, then whichever accesses it first will get it and succeed in reaching C.
We begin by proving the three probability 1 claims, since they are the easiest.
If a process is at leave-trying, then within time t~, that same process will take a step and enter C.
If any process is initially in C or enters C within time 3t~, then we are.
But  any processes that  are initially in E re turn  to R within time 3t~
This forces all the processes into R U T within time 3g, as needed.
If any process is initially in F U L or enters L within time 3~, then we.
Moreover, no process reaches S U D within time t~
Because some process is in W, we know that  some process must  take a step.
Let i be the first process to take a step.
W, then, since no fork is held, i immediately  obtains its first fork.
If any process is initially in L, then we are done, so assume that  this is.
Let i be any process that is initially in F.
Then with probability ~, and i -  l ' s  next random choice is right.
Then we claim that i -  l ' s  state must still be in the set ,-~ U R U F; this is argued by an examination of the possible transitions out of this set of states, using the fact that i -  l ' s  next random choice is right.
Then i -  1 obtains its second fork and goes to L, which suffices.
This is the interesting case, because the situation looks nothing at all like what is supposed to happen in a good state.
We leave it as a simple exercise to show this.
This means that the resulting system state is in G, unless in the meantime, j has moved out of the set.
But if it has, then j has obtained its second fork and gone to L, which suMces.
Their statements do not involve probability explicitly; rather, they involve it implicitly by referring to the values of certain future random choices.
The first one bounds the amount of time a process can remain waiting for its first fork, if a neighbor is favorably oriented.
Then, initially, i + 1 does not hold the shared fork.
If in the meantime i + 1 has not accessed it, then i obtains.
Suppose, on the other hand, that i + 1 has accessed the shared fork in the meantime and consider the first such time.
Because of i + l ' s  state, the shared fork must be i + l ' s  second fork.
In the cases ~ ,  R, and F,  this is because of the fact that i + l 's  next random choice is left.
Since i + 1 obtains this fork, it succeeds in reaching L, as needed.
Note that the time for this case is at most ~
The time for this case is thus at most 2~
The time for this case is thus at most 3t~
If the first one is i, then we have i C ~-,  as needed.
The time for this case is thus at most 4f.
The second claim bounds the time from when a process is ready to test  its second resource and a neighbor is favorably oriented, until someone reaches L.
But if i -  1 has obtained it, then i has gone to L, since the shared fork must  be i -  l ' s  second fork.
It bounds the time from when a process i is waiting for its first fork and both neighbors are favorably oriented, until someone reaches L.
In the latter case, we are done, so assume that i reaches ~-
If, in the meantime, i -  1 has reached L, we are done, so assume that  it has not.
Then  i - 1 must  still be in %+ U RU F.
Now we re turn  to the proof of Lemma 11.12
The Dining Philosophers problem was originally defined by Dijkstra [91], who devised an algorithm for an asynchronous shared memory model containing a globally shared semaphore variable.
The RightLeftDP algorithm seems to be folklore; its generalization to the Coloring algorithm is due to Lynch [213]
The LehmannRabin algorithm was designed by Lehmann and Rabin [192]
An informal proof sketch appears in [192], but it is not clear how to formalize that sketch.
Lehmann and Rabin [192] gave a modification of the LehmannRabin algorithm that  also guarantees lockout-freedom with high probability.
All of the algorithms in this chapter use shared variables.
Show that not every exclusion specification has an equivalent explicit resource specification.
It is possible to generalize the definition of an explicit resource specification to allow for alternative resource possibilities.
Namely, for each i, the specification includes a description of resource requirements, in the form of.
The meaning of the formula is that  the acceptable sets of resources are those sets whose exclusive possession authorizes the user to enter the critical region.
Modify the RightLeftDP algorithm so that  it works for a ring with an odd number of processes.
Obtain an upper bound for the time complexity of the modified algorithm.
Research Question: Construct a new algorithm for the general resourceallocation problem of this chapter, for the model in which there is one read-modify-write variable associated with each resource, accessible only.
Your new algorithm should have a much better time performance than the Coloring algorithm.
Dining Philosophers algorithm for which the probability of locking out a particular process is non-zero.
Use Theorem 11.16 to prove the following, for the LehmannRabin algorithm:
You get to define f - - t r y  to make it as small as possible.
For this case, state and prove an interesting claim of the form T - ~  C.
A novice programmer at the Flaky Computer Corporation, upon learning about the LehmannRabin algorithm, has proposed to improve its time performance by removing the wait for the first fork.
Now instead of waiting for its first fork, a process simply tests it just as it does for its second fork.
If the fork is unavailable, then the process goes back to the beginning and flips again.
Explain patiently to the programmer what is wrong with his algorithm.
Philosophers problem, while preserving the properties of exclusion, independent progress, and progress with probability 1?
In this chapter, we introduce another complication into our study of the asynchronous shared memory model: the possibility of failures.
In fact, we only consider the simplest type of process failure: stopping failure, whereby a process just stops without warning.
The problem we study in this chapter is one of consensus.
For the case of process failures, we have shown that basic consensus problems are solvable, not only for stopping failures, but also for less well-behaved Byzantine failures.
However, we gave several results showing that the costs of solutions, measured in terms of the.
Perhaps surprisingly, the situation turns out to be very different in the asynchronous setting, at least for read/wr i te  shared memory.
Namely, we present a fundamental impossibility result, saying that a basic consensus problem cannot be solved at all in the asynchronous read/wr i te  shared memory setting, even if it is known that at most one process will fail.
The impossibility of consensus is considered to be one of the most fundamental results of the theory of distr ibuted computing.
It has practical implications for any distr ibuted application in which some type of agreement is required.
For example, processes in a database system may need to agree on whether a transaction commits or aborts.
Processes in a communication system may need to agree on whether or not a message has been received.
Processes in a control system may need to agree on whether or not a particular other process is faulty.
Then the impossibility result implies that there is no purely asynchronous algorithm.
This means that, in practice, designers must go outside the asynchronous model in order to solve such problems, for example, relying on timing information.
We define a particular consensus problem in the shared memory setting.
Chapter  10 contains a similar informal presentation for the mutual exclusion problem, plus some guidelines showing how it can be formalized.
The architecture we use here is essentially the same one we used in Chapters.
The entire assembly of processes and variables is modelled as a single I /O  automaton.
See Example 9.2.1 for one collection of users for the agreement problem.
This time, we assume that the external interface of each user Ui consists of output  actions init(v)i, where v E V is an input value for the shared memory system, and input actions decide(v)i inputs, where v E V is a decision value.
The external interface of the shared memory system includes all the input actions init(v)~, where v E V is an input value and i is a port name (i.e., process index), and all the output  actions decide(v)i, where v E V is a decision value and i is a port  name.
Thus, we are assuming that the inputs for the problem arrive from the users in input actions.
Note that most of the research papers in this area assume that the initial values appear  in designated variables in the initial process states, while decisions are writ ten into designated state variables.
The formulation we use is more consistent with the style we are using elsewhere in the book.
Each user automaton must satisfy one restriction: it can only perform at most one initi event in an execution; that is, we assume that each process receives at most one input.
We assume in this chapter that there is exactly one task per process; in light of Exercise 8.8, this is not a significant restriction.
We assume that the processes are subject to stopping failures, by which we mean that they might simply stop without warning.
Formally, we model this by including special stopi input actions, one for each process, in the external interface (external signature) of the shared memory system.
The stopi actions are not considered to be par t  of the external  interfaces of the user automata;  they just  arrive from some unspecified external  environment  (see Section 9.6)
Wi th  this method of modelling failures, and according to the formal definitions in Chapter  8, the fair executions of the system are those in which each process that  does not fail, as well as each user task, gets infinitely many opportunit ies  to perform locally controlled steps.
We say that  an execution of the system is failure-free if it contains no stop events.
We say that  a sequence of init4 and decidei actions is well-formed for user i, provided that  it is some prefix of a sequence of the form init(v)i, decide(w)i (i.e., the empty  sequence, just  an init(v)i, or a two-action sequence init(v)i, decide(w)i)
In part icular ,  it does not contain repeated inputs at port  i, nor repeated decisions at port  i, nor does it contain any decision without  a preceding input.
We require the following properties of any execution, fair or not, of the combined system.
Well-formedness: For any i, the interactions between Ui and the system are well-formed for i.
Validity: If all init actions that occur contain the same value v, then v is the only possible decision value.
Notice that the agreement and validity conditions are analogous to the curresponding conditions in Section 6.1, for the stopping agreement problem in the.
Failure-free termination: In any fair failure-free execution in which init events occur on all ports, a decide event occurs on each port.
We say that a shared memory system A solves the agreement problem for a particular collection of users Ui if it guarantees the well-formedness, agreement, validity, and failure-free termination conditions for the users Ui.
We say that i c solves the agreement problem if it solves the agreement problem for all collections of users.
The strongest condition we consider is the following, for executions in.
Wait-free termination: In any fair execution in which init events occur on all ports, a decide event occurs on every non-failing port (i.e., every port i on which no stopi event occurs)
That is, any process that does not fail eventually decides, regardless of the failures of any of the other processes.
This condition is analogous to the termination condition given in Section 6.1, for the stopping agreement problem in the synchronous setting.
This condition is called wait-freedom because it implies that no process can ever be blocked, waiting indefinitely for help from any other process.
Note that we have stated the wait-freedom condition to assume that inputs arrive on all ports.
We could have stated it equivalently to assume only that an input arrives at port i.
We leave it as an exercise for you to show that this.
Because the main impossibility result of this chapter involves only a single process failure rather than arbi t rary process failures, we need yet another termination condition.
It should be easy to see that the failure-free termination and wait-free termination conditions are the special cases of the f-failure termination condition where f is equal to 0 and n, respectively.
We say that a shared memory system guarantees wait-flee termination, guarantees f-failure termination, and so on, provided that it guarantees the corresponding condition for all collections of users.
The external actions of the combined system are also exactly these actions, and the requirement in each case is that the fair traces of the combined system are all in traces(P)
Synchronous termination c o n d i t i o n s.
The failure-free termination condition is similar to the weak termination condition of Section 7.3
In most of this chapter, we will consider the case of read/wr i te  shared memory, since that is the case in which the impossibility results hold.
We allow the variables to be mult i -wri ter /mult i -reader  registers.
Throughout this section, we suppose that A is an algorithm in the read/wri te.
Our objective is to reach a contradiction, showing that such an A cannot exist.
We first make some simplifying restrictions on A, all without loss of generality, and then present some needed terminology.
Then, because the proof is easier, we show that the agreement problem is unsolvable in the read/wri te  shared memory model, if the very.
Finally, we show the main r e su l t~ tha t  not even a single fault can be tolerated.
Third, we assume that A is "deterministic," in the sense that the automaton.
Finally, we assume that every non-failed process always has a locally controlled step enabled, even after it decides.
We define an initialization to be an execution of the combination of A and the users consisting exactly of n init steps, one for each port, in order of index.
We define an execution c~ to be input-first provided that it begins with an initialization.
The following lemma says that this classification is exhaustive, in the absence of failures.
That  is, there are no finite failure-free executions after which no decision is possible.
The fact that this is well-defined depends on two of the restrictions we made above: that every non-failed process always has a locally controlled step enabled and that the system is deterministic.
We begin by showing that A must have a bivalent initialization.
This means that the final decision value cannot be determined just from the inputs.
We leave the discovery of such algori thms for an exercise.
Similarly, the initialization a l  consisting of all ls  must  be 1-valent.
By assumption,  every initialization in the chain is univalent,  so.
Now consider any fair execution that  extends c~ and in which i fails immediately after the initialization (i.e., the next action is stopi), but  in which none of the other processes ever fails.
Now we can prove the first (simpler) impossibi l i ty r e su l t - - the  one for wait-free.
Namely, we suppose in this subsection that  a lgor i thm A has the.
The contradict ion is based on pinpoint ing a way in which a decision might.
In part icular ,  we define a decider execution a to be a finite failure-free input-first  execution satisfying the following conditions:
This chain construction is similar to the constructions used in the proof of Theorem 6.33, the lower bound on the number of rounds needed for agreement in the synchronous setting.
Thus, after a decider execution, no decision has yet been determined, but any additional (non-stop) process step will determine the decision.
We prove that A (with the wait-free termination property) must have a decider execution.
Suppose the contrary: that any bivalent failure-free input-first execution has a one-step bivalent failure-free extension.
The construction is simple: at each stage, we start  with a bivalent failure-free input-first execution, and we extend it by one step to another bivalent failure-free execution.
Our assumption at the beginning of this proof says that we can do this.
Since a is infinite, it must contain infinitely many steps for some process, say.
We claim that i must decide in c~, which yields a contradiction.
To see this, modify c~ by inserting a stopj event for each process j that.
Then c~' is a fair execution in which process i does not fail.
The wait-free termination condition then implies that i must decide in c~'
Now we can obtain the contradiction that we need to prove the impossibility.
We complete the proof with a case analysis, getting a contradiction for each possibility.
Consider extending extension(c~,j) in such a way that no process fails, process i takes no further steps, and each process except for i takes infinitely many steps.
This looks to every process except i like a fair execution in which process i fails immediately and no other process fails.
This is because i's step is just  a read, so the only thing it changes is the state of process i.
So we can take the same suffix that we previously ran after c~, beginning with the step of j ,  and run it after extension(a, i)
In this case also, all processes except i decide 1, which contradicts the assumption that.
This case is symmetric to Case 1, and the same argument applies.
Process i's step and process j ' s  step are both writes.
Consider two executions that extend c~, one by allowing first i to take its step and then j ,  and the other allowing first j ,  then i.
Since the two steps involve different processes and different variables, the system state is the same after either execution.
If we run all the processes from this state with no failures, they are required to decide.
This is because the step of j overwrites the value writ ten by i, so.
So we can take the same suffix that we previously ran after eztension(c~, j) and run it after extension(a, ij)
So, we have contradictions in all possible cases, and thus we conclude that no such algorithm A can exist.
Notice that the proof of Theorem 12.6 in the previous section does not work for.
The problem is in the proof of Lemma 12.4, where we use the wait-free termination condition to assert that process i must decide in a fair execution in which it does not fail.
This time, the proof is based on the following lemma, which says that a bivalent execution can be extended to allow a given process to take a step, while still maintaining bivalence.
This implies, in particular, that extension(a, i) is univalent; suppose without loss of generality that it is 0-valent.
Let a '  be the execution up to the first point.
Suppose that j is the process that takes the intervening step.
We finish with a case analysis similar to the one in the proof of Lemma 12.5, obtaining a contradiction for each case.
Then we claim that the states after extension(a', ji) and extension(a', iN) are indistinguishable to every process except for i.
This is because the steps of i involved in these two extensions are both read steps, which do not affect anything except the state of process i.
Consider extending extension(a ~, ij) in such a way that i takes no further steps and every other process takes infinitely many steps.
Process i's step and process j ' s  step are both writes.
In this case we get the same sort of commutative scenario as in Case.
We use Lemma 12.7 to construct a fair failure-free input-first execution in which no process ever decides.
The construction begins with a bivalent initialization, whose existence is guaranteed by Lemma 12.3
The resulting execution is fair, because each process takes infinitely many steps.
However, no process ever reaches a decision, which gives the needed contradiction.
In contrast  to the situation for read/wr i te  shared memory, it is very easy to solve the agreement problem, guaranteeing wait-free termination, using readmodify-write shared memory.
RMWAgreement algorithm: The shared variable begins with the value unknown.
If it sees the value unknown, then it changes the value to its own initial value and decides on this value.
On the other hand, if it sees a value v 6 V, then it does not change the value written in the variable but instead accepts the previously written value as its decision value.
Namely, the state contains an additional component stopped, a set of processes, initially empty.
There is a new stopi action, which puts i into stopped.
Wait-free termination follows, because each process i, after receiving an initi input, is immediately enabled to perform an accessi and then a decidei.
Agreement and validity follow, because the first process to perform an access establishes the common decision value.
The agreement problem can also be considered using shared memory of other variable types besides read/wri te  and read-modify-write.
For example, we can consider variables with operations such as swap, test-and-set, fetch-and-add, and compare-and-swap.
The agreement problem is only one example of a "decision problem" that can.
In this section, we define the general notion of a decision problem, give some examples, and state (without proof) some typical computability results.
Our definition of a decision problem is based on the preliminary definition of.
A decision mapping D specifies, for each length n vector w of inputs over some fixed value set V, a nonempty set D(w) of allowable length n vectors of decisions.
We use a decision mapping D in the formulation of a problem to be solved.
The well-formedness condition and the various termination conditions are defined in exactly the same way as for the agreement problem.
However, in place of the agreement and validity conditions used in the agreement.
The agreement problem is an example of a decision problem, based.
Vn of inputs in V, the set D(w) of allowable vectors of decisions is defined by.
It is easy to see that the decision problem based on D is the same as.
One apparent difference is that the definition of a general decision problem only mentions executions in which init inputs arrive on all ports, whereas the definition of the agreement problem involves other executions as well.
In the k-agreement problem, where k is any positive integer, the agreement and validity conditions of the agreement problem are replaced with the following:
A g r e e m e n t :  In any execution, there is a subset W of V, IWI = k, such that all decision values are in W.
Va l id i ty :  In any execution, any decision value for any process is the initial value of some process.
The agreement condition is weaker than that for ordinary agreement in that it permits k decision values rather than only one.
The validity condition is a slight strengthening of the validity condition for ordinary agreement.
It is easy to formalize the k-agreement problem as a decision problem.
The following can be shown, though we omit the proofs here and leave them for exercises:
In the approzimate agreement problem, the set V of values is the set of real numbers, and processes are permitted to send real-valued data in messages.
Now instead of having to agree exactly, as in the agreement problem, the requirement is that the processes agree approximately, to within a small positive tolerance e.
That is, the agreement and validity conditions of the agreement problem are replaced with the following:
A g r e e m e n t :  In any execution, any two decision values are within e of each other.
Again, it is easy to formalize this problem as a decision problem.
We close this chapter with a theorem that gives some conditions that imply that a decision problem cannot be solved with l-failure termination.
For any set of length n vectors of elements of V, we define a graph.
The vertices of this graph are the vectors of length n, and the edges are the pairs of vectors that differ in exactly one position.
Then there must be a decision mapping D' with D'(w) C_ D(w) for all w, such that both of the following hold:
If input vectors w and w' differ in exactly one position, then there exist y C D' (w) and y' C D' (w') such that y and y' differ in at most one position.
For each w, the graph defined by D'(w) is connected.
The first result in the literature about the impossibility of agreement in faultprone systems was proved by Fischer, Lynch, and Paterson [123]
This result was proved for the asynchronous message-passing setting, for the case of l-failure termination.
Later, this result and its proof were extended to the asynchronous shared memory setting, a slightly stronger model, by Loui and Abu-Amara [199]
See Chapter 17 for relationships between the asynchronous shared memory and asynchronous network models.
The presentation in this chapter follows the proofs of [199]
The results about agreement using other types of shared variables besides read/write variables are due to Herlihy [150]
Herlihy's paper not only classifies which types of variables are capable of solving the agreement problem, but also determines which types can "implement" which other types.
The problem of k-agreement was originally posed by Chaudhuri [73], in the setting of asynchronous networks.
Chaudhuri proved that k-agreement can be solved with k -  1-failure termination, but the question of whether it can be solved with k-failure termination remained open for several years.
Herlihy and Shavit presented their result in the context of a topological characterization of the problems that can be solved in fault-prone asynchronous read/write shared memory systems.
The characterization includes consideration of restricted sets of input vectors rather than just the complete sets considered in this book.
The problem of approximate agreement in asynchronous systems was originally defined by Dolev, Lynch, Pinter, Stark, and Weihl [98]
Their work was carried out in the asynchronous network model.
Attiya, Lynch, and Shavit [24] developed a wait-free asynchronous shared memory algorithm for approximate agreement.
The characterization includes consideration of restricted sets of input vectors.
These results were originally proved for the asynchronous network setting, but the proofs extend to the asynchronous read/write shared memory setting.
Prove that the stronger form of the wait-free termination condition in which inputs need only arrive at port i is equivalent to the given formulation.
More specifically, show how to modify a given algorithm A that guarantees well-formedness, agreement, validity, and wait-free termination, so that the modified version guarantees the same conditions but with the stronger wait-free termination condition.
Describe an algorithm that solves the agreement problem (without any fault-tolerance requirements) in the read/write shared memory model and.
This time consider a more constrained fault model than general stopping failures, in which processes can only fail at the very beginning of computation.
Can the agreement problem be solved in this model, guaranteeing.
In each case, give either an algorithm or an impossibility proof.
Prove that any agreement protocol in the read-modify-write shared memory model that guarantees 1-failure termination must have a bivalent initialization.
If a and b are invocations of the variable type, then, letting f2(a, v) denote the second projection of f(a, v) (i.e., the new value of the variable), at least one of the following holds:
Express the following formally as decision problems by giving the decision mappings:
Consider the approximate agreement problem for n = 2 processes.
Generalize the result of Exercise 12.13 to an arbitrary number n of processes.
Consider the two-process wait-free approximate agreement algorithm you designed for Exercise 12.13
We are assuming that your algorithm is "deterministic," as defined in Section 12.2.1
For each input-first prefix ct of this execution, describe the set of decision vectors that are actually attained in extensions of a.
Hint: Fix any algorithm A that solves D with l-failure termination, in the read/write shared memory model.
For any input vector w, define D~(w) to be the set of decision vectors that  are actually attained in input-first executions of A with input vector w.
This time, after each finite failure-free input-first execution, consider whether the set of attainable decision vectors is connected or disconnected.
Use Theorem 12.15 to prove that some other decision problems besides ordinary agreement cannot be solved in asynchronous read/write shared memory systems with l-failure termination.
Define as many interesting problems as you can for which impossibility can be proved in this way.
Extend the conditions in Theorem 12.15 to a general characterization of the decision problems that can be solved in asynchronous read/write shared memory systems with l-failure termination.
In this chapter, our last on the asynchronous shared memory model, we introduce atomic objects.
An atomic object of a particular type is very much like an ordinary shared variable of that same type.
The difference is that an atomic object can be accessed concurrently by several processes, whereas accesses to a shared variable are assumed to occur indivisibly.
Even though accesses are concurrent, an atomic object ensures that the processes obtain responses that make it look like the accesses occur one at a time, in some sequential order that is consistent with the order of invocations and responses.
In addition to the atomicity property, most atomic objects that have been studied satisfy interesting fault-tolerance conditions.
The strongest of these is the wait-free terminat ion condition, which says that any invocation on a nonfailing port eventually obtains a response.
This property can be weakened to require such responses only if all the failures are confined to a designated set I of ports or to a certain number f of ports.
The only types of failures we consider in this chapter are stopping failures.
Atomic objects have been suggested as building blocks for the construction of multiprocessor systems.
Then starting from these basic atomic objects, you could build successively more powerful atomic objects.
The resulting system organization would be simple, modular, and provably correct.
The problem, as yet unresolved, is to build atomic objects that provide sufficiently fast responses to be useful in practice.
Atomic objects are indisputably useful, however, as building blocks for asynchronous network systems.
Formally, many of these can be viewed as distributed implementations of atomic objects.
In Section 13.1, we provide the formal framework for the study of atomic objects.
That is, we define atomic objects and give their basic properties, in particular, results about their relationship to shared variables of the same type and results indicating how they can be used in system construction.
Then in the rest of the chapter, we give algorithms for implementing particular types of atomic objects in terms of other types of atomic objects (or, equivalently, in terms of shared variables)
The types of atomic objects we consider are read/wri te  objects, read-modify-write objects, and snapshot objects.
The results we present are only examples-- there  are many more such results in the research literature, and there is still much more research to be done.
We first define atomic objects and their basic properties, then give a construction of a canonical wait-free atomic object of a given type, and then prove some basic results about composing atomic objects and about substituting them for shared variables in shared memory systems.
These results can be used to justify the hierarchical construction of atomic objects from other atomic objects.
Many of the notions in this section are rather subtle.
So we will go slowly here and present the ideas somewhat more formally than usual.
On a first reading, you might want to skip the proofs and only read the definitions and results.
The definition of an atomic object is based on the definition of a variable type from Section 9.4
In particular, recall that a variable type consists of a set V of values, an initial value v0, a set of invoca t ions , a set of responses ,  and a function f : i n v o c a t i o n s  x V --+ responses  x V.
This function f specifies the response and new value that result when a particular invocation is made on a variable with a particular value.
Also, the traces of a variable type are the sequences of a's and b's that are derived from executions of the type.
In particular,  it must have a particular type of external interface (external signature) and must satisfy certain "well-formedness," "atomicity," and liveness conditions.
Associated with each port i, A has some input actions of the form ai, where a is an invocation of the variable type, and some output  actions of the form bi, where b is a response of the variable type.
If ai is an input action, it means that a is an allowable invocation on port i, while if bi is an output  action, it means that b is an allowable response on port i.
We assume a technical condition: if ai is an input on port i and if f (a ,  v) = (b, w) for some v and w, then bi should be an output  on port i.
That  is, if invocation a is allowed on port i, then all possible responses to a are also allowed on port i.
In addition, since we will consider the resiliency of atomic objects to stopping failures, we assume that there is an input stopi for each port i.
We describe an external interface for a 1-writer/2-reader atomic object for domain V.
Next, we describe the required behavior of an atomic object automaton A of a particular variable type 7-
The outputs of Ui are assumed to be the invocations of A on port i, and the inputs of Ui are assumed to be the responses of A on port i.
The stopi action is not part  of the signature of Ui; it is assumed to be generated not by Ui, but by some unspecified external source.
The only other proper ty  we assume for Ui is that  it preserve a "well-formedness" condition, defined as follows.
Ui to be well-formed for user i provided that  it consists of al ternat ing invocations and responses,  s tar t ing with an invocation.
We require that  A x U, the combined system consisting of A and U, satisfy.
First ,  there is a well-formedness condition similar to the ones.
Since we have already assumed that the users preserve well-formedness, this.
The way of saying this formally is a little more complicated than you might.
So we st ipulate that  each execution looks as if the.
In order to define atomici ty  for the system A x U, we first give a more basic.
This would require some extensions to the theory presented in this chapter; we avoid these complications so that we can present the basic ideas reasonably simply.
These operations and responses should be selected, and these serialization points inserted, so that the sequence of invocations and responses constructed as follows is a trace of the underlying variable type T:
That is, "shrink" the interval of operation rr to its serialization point.
Finally, remove all invocations of incomplete operations rr ~ (I)
Notice that the atomicity condition only depends on the invocation and response events-- i t  does not mention the stop events.
We can easily extend this definition to executions of A and of A x U.
In (b), the same operation intervals are assigned serialization points in the opposite order.
Each of the executions in ( c ) a n d  (d) includes  an incomplete write(8) operation.
In each case, a serialization point is assigned to the write(8), because its result is seen by a read operation.
Now we are (finally) ready to define the atomicity condition for the combined system A x U.
A t o m i c i t y :  Let c~ be a (finite or infinite) execution of A x U that is well-formed for every i.
We can also express the atomicity condition in terms of a trace property (see the definition of a trace property in Section 8.5.2)
Namely, define the trace property P so that its signature sig(P) is the external interface of A x U and its trace set traces(P) is exactly the set of sequences that satisfy both of the following:
The interesting thing about P is that it is a safety property, as defined in Section 8.5.3
This is not obvious, because the atomicity property has a rather complicated definition, involving the existence of appropriate placements of serialization points and selections of operations and responses.
The proof of Theorem 13.1 uses KSnig's Lemma, a basic combinatorial lemma about infinite trees:
We show how to make such selections for fl'Let -~ denote the sequence obtained from fl by inserting the selected serialization points.
Consider an infinite sequence fl and suppose that all finite prefixes of/3 are in traces(P)
The tree G that we construct in order to apply KSnig's Lemma describes the possible placements of serialization points in ft.
Each node of C is labelled by a finite prefix of fl, with serialization points inserted for some subset of the operations that are invoked in ft.
We only include labels that are "correct" in the sense that they satisfy the following three conditions:
Every completed operation has exactly one serialization point, and that serialization point occurs between the operation's invocation and response.
Every incomplete operation has at most one serialization point, and that serialization point occurs after the operation's invocation.
Start with the initial value v0 and apply the function once for each serialization point, in order, with the corresponding invocation as the first argument.
The response that is calculated for zc is the response obtained when the function is applied for the serialization point ,~
The label of each non-root node is an extension of the label of its parent.
The label of each non-root node ends with an element of/3
The label of each non-root node contains exactly one more element of fl than does the label of its parent node (and possibly some more serialization points)
Thus, at each branch point in G, a decision is made about which serialization points to insert, in which order, between two particular symbols in ft.
First, it is easy to see that each node of G has only finitely many children.
This is because only operations that have already been invoked can have their serialization points inserted and there are only finitely many places to insert these serialization points.
Second, we claim that G contains arbitrari ly long paths from the root.
This assignment yields a corresponding path in G of length Ifl~l.
Since G contains arbitrari ly long paths from the root, it is infinite.
Then KSnig's Lemma (Lemma 13.2) implies that G contains an infinite path from the root.
The node labels on this path yield a correct selection of serialization points (and consequently, of incomplete operations and responses) for the entire sequence ft.
The liveness properties we consider are termination conditions similar to those we gave for the agreement problem, in Section 12.1
The simplest requirement is for failure-free executions, that is, those executions in which no stop event occurs.
Fai lure- free  t erminat ion:  In any fair failure-free execution of A x U, every invocation has a response.
Note that if we wanted to consider only the failure-free case, then we could.
The reason we have given the more complicated statement of the atomicity condition is that we shall also consider failures.
As for the mutual exclusion problem in Section 10.2, it is possible to reformulate the entire definition of an atomic object equivalently in terms of a trace.
This time, sig(P) includes all the external interface actions of the atomic object, including the stop actions as well as the invocation and response actions, and traces(P) expresses well-formedness, atomicity, and failure-free termination.
Then an automaton A with the right interface is an atomic object of.
That is, any port on which no failure occurs provides responses for all invocations, regardless of the failures that occur on any of the other ports.
Failure-free termination and wait-free termination are the special cases of the ffailure termination condition where f is equal to 0 and n, respectively.
A further generalization allows us to talk about the failure of any particular set of ports.
Thus, f-failure termination is the same as /-failure termination for all sets I of ports of size at most f.
We say that A guarantees wait-free termination, guarantees I-failure termination, and so on, provided that it guarantees the corresponding condition for all collections of users.
We close this section with a simple example of a shared memory system that is an atomic object.
We define the read/increment variable type to have N as its domain, 0 as its initial value, and read and increment as its operations.
Let A be a shared memory system with n processes in which each port  i supports both read and increment operations.
Shared variable x(i) is writable by process i and readable by all processes.
When an increment4 input occurs on port i, process i simply increments its own shared variable, x(i)
It can do this using only a write operation, by remembering the value of x(i) in its local state.
When a readi occurs on port i, process i reads all the shared variables x( j )  one at a time, in any order, and returns the sum.
Then it is not hard to see that A is a read/ increment  atomic object and that it guarantees wait-free termination.
For example, to see the atomicity condition, consider any execution of A x U.
Now, note that any completed (high-level) read operation 7r returns a value v that is no less than the sum of all the x(i) 's  when the read is invoked and no greater than the sum of all the x(i) 's  when the read completes.
In this subsection we give an example of an atomic object automaton C for a given variable type 7- and given external interface.
It can be used to help show that other automata are wait-free atomic objects.
It also has two buffers, inv-buffer for pending invocations and resp-buffer for pending responses, both initially empty.
Finally, it keeps track of the ports on which a stop action has occurred, in a set stopped, initially empty.
When an invocation arrives, C simply records it in inv-buffer.
At any time, C can remove any pending invocation from inv-buffer and perform the requested operation on the internal copy of the shared variable.
When it does this, it puts the resulting response in resp-buffer.
Also at any t ime,  C can  remove  any  pend ing  r e sponse  f rom resp-buf fer  and  convey  the r e sponse  to the user.
A stopi event  j u s t  adds  i to stopped, which  enables  a special  d u m m y i  ac t ion hav ing  no effect.
It  does  not ,  however ,  d isable  the o ther  local ly  con t ro l l ed.
To see wait-freedom, consider any fair execution a of C x U and suppose that  there are no failures on.
The fairness of then implies that  every invocation on port  i t r iggers  a performi event and a.
Also, for each 7~ E (I), select the response re turned  by the perform as the response for the operation.
Suppose that fa ir traces(A x U) C fair traces(C x U) for  every composition U of user automata.
Then A is an atomic object guaranteeing waitfree terminat ion.
The wai t - f reedom condition follows immedia te ly.
We also have a converse to Theorem 13.4, which says that every fair trace that is allowed for a wait-free atomic object is actually generated by C:
Theorem 13.5 Suppose that A is an I /O automaton with the same external interface as C.
Suppose that A is an atomic object guaranteeing wait-free terruination.
Then fairtraces(A x U) C_ fairtraces(C x V), for every composition U of user automata.
In this subsection, we give a theorem that says that the composition of atomic objects (using ordinary I /O automaton composition, defined in Section 8.2.1) is also an atomic object.
Recall the definitions of compatible variable types and composition of variable types from the end of Section 9.4
Furthermore, if every Aj guarantees I-failure termination (for all collections of users), then so does A.
In atomic object A, port i handles all the invocations and responses that are handled on port i of any of the Aj.
According to the definition of composition, the state of A has a piece for each Aj.
The invocations and responses that are derived from Aj only involve the piece of the state of A associated with Aj.
The stopi actions, however, affect all parts of the state.
We leave the proof of Theorem 13.6 for an exercise.
The definition of an atomic object says that its traces "look like" traces of a sequentially accessed shared variable of the underlying type.
The most important  fact about atomic objects, from the point of view of system construction, is that it is possible to substitute them for shared variables in a shared memory system.
This permits modular construction of systems: it is possible first to design a shared memory system and then to replace the shared variables by arbitrary atomic objects of the given types.
Finally, we define the sense in which the resulting system behaves in the same way as the original system and prove that, with the given conditions, the resulting system really does behave in the same way.
Although the basic ideas are reasonably simple, there are a few details that have to be handled carefully in order to make the substitution technique work out right.
We begin with A, an arbi t rary algorithm in the shared memory model of.
We permit  each process i of A to have any number of tasks.
We also include stopi actions, as discussed in Section 9.6, and assume that each stopi event permanently disables all the tasks of process i.
Consider A in combination with any collection of user automata Ui.
This is supposed to indicate whose turn it is to take the next step, after c~
Then to satisfy the conditions we need here, we would have to add a restriction, namely, that process i cannot do anything before an initi occurs.
This condition is satisfied by the only algorithm in Chapter  12, R M W A g r e e m e n t.
Suppose that for each shared variable x of A, we are given an atomic object automaton B~ of the same type and the appropriate external interface.
On each port,  it allows all invocations and responses that are used by process i in its interactions with shared variable x in algorithm A.
It also has stopi inputs, one for each port, as usual.
Then we define Trans(A), the transformed version of A that uses the atomic objects B~ in place of its shared variables, to be the following automaton:
Trans(A) is a composition of I /O automata, one for each process i and one for each shared variable x of algorithm A.
For each process i, the automaton is Pi, defined as follows.
The inputs of Pi are the inputs of A on port i plus the responses of each Bx on port i plus the stopi action.
The outputs of Pi are the outputs of A on port i plus the invocations for each B~ on port i.
Pi's steps simulate those of process i of A directly, with the following exceptions: When process i of A performs an access to shared variable x, Pi instead issues the appropriate invocation to Bx.
After it does this, it suspends its activity, awaiting a response by Bx to the invocation.
When a response arrives, Pi resumes simulating process i of A as usual.
There is a task of Pi corresponding to each task of process i of A.
If a stopi event occurs, all tasks of Pi are thereafter disabled.
The architecture of the transformed system Trans(A) is depicted in part (b)
Note the external interfaces of the automata Bx and By.
For the purpose of disambiguation, such invocation and response actions could also be subscripted with the name of the object, here x and y.
We avoid this detail in this example since there happens to be no ambiguity here.
Now we give a theorem describing what is preserved by transformation.
Execution a does not have to be fair for these conditions to hold.
These conditions say that  a looks to the users like an execution a~ of.
Theorem 13.7 then goes on to identify some conditions under which the.
As you would expect, one of the conditions is that  c~ is itself a fair execution of the.
But this is not enough--we also need to make sure that  the object au tomata  Bx do not cause processing to stop.
So we include two other conditions that  together ensure that  this does not happen, namely, that  all the.
Then there is an execution a ~ of A x U such that the following conditions hold:
These serialization points and responses can be guaranteed to satisfy the "shrinking" property described in the atomicity.
There is one additional technicality: if any stopi event in a occurs after an invocation by process i and before the serialization point to which the invocation is moved, then that stopi event is also moved to the serialization point, just after the invocation and response.
We claim that it is possible to move all the events that we have moved in this.
And second, while Pi is waiting for a response, it is the sys tem's  turn to take steps.
This means that U~ will not perform any output steps, so Pi will receive no inputs.
Similarly, we claim that we can add the responses we have added and remove.
This is because if Pi performs an incomplete operation in c~, it does not do anything after that operation.
It does not matter if Pi stops just before issuing the invocation, while waiting for a response, or just after receiving.
We use the definition of indistinguishable given in Section 8.7
Since we have not changed anything significant by this motion, addition, and removal of events, we can simply fill in the states of the processes Pi as in c~
The result is a new execution, C~l, also of the system Trans(A) x U.
Now, c~1 is an execution of Trans(A) x U, which is not exactly what we need; rather, we need an execution of the system A x U.
But notice that in C~l, all the invocations and responses for the object automata  Bz occur in consecutive matching pairs.
So we replace those pairs by instantaneous accesses to the corresponding shared variables and thereby obtain an execution c~' of the system A x U.
Thus, Theorem 13.7 implies that any algorithm for the shared memory model (with some simple restrictions) can be t ransformed to work with atomic objects instead of shared variables and that the users cannot tell the difference.
We give as a corollary the special case of Theorem 13.7 where the atomic objects Bx all guarantee wait-free termination.
Suppose that c~ is any fair execution of Trans(A) x U.
Then there is a fair execution ~' of A x U such that the following conditions hold:
In the special case where A is itself an atomic object, Theorem 13.7 implies that Trans(A) is also an atomic object.
Corollary 13.9  Suppose that A and all the Bx's are atomic objects guaranteeing I-failure termination.
Then Trans(A) is also an atomic object guaranteeing I-failure termination.
First  let c~ be any execution of Trans(A) and a collection of users Ui.
It remains to consider t h e / - f a i l u r e  terminat ion condition.
This is enough to show/ - fa i lu re.
Hierarchical construction of  s h a r e d  m e m o r y  s y s t e m s.
In the special case where each atomic object Bx is itself a shared memory  system, we claim that.
Trans(A) can also be viewed as a shared memory  system.
Namely, each process i of Trans(A) (viewed as a shared memory  system) is a combination of process Pi of Trans(A) and the processes indexed by i in all of the shared memory  systems Bx.
This combinat ion is not exactly an I / O  au tomaton  composit ion,  because the processes in the Bx's are not I / O  automata.
However, the combination is easy to describe: the state set of process i of Trans(A) is just  the Car tes ian  product of the state set of Pi and the state sets of all the processes indexed by i in all the.
Trans(A) are just  the actions of all the component  processes i, and similarly for the tasks.
Par t  (a) shows Trans(A), including the shared memory  systems Bx plugged in for all the shared variables x of A.
Par t  (b) shows the same system as in par t  (a), with.
Thus, all the shaded processes from part (a) are now combined into a single process 1 in part (b)
By the definition of Trans(A), the effect of a stopi event in the system of part (a) is to immediately stop all tasks of all the processes associated with port / - - the  tasks of Pi as well as the tasks of all the processes i of the Bx's.
This is the same as saying that stopi stops all tasks of the composed process i in the system of part (b), which is just what stopi is supposed to do when that system is regarded as a shared memory system.
Finally, consider the very special case where shared memory system A is an atomic object guaranteeing /-failure termination and each atomic object Bx is a shared memory system that guarantees /-failure termination.
Then Corollary 13.9 and the previous paragraph imply that Trans(A) is an atomic object guarantee ing/ - fa i lure  termination and also that it is a shared memory system.
This observation says that two successive layers of atomic object implementations in the shared memory model can be collapsed into one.
Before presenting specific atomic object constructions, we give a sufficient condition for showing that a shared memory system guarantees the atomicity condition.
This lemma enables us to avoid reasoning explicitly about incomplete operations in many of our proofs that objects are atomic.
For this lemma, we suppose that A is a shared memory system with an external interface appropriate for an atomic object for variable type 7-
Suppose that every (finite or infinite) execution c~ of A x U containing no incomplete operations satisfies the atomicity property.
Then the same is true for every execution of A x U, including those with incomplete operations.
Let c~ be an arbitrary finite or infinite execution of the combined system A x U, possibly containing incomplete operations.
Since A guarantees failure-free termination, every operation in c~2 is completed.
Since, by Theorem 13.1, atomicity combined with well-formedness is a safety property and hence is limit-closed, it follows that alext(U ) satisfies the atomicity property, as needed.
We consider the problem of implementing a read-modify-write atomic object in the shared memory model with read/write shared variables.
See Section 9.4 for the definition of a read-modify-write variable type.
To be specific, we fix an arbitrary n and suppose that the read-modify-write object being implemented has n ports, each of which can support arbitrary update functions as inputs.
If all we require is an atomic object and we are not concerned about tolerating failures, then there are simple solutions.
The latest value of the read-modify-write variable corresponding to the object being implemented is kept in a read/write shared variable x.
Using a set of read/write shared variables different from x, the processes perform the trying part of a lockout-free mutual exclusion algorithm (for example, PetersonNP from Section 10.5.2) whenever they want to perform operations on the atomic object.
When a process i enters the critical region of the mutual exclusion algorithm, it obtains exclusive access to x.
Then process i performs its read-modify-write operation using a read step followed by a separate write step.
After completing these steps, process i performs the exit part of the mutual exclusion algorithm.
However, this algorithm is not fault-tolerant: a process might fail while it is in its critical region, thereby preventing any other process from accessing the simulated read-modify-write variable.
We give an impossibility result, even for the case where only a single failure is to be tolerated.
Suppose for the sake of contradiction that there is such a system, say B.
Let A be the RMWAgreement algorithm for agreement in the read-modify-write shared memory model, given in Section 12.3
Now we apply the transformation of Section 13.1.4 to A, using B in place of the single shared read-modify-write variable of A.
The proof of this is similar to that  of Corollary 13.9
First  let c~ be any execution of Trans(A) and a collection of users Ui.
Since A solves the agreement  problem, c~' satisfies the well-formedness, agreement, and validity properties.
Now consider any port  i with no stopi event in c~
Because A guarantees  l-failure terminat ion,  there is a decidei event in c~'
However, by the pa ragraph  at the end of Section 13.1, Trans(A) is itself a shared memory  system in the r ead /wr i t e  shared memory  model.
But  then Trans(A) contradicts  Theorem 12.8, the impossibil i ty of agreement  with l-failure terminat ion in the r ead /wr i t e  shared memory model.
In the rest of this chapter,  we consider the implementat ion of par t icular  types of atomic objects in terms of other types of atomic objects,  or, equivalently, in terms of shared variables.
This section is devoted to snapshot  atomic objects, and the next is devoted to r ead /wr i t e  atomic objects.
In the r ead /wr i t e  shared memory model, it would be useful for a process to be able to take an instantaneous snapshot of the entire state of shared memory.
Of course, the r ead /wr i t e  model does not directly provide this capabi l i ty - - i t only permits  reads on individual shared variables.
In this section, we consider the implementat ion of such a snapshot.
We formulate the problem as that  of implementing a par t icular  type of atomic object.
The variable type underlying a snapshot atomic object has as its domain V the set.
The operations are of two kinds: writes to individual vector components, which we call update operations, and reads of the entire vector, which we call snap operations.
A snapshot atomic object can simplify the task of programming a read/wr i te  system.
We start  with a description of the problem, then give a simple solution that.
Then we show how the construction can be modified to work with bounded-size shared variables.
Section 13.4.5 contains an application of snapshot atomic objects in the implementation of read/wr i te  atomic objects.
We first define the variable type 7- to which the snapshot atomic object will correspond; we call this a snapshot variable type.
The definition begins with an underlying domain W with initial value w0
The domain V of T is then the set of vectors of elements of W of a fixed length m.
An update(i,w) invocation causes component i of the current vector to be set to the value w and.
A snap invocation causes no change to the vector but triggers a response containing the current value of the entire vector.
Next we define the external interface that we will consider.
We assume that there are exactly n - m + p ports, where rn is the fixed length of the vectors and p is some arbi t rary  positive integer.
The first m ports are the update ports, and the remaining p ports are the snap ports.
We sometimes abbreviate the redundant  notation update(i, w)~, which indicates an invocation of update(i, w) on port  i, as simply update(w)i.
Notice that we are considering a special case of the general problem, where updates to each vector component arrive only at a single designated port  and hence arrive sequentially.
It is also possible to consider a more general case, where many ports allow updates to the same vector component.
We consider implementing the atomic object corresponding to this variable type and external interface using a shared memory system with n processes, one per port.
We assume that all the shared variables are l -wr i te r /n- reader read/wr i te  shared variables.
Each variable x(i) can be writ ten by process i (the one connected to port i, which is the port for update(i, w) operations) and can be read by all processes.
Each variable x(i) holds values each of which consists of an element of W plus some additional values needed by the algorithm.
One of these additional values is an unbounded integer "tag."
In the UnboundedSnapshot algorithm, each process i writes the values that  it receives in updatei invocations into the shared variable x(i)
A process performing a snap operation must somehow obtain consistent values from all the shared variables, that  is, values that  appear to have coexisted in the shared memory at some moment  in time.
The way it does this is based on two simple observations.
Observation 1: Suppose that  whenever a process i performs an update(w)i operation, it writes not only the value w into x(i), but also a "tag" that  uniquely identifies the update.
Then, if a process j that  is a t tempt ing  to perform a snap operation reads all the shared variables twice, with the second set of reads start ing after the first set of reads is finished, and if it finds the tag in each variable x(i) to be the same in the first and second set of reads, then the common vector of values returned in the two sets of reads is in fact a vector that  appears in shared memory at some point during the interval of the snap operation.
In particular, this vector is the vector of values at any point after the completion of the first set of reads and before the start  of the second set.
Each process j performing a snap repeatedly performs a set of reads, one per shared variable, until two consecutive sets of reads are "consistent," that is, they return identical tags for every x(i)
When this happens, the vector of values returned by the second set of reads (which must be the same as that returned by the first set of reads) is returned as the response to the snap operation.
It is easy to see that whenever this simple algorithm completes an operation, the response is always "correct," that is, it satisfies the well-formedness and atomicity conditions.
However, it fails to guarantee even failure-free termination: a snap may never return, even in the absence of process failures, if new update operations keep getting invoked while the snap is active.
In particular,  the updatei operation that writes tag3 must be totally contained within the current snap.
To see why this is so, we argue first that the update that writes tag3 must begin after the beginning of the snap.
Second, we argue that the update that writes tag3 must end before the end of the snap.
It extends the simple algorithm above so that before an update process i writes to x(i),  it first executes its own embedded-snap subroutine, which is just like a snap.
Then, when it writes its value and tag in x(i),  it also places the result of its embeddedsnap in x(i)
A snap that fails to discover two sets of reads with identical tags despite many repeated at tempts  can use the result of an embedded-snap as a default snapshot value.
In this description, each shared variable is a record with several fields; we use dot notation to indicate the fields.
Two sets of reads re turn  the same x(i).tag for every i.
This is the same as the vector re turned by the first set of reads.
For some i, four dist inct  values of x(i).tag have been seen.
In this case, the snap re turns  the vector of values in x(i).view associated with the third of the four values of x(i).tag.
When an update(w)i input  occurs, process i behaves as follows.
This involves exactly the same work as is performed by a snap, except that  the vector determined is recorded locally by process i instead of being re turned to the user.
We insert the serialization point for each update operation at the point at.
The insertion of serialization points for snap operations is a little more complicated.
To describe this insertion, we find it helpful to assign serialization points not just to the snap operations but also to the embedded-snap operations.
First, consider any snap or embedded-snap that terminates by finding two consistent sets of reads.
For each such operation, we insert the serialization point anywhere between the end of the first of its two sets of reads and the beginning of its second.
Second, consider those snap and embedded-snap operations that terminate by finding four different tags in the same variable.
We insert serialization points for these operations one by one, in the order of their response events.
Note that this operation r has already been assigned a serialization point, since it completes earlier than 7~
We insert the serialization point for 7~ at the same place as that for r.
It is easy to see that all the serialization points are within the required intervals.
For the update operations and for the snap and embedded-snap operations that terminate by finding two consistent sets of reads, this is obvious.
For the snap and embedded-snap operations that terminate by finding four distinct tags, this can be argued by induction on the number of response events for such operations in a.
It remains to show that the result of shrinking the operation intervals to their respective serialization points is a trace of the underlying snapshot variable type.
For this, first note that after any finite prefix a '  of a,  there is a unique vector in V resulting from the write events in a '
It is enough to show that every snap operation returns the correct vector after the prefix of a up to the operation's serialization point.
More strongly, we argue that every snap and embedded-snap operation returns the correct vector for its serialization point.
This is clear for the operations that terminate by finding two consistent sets of reads.
For the other snap and embedded-snap operations, we argue this by induction on the number of response events for such operations in ~
The UnboundedSnapshot algorithm uses m shared variables, each of which can take on an unbounded set of values.
Even if the underlying domain W is finite, the variables are still unbounded because of the.
The main problem with the UnboundedSnapshot algorithm is that it uses unbounded-size shared variables to store the unbounded tags.
In this subsection, we sketch an improved algorithm called BoundedSnapshot, which replaces the unbounded tags with bounded data.
In order to achieve this improvement in efficiency, the BoundedSnapshot algorithm uses some mechanisms that are more complicated than simple tags.
Note that the unbounded tags are used in the UnboundedSnapshot algori thm only for the purpose of allowing processes performing snap and embedded-snap operations to detect when new update operations have taken place.
This information could, however, be communicated using a less powerful mechanism than a tag, in particular,  using a combination of handshake bits and a toggle bit.
Each variable x(i) is writable by update process i and readable by all processes, as before.
Note that, unlike in the UnboundedSnapshot algorithm, the execution of the snap and embedded-snap operations in BoundedSnapshot involve writing to shared memory.
The pair of bits for (i, j )  allow process i to tell process j about new updates by process i and also allow process j to acknowledge that it has seen this information.
Specifically, x(i) contains a length n vector comm of bits, where the element comm(j) in variable x ( i ) - -which  we denote by x(i) .comm(j)-- is  used by process i to communicate with process j about new updates by process i.
And y(j) contains a length m vector ack of bits, where the element ack(i) in variable y(j)--which we denote by y(j).ack(i)--is used by process j to acknowledge that it has seen new updates by process i.
Thus, the pair of handshake bits for ( i , j )  are x(i).comm(j) and y(j).ack(i)
A process j performing a snap or embedded-snap repeatedly tries to perform two sets of reads, looking for the situation where nothing has changed in between the two sets of reads.
But this time, changes are detected using the handshake bits rather than integer-valued tags.
Specifically, before each at tempt to find two consistent sets of reads, process j first reads all the handshake bits x(i).comm(j) and sets each handshake bit y(j).ack(i) equal to the value of x(i).comm(j) just read.
Thus, the update operations at tempt to set the handshake bits unequal and the snap and embedded-snap operations at tempt to set them equal.
Process j looks for changes to the handshake bits comm(j) in between its two sets of reads; if it finds such changes on 2m + 1 separate attempts,  then it knows it has seen the results of four separate update operations by the same process i and can adopt the vector view produced by the third of these operations.
The handshake protocol described so far is simple and is "sound" in the sense that every time a process performing a snap or embedded-snap detects a change, a new update has in fact occurred.
However, it turns out that the handshake is not sufficient to discover every upda te - - i t  is possible for two consecutive updates by a process i not to be distinguished by some other process j.
Then the following events may occur, in the indicated order.
The actions involving the two processes i and j appear in separate columns.
In this sequence of events,  process  j per forms three reads of x ( i )
The first of these is jus t  a p re l iminary  test;  the second and th i rd  are.
Here, process j de te rmines  as a resul t  of its second and third  reads tha t  no upda tes have occur red  in between.
To overcome this problem,  we augment  the handshake  protocol  with a second.
This  ensures  tha t  each update changes the value of the shared  variable x( i )
In a bit  more  detail ,  the protocol  works as follows:
It r epea ted ly  a t t e m p t s  to ob ta in  two sets of reads tha t  look "consis tent ."  Specifically, in each a t t empt ,  process  j first reads  all the.
Then  for each i, process  j sets y ( j )
If process j ever records on three separate attempts that the same x(i) has changed, then consider the second of these three attempts.
The snapj operation returns the vector of values in x(i).view obtained in the final read of x(i) at that attempt.
It is guaranteed that this vector was written in the course of an update operation whose interval is completely contained within the interval of the given snapj.
Second, it performs an embedded-snap, which is the same as a snap except that the vector determined is not returned to the user.
For each j ,  x(i).comm(j) is set unequal to the value of y(j).ack(i) obtained in the initial read of y(j)
Well-formedness and wait-freedom are easy to see, as in the proof of Theorem 13.13 for the UnboundedSnapshot algorithm.
For example, for a snap or embedded-snap operation that terminates by finding two consistent sets of reads, we select any point between the end of the first of these two sets and.
As before, it is easy to see that the serialization points occur within the required intervals.
It remains to show that the result of shrinking the operation intervals to their respective serialization points is a trace of the snapshot variable type.
As before, it is enough to show that every completed snap and embedded-snap operation returns the correct vector after the prefix of c~ up to the serialization point.
This time, it is not so easy to show this property for snap and embedded-snap operations that terminate by finding two consistent sets of reads.
To show this, it is enough to prove the following claim.
No write event by process i occurs between the read of x(i) in the first set and the read of x(i) in the second set.
Let r be the last such write, that is, the last write of x(i) prior to 7r2
Let b denote this common value and let :r0 denote this last write event.
Also by consistency, the values of x(i).toggle read in :rl and 7r2 are equal.
Since r is the last write of x(i) prior to 7r2, it must be that it sets x( i )
The update operation containing r must contain an earlier read event r of y(j)
By the way update operations behave, the value of y(j) .ack( i)  read by r must be b.
We are using the bar notation here to denote bit complementation.
Thus, the order of the various read and write events must be the following.
Again, the actions involving the two processes i and j appear in separate columns.
This shows Claim 13.15, which implies that every snap or embedded-snap operation that terminates by finding two consistent sets of reads in fact returns the correct vector after the prefix of a up to the serialization point.
For the other snap and embedded-snap operations, the needed property is argued, as for UnboundedSnapshot, by induction on the number of response events for such operations in a.
Snapshot shared variables represent a powerful type of shared memory.
For example, using a single snapshot shared variable, it is possible to simplify considerably the Bakery mutual exclusion algorithm of Section 10.7
This transformation requires some simple restrictions on A, as discussed in Section 13.1.4
Also, technically, the snapshot atomic objects used in the transformation have one port corresponding to each process of A; process i of A might submit both update and snap operations on the same port i.
But there is no problem in modifying the snapshot atomic object external interface and implementations to permit this.
A useful variation on a snapshot shared variable, which only supports update and snap operations, is a r ead /upda te / snap shared variable, which supports read operations on individual locations in the shared vector in addition to snap operations returning the entire vector.
Of course, a model using read /upda te / snap  shared variables has no more power than a model using only snapshot variables, because a read can be implemented using.
However, the use of r ead /upda t e / snap  shared variables can allow more efficient programming,  because it is possible to implement a r e ad /upda t e / snap atomic object so that the reads are very fast.
Read/wr i te  shared variables (registers) are among the most basic building blocks used in shared memory multiprocessors.
Fix a domain V and initial value v0 E V.
Since we consider the implementation of read/wr i te  atomic objects in terms of read/wr i te  shared variables, we need a way of distinguishing the high-level read and write operations that are submitted by the users at the ports from the low-level read and write operations that are performed on the read/wr i te shared variables.
We use the convention of capitalizing the names of the highlevel operations.
We don' t  a t tempt  to capitalize the values in V.
We consider implementing such an m-writer~p-reader atomic object, where n - m +p,  using a shared memory system with n processes, one per port.
We assume that all the shared variables in this system are read/wr i te  shared variables, but the numbers of readers and writers will vary in the different algorithms we present.
We begin with a technical lemma that is useful for showing that a sequence of actions of a read/wri te  atomic object external interface satisfies the atomicity property for read/wri te  objects.
If an ordering satisfying these four conditions exists, it is guaranteed that  there is some way to insert serialization points so as to satisfy the atomicity property.
When reasoning about algorithms, it is often easier to show the existence of such a partial order than it is to explicitly define the serialization points.
Suppose that/3 is well-formed for each i, and contains no incomplete operations.
Suppose that -< is an irreflexive partial ordering of all the operations in II, satisfying the following properties:
The value returned by each READ operation is the value written by the last preceding W R I T E  operation according to -4 (or vo, if there is no such WRITE)
Condition 1 is a technical one, ruling out funny orderings in which infinitely many operations precede some particular other operation.
By construction, ,r  is placed after the latest of the invocations for r and for all the operations that  precede r in the -4 order.
Next, we claim that  these serialization points are within the required intervals.
Suppose for the sake of contradiction that it appears after the response for 7r.
It remains to show that  the result of shrinking the operation intervals to their serialization points is a trace of the underlying read/wri te  variable type.
In the rest of this section, we use Lemma 13.16 to show that  objects guarantee the atomicity condition.
This algorithm is simple but has the disadvantage that  the shared variables are unbounded in size.
Each variable x(i , j)  is readable only by process i and writable only by process j; thus, each process i can read all the variables in row i and can write all the variables in column i of X.
We use the abbreviation tagpair for the pair (tag, index)
When a WRITE(v ) i  input occurs, process i behaves as follows.
When a READi  input occurs, process i behaves as follows.
Let ( v , k , j )  be any (val, tag, index) triple it finds with maximum tagpair = (tag, index)
That is, it propagates the best information it has read to all the variables it can write.
Finally, process i outputs vi (i.e., outputs value v on port  i)
In order to prove the correctness of the VitanyiAwerbuch algorithm, we could proceed as in the proofs for the snapshot algorithms, explicitly inserting serialization points and then showing that the atomicity property is satisfied.
However, for the VitanyiAwerbuch algorithm, it is not easy to see (as it is for the earlier algorithms) exactly where the serialization points ought to be placed.
A more natural  proof strategy here is to establish a partial order of operations based on the tagpair values, and then show that this partial order satisfies the conditions of Lemma 13.16
Note that variable x ( i , j )  is writ ten only by process j and that, by well-formedness, all operations by j must occur sequentially.
Also, after any number of complete operations by j ,  all the variables in the j t h  column contain the same tagpair.
Each time j performs an operation, it starts by reading all variables in the j t h  row, including the "diagonal" variable x(j,  j)
The tagpair that it writes is then chosen to be at least as large as the tagpair that it finds in x ( j , j )
But this is the same as the tagpair in x ( i , j )  prior to the operation.
So the tagpair in x(i, j)  after the operation is at least as large as before the operation.
Next, define II to be the set of operations occurring in c~
For every ( W R I T E or READ) operation 7r C II, we define tagpair(Tr) to be the unique tagpair value that it writes.
For W R I T E  operations on different ports this is certainly true, since the index fields of the tagpairs are different.
So consider operations on the same port; by well-formedness, these operations occur sequentially.
In particular, r sees, in the "diagonal" variable x(i, i), a tagpair written by ~ or a later operation.
Then r chooses a larger, and hence a different, tagpair for itself.
Now we define a partial ordering on operations in H.
Claim 13.19 implies that it cannot have infinitely many predecessors that are W R I T E  operations, so it must have infinitely many predecessors that are R E A D  operations.
Without  loss of generality, we may assume that ~ is a WRITE.
Then there must be infinitely many R E A D  operations with the same tagpair, t, where t is smaller than tagpair(Tc)
This contradicts the existence of infinitely many R E A D  operations with tagpair t.
Thus by Claim 13.18, when r reads its row variables, it reads a tagpair that is at least as large as tagpair(zr)
This implies that all of the WRITEs are totally ordered and also that each READ is ordered with respect to all the WRITEs.
The VitanyiAwerbuch algorithm uses n 2 shared variables, each of unbounded size, even if the underlying domain V is finite.
Each READ and each WRITE that completes involves 4n shared memory accesses, for a total time complexity that is O (ng)
Like the UnboundedSnapshot algorithm, the VitanyiAwerbuch algorithm has the disadvantage that it uses unbounded-size shared variables to store unbounded tags.
In this section, we present only one very simple algorithm, for a special case.
Each x ( i ) i s  writable by WRITE process i and readable by all the other processes.
Figure 13.10 depicts the architecture for the special case of two readers.
The algori thm is simple but  does not have an apparent  generalization to more writers.
First,  it reads both registers; let b be the sum modulo 2 of the two tags that it finds there.
Thus, all READ processes behave in exactly the same way.
Each READ process reads both registers to determine whether they contain equal or.
Once again, in order to prove correctness, we could proceed by explicitly.
Then we show that Bloom is correct by using a simulation relation from Bloom to IntegerBloom.
I n t e g e r B l o o m  algorithm:
First ,  it reads both registers; let t l and t2 be the respective tags it finds there.
The following lemma gives some basic propert ies of IntegerBloom.
As before, we assume without loss of generality that  a contains no incomplete operations.
Let II denote the set of operations occurring in a.
Now we define a part ial  ordering on operations in II.
First ,  we order the WRI TE  operations by their tag values.
If two WRITE  operations have the same tag, then they must  belong to the same writer,  and we order them in the order in which they occur.
Next,  we order each READ operat ion in II just  after the WRI TE  whose value it obtains (or before all the WRITEs,  if there is no such WRITE)
By Claim 13.23, the tag read by r is greater than  or equal to tag(Tr)
Then r must see x(i).tag - t -  1 on either its first or its second read, and again on its third read.
So it must be that  r sees x(i).tag > t.
If r is a WRITE, then clearly ~ cannot re turn the result of r since r does not perform its write step until after r has completed.
Now we show the correspondence between the Bloom and IntegerBloom algorithms, using a simulation relation.
Example 13.4.1 Bits versus integers in the B l o o m  algorithm.
The tag values in the two registers, written in binary notation, are shown in Figure 13.11
In the corresponding execution of Bloom, the tag values in the two registers are as shown in Figure 13.12
It turns out that the correspondence illustrated in Example 13.4.1 holds in all executions of the two algorithms.
Figure 13.11: Successive tag values in the two registers, in the IntegerBloom algorithm.
Since the unique initial states of the two algori thms are related by f ,  the s tar t  condition of the simulation definition is s t raightforward.
It is enough to show that  for any step (s, rr, s') of Bloom and any u E f(s) ,  where s and u are reachable states, there is a corresponding step (u, r u/) of IntegerBloorn, where u' C f(s ')  and r is "almost" the same as 7r.
If rr is an invocation or response event, then the arguments are s t raightforward.
The interesting steps are the write steps within the WRITE operations and the third read steps within the READ operations.
In the corresponding state u of IntegerBloom, process i remembers  reading an integer-valued tag t from x(2).tag; since u E f(s) ,  it must  be that  b is the secondlowest-order bit of t.
Let u t be the unique state that  results in IntegerBloom.
In this case, both Bloom and IntegerBloom read from register x(1)
In this case, both Bloom and IntegerBloorn read from register.
In this case, IntegerBloom permits either register to be read.
Now we can prove Theorem 13.20, which asserts the correctness of the Bloom algorithm.
Recall that traces here include invocation and response events on ports, plus the stop events.
Theorem 13.22 implies that the well-formedness and atomicity conditions hold for IntegerBloom.
Since the well-formedness and atomicity conditions are expressible as properties of traces, they carry over to the Bloom algorithm.
The Bloom algorithm uses two shared variables, each of which can take on 2IV I values.
Each operation requires only a constant number of shared memory accesses, or time O (g)
In this final subsection, we give an implementation, SnapshotRegister, of a waitfree m-writer~p-reader read/wr i te  atomic object using a snapshot shared variable.
The snapshot shared variable used by SnapshotRegister has unbounded size, even if the underlying domain V for the read/wri te  atomic object being implemented is bounded.
It is possible, though quite difficult, to modify the SnapshotRegister algorithm to use a bounded snapshot shared variable.
SnapshotRegister algorithm: The algorithm uses a single shared variable x, which is a snapshot object based on a length m vector.
First, it performs a snap operation on x, thereby determining a vector u.
First, it performs a snap operation on x, thereby determining a vector u.
Then process i performs an update(i, (v, u(j).tag + 1))
The SnapshotRegister algorithm is somewhat similar to the VitanyiAwerbuch algorithm, but it is simpler because of the extra power provided by the snapshot shared memory.
This is similar to the proofs for VitanyiAwerbuch and IntegerBloom, using Lemma 13.16, but simpler.
The SnapshotRegister algorithm uses one snapshot shared variable, which is of unbounded size, even if the underlying domain V is finite.
Technically, in order to apply Corollary 13.9, we need a snapshot atomic object with only n - m + p ports, one per process--for example, WRITE process i should perform both its update and snap operations on the same port.
There is no problem modifying the snapshot atomic object external interface and implementations to permit this.
There are several interesting generalizations of the SnapshotRegister algorithm that also work correctly.
First, during a WRITEi, if i = j - that is, if process i itself has the largest tag pair-- then i may optionally use the same tag that it previously had.
Second, it is possible to use nonnegative realvalued tags rather than integer-valued tags.
Then the tag chosen by a writer i can be any real number that is strictly greater than the largest tag it sees.
Once again, if i itself has the greatest tag pair, then it can reuse its previous tag.
Both of these generalizations are useful for proving the correctness of other implementations of read/write atomic objects using a snapshot shared variable.
Herlihy and Wing [153] extended the notion of atomicity to arbitrary variable types and renamed it linearizability.
The canonical wait-free atomic object automaton is derived from the work of Merritt, described in [3]
The impossibility of implementing read-modify-write atomic objects using read/write objects is due to Herlihy [150]
The snapshot atomic object implementations presented here, both UnboundedSnapshot and BoundedSnapshot, are due to Afek, et al.
The handshake strategy used in the BoundedSnapshot protocol is due to Peterson [240]
Many algorithms have been designed for implementing read/write atomic objects in terms of simpler kinds of read/write registers.
The VitanyiAwerbuch algorithm appears in a paper by Vitanyi and Awerbuch [283]; that paper also contains an algorithm using bounded shared variables, but that algorithm is incorrect.
In particular, Schaffer's algorithm corrects errors in Peterson and Burns's algorithm.
Attiya and Welch have compared the costs of implementing read/write atomic objects with those of implementing read/write objects with slightly weaker consistency requirements [28]
Their work is carried out in the asynchronous network model.
Define the external interface for a 2-writer/i-reader atomic object and give several interesting examples of sequences for this external interface that satisfy the atomicity property, as well as sequences that do not satisfy the atomicity property.
Be sure to include both finite and infinite sequences, as well as sequences that contain incomplete operations.
See Section 9.4 for the definition of a read-modify-write variable type--recall that the return value for a read-modify-write shared variable is the value of the variable prior to the operation.
Fill in some more details in the proof of Theorem 13.1
In particular,  show in more detail than we have in the text that there are arbitrari ly long paths from the root and that an infinite path yields a correct selection for the entire sequence/3
Generalize the definition of a variable type to allow finitely many initial values rather than just  one and to allow finite nondeterministic choice rather than just  a function.
Generalize Theorem 13.1 and its proof to this new setting.
Suppose that we modify Example 13.1.4 so that the system supports decrement operations as well as read and increment operations.
The algori thm is the same as before, with the following addition: when a decrementi input occurs on port  i, process i decrements x(i)
Is the resulting system a read / increment /decrement  atomic object? Either prove that it is or give a counterexample execution.
Show that Theorem 13.7 is false if we do not include the special assumption about A's turn function.
Your description should be modular  in that it should represent the mutual  exclusion component as a separate automaton,  combined with the main portion of the RMWfromRW algorithm using I /O.
Prove that your algorithm works correctly (assuming the correctness properties of the mutual exclusion component)
Consider a modification of the UnboundedSnapshot algorithm in which each snap and embedded-snap looks for three different tags for some x(i) rather than four as described.
Is the modified algorithm still correct? Either prove that it is or give a counterexample execution.
Consider a modification of the UnboundedSnapshot algorithm in which process i increments x(i).tag when it performs a snap operation, as well as when it performs an update operation.
The x(i).val and x(i).view components are not changed, and the embedded-snap operation is not modified in any way.
Research Question: Can you give an alternative proof of correctness for the UnboundedSnapshot algorithm, based on a formal relationship with the appropriate canonical wait-free atomic object automaton?
Design a modification of the BoundedSnapshot algorithm that eliminates the toggle bits.
In your algorithm, a snap process should determine the consistency of two sets of reads, based not only on the handshake bits but also on the val fields.
Can you design one that terminates in linear rather than quadratic time in the number of processes?
Research Question: Design a good implementation of a snapshot atomic object that allows updates to the same vector component to occur on several ports (and hence, concurrently)
Give a simplified version of the Bakery algorithm of Section 10.7 that uses snapshot shared variables.
State carefully and prove a result asserting the impossibility of solving the agreement problem with l-failure termination using snapshot atomic objects.
Give a simplified version of the Bakery algorithm of Section 10.7 that uses read/update/snap shared variables.
Try to make your algorithm as simple and efficient as you can.
Generalize Lemma 13.16 to handle arbitrary variable types rather than just read/write types.
Is the "propagation phase" of the READ protocol in the VitanyiAwerbuch algorithm needed? Either prove that the algorithm works without it or exhibit a counterexample.
Give an alternative correctness proof for the VitanyiAwerbuch algorithm, based on explicitly inserting serialization points into an arbitrary execution in which all operations complete, and then showing that the atomicity property is satisfied.
Is the propagation phase of the READ protocol needed? Prove correctness and analyze complexity.
Prove that the third read within the READ protocol in the Bloom algorithm is necessary.
That is, give an incorrect execution of the modified algorithm in which each READ simply returns the value already read (in the first or second read) from the appropriate register.
Fill in the details in the proof of Lemma 13.26
Research Question: Try to extend the Bloom algorithm to more than two writers.
Give example executions to show that the SnapshotRegister algorithm is not correctly serialized by serialization points placed in either of the following two ways:
Describe a single algorithm that generalizes the SnapshotRegister algorithm in both of the two ways described at the end of Section 13.4.5
That is, a WRITE process whose own tag is the largest is allowed (though not forced) to reuse its tag, and real-value tags are permitted.
Design an algorithm to implement an m-writer/p-reader read/write atomic object with domain V and initial value v0, using a snapshot shared variable.
Unlike the SnapshotRegister algorithm, your snapshot variable should be of bounded size, in the case where V is finite.
Research Question: Use Lemma 13.16 to prove the correctness of some of the other atomic register implementations in the research literature.
Research Question: Design a hierarchy of atomic objects that are efficient and simple enough to be used as the basis for the development of a practical multiprocessor system.
Chapters 14-22 deal with algorithms for the asynchronous network model, in which processes take steps asynchronously and communicate by exchanging messages.
The ideas in these chapters build in many interesting ways on ideas presented in Parts I and IIA.
We follow this with Chapter 15, which contains a survey of basic algorithms for asynchronous networks, all programmed directly in terms of the model.
Since some of these algorithms turn out to be quite complicated, we proceed, in Chapters 16-19, to introduce four techniques for simplifying the programming of asynchronous networks.
The first technique, described in Chapter 16, is the introduction of a synchronizer.
The second technique, described in Chapter 17, is the simulation of the asynchronous shared memory model by the asynchronous network model.
The third technique, described in Chapter 18, is the assignment of consistent logical times to events in an asynchronous distributed network.
Chapter 19 contains our fourth technique, the monitoring of asynchronous network algorithms while they run.
We then return to the study of specific problems in the asynchronous network setting.
Chapter 20 studies the problem of resource allocation in asynchronous networks.
Chapter 21 considers the problem of computing in an asynchronous network in the presence of failures.
Finally, Chapter 22 considers the data link problem, a problem of implementing reliable communication in an unreliable network.
In this chapter, we change the computing paradigm once again, this time switching from asynchronous shared memory systems to asynchronous networks.
An asynchronous network consists of a collection of processes communicating by means of a communication subsystem.
In the version of this model that is most frequently encountered, this communication is point-to-point, using send and receive actions.
Other versions of the model allow broadcast actions, by which a process can send a message to all processes in the network (including itself), or multicast actions, by which a process can send a message to a subset of the processes.
Special cases of the multicast model are also possible, for example, one that allows a combination of broadcast and point-to-point communication.
In each case, various types of faulty behavior of the network, including message loss and duplication, can be considered.
The chapter contains three main sections, treating send/receive systems, broadcast systems, and multicast systems, respectively.
As in the synchronous network model defined in Chapter 2, we start with an n-node directed graph G = (V, E)
As before, we use the notation out-nbrsi and in-nbrsi to denote the outgoing and incoming neighbors of node i in the digraph, distance(i, j)  for the length of the shortest directed path from i to j in G, and diam for the maximum distance from any node to any other.
As in the synchronous network model, we associate processes with the nodes of G and allow them to communicate over channels associated with directed.
However, unlike in the synchronous model, there are no synchronous rounds of communication: now we allow asynchrony in both the process steps and the communication.
To describe this asynchrony, we model the processes and the channels as I /O automata.
The process associated with each node i is modelled as an I /O automaton, Pi.
Pi usually has some input and output actions by which it communicates with an external user; this allows us to express problems to be solved by asynchronous networks in terms of traces at the "user interface." In addition, Pi has outputs of the form send(m)i,j, where j is an outgoing neighbor of i and m is a message (that is, an element of M), and inputs of the form receive(m)j,i, where j is an incoming neighbor of i.
Except for these external interface restrictions, Pi can be an arbitrary I /O automaton.
For specific results, we might sometimes want to impose additional restrictions on Pi, such as limiting the number of tasks or the number of states.
See Example 8.1.2 for an example of a process I /O automaton.
We consider two kinds of faulty behavior on the part of node processes: stopping failure and Byzantine failure.
The stopping failure of Pi is modelled by including in the external interface of Pi a stopi input action, the effect of which is to permanently disable all tasks of Pi.
We do not constrain the state changes caused by a stopi, nor the state changes caused by subsequent input actions.
It is not important to constrain these state changes, because their effects could never be seen outside Pi, anyway.
The Byzantine failure of Pi is modelled by allowing Pi to be replaced by an arbitrary I /O automaton having the same external interface.
The channel associated with each directed edge (i, j) of G is modelled as an I /O automaton Ci,j.
Its external interface consists of inputs of the form send(m)i,j and outputs of the form receive(m)i,j, where m E M.
In general, except for this external interface specification, the channel could be an arbitrary I /O automaton.
However, interesting communication channels have restrictions on their external behavior, for example, that any message that is received must in fact have been sent at some earlier time.
The needed restrictions on the external behavior of a channel can generally be expressed in terms of a trace property P, as defined in Section 8.5.2
The allowable channels are those I /O automata whose external signature is sig(P) and whose fair traces are in traces(P)
There are two ways in which such a trace property P is commonly specified: by listing a collection of axioms or by giving a particular I /O  automaton whose external interface is sig(P) and whose fair traces are exactly traces(P)
An advantage of listing axioms is that this makes it easier to define a variety of channels, each of which satisfies a different subset of the axioms.
On the other hand, an advantage of giving an explicit I /O  automaton is that in this case, the entire system consisting of the processes and the most general allowable channels is described as a composition of I /O  automata,  which is itself another.
This allows us to use the proof methods that have been developed for automata.
For example, this provides us with a notion of "state" for the entire system, both processes and channels, which we can use in invariant assertion and simulation proofs.
Sometimes it may be necessary to do some rather annoying programming to specify the desired trace property as an I /O  automaton; this is especially so when the trace property involves complicated liveness constraints.
This often leads to a mixed strategy wherein the safety properties are described in terms of a basic automaton (which provides the machinery needed to support  invariant and simulation proofs), while the liveness properties are described using special liveness axioms.
The complete trace property P then has its traces defined to.
In the rest of this subsection, we describe some particular send/receive channels that we will use in Chapters 15-22
The communication channel that is most frequently assumed in the research literature and that we will use most frequently here is a reliable FIFO channel.
The behaviors allowed for such a channel are easily specified as the fair traces of an I /O  automaton with the appropriate external.
The send(m)i,j action adds m to the end of the queue.
The receive(m)i,j action is enabled if m is first on the queue, and its effect is to remove the first message from the queue.
The task parti t ion puts all the locally controlled actions in a single class.
A formal definition of this automaton has already been given, in Example 8.1.1
This automaton is not only a specification of the allowable behavior for reliable FIFO channels, it is itself an example of a reliable FIFO channel.
We call it the universal reliable FIFO channel with the given external interface.
Now we give an alternative specification, using axioms, of the allowed behavior for a reliable FIFO channel.
Namely, we define a trace property P with sig(P) equal to the given signature and traces(P) equal to the set of sequences /3 of actions in sig(P) that satisfy the following condition.
The cause function is a device for identifying which send event "causes" each receive event.
Notice that (for this part icular trace property P)  the cause function for each sequence in t races (P)  is unique.
Another type of channel that is often considered guarantees delivery of all messages, each exactly once, but does not necessarily preserve their order.
The behaviors allowed for this type of channel are not so easily specified using an I /O  automaton,  so we instead use axioms.
Namely, the specification is exactly the same as the axiomatic specification P for the reliable FIFO channel, given above, except that Condition 4 for the cause function is dropped.
An alternative, equivalent specification can be given using the mixed strategy mentioned above--us ing a basic I /O automaton A to describe the safety properties and additional axioms to describe liveness.
A a u t o m a t o n :
States : in-transit, a multiset of elements of M, initially empty.
The task part i t ion does not matter ,  because we are not using it here.
Using au tomaton  A, we define a t race proper ty  P.
The signature is the same as sig(A), and traces(P) is the set of t races of (not necessarily fair) executions c~ of A that satisfy the following condition.
We can also consider send/receive channels in which some failures occur.
In this book, the only kinds of channel failures we discuss are message loss and duplication.
A channel permit t ing a rb i t ra ry  loss but  no duplication, or a rb i t ra ry  duplication but  no loss, or a rb i t ra ry  duplication and loss, can be specified in the same way as reliable reordering channels, using the cause function.
However, often we want to assume a limited amount of message loss and /o r duplication.
For example, when we consider message loss, we generally do not want  to consider the case where all messages are lost, because in this case nothing can be guaranteed  ever to happen.
A typical condition restr ict ing message loss is one that  says that  a message that  is sent infinitely many times must  be received infinitely many times.
To say this formally, we use the following condition on the cause function.
Notice that  this says that  infinitely many different send events succeed in having their messages delivered.
Another typical condition restricting message loss is one that does not mention any particular m, but just  says that infinitely many sends  cause receives of infinitely many messages.
For duplication, we might want to limit the number of copies of each message to be finite or to be bounded by some particular number k.
So far, we have described all the channels with failures using axioms.
We now use the mixed strategy to specify two such channels.
We define a channel that allows limited loss, finite duplication, and no.
This channel will be used in Section 22.3, in the description of the Alternating Bit communication protocol.
A a u t o m a t o n :
States: queue, a FIFO queue of elements of M, initially empty.
The definition of automaton A guarantees that the channel does not reorder messages and only delivers finitely many copies of any message.
If, at any point, queue is nonempty, then at some later point, a receive event occurs.
If there are infinitely many send events, then infinitely many of them succeed in putting (at least one copy of) their messages on the queue.
The combination of A and the liveness conditions are used to define a trace property as before.
This trace property implies that if there are infinitely many send events, then infinitely many of those have corresponding receive events, that is, it implies the weak loss limitation (WLL) condition.
We define a channel that allows limited loss, finite duplication, and reordering.
This channel will be used in Section 22.2, in the description of Stenning's communication protocol.
A a u t o m a t o n :
States : in-transit, a mult iset  of elements of M,  initially empty.
If, at any point, in-transit is nonempty, then at some later point, a receive event occurs.
If there are infinitely many send events, then infinitely many of them succeed in putting (at least one copy of) their messages in in-transit.
As in Example 14.1.1, the resulting trace property implies that if there are infinitely many send events, then infinitely many of them have corresponding receive events, that is, it implies the WLL condition.
Note that every trace allowed by the specification in Example 14.1.1 is also allowed by this specification.
However, there are some traces allowed by this specification that are not allowed by the previous one.
An asynchronous send/receive network system for directed graph G is obtained by composing the process and channel I /O automata, using ordinary I /O automaton composition.
An example of the architecture for such a system appears in Figure 8.3
The composition definition allows for the right interactions among the components; for example, when process Pi performs a send(m)i,j output action, a simultaneous send(m)i,j input action is performed by channel Ci,j.
Sometimes it is convenient to model the users of a send/receive system as another I /O automaton, U.
U's external actions are just the actions of the processes at their user interface.
The user automaton U is often described as the composition of a collection of user automata Ui, one for each node i of the underlying graph.
In this case, Ui's external actions are the same as the actions of Pi at the user interface.
If stopping failures are considered, the stop actions are not included among the actions of the users.
It identifies circumstances under which the events of a fair trace can be reordered to yield another fair trace.
Note that, according to the formal definition of I /O automaton composition, the traces include the send and receive events, as well as the events at the user interface.
What is required is that the reordering should respect certain basic dependencies: the dependency of a receive event on the corresponding send event (with respect to the uniquely determined cause function) and the (possible) dependency of any event on all preceding events at the same node process.
Fix any asynchronous send/receive system A with universal reliable FIFO channels.
Theorem 8.4 implies that fllPi E fairtraces(Pi) for every i.
Theorem 14.1 has a corollary that says that certain reorderings of fair executions are also fair executions.
This uses the formal definition of indistinguishable from Section 8.7
We measure communication complexity in terms of the number of messages that are sent and /or  the number that are received.
We can also take into account the number of bits in the messages.
For measuring time complexity, we use a special case of the general time.
We also need assumptions about the time for delivery of messages.
For the special case of universal reliable FIFO channels, we usually associate an upper bound of d with the single task consisting of the receive actions of each channel; this imposes an upper bound of d on the delivery time for the oldest message in the channel.
Thus, our usual time complexity measure takes into account the costs of pileups of messages in channels-- the kth message on a channel's queue is guaranteed to be delivered within time kd.
We sometimes also make a less realistic but simpler assumption about message delivery time: an upper bound of d on the delivery time for each message in a channel, regardless of pileups.
This assumption is not expressible just by associating time bounds with tasks (but it makes sense nonetheless)
Also, we can extend the channel time bound assumptions to non-universal FIFO channels, in the obvious way.
Process i in a broadcast  system is modelled as an I /O  automaton Pi.
As for processes in send/receive network systems, Pi usually has some input and output actions by which it communicates with an external user.
In addition, Pi has outputs of the form bcast(m)~, where m E M, and inputs (as before) of the form receive(m)j,i, where rn C M.
Except for these external interface restrictions, Pi can be an arbi t rary I /O  automaton.
A broadcast channel is modelled as a single I /O automaton.
In this book, we consider only reliable broadcast channels, but it is possible also to define other types of broadcast channels that exhibit various forms of failure.
A reliable broadcast channel delivers every message that is broadcast, to every process, including the sender.
We make one assumption about the ordering of the message deliveries: that the delivery order is FIFO between each particular pair of processes.
The allowed behaviors for such a channel are easily specified as the fair traces of a single I /O automaton B that maintains a separate queue for each ordered pair of processes.
We call B the universal reliable broadcast channel with the given external interface.
An asynchronous  broadcas t  system is obta ined by composing the process and.
The definitions and results in Section 14.1.4 can be modified for broadcas t  systems with universal reliable broadcas t  channels.
Fix  any asynchronous  broadcas t  sys tem A with a universal reliable broadcas t.
We define an irreflexive par t ia l  order on the.
We can measure communication complexity either in terms of the number of bcast events or the number of receive events.
For measuring time complexity, we use a special case of the time complexity measure for I /O  automata.
Namely, we associate an upper bound of t~ with each.
And for the special case of a universal reliable broadcast.
Thus, we again take into account the costs of pileups of messages.
Again, we occasionally make the stronger assumption of an upper bound.
Send/receive and broadcast  systems are both generalized by multicast systems, which allow each process to send a message to a subset of the processes in the network.
The system is parameterized by a se t /7  of pairs of the form (i, I) ,  where i is a.
Each such pair (i, I) indicates that process i can use set I as a destination set for multicasts.
In addition to some actions at the user interface, Pi has outputs of the form mcast(m)i, i ,  where rn is a message and.
Except for these external interface restrictions, Pi can be an arbitrary I /O automaton.
A multicast channel is modelled as a single I /O automaton.
The allowed behaviors for a reliable multicast channel with set I of pairs are easily specified as the set of fair traces of the following I /O automaton B.
We call B the universal reliable multicast channel with the given external interface.
An asynchronous multicast system is obtained by composing the process and multicast channel I /O automata.
It is straightforward to extend the definitions and results in Section 14.1.4 to multicast systems based on universal reliable multicast channels.
Likewise, the complexity measures for broadcast systems can be extended to multicast systems.
In general, we use no special source for the modelling of asynchronous send/receive, broadcast, and multicast networks; similar material appears in many papers on distributed algorithms and on formal verification of network protocols.
Our modelling of broadcast and multicast channels only includes basic cotrectness and complexity properties.
There has been much work on the implementation and use of broadcast and multicast channels with stronger properties, including stronger ordering requirements and fault-tolerance properties.
Let P be the trace property defined in Section 14.1.2 to describe the allowable behaviors for a reliable FIFO send/receive channel.
Prove that traces(P) is exactly equal to the set of fair traces of the universal reliable FIFO channel automaton with the same external interface.
Let A be any I /O automaton that implements a universal reliable FIFO send/receive channel B - - t h a t  is, A has the same external signature as B and fairtraces(A) C_ fairtraces(B)
In this sense, any reliable FIFO channel must be universal.
Consider an alternative trace property Q as a specification for the allowable behavior of a reliable FIFO send/receive channel.
Give a careful description of a send/receive channel C that can lose messages, but not duplicate or reorder them, as an explicit I /O automaton.
Suppose that C is even permitted to lose all of its messages.
However, C should exhibit all the possible traces that satisfy this condition~for example, it should not be required to lose messages.
Repeat Exercise 14.6, but in place of reliable FIFO send/receive channels, consider channels that allow arbitrary reordering, strong loss limitation (SLL), and.
Prove that the FIFO assumption for reliable send/receive channels is not necessary.
Specifically, show how to t ransform any send/receive system A based on reliable FIFO channels into a send/receive system T(A) based on reliable reordering channels that looks the same to the environment, in the following sense.
Prove that the FIFO assumption for reliable broadcast  channels is not necessary.
That  is, show that a system A with this assumption can be.
Strengthen Theorem 14.1 so that it includes a claim about what is preserved at the user interface.
In this chapter, we describe a collection of algorithms for solving some basic problems--leader election, constructing an arbitrary spanning tree, broadcast and convergecast, breadth-first search, finding shortest paths, and constructing a minimum spanning t ree-- in  the asynchronous network model with reliable FIFO send/receive channels.
As before, these problems are motivated by the need to select a process to take charge of a network computation and by the need to build structures suitable for supporting efficient communication.
All the algorithms in this chapter are constructed by direct programming of the "bare" asynchronous network model.
It will not take long for us to see that this model is much more difficult to program than the synchronous network model.
This will lead us to seek ways of simplifying and systematizing the programming task.
In the four chapters following this one, Chapters 16-19, we introduce four such simplification techniques: synchronizers, simulating shared memory, logical time, and runtime monitoring.
For the asynchronous version of the problem, the underlying digraph is again a ring of n processes, numbered 1 to n in the clockwise direction.
As before, we often count mod n, allowing 0 to be another name for process n, and so on.
Now processes and channels are modelled as I /O  au tomata.
As in the synchronous setting, processes do not know their indices, nor those of their neighbors, but  use local, relative names.
This allows arbi t rary  processes to be arranged into a ring in an arbi t rary  order.
Besides the send and receive actions by which process au tomaton  Pi interacts with its channels, Pi has a leaderi output  action by which it can announce its election as leader.
We assume, here and throughout  the rest of the chapter,  tha t  the channels are reliable FIFO send/receive channels.
We also assume here tha t  the processes have UIDs.
The problem is for exactly one process eventually to produce a leader output.
The LCR algori thm described in Section 3.3 can easily be adapted  to run in an asynchronous network.
Recall tha t  in the LCR algorithm, each process sends its identifier around the ring.
When a process receives an incoming identifier, it compares tha t  identifier to its own.
If the incoming identifier is greater than its own, it keeps passing the identifier; if it is less than  its own, it discards the incoming identifier; if it is equal to its own, the process outputs  leader.
We call the mod i f i ed  a l g o r i t h m.
In the following code, we use A synchLCRi  as an  a l t e rna t ive  n a m e  for p rocess.
Pi in the A s y n c h L C R  a lgo r i thm.
A s y n c h L  C R i  a u t o m a t o n :
Precondition: Precondition: v is first on send status = chosen.
Effect: Effect: remove first element of send status := reported.
Process i is responsible for performing two tasks: sending messages to process i + 1 and announcing itself as.
Thus, it has two tasks, one for all its send actions and one for its leader action.
The behavior of the A synchLCR is essentially the same as that of LCR, but possibly "skewed" in time.
In order to prove that AsynchLCR solves the leader-election problem, we use invariant assertions as we did for the synchronous LCR algorithm.
Invariant assertion proofs work for asynchronous networks just as well as for synchronous.
Technically, in order to use invariant assertion proofs, we must know the.
Then we know that the state of each Ci,i+l consists of a single queue component, which we refer to as queuei,i+l.
This assumption does not restrict the generality of the results, because an algorithm that works correctly.
We will make the same assumption in all of our correctness proofs for send/receive systems with reliable FIFO channels.
Let /max denote the index of the process with the maximum UID, and let Umax denote its UID.
Here, as in the synchronous case, we must show two things:
No process other than imax ever performs a leader output.
The first of these two conditions is a safety property while the second is a liveness property.
We use an invariant similar to Assertion 3.3.3 for the synchronous case.
Recall that Assertion 3.3.3 said that no UID v could reach any send queue between/max and v's original home i.
Now, because the AsynchLCR algorithm includes channel automata, we need a slightly stronger assertion that involves the UIDs in the channel states as well as the UIDs in the process states.
A s s e r t i o n  15.1.1 The following are true in any reachable state:
I f  i 7~ imax and j E [imaz, i), then ui does not appear in sendj.
If i ~ imax and j c [imax, i), then ui does not appear in queuej,j+l.
Assertion 15.1.1 is proved by induction on the number of steps in a finite.
The proof is generally similar to that of Assertion 3.3.3
This time, we proceed by case analysis based on the individual.
The key case is that of a receive(v)j_l,j event where j =/max; for this case, we must argue that if v = ui where i J=/max, then v gets discarded.
Then it is easy to see that no process other than im~x ever performs a leaderi output, since the precondition of this action is never satisfied.
Notice that this needs the hypothesis that the execution of A synchLCR is fair.
This formal notion means that the processes and channels continue to perform their work.
The proof of this property for A synchLCR is quite different from the proof of the corresponding result, Lemma 3.2, for the synchronous LCR algorithm.
Recall that in the synchronous case, we used a very strong invariant.
Also, it is impossible to characterize precisely what happens in the computation, since the asynchrony introduces so much uncertainty.
Our proof is based on establishing intermediate milestones toward the main goal of electing a leader.
The fairness properties of the process and channel I /O automata are used to prove all these eventuality claims.
For example, consider a state s in a fair execution c~ in which any UID v appears at the head of the sendi buffer.
If not, then examination of the transitions of process AsynchLCRi shows that v remains at the head of the sendi buffer forever.
But since v is the message at the head of the send4 buffer, this means that send(v)i must eventually occur.
This follows by induction on k, with the basis case, k - 1, given just above.
Similar arguments can be made for the UIDs in the channels.
The number of messages is O (n2), just as for the synchronous LCR algorithm.
Recall that the time bound for L CR is n rounds.
For the time analysis of A synchLCR, we assume an upper bound of t~ for each task of each process, and an upper bound of d on the time to deliver the oldest message in each channel queue.
Namely, note that the maximum length of any process send buffer or any channel queue is n.
Therefore, it takes at most ng time for a UID in a process send buffer to get placed in the adjacent channel, and at most nd time for a UID in a channel queue to get received by the next process.
The overall time complexity is therefore O (n 2 (g + d))
However, it is possible to carry out a more refined analysis, yielding an upper bound that is only O (n(t~ + d))
The point is that although some send buffers and queues can reach size n, this cannot happen everywhere.
In order for a pileup to form, some UIDs must travel faster than the worst-case upper bound in order to overtake others.
The overall time turns out to be no worse than if the UIDs had all travelled at the same speed.
By time r(g + d) + ~, UID ui either reaches queuei+r,i+r+l or is deleted.
Inductive step: Suppose that  the claim holds for r -  1 and prove it for r.
Suppose for the sake of contradiction that  ui is not delivered to process i + r by time t and also does not reach the head of queue4+~-l,i+~ by time t.
Then it must be that  some other UID, uj, is ahead of ui on queuei+~-l,i+~ at time t.
This is a pileup, where ui has overtaken uj; since ui has not yet travelled distance r around the ring, it follows that  uj has not yet travelled distance r -  1 around the ring.
This implies that  uj cannot still be in queuei+~-l,i+~ at time t, which is a contradiction.
Thus, either ui is delivered to process i + r by time t, or else ui reaches the head of queue~+~_l,i+~ by time t.
In this latter case, within an additional t ime d, ui is delivered to process i + r.
We can modify the i npu t /ou tpu t  conventions for the leader-election problem so that  the inputs (here, the UIDs) arrive at the processes in special wakeup(v)i messages from an external user U, instead of originating in the start states.
The correctness conditions would then be modified to assume that  exactly.
Then the AsynchLCR algorithm can easily be modified to satisfy the new correctness conditions: each process Pi simply delays performing any locally controlled actions until after it receives its wakeup.
If Pi receives any messages before receiving its wakeup, then it buffers those messages in a new receive buffer and processes them after receiving the wakeup.
A similar modification can be made to the other leader-election algorithms later in this section.
More generally, any distributed problem that is formulated with inputs in the start states can be reformulated to allow the inputs to arrive in wakeup messages.
Using the same strategy described above, we can modify any algorithm that solves the original problem so that it satisfies the new correctness conditions.
Recall the synchronous HS algorithm of Section 3.4, in which each process sends exploratory messages in both directions, for successively doubled distances.
It is straightforward to see that this algorithm, suitably rewritten in terms of process I /O automata, still works correctly in the asynchronous network model.
Its communication complexity is O (n log n), as before.
We leave the determination of an upper bound on the time complexity for an exercise.
The HS algorithm (in both its synchronous and asynchronous versions) requires only O (n logn)  messages and uses bidirectional communication.
In this subsection, we present the PetersonLeader algorithm, which achieves O (n logn) communication complexity using only unidirectional communication.
This algorithm does not rely on knowledge of n, the number of nodes in the ring.
It elects an arbitrary process as the leader, not necessarily the process with the maximum or minimum UID.
The O (n logn) communication complexity has only a small constant factor (approximately 2)
While the algorithm is executing, each process is designated as being either in active mode or relay mode; all processes are initially active.
The active processes carry out the "real work" of the algorithm; the relay processes just pass messages along.
An execution of the PetersonLeader algorithm is divided into (asynchronously determined) phases.
In each phase, the number of active processes is reduced by a factor of at least 2, so there are at most log n phases.
In the first phase of the algorithm, each process i sends its UID two steps clockwise.
Then process i compares its own UID to those of its two predecessors in the counterclockwise direction.
Each active process i now sends its temporary UID to the next and second-next active processes in the clockwise direction, and waits to learn the temporary UIDs from its two active predecessors in the counterclockwise direction.
Now if the first active predecessor's UID is the largest of the three UIDs, process i remains active, adopting that  predecessor's UID as its new temporary UID.
On the other hand, if one of the two other UIDs is the largest of the three, then process i becomes a relay.
Also, if at any phase, a process i sees that  the temporary UID it receives from its immediate active predecessor is the same as its own temporary UID, then i knows that  it is the only active process left.
It should be clear that  in any phase in which there is more than one active process, at least one process will discover a combination of UIDs that  allows it to remain active at the next phase.
Moreover, at most half of the active processes can survive a given phase, since every process that  remains active must have an immediate active predecessor that  becomes a relay.
Effect: uid(3) := first e lement  of receive remove first e lement  of receive.
As stated above, the number of active processes is at least halved in each phase, until only one active process remains.
During each phase, each process (either active or relay) sends at most two messages.
This is O (n log n), with a much better constant factor than in the HS algorithm.
For the time complexity, it is not hard to prove a naive upper bound of O (n log n(t~ + d))
This is because there are O (log n) phases, and we can show that, for any p, the first p phases are completed within time O (pn(g + d))
In each phase, each UID travels distance O (n) around the ring.
It takes time at most t~ + d for a message to travel from one node to the next, provided that it is not blocked by a pileup.
The same method we used in the proof of Lemma 15.4 can be used to argue that pileups cannot hurt the worst-case bound.
We only sketch the main ideas here, leaving the proof for a somewhat intricate exercise.
First, we can ignore pileups, since arguments such as those for Lemma 15.4 can be used to show that they do not affect the worst-case bound.
The time complexity is proportional to the length of a certain chain of messages, ending with the message at the final phase p that causes the leader, ip, to become chosen.
The UID in that message originates at ip itself at phase p and so travels a total distance of n at phase p.
This implies that the total length of the chain is 3n, which translates into a time bound of O (n(g + d))
We have just described two asynchronous network leader-election algorithms, PetersonLeader and the asynchronous version of HS, that have communication complexity O (n log n)
In this section, we argue that the problem also has a lower bound of f~(n log n)
Throughout this section we assume, without loss of generality, that the channels are universal reliable FIFO channels.
Theorem 3.9 gives a lower bound for algorithms that are comparison based; it allows bidirectional communication and allows processes to know the number of nodes in the network.
This result can be carried over directly to the asynchronous setting, since the synchronous model can be formulated as a restriction of the asynchronous model.
Then there is a fair execution of A in which ~(n  log n) messages are sent by the time the leader is elected.
Theorem 3.11 gives a lower bound for algorithms that can use UIDs in arbitrary ways but that have a fixed time bound and a large space of identifiers.
Again, it allows bidirectional communication and allows processes to know the number of nodes.
We also carry over a version of this result to the asynchronous setting:
Then there is a fair execution of A in which f~(n log n) messages are sent by the time the leader is elected.
If there is any fair execution of A in which more than n log n messages are sent by the time the leader is elected, then we are done, so assume that this is not the case.
We "restrict" A to yield a synchronous algorithm S in which some message is sent at every round.
Since at most n log n messages are sent in any fair execution of A by the time the leader is elected, this means that the number of rounds required for S to elect a leader is at most n log n.
Since the UID space is infinite, Theorem 3.11 applies to show that there is an execution of S in which ft(n log n) messages are sent by the time the leader is elected.
This can be converted into a fair execution of A in which f~(n log n) messages are sent by the time the leader is elected.
Then there is a fair execution of A in which f t(n log n) messages are sent.
Assume that we have a universal infinite set P of process automata.
All processes in P are assumed to be identical except for UIDs; also, they are assumed to know their neighbors only by local names, say "right" and "left."
We define a line to be a linear composition (using I /O  automaton composition) of distinct process automata from P,  with intervening reliable FIFO send/receive channels in both directions.
We say that two lines are disjoint if they contain no common process automaton, that is, no common UID.
The join operator is associative, so we can extend it to apply to any number of lines.
If L is any line of automata,  we define ring(L) to be the ring consisting of L wrapped around, with new reliable FIFO send/receive channels inserted in both directions between the r ightmost and leftmost processes of L.
The ring and join operations are depicted in Figure 15.3
We now represent the channels as just  arrows rather than ovals.
We say that a state s of a ring is silent if there is no execution fragment.
We say that a state s of a line is silent if there is no input-free execution fragment starting from s in which any new message is sent.
Note that if a ring or line is in a silent state, it does not.
We show something stronger: that all except possibly one process automaton in P can send at least one message without first receiving any message.
Suppose, to obtain a contradiction, that there are two processes in P,  say processes i and j ,  such that neither can send a message without first receiving.
Since neither i nor j can send a message unless it first receives one, no messages are ever sent in any execution of any of the three rings.
Thus, the processes i and j proceed independently, performing local computation and leader.
Because there is no communication, a is indistinguishable by process i.
But this causes two leaders to be elected in R3, a contradiction.
We have shown that there cannot be two processes, i and j ,  in P,  neither of which can send a message without first receiving one.
Since P is an infinite set, removing one process leaves an infinite set of processes, each of.
The proof of Theorem 15.12 uses the following key lemma.
Let L:0 be the set of all single-node lines corresponding to all the processes in P.
Let s be any infinite collection of disjoint two-node lines composed of processes each of which can send a message without first receiving one.
The existence of this collection is implied by Lemma 15.13
Let L, M,  and N be any three lines from s We consider the six possible joins of two of these three lines: join(L, M),  join(M, L), join(L, N),  join(N,  L), jo in(M, N),  and join(N,  M)
The lemma then follows from Claim 15.15, because infinitely many sets of.
Assume the contrary, that  none of these six lines n log n messages.
By the inductive hypothesis, can be made to send as many as.
We can assume without loss of generality that  the final state of OLL is.
This extension cannot go on indefinitely, since log n messages.
Similarly, we know that  L alone cannot send as many as.
Now we construct a finite execution C~L,M of the line join(L, M)
Execution OZL, M starts by running a L on L and C~M on M, delaying all messages sent on the channels connecting the lines L and M.
Note that ,  however this happens, the number of additional messages that  are sent in the extension must be strictly.
But this is a total of at least ~ additional messages in the extension of aL and.
So the indicated state of join(L, M) must be silent.
Informally speaking, after aL,M, information about the junction of lines L.
Only the ~ processes on either side of the junction can know about the junction, and.
Now we combine the lines L, M, and N into several different rings to obtain a contradiction.
Since the processes that  learn about each junction extend at most halfway into each of the adjacent lines, there.
Furthermore, after these three extensions, the entire ring is silent.
The correctness conditions imply that some leader, say il, is elected in C~l.
We may assume without loss of generality that process il is between the midpoint of L and the midpoint of M, as depicted in Figure 15.6
We claim that no leader can be elected in c~4
But the fact that no leader is elected in O~4 violates the problem requirements, which yields the contradiction needed to prove the claim.
The lemma now follows immediately from Claim 15.15, as described just before the proof of the claim.
Firs t  suppose  that  n is a power of 2, say n =
We leave the argument for values of n that  are non-powers of 2 for an exercise.
Note the crucial parts played in the proof of Theorem 15.12 by the asynchrony and the unknown ring size.
So far in this chapter, we have considered algorithms for electing a leader in an asynchronous ring network.
Now we will consider the leader-election problem in networks based on more general graphs.
We assume in this section tha t  the underlying graph is undirected, that  is, that  there is bidirectional communication on all the edges, and that  it is connected.
Recall the FloodMax algorithm for synchronous networks from Section 4.1.2
It requires that  processes know diarn, the diameter of the network.
In that algorithm, every process maintains a record of the maximum UID it has seen so far, initially its own.
At each synchronous round, the process sends this maximum on all its channels.
The algorithm terminates after diam rounds; the unique process that  has its own UID as its known maximum then announces itself as the leader.
The FloodMax algorithm does not extend directly to the asynchronous setting, because there are no rounds in the asynchronous model.
We simply require each process that  sends a round r message to tag that  message with its round number r.
The recipient waits to receive round r messages from all its neighbors before performing its round r transition.
In the synchronous setting, we described an optimization of FloodMax called OptFloodMax, in which each process only sends messages when it has new information, that  is, when its maximum UID has just changed.
It is not clear how to simulate this optimized version in an asynchronous network.
If we simply tag messages with round numbers as for FloodMax, then a process that  does not hear from all its neighbors at a round r cannot determine when it has received all its incoming messages for round r, so it cannot tell when it can perform its round r transition.
We can, of course, add dummy messages between pairs of neighbors that  do not otherwise communicate,  but that  destroys the optimization.
But there is a problem: now the processes have no way of knowing when to stop.
Many different solutions can be developed for the leader-election problem in general asynchronous networks, using many of the techniques that we will develop in the following sections and chapters.
Asynchronous broadcast and convergecast, based on a searching algorithm (Section 15.3)
Using a synchronizer to simulate a synchronous algorithm (Section 16.5.1)
Using a consistent global snapshot to detect termination of an asynchronous algorithm (Section 19.2.3)
Among the most fundamental tasks to be performed in an asynchronous network are the construction of a spanning tree for the network rooted at a given source node i0 and the use of such a tree for performing broadcast and convergecast communication.
We again assume that the underlying graph G = (V, E) is undirected and connected.
The processes do not need to know the size or diameter of the network.
For the spanning tree problem, the requirement is that each process in the network should eventually report, via a parent output action, the name of its parent in a spanning tree of the graph G.
The SynchBFS algorithm searches the graph synchronously starting from i0, allowing each non-source process i to report as its parent the first neighbor from which it hears.
This algorithm can be run in the asynchronous setting and is still guaranteed to produce a spanning tree, though not necessarily a breadth-first spanning tree.
A synchSpanning Treei a u t o m a t o n :
A key a s se r t ion  for the p roof  is.
In any reachable state, the edges defined by all the.
Thi s  is p roved  by induct ion ,  as usual.
To show the l iveness c o n d i t i o n - - t h a t  each.
Pileups are not an issue here, because only one message is ever sent on each channel.
Note that the paths that are produced by the A synchSpanningTree algorithm might be longer than the diameter of the network.
This is because, in an asynchronous network, messages can sometimes travel faster on longer paths than on shorter ones.
Nevertheless, the time to produce the tree is still bounded in terms of the diameter, because the time for each process to receive its first search message is no greater than the time for a message to travel to it from i0 along a shortest path.
As for SynchBFS, it is easy to augment the A synchSpanning Tree algorithm to implement message broadcast from the source i0
The message need only be piggybacked on all search messages during the formation of the spanning tree.
The communication complexity of this broadcast is thus O (IEI) and the time for it is O (diam(f + d))
It is also easy to augment the AsynchSpanningTree algorithm so that parents learn who their children are.
Since communication is here assumed to be bidirectional, all that is needed is for each recipient of a search message to respond directly with either a parent or non-parent message, as appropriate.
A precomputed spanning tree with child pointers can also be used for convergecasting information from all the processes in the tree to i0
This works in the same way as it does in the synchronous setting: Each leaf process sends its information to its parent.
Each internal process other than i0 waits until it receives information from all its children, then combines this information with its own and sends the result to its parent.
The number of messages is O (n), and the time is O (h(e + d))
As in the synchronous setting, this scheme can be used for the computation of a.
A combination of a broadcast and a convergecast can be used to allow i0 to.
Each leaf simply initiates a convergecast when it receives the broadcast message.
The total number of messages is again O (n), and the time is again O(h(e + d))
We can also allow i0 to broadcast a message and receive acknowledgments from all processes while a spanning tree is being constructed.
The total communication is O (IEI), and the time is O (n(~ + d))
The upper bound on time depends on n instead of diam because of the timing anomaly described above--the broadcast might travel fast along a long path, and the subsequent acknowledgments might travel slowly when they return along the same path.
In Chapter 16, we will see how to obtain an algorithm whose time complexity depends only on diam.
If the tree in AsynchBcastAck is only needed for sending and acknowledging one message, each process can delete all of the information about the algorithm after it performs its report action and sends out its acks.
We leave this modification and its correctness proof as an exercise.
A p p l i c a t i o n  to  l e a d e r  e lec t ion.
Asynchronous broadcast and convergecast can be used to solve the leader-election problem in arbitrary graphs without any distinguished source node and without the processes having any knowledge of the number of nodes or the diameter of the network.
The node that finds that the maximum is equal to its own UID elects itself as leader.
We finish this section by noting a close connection between two fundamental problems, in a connected, undirected graph network with only local knowledge, without any distinguished nodes, but with UIDs:
First, if we are given an unrooted spanning tree, then it is possible to elect a leader as follows.
The idea is the same as we discussed for the synchronous case, at the end of Section 4.4
Each leaf node is initially enabled to send an elect message to its unique neighbor.
Any node that receives elect messages from all but one of its neighbors is enabled to send an elect message to its remaining neighbor.
In the end, there are two possibilities: either some particular process receives elect messages along all of its channels before it has sent out an elect message, or elect messages are sent on some particular edge in both directions.
In the first case, the process at which the elect messages converge elects itself as the leader.
In the second case, one of the two processes adjacent to this edge, say the one with the larger UID, ele'cts itself as the leader.
Theorem 15.17 The S TtoLeader algorithm elects a leader in a connected undirected graph network with a spanning tree in which the processes have only local knowledge and have UIDs.
The STtoLeader algorithm uses only at most n messages and takes time only O (n(~ + d))
Conversely, if a leader is given, then we have already shown how to construct a spanning tree, using AsynchSpanningTree.
This requires O (IEI) messages and 0 (diam(g + d)) time.
So, modulo the (reasonably small) costs of these two basic algorithms, the problems of leader election and finding an arbi t rary spanning tree are equivalent.
Now we assume that the underlying graph G = (V, E) is a connected undirected graph and that there is a.
For the shor tes t  pa ths  problem,  we also assume tha t.
For breadth- f i r s t  search,  the p rob lem is for each process  in the ne twork  eventua l ly  to repor t ,  via a parent  ou tpu t  action, the name of its pa ren t  in a b read thfirst spann ing  tree.
Recall  that  in the synchronous  case, this can be accompl i shed.
The  asynchronous  version of S y n c h B F S  is.
It is possible to modify  A synchSpanningTree  so that  processes  correct  erroneous parent  designat ions.
In this case, process  i must  inform its other  neighbors  about  its correction, so that  they  might  also correct  their  parent  designat ions.
A s y n c h B F S i  a u t o m a t o n :
A s s e r t i o n  15.4.1 The following are true in any reachable state.
For every message m in channel Ci,j, m is the length of some path p from io to i.
This implies that  each process i always has correct information about some path from i0 to i.
But in order to show the liveness p rope r ty - - tha t  each process eventually obtains information about a shortest pa th - -we  need another invariant that  implies that  information about shortest paths is "conserved."
A s s e r t i o n  15.4.2 The following is true in any reachable state.
A problem with AsynchBFS is that  there is no way for a process to know when there are no further corrections for it to make.
This would be true even if the size of the network were known.
Thus, the algorithm is technically not a solution to the BFS problem, because it never produces the required parent outputs.
It is possible to augment A synchBFS to produce the outputs  by adding acknowledgments for all messages, convergecasting the acknowledgments back to i0 as in AsynchBcastAck.
This enables i0 to learn when the system has reached.
This convergecast is a bit complicated, because, unlike for AsynchBcastAck, a process i may need to participate many times.
Each time process i obtains a new dist estimate from a neighbor j and sends out corrections to all of its other neighbors, it waits for corresponding acknowledgments from all those neighbors before sending an acknowledgment to j.
Bookkeeping is needed to keep the different sets of acknowledgments separate.
If diam is known, then A synchBFS can be improved somewhat by only allowing distance estimates that are less than or equal to diam.
We now give another solution; this one does produce the needed parent outputs.
It does not require any knowledge of the size or diameter of the network graph.
This solution has smaller communication complexity than any of the versions of A synchBFS but has higher time complexity than the version of A synchBFS with known diam.
The BFS tree is constructed in layers, where each layer k consists of the nodes at depth k in the tree.
The layers are constructed in a series of phases, one per layer, all coordinated by process i0
In the first phase, process i0 sends search messages to all of its neighbors and waits to receive acknowledgments.
A process that receives a search message at phase 1 sends a positive acknowledgment.
Inductively, we assume that k phases have been completed and that the first k layers have been constructed: each process at depth at most k knows its parent in the BFS tree, and each process at depth at most k -  1 knows its children.
Moreover, the source i0 knows that all of this has been accomplished.
Upon receiving a newphase message, each depth k process sends out search messages to all its neighbors except its parent and waits to receive acknowl15.4
When a non-i0 process receives its first search message in an execution, it designates the sender as its parent and returns a positive acknowledgment.
When a non-i0 process receives a subsequent search message, it returns a negative acknowledgment.
When i0 receives any search message, it returns a negative acknowledgment.
When a depth k process has received acknowledgments for all its search messages, it designates the processes that have sent positive acknowledgments as its children.
Then the depth k processes convergecast the information that they have completed the determination of their children back to i0, along the edges of the depth k spanning tree.
They also convergecast a bit, saying whether any depth k + 1 nodes have been found.
There are a total of O (IEI) search and acknowledgment messages because each edge is explored at most once in each direction.
Also, at every phase, each tree edge is t raversed at most once by newphase and convergecast messages; since there at most diam + 1 phases, this yields a total of at most.
The A synchBFS algorithm with known diam and the LayeredBFS algorithm.
This trade-off is further illustrated by the following hybrid of the A synchBFS and LayeredBFS algorithms.
If m - 1, then HybridBFS is the same as LayeredBFS, while if m - diam, HybridBFS is similar to A synchBFS with known diam.
For intermediate values of m, the communication and time complexity measures are between those of LayeredBFS and A synchBFS with known diam.
In each phase, m layers in the BFS tree are determined (rather than just one as in LayeredBFS)
In each phase, the next m layers are explored asynchronously, with corrections as in A synchBFS.
By the time a convergecast is completed, process i0 knows that all the processes in the layers being explored in the current phase have stabilized to their correct.
The HybridBFS algorithm has communication complexity O (rolE I + n.diam).m There are a total of 0 (m El) search and acknowledgment messages because each edge only carries information about at most m different distance estimates.
Also, at every phase, each tree edge is traversed at most once by newphase and convergecast messages; since there at most O (A_~) phases, this yields at most O (n.diam) such messages.
The m 2 term results from the possibility of a pileup of m messages in a single channel.
We have given three algorithms to solve the BFS problem: the AsynchBFS algorithm (with termination), the LayeredBFS algorithm, and the HybridBFS algorithm.
For a simple comparison among the three, we consider the version of AsynchBFS with termination and in which diam is known.
We neglect the local processing time g and also neglect the effects of pileups in the links, using d as an upper bound for the delivery of each message in a channel.
Now we turn to the problem of finding shortest paths in an asynchronous network based on a weighted undirected graph.
Recall that in the synchronous setting, the BellmanFord algorithm solves the problem of finding shortest paths.
Even though this algorithm is synchronous, it must correct erroneous estimates of its distance.
The BellmanFord algorithm can be run asynchronously, using the following code, which is the natural generalization of the code for AsynchBFS.
A s y n c h B e l l m a n F o r d i  a u t o m a t o n :
In any fair  execution of the AsynchBel lmanFord algorithm, the system eventually stabilizes to a state in which the parent variables represent.
A prob lem for AsynchBellmanFord,  as for AsynchBFS,  is t ha t  there  is no way for a process to know when  it has no fur ther  correct ions  to make.
We can a u g m e n t  AsynchBel lmanFord with  a convergecast  of acknowledgments , in the  same way t h a t  we did for A synchBFS, and thus  ob ta in  the  needed ou tpu t s.
The  complex i ty  analysis  of AsynchBel lmanFord is interest ing,  main ly  because the worst -case  message and  t ime complexi t ies  are ex t remely  b a d - - t h e y.
We assume that the channels are universal FIFO reliable channels.
In fact, we claim that it is possible to force ik to take on all of these estimates in order, from the largest to the smallest, in the same execution, as follows.
Process ik-1 then sends this reduced estimate on both paths to ik.
It is possible to run the system in such a way that all the processes, and all the channels except for Cik,ik+l, operate very quickly.
We next consider upper bounds on complexity for A synchBellmanFord.
The number of messages sent on any channel Ci,j is proportional to the number of different estimates that the sending process, i, obtains.
Actually, it is smaller, but we leave the improvement for an exercise.
An upper bound on the time complexity is O (nn+l(g + d)), using the bound of n n on the number of messages in one channel.
Notice how heavily the time bounds depend on the pileups in the message channels.
If we adopt the simpler assumption, sometimes made in the theoretical research literature, that any message takes at most time d from sending until receipt (and if we ignore local processing time), then the time bound for AsynchBellmanFord can be calculated as only O (nd)
This is certainly not a realistic analysis for this algorithm.
For the last section in the chapter, we return to the problem of constructing a minimum-weight spanning tree of a network based on an arbitrary connected undirected graph.
In Section 4.4, we gave an algorithm, SynchGHS, to solve this problem in the synchronous setting; now we show how to modify this algorithm so that it can be used in the asynchronous setting.
The resulting algorithm, which we call GHS after its discoverers, Gallager, Humblet, and Spira, is one of the best-known algorithms in distributed computing theory.
It is a carefully engineered, complex algorithm that has been considered interesting enough to serve as a case study for algorithm verification methods.
We suggest that you reread Section 4.4 at this point; it contains the underlying theory on which the GHS algorithm is based, plus the SynchGHS algorithm, which contains many of the ideas needed for GHS.
As before, we assume that the underlying graph G = (V, E) is connected and undirected, and we assume that the edges have associated weights.
We want the processes to cooperate to construct a minimum-weight spanning tree (MST) for the graph G, that is, a tree spanning the vertices of G whose total edge weight is less than or equal to that of every other spanning tree for G.
We assume that processes have UIDs and that the weight Of each edge is known to the processes associated with the incident vertices.
We make one technical assumption: we assume that all the edge weights are unique.
The same argument that we gave at the end of Section 4.4 shows that this uniqueness assumption is not significant--ties among edges with the same weights can be broken using the adjacent process UIDs.
We assume that the processes have only local knowledge of the graph; in particular, they do not know the number of nodes or the diameter.
We assume that the processes are initially quiescent, that is, that no locally controlled actions are enabled in their start states.
We assume that each process has a wakeup input action by which the environment signals it to begin executing an MST algorithm.
We allow any number of processes to receive wakeup inputs during the course of an execution; thus, the algorithm must work regardless of the number of processes that initiate computation and regardless of when they do so.
Note that we assume only that processes' start states are quiescent; we permit a process to awaken when it receives any sort of inpu t - -a  wakeup or a message from another process.
The output of the algorithm is the set of edges comprising an MST, in particular, every process is required to output the set of edges adjacent to it that are in the MST.
These properties are used to justify a strategy in which, at any intermediate state, the algorithm has constructed a spanning forest all of whose edges are in the MST.
Then each of an arbitrary subset of the components of the spanning forest may independently determine its own minimum-weight outgoing edge (MWOE), knowing that all such edges found must be included in the unique MST.
The SynchGHS algorithm works in "levels." The level 0 spanning forest consists of individual nodes and no edges.
Given the level k spanning forest, the algorithm constructs the level k + 1 spanning forest by allowing all components in the level k spanning forest to determine their MWOEs and then combining all the components along these edges.
It follows that each level k component contains at least 2 k nodes.
The determination of the MWOE for a component is managed by a distinguished leader node of the component, whose UID is used as a component.
The assumpt ions  we are making here about  wakeup messages are different from those we made at the end of Section 15.1.1
There,  we assumed that  wakeup messages  arrived at all processes.
The leader broadcasts a request to determine the MWOE along the component edges, then the processes engage in a query protocol to learn which of their neighbors are in the same or different components, and then the processes convergecast their information back to the leader.
The combination of components involves communication from the leader to the process adjacent to the MWOE.
Using careful bookkeeping, the processes can ensure that  the communication complexity is kept to O (n log n + IEI) and the number of rounds to O(nlogn)
If we try to run SynchGHS in an asynchronous network, some dimculties arise.
Difficulty 1: In Synch GHS, when a process i queries a neighbor j to see if j is in the same component of the current spanning forest, it knows that  j is up to the same level of the construction.
Therefore, if process j has a distinct component identifier, then it must be the case that  j is not in the same component.
But in the asynchronous setting, a situation could arise whereby process j is actually in the same component as i but has not yet learned this (because a message containing the latest component identifier has not yet reached it)
Difficulty 2: The SynchGHS algorithm achieves a message cost of O(n log n + IEI), based on the fact that  the levels are kept synchronized.
Each level k component has at least 2 k nodes, which implies that  the total number of levels is at most log n.
In the asynchronous setting, there is a danger of constructing the components in an unbalanced way, leading to many more messages.
The number of messages sent by a component to find its MWOE will be at least proportional to the number of nodes in the component.
Difficulty 3: In SynchGHS, the levels remain synchronized, whereas in the asynchronous setting, some components could advance to higher levels than others.
It is not clear what type of interference might occur as a result of concurrent searches for MWOEs by adjacent components at different levels.
These difficulties require careful consideration in adapting the SynchGHS algorithm to the asynchronous setting.
In particular, it achieves the same communication complexity, O ( n l o g n  + IEI), and a corresponding time bound, O (n log n(g + d))
In the GHS algorithm, processes form themselves into components, which.
Each component has a distinguished leader node, as well as a spanning tree that is a subgraph of the MST.
Within any component,  the processes cooperate in an algorithm to find the M W O E  for the entire component.
This involves a broadcast  originating at the leader, asking each process in the component to determine its own minimumweight edge that leads outside the component.
Information about all these edges is convergecast back to the leader, who can determine the MWOE for the entire component.
Once the MWOE is found, a message is sent out over that edge to the component on the other side.
The two components may then combine into a new, larger component.
In this case, the entire procedure is repeated for the new component.
Enough combinations are carried out so that, eventually, all the nodes in the graph are included in a single component,  whose spanning tree is the needed MST.
There are several problems that need to be addressed in making this algor i thm work correctly.
First, how does a process i know which of its edges lead.
But this issue is more complicated than this: it may be, as described in Difficulty 1 above, that an adjacent process j with a different component name is in fact in the same component as the querying process i, but has not yet learned this fact because of communication delays.
Some sort of synchronization is needed, to ensure that process j does not respond that it is in a different component unless it has current information about its component name.
The second problem, described in Difficulty 2 above, involves an excessive number of messages that might be produced by an unbalanced combination of components.
In order to cope with this difficulty, we will try to keep the sizes of.
More precisely, we will associate a level with each component, as we do in SynchGHS.
A level k + 1 component will only be formed by combining exactly two level k components, thereby preserving the size requirement.
This strategy departs slightly from that used in SynchGHS: in SynchGHS, an arbitrary number of level k components can be combined to yield a level k + 1 component.
As it turns out, these levels will not only be useful in keeping the combinations balanced-- they also provide some identifying information that can help processes determine if they are in the same component.
The third problem, described in Difficulty 3, is that  some components can advance to higher levels than others, leading to possible interference between concurrent searches for MWOEs by adjacent components at different levels.
The GHS algorithm combines components in two different ways, which we call merging and absorbing.
The result of the merge is a new component containing all the nodes and edges of C and C ~ plus the common MWOE.
The result of the absorb is a new component containing all the nodes and edges of C and C ~, plus the MWOE of C.
The new component is assigned the same level as C ~
In fact, we prefer not to think of the absorb as actually producing a "new component," but rather as just adding C to the already existing C ~
The absorb operation is useful for the case where some processes lag behind others.
Suppose that a large group of nodes are formed into a large component, C ~, with a high level by a series of merge operations, while some other small components lag behind with lower levels.
These two combining strategies are illustrated roughly by Figure 15.12
We now argue that the merge and absorb operations are sumcient to combine all components into an MST for the entire graph.
Then after this sequence of operations, either there is only one component, or else some merge or absorb operation is enabled.
Suppose that there is more than one component after a sequence of mewe and absorb operations.
We consider the "component digraph" G ~, whose nodes are the current components and whose directed edges correspond to the MWOEs; each edge is directed away from the component for which it is the MWOE.
This says that there are two components, C and C ,  whose MWOEs point to each other.
But it is easy to see that in this case, the two MWOEs must be the same edge of the original graph G.
Now we consider in more detail how the MWOE is found for a given component.
This involves each process i in the component determining its own minimum-weight edge (if any) that is outgoing from the component,  mwoe( i ) , and then all the processes sending their information to a leader node, who selects the one with the minimum weight overall.
First, we need a mechanism for selecting the leader process for each component.
And second, we need a way for a process to determine whether a given edge is outgoing from the component.
To help in these tasks, for every component of level 1 or greater, we identify a specific edge that we call its core edge.
This edge is defined in terms of the series of merge  and absorb operations that are used to construct the component.
After a merge  operation, the core is the common MWOE of the two original components.
After an absorb operation, the core is the core of the original component with the larger level number.
Thus, the core of a component is the edge along which the last merge  that was.
For a component of level 1 or greater, we use the pair consisting of the core.
This makes sense because the weights of edges are assumed to be unique.
We also designate one of the endpoints of the core edge--for  instance, the one with the higher UID- -a s  the leader.
For a level 0 component,  the unique node is, of course, the leader.
Now suppose that process i wishes to determine whether its edge to neighboring process j is outgoing from i's current component.
If process j ' s  current component identifier is the same as that of i, then process i is certain that j is in the same component as itself.
However, if j ' s  component identifier is different from that of i, then it is still possible that i and j are in the same component but that j has not yet received notification of the current component identifier.
There is one special case that can be resolved: if j ' s  component identifier is different from that of i, and j ' s  latest known level is at least as high as that of i, then it is.
This is so because, in the course of an execution, a node can only have at most one component identifier for each level, and because, when i is actively searching for its outgoing edges, it is certain that i 's component identifier is up-to-date.
Thus, if i and j have the same component identifiers, j responds that  it is in the same component.
Also, if i and j have different component identifiers and the level of j is at least as great as that  of i, then j responds that  it is in a different component.
The only remaining case is where the level of j is strictly smaller than that  of i; in this case, process j simply delays answering i until its own level rises to become at least as great as that  of i.
However, notice that  we now have to reconsider the progress argument,  since this new delay could conceivably cause progress to be blocked.
The fact that some processes in a component can be delayed in finding their minimum-weight outgoing edges means that  the component as a whole can be delayed in finding its MWOE; we must consider whether this can cause the system to reach a state in which no further merge or absorb operations can be performed.
To see that  this cannot happen, we use essentially the same progress argument as before, but this time we consider only those components with the current lowest level, say k.
All the processes in these components must succeed in their individual minimum-weight  outgoing edge determinations,  so these components must succeed in determining their MWOEs.
If any of the level k components finds that  its MWOE leads to a higher-level component,  then an absorb operation is possible.
Thus, even with the new type of delay, the algorithm must make progress until the complete MST is found.
Thus, we have seen how each process determines its own minimum-weight outgoing edge (if any)
Then, as described above, the leader of the component determines the MWOE for the component via a broadcast and convergecast, selecting the edge with the overall minimum weight.
We must still consider Difficulty 3: the possible interference between concurrent searches for MWOEs by adjacent components at different levels.
Suppose that  the MWOE of C connects node i of C and node j of C'
First, suppose that  process j has not yet determined its minimum-weight edge outgoing from the component at the time the absorb occurs.
In this case, the algorithm searches for the MWOE of the combined component in C as well as in C.
The fact that  j has not yet determined mwoe(j) means that  it is not too late to include C in the search.
On the other hand, suppose that process j has already determined mwoe(j) at the time the absorb occurs.
In this case, we claim that mwoe(j) r (i, j), that is, the minimum-weight edge for j cannot possibly be the same as the MWOE for C.
This is because the fact that mwoe(j) has already been determined implies that it leads to a component with a level at least as great as that of C ~
A technical point: The fact that the level told to j by the other endpoint of mwoe(j) was at least as great as the level of C ~ implies that it is still at least as great, because the level known by a process cannot decrease.
However, since C is absorbed into C', we know that level(C) is strictly smaller than level(C')
This implies that the weight of mwoe(j) is strictly less than the weight of (i, j)
Then we claim that the MWOE for the combined component cannot possibly be adjacent to a node in C.
This is true because (i, j )  is the MWOE for fragment C, so there can be no edges leading out of C with smaller cost than (i, j) ,  and so no edges leading out of C with smaller cost than the already discovered mwoe(j)
Thus, if mwoe(j) has already been determined at the time of the absorb, the algorithm need not search for the MWOE of the combined component in C.
This is fortunate, since it might already be too late to search there--process j might have already reported its minimum-weight edge, and component C ~ might be in the process of deciding on an overall MWOE without knowing about the newly absorbed nodes.
We now give a little more detail about the specific messages that are sent in the GHS algorithm.
An initiate message is broadcast throughout a component, starting at the leader, along the edges of the component 's  spanning tree.
Normally, 2 it triggers processes to start trying to find their mwoes.
There is an exceptional case, which we will mention below.
A report message convergecasts information about minimum-weight edges back toward the leader.
A process i sends a test message to a neighbor j to try to ascertain whether or not j is in the same component as i.
This is part of the procedure by which process i searches for its own mwoe.
They tell the testing node whether the responding node is in a different component (accept) or the same component (reject)
A changeroot message is sent from the leader of a component toward the component process that is adjacent to the component 's  MWOE, after the MWOE has been determined.
It is used to tell that process to at tempt to combine with the component at the other end of the MWOE.
A connect message is sent across the MWOE of a component C when that component at tempts to combine with another component.
A merge operation occurs when connect messages have been sent both ways along the same edge.
An absorb operation occurs when a connect message has been sent one way along an edge that leads to a process at a higher level than the sender.
In the test-accept-reject protocol, there is some bookkeeping that the testing process i must do in order to keep the communication complexity low; this is similar to the bookkeeping described earlier for SynchGHS.
Namely, process i maintains a list of its incident edges in increasing order of weight.
These are the edges that process i cannot yet classify as being in or out of the MST.
When process i searches for its minimum-weight outgoing edge, it only needs.
It tests the basic edges sequentially, lowest weight to highest.
For each basic edge, process i sends a test message containing the component identifier (core and level) of its component C.
When  i receives the reject message, it reclassifies the edge as a rejected edge.
Also, if the recipient j ' s  core is different from that  of i and its level is at least as great as that  of i, then j responds with an accept message.
Finally, if j ' s  core is different from that  of i and its level is strictly smaller than that  of i, process j simply delays responding until such time as it is able to send back a reject or accept, according to the rules above.
Note that  it is possible for i to receive an accept message for edge (i, j ) , but  for edge (i, j )  not to be the one eventually identified as the M W O E  for the entire component  C.
In this case, the same edge (i, j )  may be re tes ted by i in subsequent  searches.
Process i only reclassifies an edge as a branch edge when it actually discovers that  the edge is par t  of the MST, for example, when process i receives a changeroot message referring to that  edge or receives a connect message over the edge.
When  two connect messages cross on a single edge, a merge operation occurs.
Then  the common edge is identified as the new core, the level is increased by one, and the endpoint  with the larger UID is chosen as the new leader.
The new leader then broadcasts  initiate messages to begin looking for the M W O E  of the new component  formed by the merge.
When a connect message is received by a process from a lower level component ,  an absorb operation occurs.
The recipient process knows whether or not it has already found its mwoe and thus knows whether it needs to tr igger a search in the newly absorbed component.
In either case, it will broadcas t  an initiate message to that  component  to tell the processes in that  component  the latest component  identifier.
Note that  each process is able to perform its output  as soon as it no longer classifies any of its incident edges as basic; the output  is simply the set of branch edges.
The communicat ion complexity analysis is similar to that  for SynchGHS, giving the same bound of 0 ( n l o g n  + tel)
The 0 (IEI) counts the test messages that  lead to rejection, plus the reject messages, on all.
This is a total of O (IEI), because each edge is rejected at most once: after a reject message is received on an edge by a process i, i never again tests that edge.
All the other messages-- the test-accept pairs that enable a process to accept an edge as its mwoe, the initiate and report messages that are used for broadcast and convergecast, and the changeroot and connect messages that are used after a component has determined its M W O E ~ a r e  charged to the task of finding the MWOE for a specific component (i.e., for a specific core and level)
In this task for one component, these messages can be associated with nodes in such a way that there is at most one of each of these types of messages associated with each node.
In particular, each process sends at most one successful test message.
Organizing the components according to their levels, we rewrite this expression a s.
For each level k, the inner sum is at most n, because no node ever appears in more than one component with level = k.
It follows that the overall communication complexity of the algorithm is O(n log n-tIEI), claimed.
For the time complexity, it is convenient to include a preliminary protocol to awaken all the processes as quickly as possible.
Then it can be shown by induction on k that the time for all the processes to reach level at least k is 0 (kn( f  + d))
Thus, the total time is O (n log n(t~ + d))
Note that the communication complexity must be f~(n log n), at least for some graphs.
The GHS algorithm is the first one in this book for which we have not at least outlined a correctness proof.
There is a good reason for this: at the present time, no simple proof is known.
The algorithm has been proved correct, at least four times, by a variety of methods, but none of the proofs is sufficiently nicely organized to be outlined in a few pages.
One approach that works is the usual invariant assertion approach.
Here, this involves collecting a rather large number of invariants, describing all the different tasks performed by the algorithm.
For instance, there are invariants describing the correct operation of the broadcast and convergecast tasks, invariants describing the test-accept-reject protocol, and invariants describing the changeroot-connect protocol.
All of these invariants can be proved together by a huge inductive argument.
Such a proof involves a large number of cases and a large amount of tedious detail, but is, in principle, quite straightforward.
But such a brute-force proof does not seem to take full advantage of the modularity that is present in the algorithm.
So it is not clear how we could carry out the correctness proofs for the various tasks separately and then combine the results.
Also, the brute-force invariant assertion proof does not take much advantage of high-level intuition about the algorithm.
Note that much of our discussion of the algorithm has involved high-level notions such as graphs, components, levels, and MWOEs, rather than low-level concepts such as messages and local variables.
It seems that a good proof ought to proceed, as far as possible, in terms of the high-level notions.
In fact, a second approach that works is to give a highlevel description of the algorithm, as an automaton that manipulates graphs, components, and so on, and to prove this correct using invariants.
Then it is possible to prove that the detailed algorithm correctly simulates the high-level description.
The formal correspondence between the low-level and high-level algorithms is a simulation relation, as defined in Section 8.5.5
The proofs for synchronizer algorithms demonstrate especially nicely how some complex asynchronous network algorithms can be decomposed in two ways: using I/O automaton composition for.
Another approach to proving the correctness of GHS is to try to relate its behavior formally to that of the synchronous version of the algorithm, SynchGHS.
Note that this relationship cannot be a simple simulation relation, because in the asynchronous algorithm, different portions of the network can be far out of synchronization, as determined by the current levels.
Whatever correspondence is used must allow some reordering of activities that happen in different places in the network.
We regard it as an interesting open problem to find a nicely decomposed proof of correctness for the GHS algorithm.
It would be acceptable to modify the algorithm slightly to obtain the modularity, as long as the modifications do not affect the important algorithmic ideas or the complexity.
In Chapters 16-22, you will see a variety of asynchronous network algorithms, decomposed using a variety of methods.
We hope that the complications of algorithms such as GHS have convinced you that it is important  to find such decompositions.
Note that the GHS algorithm has many complications that do not arise in the SynchGHS algorithm; most of these are the result of the fact that different pottions of the network can be far out of synchronization, as determined by the current levels.
One way of avoiding these complications is to try to simulate SynchGHS as closely as possible, keeping the levels of nearby processes close to each other.
Now level k components can only be combined into level k + 1 components, using the same general strategy as in SynchGHS.
Each process i maintains a local-level variable, which keeps track of the latest level process i knows for its component.
Initially, the local-level is 0, and when process i learns about its membership in a new component with level = k, i raises its local-level to k.
The key idea is that a process i with local-level = k tries not to participate in the algorithm for finding its level k component 's MWOE until all the processes in the network have local-levels at least equal to k.
But in fact, a weaker local synchronization is enough: each process only waits to learn that all of its neighbors in the underlying graph have local-levels at least k.
So that all processes can discover this, each process sends a message on each of its incident edges each time its local-level increases.
The SimpleMST algorithm has the same time complexity upper bound as GHS, namely, O (n log n(t~ + d)), and, of course, it is much simpler than GHS.
The communication complexity is worse, however, because of the synchronization messages used at every level: now it is O (IZl log n)
An MST algorithm can be used to solve the leader-election problem in an arbitrary connected undirected weighted graph with UIDs.
Namely, after establishing an MST, the processes participate in the STtoLeader protocol to select the leader.
Note that the processes do not need to know when the MST algorithm has completed its execution throughout the network; it is enough for each process i to wait until it is finished locally, that is, has output its set of incident edges in the MST.
If process i receives a message that is part of the STtoLeader algorithm before it has performed its output for the MST protocol, it simply delays the message until it is done with MST.
The idea is the same as in the general strategy for handling input arrivals in wakeup messages, described at the end of Section 15.1.1
If the GHS algorithm is used for establishing the MST, the total number of messages to elect a leader is O (n log n + IEI) and the total time is O (n log n(t~ + d))
The PetersonLeader algorithm was developed by Peterson and appears in [239]
Another unidirectional algorithm that achieves O (n log n) communication complexity was developed by Dolev, Klawe, and Rodeh [97]
The direct proof of the lower bound for the asynchronous setting is due to Burns [61]
Afek and Gafni [6] have developed complexity bounds for leader election in complete asynchronous networks.
Another interesting shortest paths algorithm was designed by Gabow [128]
Humblet [160] designed an asynchronous distributed algorithm for finding a minimum spanning tree in a directed graph network.
Give an alternative proof of correctness for the AsynchLCR algorithm, based on relating it formally to the synchronous L CR algorithm.
Strive to make your algorithm as simple (to write and to understand) as possible, while keeping the unidirectionality and the O (n log n) communication complexity.
Analyze the time (number of rounds) complexity of your algorithm.
Give a careful proof of the O (n(t~ + d)) upper bound for the time complexity of the PetersonLeader algorithm.
Design a version of the PetersonLeader leader-election algorithm for rings with bidirectional communication.
In the new version of the algorithm, the UIDs remaining in contention do not need to precess around the ring, but can stay where they originate; each process simply collects the UIDs from its two active neighbors at each phase.
Extend the AsynchLCR algorithm, the asynchronous HS algorithm, and the PetersonLeader algorithm so that the non-leaders also announce that they are not the leader, via non-leaderi output actions.
Analyze the communication and time complexities of the resulting algorithms.
Fill in the details of the proof sketch for Theorem 15.11
What is the best lower bound you can obtain in this way?
Assume that each process knows its neighbors by the local names "right" and "left," with the orientation consistent along the line.
Assume that each process knows whether or not it is an endpoint.
Consider the asynchronous simulation of OptFloodMax described in Section 15.2, in which the processes do not know when to terminate.
Fill in the details of the proof of Theorem 15.16
Design an algorithm for broadcast and acknowledgment in asynchronous networks, in which the time complexity depends on the diameter of the network rather than the total number of nodes.
Extend the spanning tree, broadcast, and convergecast algorithms in Section 15.3 to the case where the network is based on a strongly connected directed graph.
Give a careful description and complexity analysis for the leader-election strategy given just after the description of AsynchBcastAck.
Analyze the time complexity under two different assumptions: the usual upper bound of d on delivery of the oldest message in each channel and an upper bound of d on the delivery of an arbitrary message in each channel.
In the latter case, you may ignore local processing time.
Describe in detail an algorithm that allows a distinguished process i0 in an asynchronous network based on an arbitrary connected undirected graph G to calculate the number of nodes in G.
Fill in the details of the proof of Theorem 15.18
Do not assume any knowledge of the size or diameter of the network graph.
Prove the correctness of your protocol and analyze its complexity.
Hint: The communication complexity should be the same as for the basic AsynchBFS algorithm.
The time complexity becomes bigger because of the timing anomaly discussed for AsynchSpanningTree and AsynchBcastAck.
Repeat Exercise 15.23 for the modification of A synchBFS in which diarn is known and in which processes produce parent outputs.
Give an upper bound for the time complexity of the AsynchBellmanFord shortest paths algorithm.
It should be as tight as you can make it.
Prove the correctness of your protocol and analyze its complexity.
Design an algorithm to find the shortest paths from a fixed source node i0 to all other nodes in the network.
Your algorithm should have a much better time bound than the AsynchBellmanFord algorithm, say, O (n(g + d))
Extend the breadth-first search and shortest paths algorithms in Section 15.4 to the case where the network is based on a strongly connected directed graph.
You may assume that a preliminary protocol is used to awaken all the nodes as quickly as possible.
Describe an execution of GHS in which a reject message arrives at process i along channel Cj,i, in response to a previous test message by i, at a time when i classifies edge (i, j)  as a branch edge.
Suppose that, at some point in an execution of the GHS algorithm, a process i in a component C sends a connect message over some edge (i, j) , directed toward a component C' having the same level as C.
Argue that component C eventually either gets merged with C' or else absorbed into some component that includes C'
Research Question: Compare the operation of the GHS minimum spanning tree algorithm to that of SynchGHS.
Research Question: Find a nice, simple proof of correctness for the GHS algorithm as described in this chapter and in [130]
If it helps, you may modify the algorithm slightly, as long as you retain the same basic algorithmic ideas and the same message and time complexity.
Research Question: Find an MST algorithm with approximately O (diam 9 d) time complexity and with all messages of size O (log n)
I /O  automata that use an MST to elect a leader.
Describe the interactions between these two sets of automata carefully, identifying what actions are used for communication between the two sets of automata and identifying exactly what behavior each set of automata  requires of the other set.
Consider a network based on a line graph, as described in Exercise 15.12
Each process knows its neighbors by the local names "right" and "left," with the orientation consistent along the line.
Assume that each process i initially has a very large integer value vi, and that it can hold in memory only a constant number of such values at any time.
Try to design the most efficient algorithm you can, both in terms of the number of messages and in terms of the time.
Design an algorithm that will cause each process to return the sum of all the inputs in the network.
Try to keep the communication complexity, as measured in terms of the number of messages, low.
Consider a "banking system" in which each process in a network keeps a number indicating an amount of money.
We assume, for simplicity, that there are no external deposits or withdrawals, but messages travel between processes at arbitrary times, containing money that is being "transferred" from one location to another.
Design a distributed network algorithm that allows each process to decide on (that is, to output) its own balance, so that the total of all the balances is the correct amount of money in the system.
Assume that the execution of this algorithm is triggered by signals arriving from the outside, at one or more of the system locations.
These signals could happen at any time and could happen at different times at different locations.
Your algorithm should not halt or delay transfers "unnecessarily." Give a convincing argument that your algorithm works correctly.
Design a version of the LubyMIS algorithm of Section 4.5 that works in asynchronous networks.
Give a careful statement of what your algorithm guarantees and prove it.
In Chapter 15, we gave several examples of distributed algorithms programmed directly on the "bare" asynchronous network model.
As should be apparent by now, this model has so much uncertainty that it is very difficult to program directly.
It is, therefore, desirable to have simpler models that can be programmed more easily and whose programs can be translated into programs for the general asynchronous network model.
We have already presented two models that are simpler than the asynchronous network model--the synchronous network model and the asynchronous shared memory model--and have given many examples of algorithms for these two models.
In this chapter, we show how algorithms for the synchronous network model can be transformed into algorithms for the asynchronous network model, while in Chapter 17, we show how asynchronous shared memory algorithms can be transformed into asynchronous network algorithms.
These transformations enable algorithms for the two simpler models to be run in asynchronous networks.
The strategy of transforming synchronous to asynchronous network algorithms works only for non-fault-tolerant algorithms.
In fact, such a transformation cannot work for fault-tolerant algorithms because, as we will show in Chapter 21, the capabilities for fault-tolerance are fundamentally different in synchronous and asynchronous networks.
We formulate the transformation from the synchronous network model to the asynchronous network model in terms of a system module called a (local) synchronizer.
All of these implementations involve synchronizing the system at every.
The ability to synchronize less frequently (as, for example, in the SimpleMST algorithm) depends on special properties of the algorithm that  ensure that  it still works correctly if it is allowed to exhibit arbitrary interleavings of process steps between synchronization points.
Our presentation of the synchronizer implementations turns out to be a very good example of modular decomposition of distributed algorithms.
We begin with a "global" specification of correctness in terms of I /O automata.
Then we define a local synchronizer abstractly and show that  it implements the global specification; this requires techniques based on partial orders of events.
Next we describe several alternative ways of implementing the local synchronizer; each could be shown to do so using the simulation method of Section 8.5.5
However, most of these implementations can take advantage of additional decomposition steps.
Thus, we define another system module known as a safe synchronizer, show how it can be used to implement the local synchronizer, and then develop several distributed algorithms as implementations of the safe synchronizer.
The entire development is a good illustration of the power of decomposition methods in enabling simple description (and proofs) of complicated distributed algorithms.
We close the chapter with a contrasting lower bound on the time overhead required to run a synchronous network algorithm in an asynchronous network, if the synchronization requirements are very strong.
In this section, we describe the problem to be solved by a synchronizer.
The starting point is the synchronous network model, with a collection of n synchronous processes running at the nodes of an undirected graph G - (V, E), communicating by messages sent over the edges.
In the formulation of that model in Chapter 2, each process i is presented as a kind of state machine, with message-generation and transition functions.
Here, we deviate from the earlier development by instead representing each process i as a "user process" I /O automaton Ui.
Let M be the fixed message alphabet used in the synchronous system.
The user automaton Ui has output  actions of the form user-send(T, r)i, where.
The tag in a tagged message indicates the message destination, and the r argument represents the round number.
If Ui does not have any messages to send at round r, then it performs user-send(O, r)i.
Ui also has input actions of the form user-receive(T, r)i, where T is a set of tagged messages and r C N +, by which it receives messages from its neighbors.
Here, a tag indicates the message source and r is again the round number.
Ui may also have other external actions by which it interacts with the outside world.
We now model inputs and outputs of the user automata using input actions and output  actions rather than encoding them in the states (as we did in Chapter  2)
Example 16.1.1 user-send a n d  user-receive a c t i o n s.
Ui is expected to preserve the well-formedness condition that the user-sendi and user-receivei actions alternate, starting with a user-sendi action, and that successive pairs of actions occur in order of rounds.
That  is, the sequence of such actions is a prefix of an infinite sequence of the form.
There is one other condi t ion--a  liveness condi t ion-- that  Ui is required to satisfy: in any well-formed fair execution, Ui must eventually perform a usersendi for each round r such that user-receivei events for all previous rounds have already occurred.
That  is, the users continue sending messages for infinitely many rounds, as long as the system keeps responding.
We describe the rest of the system as a global synchronizer, GlobSynch.
Its job is, at each round, to collect all the messages that are sent by user automata at that round in user-send actions and to deliver them to all the user automata in user-receive actions.
It synchronizes globally, after all the user-send events and before all the user-receive events of each round.
See Figure 16.1 for a picture of the combination of user and GlobSynch automata,  that is, the GlobSynch system.
Notice that user-send actions are input actions of GlobSynch, while user-receive actions are output  actions of GlobSynch.
GlobSynch  c a n  eas i ly  be  d e s c r i b e d  as an  I / O  a u t o m a t o n.
Effect: user-sent(i, r):= true for all j ~ i do.
In  th i s  code ,  tray(i,  r) is d e s i g n e d  to  hold  the  m e s s a g e s  to  Ui t h a t  a re  s u b m i t t e d  by  all i ts  n e i g h b o r s ;  t h e s e  m e s s a g e s  a re  t a g g e d  w i t h  the i r  s e n d e r s '  indices.
The user-sent and user-rcvd components just keep track of whether user-send and user-receive events have occurred.
It should not be hard to see that any algorithm in the synchronous network model of Chapter  2 can be described in this new s ty le- -as  a composition of user automata  Ui and the GlobSynch automaton.
The synchronizer problem is to "implement" the GlobSynch automaton with an asynchronous network algorithm, with one process Pi at each node i of the underlying graph G and a reliable FIFO send/receive channel Ci,j in each direction on each edge (i, j )  of G.
This implementation should ensure that the individual user automata Ui cannot tell the difference between running in the implementation system (i.e., user automata plus the distr ibuted algorithm) and running in the GlobSynch system.
Note that we do not require that the relative order of events at different users be preserved, but only the view of each individual user.
All of the synchronizer implementations we describe are "local," in the sense that they only involve synchronization among neighbors in the network rather than among arbi t rary nodes.
The advantage of using only local synchronization is the potential for savings in communication and time complexity.
In this section, we define a local variant of GlobSynch that we call LocSynch; the algorithms will be presented as implementations of LocSynch.
The only difference is in the user-receive transitions, which are now described by.
Thus, in LocSynch, round r messages can be sent to Ui as soon as round r messages have been received from all its neighbors and from Ui itself; it is not necessary to wait for messages from all users in the entire network.
We cannot use simulation techniques to prove this correspondence as we did, for example, in the proof of TicketME in Section 10.9
This is because the relative order of external actions that  happen at different nodes is sometimes different in the two systems.
Rather ,  we use a method based on partial orders of events.
Let L and G denote the LocSynch and GlobSynch systems, respectively, modified slightly by reclassifying all the internal actions of the user au toma ta  as outputs.
Thus, the external actions of each system are exactly all the actions of the user au tomata.
Certain events of L "depend on" other events: a user-receive event depends on user-send events for the same round at the same or neighboring nodes, and any event at a user au tomaton  may depend on any preceding event at the same automaton.
The key proper ty  of these relations is the following claim.
It says tha t  the --+Z relations capture enough about  the dependencies in the fair t race /3  to ensure tha t  any reordering tha t  preserves these dependencies is still a fair trace.
This new ordering requirement is consistent with the dependency requirements in --4Z, since they never require the reverse order, even when they are applied transitively.
By Claim 16.2, y is also a fair trace of L.
But, in addition, since all the user-send events for each round r precede all the userreceive events for the same round r, it is not hard to show that 7 is a trace of G.
A simple example of a distr ibuted algorithm that implements LocSynch is as follows.
SimpleSynch algorithm (informal): For any round r, after receiving an input of the form user-send(T,r)i, process SimpleSynchi first sends a message to each neighbor SimpleSynchj, containing the round number r and any messages from Ui to Uj that appear in T.
When SimpleSynchi has received a round r message from each of its neighbors, it outputs user-receive(T', r)i, where T' is the set of messages received, each tagged with its sender.
Input : user-send(T, r ) i ,  T a set of tagged messages,  r C N + receive(N,r)j,i, N a set of messages,  r C N +, j E nbrs.
Output : user-receive(T, r) i ,  T a set of tagged messages,  r E N + send(N,r)i,j, N a set of messages,  r C N +, j C nbrs.
States: user-sent, user-rcvd, each a vector indexed by N + of Booleans,  initially all false pkt-sent, pkt-rcvd, each an ar ray  indexed by nbrs.
This time, unlike in the proof of Lemma 16.1, there is no reordering of events at different users, and the correspondence can be proved using simulation methods.
Let S and L denote the SimpleSynch and LocSynch systems, respectively, each modified slightly so that the actions that are classified as external are exactly all the actions of the user automata.
If s and u are states of S and L, respectively, then we define (s, u) C f exactly if all of the following hold:
To prove that f is a simulation relation, we need the following invariant assertion for S.
A s s e r t i o n  16.2.1 In any reachable state of the SimpleSynch system, if pkt-rcvd(j, r)i = true, then.
The proof of this invariant uses other intermediate invariants, involving the correctness of the messages in transit.
As before, we assume that the channels are universal reliable FIFO channels in the statement and proof of such invariants.
We leave the details of the invariant and simulation proofs as an exercise.
The existence of a simulation relation implies that every trace of S is a trace of L.
Recall that the actions that are included in these traces are exactly the actions of the user automata.
But we need more - - in  particular,  we need to know that the fairness conditions of S imply the fairness conditions of L.
To prove fair trace inclusion, we use the fact tha t  a simulation relation guarantees more than  just trace inclusion-- i t  also guarantees a close correspondence.
There are two ways in which it might fail to be fair.
Second, there might be some i and r such tha t  the user-receivei task for.
I f  pkt-sent(i, r)j = true, then either channel Cj,i contains a message or pkt-rcvd(j, r)i = true.
Then for each j E nbrsi, fairness for the send task at round r implies tha t eventually in a,  pkt-sent(j,  r)i becomes true.
Then Assertion 16.2.2 and channel fairness imply tha t  eventually pkt-rcvd(j, r)i becomes true.
Then fairness for the user-receivei task at round r in S implies tha t  a step of this task eventually occurs in a,  and so, by the correspondence, in a ~, a contradiction.
Note tha t  the proof of Lemma 16.3 actually shows that  fairtraces(S) c fairtraces(L), in addit ion to showing indistinguishabili ty to the individual users.
Each round requires 2]E[ messages, one in each direction on each edge of the graph.
Then the total amount  of time required to simulate r rounds is at most r(c + d + 0 (e) )
It is impossible to reduce the time complexity of the SimpleSynch algorithm significantly, but it is possible to reduce the communication complexity.
Namely, if there is no message from Ui to neighbor Uj at round r in the underlying synchronous algorithm, then we may be able to avoid a round r message from process i to process j in the asynchronous algorithm.
Each process needs to determine that it has already received all the messages that its neighbors will ever send it for round r, before it can perform a user-receive output  for round r.
The messages of the SimpleSynch algorithm are used to help determine this, as well as to deliver the user's messages.
The basic strategy for reducing communication is to separate these two functions.
Thus, we decompose the implementation of LocSynch into several pieces: a "front end," FrontEnd for each node, communicating with the FrontEnds of neighboring nodes over special channels Di,j, and a "safe synchronizer," SafeSynch.
The job of each FrontEndi is to deliver the messages received from the local user Ui in user-sendi events.
At each particular round r, after receiving a user-send4, FrontEndi sorts all the outgoing messages for round r into "outboxes." Then it sends the contents of each nonempty outbox to the appropriate neighbor j using channel Di,j and waits to receive an acknowledgment on Dj,i.
When FrontEndi has received acknowledgments for all of its messages, it is said to be safe; this implies that all of i 's messages have been received by the appropriate neighboring FrontEnds.
Meanwhile, FrontEndi collects and acknowledges messages sent to it by its neighboring FrontEnds.
When is it permissible for FrontEndi to perform a user-receivei for round r, that is, to deliver to Ui all the round r messages it has collected from its neighbors? It can only do this when it knows that it already has received all the messages it will ever receive for round r.
It is therefore sufficient for FrontEndi to determine that all its neighboring FrontEnds are safe for round r, that is, that those neighbors know that all their messages for round r have been received by the appropriate FrontEnd automata.
Thus, the job of the safe synchronizer automaton SafeSynch is to tell each FrontEnd automaton when all its neighbors are safe.
To do this, SafeSynch has ok input actions, outputs of the FrontEnd automata,  by which the FrontEnd automata tell SafeSynch that they are safe.
SafeSynch sends goi to FrontEndi when it has received an ok from each of i 's neighbors, as well as from i itself.
After  Fron tEnd i  receives  goi, it can  p e r f o r m  a user-receivei.
In the res t  of this sect ion,  we desc r ibe  this  d e c o m p o s i t i o n  in more  detai l.
Each pair of front end automata, FrontEndi and FrontEndj, communicate by means of two channel automata, Did and Dj,i.
These are reliable send/receive channels from i to j and from j to i respectively, as defined in Section 14.1.2
The entire job of the safe synchronizer, SafeSynch, is to wait until it has received oks from all of the neighbors of FrontEndi and from FrontEncli itself before performing goi.
This is proved using a simulation relation from the SafeSynch system to the LocSynch system.
The strategy is the same as the one used in the proof of Lemma 16.3 for the SimpleSynch algorithm, using exactly the same simulation relation f ,  but the details are a little more complicated here because the algorithm is more complicated.
Again, the only interesting case in the simulation proof is the user-receive action, which here requires this invariant assertion.
A s s e r t i o n  16.3.1 In all reachable states of the SafeSynch system, the following holds.
A s s e r t i o n  16.3.2 In all reachable states of the SafeSynch system, the following holds.
It still remains to implement the SafeSynch automaton with a distributed algorithm.
We describe several ways of doing this in the following section.
It is also necessary to implement the Di,j channels using the actual send/receive channels Ci,j.
This is done by "multiplexing" the C~,j so that they implement not only the channels of the distributed implementation of SafeSynch but the Di,j's as well.
Recall that ok-seen is part of the state of the SafeSynch component.
In this section, we describe several implementations of SafeSynch by distributed algorithms.
There are two main implementations, Alpha and Beta, plus a way of combining them to obtain a hybrid implementation Gamma.
Recall that  the job of SafeSynch is, for each round and each i, to wait until it has received oks from all of the neighbors of FrontEnd4 and from FrontEndi itself, and then to perform goi.
The most straightforward implementation of SafeSynch is the Alpha synchronizer, which works as follows.
Alpha synchronizer: When any process Alphai receives an oki for any round r, it sends this information to all of its neighbors.
Correctness--both  safety and liveness--is easy to show, using simulation techniques to relate the Alpha system (Alpho4, FrontEnd, Di,j, and user automata) to the SafeSynch system.
This s t ra tegy  may not seem very modular ,  since the  same user, FrontEnd and Di,j aut o m a t a  appear  in bo th  systems.
However,  they  can be handled  in a tr ivial  way, let t ing the s imulat ion relat ion leave t h e m  unchanged.
An a l te rna t ive  approach  would involve formula t ing a more  abs t rac t  (and more general)  envi ronment  for the SafeSynch au toma ton.
This term accounts for a message in each direction on each edge at each round.
This does take pileups in the underlying channels into account.
Thus, both the communication complexity and the time complexity of Alpha are worse than the corresponding costs for SimpleSynch.
Like SimpleSynch, Alpha has a reasonable time complexity but high communication complexity.
In the following subsection, we give an alternative implementat ion of SafeSynch that  has better  communication complexity but at the cost of additional time complexity.
Synchronizer Beta assumes the existence of a rooted spanning tree of the entire graph G, preferably one of small height.
After the root has collected this information from all the processes, it broadcasts permission to perform go outputs,  also along the edges of the spanning tree.
The ideas are similar to those used for broadcast and convergecast in Section 15.3
Again, correctness is easy to show, using simulation techniques to relate the Beta system to the SafeSynch system.
By combining the ideas of synchronizers Alpha and Beta, we can get a hybrid algorithm, Gamma, that  (depending on the structure of the graph G) can simultaneously do as well as Alpha in terms of time and as well as Beta in terms of communication.
Algorithm Gamma assumes a spanning forest of G, where each tree in the forest is rooted.
We call each tree a cluster;, for each cluster C, we write nodes(C) for its set of nodes.
Constructing a suitable spanning forest is itself an interesting problem, but we do not describe how to do this here.
Gamma uses a version of Beta to synchronize the nodes within each cluster and a version of Alpha to synchronize among clusters.
In the extreme case where each cluster consists of a single node, Gamma is the same as Alpha, whereas in the case where there is only a single cluster containing all the nodes, Gamma is the same as Beta.
For intermediate cases, both the communication and time complexity measures of Gamma are intermediate between those of Alpha and Beta.
Consider a network graph G consisting of p complete graphs, each with k nodes.
The complete graphs are arranged in a line, with all the nodes of adjacent pairs of complete graphs connected to each other.
In the diagram, some edges arc not visible because they are "under" other edges.
Now consider the cluster decomposition for G depicted in Figure 16.5
Each cluster C of this decomposition is a tree for one of the knode complete graphs in G.
Algorithm Gamma uses a version of Beta to synchronize within each of the k-node trees, and a version of Alpha to synchronize among the p trees.
Since Gamma is a combination of two algorithms, we begin with a highlevel decomposition of SafeSynch into two kinds of automata,  which we call ClusterSynch and ForestSynch automata.
There is a ClusterSynchk automaton for each cluster Ck, and a single ForestSynch automaton.
For each cluster Ck and any round r, the automaton ClusterSynchk has two jobs.
First, after it receives oki inputs for all nodes i in Ck, it outputs a single cluster-okk to ForestSynch.
And second (in a completely independent task), after a cluster-gok input arrives from ForestSynch, ClusterSynchk produces a go~ for each node i in Ck.
This combination of jobs is a lot like the activities of Beta.
Input: ok(r)i, r e N + , i e nodes (Ck) cluster-go(r)k, r C N +
The Fores tSynch  a u t o m a t o n  is (up to renaming  of external  actions) a safe.
Then the code for ClusterSynchk implies that prior to the go(r)i, there must be a cluster-go(r)k.
Then the definition of ForestSynch implies that prior to the cluster-go(r)k, there must be a cluster-ok(r)k.
But this in turn implies that there is a previous ok(r)j, which suffices.
Since j E nbrsi, it must be that the two clusters Ck and Ce are neighbors in the cluster graph G ~ (by definition of neighboring clusters in the cluster graph)
As before, prior to the go(r)~, there must be a cluster-go(r)k.
Then the definition of ForestSynch implies that, prior to this, there must be a cluster-oke.
This implies as before that there is a previous ok(r)j.
To finish the description of synchronizer Gamma, we describe how to implement the ForestSynch and ClusterSynch automata with distributed algorithms.
ClusterSynchk can be implemented using a variant of synchronizer Beta on the rooted tree Ck.
That is, a convergecast is first carried out, collecting the oks at the root, which then performs a cluster-ok output.
The root also receives cluster-go, then broadcasts to all the nodes in nodes(Ck) to tell them to perform go.
These two activities could actually be formalized using two separate automata.
Any implementation of SafeSynch may, with suitable renaming, be used to implement ForestSynch; we choose synchronizer Alpha.
A technical complication is that we cannot run Alpha directly on the given distributed network, because Alpha is supposed to run on processes that correspond to the entities being synchronized (which in this case are whole clusters), using channels that correspond to edges between neighboring entities (here, clusters)
The given model only allows processes and channels corresponding to the nodes and edges of G.
However, it is not hard to implement the needed processes and channels: we run the process for any cluster at the cluster's root node and simulate direct communication between processes for neighboring clusters using a designated path between the root nodes in the two clusters.
Such a path must exist, because the clusters are connected and there exist nodes in the two clusters that are neighbors in G.
Again, some preprocessing is needed to determine these paths, but.
The cluster-ok and cluster-go actions are implemented as internal actions of the processes at the root nodes of the clusters.
For that graph and decomposition, we run the Alpha process for each cluster at the root (the top node, in Figure 16.5) of that cluster's tree.
Communication between the Alpha processes for neighboring clusters could be simulated using the direct edge in the underlying graph G (in Figure 16.4) between the roots of the clusters.
In the complete implementation Gamma, the process associated with each node i of G is, formally, a composition of three processes: FrontEndi, process i in the ClusterSynch implementation, and process i in the ForestSynch implementation.
Each channel Ci,j is used to implement three channels: Di,j and the channels from i to j in the ClusterSynch and ForestSynch implementations.
Defining the Gamma system to be the entire implementation, we can use simulation techniques to prove the following.
You may find it interesting to observe that the complete Gamma system has two natural decompositions.
One is logical, in terms of the functions (data communication, cluster synchronization, and forest synchronization) being performed.
The other is spatial, in terms of processes and channels in the complete implementation.
These two decompositions correspond to different orders of composing the primitive I /O automata that constitute the algorithm.
Since the composition operation is associative, we end up with the same algorithm either way we look at it.
Let h be the maximum height of any cluster tree and let e ~ be the total number of edges on all the paths used for communication among the roots.
The 0 (rn) is for the messages sent within all the cluster trees in the ClusterSynch implementation.
Again consider the network graph G and cluster decomposition of Example 16.4.1
For that graph and decomposition, we compare the costs of the three safe synchronizer implementations we have given.
Costs are per round, and we neglect the costs incurred by the users, FrontEnds, and Di,j's, which are the same for all three algorithms; we also neglect local processing time.
For Beta, we assume that the tree used has the minimum possible height, approximately p.
If p and k are approximately equal, then Gamma represents an order-of-magnitude improvement over each of Alpha and Beta.
The synchronizer algorithms given in the previous sections allow a fault-free asynchronous network to implement any non-fault-tolerant synchronous network algorithm.
In this section, we give a few examples of asynchronous algorithms constructed using synchronizers.
Recall that we are considering only undirected networks in this chapter.
In all the analyses in this section, we neglect local process step times.
Using synchronizers, synchronous ring leader-election algorithms such as LCR and HS can be run in an asynchronous ring.
But this is not interesting, because these algorithms already work in an asynchronous network, without the overhead introduced by synchronizers.
In an asynchronous network based on an arbitrary undirected graph with a known diameter, diarn, a synchronizer can be used to run the FloodMax synchronous leader-election algorithm.
A synchronizer can also be used to run the OptFloodMax synchronous leaderelection algorithm, which is like FloodMax except that nodes only send messages when they have new information to send.
If synchronizer Alpha is used, the advantage of the optimization is lost, since the synchronizer itself sends messages on all channels at all rounds.
However, if synchronizer Beta is used, then communication complexity is kept reasonably low (at the cost of additional time)
Using synchronizers, the SynchBFS algorithm can be run in an asynchronous network.
Some improvement in the time complexity is possible using Gamma, at the expense of extra communication complexity.
There is a technicality: it is not obvious how the BFS algorithms obtained using the synchronizers are supposed to terminate.
As described, the implementation continues to simulate rounds forever, thus generating an infinite number of messages.
If the processes knew diam, then they could simply stop after simulating diam rounds, but we have assumed here that the processes do not know diam.
An ad hoc solution to this problem is to have each user automaton that determines its parent perform only one additional round to notify its neighbors and then halt.
For the problem of finding shortest paths from a designated source, the use of a synchronizer is a big win.
Recall that the AsynchBellmanFord algorithm has both message and time complexities that are exponential in the number of nodes.
We can run the synchronous BellrnanFord algorithm using, say, synchronizer Alpha, obtaining an algorithm that sends O ( IEI) messages and uses O (nd) time to simulate the required n rounds.
Compare this with the complexity of AsynchBcastAck in Section 15.3
Synchronizers can also be used with randomized synchronous algorithms such as LubyMIS.
An informal paraphrase of the results about synchronizers is as follows:
In particular, by using synchronizer Alpha or SimpleSynch, it is possible not to increase the time cost at all.
In this section, we show a limitation on the synchronizer approach, by giving a lower bound on the time required for an asynchronous network algorithm to solve a particular problem.
Since there is a very fast synchronous algorithm to solve the same problem, this means (informally speaking) that.
Not every synchronous algorithm can be transformed to a corresponding asynchronous algorithm with a similar time complexity.
It turns out that the reason for the difference is the locality of the correctness condition guaranteed by the synchronizers.
We return to this point after the lower bound proof.
The result of this section is the only lower bound in this book for the time complexity of a problem in an asynchronous distributed system.
The problem we consider is called the "session problem." Let G - (If, E) be a graph, with diam its diameter as usual.
The system's interface with its environment includes flashi output actions, one for each node i of G; flash4 is an output of the process automaton at node i.
We treat the flash actions as abstract actions, but you might want to think of them as signals that the corresponding processes have completed some computation task.
Define a session to be any sequence of flash events containing at least one flashi for every i.
For any nonnegative integer k, the k-session problem requires simply that the algorithm should perform at least k disjoint sessions, in any fair execution.
The k-session problem was originally inspired by a matrix computation problem for the asynchronous shared memory model.
Consider a collection of asynchronous parallel processes performing a coordinated calculation of the transitive closure of an rn x rn Boolean matrix.
The matrix starts out in shared memory, and all the partial results and final outputs are written to shared memory.
Each process Pi,j,k is responsible simply for writing 1 in location (i, j) of the output matrix in case it ever sees ls in both locations (i, k) and (k, j)
Thus, each goes through a simple loop, reading locations (i, k ) a n d  (k, j),  then (possibly)wri t ing (i, j)
Each individual read or write operation on shared memory is represented abstractly as a.
Basic properties of matrices then imply that the calculation is.
It does not matter if the processes do excess reading and wri t ing--as  long as enough interleaving occurs, the correct output  will be produced.
A simpler version of the problem for which a similar lower bound could be proved is one in which each process is required to perform ezactly one flash in each session.
The version of the problem that we use is less constrained, so it leads to a stronger lower bound result.
It is trivial to solve the k-session problem in the synchronous network setting.
All we need is for each process i to perform a single flash4 output at each of k rounds.
In the asynchronous network setting, we model the processes as I / O  au tomata.
Section 8.6 that  a fair execution with times associated with all events, subject to.
Next, we define the time measure T(A) for a lgor i thm A.
We use a supremum instead of a max imum here because.
That  is, T(A) is the supremum of the times at which a flash occurs in any t imed execution of A.
In order to compare this result with the simple upper  bound of k rounds for.
This proves that  the inherent overhead due to asynchrony, for the session problem, is a factor of diam.
We assume without  loss of generality that  all actions of A are external.
Define a t imed execution of A to be slow if all the message deliveries take the max imum time d.
We now construct  a fair t race fl of A; fl will be an ordinary unt imed fair t r ace - -w i thou t  times associated with its events.
We will show that fl contains fewer than k sessions, which will contradict  the correctness of A.
All the reordering that  we do in construct ing fl will preserve the impor tan t dependencies among actions in c~, in part icular,  the dependency of a receive event on the corresponding send event and the (possible) dependency of any event of any process i on any prior event of the same process.
Theorem 14.1 will be used to show that  fl is in fact a fair t race of A.
The following claim describes the propert ies we require of our reordered sequences fir.
Fix j0 and j l  to be any two nodes of G whose distance is equal to diam, and define.
We first show how to complete the proof of the theorem using Claim 16.12
Since the only reordering of events is for individual fl~ sequences and since that.
This implies that each session must  contain events on both sides of some 7~-5~ boundary.
Thus,  fl violates the correctness guarantees  of A, which yields a contradiction.
This is so because c~ is a slow execution, so the time for a message to.
Timing information is used in the proof to deduce that certain.
Loca l  n o t i o n  of  c o r r e c t n e s s.
Theorem 16.11 looks almost like a contradiction to some of the synchronizer resul ts- - those that give transformations from synchronous to asynchronous algorithms with only constant time overhead.
The difference is that the synchronizers only guarantee a "local" notion of correctness.
Rather than preserving the behavior of the collection of users (i.e., synchronous processes) as a whole, they only preserve the behavior of each user separately, permitt ing reordering of the events at different users.
For many distr ibuted applications, the order of events at different users does not matter; for instance, typical data processing and financial applications can.
However, for applications in which there is significant communication among the users outside of the distr ibuted system, the order of events at different users may be important.
Awerbuch [29] introduced the general notion of a synchronizer, as well as the decomposition of the synchronizer problem into a data communication part and a safe synchronizer.
Awerbuch's paper also defines the Alpha, Beta and Gamma synchronizers and contains algorithms for obtaining good cluster decompositions for Gamma.
The lower bound proof is due to Arjomandi, Fischer, and Lynch [14], who presented the result for a shared memory model.
The presentation in this chapter uses some simplifications by Attiya and Mavronicolas [17]
Attiya and Mavronicolas [17] also extended the lower bound result to the setting of partially synchronous systems.
Fill in the details of the proof of Lemma 16.1
Specifically, Claim 16.2 needs a proof, as does the claim that it is possible to reorder the events of.
Let L and G denote the LocSynch and GlobSynch systems, respectively, modified slightly so that the external actions are exactly all the actions of the user automata.
That is, the internal actions of the users are reclassified as outputs.
Prove, by exhibiting a counterexample execution, that it is not the case that fairtraces(L) C_ fairtraces(G)
Fill in all the details of the proof and complexity analysis for the SimpleSynch system.
Don't  forget that the assumed bound of d only refers to the delivery of the oldest message currently in any channel.
Let S and G denote the SimpleSynch and GlobSynch systems, respectively, modified so that the external actions are exactly all the actions of the user automata.
That is, the internal actions of the users are reclassified as outputs, and the send and receive actions are "hidden"-- tha t  is, reclassified as internal.
Fill in the details in the proof of Lemma 16.5
Use a simulation relation from the Alpha system to the SafeSynch system.
Use a simulation relation from the Beta system to the SafeSynch system.
True or false? Let B and G denote the Beta and GlobSynch systems, respectively, again modified so that the actions that are classified as external are exactly all the actions of the user automata.
You may assume the nodes have UIDs, but there is no distinguished node.
Also, produce the distinguished paths for communication between the roots of neighboring clusters.
You may assume the nodes have UIDs, but there is no distinguished node.
Your algorithm should yield trees of small height, as well as short communication paths.
Consider a partition Pk into k 2 equal-sized clusters, obtained by dividing each side into k equal intervals.
A programmer at the Flaky Computer Corporation who has substantial experience with fault-tolerant algorithms has just had a brilliant idea for a synchronizer to be used in fault-tolerant asynchronous network programming.
He admits that his idea only works for a completely connected network G but still thinks it is a big win.
His synchronizer is like GlobSynch, except that at each round r, it waits to obtain user-sends for round r from at least n - f  of the processes (including i), rather than from all n processes, before performing a user-receivei event for round r.
Show his superiors that his algorithm is incorrect before they install it in a fault-tolerant aircraft-control system.
Hint: You can consider a correct synchronous consensus algorithm such as FloodSet in conjunction with the proposed synchronizer.
Prove that the termination strategy described for SynchBFS with a synchronizer works correctly.
State and prove a result giving the important properties guaranteed by the asynchronous algorithm obtained by running LubyMIS with your favorite synchronizer.
Prove that O (log n) sessions suffice to solve the Boolean matrix, transitive closure problem described in Example 16.6.1
Obtain the best upper bound you can for the time complexity of an asynchronous solution to the k-session problem.
Generalize your algorithm to the asynchronous implementation of arbitrary synchronous algorithms.
Redo Exercise 15.40, this time using some of the algorithm decomposition ideas presented in this chapter.
For example, you should give abstract automata to represent the behavior required of the MST algorithm and of the algorithm that uses the MST to elect a leader.
In the previous chapter, we described synchronizers, which comprise one method for simplifying the programming of asynchronous networks.
In this chapter, we describe a second strategy for simplifying the programming of asynchronous networks: using them to simulate asynchronous shared memory systems.
Many other asynchronous shared memory algorithms can also be adapted to run in asynchronous networks, including practical algorithms for scientific programming and financial databases.
The premise underlying this strategy is that the asynchronous shared memory model is easier to program than the asynchronous network model.
More generally, this chapter deals with relationships between the asynchronous shared memory model and the asynchronous network model.
It turns out that there are strong transformation results in both directions, some of which preserve even some fault-tolerance properties.
This leads to the conclusion that (except for differences in efficiency) the two models are pretty much the same.
There are other consequences of these transformation results besides just the provision of a simpler programming model for asynchronous networks.
For example, a fault-tolerant transformation from the network model to the shared memory model implies that certain impossibility results for the asynchronous shared memory model yield corresponding impossibility results for the asynchronous network model.
A different kind of transformation from the asynchronous shared memory.
That  transformation rests on the establ ishment  of a notion of logical t ime in an asynchronous network.
In this section, we describe several ways of t ransforming asynchronous shared.
As for the user au tomata in Chapters  10-13, we assume that  the external actions of each Ui are exactly those actions by which it interacts with A.
It turns  out that we need a technical restr ict ion on A in order for our transformations to work correctly.
This technical restr ict ion is the same one we used.
That  is, consider A in combination with any collection of user.
This is supposed to indicate whose turn  it is to take the next step, after c~
Moreover, if a is a fair execution and if every i for which stopi appears in c~ is in I, then a '  is also a fair execution.
If B is a n / - s i m u l a t i o n  of A for every I with.
You might recognize these conditions as being similar to the ones that are.
This connection will be exploited in this chapter, in proving that certain network systems simulate shared memory systems.
As described in Section 14.1.1, in system B, each stopi event permanently disables all the tasks of process Pi.
However, a stop event has no effect on the channels.
In the absence of failures, there are simple strategies that work.
The simplest simulation strategy involves just  dist r ibuting the shared variables of A arbi trar i ly among the processes of B, with each shared variable located at a single process.
This strategy works for shared variables of arbi t rary  types.
Each shared variable x of A is assumed to be "owned" by a single process.
The job of process Pi is twofold: to simulate the corresponding process i of A and to manage the shared variables that it owns.
For each i, process Pi has the same actions at the user interface as does process i of A.
Pi's steps simulate those of process i directly, with the following exceptions: When process i of A performs an access to a shared variable x, Pi instead sends a message containing the invocation to the process Pj that owns variable x.
When a response arrives, Pi resumes simulating process i of A as  u s u a l.
The response is sent in a response message to the.
We can express each process Pi as the composition of an I /O  automaton Qi, which is responsible for simulating process i of A, and an I /O  automaton Rx,i for each shared variable x.
For Qi, we simply use automaton Pi of the Trans(A) algorithm of Section 13.1.4
More precisely, we assume that the outputs of automaton Qi include actions of the form ax,i, where a is an invocation that process i of A uses on shared variable x, and that the inputs include actions of the form bx,i, where b is a response to process i from shared variable x.
For convenience, we assume that for any particular shared variable x, all the automata Rx,i have reliable FIFO send/receive channels by which they communicate with each other.
As in Exercise 14.6, the channels for the individual x can all be simulated by the given FIFO reliable channels.
It will turn out that, for each x, the composition.
Figure 17.1 shows the architecture for SimpleSh VarSim, for the special case of two processes and two shared variables.
This handling is not particularly interesting here, because we do not make any claims about the behavior of this algorithm in the presence of faults.
For the purpose of disambiguation, we subscript channel actions by the name of the variable as well as the nodes at both ends.
R~,i, Pi t he  o w n e r  of  x:
A r c h i t e c t u r e  for SimpleShVarSim-- two p r o c e s s e s  and  two  s h a r e d  var i ables.
States: resp-buffer, a set of responses  b, ini t ia l ly  e m p t y send-buffer, a F I F O  queue of invocat ions ,  ini t ia l ly  e m p t y stopped, a Boolean,  ini t ia l ly  false.
We do not claim any fault-tolerance properties for B~, however.
With these atomic objects Bx, system B is exactly the system Trans(A)
The SimpleSh VarSim algorithm permits the variables to be owned by arbitrary processes.
As a general guideline, however, the best performance is obtained by locating variables at the processes that access them most frequently.
Of course, in this case all read accesses by processes other than the writer are slow, since they involve message exchanges over the network.
If write accesses are frequent relative to read accesses, this arrangement works well, but it may not be the best if writes are relatively rare.
The SimpleSh VarSim algorithm does not have any interesting fault-tolerance properties.
For example, if a stopi occurs, then all processes are thereafter prevented from accessing any of the variables owned by process P~
The SimpleSh VarSim algorithm could be modified to remove such loops, by instead having the owner of the variable notify the busy-waiting process when the value of the variable changes (or when the awaited condition becomes true)
It is sometimes useful to allow several processes to maintain copies of the same shared variable x.
Consider, for example, the case where x is a read/wri te  shared variable for which read operations are frequent but write operations are rare.
Then, if many processes maintain "cached" copies of x, many reads can be performed locally and therefore at low cost.
The problem, however, is that write operations become more expensive than before, since they must be performed on all copies of x.
This means that messages have to be sent from a writer process to all the processes that maintain copies of x.
This could lead them to apply the writes to their copies in different orders, yielding inconsistent results for subsequent reads.
Even in the case where x is a single-writer register, anomalies can occur.
Thus, a more clever protocol is required to manage the writes.
For instance, a writer could work in two phases: "locking" and modifying all the copies of x in the first phase, then releasing the locks in the second.
A read operation would be delayed while the local copy is locked.
In this case, some care must be taken that all invoked operations eventually get performed.
This type of algorithm is an example of a concurrency control algorithm.
Specifically, the algorithm we just sketched is a read/write locking algorithm implementing an atomic transaction that writes to all the copies of x.
This means that it appears to the processes performing operations on x that writes to all copies are performed instantaneously, at some "serialization point" within the interval of the containing write operation.
There are many other kinds of concurrency control protocols, including locking algorithms for other types of shared variables besides read/wri te  variables, timestamp-based algorithms, hybrid algorithms that combine the use of locking and timestamps, and optimistic algorithms.
We do not present these here, but instead refer you to the book Atomic Transactions, by Lynch, Merritt, Weihl, and Fekete for a complete presentation (in the same style as this book)
A popular multi-copy algorithm for read/wri te  shared variables is the Majority Voting algorithm.
The heart of this algorithm is the implementation, for each read/wri te  shared variable x, of a read/wri te  atomic object for x.
This implementation is in turn based on an underlying implementation of atomic transactions.
A process that wants either to read or to write x performs an atomic transaction involving some of the copies of x.
The atomic transaction consists of a series of operations that appear to be performed instantaneously at some "serialization point" during the execution of the transaction.
An incomplete operation might or might not have a serialization point.
The transactions can be implemented using two-phase locking, or t imestampbased, hybrid, or optimistic concurrency control methods, augmented by some priority mechanism to ensure that (if no process fails) each transaction eventually completes.
In order for process Pi to perform a read of x, it reads at least a majority of the copies of x.
Among these, it chooses one with the largest tag and returns the associated value of x.
All these steps are part of the same atomic transaction and so are executed "as if" instantaneously.
In order for process Pi to perform a write(v) to x, it first performs an embedded-read, which is exactly like a read as described just above.
From the result of this embedded-read, Pi determines the largest tag, t.
Then it writes (v, t + 1) to at least a majority of the copies of x.
All these steps those of the embedded-read and those that write the copies--are part of the same atomic transaction and so are executed "as if" instantaneously.
We verify the conditions in the definition of an atomic object, as given in Section 13.1.1
We choose the subset (I) of incomplete operations to be exactly those that are assigned serialization points in the underlying transaction implementation and adopt the responses for the operations in (I) and the serialization points from the transaction implementation.
To see that the shrinking property holds, we need to know that each read obtains the value written by the write serialized just before it, if there is one; if not, it obtains the initial value v0
Each read or embedded-read obtains the largest tag that has been written by a write operation serialized before it (or 0 if there are none), together with the accompanying value.
These facts are true because each read or embedded-read reads a majority of the copies, the largest tag has been written to a majority of the copies, and all majorities intersect.
Now, if the shared memory system A uses read/wri te  shared variables, we define the Majority Voting algorithm based on A to consist of the same Qi components that are used in SimpleSh VarSim, together with Majority VotingObjects for all the read/wri te  shared variables.
Although the Majority VotingObject algorithm allows flexibility in the choice of which major i ty  is read or written, it does not, in general, provide a fault-tolerant implementat ion of an atomic object for x.
This is because the s tandard t ransact ion implementations are not fault-tolerant.
For example, in a read/wr i te  locking algorithm, a process performing a read t ransact ion might send out messages to read a majori ty  of the copies, causing a majori ty  of the copies to become locked.
This would prevent any later write t ransact ion from ever obtaining the locks it requires.
In practice, this problem can be handled by using timeouts to detect process failures (which we cannot do in the asynchronous network model) and /or weakening the resiliency requirements.
As we noted, the strategies described in Section 17.1.2 do not have any interesting fault-tolerance properties.
In this section, we present the ABD algorithm of Attiya, Bar-Noy, and Dolev, which works in the presence of a limited number f of process stopping failures; the network is assumed to be reliable.
We assume that n, the total number of processes, is strictly greater than 2f,  that is, that a majority of the processes do not fail.
We only consider the case of singlewri ter /mul t i - reader  read/wr i te  shared memory.
The heart of the ABD algorithm is the implementation, for each read/wr i te shared variable x, of a read/wr i te  atomic object guaranteeing f-failure termination.
The algorithm uses ideas from the Majority Voting algorithm and from the VitanyiAwerbuch algorithm of Section 13.4.3
The main idea is that the result of each write is stored at a major i ty  of the nodes in the network, before the write completes.
A B D O b j e c t  algorithm (informal):
Each of the n processes maintains a copy of x, initially the initial value of x, together with a nonnegative integer tag, initially O.
When the unique writer process wants to perform a write(v) on x, it first lets t be the smallest tag that it has not yet assigned to any write.
Then it sets its local copy of x and local tag to v and t, respectively, and sends ( "write", v, t) messages to all the other processes.
A process receiving such a message updates its copy of x and its tag in the same way, provided that t is greater than its current tag; in any case, it sends an acknowledgment.
When any process Pi wants to perform a read of x, it sends read messages to all the other processes and also reads its own value of x and its own tag.
A process receiving such a message responds with its latest value of x and tag.
When Pi has learned the x and tag values of a major i ty  of the processes, it prepares  to re turn  the value v of x associated with the.
But before doing this, Pi propagates  (v, t) to a major i ty  of the processes: it updates  its own value of x and tag and also sends a second round of messages to all the other processes (except for the writer)
A process receiving such a message updates  its copy of x and its tag accordingly, provided that  t is greater  than its current  tag; in any case, it sends an acknowledgment  to Pi.
When Pi knows (via the acknowledgments and its knowledge of its own local behavior) that  a major i ty  of the processes have their tag values at least equal to t, it re turns  v.
For simplicity, we do not include explicit mention of stop actions, which we assume are handled as for SimpleSh VarSim.
Also, we omit the explicit subscript  x on the various actions.
The code is a lready long enough without  these details.
We assume that  V is the domain of values and v0 the initial value for x.
Note that, in contrast to the Majority Voting and VitanyiAwerbuch algorithms, the choice of a new tag is simple in the ABDObject algorithm, because there is only one writer.
In this code, the read-tag is used to keep track of which acknowledgments belong to the current operation.
The response-val is used to remember the value to be returned while it is being propagated.
Note that it is not necessary to propagate the response value to the writer, since the writer must already have the latest information.
So, as usual, atomicity is the key property to show.
Define II to be the set of operations occurring in c~
First, order the write operations in the order in which they are performed, that is, in the order of their tags.
Then order each read right after the write whose tag it obtains, if any, otherwise prior to all the write operations.
If a write 7r with tag = t completes before a read r is invoked, then r obtains a tag that is at least as large as t.
This is because 7o's tag is received by a majority of the copies, r reads a majority of the copies, and all majorities intersect.
This is by a similar argument, because 7r propagates its information to a majority of the copies.
Using these two properties, it is not hard to show that the four conditions required for Lemma 13.16 hold, which implies the atomicity condition.
It is also easy to modify the algorithm so that read operations are also permitted on the single write port.
The complete ABD algorithm based on A is then constructed by using the processes of Trans(A), as we did for SimpleSh VarSim and Majority Voting, plus an atomic object for each shared variable x.
Each atomic object is the appropriately modified version of the ABDObject.
Then the ABD algorithm based on A is an f-simulation of A.
It is possible to modify the algorithm so that it uses bounded tags instead.
For example, the atomic snapshot and atomic multi-writer register algorithms in Chapter 13 can be transformed using ABD into algorithms implementing the same objects in the asynchronous send/ receive network model.
This is because the failure of this many processes makes the other processes permanently unable to secure the majorities that they need to complete their work.
The key result is the following, giving a limitation on the fault-tolerance of read/wri te  atomic object implementations in asynchronous networks.
Then there is no algorithm in the asynchronous broadcast model (with a reliable broadcast channel) that implements a read/write atomic object with m writers and p readers, guaranteeing f-failure termination.
Suppose for the sake of contradiction that there is such an algorithm, say A.
As usual for such impossibility proofs, we assume that the users are the most nondeterministic possible.
Consider a fair execution Ctl of the system (A plus users) that contains an invocation write(v)l on port 1, where v =/= vo, and no other invocations.
By f-failure termination, the write must eventually terminate with a matching ackl.
Let a~ be the prefix of Ct I ending with the ackl.
Now consider a second fair execution a2 containing an invocation readn on port n and no other invocations.
Furthermore, suppose that stop events occur on exactly the ports in G1, at the start  of the execution.
Again by f-failure termination, the read must eventually terminate, and the response value must be v0
Now we construct a finite execution a that does not satisfy the atomicity property, thus yielding a contradiction.
In a, the ackl response event precedes the rea~ invocation event.
This violates the atomicity condition, which says that the read is supposed to return v, the value written by the write, rather than the initial value v0
It is easy to see that c~ satisfies all the required properties.
The argument for this is similar to the proof of Corollary 13.9
Now we describe transformations in the opposite direction, from the asynchronous network model to the shared memory model.
These transformations tolerate process stopping failures: a shared memory system with at most f process failures can simulate a network with at most f process failures (and reliable communication)
Moreover, the constructions are much simpler than the transformations in the opposite direction.
The reason why these constructions are simpler and yield stronger results is that the asynchronous shared memory model is, in a sense, more powerful than the asynchronous network model.
The extra power comes from the availability of reliable shared memory.
It is possible to use these transformations to run asynchronous network algorithms in asynchronous shared memory systems.
But this is probably not a very interesting thing to do, because the shared memory model is easier to program.
A more important  use is to allow impossibility results for the asynchronous shared memory model to be carried over to the asynchronous network model.
For example, the impossibility of consensus in the presence of failures, proved in Theorem 12.8 for the shared memory model, can be extended to the network model using these transformations.
As before, each stopi event immediately  disables all tasks of Pi but has no effect on the channels.
The general problem (including fault- tolerance requirements)  is to produce a shared memory  system B with n processes, using s ingle-wri ter /s ingle-reader shared registers, that  "simulates" A.
The sense in which it should simulate A is exactly the same as for the t ransformat ion in the reverse direction.
For any execution a of B with any set of users Ui, there should be an execution ~ of A with the same users such that  the following conditions hold:
I f /3  simulates A in this way, for a par t icular I,  then we say that  B is an I-simulation of A.
For each directed edge (i, j )  in the underlying directed graph G , / 3  includes a s ingle-wri ter /s ingle-reader  r ead /wr i t e  shared variable x(i, j), writable by process i and readable by process j.
Process i only adds messages to the queue; no messages are ever removed.
Simulations of user interface steps and internal steps of Pi are direct.
In order to simulate a send(m)i,j action of Pi, process i of A adds the message m to the end of the queue in the variable x(i, j)
It can do this using only a write operat ion by keeping a duplicate local copy of the queue.
Also, from time to time, process i checks all its "incoming" variables x(j, i) in order to determine if there are any new messages that  have been placed there since the last time it checked.
If so, process i handles those messages in the same way that  Pi handles them.
I n  t h a t  c o d e  f r a g m e n t ,  t h e  s e q u e n c e  M c o n t a i n s  t h e  n e w  m e s s a g e s.
A c t i o n s  of  i: As for P~, except: Input:
Then it should not be hard to see that the simulation is correct.
A similar construction to SimpleSRSim can be used to simulate an asynchronous broadcast  system having a reliable broadcast  channel.
As before, process i of B simulates process Pi of A, with direct simulations of user interface steps and internal steps of Pi.
In order to simulate a bcast(m)i action of P/, process i of A adds the message m to the end of the queue in the variable x(i)
Also, from time to time, process i checks all variables x(j)  (including x(i)) in order to determine if there are any new messages.
If so, process i handles those messages in the same way that P/ handles them.
Theorem 17.8 can be used to prove the impossibility of solving the fundamental agreement problem of Chapter 12 in an asynchronous network, even if the network guarantees reliable broadcast, there is guaranteed to be no more than one process failure, and the only type of failure is stopping! This impossibility result represents a fundamental limitation on the computing capabilities of asynchronous networks.
This result should be contrasted with the results in Chapter 6 for the stopping agreement problem in the synchronous network model.
In that setting, the problem is solvable, although it has a nontrivial inherent time cost that depends on the number of tolerated failures.
The proof of Theorem 6.33, the lower bound on the time, rests on the possibility that a process might stop in the middle of a broadcast.
In contrast, in the asynchronous model, the impossibility result still holds even without the possibility of partial broadcasts.
We use the problem statement given in Section 12.1 for the agreement problem with l-failure termination.
Note that that statement can be formulated in terms of trace properties and so makes sense for asynchronous network systems as well as for shared memory systems.
Suppose for the purpose of obtaining a contradiction that there is such an algorithm A.
Then Theorem 17.8 yields an algorithm B in the single-writer/ multi-reader shared memory model that is an n-simulation of A.
The definition of an n-simulation implies that B is a solution to the agreement problem and that it guarantees 1-failure termination.
But this contradicts Theorem 12.8, the impossibility of solving the agreement problem in the read/write shared memory model.
Their paper also includes an algorithm that uses bounded tags, based on the ideas of Israeli and Li [162], plus additional applications for the ABD simulation.
They proved the result directly, in terms of the network model, rather than via a transformation as we have presented.
Prove the claim within the proof sketch for Theorem 17.1--that for each x, the composition of all the automata Rx,i plus the channels between them (with hiding of send and receive actions) constitute an atomic object Bx of the appropriate type and interface.
State and prove a result relating the time complexity of the system B obtained by applying the SimpleSh VarSim algorithm to a shared memory system A, to the time complexity of the original system A.
Let B be an asynchronous network algorithm obtained by applying SimpleSh VarSim to the PetersonNP algorithm of Section 10.5.2
Obtain the best upper bound you can on the time complexity of B, more specifically, on the time from any tryi event to the corresponding criti event.
How does this compare to the general upper bound obtained for Exercise 17.2?
Research Question: State and prove a result describing what is guaranteed when the SimpleSh VarSim transformation is applied to a randomized shared memory system such as the LehmannRabin algorithm in Section 11.4
This outline appears a couple of paragraphs before the description of the Majority VotingObject algorithm.
Each reader of a shared variable x should keep a local copy of x and read it (if it is available)
The writer should perform its writes to individual copies using a two-phase locking protocol.
Consider the Bakery mutual exclusion algorithm of Section 10.7, transformed to run in asynchronous networks in two different ways:
Compare the time and communication complexity of the two resulting algorithms.
Generalize the Majority VotingObject algorithm to allow each read operation to access a read quorum of copies instead of a majority of copies, and each write operation to access a write quorum of copies.
Is the "propagation phase" of the reader code in the ABDObject implementation necessary? Either argue that the algorithm works without it or exhibit a counterexample.
Modify the ABDObject algorithm so that it uses bounded instead of unbounded tags.
Hint: It is not enough just to use the integers mod k for some fixed k; a finite data type D with more interesting structure is needed.
The writer needs to choose successively "larger" tags, according to data type D, knowing that any old tags that are held by slow processes can be detected by those processes to be "smaller" than the newer tags.
So when the writer chooses a new tag, it needs to take account of all the tags that could possibly be held by any process.
In order for the writer to keep track of this set, whenever any process modifies its local tag, it first ensures that a majority of the processes know that it is adopting the new tag.
Then the writer can always determine the possible tags at all processes, simply by querying a majority of the processes for this information.
In this chapter we present the third of our major methods for simplifying the job of programming an asynchronous network: the introduction of a notion of logical time.
In our asynchronous network model, there is no built-in notion of real time.
It is, however, possible to impose a notion of logical time by means of special protocols.
Logical time can sometimes be used in place of real time, in cases where the users of the system do not care about the relative order of events that occur at different network locations.
The basic idea is for every event of an execution of an asynchronous network system A to be assigned a "logical time," which is an element of some fixed totally ordered set T.
Typically, this set T is either the nonnegative integers or the nonnegative reals (perhaps with other types of values such as process indices as tiebreakers)
These logical times need not have any particular relationship to real time.
However, the logical times of different events are required to respect all the possible dependencies among the events within system A, as described in Section 14.1.4
Under these assumptions, we will be able to prove that the logical-time assignment "looks like" a real-time assignment to the processes.
We consider logical time for send/receive systems and broadcast  systems separately.
We assume throughout the chapter that the channels are the particular.
We consider an asynchronous send/receive network system with universal reliable FIFO send/receive channels.
We assume that the underlying network graph G is an arbi t rary strongly connected directed graph.
Recall that the events of such a system are of the following types: user interface events by which process automata  communicate with the system's users, send and receive events by which process automata interact with channel automata,  and internal events of process automata.
We do not need to consider internal events for channels, because the particular universal channels we are using do not have any internal events.
Let c~ be an execution of an asynchronous send/receive network system A.
The logical times of events at each process are strictly increasing, according to their order of occurrence in c~
The logical time of any send event is strictly smaller than that of the corresponding receive event.
For any particular value t E T, there are only finitely many events that get assigned logical times smaller than t.
However, we allow some events at different processes to have their logical times ordered in the opposite order from their order in c~
We claim that any logical-time assignment "looks like" a real-time assignment to every process in the network.
Then there is another  fa i r  execution a ~ of  A such that.
However, it permits events at different processes to be reordered.
Let 7 be the sequence obtained by reordering the events of a in the.
In applying Corollary 14.2, we regard (i.e., reclassify) all process actions as external.
Consider a send/receive system A based on a three-node complete undirected graph.
In this send/receive diagram, each process's execution is represented by a vertical line, with time proceeding downward.
The dots indicate send and receive events, and each slanted line joins the send event to the receive event for a single message.
Here we do not depict other events, that is, internal events of processes and events by.
These could be represented by other dots on the vertical lines.
Figure 18.2 shows a logical-time assignment ltime for a (assuming that a contains only send and receive events)
However, it is consistent with all possible dependencies among events in a.
Note that the order of events at each process is the same in a and a ~
Notice the close parallel between the ideas of this section and those used in Section 16.2 to relate local and global synchronizers.
In each case, a dependency order is defined on events in an execution, capturing all possible dependencies among events.
Then, in each case, the events of the execution are reordered, preserving all dependencies but realigning them according to a global notion of time.
The definitions of a local synchronizer and of logical time are used to show that this can be done.
In each case, the conclusion is that the reordered execution is locally indistinguishable from the original execution.
Thus, it looks to all the participants in the original execution as if they are operating in global synchrony.
We can also define logical time for reliable asynchronous broadcast systems with universal reliable broadcast channels.
In this case, the events are user-interface events, bcast and receive events, and internal events of processes.
Let a be an execution of an asynchronous broadcast system.
A logical-time assignment for a is defined to be an assignment of a value in T to every event in a, in such a way as to satisfy the same properties as for send/receive systems, except that Property 3 now says:
The logical time of any bcast event is strictly smaller than that of each corresponding receive event.
Then  there is ano ther  fa i r  execut ion c~ I of  A such that.
In the previous section, we defined the notion of logical time for asynchronous send/receive and broadcast systems.
Now we give two algorithms for generating logical times for the events of a given asynchronous send/receive network algorithm A.
Each of these algorithms is really an algorithm transformation that "transforms" the given algorithm A into a new asynchronous send/receive algorithm L(A) with the same underlying network digraph.
The transformation works process by process, defining L(A)i (process i of the L(A) system) in terms of A~ (process i of the A system)
The processes in L(A) cooperate to somehow "simulate" a fair execution of A, where each L(A)i simulates the corresponding Ai.
Whenever a process of L(A) simulates a step of A, it also "generates" a logical-time value.
The fact that we have included quotes around some terms (i.e., "transform," "simulate," "generate") indicates that we do not have a single clear meaning for these terms but will interpret them slightly differently in different situations.
Both the transformations we describe can be modified for use in broadcast systems.
The following is a simple algorithm transformation for producing logical times for an execution of a given asynchronous send/receive network algorithm A.
We call it the LamportTime transformation after Lamport ,  its discoverer.
It is based on maintaining local clocks, advancing them when messages are received in order to keep them adequately synchronized.
The logical-time domain T is the set of pairs (c, i), where c is a nonnegative integer and i is a process index; the ordering of pairs is lexicographic.
Process LamportTime(A)i maintains the state of process Ai, plus a local variable clock that takes on nonnegative integer values, initially O.
The clock variable gets increased by at least 1 at every event (including user interface events, send and receive events, and internal events) that occurs at process i.
The logical time of any event is defined to be the value of the clock variable immediately after the event, paired with the process index i as a tiebreaker.
Whenever process i performs a send event, it first increments its clock variable to get the clock value v for the send event, then it attaches value v to the message being sent, as a timestamp.
When process i performs a receive event, it increases its clock variable to be not only strictly larger than its previous value, but also strictly larger than the t imestamp of the message.
The new clock value gets  assigned to the receive event.
More precisely, the code for process i in the LamportTime(A) algorithm is as follows.
As for Ai, except that  send(m)i and receive(m)i actions are replaced, respectively, with send(m, c)i and receive(m, c)i actions, where c C IN.
Trans i t i ons : As for Ai, with the following modifications: Input action ~ receive.
Property 3 follows from the handling of the receive events.
In terms of the informal conditions mentioned at the beginning of this section, the "transformation" of each Ai that produces LamportTime(A)i simply adds the new clock component, plus statements to maintain it.
It does not, for example, add entirely new types of actions or delay events.
The "simulation" is step by step, directly producing a fair execution of A.
When process LarnportTime(A)i simulates a step of Ai, the logical-time value that is "generated" is just the pair (c, i), where c is the value of clock after the step.
It is easy to modify the LamportTime transformation to work in asynchronous broadcast systems.
Now we give an alternative algorithm transformation for producing logical times in an execution of a send/receive network algorithm A.
Like LamportTime, Welch Time is based on maintaining local clocks, only this time the clocks are not advanced in response to message receipts; rather, messages that arrive "too soon" are delayed.
The logical time domain T is the set of triples (c, i, k), where c is a nonnegative real, i is a process index, and k C N+; the ordering of triples is lexicographic.
Welch Time t r a n s f o r m a t i o n : Each process Welch Time(A)i maintains a local variable clock, with nonnegative real values.
We assume that  the clock values of process i are maintained by a separate task, which ensures that  the values of the clock are monotonically nondecreasing and unbounded.
The logical time of any event is defined to be the value of clock when the event occurs, with the process index as a first-order tiebreaker and (for events at the same process when the clock has the same value) a sequence number giving the order of execution as a second-order tiebreaker.
Note that  the clock value does not change during the performance of any event of the underlying algorithm A.
The clock value of a send event is at tached as a timestamp to the message being sent.
Each process i maintains a FIFO queue receive-buffer, in order to hold messages whose t imestamps are greater than or equal to the local clock value.
When a message arrives at process i, its t imestamp is examined.
If the t imestamp is less than the current clock value, the message is processed immediately; otherwise, it is placed in the receive-buffer.
At each locally controlled non-clock step, process i first removes from the receive-buffer and processes all messages whose t imestamps are less than its current clock value; these messages are processed in the order in which they appear in the receive-buffer.
This algorithm is said to simulate a receive(m)i event of A when the corresponding message is processed (rather than when it first arrives at process i)
The clock value that  gets associated with the receive event is the clock value at the time the message is processed.
Property 4 of Welch Time(A) follows from the unboundedness of the local clock variables.
The unboundedness of the local clock variables also implies that  every message in a receive-buffer is eventually processed, so every receive event is eventually simulated and assigned a logical time.
In terms of the informal conditions mentioned earlier, the "transformation" of each Ai that  produces Welch Time(A)i adds and manages the clock, receivebuffer, and sequence-number tiebreaker components.
The "simulation" now produces a fair execution of A that reorders some receive events of A with respect to other events.
Each time process i simulates a step of A, the logical-time value that is "generated" is just the triple (clock, i, k), where k is a sequence number used as a second-order tiebreaker.
Note that the amount of delay introduced by the Welch Time transformation is especially great when the local clocks are far out of synchronization.
This algorithm works best when the clocks happen to stay closely synchronized.
It is easy to modify the Welch Time algorithm transformation to work in asynchronous broadcast systems.
In this section, we present some simple applications of the addition of logical time to asynchronous network algorithms.
We consider the problem, given in Exercise 15.43, of counting the total amount of money in a banking system in which there are no external deposits or withdrawals but in which money is transferred between processes via messages.
The banking system is modelled as an asynchronous send/receive network algorithm A with no actions at its user interface.
Each process has a local variable money that contains the amount of money currently residing at that location.
The send and receive actions have arguments that represent amounts of money.
The processes in A decide when and where to send money and how much to send.
We make one technical assumption: that each  process sends infinitely many messages to each of its neighbors.
This is not a serious restr ic t ion-- i t  is always possible to add dummy messages containing $0
We would like an asynchronous send/receive network algorithm in which each process decides on a local balance, in such a way that the total of all the balances is the correct amount of money in the system.
The execution of this algorithm should be triggered by signals arriving from the outside, at one or more of the system locations.
These signals could happen at any time and could happen at different times at different locations.
So, we suppose that algorithm A is transformed somehow (e.g., using LamportTime or WelchTime) to a new system L(A), which simulates A and generates logical times for its events.
Then the required algorithm, CountMoney, is ohtained as a further transformation of L(A), where each process CountMoneyi.
CountMoney algorithmThe heart of the algorithm is a "subroutine" that uses a predetermined.
For each process of A, determine the value of the money variable after all events with logical times less than or equal to t and before.
For each channel, determine the amount of money in all the messages sent at logical times less than or equal to t but received at logical.
Specifically, each process CountMoneyi is responsible for determining the value of the money variable of process Ai, as well as the amounts of money in all the channels incoming to Ai.
To determine these amounts, process CountMoneyi attaches the logical time of each send event to the message being sent, as a timestamp.
In order to determine the value of the money variable of process Ai, process CountMoneyi keeps track of the money values before and after the event of Ai most recently simulated.
When it simulates the first event of Ai having a logical time strictly greater than t, CountMoneyi returns the recorded value of the money variable before this event.
There must be such an event, because Ai performs infinitely many events and there are only finitely many events with logical time less than or equal to t.
Ai with logical time exceeding t (i.e., the one at which CountMoneyi determines the value of money at Ai), process CountMoneyi records messages coming in on the channel.
It continues recording them as long as the attached t imestamp is less than or equal to t.
Such a message must arrive, because Aj sends infinitely many messages to Ai.
The balance computed by each process CountMoneyi (in the subroutine) is the sum of the values it determines for process Ai and for all the incoming channels.
Recall that all of this assumed a predetermined logical time t.
Since there is really no such predetermined t, the processes need some mechanism to determine one.
Just choosing an arbitrary t does not work, because that logical time might have already passed at some process before it begins executing the subroutine.
By broadcasting their results, the processes can determine the first ti whose subroutine succeeds everywhere and use the results of that subroutine.
We argue correctness for the subroutine, for any particular t.
First, to see that the general strategy yields the correct total amount of money, consider any fixed fair execution of CountMoney.
This execution simulates a fair execution c~ of A, together with a logical-time assignment ltime for a.
What the general strategy does is to "cut" execution a~ immediately after any events that have ltime -- t and to record the money that is at all the processes and in all the channels, at this instant.
It should be straightforward to see that the distributed algorithm in fact correctly implements the general strategy.
Now consider a fair execution of the CountMoney algorithm that simulates execution ~
Suppose the value of t - 7.5 is used in this.
We remark that the CountMoney algorithm does not introduce any new delays in the operation of A, in addition to those already imposed by L(A)
The idea of the CountMoney algorithm can be generalized beyond just a banking system, to an arbitrary asynchronous send/receive system A.
As before, we assume that each process Ai sends infinitely many messages to each of its neighbors.
Suppose we want an instantaneous global snapshot of the system state at some point during an execution of A.
This might be useful, for instance, for debugging, for establishing a backup version of the system state in case of failure, or for detecting certain global properties such as whether the algorithm has terminated everywhere.
It is possible to obtain an instantaneous global snapshot by delaying all the processes and messages for as long as it takes to record all the.
But for some applications, a true instantaneous global snapshot may not be needed; a system state that "looks like" an instantaneous global snapshot to all processes may be good enough.
In such a case, the strategy used for determining the total amount of money in a banking system can be adapted to provide an acceptable global snapshot of asynchronous send/ receive network system A.
Logica l  T i m e S n a p s h o t  algorithmAs for CountMoney, the heart of the algorithm is a subroutine that uses a predetermined logical time t E T, assumed to be known to all processes.
Determine the state of each process of A after all events with logical times less than or equal to t and before all events with logical times greater than t.
This information is determined using the same dis t r ibuted  algori thm that.
Logical time can also be used to allow a d is t r ibuted  system to simulate a central ized state machine, or, in other words, a single shared variable.
We show how to "implement" a shared variable x of a given variable type in the asynchronous broadcast  network model.
We consider a setting in which there are n user processes submit t ing invocations to x and receiving responses from x, one user process Ui at each node i of the network.
We assume that each user process issues invocations sequentially, that  is, it waits until it has received a response for any previous invocation.
We would like the users to obtain a view that.
More precisely, the network as a whole (with send and receive actions hidden) should be an atomic object of the given type, as defined in Section 13.1
We impose no resiliency requirements here; we only require well-formedness, a tomici ty  and failure-free termination.
There are many possible solutions to this problem, some of which are discussed in Section 17.1
For instance, one process could mainta in  a single copy of.
Here we consider a solution in which every process keeps a private copy of x; all invocations are broadcast  to all processes, who perform them on their.
The process originating an operat ion can determine the needed response.
We use the notion of logical time to obtain the needed synchronization.
Each process Ai simply receives invocations from user Ui and broadcasts  them.
It does not mat ter  what  processes do with these messages when they are received.
In addition, Ai broadcasts  dummy messages, if necessary, to ensure that  it broadcasts  infinitely often.
Then  logical time is added to A by a t ransformation,  yielding L(A), as before.
Besides a local copy of x, each process i has a local variable invocation-buffer in which it stores all the invocations it has ever heard about,  together with the logical times of their bcast events.
Process i places a local invocation in its invocation-buffer when it performs the bcast for that  invocation, and places a remote invocation (that is, one occurring at another  process) in its invocation-buffer when it performs the receive for that  invocation.
Process i is permi t ted  to apply an invocation 7r in its invocation-buffer to its copy of x when the following conditions are both true.
Invocation 7r has the smallest logical time of any invocation in invocationbufferi that  has not yet been applied by process i to x.
For every j ,  known-time(j)i is at least as great as the logical t ime o f  71-
When process i applies an operation that  was invoked locally to its copy of x, it conveys the response from x to the user.
Thus, there is a uniquely defined sequence II of invocations in c~, arranged in the order of the logical times of their bcast events.
The reliable broadcast  ensures that each process eventually places each invocation in its invocation-buffer.
Since infinitely many events occur at each process of A, Property  4 implies that the logical time at each process grows without bound.
The fact that each process broadcasts  infinitely many times implies that each component in each process's known-time vector also grows without bound.
Then we can argue, by induction on the positions of invocations in sequence II, that every invocation eventually is applied to every copy of x.
This implies that a response is produced for every invocation, showing termination.
We first claim that each process applies operations to its local copy of x in the order of their logical times, with no gaps.
This is because when process i applies an operation 7r with logical time t to x, it checks explicitly that it does not know of any pending invocations with logical times smaller than t and that its known-times for all processes are at least equal to t.
Then the FIFO property of the broadcast  channel between each pair of processes implies that process i will never hear of any other invocations with logical times smaller than t.
Now we define a serialization point for each operation of c~
Break ties by arranging the serialization points in the order of logical times.
Since the serialization points occur in logical time order, which is the same order as that in which the operations are performed on the local copies, the "shrinking" property required for the atomicity condition holds.
One advantage can be seen in the case where the logical times at the different processes happen to remain closely synchronized.
In this case, the time to perform an operation in the SimpleSh VarSim algorithm is approximately a two-way message delay.
If the clocks are closely synchronized, this requires only approximately a one-way message delay.
This approach is an alternative to the implementation techniques suggested in Section 17.1
Spec ia l  h a n d l i n g  of  r e a d  o p e r a t i o n s.
Suppose that some of the operations on the shared variable x being implemented are read operations (or, more generally, any operations that do not modify the value of the variable but only return a response)
This modification yields weaker correctness guarantees than those of an atomic object, but it may still be reasonable for many applications.
Typical operations for this case would be deposit, withdraw, addinterest, and so on.
The database might be replicated, say, at each branch of the bank.
For many operations in such a database, the order of the updates is important.
For example, different results can be obtained if a withdraw operation is invoked before a deposit rather than after, if the balance is low.
It is often useful for the individual branches to be able to read information from the local copy of the database, even when the information is not completely up-to-date.
In this case, the special handling of read operations described above can be useful.
Briefly, users request exclusive use of a resource via try actions, and the system grants it via crit actions.
The system is supposed to guarantee that at most one user has the resource at a time and that the resource continues to be granted if there are requests.
Here, we will also require lockout-freedom, that is, that every request is eventually granted.
The add(i) operation adds the indicated index to the end of the queue.
The first(i) operation is a query that returns true if i is the first element on the queue, but otherwise returns false.
The remove(i) operation removes all occurrences of index i from the queue.
Let Bx be an atomic object for x, where port i supports all the operations with argument i.
When user i requests access to the critical region via a tryi event, process i invokes an add(i) operation on atomic object B~, which has the effect of adding i to the end of the queue.
Then process i repeatedly invokes the first(i) operation, waiting for the answer true, which indicates that i has reached the first position on the queue.
When i receives the answer true, it allows user i to go to the critical region with a criti event.
When this operation returns, process i allows user i to go to the remainder region with a rera operation.
Namely, modify the add(i) operation so that it has a return value: either the index of i's predecessor j on the queue, if there is one, or else null.
If the return value is null, then there is no predecessor and process i can immediately perform criti.
Otherwise, process i simply waits until it performs remove(j) for i's predecessor j on its local copy of the queue (at which point it knows that user j has returned the resource)
Each of the algorithms we have described so far has been built upon an asynchronous algorithm A, augmented with logical time.
Another design strategy is to start  with an algorithm that uses a notion of "real time," and then to t ransform it into one that uses logical time instead of real time.
Suppose that we begin with an asynchronous send/receive network system.
Suppose that all the processes'  real-time variables are maintained by a global RealTime I /O  automaton, via tick(t) outputs that simultaneously set all the processes'  real-time variables to t.
The I /O  automaton model permits a single output  action to synchronize with more than one input action.
The only requirement on the Real Time automaton is that the times occurring as arguments in its output  events should be nondecreasing and unbounded in any fair execution.
The processes Ai are not permit ted to modify the real-time variables.
Then it is possible to t ransform each process Ai into a process Bi that works without Real Time, using logical time instead.
Bi does not have a real-time variable but instead has a clock variable that it uses in the same way as Ai uses real-time.
In order to describe what this t ransformation guarantees, we consider both.
That  is, each fair execution of B looks like an execution of A to each individual user.
It is possible to design an algorithm similar to CountMoney but using real time, to count the total amount  of money in a bank.
Namely, each process i records the value of its money variable just  before the step where it finds that its real-time variable exceeds t.
Then it records all incoming messages sent when the sender's real-time variable is less than or equal to t, but received when process i's real-time variable is greater than t.
The resulting algorithm can be t ransformed as above into an algorithm that uses logical time.
Since RealTime is just an ordinary I//O automaton, we cannot assume anything about the "rate" at which its outputs occur.
In Chapters 23-25, we consider a model in which such rate assumptions can be expressed.
The notion of logical time is due to Lamport, in his famous paper "Time, Clocks and the Ordering of Events in a Distributed System" [176]
Lamport later extended the replicated state machine approach to tolerate a limited number of failures [179]
Schneider [255] has written a survey of the uses of replicated state machines to implement fault-tolerant services.
The CountMoney and LogicaI TimeSnapshot algorithms are closely related to the consistent global snapshot algorithm of Chandy and Lamport [68]
Banking database examples such as those in this chapter are discussed extensively by Lynch, Merritt, Fekete, and Weihl in [207]; the focus there is on atomic transactions for banking and other databases.
A survey of applications of vector clocks appears in [256]
Write "code" for the Welch Time algorithm transformation in the same general style as the LamportTime code.
Describe an implementation of logical time for a send/receive network system in which the logical time domain is R >~
During a Friday late-night work session, over pizza, several of the programmers at the Flaky Computer Corporation have invented four notions of "illogical time" for asynchronous send/receive network systems.
Each of the four notions of illogical time results from dropping exactly one of the four properties required for logical time.
They think that these notions might be useful for some applications.
The CountMoney algorithm is formulated as a double algorithm transformation applied to the underlying banking system A, which may make it difficult to see what is going on.
For this exercise, you will combine the various pieces into a single algorithm.
That  is, you need to specify the initial amounts of money at all the processes, plus some rules determining when and to whom money is transferred, and how much is sent.
You may choose your favorite algorithm for generating logical times.
Be sure to include a mechanism for determining an appropriate logical time t.
Now suppose that the underlying banking system A allows deposits and withdrawals (modelled as input actions at the user interface of the system) in addition to transfers.
If we apply the same CountMoney transformation as before, what can be claimed about the output of the resulting system?
Adapt the Logical TimeSnapshot algorithm to broadcast systems rather than send/receive systems.
In the CountMoney and Logical TimeSnapshot algorithms, the logical time is piggybacked on each message.
Develop an alternative algorithm that does not piggyback logical time but instead sends a single extra marker message on each channel to indicate the dividing point between the messages sent at logical times less than or equal to t and those sent at logical times greater than t.
Develop the modified implementation of a shared variable described in Section 18.3.3, which handles read operations locally.
Show that it does not, in general, implement an atomic object.
How can it be modified to work in the send/receive network model?
Give a careful proof of Theorem 18.4; this will require describing the transformation precisely.
Design an algorithm based on logical time for simulating single-writer/ multi-reader shared memory algorithms in an asynchronous send/receive network.
This method should be an alternative to the two-phase locking strategy described in Section 17.1.2
Each reader of a shared variable x should keep a local copy of x.
Each read and write operation on x should be assigned a logical time, and the operations should be performed on each local copy in the order of their logical times.
Consider weakening the definition of logical time to weak logical time, by allowing T to be a partially ordered set rather than a totally ordered set.
However, Properties 1-4 in the definition of logical time must still hold.
Thus, not all events are required to be related in the logical time order, but events that  depend on each other (events at the same node, or sends and corresponding receives) must still be related.
It should be stated in terms of an arbitrary total order consistent with the given partial order.
Hint: An algorithm can be based on the set T of length n vectors of nonnegative integers.
Each process i maintains a local clock that is a vector in T, initialized at all 0s.
When process i receives a message, it first increments clocki(i), then sets its clock vector to be the component-wise maximum of the newly incremented clock vector and the vector t imestamp of the message.
Show that your t ransformation in fact produces a weak logical-time.
In this chapter, we present the last of our four methods for simplifying the programming of asynchronous networks, namely, monitoring an asynchronous network algorithm A while it runs.
We focus on two notions in this chapter: consistent global snapshots and stable property detection.
A global snapshot returns a global state of A, that is, a collection of states for all processes and channels of A.
The snapshot is said to be "consistent" if it looks to the processes as if it were taken at the same instant everywhere in the system.
Such a snapshot is useful for all the tasks listed above.
A stable property of A is any property of the global state of A that, if it ever becomes true, will remain true forever.
Each monitoring algorithm is described as a transformed version B(A) of the original algorithm A; more specifically, B(A) is based on the same underlying.
B(A)i is not expressed as a simple composition of some new I /O automaton with Ai, because the new process B(A)i needs access to the state of Ai.
Rather, B(A)i is described as adding some new state components and actions and making some modifications to old actions.
We assume that the underlying graph G is an arbitrary connected undirected.
We assume that in algorithm A, all processes' initial states are quiescent (as defined in Section 8.1)
A in an environment that only supplies a single input event to a single (arbitrary) process.
According to the I /O automaton definitions, the arrival of such an.
These messages may then awaken the recipient processes, who may then send additional messages, and so on.
A global state of A is said to be quiescent provided that no process is enabled to perform any locally controlled action and there are no messages in the channels.
This again coincides with the definition of quiescent in Section 8.1, this time applied to the single I /O automaton representing the entire algorithm A.
The actual termination detection, including the done output, is to be performed by a monitoring algorithm B(A)
B(A) should also be a send/receive network algorithm, based on the same graph G as A.
B(A)i of the monitoring algorithm B(A) should be defined in terms of the corresponding process automaton Ai.
The changes we permit to Ai in order to get B(A)i are as follows.
B(A)i may contain new state components in addition to all the state components of Ai.
The projection of the start states of B(A)i on the state components of Ai must be exactly the start states of Ai.
B(A)i may contain new input, output, and internal actions, in addition to the actions of Ai.
The actions of Ai may have new information piggybacked on them in B(A)i, for example, a send(m)i action may be transformed into a send(m,c)i action.
The actions of Ai retain their preconditions and remain in the same classes of the task partition in B(A)i.
They have the same effects as before on the state components of Ai, but they may also affect the new state components.
The new input actions of B(A)i can change the values of the new state components of B(A)i only.
The preconditions of the new locally controlled actions of B(A)i may involve the entire state of B(A)i, including both old and new state components.
However, the new locally controlled actions may affect only the new.
They are grouped into new classes in the task partition of B(A)i.
We present the DijkstraScholten algorithm for termination detection for diffusing algorithms.
The idea of the algorithm is to augment the underlying algorithm A with the construction and maintenance of a spanning tree of the graph nodes.
This tree is rooted at the source node, that is, the node at which the input occurs.
The messages used by the algorithm are the messages of A plus an ack message.
The messages of A are treated like the search messages in the AsynchSpanningTrce algorithm.
Each process other than the source designates the neighbor from which it first receives an A message as its parent in the spanning tree.
Any subsequent A message is immediately acknowledged; only the first remains unacknowledged (for now)
Also, the source process immediately acknowledges any A message it receives.
Thus, as A messages get sent around the network, a spanning tree of the nodes involved in the protocol is constructed.
Now, we allow the spanning tree to "shrink," using a convergecast procedure, in order to report termination back to the source process.
When it finds this, it "cleans up": a non-source process sends an acknowledgment to its parent and deletes all information about this protocol, while a source process reports that it is done.
A similar cleanup procedure to the one used here was described for the AsynchBcastAck algorithm in Section 15.4
But in the present case, after a process cleans up, it may receive another A message, causing it to participate once again in the spanning tree construction.
In fact, this may happen any number of times, depending on the message transmission pattern of the underlying algorithm A.
An arrow on an edge indicates a message in transit; an arrow parallel to an edge indicates a parent pointer.
DS(A)3 already has a parent,  it responds with an acknowledgment.
This execution can continue in this fashion indefinitely, with portions of the spanning tree growing and shrinking as corresponding portions of algorithm A quiesce.
If A1 reaches a quiescent state and DS(A)I has acknowledgments for all its outgoing messages, then DS(A)I can announce termination.
The deficit variable is used to keep track of the number of outstanding acknowledgments.
As for Ai, plus: if s t a t u s -  idle then.
It  shou ld  be c lear  t ha t  any  g lobal  s t a t e  of D i j k s t r a S c h o l t e n ( A )  p r o j e c t s  to  give.
To see tha t  D i j k s t r a S c h o l t e n ( A )  cor rec t ly  de t ec t s.
For every j ,  if statusj = idle, then the projected state of Aj is quiescent, parentj = null, and deficit(k)j = 0 for every k.
I f  statusi = source, then the parent pointers form a directed tree rooted at i and spanning exactly the set of nodes with status 7~ idle.
I f  statusi = idle, then statusj = idle for all j and all channels are empty.
Then, after the point  of quiescence, no further A messages are sent or.
Since there are no further A messages or changes to the tree, eventually there.
But then any leaf node i of T is enabled to perform a cleanup, so it eventually does so.
It follows that eventually in c~, a done event must  occur.
Recall the AsynchBFS algorithm from Section 15.4, in which processes correct erroneous parent information until this information stabilizes.
As presented, the algorithm does not terminate, since the processes have no way of knowing when the algorithm has become quiescent.
To express A synchBFS as a diffusing algorithm, we make a tiny change, letting process i0 be initially quiescent and awakening it with a wakeup input action.
Then we apply the DijkstraScholten algorithm to obtain a terminating BFS algorithm.
This is a systematic version of the ad hoc termination strategy presented for A synchBFS.
Now we turn to the problem of taking a consistent global snapshot of a running asynchronous send/receive network algorithm A.
Informally speaking, we say that a snapshot is "consistent" if it looks to the processes as if it were taken at the same instant everywhere in the system.
Once again, we assume that the underlying graph G is an arbitrary connected undirected graph.
Now the underlying algorithm A is an arbitrary send/receive network algorithm.
The snapshot is to be taken by a monitoring algorithm B(A), also a send/receive network algorithm based on graph G.
Again, each process automaton B(A)~ of the monitoring algorithm B(A) should be defined in terms of the corresponding Ai.
The types of changes we allow this time are a little more general than those we allowed in Section 19.1.1, but they still are enough to ensure that any fair execution of B(A) "contains" a fair execution of A.
The difference is that now we also allow B(A)i to "delay" a send(m)i,j action of Ai until after B(A)i places another message ahead of rn in the channel from i to j.
We assume that each B(A)i has an input action snapi that signals it to begin taking a snapshot of A.
We require that in any fair execution of B(A) containing at least one snap input event, eventually every B(A)i will perform a report4 output containing a state of Ai and states for all the channels of A incoming to Ai.
The various states reported by all the B(A)i constitute a global state of A.
Namely, let c~ be the fair execution of A that is contained in the given fair execution of B(A)
Thus, as far as the processes can tell, the returned global state is extracted instantaneously at some point in the execution of A.
Moreover, this point is somewhere between the beginning and the end of the execution of the snapshot algorithm.
Figure 18.4 depicts an execution of A containing five transfers of money among the three processes in the system.
Suppose that some process of the monitoring algorithm B(A) receives a snap input at the beginning of the execution.
Then one example of a global state that might be returned by a consistent global snapshot algorithm is the one given in Figure 18.5
ChandyLamport algorithm (informal): When a process ChandyLamport(A)i that  has not previously been involved in the snapshot algorithm receives a snapi input, it records the current state of Ai.
Then it immediately sends a marker message on each of its outgoing channels; this marker indicates the boundary between the messages that  are sent out before the local state was recorded and the messages sent out afterward.
Then ChandyLamport(A)i begins recording the messages arriving on each incoming channel in order to obtain a state for that  channel; it records messages on the channel just until it encounters a marker.
At this point, ChandyLamport(A)i has recorded all the messages sent on that  channel before the neighbor at the other end recorded its local state.
There is one remaining situation to consider: suppose that  process ChandyLamport(A)i receives a marker message before it has recorded the state of Ai.
In this case, immediately upon receiving the first marker message, ChandyLamport(A)i records the current state of Ai, sends out marker messages, and begins recording incoming messages.
The channel upon which it has just received the marker is recorded as empty.
For example, if A is a banking system as described in Example 19.2.1, then money sent before the marker  is not included in the recorded local s tate  of the sender, but  money sent after the marker is included.
In the banking example, this means tha t  ChandyLamport(A)i has counted all the money tha t  was sent out by the neighbor before recording its local s tate  and hence was not counted by the neighbor.
Output : report(s, C)i, s E states(A~), C a mapping from nbrs to finite sequences of A messages send( "marker")i,j, j E nbrs.
Tasks: As for Ai, except: internal-sends are in tasks corresponding to sends in Ai, plus there are new tasks:
We first argue tha t  every process  eventua l ly  per forms  a report outpu t.
Because  of the connec t iv i ty  of the graph,  markers  thus eventua l ly  p ropaga te  to all processes ,  and all processes  record their  local s tates.
Now we argue tha t  the r e tu rned  global s ta te  is consis tent.
But this implies that the marker arrives at ChandyLamport(A)j before m does, which means that the state of Aj is already recorded by the time m arrives.
We must also check that the channel recordings give exactly the messages that are in transi t  in the channels of A after c~3
These are exactly the messages that arrive at ChandyLamport(A)j from ChandyLamport(A)i ahead of the marker and after ChandyLamport(A)j records the state of Aj, which are exactly the messages recorded by ChandyLamport(A)j for this channel.
It is easy to see that the ChandyLamport algorithm works in strongly connected directed graphs as well as in connected undirected graphs.
Let A be a simple special case of the banking system of Example.
We use the notation CL(A)i as shorthand for the process ChandyLamport(A)i.
Consider the fair execution of ChandyLamport(A) depicted in Figure 19.2
Then CL(A)I sends a marker to CL(A)2 and starts recording incoming messages.
The global state returned by the algorithm is shown in (h)
Note that the global state returned by the snapshot algorithm does not actually appear in the contained fair execution a of A.
It does, however, appear in an alternative fair execution a ~ of A in which.
The state returned by the snapshot algorithm is the state represented by the horizontal line in the second diagram.
The time from the first snap event until the last report event depends on the number of A messages that pile up in the channels and send-buffers.
If we ignore these pileups, we obtain a time bound of only O (diam(g + d)), but it is probably not reasonable to ignore them.
More realistic time bounds can be obtained in terms of the number of A messages that appear anywhere in the global state during the time of the snapshot.
In this subsection, we give some applications for consistent global snapshots.
The ChandyLamport algori thm--or  any other algorithm that produces a consistent global snapshot- -can be used to count the total amount of money in the banking system described in this chapter.
A consistent global snapshot algorithm can be used to help debug distributed algorithms.
The designer of a distributed algorithm A can (and should) describe key properties of A by invariant assertions about the global state of A.
A debugger can allow A to run, obtaining consistent global snapshots from time to time and checking that the invariants are true for each snapshot.
Since each global state returned by the snapshot algorithm is a reachable global state of A, the invariants ought to be true for those states.
The designer can carry out such checking before attempting detailed inductive proofs for the invariants.
Some work is required to verify that the invariants are true of the returned global state.
For example, the global state information can be transmitted to a single process, which can check the invariants locally.
Or, a distributed algorithm can be used, using the information returned by the snapshot algorithm as input data.
Assertion 15.3.2 can also be checked by a distributed algorithm.
In this case, the distributed algorithm is particularly simple because the invariant is representable as the conjunction of a set of properties, each of which can be verified locally.
The results of local verification can be convergecast to i0
An alternative debugging strategy is to use a centralized simulation of A on a single processor.
In this case, the invariants can be verified after every simulated step of A (or from time to time), using the simulated state of A.
No global snapshot algorithm is needed in this case; the disadvantage is that the simulation takes longer, since it is all carried out on a single processor.
A stable property P of an asynchronous send/ receive algorithm A is a property of global states of A that satisfies the following condition: if P is true of any reachable state s of A, then P is true of all states reachable from s.
Informally speaking, this says that if P ever becomes true in an execution of A, then P remains true from that point onward.
A simple strategy to determine whether or not a stable property P is true of the global state of an algorithm A is to obtain a consistent global state using a global snapshot algorithm and then to determine whether P is true or false of the returned global state.
Again, this determination can be made either by collecting the information at a single process, which can determine P locally, or.
The correctness conditions for a consistent global snapshot algorithm imply the following:
A just after the last report of the snapshot algorithm.
If P is false for the snapshot state, then P is also false for the global state of A just before the first snap of the snapshot algorithm.
The first of these facts is true because the state of A after the last report is reachable from the snapshot state, while the second is true because the snapshot state is reachable from the state of A before the first snap.
The algorithm provides no information about whether P is true of the global states of A that arise while the snapshot algorithm is in progress.
This time, consider a send/receive algorithm A with no external inputs but in which the start states are not necessarily quiescent.
Since A has no external inputs, quiescence is a stable property.
So termination can be detected using the general strategy for detecting stable properties: take a global snapshot, then determine if the returned global state is quiescent.
In this case, once the snapshot has been performed, each process i can determine whether its recorded state of Ai is quiescent and whether its recorded incoming channel states are empty.
The results (a bit for each process saying whether or not its information indicates quiescence) can then be convergecast to some distinguished process along a spanning tree.
In fact, each process only needs to convergecast a single bit, saying whether or not all the processes in its subtree have reported quiescence.
If this strategy concludes that A has terminated, then this is guaranteed to be the case.
Moreover, if the snapshot is executed repeatedly, this strategy is guaranteed eventually to detect termination.
The strategy just described can be used to detect termination for the AsynchBFS and AsynchBellmanFord algorithms.
The snapshot can be initiated by the source node i0
If the answer is positive, that is, that the underlying algorithm has terminated, then process i0 can.
On the other hand, if the answer is negative, that is, that the underlying algorithm still has not terminated, then process i0 must continue to perform snapshots until one returns a positive answer.
The asynchronous OptFloodMax leader-election algorithm of Section 15.2 can be augmented with termination detection based on the ChandyLamport snapshot algorithm to produce a terminating algori thm for leader election in an arbitrary connected undirected graph.
A snapshot can be initiated, for example, by any process whose maximum known UID changes.
Several snapshots may have to be performed before termination is detected.
Messages of the various snapshots can be tagged with identifying numbers for the snapshots in order to keep the snapshots separate.
On the other hand, the snapshot strategy always involves all the processes in the network, so its costs must depend on the network size.
But in the case where the snapshot only needs to be executed once (and there is no pileup of A messages), the costs of the snapshot strategy do not depend on the total number of A messages sent.
We give only one version of the deadlock-detection problem; there are many variants.
Consider a send/receive network algorithm A in which each process Ai has local states that indicate that it is "waiting for" some subset of its neighboring processes (say, to release resources)
We assume that when Ai is waiting for a nonempty set of neighbors, it is in a quiescent state; in fact, it cannot perform any locally controlled steps until it has received a message from each of the neighbors for which it is waiting (say, informing it that a resource has been released)
After Ai receives a message from any of the processes for which it is waiting, it continues to wait for the remaining processes.
A deadlock in a global state of A consists of a cycle of two or more processes, each waiting for the next in the cycle, with no messages en route from any process to its predecessor in the cycle.
Deadlock is a stable property, because once such a cyclic pattern is established, none of the processes in the cycle can ever perform any more locally controlled steps.
Thus, we can detect deadlock using the general strategy for detecting stable properties: take a global snapshot, then determine if there is a deadlock in the returned global state.
This determination can be made by collecting the information at a single process and carrying out a sequential cycle-detection algorithm (say, using depth-first search)
Alternatively, this determination can be made by a distributed cycle-detection algorithm operating on the snapshot results.
Moreover, if the snapshot is executed repeatedly, it is guaranteed eventually to detect any deadlock that occurs.
The DijkstraScholten algorithm was invented by Dijkstra and Scholten [92]
The presentation in their paper is quite different from ours; it provides a "derivation" of the algorithm along with a proof.
A generalization of DijkstraScholten in which activity is allowed to begin at multiple locations was studied by Francez and Shavit.
Other work on termination detection appears in a paper by Francez [126]
The ChandyLamport consistent global snapshot algorithm and its use for detecting stable properties are due to Chandy and Lamport [68]
The algorithm is derived from Lamport 's  earlier work on logical time [176]
The restrictions we listed on the modifications to the underlying algorithm A are derived from the definition of the superposition operation in the Unity programming language, as designed by Chandy and Misra [69]
The approach of this chapter to deadlock detection is closest to that of Bracha and Toueg [57]
Tay and Loke have designed a model that can be used to understand some deadlock-detection algorithms [274]
In the DijkstraScholten algorithm, the spanning tree of processes involved in the algorithm can grow and shrink repeatedly, incorporating the same process many times.
This behavior does not arise in the version of A synchBcastAck with garbage collection--there, once a process has cleaned up its state, it will never again need to participate in the algorithm.
Give the best upper bounds you can for the communication and time complexity of the terminating breadth-first search algorithm described in Section 19.1, obtained by applying DijkstraScholten to A synchBFS.
DijkstraScholten together with the A synchBellmanFord algorithm of Section 15.4
Give the best upper bounds you can for its communication and time complexity.
Consider an algorithm A that begins in a quiescent global state (as does a diffusing algorithm) but that is used with an environment that can submit inputs at any number of locations (one per location)
Design an algorithm to detect when A reaches a quiescent global state.
Now we say that termination is detected when done outputs are performed by all processes that have received inputs from the environment.
You may allow snap inputs to occur at any subset of the processes, at any time.
We consider a generalization of the banking system discussed in this chapter.
Suppose we are given a send/receive system A in which the processes maintain a distributed database, with each process managing some of the data items.
Here, we define a transaction to be simply a sequential program consisting of a.
A snapshot is considered reasonable if it includes all transactions that finish before the snapshot algorithm begins, along with an arbitrary subset of the other transactions that start before the snapshot ends.
The transformation B should not interfere unnecessarily with the operation of A; for example, it is not allowed to stop all transactions while it is obtaining the snapshot.
Prove an upper bound on the time complexity for ChandyLamport(A), in terms of the number of A messages that appear in the global state during the time of the snapshot.
Consider a connected undirected graph G with a distinguished node i0
Design an asynchronous send/receive algorithm A with underlying graph G to verify that a given, fixed set of parent pointers constitute a directed spanning tree of a subgraph of G rooted at i0
More precisely, assume that each process of A has a parent pointer whose value is either the index of a neighboring process or else null.
Consider the AsynchBFS algorithm augmented with the ChandyLamport snapshot algorithm to detect termination, as described in Example 19.2.3
Is there an upper bound on the number of snapshots that can be invoked before one must succeed in returning a positive answer?
Comparison of the DijkstraScholten and snapshot approaches to termination is only meaningful for algorithms A to which both types of termination strategy are applicable.
Describe the largest class of algorithms you can find to which both strategies can be applied.
Consider a collection of processes, each of which might be waiting for some of its neighbors.
That is, each process has a fixed local value wai t ing@r, indicating the set of neighbors for which that process is waiting.
Your algorithm should determine whether or not there is a cycle of two or more processes, each waiting for the next in the cycle, with no messages en route from any process to its predecessor in the cycle.
In another version of the deadlock problem, processes wait for sets of neighbors as in Section 19.2.3, but now each waiting process only needs to hear from any one of these neighbors rather than all of them.
Define an appropriate notion of deadlock for this version of the problem and design an algorithm based on consistent global snapshots for detecting this new type of deadlock.
Describe some other applications of consistent global snapshots for monitoring send/receive network algorithms.
Having now finished Chapters 16-19, on general methods for programming asynchronous networks, we now resume our study of specific problems in asynchronous networks.
Next, in Chapter  21, we consider consensus and other problems in asynchronous networks in which some of the processes might fail.
The final chapter on asynchronous computing is Chapter  22, in which we study the problem of reliable communication over unreliable channels.
The problem statement is much the same as in Section 10.2
Now we assume that the system A being used to solve the problem is an asynchronous network system, with one process Pi corresponding.
We assume that the actions tryi, criti, exiti, and rerr~ are used for communication between I /O  automata Ui and Pi.
In the case of a send/ receive network, the processes Pi communicate via reliable FIFO channels Ci,j, as depicted in Figure 20.1
We will also consider broadcast  systems, as well as systems containing a combination of send/receive and broadcast  channels.
Such a combination can be regarded as a special case of a multicast channel--see Section 14.3.2
The basic correctness conditions to be guaranteed by the system are the same.
We say that an asynchronous network system A solves the mutual exclusion problem provided that it solves it for every collection of users.
In this chapter, we drop the restriction, made in Section 10.2, that a process can perform locally controlled actions only when its user is in the trying region or exit region.
That  restriction is workable in the shared memory setting, because there the shared variables maintain information so that it is always available to all the processes.
However, in the network setting, there are no shared variables, so the processes need to do the work of maintaining this information and communicating it to other processes whenever it is required.
In this chapter, we will sometimes analyze the communication and time complexity for requests that operate "in isolation." We say that a request by a user is isolated provided that, during the time from its try to its crit, all other users remain in their remainder regions.
In the rest of this section, we present several mutual exclusion algorithms for asynchronous networks.
Chapter 10 contains many shared memory algorithms for mutual exclusion.
Using the techniques of Chapter 17, we can transform these into algorithms for the asynchronous network model.
For instance, the Bakery algorithm of Section 10.7 can be implemented reasonably efficiently in an asynchronous send/ receive network.
The simplest mutual exclusion algorithm for the asynchronous send/receive network setting works when the network is a unidirectional ring.
A token representing control of the resource circulates continuously around the ring.
When process Pi receives the token, it checks whether or not there is an outstanding request from user Ui.
If there is no such request, Pi passes the token to Pi+l.
On the other hand, if there is an outstanding request, Pi grants the resource to Ui and holds the token until Ui returns the resource.
When Ui returns the resource, Pi passes the token to Pi+l.
Tasks: Each locally controlled action comprises  a task by itself.
Mutual exclusion is guaranteed, because there is only one token, and only the user where the token is located can be.
Progress is guaranteed, because the token keeps circulating until it finds.
Lockout-freedom is guaranteed, because no process satisfies two consecutive requests without allowing the token to circulate around the ring in the.
It is not clear what we should measure, because the messages are not naturally apportioned to particular requests.
One thing we can say is that the total number of messages sent between a tryi and its corresponding crit4 is at most n.
We can also give an amortized analysis for the "heavy load" case, where there is always an active request at each node.
In this case, there are only a constant number of messages per request.
For the time complexity, we assume as usual that t~ is an upper bound on.
We also assume that c is an upper bound on the time.
Note that this time bound has a dn term, which can appear even in the case of a very light load, for instance, an isolated request.
The Circulating Token algorithm can be used in an arbitrary send/receive network based on a strongly connected directed graph G, if the.
The consecutive processes on the ring need not be neighbors in G--communicat ion between any pair of processes can be simulated by a series of communications along a directed path in the.
The performance of the resulting algorithm depends strongly on the graph G and the order in which the processes are arranged in the r ing-- i t  is important to minimize the total length of the paths used in the simulation.
In practice, the Circulating Token algorithm can be made resilient to some types of failures.
For example, if a process fails cleanly, in a way that is detectable to the other processes, then the other processes can.
For another example, if the token is lost, again in a way that is detectable, a new token can be generated using a leader-election protocol on the ring, for instance, one of those in Section 15.1
In the asynchronous model, ordinary process stopping failures and message losses cannot be detected, because there is no way processes can distinguish such failures from situations in which the processes or messages are simply delayed.
Thus, in order to achieve fault-tolerance, it is necessary to assume a stronger model that includes events that announce such failures.
In Section 18.3.3, we described another solution to the mutual exclusion problem for an asynchronous network system, in particular, for a broadcast network system.
In this section we present a similar algorithm, but to compare it more easily with the other algorithms in this chapter, we put the pieces together.
For simplicity, we do not handle local operations in a special way as described in Section 18.3.3
This algorithm generates logical times for events using the LamportTime strategy, based on local nonnegative integer clock values.
A logical time is a pair (c, i), where c C N and i is a process index; logical time pairs are ordered lexicographically.
The algorithm uses both broadcast and send/receive communication, where send/receive communication is allowed for all pairs of distinct processes.
In place of the separate invocation-buffer and queue, each process Pi maintains a single history data structure.
For each j, history(j)i records all the messages Pi has ever received from Pj, each with a nonnegative integer c, which is the clock value associated with that message's bcast or send event.
The try and exit requests are broadcast, much as before.
Instead of broadcasting dummy messages, each process acknowledges each try message with an ack message.
Pi can perform a criti when its latest try request has reached its history(i), provided that every other request that Pi has heard of with a smaller logical time has already been granted and provided that Pi has received a mes20.1
These latter two properties together ensure that  there is no current request with a smaller logical time, and moreover, there never will be one.
Pi can perform a remi as soon as its latest exit request has reached its history(i)
We let < denote lexicographic order on logical t ime pairs.
LogicalTimeMEi automaton (formal)S i g n a t u r e :
To see that the algorithm guarantees mutual  exclusion, we proceed by contradiction.
Suppose that, in some reachable system state, two processes, Pi and Pj, are in C at the same time.
Assume (without loss of generality) that the logical time ti of Pi's latest try message is smaller than the logical time tj of Pj's latest try message.
Then, in order to perform critj and enter C, Pj had to see, in its history(i), a message from Pi with logical time greater than tj and hence greater than ti.
Then the FIFO property of the communication channel from Pi to Pj implies that Pj must have seen Pi's current try message when it performed critj.
But then the precondition of critj implies that Pj must have seen a subsequent exit message from Pi.
This implies that Pi must have already left C at the time Pj performed critj, a contradiction.
Lockout-freedom for the trying region follows from the fact that requests are serviced in the order of the logical times of their try messages.
We argue that a try message with the smallest logical time among those for current requests eventually receives a crit response.
Since there are only finitely many try messages that get assigned logical times smaller than that of any particular try message, an inductive argument can then be used to show that all requests are granted.
So suppose that Pi is in T and has the try message with the smallest logical time, ti, among those for current requests.
We argue that eventually the preconditions for crit4 must become satisfied and must remain satisfied until criti.
The fairness properties for the broadcast channel implies that  eventually Pi receives its own try message and places it in history(i)i.
Also, since try messages receive corresponding acks and the clock variables are managed using the LamportTime discipline, eventually Pi obtains a message from each of the other processes with a logical time greater than ti.
Finally, since Pi's request is the current request with the smallest logical time, any request with a smaller logical time must have already had a corresponding exit event.
Then the fairness properties of the broadcast channel imply that  eventually Pi receives these exit messages.
In this way, all the preconditions for criti must eventually become satisfied.
For the communication complexity, we note that  in LogicalTimeME, unlike in Circulating Token, all messages are naturally apportioned to particular requests.
For the time complexity, we consider first the case of an isolated request by a user U/
In fact, we consider a "strongly isolated" request, for which we also require that  no residual messages arising from prior requests remain in the system state when the tryi event occurs.
In contrast, recall that  the time complexity of the Circulating Token algorithm has a dn term, even in the case of an isolated request.
We leave the general worst-case upper bound on the time from a tryi event to the corresponding criti event for an exercise.
Now we describe a simple variation on the LogicalTimeME algorithm that  is designed to reduce the communication complexity.
It improves on Logical TimeME by acknowledging requests in a careful manner  that  eliminates the need for exit messages.
The algorithm uses both broadcast and send/receive communication, where send/receive communicat ion is allowed for all pairs of distinct processes.
Logical times for events are generated as in Logical TimeME.
The only message that is broadcast  is try, and the only message that is sent on a send/ receive channel is ok.
Each message carries the clock value of its beast or send event.
After a tryi input, Pi broadcasts try just as in Logical TimeME and can go to C after it receives subsequent ok messages from all the other processes.
The interesting part  of the algorithm is a rule for when a process Pi can send an ok message to another process Pj.
In response to a try message from Pj, Pi does the following:
If Pi is in E or R, or in T prior to broadcasting the try message for its current request, then Pi replies with ok.
If Pi is in C, then Pi defers replying until it reaches E, and then immediately sends any deferred oks.
Pi compares the logical time ti of (the beast event of) its own request to the logical time tj associated with the incoming try message of Pj.
If ti > tj, then Pi's own request is given lower priority and Pi replies with an ok message.
Otherwise, Pi's own request has higher priority, so it defers replying until such time as it finishes its next critical region.
Pi can perform a remi at any time after it receives an exiti.
In other words, when there is a conflict, the RicartAgrawalaME algorithm resolves it in favor of the "earlier" request, as determined by the logical times.
Suppose that, in some reachable system state, two processes, Pi and Pj, are in C at the same time.
Assume (without loss of generality) that the logical time ti of Pi's latest try message is smaller than the logical time tj of Pj's latest try message.
Then there must have been try messages and ok messages sent from each of Pi and Pj to the other, prior to their entry into C.
Moreover, at each process, the receipt of the try from the other precedes its sending of the corresponding ok.
This still leaves several possible orderings of the various events.
Now we claim that the receive event for Pj's latest try message occurs after Pi broadcasts its own latest try message.
Therefore, at the time Pi receives Pj's try message, Pi is either in T or in C.
But in either of these cases, Pi's rules say that it should defer sending an ok message until it finishes its own critical region.
Thus, Pj could not enter C before Pi leaves, a contradiction.
Suppose that in fair execution a a point is reached at which some.
Since Pi is stuck forever in T, it must be that some other process Pj never replies with an ok message to Pi's last try message.
There are only two reasons why Pj might not send the ok immediately upon receiving the try from Pi:
Pj is in T when it receives the try, with a logical time tj < ti assigned to its request.
But once again, this means that Pj must send the deferred ok message to Pi.
In either case, Pi receives all the needed ok messages and proceeds to C, a contradiction.
A n o t h e r  o p t i m i z a t i o n.
It is possible to improve further on the RicartAgrawalaME algorithm by giving a different interpretation to the ok messages.
Now when some process Pi sends an ok to some other process Pj, not only does.
The rules for responding to a try message are the same as for Rica rtA gra walaME.
This version of the a lgori thm performs part icular ly well in the si tuat ion where.
In this case, the requesting user can go to its critical region.
The problem definition is much the same as in Section 11.1, using the notions.
We assume the same kinds of user au tomata  as in Section 20.1
The basic correctness conditions to be guaranteed by the system are the same.
Well-formedness: In any execution, and for any i, the subsequence describing the interaction between Ui and A is well-formed for Ui.
We say that  an asynchronous network system solves the general resourceallocation problem provided that  it solves it for every collection of users.
We also consider the same lockout-freedom condition as for mutual  exclusion.
As we did for mutual  exclusion, we drop the restriction that  a process can perform locally controlled actions only when its user is in the trying or exit region.
For a given resource specification T4, we say that  a request by a user is isolated provided that ,  during the t ime from try to crit, all other users with conflicting requests are in their remainder  regions.
This version of the problem is based on a given resource specification 7~, and we assume that ,  for every i, the tryi action is parameter ized by an arbi t rary  subset of Ri, the set of resources specified for user Ui.
The exclusion condition is reinterpreted to refer to the actual resources that have most recently been requested ra ther  than the potential  resource requirements described by 7~
Tha t  is, we require that  there be no reachable system.
The progress condition and lockout-freedom condition are the same as before.
The independent progress condition and the definition of an isolated request arc reinterpreted to refer to the actual requests.
Coloring a l g o r i t h m :
We include a process to manage each resource, in addition to processes tha t.
Each process Pi of the network algori thm simulates exactly one process of the.
When user Ui performs tryi, process Pi collects the needed resources one at a time, in increasing order according to color as before, this t ime by sending messages to the appropria te  resource processes.
After sending each message, Pi waits to receive a response.
Each resource process maintains a FIFO queue of requesting users, adding each newly received request to.
When the index i reaches the front of a resource.
When Pi has obtained all its needed resources, it performs criti.
When exit4 occurs, Pi sends messages to all the involved resource processes to tell the resource processes to remove index i from their queues.
This algori thm requires that  each process Pi be able to communicate  with all processes Pj tha t  manage resources assigned to i by the given resource specification 7~
As usual, this communicat ion can be performed directly if the.
The analysis of this version of the Coloring algori thm for networks is similar.
In this case, the t ime bound depends on upper  bounds on process step time, message-delivery time, and critical region time, plus the number  of colors used to color the resource graph, and the maximum number  of users for a single resource.
However, as before, the time bound is not directly dependent  on the size of the underlying.
The RicartAgrawalaME algorithm can be generalized to solve the resourceallocation problem for an arbi t rary  resource specification TO.
Now we assume tha t  we have a combination of multicast  and send/receive communication.
Technically, this can be regarded as a special case of multicast  communica t ion- -see Section 14.3.2
Multicast  must be permi t ted  from any process to the set of all the others tha t  share resources with it, and send/receive communicat ion must.
RicartAgrawalaRA algorithm: Processes compute  logical times using the LamportTime algorithm.
After a tryi input, process i multicasts a try message with an associated clock value to all the processes with which it shares resources.
Processes use the same rule for sending ok messages as in RicartAgrawalaME, using the logical times to determine priority.
Process i can perform a remi at any time after it receives an exiti.
As for the RicartAgrawalaME algorithm, we can modify the RicartAgrawalaRA algorithm so that  the ok messages extend permission until it is explicitly revoked.
In the RicartAgrawalaRA algorithm, logical times are used to assign priorities to conflicting requests, thereby breaking ties.
Alternative strategies can be used to break ties, for example, maintaining an acyclic digraph involving all the processes.
For simplicity, we consider an explicit resource specification 74 satisfying the following two restrictions:
Each resource is in the resource sets of exactly two users.
We leave the extensions to remove these restrictions for an exercise.
We assume a send/receive network based on a connected undirected graph G.
We assume that  any two processes that  share a resource are connected directly by an edge in G.
Also, just to make things simple, we assume that  all the edges in G are between processes that  share resources.
AcyclicDigraphRA algorithm: The algorithm is based on maintaining orientations of all the edges of G in such a way that ,  at any time, the digraph H consisting of all the oriented edges is acyclic.
The orientation of each edge is recorded in local orientation variables at the two cndpoint processes and is changed by means of a change message sent from the process at the head of the directed edge to the process at the tail of the edge.
We must assume that  the digraph determined by the initial edge orientations is acyclic.
If process i is in the trying region and has all its incident edges oriented inward, then it can perform a criti output.
The change messages are placed simultaneously in local send-buffers directed to all the neighbors.
Also, if process i is in the remainder region with all its edges oriented inward, then process i can set all its orientation variables to point outward and send a change message on each incident edge, again in one step.
We begin by giving a somewhat more careful definition of the orientation of each edge in an arbitrary reachable state.
Namely, we say that an edge (i, j )  is oriented from i to j provided that Pi's orientation variable for the edge indicates "outward" and either Pj's orientation variable indicates "inward," or else there is a change message on the way from Pi to Pj (in the send-buffer(j)i or in the channel from i to j)
An invariant can be used to show that this rule determines a unique orientation for each edge, in each reachable state.
Then we prove the invariant that when a process Pi is in the critical region, then all its incident edges are oriented inward and no change messages are in transit  in either direction on any of those edges.
Next we prove the key invariant that the digraph H is acyclic.
The only steps that can falsify this assertion are those in which some edge orientations change.
But every step that changes edge orientation simultaneously changes the orientation for all the edges incident on some particular node i in such a way that all the edges are directed outward after the step.
Because no edge is directed inward toward i after this step, there can be no cycle after the step involving the newly directed edges.
It follows that no cycle can be created by the step.
We consider only lockout-freedom for the trying region; as usual, the condition for the exit region is trivial.
Since the graph is always acyclic, at any point in an execution, we may define the height of a graph node i to be the maximum length of a directed path starting at i in the digraph H.
We first note that the height of a node never increases until the node reaches height 0 (and gives the process at that node a chance to enter the critical region)
We then show that any node at height 0 eventually directs all its incoming edges away from itself.
This gives the process at that node a chance to enter the critical region.
An interesting feature of the AcyclicDigraphRA algorithm is that the processes are "almost" identical: they do not use UIDs or any other distinguishing information other than the initial orientations of all the edges.
In order to solve this problem in arbitrary graphs, arguments such as the one for Theorem 11.2 imply that some method of breaking symmetry is needed.
Here, symmetry is broken by the condition that the digraph H is initially acyclic.
Now we describe a particular solution to the Drinking Philosophers problem for a given resource specification ~ ,  in a send/receive network with reliable FIFO channels based on a connected undirected graph G.
The architecture for this solution, which we call ModularDP, is depicted in Figure 20.3
The communication between each Ui and the corresponding Di uses try(B)i, criti, exit.i, and remi actions.
Each process Pi in the complete solution is the composition of Di and a corresponding process of A.
Each channel Ci,j in the complete solution must implement both the channel from Di to Dj in Figure 20.3 and also the corresponding channel of A.
For simplicity, we again make one of the assumptions about T~ that we made.
We also assume that any two processes that share a bottle are connected by an.
The recipient Dj of a request satisfies it if Uj is in E or R.
If Uj is in T or C, then Dj defers the request so that it can satisfy it when Uj finishes its critical region.
Thus, as soon as a process Di in its trying region is able to do so, it invokes internal-tryi to try to gain priority.
When Di receives an internal-crit~ input while it is still in its trying region-- tha t  is, when it enters its internal critical region--it sends demand messages for needed bottles that are still missing.
The recipient Dj of a demand always satisfies it if it has the bottle, unless Uj is actually in the critical region using the bottle; in this case, Dj defers the demand and satisfies it when Uj finishes its critical region.
Once Di is in its internal critical region, we can show that it eventually receives all its needed bottles.
When Di is in the trying region and has all its bottles, it can enter its critical region.
Once Di enters its critical region, it can output  internal-exiti, since it no longer needs the priority associated with the internal critical region.
Fi rs t ,  we can show tha t  when.
Di receives a ("request" ,  b) message,  it ac tua l ly  has the bot t le  b.
On the other  hand,  it is possible for Di to receive a ( " d e m a n d " ,  b)
So before sat isfying a d e m a n d ,  Di.
Second, the flag curren t i  keeps t rack  of whether  there is a cur rent  in ternal.
The  curren t i  flag is set to t rue  when an in ternal-cr i t4  occurs  while regioni =
When currenti = false, Di can perform internal-exit4, thus terminating the internal critical region.
The exclusion condition follows from the fact that the bottles sets and bottle messages explicitly represent the bottles, plus the fact that a process must have all needed bottles in order to perform a crit output.
First, it is easy to see from the code that the environment of the resourceallocation module preserves well-formedness for that module.
Then the properties of the module imply that every execution of the system satisfies the wellformedness and exclusion conditions for the module.
Also, every fair execution satisfies the lockout-freedom condition for the module.
Also, by the exclusion condition for the module, no neighbor of Di can be in its internal critical region during c~1
When the internal-criti event occurs, it must be that regioni = T, because currenti is set to true.
Therefore, as part of the internal-crit4 event, Di sends demand messages for all its needed bottles.
Consider any recipient Dj of such a ("demand", b) message.
If Dj has bottle b and is not actually using it (i.e., is not in its critical region, with b E needj), then it sends ("bottle", b) to D~
On the other hand, if Dj is using b, then, since every critj is followed by an exitj, Dj eventually finishes the critical region and satisfies the deferred demand.
We claim that it must keep those bottles until it performs crit~
Since Di gets all the needed bottles, Di eventually performs criti.
But this event causes current to be set to false, a contradiction.
But because of the handling of the current flag, the only way this could happen is if, in the interim, a crit4 occurs.
So we may assume that no internal-crit occurs in c~1
If internal-region is ever equal to T during c~1, the lockout-freedom property for the module implies that eventually an internal-crit must occur, a contradiction.
If internalregion is ever equal to R during c~1, then eventually an internal-tryi occurs, leading to internal-region = T, again a contradiction.
The only remaining possibility is that internal-region = C throughout c~1
But since Ctl immediately follows a tryi event, it must be that current = false throughout c~1
But then eventually an internal-exiti occurs, leading to internalregion = E, a contradiction.
Claim 20.8 yields lockout-freedom for the trying region for the ModularDP system; lockout-freedom for the exit region is easy.
The Di components of the algorithm send at most 3k messages per request, if k is the maximum degree of any node in the underlying graph G.
For the time complexity, let t~ and d be as usual and let c be an upper bound.
T1 will typically be a function of an upper bound on the length of an internal critical region.
For a "strongly isolated" request, that is, an isolated request in which any residual messages from prior requests have already been delivered, the time complexity is at most 2d + O (g)
His paper includes a discussion of various forms of fault-tolerance for mutual exclusion algorithms, including regeneration of a lost token using a leader-election algorithm.
Raynal's book [250] contains a large collection of mutual exclusion algorithms, for both the asynchronous network and asynchronous shared memory models.
Welch and Lynch [285] developed the ModularDP algorithm in the form presented here, based on the ideas of Chandy and Misra.
In particular, they made explicit the modularity that was implicit in the Chandy-Misra algorithm.
These papers focus on obtaining improved running time and/or fault-tolerance.
Note: Your implementation need not be, but may be, obtained using a general transformation applied to the original Bakery algorithm.
Fill in the details of the proof of Theorem 20.1
Design an efficient send/ receive network algorithm based on G that causes all the processes in the network to configure themselves into a virtual ring.
Each process must output  the UID of its ring successor, plus the UIDs of all the nodes along a path to that successor.
Try to minimize the total length of all the paths.
Repeat Exercise 20.4, but for the case where G is a strongly connected directed graph.
Hint: The key invariant says that if a process i is in C, then the logical time associated with its try message is less than that of any other try message that does not have a subsequent ezit message.
Prove a general worst-case upper bound on the time between a tryi event and the corresponding criti event, in the LogicalTimeME algorithm.
That is, condense the information that is retained, while permitting each process to exhibit the same behavior as before.
Prove the correctness of your optimized algor i thm using a simulation relation relating it to Logical TimeME.
Suppose that we modify the LogicalTimeME algorithm so that each process increments its local clock when it receives a message but does not increase it additionally to guarantee that the new clock value is larger then the value in the received message.
This yields one of the notions of "illogical time" described in Exercise 18.4
Which correctness properties does the modified algorithm retain? Prove your claims (both positive and negative)
Prove that the RicartAgrawalaME algorithm is lockout-free and prove an upper bound on the time from any tryi event until the corresponding criti event.
Analyze the communication and time complexity of the modified Coloring algorithm described in Section 20.2.2
Explain how the Circulating Token algorithm can be regarded as a special case of the AcyclicDigraphRA algorithm.
Generalize the AcyclicDigraphRA algorithm to remove the two given restrictions on the resource specification.
Give an efficient algorithm for a send/receive network based on a connected undirected graph G, to orient all the edges to form an acyclic digraph H.
State and prove an analogue of Theorem 11.2 for the asynchronous network setting.
AcyclicDigraphRA, in which processes do not explicitly acquire individual resources.
The programmers at the Flaky Computer  Corporation have decided to try to improve the AcyclicDigraphRA algorithm.
Namely, a process that is in the remainder region with all edges oriented inward does not change the orientation of the edges to point outward unless it receives an explicit try message from a neighbor.
A process Pi sends try messages to all its neighbors when it receives a tryi input from user Ui.
Assume that any two processes that share a resource are connected by an edge in the underlying graph G.
Design your algorithm to achieve low time complexity for a request that has a small number k of "overlapping" conflicting requests.
Assume that any two processes that share a resource are connected by an edge in the underlying graph G.
Design your algorithm so that it guarantees lockout-freedom for any particular process i, even in the face of stopping failures of processes whose distances from i in G are greater than or equal to k.
Fill in all the details in the proof of Theorem 20.6
In particular, you will need to prove some invariant assertions, including.
Generalize the ModularDP algorithm to remove the restriction on the resource specification.
In this chapter, we consider what can and what cannot be computed in asynchronous networks in the presence of process stopping failures.
Here, we only consider process failures and assume that communication is reliable.
We begin by showing that, for the purpose of obtaining computability results, it does not matter whether we consider send/receive or broadcast systems.
Then we (re-)state the fundamental impossibility result for the problem of distributed agreement in the asynchronous network model.
This result says that the agreement problem cannot be solved in asynchronous networks, even if there is guaranteed to be no more than one process failure.
In Chapter 12, we discussed this problem and gave an analogous impossibility result for the asynchronous shared memory setting.
As we noted at the beginning of Chapter 12, such impossibility results have practical implications for distributed applications in which agreement is required.
These include database systems requiring agreement on whether transactions commit or abort, communication systems requiring agreement on message delivery, and process control systems requiring agreement on fault diagnoses.
The impossibility results imply that no purely asynchronous algorithm can work correctly.
In the rest of this chapter, we describe some ways around this fundamental dii~culty: using randomization, strengthening the model with mechanisms for failure detection, agreeing on a set of values rather than just one, and agreeing approximately rather than exactly.
In particular, many results about computability in asynchronous networks follow directly from analogous results about computability in asynchronous read/write shared memory systems, by means of general transformations.
The model we assume throughout this chapter is an asynchronous broadcast system with reliable broadcast channels and process stopping failures (modelled with stop events)
We could equally well have considered send/receive systems with reliable FIFO send/receive channels between all pairs of distinct processes: it turns out that the two models are the same from the point of view of computability.
It is not hard to see that the broadcast model is at least as powerful as the send/receive model.
The following theorem shows that it is not more powerful.
Each Qi is responsible for simulating Pi, plus participating in the simulation of the broadcast channel.
Qi simulates a bcast(m)i output of Pi by performing send(m, t)i,j outputs for all j ~ i, where t is a local integer-valued tag, and then performing an internal step simulating receive(m)i,i.
The tag values used by Qi start with 1 and are incremented with each successive bcast.
If Qi receives (m, t, j )  from k, it continues helping by sending (m, t, j )  to all processes other than i, j ,  and k to which Qi has not already sent (m, t, j)
Meanwhile, Qi collects tagged messages (m, t) originally broadcast by each Pj, j ~ i; these are either received directly from Qj or via relays.
At certain times, Qi is allowed to perform an internal step simulating a receive(m)j,i event.
Specifically, Qi can do this when Qi has a message (re, t) originally broadcast by Pj, Q~ has already relayed (m, t, j)  to all processes other than i and j,  and Qi has already simulated receivej,i events for messages from Pj with all tag values strictly less than t.
First, note that no process Qi simulates a receive(m)j,i event for any j until after it has succeeded in sending the corresponding (m, t) to all the other processes, and thus after it has been guaranteed that all processes will eventually receive (m, t) from j.
Second, note that although a process Qi can receive messages originally broadcast by Pj out of the order in which they were broadcast by Pj, the tags allow Qi to sort these messages into the proper order.
Third, note that if a message with tag t is sent by any process Qi, then it must be that messages originating at Pi with all smaller tag values have previously been sent to all processes.
Theorem 21.1 implies that it does not matter, from the point of view of computability, whether we consider broadcast systems or send/receive systems.
Of course, the complexity is different--the total number of receive events might be multiplied by approximately n in the simulation described above--but  we will not worry much about complexity in this chapter.
We choose to consider broadcast systems because they make the impossibility results appear slightly stronger and because they make the algorithms easier to write.
We use the definition of the agreement problem in Section 12.1
Although it was formulated there for shared memory systems, it also makes sense for asynchronous (broadcast or send/receive) network systems.
All the actions with subscript i are said to occur on port i.
U~ is assumed to perform at most one initi action in any execution.
A sequence of initi and decidei actions is well-formed for i provided that it is some prefix of a sequence of the form initi(v), decidei(w)
Well-formedness: In any execution, and for any i, the interactions between Ui and A are well-formed for i.
Validity: In any execution, if all init actions that occur contain the same value v, then v is the only possible decision value.
Failure-free termination: In any fair failure-free execution in which init events occur on all ports, a decide event occurs on each port.
We say that an asynchronous network system solves the agreement problem if it guarantees well-formedness, agreement, validity, and failure-free termination (for all collections of users)
Wait-free termination is defined to be the special case of f-failure termination where f = n.
Of course, it is easy to solve the agreement problem in the asynchronous broadcast  model if there are no fault-tolerance requirements.
For example, each process could simply broadcast  its initial value and apply some appropriate agreed-upon function to the vector of initial values it receives.
Since all processes are guaranteed to receive the same vector of values, all will obtain the same result.
The main impossibility result for broadcast  systems (repeated from Section 17.2.3) is.
It is also possible to prove the impossibility result directly, using a proof similar to that of Theorem 12.8
Theorem 21.2 says that the agreement problem cannot be solved in an asynchronous network system, even for only a single stopping failure.
However, the problem is so fundamental to distr ibuted computing that it is important  to find ways around this inherent limitation.
We show that the agreement problem can be solved in a randomized asynchronous network.
This model is stronger than the ordinary asynchronous network model, because it allows the processes to make random choices during the computation.
On the other hand, the correctness conditions are slightly weaker than before: although well-formedness, agreement, and validity are still guaranteed, the termination condition is now probabilistic.
Namely, all the nonfaulty processes will decide by time t after the arrival of all inputs, with probability at least p(t), where p is a particular monotone nondecreasing, unbounded function.
In the subsequent sections, we consider other ways around the inherent limitation expressed by Theorem 21.2, including the use of failure detectors, allowing more than one decision value, and allowing approximate instead of exact agreement.
An init(v)i input causes process Pi to set x := v.
It continues performing the algorithm forever, even after it decides.
Round 1: Pi broadcasts ( "first", s, v), where v is its current value of x, then waits to obtain n -  f messages of the form ("first", s, ,)
If all of these have the same value v, then Pi sets y := v; otherwise it sets y := null.
There are three cases: First, if all of these have the same value v r null, then Pi sets x := v and performs a decide(v)i if it has not already done so.
For validity, suppose that  all init events that  occur in an execution contain the same value v.
For agreement,  suppose that  process Pi decides v at stage s and no process decides at any smal ler-numbered stage.
Then it must  be that  Pi receives n -  f ( "second", s, v) messages.
This implies that  any other process Pj that  completes stage s receives at least n -  2 f  ( "second", s, v) messages, since it hears from all but  at most  f of the processes that  Pi hears from.
This means that  Pj cannot decide on a value different from v at stage s; moreover, Pj sets x := v at stage s.
Since this is t rue for all Pj that  complete stage s, it follows (as in the argument for validity) that  any process that  completes stage s + 1 must  decide v at stage.
First ,  it is not hard to see that  the a lgor i thm.
However, Lemma 21.4 does not imply that  each nonfaulty process eventually decides.
It turns  out that  this proper ty  is not guaranteed by the BenOr algori thm, but  only holds probabilistically.
As in Section 11.4, we imagine that  all the nondeterminis t ic  choices in the.
We constrain the adversary to enforce the fairness conditions of all the process I / O  au tomata  and the broadcast.
We also constrain it to observe the usual t ime restrictions:
Finally, we require that  the adversary allow init events on all ports.
We assume that  the adversary has complete knowledge of the past  execution.
In this case, by the argument  for agreement,  all nonfaulty processes.
For this stage s, consider any shortest  finite execution c~ in which some nonfaulty process, say Pi, has received n -  f ("first", s, , )  messages.
Thus, c~ ends with the delivery of one of these messages.
We claim that  if there is only one good value.
This is because if Pi receives f + 1 copies of v, then every other process receives at least one copy of v and so cannot.
It follows that  if there is only one good value v, then v is the only value.
Similarly, if there are two good values, then no value can be forced in this way.
Thus, if there is exactly one good value, then with probability at least 1 ,  all processes that choose their values of x randomly will choose the good value, thus agreeing with those that choose nonrandomly.
In either case, with probability at least 1 all nonfaulty processes end up with the same value of x at the end of stage s.
Now, the argument for each stage s only depends on the random choices at stage s, and these are independent of the choices at other stages.
So we can combine the probabilities for different stages, to see that with probability at least.
Now define a function T from N + to R >-~ such that each nonfaulty process completes each stage s by T(s) time after the last init event.
By Lemma 21.4, we can choose T(s) to be O(s(d + g))
It also guarantees that, with probability 1, all nonfaulty processes eventually decide.
One reason the BenOr algorithm is significant is that it demonstrates an inherent difference between the randomized and nonrandomized asynchronous network models.
Namely, the agreement problem cannot be solved at all in the presence of process failures in the nonrandomized model, but can be solved easily (with probability 1) in the randomized model.
A similar contrast is shown by the LehmannRabin algorithm in Section 11.4
The BenOr algorithm is not practical, because its probabilistic time bound is high.
It is possible to improve the time complexity by increasing the probability that different processes' random values at the same stage are the same.
However, this requires the use of cryptographic techniques, which are outside the model given here.
Another way to solve the agreement problem in fault-prone asynchronous networks is to strengthen the model by adding a new type of system component known as a failure detector.
A failure detector is a module that provides information to the processes in an asynchronous network about previous process failures.
There are different sorts of failure detectors, based on whether the information about stopping is always correct and on whether it is complete.
The simplest one is a perfect failure detector, which is guaranteed to report only failures that have actually happened and to eventually report all such failures to all other non-failed processes.
Formally, we consider a system A that has the same structure as an asynchronous network system, except that it has additional input actions informstopped(j)i for each pair i and j of ports, i =/= j.
The idea is that the failure detector learns about stopping failures that occur anywhere in the network and informs the other processes about them.
An inform-stopped(j)~ action is intended as an announcement at port i that process j has stopped.
Figure 21.1 shows the architecture for a simple three-process system.
The following algorithm solves the agreement problem when used with a perfect failure detector:
If j E stopped, it means that Pi has learned that Pj has stopped.
Process Pi continually broadcasts its current val and stopped data and updates it upon receipt of new data from processes not in stopped.
Pi also keeps track of processes that "ratify" its data, that is, from which it receives the same (val, stopped) data that it already has.
When Pi reaches a point where its data has "stabilized," that is, when it has received ratifications for its current data from all non-stopped processes, then Pi decides on the non-null value corresponding to the smallest index in its val vector.
For all k, if w(k) E V, then w ( k ) -  w'(k)
To avoid confusion, we do not explicitly describe the behavior of Pi after a stopi event occurs.
It is just as usua l - - the  process stops.
For wait-free te rminat ion , consider a fair execution a in which init events occur on all ports and let i be any non-failing port; we show that Pi eventually decides in a.
Note that every time Pi's data (vali, stoppedi) changes in a,  it must be that the new pair dominates the old pair.
Since there are only finitely many possible pairs, eventually this.
If P~ decides before this point, then we are done, so suppose that it does not.
Suppose that Pi is the first process that decides and let w and I be the values of vali and stoppedi, respectively, when the decidei event, 7r, occurs.
Then all processes in I fail in a prior to 7r and so can never.
We claim that each process j in J must keep val = w forever after point tj in a,  which implies that if it decides, it agrees with Pi.
So suppose that this is not the case and let j be the first process in J to acquire a val vector containing information that is not in w (i.e., some element of the vector is in V, whereas the corresponding element of w is null)
Then this acquisition must occur as a result of a receivek,j event occurring after point tj, where the broadcasting process Pk has, at the time of the broadcast ,  a val vector containing information not in w.
Since Pj ignores all processes in I after point tj, it must be that the broadcasting process Pk is in J.
But this contradicts the choice of j as the first process in J to acquire information not in w.
The communication complexity and time complexity of the PerfectFDAgreement algorithm are unbounded.
However, it is possible to devise similar protocols with bounded complexity.
Va l id i ty :  In any execution, any decision value for any process is the initial value of some process.
The validity condition is a slight strengthening of the validity condition for ordinary agreement.
There is a trivial algorithm to solve the k-set agreement problem in an asynchronous broadcast network, where f < k:
Every process Pi decides on the first value it receives.
It turns out that the k-agreement problem cannot be solved if the number of failures is > k.
Theorem 21.10  The k-agreement problem is not solvable with k-failure termination in the asynchronous broadcast model.
We use the same problem definition as in Section 12.5
That is, the set V of values is the set of real numbers, and processes are permit ted.
Instead of having to agree exactly, as in the agreement problem, the requirement is that they agree to within a small positive tolerance e.
The problem has the same well-formedness and termination conditions as the ordinary agreement problem, and the agreement and validity conditions are replaced by the following.
Agreement: In any execution, any two decision values are within c of each other.
Va l id i t y :  In any execution, any decision value is within the range of the initial values.
Each process Pi executes a series of stages, at each of which it waits to hear from any n -  f processes rather than from all n processes.
It cannot wait to hear from all processes, because up to f processes might stop.
Because we are now considering stopping failures only, it is not necessary for Pi to "reduce" its multiset of values by discarding the extreme values.
The mean and select functions used in the following description, as well as some notions like the width of a multiset of reals, are defined in Section 7.2
Each Pi maintains a variable val containing its latest estimate.
This gets initialized to the value v that arrives in an.
At each stage, Pi does the following: First, it broadcasts its val value, tagged with the stage number s.
Then it collects the first n -  f values it receives for stage s into a multiset W.
We claim that, at each stage, the width of the multiset of.
But we do not yet have a complete algorithm, because we have not said when processes actually.
We use the extra processes to help in achieving termination.
However, we can modify this s trategy slightly by adding.
Thus, each Pi can use the range of the multiset it collects at stage 0 to compute a stage number by which it is sure that the val values of any two processes at stage s are at most c apart.
Then Theorem 17.5 can be used to infer the existence of an.
We consider a fair execution OZl in which all processes begin with value Vl and all processes with indices in G2 fail right at the start.
By f-failure termination, all processes in G1 must eventually decide, and the validity condition implies that they must decide Vl.
As we did in Section 12.5, we can consider the solvability of arbi t rary decision problems in asynchronous networks.
Ordinary agreement, k-agreement, and approximate agreement problems are all examples of decision problems, and we have already given the main results about the computabili ty of these problems in asynchronous networks.
As for the read/wr i te  shared memory model, we state a theorem that gives some conditions that imply that a problem cannot be solved.
Then there must be a decision mapping D' with D'(w) C D(w) for all w, such that both of the following hold:
The shared memory approximate agreement algorithm can be constructed so as to satisfy this condition.
I f  input vectors w and w ~ differ in exactly one position, then there exist y C D'(w) and y' C D'(w')  such that y and y' differ in at most one position.
For each w, the graph defined by D'(w) is connected.
In general, impossibility results for computabiliy in the read/write shared memory setting carry over to the network setting using Theorem 17.8
Their original proof was given directly in terms of the asynchronous broadcast model rather than via a transformation.
Our proof of Theorem 12.8 follows the presentation of Loui and Abu-Amara.
These use "secret sharing" techniques to increase the probability that the random values chosen by different processes at the same stage are the same.
Those papers describe not only the perfect failure detector discussed here but also many less perfect variations, including failure detectors that falsely identify processes as faulty and failure detectors that fail to notify all processes about failures.
Such weaker failure detectors can also be used to solve the agreement problem, and some can be implemented in practical distributed systems using timeouts.
Failure detectors are also discussed by Hadzilacos and Toueg [143]
The idea of a stable vector algorithm is due to Attiya et al.
Define a decider execution c~ to be a finite failure-free input-first execution satisfying the following conditions, for some i:
That is, a single process i can operate on its own in two different ways (e.g., interleaving locally controlled and message-receiving steps in two different ways, or else receiving two different sequences of messages), in such a way as to resolve the final decision in two different ways.
Prove that if A has a bivalent initialization, then A has a decider.
Note that we have assumed only that A solves the agreement problem; we have made no fault-tolerance assumptions.
Reconsider the agreement problem of this chapter, using the broadcast model.
This time consider a more constrained fault model than general stopping failures, in which processes can only fail at the beginning of computation.
Can the agreement problem be solved in this model, guaranteeing.
In each case, give either an algorithm or an impossibility proof.
Design a variant of the BenOr algorithm in which all nonfaulty processes eventually halt.
Design variants of the BenOr randomized agreement algorithm that work for the following cases:
As mentioned in Section 14.1.1, a Byzantine failure of a process Pi is modelled by allowing Pi to be replaced by an arbitrary I /O automaton with the same external interface.
In each case, try to design the algorithm to work for as few processes as possible, relative to the number f of tolerated failures.
Devise an alternative protocol to PerfectFDAgreement that also uses a perfect failure detector to achieve wait-free agreement but that has "small" communication and time complexity.
Try to obtain the smallest communication and time complexity that you can.
This is used to correct a previous inform-stopped(j)i action, that is, to notify process Pi that Pj has in fact not stopped, in spite of a previous erroneous notification.
Devise an algorithm that solves the agreement problem guaranteeing f-failure termination, using any imperfect failure detector.
Hint: The state only contains the components val, ratified, and decided but not the stopped component.
A decision can be made when I ratifiedl >_ n -  f.
Prove (without using Theorem 21.10) that any k-agreement algorithm in the asynchronous broadcast  model that guarantees k-failure termination must have a k + Sperner's Lemma.
Prove the most general impossibility result you can, using the construction in the proof of Theorem 21.12
In this chapter, we consider the problem of implementing reliable FIFO communication using less reliable channels.
This is one of the most fundamental problems solved by communication networks.
The "less reliable channels" we consider include channels that exhibit failures such as the loss and duplication of messages, as well as channels that reorder messages.
We also consider process crashes that lose process state information.
We only consider the problem in the very special case of a two-node network.
We begin by presenting two simple, well-known algorithms: Stenning's protocol and the Alternating Bit protocol.
In Stenning's protocol, the process at the sending end attaches (unbounded) integer tags to messages submitted by the user; this protocol tolerates loss, duplication, and reordering of messages on the channels.
The Alternating Bit protocol, on the other hand, uses only bounded tags and tolerates loss and duplication, but not reordering.
We then consider whether it is possible to tolerate reordering using bounded tags.
Finally, we consider the case of crashes that lose process state information (the contents of volatile memory)
Throughout this chapter, we discuss messages at two levels: the level of the users of the communication system and the level of the underlying channels.
In order to distinguish between these two types of messages, we call them highlevel and low-level messages, respectively.
We generally let M and M ~ denote the high-level and low-level message alphabets, respectively.
Also, we usually capitalize the actions at the user interface, for example, SEND and RECEIVE, while we continue to use lowercase for the actions at the channel interface, for example, send and receive.
The techniques that we use for modelling the algorithms in this chapter (using I /O automata, composition, and simulation relations) are suitable for modelling layered communication architectures such as the ISO hierarchy.
Each message should be delivered exactly once, and the deliveries should occur in the order in which the messages are submitted.
Then the correctness requirement for a protocol is that it should "implement" F,  in the sense that each of its fair executions a, when projected on the external actions of F,  should yield a fair trace of F.
Note that the universal reliable FIFO channel F is essentially an unbounded queue, so any implementation of F will also need unbounded storage.
However, it would introduce the additional complication of modelling the handshake protocol.
The two processes executing the code to implement F are modelled as I /O automata.
The channels connecting them in both directions are also I /O attomata, but they are generally not reliable FIFO channels.
In particular, they may lose, duplicate, or reorder low-level messages.
We do not consider certain other types of unreliability, however, such as the manufacture of spurious messages.
Also, we impose some limitations on message loss--we usually assume some liveness property that says, roughly speaking:
If infinitely many messages are sent, then infinitely many of them are delivered.
There are basically two ways to formalize this proper ty--us ing the strong loss limitation (SLL) and weak loss limitation ( WLL) conditions defined in Section 14.1.2
The difference is that the SLL condition specifies that the channel is fair to each particular type of message.
We also usually impose a finite limit on message duplication.
Formal descriptions of the allowed behavior for most of the channels we need.
Some of these descriptions are themselves I /O automata (and use I /O automaton fairness to express the needed liveness conditions)
Others are axiomatic, in terms of a cause function from receive events to send events.
Still others consist of a combination of an automaton and some extra liveness constraints.
In this chapter, we use all three types of descriptions, as convenient.
The architecture we consider throughout this chapter is depicted in Figure 22.1
The processes interact with the users by means of SEND and RECEIVE actions and with the channels by means of send and receive actions.
In Section 22.5, we also introduce additional actions to model process crashes.
The simplest protocol for ensuring reliable FIFO message delivery in terms of less reliable channels is due to Stenning.
It tolerates all three types of channel unreliability: (limited) loss, (finite) duplication, and reordering.
Then P2 accepts each subsequent message exactly if its tag is one greater than the tag of the message previously accepted.
When P1 receives an acknowledgment for its current tag, it moves on to begin processing the next high-level message.
The following is the code for process P1 of the Stenning protocol.
That  is, they allow limited loss, finite duplication, and reordering.
The allowed channel behavior is specified in Example 14.1.2 using a combination of a basic automaton and some additional liveness properties.
We want this form of specification here because it yields an explicit state that we can use in invariant assertions and simulation relations.
In order to prove the correctness of the Stenning protocol, we begin with some.
But note the following technicality: since we need invariants that mention the channel states, we must give them in terms of particular automata for the channels.
Thus, we state the invariants in terms of the basic I /O  automata.
Our goal is to show that the Stenning protocol, using any allowable channels, guarantees reliable FIFO message delivery.
We first give a technical lemma that asserts correctness in terms of the channel specifications rather than in terms of arbitrary allowable channels.
This lemma implies the result for arbi t rary allowable channels.
The statement of Lemma 22.2 is slightly heavy on notation, but it is not really that complicated.
The conclusion says that c~ yields a fair trace of F,  that is, it exhibits reliable FIFO message delivery.
The correspondence between sending and delivery events is uniquely determined by the definition of F.
So suppose not; consider the first high-level message m that is submit ted but not delivered and let k denote its associated tag.
We claim that this message m eventually reaches the front of bufferl.
This means that the message with t a g -  k -  1 gets removed from bufferl, so m reaches the front.
Once this message m reaches the front of bufferl, it must stay there forever (since it is never accepted by P2)
It is also possible to prove the fairness condition by means of an execution correspondence, using Theorem 8.13 and a simulation from Stenning to F.
Lemma 22.2 implies the main correctness result for the Stenning protocol, given in the following theorem.
It says that the Stenning protocol with lossy reordering channels guarantees reliable FIFO message delivery.
In addition to being interesting on its own, the ABP has for many years served as a standard example for demonstrating the use of various protocol verification techniques.
Then P2 accepts each subsequent message exactly if its tag is different from the tag of the message previously accepted.
When P1 receives an acknowledgment for its current tag, it moves on to begin processing the next high-level message.
A B P 2  a u t o m a t o n  ( f o r m a l ) :
The A B P  requires channels with s t ronger  reliabil i ty condit ions than  those we.
Tha t  is, they allow l imited loss, finite duplicat ion,  and no reordering.
As before, the allowed channel behavior  is specified using a combinat ion  of a.
Our strategy for proving the correctness of ABP is to relate it to the Stenning protocol using a simulation relation.
In this simulation, we consider the Stenning processes in combination with lossy FIFO channels rather than the more general lossy reordering channels we considered in Section 22.2
Now we can relate the ABP and the Stenning protocol.
Specifically~ if s and u are states of A B P  and Stenning, respectively, then we define (s, u) c f exactly if.
It is straightforward to show that  f is a simulation relation.
Most of what we must show follows immediately from the definition of f and the transitions of A B P  and Stenning.
In particular, for each receive step of A B P  in which the message is accepted, we must argue that  the corresponding receive step of the Stenning protocol also causes the message to be accepted.
Lemma 22.4 can be used to show that  this must be the case.
Just producing a simulation relation is not enough to show the liveness properties, however.
But, actually, it turns out that  f is stronger than an ordinary simulation relation: it maps each step of A B P  to a step of the Stenning protocol with the same type of action.
In fact, the actions are identical, except where the Stenning action contains an integer k and the corresponding A B P  action contains the low-order bit b.
Now fix a as in the hypothesis of the theorem.
States in the same positions in a and c~' are related by f.
Lemma 22.5 implies the following technical lemma for the ABP.
It says that any fair execution of the A B P  protocol whose channel behavior is allowed by the specification of a lossy FIFO channel exhibits reliable FIFO message delivery.
Lemma 22.6 in turn implies the main correctness result for the ABP, given in the following theorem.
It says that the A B P  with lossy FIFO channels guarantees reliable FIFO message delivery.
I n f in i t e  d u p l i c a t i o n.
Note that the A B P  still works with slightly more general channels that allow infinite duplication.
These channels still do not reorder messages, and losses are limited by the WLL condition.
So far, we have seen that it is possible to achieve reliable FIFO communication in the presence of limited loss, finite duplication, and arbitrary reordering of lowlevel messages, using the Stenning protocol with unbounded tags.
With bounded tags, using the ABP, it is possible to tolerate limited loss and finite duplication, but not reordering.
In this section, we consider the question of whether it is possible to design bounded tag protocols that tolerate reordering of low-level messages.
Consider first what goes wrong when the ABP is used with channels that can reorder low-level messages: process P2 can get fooled into accepting an old high-level message m that happens to arrive tagged with the same bit as the one currently expected.
This behavior can cause duplicate delivery to U2 of the same high-level message, violating the requirements for reliable communication.
Thus, we see that the ABP does not work with channels that can reorder low-level messages, but of course this does not imply that there cannot be other bounded tag protocols that do tolerate reordering.
First, in Section 22.4.1, we show the nonexistence of bounded tag protocols that tolerate both reordering and duplication.
Next, in Section 22.4.2, we present a bounded tag protocol that tolerates loss and reordering, but not duplication.
Finally, in Section 22.4.3, we prove the nonexistence of "efficient" protocols that tolerate loss and reordering.
This implies that the high complexity of the protocol in Section 22.4.2 is unavoidable.
Throughout this section, we formalize the notion of a "bounded tag" protocol by simply assuming that the high-level message alphabet M and the low-level message alphabet M ~ are both finite.
We show that there is no protocol that solves the reliable FIFO communication problem using channels that can both reorder and duplicate low-level messages.
For convenience, we now base our formal statement on axiomatic specifications of the allowed channel behavior.
We need some general terminology to describe the interaction between process automata and channel trace properties.
Formally, there is a cause function as in Section 14.1.2 that is onto, and finitely many to one.
Let Q2,1 be the analogous trace property, for the opposite channel direction.
The following theorem says that there is no bounded tag protocol that guarantees reliable FIFO message delivery using channels that can reorder and duplicate messages.
First, we run the system as far as we can, until it is no longer possible for process P1 to send any additional low-level messages with new values.
This construction can be carried out by successive extension, where we at tempt to send a new low-level message in each extension until we can no longer do this; the finiteness of the low-level message alphabet M ~ implies that this construction must eventually terminate.
Suppose there are n (user-interface) SEND events in Ct I.
Now we construct a finitely consistent execution c~4 with the following properties:
The additional events of P2 might include receive events, send events, and internal events, as well as the required R E C E I V E  events.
To complete the contradiction, we extend a4 to a fair, consistent execution without introducing any new SEND events.
The resulting execution has more RECEIVE events than SEND events, contradicting the correctness conditions.
Thus, if the channels permit  finite duplication and arbi t rary reordering of.
Although it is far from obvious, it turns out that it is possible to tolerate loss and reordering of messages (though, of course, not duplication), using bounded tags.
We present an algorithm, the Probe algorithm, that accomplishes this.
The Probe algorithm is not a practical communication protocol; it is a counterexample algorithm whose main purpose is to show that there can be no impossibility proof for the task in question.
This algorithm is most easily presented in two layers, combined using I/O automaton composition.
More precisely, each intermediate channel satisfies an axiomatic specification in terms of a cause function as in Section 14.1.2
In this case, the cause function is required not to reorder messages, but to satisfy the WLL loss limitation condition.
Layer 2 uses the resulting FIFO channels to implement reliable FIFO communication.
Also, each channel in the complete algorithm must be "multiplexed" to implement one channel of each Layer 1 implementation.
Layer 1, which involves implementing the intermediate channels in terms of the given channels (which can lose and reorder messages but not duplicate them) is more dimcult.
The justification for this is that the intermediate channel being implemented is permitted to lose some high-level messages, anyway.
In this description, we use M for the high-level message alphabet of the Layer 1 protocol.
Formally, their specifications are given in terms of a cause function, as in Section 14.1.2
In this case, the cause function is required to be one-to-one but need not be onto or monotonic.
Therefore, at least one of the messages containing m must have been sent by P1 since the preceding RECEIVE event.
This implies that rn must have been the value of latest1 at some point after the preceding RECEIVE event.
It remains to show that I1,2 guarantees the WLL condit ion-- that  if there are infinitely many SEND events, then infinitely many of them must have corresponding RECEIVE events.
This is enough to imply that the RECEIVE events must correspond to infinitely many different SEND events.
Each channel is "multiplexed" to implement one channel of each of the two Layer 1 protocols.
Formally, the channel specifications are given in terms of a cause function, as in Section 14.1.2
Namely, each channel of the complete Probe protocol must satisfy the WLL condition for each of the two channels it implements.
We do something simpler and more conservat ivewe require the SLL condition.
This actually guarantees SLL for each of the two implemented channels.
See Exercise 14.7 for a description of the channel multiplexing strategy.
Now the channels are any I /O automata (with the appropriate external interfaces) whose fair traces satisfy these new channel specifications.
The following theorem says that the full Probe protocol, with the given nonduplicating SLL channels, guarantees reliable FIFO delivery.
Note that the SLL condition for each of the given channels implies the weaker WLL conditions for each of the two Layer 1 channels it implements.
We do not attempt a formal complexity analysis of the Probe protocol (nor for the other protocols in this chapter)
However, notice that the Probe protocol has a serious complexity problem: it can require more and more low-level messages to deliver later and later high-level messages.
In the following subsection, we consider whether it is possible to avoid this cost.
We have just described the Probe protocol, which implements reliable FIFO communication using channels that can lose and reorder, but not duplicate, messages.
In this section, we show that any protocol that accomplishes this must incur the sort of cost that the Probe protocol exhibits, requiring more and more low-level messages to deliver later and later high-level messages.
As for our previous impossibility result, Theorem 22.8, we base our formal statement on an axiomatic characterization of the trace properties defining the allowed channel behavior.
Let Q2,1 be the analogous trace property, for the opposite channel direction.
Then we just say that executions are consistent and finitely consistent, without explicitly mentioning the channel trace properties.
The Probe protocol works (i.e., implements reliable FIFO communication) using any channels satisfying these specifications.
We show that any protocol that does this must be costly, in terms of the number of low-level messages needed to deliver later high-level messages.
To do this, we need a precise definition of cost.
The following definition expresses the idea that, in order to successfully deliver any high-level message, the protocol only needs in the best case to send a bounded number of low-level messages.
A protocol is message-bounded if it is k-message-bounded for some k C H +
Thus, a message-bounded protocol satisfies only a very minimal  requirement.
Suppose that  we could produce a mult iset  T of elements of M' ,  a complete.
In this case, we could derive a contradict ion as follows.
The multiset of messages that are sent but not received is uniquely determined by the execution c~
Thus,  it would be enough to manufacture  this bad situation.
P2, then either the bad si tuat ion already exists, or else we can increase T to a.
This says that T is a proper submultiset of T', that is, that there is at least one more copy of at least one element of M' in T' than there is in T.
Fix an a rb i t ra ry  m E M and obtain a k-extension.
Then there is some p E M ~ for which the number of new.
Then the multiset  T' of low-level messages is in t rans i t.
The results presented so far in this chapter  settle pre t ty  much every quest ion.
If a process crash amounts  simply to stopping and a subsequent  recovery involves simply resuming where the process.
In this section, we consider the reliable F IFO communicat ion problem in the.
The first thing that  is normally done when a processor recovers is that.
In Section 22.5.1, we show the impossibi l i ty  of implementing,  in the presence.
In Section 22.5.2, we give a second impossibi l i ty  result, this t ime.
Throughou t  this section, we assume that  each process Pi has an addit ional input  action CRASHi and an addit ional  ou tput  action RECOVERi, this latter considered to comprise a new task.
The occurrence of a CRASHi is assumed to enable a corresponding RECOVERi and to disable all other locally controlled actions until a RECOVERi occurs.
It follows that  such a RECOVERi must eventually occur, in any fair execution of Pi.
We assume that,  in the interval between a CRASHi and the next RECOVERi, any inputs that  occur (including addit ional  CRASHi events) have no effect on the state.
We consider the case where the RECO VERi action sets the entire state of process Pi back to an a rb i t ra ry  s tar t  state.
Thus, in this case, a CRASHi and subsequent RECO VERi cause all state information to be lost.
Assume for the purpose of obtaining a contradict ion that  there is such.
The basic idea of the proof is that  after a crash of P2, the protocol is.
Let c~1 be any fair execution of the protocol in which a single SEND event occurs but  no CRASH event occurs.
Notice that  the proof of Theorem 22.13 still works in a s tronger model in.
Theorem 22.13 suggests that the problem statement that we have been using is too strong for the setting with crashes.
The logical thing to do is to try to weaken the problem statement in order to obtain a version that can be solved in this setting.
Unfortunately, it turns out that even when the problem statement is weakened quite a lot, the problem still cannot be solved.
In this section, we present an impossibility result for a much weaker version of the problem.
The crash model we use is the same as in Section 22.5.1--in particular, all state information is lost when a process crashes.
We weaken the problem statement by requiring less at the external interface.
Namely, the channel to be implemented permits no duplication but does allow reordering.
For losses, we now only require that a message be delivered if its SEND event has no following R E C O V E R  event.
But if there are only finitely many such events, any message sent after the last R E C O V E R  must be delivered.
We use B to denote this specification (formally, a trace property)
We also weaken the problem statement by assuming more about the channels to be used in the implementation.
All the channels can do is lose messages, with losses limited by the SLL condition.
Now we say that an execution of a protocol is consistent or finitely consistent to mean that it has these properties for both of the specific channels.
This means that T is any subsequence of the sequence of messages that have been sent since the sending of the last message that has already been delivered (for some cause function)
A consequence of this definition is that any sequence T of messages in transi t  is a possible sequence of messages that might next be delivered by the channel, even if there are no further send events.
In the proof, we use the notat ion i to denote the opposite process to i, that.
Assume for the purpose of obtaining a contradict ion that  there is such.
The sequence out(a, i) is in transit f rom Pi to ~
The proof is by induction on the number  of steps.
Then let a l be the longest prefix of a that  ends with a step of P~
Note that  a l  is a proper prefix of a,  because we have assumed that  the.
Then by inductive hypothesis, there is a finitely consistent execution c~ at the end of which the following hold:
The sequence out(cA1, i) is in transit  from P / t o  Pi.
First, a CRASHi and a RECO VERi occur, returning Pi to its initial state in c~
Then Pi runs on its own exactly as it does in c~, extracting low-level messages from the incoming channel as needed.
This brings the state of Pi to state(a, i) and puts the needed low-level messages, those in out(a, i), in the outgoing channel.
More precisely, there are no following SEND, RECEIVE, CRASH, or RECOVER events, and there are no unmatched CRASH events.
Again, the needed input sequence in(a, 1) is in transit  in the incoming channel.
Theorem 22.14 says that it is impossible to solve even a very weak version of the reliable FIFO message-delivery problem, if we have to contend with crashes.
In spite of the impossibility results given in the last two subsections, it is important  in practice to have message-delivery protocols that guarantee some sort.
This protocol is the standard method for setting up network connections, used in TCP, ISO TP-4, and many other t ransport  protocols.
We use the word "packet" in this subsection synonymously with "low-level message."
In fact, it guarantees more, in that it does not reorder messages.
It tolerates not only process crashes, but also a wide range of channel failures.
Why is it reasonable to model UIDs in terms of stable memory? The key property of UIDs is that no UID is ever generated twice, even if there is an intervening crash.
In the formal model, we can express this abstractly by allowing the protocol to remember, even after a crash, which UIDs have previously been generated, and to check that it never generates any of them a second time.
More specifically, we can keep a component used in the protocol state, containing all the UIDs that have ever been generated.
When the protocol chooses a new UID, it picks one that is not already in the used set.
The used set is assumed to survive crashes, that is, to reside in stable memory.
In reality, there are many different ways to generate UIDs--for  example, using a random number generator or a real-time clock.
However, it turns out to be simple and informative to model all these techniques formally by keeping the used UIDs in stable memory.
We permit the underlying channels to lose, duplicate, and reorder messages.
However, we permit only finite duplication, and the losses are limited by the SLL condition.
After accepting a message, /:'2 sends an acknowledgment packet of the form ("ack", u)
For convenience, we include a component used in each process state containing all the UIDs that have ever been generated by that process.
The used components are the only components to survive crashes.
Likewise, there are two situations in which P2 generates an ack packet.
In this latter situation, it is possible that P1 still has status = send and uid-u = u and that an ack packet may be needed to dislodge u.
Namely, the channels are allowed to lose, reorder, and duplicate messages, subject only to the SLL condition and the finiteness restriction on duplication.
The safety proper t ies - - tha t  the protocol does not reorder or duplicate messages- -are  fairly easy to see.
The tricky part  of the proof is the liveness argument.
It is not at all obvious that this algorithm continues to make progress, delivering successive messages to/-72
Again by channel liveness, eventually one of these ("cleanup", u) packets must arrive at P2
But then the same argument as above shows that this value of uid-v is also dislodged.
This can happen any number of times, but since we have assumed that the channels permit  only finite duplication, it can happen only finitely many times before a current needuid packet finally arrives at P2
Informally speaking, the protocol eventually "forgets" everything that has happened so far.
The instances of the protocol are combined using I /O automaton composition at each process.
In practice, the number of available UIDs is very large, but it is not infinite as we have been assuming.
For example, UIDs can be chosen to be successively increasing integers modulo n, for some very large number n.
It may be possible to assert this in a practical setting, because of known limits on the message-delivery time, local processing time, and rate of submission of high-level messages, or because of an explicit policy of discarding old packets.
Besides being an interesting and useful protocol on its own, the ABP has served as a test case for protocol verification techniques.
The simple impossibility result for reordering and duplication is derived from the work of Wang and Zuck [284]
An earlier protocol to solve the same problem, but without the modularity presented here, was developed by.
The two results are combined into a single paper [112]
Spinelli [268] also proved a number of other results about the implementability of reliable communication.
Baratz and Segall [41] showed how to tolerate crashes using a very small amount of stable data and also conjectured the impossibility result for the case without stable data.
The FivePacke tHandshake  protocol is one of a series designed by Belsnes [44]; the protocols in the series guarantee stronger correctness conditions and tolerate successively stronger types of faulty behavior on the part of the channels as additional packets are added to the exchange.
The FivePacke tHandshake  protocol is the standard protocol for setting up network connections, used in TCP, ISO TP-4, and many other transport protocols.
Specifically, if s and u are states of the Stenn ing  protocol and F, respectively, then we define (s, u) E f exactly if the following are true:
In particular, use the simulation and an execution correspondence to prove the fairness property.
Consider the Stenning protocol with the channels that are like the ones considered in Section 22.2 but that allow infinite duplication.
That  is, the code for automaton A in Example 14.1.2 is modified by removing the finiteness restriction on the effect of the send action.
Prove that f in the proof of Lemma 22.5 is a simulation relation.
Your new protocol should still use the same (FIFO) channels as ABP and should still implement F.
However, in your new protocol, P1 should be able to send the first p messages at the front of its buffer while waiting for an acknowledgment for the first message.
In terms of k, what is the largest value of p that you can achieve?
Show that the ABP still works if the channels are permit ted unlimited duplication of messages.
The channels still cannot reorder messages, and the losses are limited by the WLL condition.
Is Theorem 22.8 still true if the channels are constrained to make at most k duplicates of any low-level message, for some known bound k? We still assume that the channels do not lose messages, but are allowed to reorder them arbitrarily.
Fill in the details of the proof of Lemma 22.9
In particular,  give a careful definition of the cause function and show that it satisfies the required properties for the I1,2 specification.
Is the resulting protocol still correct? Prove that it is or give a counterexample.
However, if there are only finitely many CRASH and RECOVER events, then all messages after the first k that are sent after the RECOVER must be delivered.
As before, no duplication is permitted, but reordering is allowed.
Research Question: Answer the same question as in Exercise 22.16, but this time weaken the specification B some more, as follows.
Prove that, in this case, eventually both processes reach and remain in states that are the same as.
Assume that there is a process at each node of the graph, as usual, and a reliable FIFO send/receive channel on each edge.
The final part of this book consists of Chapters 23-25
These chapters contain algorithms and lower bound results for the partially synchronous model, in which system components have some information about timing, although not complete information as they do in the synchronous model.
Such partial information can provide a realistic model of the timing knowledge that is available in real distributed systems.
As usual, the first chapter, Chapter 23, contains our formal model.
These chapters represent the beginnings of what is likely to become an interesting new part of the theory of distributed algorithms.
The final three chapters of this book comprise a short introduction to the study of partially synchronous, or timing-based, distributed algorithms.
It turns out that there is an interesting class of models and algorithms between these two extremes, which we call partially synchronous.
In a partially synchronous systern, the components have some information about time, although the information might not be exact.
Partially synchronous models are probably more realistic than either completely synchronous or completely asynchronous models, since real systems typically do use some timing information.
However, the theory of partially synchronous systems is not nearly so well developed as the theories of synchronous and asynchronous systems.
The ideas that we present here are only the beginning of what we think will be a large amount of interesting research on the foundations of timing-based computing.
In this chapter, we give an introduction to models and proof methods for timing-based distributed algorithms.
We begin in Section 23.1 by presenting a timed automaton model that we call the MMT model after its discoverers, Merritt, Modugno, and Tuttle.
The MMT model is a simple variant of the I /O automaton model that is adequate for modelling most timing-based algorithms.
In order to use certain basic proof methods-- in  particular, the invariant and simulation methods--wi th  this model, we find it useful to be able to transform.
We present the GTA model in Section 23.2, along with the transformation from MMT au tomata  to GTAs.
In Section 23.3, we discuss verification techniques that  can be used with these models.
An MMT timed automaton  model is obtained by simply replacing the fairness conditions of the I /O au tomaton  model with lower and upper bounds on time.
Notice that  replacing the fairness conditions with just  upper bounds would not add any interesting power to the model, because upper bounds alone do not restrict the set of executions that  are produced by an I /O automaton.
In fact, throughout  the "asynchronous" chapters of the book, we have already been associating upper bounds with tasks of an algorithm, in order to analyze time complexity.
The usefulness of this analysis depends on the fact that  these bounds do not restrict the algorithm's behavior.
However, introducing both lower and upper bounds does give extra power, because this allows us to restrict the set of executions.
Indeed, for many timing-based algorithms, correctness depends crucially on the restrictions on executions that  are imposed by the time bounds.
We start  with an I /O au tomaton  A having only finitely many tasks.
A boundmap b for A is a pair of mappings, lower and upper, that  give lower and upper bounds for all the tasks.
That  is, the lower bounds are not allowed to be oc, the upper bounds are not allowed to be 0, and the lower bounds cannot be greater than the upper bounds.
An MMT automaton is an I /O automaton  A together with a boundmap for A.
Wha t  does it mean to satisfy the lower and upper  bound requirements? To.
The initial indices represent  the points at which we begin to measure the time.
Then, for every initial index r for a task C, we require that  the following.
The upper  bound condition says that,  from any initial index for a task C, if t ime.
We denote the set of t imed executions of B by texecs(B)
A state is said to be reachable in B if it is the final state of some finite t imed execution of B.
A d m i s s i b i l i t y -  If t imed execution a is an infinite sequence, then the t imes of.
If a is a finite sequence, then in the final state of.
The admissibi l i ty  condition says that t ime advances normally and that  processing.
In this book, we will focus mainly on the admissible t imed executions.
Note that  in an admissible t imed execution, an upper bound of oc for a task C does not  impose any requirement that  actions in task C ever occur.
This is somewhat different from what we did in the asynchronous chapters: In Section 8.6, we defined another notion of t imed execution which specified that  all tasks satisfied the fairness condition and, in addition, that  some of them satisfied upper time bounds.
Now we are dropping the fairness conditions entirely and just considering time bounds.
It is possible to define a version of the MMT model in which some tasks have time bounds and some have fairness conditions, but we will not do this formally in this book.
Instead, we will discuss the issue of combining time bounds and fairness conditions informally, when it arises in particular algorithms.
Some sort of admissibility condition is needed in any useful model for timingbased computing, in order to rule out some rather strange behavior, such as an automaton performing infinitely many outputs in a finite amount of time.
Although such executions make some formal sense, they are meaningless in reality and hard to think about.
A good model for t imed systems should make it possible to avoid thinking about this issue.
In order to describe the external behavior of MMT automata,  we define timed traces.
The admissible timed traces of B, which we denote by attracts(B), are the timed traces of admissible t imed executions of B.
They are especially good for modelling computer systems at a low level, since the task structure and associated time bounds provide natural  ways of modelling physical system components and their speeds.
However, they are somewhat less well suited for describing systems at a high level or for providing correctness specifications.
This is because their rather stylized conventions about tasks and bounds do not always provide the best "language" for expressing the desired behavior.
We define an MMT a u t o m a t o n  Di,j -- (Ci,j ,  b) based on the universal reliable FIFO send/receive channel automaton Ci,j of Example 8.1.1
The boundmap b of Di,j imposes an upper bound of d, where d is some fixed positive real, on the delivery time for the oldest message in the channel.
Di,j  is a formal description of a channel we have used frequently in the chapters.
This behavior is sometimes called Zeno behavior, in reference to Zeno's paradox.
In Zeno's paradox, the runner Achilles takes infinitely many steps, each successively shorter, approaching closer and closer to his goal (a tortoise) but never quite reaching it.
Thus, if rec denotes the single task of Ci,j, then we define b to be the pair (lower, upper), where lower(rec) = 0 and upper(rec) = d, for some fixed d C R +
On the other hand, the following are not admissible t imed traces of.
The first of these three sequences fails to be an admissible t imed trace because it is finite, yet the rec task is enabled at the end.
In general, any admissible timed execution that contains at least k send inputs must also contain at least k corresponding receive outputs, because the upper bound condition and the admissibility condition together imply the usual fairness condition for the rec task.
The second sequence fails to be an admissible t imed trace because it violates the upper bound condition.
The third sequence fails because it violates the admissibility condi t ion-- i t  does not allow time to increase beyond d, even though an infinite amount  of activity occurs.
Notice that we write the lower and upper bounds for each task in the form of a closed interval--we will use this convention frequently.
It is not  ha rd  to see tha t ,  in any t imed.
Moreover ,  if a t i m e o u t  occurs,  t hen  there.
P2, if no receive occurs,  t hen  a t i m e o u t  does in fact occur.
We define a s imple M M T  a u t o m a t o n  Race  with  two tasks,  m a i n  and.
The  m a i n  t ask  inc rements  a counter  coun t  as long as.
The m a i n  task has associated bounds  of ~1 and.
States: count E N, initially 0 flag, a Boolean, initially false reported, a Boolean, initially false.
Effect: reported = false count := c o u n t -  1 Effect:
In every admiss ible  t imed execut ion of Race ,  a r e p o r t  eventual ly  occurs.
In Section 23.3.3, we will sketch a proof  that  this r e p o r t  must.
We define compos i t ion  and hiding operat ions  for M M T  automata ,  analogous to those for I / O  au tomata.
However, unlike what we did for I /O automata,  we only define composition for a finite collection of MMT automata.
This is because an MMT automaton is only allowed to have a finite number of tasks.
For each task C of A, b's lower and upper bounds for C are the same as those of bi, where Ai is the unique component I /O automaton having task C.
We close this subsection with three basic results analogous to Theorems 8.18.3
These relate the admissible timed executions and admissible timed traces of a composition to those of the component MMT automata.
The first says that an admissible timed execution or admissible timed trace of a composition projects to yield admissible timed executions or admissible timed traces of the component automata.
I f  a e atexecs ( B ) , then a l Bi e atexecs ( Bi ) for every i C I.
The next theorem says that, under certain conditions, admissible timed executions of component MMT attomata can be pasted together to form an admissible timed execution of the composition.
The final theorem says that  admissible timed traces of component MMT automata  can also be pasted together to form an admissible timed trace of the composition.
The hiding operation for MMT automata  is defined in terms of the hiding operation for ordinary I /O automata,  as given in Section 8.2.2
As for I /O automata,  this operation simply reclassifies output actions as internal.
The timing restrictions in MMT automata  are specified by means of upper and lower bound conditions imposed on executions.
An alternative approach is to encode timing restrictions directly into the states and transitions of the automaton.
This approach has the advantage that  it allows some important state-based proof methods, such as the methods of invariant assertions and of simulation relations, to be used to reason about correctness and timing properties of timed systems.
In this section, we describe a second timed automaton model, which we call the general t imed automaton (GTA)  model.
General timed automata  have no "external" timing restrictions--all their time constraints are explicitly encoded into their states and transitions.
As we will show, MMT automata  can be viewed as a special case of general timed automata,  by encoding the timing restrictions.
There are GTAs that  are not MMT automata,  however; in fact, there are some GTAs that  exhibit behavior that  cannot be exhibited by any MMT automaton.
We assume a universal set of actions, including special time-passage actions v(t), t C R +
The t ime-passage action u(t) denotes the passage of time by the amount t.
A timed signature S is a quadruple consisting of four disjoint sets of actions: the input actions in(S), the output actions out(S), the internal actions int(S), and the t ime-passage actions.
Unlike I /O  automata  and MMT automata,  GTAs do not have tasks(A) components.
As before, we use acts(A) as shorthand for acts(sig(A)), and similarly in(A), and so on.
There are two simple axioms that A is required to satisfy:
Note that  if the sequence is finite, it must end with a state.
We denote the set of admissible timed executions of A by.
We will mainly consider the admissible timed executions, though we will also sometimes consider the finite timed executions, that  is, those that are finite sequences.
A state is said to be reachable in A if it is the final state of a finite timed execution of A.
The timed trace of a timed execution fragment a is the sequence of visible events in a, each paired with its time of occurrence.
The admissible timed traces of A, which we denote by attraces(A), are the timed traces of admissible timed executions of A.
Note that  an admissible timed trace of A can be finite, even.
So we define an equivalence relation on timed execution fragments that.
We say that  timed execution fragments a and a ~ are.
Example  23.2.1 A general  t imed a u t o m a t o n.
In particular, it has the same set of admissible timed t races.
D~,j simply encodes the timing restriction of Did--the upper bound of d on the time to deliver the oldest message in the channel-- into  its states and transitions.
When a send  event occurs, the queue is modified as before, but.
The code for the time-passage actions u(t) is writ ten in much the.
The effect of u(t) is simply to increase the current time now by t.
This may at first seem somewhat s t range- -a f te r  all, how.
Di,  j a u t o m a t o n :
It should not be hard  to see tha t  D~,j has the same set of admissible t imed traces as Di, j.
Example  23.2.1 should give you an idea of how M M T  a u t o m a t a  can be.
The GTA model  is more general t han  the M M T  a u t o m a t o n  model,  however.
The next example contains another  channel expressed as a GTA; it tu rns  out.
We describe another  GTA, D~t,j, t ha t  represents a reliable F IFO channel, but  this t ime the t ime bound  of d is required for every  message.
Input: s e n d ( r n ) i , j ,  m C M.
Output : rece ive (m)~ , j ,  m E M.
Effect: add (rn, n o w  + d) to queue.
Precondit ion: (rn, t) is first on queue,  for some t.
We claim (and leave it as an exercise to show) that there is no.
This could be interpreted to mean that D:~j is not physically implementable.
However, as we have seen in earlier chapters, D~j can be a convenient abstraction for use in analyzing the time complexity of algorithms when we do not want to bother considering the pileups.
The next example shows an anomaly: a GTA that has no admissible timed executions.
Although this is a strange situation, there is nothing in the general model that prevents this.
Consider a "process automaton" A that sends the same message m infinitely many times.
A a u t o m a t o n :
Output :  Time-passage: s e n d ( m )  v ( t ) ,  t E R +
Effect: Effect: las t  " -  n o w  + 1-now n o w  "-- n o w  + t.
In fact, things can be even worse--the definition of a GTA even allows timed automata that  have no time-passage steps at all!
The GTA model is not the most general model possible for timing-based computing.
For example, it has no features for expressing liveness properties (except for admissibility)
Liveness considerations are somewhat less important in the timed setting than they are in the untimed setting, since many liveness conditions (e.g., a condition saying that something eventually happens) can be replaced by corresponding upper time bound conditions (e.g., a condition saying that the event happens within time t)
However, sometimes it is useful to be able to express both time bounds and livencss conditions for the same system.
The GTA model is also not general enough to provide detailed descriptions of hybrid systems--systems composed of analog physical components as well as discrete computer components.
However, the model is sufficient for our purposes in this book.
We have spoken of the general timed automaton model as a generalization of the.
However, this is not formally true, because of the different ways in which they specify timing restrictions: the MMT automaton.
In order to view the MMT model as a special case of.
In this section, we show how to transform any MMT automaton (A, b) into a naturally corresponding general timed automaton A~= gen(A,  b)
That is, it involves building time deadlines into the state and not allowing time to pass beyond those deadlines while they are still in force.
Specifically, the state of the underlying I /O automaton A is augmented with.
The f irst(C) and last(C) components represent, respectively, the earliest and latest times at which the next action in task C is allowed to occur.
The now, first, and last components all take on values that represent absolute times, not incremental times.
The first and last components get updated in the natural way by the various steps, according to the lower and upper bounds specified by the boundmap b.
The time-passage actions u(t) have an explicit precondition saying that time.
In more detail, the timed signature of A' = gen(A,b)  is the same as the signature of A, with the addition of the time-passage actions u(t), t C R +
I f  ( A , b )  is a n y  M M T  t i m e d  a u t o m a t o n ,  t h e n  g e n ( A , b )  is a g e n e r a l  t i m e d  a u t o m a t o n.
I f  C is enabled,  t h e n  l a s t ( C )  < n o w  + u p p e r ( C )
If some of the  t iming  requ i rements  specified by b are t r i v i a l - - t h a t  is, if some lower bounds  are 0 or some upper  bounds  are.
Example  23.2.4 Transformed M M T  a u t o m a t o n.
Let (A, b) be the  compos i t ion  M M T  a u t o m a t o n  descr ibed in Ex am p le.
We give explicit code for the  t r ans fo rmed  M M T  a u t o m a t o n  A ' -  g e n ( A ,  b)
A ~ a u t o m a t o n :
We say that  a collection of GTAs is compatible if their t imed signatures are compatible.
Also, we are here using the notat ion si to denote the i th component of the s tate  vector s.
Note that this implies that all the components participate in t ime-passage steps, with the same amount  of time passing for all of them.
For a given compatible collection of MMT automata,  it turns out that it does not mat ter  whether we compose first and then apply the gen t ransformation to the composition, or first apply the gen transformation to the components and then compose.
The resulting GTAs are the same, up to isomorphism (of the reachable portions of the machines)
The first pasting theorem, Theorem 23.8, has a small technicality that is a consequence of the fact that the GTA model allows consecutive time-passage steps to appear in an execution.
Namely, the admissible timed execution a that is produced by "pasting together" individual admissible timed executions ai might not project to give exactly the original ai's, but rather admissible timed executions that are time-passage equivalent to the original ai's.
If A is a GTA and (I) c_ out(A),  then hider is the GTA that is identical to A, except that the actions in (I) are reclassified as internal.
The correctness of timing-based algorithms and systems, as well as their performance, often depends critically on timing assumptions.
Unlike in the asynchronous setting, drastic changes of behavior of timing-based algorithms can result from small changes in timing assumptions.
However, reasoning about this timing-dependence can be extraordinarily difficult, even for extremely simple "algorithms" such as those in the examples in this chapter.
Systematic proof methods can be a great help in this setting.
In this section, we describe two important proof techniques for timing-based algorithms: the method of invariant assertions and the method of simulation relations.
Since these methods have been used so successfully in the synchronous and asynchronous settings, it is natural to try to adapt them for use in the timing-based setting.
We also define a notion of timed trace property, analogous to the notion of trace property introduced in Section 8.5.2
We define an invariant assertion for a general timed automaton A to be any.
This definition is formally the same as the one we used in the asynchronous.
But there is a difference: In an asynchronous system, the state typically consists of ordinary data such as the values of local and shared variables and.
Although the type of information included in the state is richer in the timed.
This time, the induction is on the number of steps in a timed execution leading to the.
Note that we present the method of invariant assertions in the context of.
It would be nice to prove that the system only.
The following invariant assertion can be used to prove this.
Then we prove the following strengthened version of Assertion 23.3.1, by a not-so-trivial induction.
Notice that this assertion involves statements about the first and last time components of the state.
Thus, some claims about  the t iming of events are concisely formulated as invariants, using the f irst  and last deadline components  of the states.
Assertion 23.3.3 can be proved by induction on the number  of actions in a t imed execution.
The argument  is s traightforward (in fact, boring), but  we include it here because it provides a good model for other such proofs.
Inductive step: As usual, we carry out a case analysis based on.
In the latter case we are done, so assume the former.
This s tatement is unaffected by the step, so Condition 1 holds.
So t imeou t  is not enabled in s, which says that this case cannot arise.
By the precondition of decrement ,  the last of these is impossible.
This follows because the second term is decreased by exactly gl, while the first term is increased by at least gl.
Recall that many of the properties to be proved for asynchronous systems can be naturally formulated as properties of their traces or fair traces.
Propert ies  tha t  can be specified in this way include performance properties as well as ordinary correctness properties.
A timed trace property P is defined to consist of the following:
We will usually interpret  the s ta tement  tha t  a GTA A satisfies a trace property P to mean tha t  i n ( A ) -  in(P) ,  o u t ( A ) -  out(P) and attraces(A) c_ ttraces(P)
Let P be the t imed trace proper ty  defined as follows.
Output: Time-passage: timeout ~,( t ) , t C R +
If there is a tirneout pair in 3, then there is no preceding receive pair.
The simulation method can be used for reasoning about  t iming-based systems as well as synchronous and asynchronous systems.
To do this, we define the notion of a "timed simulation relation" between states of two general t imed au tomata.
The definition is very similar to the definition of a simulation relation for I /O au toma ta  in Section 8.5.5
Let A and B be two general t imed au tomata  with the same input  and output.
If s E start(A),  then f (s) N start(B) # O.
If s is a reachable state of A, u E f ( s )  is a reachable state of B, and (s, :r, s') E trans(A), then there is a t imed execution fragment  c~ star t ing with u and ending with some u ~ E f ( s ' ) ,  such that.
Thus, the s tar t  condition is the same as for a simulation relation for I / O  automata.
The step condition is a little d i f ferent - -now we require that  the correspondence preserve the t imed trace, that  is, the sequence of visible actions, each paired with its time of occurrence, plus the total  amount  of t ime-passage.
Note that  in the step condition, 7r can be a t ime-passage action as well as a discrete action.
As before, since the states s and u in the step condition are assumed to be reachable, invariant assertions about  the states of A and B can be used in a.
The following theorem gives the key proper ty  of t imed simulation relations.
In the rest of this section, we give examples to show how t imed simulations can be used to prove propert ies of t imed systems.
This can be done by formalizing the t iming specification as a GTA, B, with last and first deadline components  expressing the required t iming behavior (upper and lower bounds,  respectively)
A, with last and first components representing the timing assumptions.
The existence of a t imed simulation from A to B then implies that  A satisfies the timing requirements.
Since simulations can be used in the t imed setting to prove timing properties, the simulation method is more powerful in the timed setting than it is in the asynchronous setting.
In the asynchronous setting, we are often interested in liveness properties, whereas in the t imed setting, we are more often interested in time bounds.
Formal proofs of liveness conditions often use extra machinery such as temporal  logic in addition to simulations, but time bounds can be proved just using simulations.
To simplify matters,  we define a variant A of/='2 that  does not even have a receive action in its signature.
A u t o m a t o n  A s imply  counts  down from k to 0 and  then  per forms.
Informally,  it is easy to see t h a t  a single t i m e o u t  occurs.
This  G T A  is of the  form g e n ( B ) ,  where  B is the  following t r ivia l.
Now we produce a t imed simulation relation f from gen(A)  to g e n ( B ) ,  thereby showing tha t  A satisfies the t iming requirements.
If s and u are states of gen(A)  and g e n ( B ) ,  respectively, then we define (s, u) C f provided tha t  the following conditions hold:
The relationships involving the now and s tatus  values are straightforward.
The interesting relationships involve the last and f irst  deadlines.
This quant i ty  is a calculated upper  bound on the last t ime when a t imcou t  action might be performed by gen(A)
On the other hand, if c o u n t -  0, then this time is bounded by the last time at which the tirneout can occur.
The inequality expresses the fact that  this calculated bound on the actual  time until t imeout is at most equal to the upper  bound to be proved.
The interpretat ion of the f irs t( t imeout)  inequality is s y m m e t r i c ~ the values of f irs t( t imeout)  should be no larger than a calculated lower bound on the earliest time until a t imeout action is performed by gen( A )
In order to prove that  f is a t imed simulation, we first prove an easy invariant.
Then the proof proceeds in the usual way for simulations, verifying the s tar t  condition and the step condition.
The inequalities are t rea ted  in just  the same manner  as any other type of relation between the states.
As in Example  23.3.1, we include some details as a model for other such proofs; the rest of the details are left for an exercise.
For the s tar t  condition, let s and u be the unique s tar t  states of gen(A) and gen(B),  respectively.
We must show that  u E f ( s )
For the step condition, we suppose that  (s, :r, s') E t rans(gen(A)) , s is reachable, and u is a reachable state in f ( s )
We consider cases based on types of actions, including t ime-passage actions.
The fact that  u E f ( s ) means that  s .now = u.now; s.status = u.status; u.
It suffices to show that  u E f ( s ' )
This means that  the inequality still holds after the step.
Other arguments in the same style can be made for the other types of actions.
This inequality holds because the precondition of Condition 4 implies that  u.
Time-passage steps do not change anything mentioned in the definition of f except for now, so it is easy to see that  they preserve all the relationships in f.
Of course, there are other ways to prove time bounds for timingbased systems besides using timed simulations.
With in  time g, the int task sets the flag to true.
Now we define a t imed simulation relation g from gen(Race) to gen(B')
If s and u are states of gen(Race) and gen(B') ,  respectively, then we define (s, u) C g provided that  the following conditions hold:
If flag = true, then the time remaining until report is just  the time for the main task to do the remaining decrement steps, followed by the final report.
The same reasoning holds if flag is still false, but must  become true before there is t ime for another  increment  to occur, that  is, if s.
Otherwise, s.flag = false and s.first(main) < s.last(int), which means that  there is time for at least one more increment to occur.
Then the first case of the inequality for last(report) applies.
The proof that  g is a t imed simulation relation follows the same general outline as the proof in Example 23.3.3
We close this chapter by indicating how partially synchronous shared memory systems and partially synchronous network systems can be modelled using MMT automata  and GTAs.
We model a partially synchrononous shared memory system as an MMT automaton (A,b)
Here, we assume that  I /O automaton A is an asynchronous shared memory system, according to the definitions in Chapter 9; the only new constraint is that  A has only finitely many tasks.
In this case, we will write L = g2/gl; aS before, L is a measure of the timing uncertainty in the system.
In the partially synchronous setting, we will only consider send/receive networks, not broadcast or multicast networks.
We assume an underlying directed graph G = (V, E)
We model a partially synchronous send/receive network system as a collection of process automata,  one for each vertex, plus a collection of channel automata ,  one for each edge.
The process automaton associated with each vertex i is an MMT automaton Pi.
Pi has input and output actions by which it communicates with the external users, plus outputs of the form send(m)i,j, where m is a message and j is an outgoing neighbor, and inputs of the form receive(m)j,i, where j is an incoming neighbor.
To model process stopping failures, we include a stopi input action.
The effect of this action is to permanently disable all tasks of Pi.
The channel automaton associated with each directed edge (i, j)  is a GTA Ci,j.
Its "visible interface" consists of inputs of the form send(m)i,j and outputs of the form receive(m)i,j.
Restrictions on the external behavior of a channel are expressed by a timed trace property P; the channels defined by P are those GTAs whose visible actions are the same as those of P and whose admissible timed traces are in ttraces(P)
Again, we will write L = ~2/~1 and use L as a measure of the timing uncertainty in the system.
The MMT timed automaton model was designed by Merritt, Modugno, and Tuttle [227]
Their model is somewhat more general than the one we use in this book, in that they allow eventual upper bounds as well as real-valued upper bounds.
The variant of the model we use here is close to the one defined by Lynch and Attiya [215]
The two-task race example was suggested by Pnueli [243] as a test case for proof methods for timing-based systems.
Issues involving the existence of admissible timed executions are studied by Gawlick, Segala, Sogaard-Andersen, and Lynch [136]
The transformation from MMT automata to general timed automata was developed by Lynch and Attiya [215]
The operations for GTAs are derived from [212]; that paper describes many other operations on GTAs besides composition and.
The simulation method of proving timing properties was first used by Lynch and Attiya [215]
Let (A, b) be any MMT automaton and let c~ be any finite timed execution of (A, b)
There is an (admissible) timed execution of (A, b) that  starts with c~
Suppose that the definition of an MMT automaton were weakened to allow countably many tasks instead of only finitely many.
Show that there exists an automaton (A, b) satisfying this new definition that  has no (admissible) timed executions.
Analyze the communication and time complexity of the resulting algorithm.
Moreover, A should, in various admissible t imed executions, allow for a and b to occur at any time, subject to the given limitations.
Prove that there is no MMT automaton with the same set of admissible t imed traces as A.
The style of your code should be similar to the code in Example 23.2.4
Show that the simpler restatement of Theorem 23.8, asserting that ai = alBi rather than just  that they are t ime-passage equivalent, is false.
Prove the following mult ipart  invariant of the system A' of Example 23.2.4
Prove that the relation g defined in Example 23.3.4 is a timed simulation relation.
In this chapter, we visit the mutual exclusion problem for the third time, this time in the partially synchronous shared memory setting.
We present only very basic results: simple timing-based algorithms and their analysis, and simple impossibility results.
This time, however, the users and the shared memory system are modelled as MMT automata, as defined in Section 23.1, rather than as I /O automata.
Figure 10.4 can still be used to represent the architecture we consider in this chapter.
As before, each user Ui is required to preserve well-formedness.
Formally, each MMT automaton Ui is of the form (Ai, bi), where Ai is any I /O automaton that was allowed in Section 10.2 and that has only finitely many tasks, and bi is an arbitrary boundmap.
The rest of the system consists of a single MMT automaton B = (A,b) representing the shared memory system.
The underlying I /O automaton A is of the form we considered in Chapter 10 for solving the mutual exclusion problem in the asynchronous shared memory model.
In particular, it consists of n processes, one per port.
We assume throughout this chapter that each process has just one.
As before, we write L = g2/t~l; L is a measure of the timing uncertainty in the system.
We make three other restr ict ions in this chapter.
First ,  we restr ict  process activity in the same way that  we did in Chapter  10: the single task of each.
Second, we assume that  the single task of process i is in fact always enabled when Ui is in the t rying or exit region.
However, we allow the possibili ty that  the only action enabled might  be a dummy action that causes no state changes.
Third,  we only consider shared memory  systems with r ead /wr i t e  shared variables.
Resta t ing them for t imed automata ,  we have.
We say that  B solves the mutual exclusion problem provided that  it solves it (i.e., guarantees  well-formedness, mutual  exclusion, and progress) for every collection of users.
These correctness conditions could alternatively be formulated in terms of a t imed trace proper ty  P ,  as defined in Section 23.3.2
In this section, we present  a part ial ly synchronous mutual  exclusion algori thm, the FischerME algorithm, that  uses only a single r ead /wr i t e  register.
XAs in Section 23.1, this is defined to mean that time passes normally and that processing does not stop if there is more work to be done.
The starting point for the algorithm is the following incorrect asynchronous algorithm.
Incorrec tF i scherME algorithm (informal): The algorithm uses a single read/wri te  shared variable turn, writable and readable by all processes.
After it finds turn = 0, process i sets turn equal to its own index i.
Then it checks that turn is still equal to i.
In the style used for shared memory programs in Chapter 10, this is written.
The IncorrectFischerME algorithm is incorrect in that it fails to guarantee mutual exclusion.
We know that it must be incorrect, because otherwise it would violate Theorem 10.33
In order to avoid this bad interleaving of events, we can add a simple timing.
Namely, any process i that sets t u r n  := i can delay its check of t u r n  for longer than time g2, the assumed upper bound on process step time.
All other steps proceed at the normal rate, with some time in the interval [gl, g2] between successive steps of the same process.
This restriction prevents the bad interleaving in Figure 24.1 as follows: Any process i that sets t u r n  := i is made to wait long enough before checking to ensure that any other process j that tested t u r n  before i set t u r n  (and therefore might subsequently set t u r n  to its own index) has already set t u r n  to its index.
That  is, there will be no processes left at the point of setting turn ,  when i finally checks.
This is technically not permit ted by the model, which only allows one task per process, with bounds [gl, g2]
A c t i o n s  o f  i: Input: Internal:
Effect: Effect: if turn  = 0 then pc := set pc := reset.
Effect: Effect: turn  := i turn  := 0 pc := check pc := leave-exi t.
We consider the FischerME algorithm together with any collection of users.
For the mutual exclusion property, we wish to prove the following invariant of the combined system (algorithm plus users)
As usual, proving this assertion by induction requires auxiliary invariants.
Now, however, we need auxiliary invariants that involve time information as well as ordinary program variables.
Therefore, we transform the system into a general timed automaton (GTA), as described in Section 23.2.2
This transformation encodes all timing constraints into the states and transitions of the system rather than expressing them as "external" restrictions on timed executions.
We consider Assertion 24.2.1 and the other assertions below as properties of the state of the GTA obtained by this transformation.
The key claim, which can be proved by induction, is the following.
It says that the earliest future time a successful checki can happen is after the setj of any other process j that has already passed the test testy.
This lemma is used to rule out the bad interleaving in Example 24.2.1
Assertion 24.2.2 can be proved by a simple induction on the number of steps in a timed execution leading to the state in question.
Here, the steps include time-passage steps as well as ordinary input, output, and internal steps.
See Example 23.3.1 for a model of how such proofs proceed.
Here, the indices i and j are the ones that appear in the assertion.
Assertion 24.2.2 can be used to prove the following assertion.
This one says that if a process i is in the critical region (or just before it or just after it), then t u rn  = i and no other process can be about to set turn.
Suppose that there is some j such that s ~.pcj - set.
It follows that there is no j such that s ~.pcj - set.
For this, it is useful to have one more invariant, this one proved by an easy induction.
That is, consider an admissible timed execution a that reaches a point where there is at least one user in T and no user in C and suppose for the sake of contradiction that, after this point, no user ever enters C.
Then we can show that eventually in a, no further region changes occur, every process is in T or R, and some process is in T.
Then we can argue (using Assertion 24.2.4) that eventually turn acquires the index of a contender (i.e., a process in T)
Then, subsequently, turn must always be equal to some contender's index, although it may change to the index of different contenders.
However, eventually turn stabilizes to a final (contender's) index, say i.
Again using Assertion 24.2.4, we argue that, subsequently, process i enters C.
The time from any point when any process i is in the exit region until process i is in the remainder region is at most 2~2
For the trying region bound, we could use an operational argument, but for variety, we give a proof using a timed simulation, as described in Section 23.3.3
Notice that the proof of progress for FischerME (in the proof of Theorem 24.1) is based on the execution reaching certain "milestones"--for example, the "seizing" of the turn variable by some contender and the "stabilizing" of the turn variable to some particular contender's index.
We incorporate these milestones, together with their time bounds, into an "abstract mutual exclusion algorithm" B.
We then show the time bounds for FischerME using a simulation from FischerME to B.
The n o w ,  user, and region correspondences  are all s t ra ight forward.
If t u r n  is equal  to the index of a.
If turn is equal to the index of a competitor and no process is still able to set turn, then the competition has status stab.
The second inequality for seize says that if turn = 0 (which implies that no process is at crit or reset), then the time until the turn variable is seized is determined by the minimum of a set of possible times, each corresponding to some candidate process that might set turn.
For instance, if pci = s e t - - t ha t  is, if process i is about to set t u rn - - then  the corresponding time is just the latest time at which it can take its next step; however, if pci = t e s t - that is, if process i is about to test the variable-- then the corresponding time is an additional t~2 after the test occurs.
In this simulation, each external step of the FischerME system simulates a corresponding external step of the B system.
A set step that changes turn from 0 to a process index simulates seize, and a set step that leaves no other processes at set simulates stabilize.
A set step that satisfies both of these conditions simulates both seize and stabilize (in that order)
Each other step simulates a trivial t imed execution fragment with no actions.
It follows from Theorem 23.10 that the admissible timed traces of the FischerME system are included among those of the B system.
But if L is not equal to 1, the time bound increases accordingly.
In fact, the real time t~2 in the time bound is multiplied by the timing uncertainty L.
The term of Lg2 arises in the FischerME algorithm as follows.
In order to be sure that  a certain amount of real time, say t, has elapsed, a process counts its own steps.
It must count enough steps so that  even if the steps take the smallest amount of time possible, gl, real time t must have elapsed; thus, the number of steps must be at least t /gl.
Roughly speaking, it requires real t ime Lt for processes in a system with timing uncertainty L to be sure that  real time t has elapsed.
In this sense, the time complexity is "stretched" by a factor equal to the timing uncertainty.
This stretching phenomenon has already appeared in the t imeout example in Example 23.1.4
We can consider a variant of the FischerME algorithm in which the only time constraints are a lower bound on the time from when a check action is enabled until it occurs, and an upper bound on the time for a set action.
Any enabled, locally controlled action other than a check action is just required to occur eventually.
It is not hard to see that  this variant still solves the mutual  exclusion problem.
This variant cannot be represented using the MMT model as we have presented it in this book; rather, it requires a version of the model allowing time bounds for some tasks and fairness conditions for others.
Of course, no time bounds can be proved for this version of the algorithm.
The correctness of the FischerME algorithm depends critically on timing restrictions.
Even its most basic correctness condition, mutual  exclusion, can fail to hold in a t imed execution in which the important  timing const ra in ts- - the lower bound of al for check steps and the upper bound of g2 for set steps are violated.
It would be nice to improve this algorithm so that  at least the mutual  exclusion condition is always satisfied, no mat ter  what happens to the timing.
As a general design principle, it is desirable for timing-based algorithms to guarantee their most crucial safety properties, regardless of t iming variations.
One idea for improving the FischerME algorithm in this way is to replace its critical region by the trying, critical, and exit regions of a second algorithm S.
Algorithm S should always guarantee the mutual  exclusion condition for its.
However, S should also not impede the progress of the FischerME algorithm when the timing constraints are satisfied.
We could let S be any asynchronous algorithm that solves the mutual exclusion problem (satisfying the well-formedness, mutual exclusion, and progress conditions), but, unfortunately, Theorem 10.33 implies that such an algorithm would require at least n shared registers.
Fortunately, we do not need such a strong progress condition for S; instead, we can use the following weaker progress condition.
Here, of course, the users and regions are those of the second algorithm S.
An example of an asynchronous algorithm S with the needed conditions follows.
It is similar to many of the other proofs of mutual exclusion algorithms in this book.
The combination of the FischerME algorithm and S can be described by the following code.
The FischerS code can be regarded as denoting either an asynchronous algor i thm or a partially synchronous algorithm.
When it denotes an asynchronous algorithm, we assume fairness conditions for all processes.
Well-formedness is easy, and mutual exclusion follows from the fact, claimed in Theorem 24.3, that S guarantees mutual exclusion.
We leave the determination of progress properties of FischerS for the exercises.
On the other hand, when the FischerS code denotes a partially synchronous.
The first task includes only the step where process i checks the value of turn, and the second task includes everything else.
The well-formedness and mutual exclusion conditions follow from Theorem 24.4
In this argument, R, T, C, and E denote the regions of the FischerS algorithm.
We also define the FischerME trying region to be the portion of T prior to label M, and define the S trying region to be the rest of T.
Likewise, we define the S exit region to be the portion of E before the assignment y := 0 and the FischerME exit region to be the rest of E.
We also define the FischerME critical region to be the combination of the S trying region, C, and the S exit region.
Suppose that at some point in an admissible timed execution, at least one user is in T and no user is in C.
On the other hand, assume that no process ever subsequently reaches the S trying region.
This means that the FischerME critical region is empty, so the progress condition for the FischerME algorithm implies that eventually some process enters the FischerME critical region.
But this means it enters the S trying region, which is a contradiction.
The first is a lower bound on the time required to solve the mutual exclusion problem in the partially synchronous model.
The second is an impossibility result for the case where time bounds are required to hold eventually.
But is it possible to do better? That is, does there exist a faster algorithm that solves the mutual exclusion problem in this model, still using only a constant number of variables? We give a simple result for the special case of one variable; the statement is closely related to that of Theorem 10.34
The proof of Theorem 24.6 uses an interesting argument involving "stretching" and "shrinking" timed executions, while still observing the timing constraints.
It is based closely on the proof of Theorem 10.34
Suppose for the sake of contradiction that there is such an algorithm, A, using a single shared register x.
We construct a timed execution of A that violates mutual exclusion.
It is possible to extend the lower bound in Theorem 24.6 to cases where there.
The FischerS algorithm solves the mutual exclusion problem (including the progress condition) if it runs partially synchronously, and it guarantees at least the.
Is it possible to guarantee progress under weaker conditions, for example, if the algorithm runs asynchronously for a while, but eventually starts to satisfy its timing constraints? It is not hard to see that the FischerS algorithm does not make this guarantee; we leave this for an exercise.
In particular, the main lemma is analogous to Lemma 10.37--i t  asserts the existence.
Formally, we would define an eventually timed execution of an MMT automaton and state this condition in terms of eventually timed executions.
No timing restrictions appear in the statement of this lemma.
The main lemma is proved by induction using the same construction as in the proof of Lemma 10.37
The only difference is that wherever the earlier proof used the general progress condition, we must now make do with the weaker "eventually time-bounded" progress condition.
Now, whenever we want to force processes to make progress, we simply begin running them in such a way that their timing constraints are satisfied from that point on.
This algorithm has been used recently as a test case for demonstrating the power of formal methods for reasoning about timing-based systems.
Proof of an improved time bound also appears in [201]
All the proofs for the FischerME algorithm have been checked by computer using the Larch theorem prover [202]
A sketch of a time bound proof for the DijkstraME algorithm appears in [204]
Alur and Taubenfeld [10] have obtained partially synchronous mutual exclusion algorithms with good time complexity in the face of a limited number of concurrent requests; their model and measure are somewhat different from the one used here.
Attiya and Lynch [25] have some upper and lower bound results for the time complexity of mutual exclusion in partially synchronous networks.
Their problem is different from the one considered here in that the system is not given explicit notification of when critical regions are completed.
Fill in the details of the operational proof of progress for Theorem 24.1
Show that the FischerME algorithm permits a process to be locked out.
Does the IncorrectFischerME algorithm satisfy the progress condition? Give a proof or a counterexample.
Fill in the details of the simulation argument in the proof of Theorem 24.2
Describe a timed execution of the FischerME algorithm that takes as long a time as possible from when some process is in T until some process is in.
Devise an alternative mutual exclusion algorithm for the partially synchronous shared memory model, using one read/wri te  shared variable.
Suppose that P has only a single task, with associated.
Prove that there is some admissible timed execution of P in which a is.
Do this by regarding this algorithm as an MMT automaton and using a timed simulation similar to the one in the.
Hint: Let I1 be the set of processes i such that x = i and i is about to set y.
Le t /2  be the set of processes i such that x = i and i is about to test x.
Let /3 be the set of processes that are either in, just before, or just after C.
Show that algorithm S does not guarantee progress (in the presence of concurrent requests)
Do this by giving an explicit execution in which the progress condition is violated.
Give an explicit execution of the FischerS algorithm regarded as an asynchronous algorithm, in which the progress condition is violated.
Give another algorithm that has all the correctness properties we claimed for the FischerS algorithm (i.e., it guarantees well-formedness and mutual exclusion when run asynchronously and progress when run partially synchronously), but that only uses two read/wri te  shared variables instead of three.
Prove that there is no algorithm that has all the correctness properties we claimed for the FischerS algorithm but that only uses one read/wri te shared variable instead of three.
Research Question: Design a timing-based algorithm that solves the mutual exclusion problem (guaranteeing well-formedness, mutual exclusion, and progress)
Moreover, it should satisfy all of the following time bound requirements:
Also try to generalize your result by designing another algorithm for the same problem, but this time generalizing the second requirement to one that asserts a good upper bound for progress in the trying region, in the case where there are at most k users concurrently outside of R.
Obtain a lower bound on the time for progress in the trying region in the partially synchronous model, for the case of two shared read/wr i te variables.
The lower bound will be of the form cL~2, where c is a small constant.
Give a part icular execution that demonstrates  that the FischerS algori thm does not satisfy the requirements listed in the statement of Theorem 24.7
Consider the solvability of the mutual  exclusion problem in the unknown time bound model.
That is, they can be different in different executions, though each execution observes fixed bounds throughout.
Prove an analogue to Theorem 24.7 for the unknown time bound model.
In this, the final chapter, we visit consensus problems for the fourth time, this time in the partially synchronous network setting.
It turns out that the results for consensus in the partially synchronous setting are quite different from those in either the synchronous or asynchronous setting.
We first present a basic algorithm and a basic lower bound, both derived from corresponding results for the synchronous setting; there is a gap in time complexity between these two results, based on the timing uncertainty.
Then we give a more difficult algorithm and a more difficult lower bound result that mostly close this gap.
We finish with some results for weaker timing models and a look ahead to some possible future work.
Each user U~ has init(v)i outputs and decide(v)i inputs, v E V.
Now Ui is an MMT automaton that performs at most one initi action in any timed execution.
A sequence of initi and decidei actions is well-formed for i provided that it is some prefix of a sequence of the form init(v)~, decide(w)i.
Wel l - formedness :  In any timed execution of the combined system, and for any port i, the interactions between Ui and A are well-formed for i.
Va l id i t y :  In any timed execution, if all init actions that occur contain the same value v, then v is the only possible decision value.
Failure-free t e r m i n a t i o n :  In any admissible failure-free t imed execution in which init events occur on all ports, a decide event occurs on each port.
Wait-free termination is defined to be the special case of f-fai lure termination where f = n.
We assume that A is a partially synchronous send/receive network system, as described in Section 23.4.2
Channels are assumed to be of the second type defined in Section 23.4.2, that is, reliable FIFO channels with an upper bound of d on the delivery time for every message.
We say that A solves the agreement problem if it guarantees well-formedness, agreement, validity, and failure-free termination for every collection of users.
We consider algorithms that guarantee f-failure termination for various values of f.
The question we consider is how much time it takes after the arrival of all inputs for all nonfaulty processes to decide.
We focus here on the role of L, the uncertainty parameter,  in this time complexity.
We need one more technical assumption: each process task of a non-failed process is always enabled (though the only action of the task that is enabled might be a dummy action that causes no state changes)
This assumption allows us to consider simple patterns of step times in our lower bound proofs.
A useful building block for the algorithms in this chapter is a "perfect failure detector" F.
We defined failure detectors for the asynchronous setting in Section 21.4
Recall that a failure detector has stopi actions as inputs and informstopped(j)i actions as outputs,  j ~= i.
A perfect failure detector is guaranteed to report only failures that have actually happened and to eventually report all such failures to all other non-failed processes.
The only difference here from Section 21.4 is that we no longer assume that a failure detector is an I /O automaton but, rather, that it is a general timed automaton (GTA)
We give a partially synchronous network system (in the model assumed in this chapter) that implements a perfect failure detector.
The idea is similar to that used in the timeout MMT automaton of Example 23.1.2
Each process Pi continually sends messages to all the other processes Pj, using one task per process.
If a process P/ performs a sufficiently large number m of steps without receiving a message from Pj, it records that Pj has stopped and outputs inform-stopped(j)i.
It should be obvious that all failures are eventually detected by all other non-failed processes.
This implies that time strictly greater than d + g2 passes without Pi receiving any messages from Pj.
The first says that a failure notification can only occur after more than time d has elapsed since a failure.
The second provides an upper bound on the time until failure notification occurs.
In any timed execution of PSynchFD containing both a stopj event and an inform-stopped(j)i event, the time from the stopj event until the informstopped(j)i event is strictly greater than d.
Consider an admissible timed execution of PSynchFD in which a stopj occurs, say at time t.
Then no message is sent from Pj to Pi after time t, so no message is received by Pi from Pj after time t + d.
After receiving the last message, the time for Pi to count m steps is at most rag2
It implies that when any process Pi times out another process Pj, it knows that all messages that were sent by Pj prior to its failure have already arrived at their destinations.
Since we are assuming that Lg2 is small relative to d, we can think of the time bound for failure notification as approximately Ld + d.
We begin by considering what we know about the agreement problem from results in earlier chapters and at tempting to extend the results to the partially synchronous setting.
The main relevant results turn out to be the matching.
Section 6.2 contains several algorithms that solve the agreement problem in the.
Most of the algorithms that tolerate f stopping failures require exactly f + 1 rounds.
It is possible to transform any of these algorithms to run in the partially synchronous setting.
Let A be any synchronous network algorithm for a complete graph network.
Recall that the conventions of the synchronous model imply that inputs appear in the initial states and outputs are written to write-once local variables.
In terms of A, we describe an algorithm A ~ for the partially synchronous network model.
A ~ a l g o r i t h m :
Each process Pi is the composition of two MMT automata: Qi, which is node i's portion of the PSynchFD algorithm, plus a main automaton Ri.
Ri maintains a variable stopped, in which it records the set of processes j for which it has received informstopped(j)i inputs, that is, those that it has learned have failed.
Ri also maintains a variable containing the simulated state of process i of A.
In order to simulate each round r, process Ri first determines and sends out all its round r messages from algorithm A (using one task per destination process)
This determination is made using the msgsi function of A.
Next Ri waits, for each j ~ i, until it has either received a round r message from R i or sees that j C stopped.
Then Ri determines the new simulated state of A from the old state, using the received messages (and using a null message for any process from which Ri has not received a round r message)
Now fix f and suppose that A is any f-fault-tolerant,  f + 1-round algorithm that solves the agreement problem in the synchronous network model.
We construct a partially synchronous version A ~ of A as above.
So we modify A ~ to obtain an algorithm B as follows: First, in B, Ri does not begin the simulation of A until it receives an init(v)i input.
However, Qi begins its timeout activity right at the start  of the timed execution.
Second, in B, when Ri simulates the write of value v to its output variable, it immediately thereafter performs a decide(v)i output action.
It should be easy to see that B simulates A correctly, which implies that B solves the agreement problem.
The milestone T(r)  will be shown to be an upper bound on the time for all not-yet-failed processes to complete the simulation of round r.
First,  define T(0) to be the time at which the last init occurs in a.
Because S is an upper bound for the time to detect failures, it is easy to see that.
Now we show the required time bound, thereby completing the proof of Theorem 25.3
But the definition of the milestones and the fact that  there are at most f failures imply that.
With a little work, we can extend this bound to the partially synchronous model, giving a lower bound of (f  + 1)d time.
Note that  there is no mention in this bound of the timing uncertainty L.
Then there is no n-process agreement algorithm for the partially synchronous network model that guarantees f-failure termination, in which all nonfaulty processes always decide strictly before time (f  + 1)d.
Suppose for the sake of contradiction that  there is such an algorithm A.
Algorithm A must, of course, work correctly when we restrict at tention to a special case of the partially synchronous model, in which we only consider t imed executions satisfying certain interleaving and timing constraints:
Moreover, messages delivered to a single process i at the same time are delivered in order of sender indices.
Recall that we have assumed that each task always has a step enabled.
At a t ime tha t  is a multiple of both g2 and d, all the message deliveries occur prior to all the locally controlled process steps.
Call the part ial ly synchronous model with these restrictions the strongly timed model.
We regard A as an algori thm for the strongly t imed model.
Wi thou t  loss of generality, we may assume that  A is "deterministic," in the sense tha t  each process task has at most one locally controlled action enabled in any state, and tha t  for each state and each action, there is at most one possible new state.
Also, since all messages are delivered at t imes tha t  are multiples of d and processes decide strictly before t ime ( f  + 1)d, we may assume without  loss of generality tha t  the processes decide at their first step after the t ime fd  message del iver ies.
It turns out tha t  the behavior of algori thm A in the strongly t imed model is very close to the behavior of an f - round  synchronous network algorithm.
So we might t ry to regard all these messages as the round r messages of a synchronous algorithm.
In the synchronous model, if a process i fails at round r, then for each j :/: i, process i either succeeds in sending all or none of its round r information to process j.
But this is not a possible behavior in the strongly t imed model, if i sends several messages to each of j and j~ in tha t  interval.
In order to t ransform A into a synchronous algorithm, it is helpful to generalize the synchronous model slightly.
Namely, instead of allowing each process i, at each round r, to send only one message to each other process, we allow it to send a finite sequence of messages, each to an arbitrary, specified destination.
We allow a failure of i to interrupt  this sequence after any prefix.
It is not hard to see tha t  the proof of Theorem 6.33 extends to this slightly generalized model.
It is only necessary to include extra steps in the chain constructed in the proof of Theorem 6.33 for adding and removing the messages in the sequences one at a time.
Now the behavior caused by a failure in A ~ does correspond to possible behavior of A.
Again, extra steps must be included in the chain for adding and removing messages sent "in the middle" of rounds.
The two results described in Section 25.3 leave an interesting gap in time complexity.
The most notable difference is the fact that the timing uncertainty L appears in the upper bound but not in the lower bound.
We would like to understand how the inherent complexity of this problem depends on the timing uncertainty.
The practical importance of understanding the impact of L on the time complexity depends on the size of L.
If each process Pi of an algorithm A is run on a dedicated processor, so that the speed of Pi's steps is governed by a highly accurate processor clock, then L will typically be very small and the dependency of A's complexity on L will n o t  matter much.
On the other hand, if process speeds are determined by other factors such as process swapping, then L could be quite large and this dependency could be important.
Initially, you might guess that it is possible to improve the lower bound result of Theorem 25.6 to incorporate a multiplicative factor of L.
This means, roughly speaking, that only one message delivery is "stretched" by the timing uncertainty L.
There is also a more difficult lower bound proof that yields a lower bound of Ld + ( f -  1)d.
We present the algorithm in this section and the lower bound in Section 25.5
PSynchAgreement has a very simple description, but its behavior is rather tricky to understand.
We suggest that before reading about this algorithm, you try to design a solution of your o w n.
In the PSynchAgreement algorithm, we specify that a process should send certain messages to "all processes"; this includes sending to the sender itself.
The model does not actually permit  this, but as usual, this can be simulated using internal steps.
PSynchAgreement algorithm: The algorithm uses the PSynchFD failure detector just as algorithm B in Section 25.3.1 does.
That  is, each process Pi of PSynchAgreement is the composition of two MMT automata: Qi, which is node i's portion of the PSynchFD algorithm, plus a main automaton Ri.
Ri maintains a variable stopped, in which it records the set of processes j for which it has received inform-stopped(j)i inpu t s - - tha t  is, those that it has learned have failed.
Ri only begins its round 0 after it receives its input.
Ri maintains a variable decided, to keep track of processes from which it has received a decided message.
If Ri's input is O, then Ri does the following, in order: send goto(2) to all processes output  decide(O)i send decided to all processes.
At that point, if Ri has received a goto(r + 1) message, then it does the following, in order:
Otherwise- - tha t  is, if Ri has not received any goto(r + 1) message but has received a goto(r) message from every process that is not in stopped U decided--Ri does the following, in order:
At any later round r, if Ri is told to advance to round r + 1, then it does so, after telling the other processes to do the same.
On the other hand, if Ri has not been told to advance to round r + 1 and it hears that every process.
We first show the safety properties: well-formedness, agreement, and validity.
I f  any process sends a goto(r + 2) message, then some process tries to decide at round r.
I f  any process reaches round r + 2, then some process tries to decide at round r.
The first goto(r + 2) message must be generated in this way.
Ri sends a goto(r + 2) message to every process.
The first two parts should be clear from the algorithm description.
For the third part,  suppose for the sake of contradiction that Rj  tries to decide at.
Since Ri sends no goto(r + 1) messages, it must  be that  at the designated point,  i E stoppedj U decidedj.
If i C stoppedj at this point,  then Theorem 25.2 implies that  Rj must  have already received all messages sent by Ri before Ri failed.
On the other hand, if i E decidedj at this point,  then Rj must  have received a decided message from Ri.
But Ri sends such a message only after it has sent its goto(r + 2) message to Rj.
Then the F IFO proper ty  of the channels implies that  Rj must  have already received the goto(r + 2) message at the designated point,  which is again a contradiction.
For agreement,  suppose that  Ri decides at round r and no process decides at any earlier round.
Then by Lemma 25.8, no process tries to decide at round.
Now we prove wait-free terminat ion,  as well as the time bound.
If not, then let r be the first round at which some process gets stuck;
Let i be the index of any process that  gets stuck at.
For any other process Rj that  ever fails, Ri must  eventually detect the.
Let I be the set of remaining processes- - tha t  is, all processes except those that ever fail or decide.
Then all processes in I must eventually reach round r, because r is the first round at which any process gets stuck.
This contradicts the assumption that Ri gets stuck at round r.
Now we define a notion that is useful for the liveness and complexity proofs.
PSynchAgreement, we define a round r to be quiet if there is some process that never receives a goto(r + 1) message from any other process.
Combining this new definition with some of the earlier lemmas, we get.
I f  no process tries to decide at round r, then round r + 1 is quiet.
I f  some process decides at round r, then round r + 2 is quiet.
The reason that the notion of a quiet round is important  is that no process.
These are eventually received, which means that round r is not quiet.
If any process decides by round f ,  this follows from Lemma 25.11
We claim that no process tries to decide at round r.
Suppose for the sake of contradiction that some process i does try.
Then, since process i does not fail at round r, admissibility implies that process i must actually decide at round r.
But this contradicts the assumption that no process decides by round f.
Consider an admissible timed execution in which init events occur on all ports.
By Lemma 25.10, Ri continues to advance from round to round until it decides.
All processes that do not fail must decide without advancing past round r.
Let S be an upper bound for the PSynchFD algorithm, where S -  Ld + d + O (Lt~2)
T' is the time at which the last init occurs.
Since round k is not quiet, Ri receives a goto(k + 1) message; we bound the time by which this happens.
Rj sends its goto(k + 1) message as part of an at tempt to send such messages to all processes, including Ri.
If Rj does not fail in the middle of this at tempt,  then Rj succeeds in sending this message to Ri, and Ri receives it within time d of when Rj sends it.
Even if Rj does fail in the middle of this at tempt,  all the messages it succeeds in sending arrive within time d of when they are sent.
Likewise, each process Rj, involved in relaying the message from Rj to Ri sends its goto(k + 1) message as part of an at tempt to send such messages to all processes, including Ri.
Again, if Rj, does not fail in the middle of this at tempt, then Rj, succeeds in sending the message to Ri, and Ri receives it within time d.
Even if/i~j, does fail in the middle of this a t tempt ,  all the messages it succeeds in sending arrive within time d of when they are sent.
As we said earlier, this does not depend on the t iming uncertainty L.
In particular, the PSynchAgreement algorithm demonstrates that  there is no hope of proving a lower bound containing a term of fLd.
In this section, we prove a lower bound that does depend on L, specifically, Ld + ( f  - 1)d.
This still leaves a gap between the upper and lower bounds, though at least the form of the dependency of the time complexity on the t iming uncertainty L is clear.
Then there is no n-process agreemeat algorithm for the partially synchronous model that guarantees f-failure termination, in which all nonfaulty processes always decide strictly before time Ld + (f  - 1)d.
Throughout  the rest of this section we suppose for the sake of contradiction.
Without  loss of generality, we assume that A is "deterministic," as we did in the proof of Theorem 25.6
We prove a series of lemmas leading to the conclusion that A cannot exist.
First,  in Lemma 25.18, we show that a certain "bad combination" of t imed executions cannot occur if algorithm A is correct.
Lemma 25.18 is proved using a stretching and shrinking argument.
Second, in Lemma 25.19, we show that a related combination does in fact exis t - -one with the same conditions, except that.
We begin by distinguishing among all the timed executions of A a subset that we call the "synchronous" timed executions.
A synchronous infinite timed execution is one for which there is an infinite sequence.
All inputs arrive right at the beginning, at time to.
Recall once again that we have assumed that each task always has a step enabled.
These conditions are somewhat  similar to those used in the proof sketch for.
A synchronous infinite t imed execution can be divided up into.
A synchronous finite t imed execution is a prefix of a synchronous infinite t imed execution consisting of some finite number.
We will be especially interested in certain part icular  kinds of block extensions.
We emphasize that  all of these types  of extensions are block extensions, by.
Note that  the designation "fast" or "slow" refers only to.
The following lemma describes a certain bad combination of t imed executions that cannot occur if the algorithm A is correct.
In more detail, let G be F together with the process, if any, to which the two.
First ,  at time tk, we provide stop events for all processes in G that  have not yet failed.
Thus, strictly less than Ld time passes in the new parts  of the two t imed executions before decisions occur.
Now consider extending c~1 to an alternative synchronous t imed execution.
We will get a contradiction by showing that a bad combination of timed executions of the sort described in Lemma 25.18 must in fact occur.
This can be proved using a chain argument similar to the one in the proof of Theorem 6.33
Now we strengthen Lemma 25.20 to include a "maximality" property.
We know that this program eventually terminates,  because decisions are required.
We claim that this c~ has all the properties we need.
It satisfies the needed time bound, bivalence, and failure conditions.
Each two consecutive timed executions in the chain are distinguishable to only one process.
Since all of these timed executions must be univalent, there.
In this section, we consider what happens to the results about the agreement problem if we weaken the timing model in several ways.
Suppose that we weaken the model to use reliable FIFO channels, as defined in Chapter  14, with no upper bound on message-delivery time but only a guarantee of eventual delivery.
In this case, it is not hard to see that the agreement problem cannot be solved for even one stopping failure.
This is so even if gl = t~2, that is, if the process step times are completely predictable.
Suppose for the sake of contradiction that A is such an algorithm.
In this way, an algorithm for agreement in the asynchronous network model, guaranteeing l-failure termination, can be produced, contradicting Theorem 21.2
Now suppose we weaken the partially synchronous model, this time keeping the upper bound of d on delivery of all messages, but imposing only fairness, and no time bounds, on the processes.
Again, it is not hard to see that the agreement problem cannot be solved for even one stopping failure.
Theorem 25.24  There is no algorithm in the model with asynchronous processes and d-bounded channels that solves the agreement problem and guarantees l-failure termination.
Suppose for the sake of contradiction that A is such an algorithm.
Then any fair execution c~ of A in the asynchronous model can be "timed" in such a way that all the messages observe the upper bound of d.
This means that the execution satisfies all of the conditions required for the agreement problem with l-failure termination.
Since none of these conditions depends on the times, the same conditions hold for the given fair execution c~
Since this works for any fair execution c~ of A, it follows that A solves the agreement problem with l-failure termination in the asynchronous model.
For the final result of the book, we consider the case of eventual time bounds, as we did in Section 24.4.2
That  is, we consider the model where the algorithm runs asynchronously for a while, but eventually starts to satisfy its timing constraints.
It turns out that the agreement problem is solvable in this model.
Using an argument similar to that in the proof of Theorem 17.6, it is not hard to show that the problem is not solvable in this.
Designing a solution to this problem in this model is not easy.
The heart  of the a lgori thm is an a lgori thm A for a variant  of the synchronous model of Chapter  2 in which, in addit ion to up to f process failures, there may.
We assume that  any messages may be lost, but  that.
Process i continues to hold some lock for v as long as it continues to think that  owner(s) might decide v at stage s.
A value v is acceptable to i if i does not have a lock on ~
The processing during any part icular  stage s with owner i is as follows.
Process i then a t tempts  to choose a value to propose.
Round gs - 2: If process i has determined a value v to propose, then it sends a ( "lock", v) message to all processes.
Any process that  receives such a message locks (v, s) and releases any earlier lock on the same value v.
Round ~s: Every  process  sends messages  conta ining all its current  locks.
Any process i that  has a lock on some (v, s ~) and.
For each stage s, there is at most one value v that is proposed at.
I f  all processes begin with initial value v, then ~ is never proposed or locked.
Since a process only decides on a value it has proposed ,  val idi ty follows.
I f  process i decides on value v at stage s, then at the end of every.
The a lgor i thm ensures  tha t  at least f + 1 processes  lock (v, s) at round.
Suppose  for the sake of cont rad ic t ion  that  one of these processes,  say process.
Then no process can decide ~ at the same stage.
To see termination, consider what happens after we reach the assumed point after which all messages are delivered reliably.
After any subsequent stage s, it is not hard to see that there can be at most one locked value among all the non-failed processes in the system.
Once this is so, the owner of any stage will succeed in obtaining all the necessary approval and acknowledgments to allow it to decide (if it does not fail)
The rate of growth of C with respect to real time is bounded from and from above, by known constant bounds.
Each clock is within a known (additive) constant of C.
In addition to maintaining its clock, each process Pi of B also simulates its.
A fairly large (but predictable) number of clock values are devoted to the simulation of each round r - - enough  to ensure that after point p in the execution, any message sent by a process Pi at the beginning of Pi's simulated round r is in fact delivered to every process Pj before the end of Pj's simulated round r.
Note that prior to point p, some Pi might not finish its simulation of some round r before its clock advances too far.
In this case, there is no harm if Pi simply omits sending the extra messages--af ter  all, in A, they might be lost, anyhow.
However, Pi must simulate the state transition for round r.
It can do this at the first step after its simulation of round r is interrupted.
In this way, B simulates algorithm A and achieves the same correctness conditions.
In this chapter and the previous one, we have presented a few basic results for two fundamental problems of distributed computing~mutual exclusion and consensus--in partially synchronous models.
These few results already demonstrate that the theory for partially synchronous distributed computing is quite different from that for either synchronous or asynchronous distributed computing.
However, much work remains to be done in this area.
There are many other problems of interest in distributed computing that can be considered in the partially synchronous setting.
These include many problems described in this book, for example, problems of network searching, construction of spanning trees, resource allocation, snapshots, and stable property detection.
They also include many other problems that arise in real communication systems, distributed operating systems, and real-time process control systems.
It would also be useful to have general characterization results describing exactly what can be computed in partially synchronous systems, and with what time complexity.
Transformation results relating the power of partially synchronous models to that of the synchronous and asynchronous models would also be good to have.
Berman and Bharali [48] improved the complexity of Ponzio's sending-omission algorithm.
Ponzio also obtained good upper and lower bounds on the time complexity for failure detection, in a two-node system [246]
The proof sketched here, based on Welch Time, is due to Welch [287]
That paper also contains a similar result for the unknown time bound model, as well as results for other failure models.
Suppose that instead of using channels that guarantee delivery of all messages in time d, we instead use channels that only guarantee delivery of the oldest message within time d.
Research Question: Design the most efficient algorithm you can for simulating synchronous network algorithms with stopping failures in the partially synchronous model.
Can you achieve an upper bound of Ld + rd (plus low-order terms) on the time required to simulate r rounds?
The processes simulate the EIGStop algorithm of Section 6.2.3 by relaying the information they receive as soon as they receive it, recording the values in their EIG trees just as before.
Each process must determine when it has finished recording values in its tree.
Give detailed code for such an algorithm, prove that it works correctly, and analyze its time complexity.
Hint: The proof is very similar to that of Theorem 6.33
Suppose that instead of using channels that guarantee delivery of all messages in time d, we instead use channels that only guarantee delivery of the oldest message within time d.
Modify the PSynchAgreement algorithm for use with such a model, trying to minimize the resulting time complexity.
Can you achieve an upper bound of Ld + fd  (plus lower-order terms) on the time?
Hint: Use a chain argument similar to the one in the proof of Theorem 6.33
The t imed executions in this subset are similar to executions in the synchronous model, and the same sort of chain argument can be used.
Can you achieve a lower bound of Ld + fd? Can you do better?
Research Question: Obtain the best upper and lower bounds you can for the problem of Byzantine agreement in the partially synchronous model.
Section 21.5, in the partially synchronous network model with f stopping failures.
Obtain good upper and lower bounds on the time for all nonfaulty processes to decide.
Prove Theorem 25.23, the impossibility result for the agreement problem in a send/receive network with synchronous processes and asynchronous channels.
Hint: Show how to simulate an algorithm for this model using the asynchronous model, using the Welch Time implementation of logical time.
The clock values used by the Welch Time algorithm can be maintained by counting steps.
Analyze the time complexity of the algorithm B you constructed for Exercise 25.16
Consider the solvability of the agreement problem in the unknown time bound model.
That is, they can be different in different executions, though each execution observes fixed bounds throughout.
Prove an analogue to Theorem 25.25 for the unknown time bound model.
Research Question: Redo the proofs of the time bound results for PSynchFD and PSynchAgreement using the simulation methods of Section 23.3.3
Obtain good upper and lower bounds for the time complexity of the session problem of Section 16.6, in the partially synchronous network model.
Obtain good upper and lower bounds for the time complexity of the problem of implementing a snapshot atomic object, as defined in Section 13.3, in the partially synchronous shared memory model.
Research Question: Obtain upper and lower bounds for the time complexity of other problems of interest in distributed computing, in the partially synchronous setting.
Look beyond the problems mentioned in this book to others that arise in actual communication systems, distributed operating systems, and real-time process control systems.
You may also want to look beyond the specific formulation of the partially synchronous setting used in this book.
Research Question: Obtain general characterization results describing exactly what can be computed in partially synchronous systems, and with what time complexity, and transformation results relating the power of partially synchronous models to that of the synchronous and asynchronous models.
Time and message bounds for election in synchronous and asynchronous complete networks.
Bounds on the time to reach agreement in the presence of timing uncertainty.
Timebounds for real-time process control in the presence of timing uncertainty.
Reducing complexities of the distributed max-flow and breadth-first search algorithms by means of network synchronization.
Optimal distributed algorithms for minimum weight spanning tree, counting, leader election and related problems.
Nearlinear cost sequential and distributed constructions of sparse neighborhood covers.
Shifting gears: Changing algorithms on the fly to expedite Byzantine agreement.
A unified method for the specification and verification of protocols.
Data requirements for implementation of N-process mutual exclusion using a single shared variable.
An improved algorithm for decentralized extrema-finding in circular configurations of processes.
More choices allow more faults: Set consensus problems in totally asynchronous systems.
Efficient fault tolerant algorithms for resource allocation in distributed systems.
Mutual exclusion of N processors using an O(N)-valued message variable.
A correctness proof of a distributed minimum-weight spanning tree algorithm.
An O(n log n) unidirectional distributed algorithm for extrema finding in a circle.
Knowledge and common knowledge in a Byzantine environment: Crash failures.
Simple and efficient bounded concurrent timestamping and the traceable use abstraction.
Final version to appear in Journal of the A CM.
The impossibility of implementing reliable communication in the face of crashes.
The consensus problem in unreliable distributed systems (a brief survey)
A lower bound for the time to assure interactive consistency.
Distributed FIFO allocation of identical resources using small shared space.
A little knowledge goes a long way: Knowledge-based proofs for a family of protocols.
The generalized railroad crossing: A case study in formal verification of real-time systems.
An effective "on-line" deadlock detection technique for distributed database management systems.
A concurrent time-stamp scheme which is linear in time and space.
From sequential layers to distributed processes: Deriving a distributed minimum weight spanning tree algorithm.
Trade-offs between message delivery and quiesce times in connection management protocols.
A Byzantine resilient fault-tolerant computer for nuclear power plant applications.
Time, clocks, and the ordering of events in a distributed system.
On the advantages of free choice: A symmetric and fully distributed solution to the Dining Philosophers problem.
A simple parallel algorithm for the maximal independent set problem.
Upper bounds for static resource allocation in a distributed system.
The intractability of bounded protocols for on-line sequence transmission over non-FIFO channels.
A review of the development and performance of the ARPANET routing algorithm.
Coordinated traversal: (t + 1)round Byzantine agreement in polynomial time.
An O(nlogn) unidirectional distributed algorithm for the circular extrema problem.
Economical solutions for the critical section problem in a distributed system.
Consensus in the presence of timing uncertainty: Omission and Byzantine failures.
Bounds on the time to detect failures using boundedcapacity message links.
The real-time cost of timing uncertainty: Consensus and failure detection.
Wait-free k-set agreement is impossible: The topology of public knowledge.
Detecting causal relationships in distributed computations: In search of the holy grail.
A tradeoff between safety and liveness for randomized coordinated attack protocols.
A latticestructured proof technique applied to a minimum spanning tree algorithm.
SIFT: Design and analysis of a fault-tolerant computer for aircraft control.
Italicized page numbers  indicate places where terms are defined or introduced.
Byzantine, see Byzantine failure channel, see channel failure communication, see communication.
Atomic Transactions Nancy Lynch, Michael Merritt, William Weihl, and Alan Fekete This book develops a theory for transactions that provides practical solutions for systems developers, focusing on the interface between the user and the database.
The authors present a formal approach to system design that is as relevant to practitioners as it is elegant.
Transaction Processing: Concepts and Techniques Jim Gray and Andreas Reuter Using transactions as a unifying conceptual framework~ the authors show how to build high-performance distributed systems and high-availability applications with finite budgets and risk.
Tamer Ozsu, Umeshwar Dayal, and Patrick Valduriez A groundbreaking collection of articles focusing on the use of object-oriented technologies in distributed computer systems.
Product developers, researchers, and database technology watchers will find this an indispensable guide to a rapidly growing field.
A comprehensive introduction to the core topics of the fields includes the motivation and history as well as a broader survey of research topics and information on forthcoming standards.
