Introducing elements of a Storm topology – streams, spouts, and bolts.
No part of this book may be reproduced, stored in a.
Every effort has been made in the preparation of this book to ensure the.
Packt Publishing has endeavored to provide trademark information about all.
Taylor Goetz is an Apache Storm committer and release manager and has.
Storm user community, Taylor leads a number of open source projects that.
Presently, he works at Hortonworks where he leads the integration of Storm.
I would like to thank my amazing wife, children, family, and friends whose love, support, and sacrifices made this book possible.
He has been a technology leader for over 15 years and is recognized as an.
He has experience as an architect in a wide variety of.
In the past, he has contributed to expert groups within the Java Community.
Science (HMS), where he heads the development of their big data platform.
For my family...To my wife Lisa, We put our faith in the wind.
Rooted to the earth by our children, and fastened to the bedrock of those that have gone before us, our hands are ever entwined by the fabric of our family.
Without all of you, this ink would never have met this page.
Vincent Gijsen is essentially a people's person, and he is passionate about.
In his spare time, he likes to get his hands dirty with.
Sonal Raj is a geek, a "Pythonista", and a technology enthusiast.
He has given talks at PyCon India on Storm and Neo4J and has published.
Did you know that Packt offers eBook versions of every book published, with.
Do you need instant solutions to your IT questions? PacktLib is Packt's online.
The demand for timely, actionable information is pushing software systems to.
Additionally, as the number of connected devices increases and as these.
Specifically, data generation is now viewed as a series of discrete events.
Storm is the most popular framework for real-time stream processing.
It is both an integration technology as well as a data flow and.
Using design patterns from this book, you will learn to develop, deploy, and.
Chapter 1, Distributed Word Count, introduces the core concepts of.
In this chapter, we will automate the installation and configuration of.
Trident provides a higher-level abstraction on top of Storm that abstracts.
Graph databases are databases that store data as graph structures with.
In this chapter, you will integrate Storm with Titan, a popular graph.
Chapter 6, Artificial Intelligence, applies Storm to an artificial intelligence.
Druid, which is an open source infrastructure for exploratory analytics, to.
Chapter 10, Storm in the Cloud, covers best practices for running and.
Additionally, you will leverage Vagrant to create clustered environments for.
The following is a list of software used in this book:
The book presents the core primitives in Storm and Trident alongside the.
Although the book focuses primarily on Java development with Storm, the.
Hadoop enthusiasts will also find this book a good introduction to Storm.
The book provides examples that apply Storm to a broad range of problems.
In this book, you will find a number of styles of text that distinguish between.
Code words in text, database table names, folder names, filenames, file.
When we wish to draw your attention to a particular part of a code block, the.
Warnings or important notes appear in a box like this.
If there is a topic that you have expertise in and you are interested in either.
Now that you are the proud owner of a Packt book, we have a number of.
You can download the example code files for all Packt books you have.
If you find a mistake in one of our books—maybe a.
By doing so, you can save other readers from frustration and help us.
Once your errata are verified, your submission will be accepted.
Piracy of copyright material on the Internet is an ongoing problem across all.
At Packt, we take the protection of our copyright and licenses very.
If you come across any illegal copies of our works, in any form, on.
We appreciate your help in protecting our authors, and our ability to bring you.
In this chapter, we will introduce you to the core concepts involved in creating.
We will begin with an overview of Storm's data structures and move on to.
By the end of the chapter, you will have gained a basic understanding of the.
Introducing elements of a Storm topology – streams, spouts, and bolts.
In Storm, the structure of a distributed computation is referred to as.
A tuple is simply a list of named values (key-value pairs), and a Stream is an unbounded sequence of tuples.
If you are familiar withcomplex event processing (CEP), you can think of Storm tuples as events.
Spouts represent the main entry point of data into a Storm topology.
Spouts act as adapters that connect to a source of data, transform the data into tuples, and emit the tuples as a stream.
As you will see, Storm provides a simple API for implementing spouts.
Developing a spout is largely a matter of writing the code necessary to consume data from a raw source or API.
Since spouts typically don't implement any specific business logic, they can often be reused across multiple topologies.
Bolts can be thought of as the operators or functions of your computation.
They take as input any number of streams, process the data, and optionally emit one or more streams.
Bolts may subscribe to streams emitted by spouts or other bolts, making it possible to create a complex network of stream transformations.
Bolts can perform any sort of processing imaginable and like the Spout API, the bolt interface is simple and straightforward.
Our word count topology (depicted in the following diagram) will consist of a.
The SentenceSpout class will simply emit a stream of single-value tuples with the key name "sentence" and a string value (a sentence), as shown in the following code:
To keep things simple, the source of our data will be a static list of sentences.
The split sentence bolt will subscribe to the sentence spout's tuple stream.
For each tuple received, it will look up the "sentence" object's value, split the value into words, and emit a tuple for each word:
The word count bolt subscribes to the output of the SplitSentenceBolt class, keeping a running count of how many times it has seen a particular word.
Whenever it receives a tuple, it will increment the counter associated with a word and emit a tuple containing the word and the current count:
The report bolt subscribes to the output of the WordCountBolt class and maintains a table of all words and their corresponding counts, just like WordCountBolt.
When it receives a tuple, it updates the table and prints the contents to the console.
Now that we've introduced the basic Storm concepts, we're ready to start.
Creating a new Storm project is just a matter of adding the Storm library and.
For this reason, it is highly recommended that you use a build.
Next, edit the pom.xml file and add the Storm dependency:
Then, test the Maven configuration by building the project with the following.
You can download the example code files for all Packt books you have purchased from your account at http://www.packtpub.com.
Maven will download the Storm library and all its dependencies.
To keep things simple, our SentenceSpout implementation will simulate a data source by creating a static list of sentences that gets iterated.
The BaseRichSpout class is a convenient implementation of the ISpout andIComponent interfaces and provides default implementations for methods we don't need in this example.
The open() method is defined in the ISpout interface and is called whenever a spout component is initialized.
The nextTuple() method represents the core of any spout implementation.
Storm calls this method to request that the spout emit tuples to the output.
Here, we just emit the sentence at the current index, and increment.
The BaseRichBolt class is another convenience class that implements both theIComponent and IBolt interfaces.
Extending this class frees us from having to implement methods we're not concerned with and lets us focus on.
The prepare() method defined by the IBolt interface is analogous to the open() method of ISpout.
This is where you would prepare resources such as database connections during bolt initialization.
The core functionality of the SplitSentenceBolt class is contained in the execute()method defined by IBolt.
This method is called every time the bolt receives a tuple from a stream to which it subscribes.
The WordCountBolt class (Example 1.3) is the topology component that actually maintains the word count.
The reason behind this pattern lies in the fact that when a topology is deployed, its component spouts.
In theexecute() method, we look up the count for the word received (initializing it to 0 if necessary), increment and store the count, and then emit a new tuple consisting of the word and current count.
The purpose of the ReportBolt class is to produce a report of the counts for each word.
One difference between the report bolt and the other bolts we've written so far.
The report bolt also introduces the cleanup() method defined in the IBolt interface.
Storm calls this method when a bolt is about to be shutdown.
One important thing to keep in mind about the IBolt.cleanup() method when writing bolts is that there is no guarantee that Storm will call it when a.
The full source for the ReportBolt class is listed in Example 1.4
In this example, we begin by defining string constants that will serve as unique identifiers for our.
We begin the main() method by instantiating our spout and bolts and creating an instance of TopologyBuilder.
TheTopologyBuilder class provides a fluent-style API for defining the data flow between components in a topology.
The next step is to register SplitSentenceBolt and establish a subscription to the stream emitted by the SentenceSpout class:
The setBolt() method registers a bolt with the TopologyBuilder class and returns an instance of BoltDeclarer that exposes methods for defining the input source(s) for a bolt.
Here we pass in the unique ID we defined for.
We will explain stream groupings in detail shortly in our discussion of parallelism in Storm.
As you'll learn, there are times when it's imperative that tuples containing.
The last step in defining our data flow is to route the stream of tuples emitted.
In this case, we want all tuples emitted by WordCountBolt routed to a single ReportBolt task.
With our data flow defined, the final step in running our word count.
Here, we're running Storm in local mode using Storm's LocalCluster class to simulate a full-blown Storm cluster within our local development.
Local mode is a convenient way to develop and test Storm.
As you'll see in the next chapter, the submitTopology() method used to deploy a topology in local mode has the same signature as the method to deploy a topology in.
Storm will merge its predefined default configuration values with the contents.
In this sense, the Config object represents a set of configuration parameters that are global to all components in a topology.
The main() method will submit the topology, wait for ten seconds while it runs, kill (undeploy) the.
Recall from the introduction that Storm allows a computation to scale.
To understand how parallelism works, we must first explain the four main.
Each node is configured to run one or more workers.
Unless explicitly overridden, Storm will assign one task for each executor.
So far in our word count example, we have not explicitly used any of Storm's.
Before changing the parallelism settings for our topology, let's consider how.
As you can see, the only parallelism we have is at the thread level.
Let's start by increasing the number of workers and executors assigned to run.
Assigning additional workers is an easy way to add computational power to a topology, and Storm provides the means to do so through its API as well as pure configuration.
Whichever method we choose, our component spouts and bolts do not have to change, and can be reused as is.
In the previous version of the word count topology, we introduced the Config object that gets passed to the submitTopology() method at deployment time but left it largely unused.
To increase the number of workers assigned to a topology, we simply call thesetNumWorkers() method of the Config object:
This assigns two workers to our topology instead of the default of one.
While this will add computation resources to our topology, in order to effectively utilize those.
As we've seen, Storm creates a single task for each component defined in a topology, by default, and assigns a single executor for each task.
Storm's parallelism API offers control over this behavior by allowing you to set the number of executors per task as well as the number of tasks per executor.
The number of executors assigned to a given component is configured by setting a parallelism hint when defining a stream grouping.
To illustrate this feature, let's modify our topology definition to parallelize SentenceSpout such that it is assigned two tasks and each task is assigned its own executor thread:
If we're using one worker, the execution of our topology now looks like the following:
Next, we will set up the split sentence bolt to execute as four tasks with two executors.
We'll also configure the word count bolt to run as four tasks, each with its own executor thread:
With two workers, the execution of the topology will now look like the following diagram:
With the topology parallelism increased, running the updated WordCountTopology class should yield higher total counts for each word:
It's important to point out that increasing the number of workers has no effect when running a topology in local mode.
A topology running in local mode always runs in a single JVM process, so only task and executor parallelism settings have any effect.
Storm's local mode offers a decent approximation of cluster behavior and is very.
Based on the previous example, you may wonder why we did not.
The answer is that it does not make any sense to do so.
A stream grouping defines how a stream's tuples are distributed among bolt.
For example, in the parallelized version of the word count.
The stream grouping determines which one of those tasks will.
Fields grouping: This routes tuples to bolt tasks based on the values.
All grouping: This replicates the tuple stream across all bolt tasks.
The global grouping should be used with caution since it will route.
None grouping: The none grouping is functionally equivalent to the.
Direct grouping: With a direct grouping, the source stream decides.
It and can only be used on streams that have been declared direct streams.
Local or shuffle grouping: The local or shuffle grouping is similar.
In addition to the predefined groupings, you can define your own stream.
The prepare() method is called at runtime to initiate the grouping with information the grouping implementation can use to make decisions on how.
The most useful parameter is targetTasks, which is a list of all the task identifiers the grouping needs to take into account.
The chooseTasks() method returns a list of task identifiers to which a tuple should be sent.
To illustrate the importance of stream groupings, let's introduce a bug into our.
Begin by modifying the nextTuple() method of SentenceSpout so it only emits each sentence once:
The bug we introduced will only be manifested if the.
This underscores the importance of testing topologies with various parallelism.
In general, you should avoid storing state information in a bolt since any time a worker fails and/or has its tasks reassigned, that information will be lost.
One solution is to periodically take a snapshot of state information to a persistent store, such as a database, so it can be restored if a task is reassigned.
Storm provides an API that allows you to guarantee that a tuple emitted by a.
We've seen that a spout stream can be split and can generate any.
What happens in the event of a failure? As an example, consider a bolt.
A child tuple can be thought of as any tuple.
In the preceding diagram, the solid lines represent the original trunk tuples.
If all bolts in the tree acknowledge tuples derived from the trunk tuple, the.
If any of the bolts in the tree explicitly fail a tuple, or if processing of.
Storm's ISpout interface defines three methods involved in the reliability API: nextTuple,ack, and fail.
As we've seen before, when Storm requests that a spout emit a tuple, it calls.
The first step in implementing guaranteed processing is to assign the outbound tuple a unique ID and pass that value to.
Assigning the tuple a message ID tells Storm that a spout would like to.
If processing succeeds, the spout's ack() method will be called with the message ID assigned to the tuple.
Implementing a bolt that participates in guaranteed processing involves two.
Anchoring to an incoming tuple when emitting a derived tuple.
Anchoring to a tuple means that we are creating a link between an incoming.
You can anchor to a tuple (or a list of tuples) by calling one of the.
Here, we're anchoring to the incoming tuple and emitting a new tuple that.
Unanchored tuples do not participate in the reliability of a stream.
After successfully processing a tuple and optionally emitting new or derived.
If tuple processing fails in such a way that the spout must replay (re-emit) the.
It will need to keep track of all tuples emitted and assign each one a unique ID.
For each tuple we emit, we'll assign a unique identifier and store it in our map of.
In this chapter, we've built a simple distributed computation application using.
Storm's core API and covered a large part of Storm's feature set, all without.
In the next chapter, we'll walk through the process of installing and setting up.
In this chapter, you'll take a deeper look at the Storm technology stack, its.
We will begin by installing Storm in the pseudo-distributed mode where all.
In a master/slave architecture, there is typically a master node that is either.
A Storm cluster consists of one master node (called nimbus) and one or more.
Both the nimbus and supervisor processes are daemon processes provided by.
Storm and do not need to be isolated from individual machines.
The nimbus daemon's primary responsibility is to manage, coordinate, and monitor topologies running on a cluster, including topology deployment, task assignment, and task reassignment in the event of a failure.
Deploying a topology to a Storm cluster involves submitting the prepackaged topology JAR file to the nimbus server along with topology configuration information.
Once nimbus has received the topology archive, it in turn distributes the JAR file to the necessary number of supervisor nodes.
When the supervisor nodes receive the topology archive, nimbus then assigns tasks (spout and bolt instances) to each supervisor and signals them to spawn the necessary workers to perform the assigned tasks.
Nimbus tracks the status of all supervisor nodes and the tasks assigned to each.
If nimbus detects that a specific supervisor node has failed to heartbeat or has become unavailable, it will reassign that supervisor's tasks to other supervisor nodes in the cluster.
As mentioned earlier, nimbus is not a single point of failure in the strictest sense.
This quality is due to the fact that nimbus does not take part in topology data processing, rather it merely manages the initial deployment, task assignment, and monitoring of a topology.
In fact, if a nimbus daemon dies while a topology is running, the topology.
The main caveat is that if a supervisor fails while nimbus is down, data processing will fail since there is no nimbus daemon to reassign the failed supervisor's tasks to another node.
The supervisor daemon waits for task assignments from nimbus and spawns and monitors workers (JVM processes) to execute tasks.
Both the supervisor daemon and the workers it spawns are separate JVM processes.
If a worker process spawned by a supervisor exits unexpectedly due to an error (or even if the process is being forcibly terminated with the UNIX kill -9 or Windows taskkill command), the supervisor daemon will attempt to respawn the worker process.
At this point, you may be wondering how Storm's guaranteed delivery features fit into its fault tolerance model.
If a worker or even an entire supervisor node fails, how does Storm guarantee the delivery of the tuples that were in process at the time of failure?
The answer lies in Storm's tuple anchoring and acknowledgement mechanism.
When reliable delivery is enabled, tuples routed to the task on the failed node will not be acknowledged, and the original tuple will eventually be replayed by the spout after it is timed out.
This process will repeat until the topology has recovered and normal processing has resumed.
ZooKeeper provides a service for maintaining centralized information in a distributed environment using a small set of primitives and group services.
It has a simple yet powerful distributed synchronization mechanism that allows client applications to watch or subscribe to individual data or sets of data and receive notifications when that data is created, updated, or modified.
Using common ZooKeeper patterns or recipes, developers can implement a number of different constructs needed by distributed applications such as leader election, distributed locks and queues.
Storm uses ZooKeeper primarily to coordinate state information such as task assignments, worker status, and topology metrics between nimbus and supervisors in a cluster.
Nimbus and supervisor node communication is largely handled through a combination of ZooKeeper's state modifications and watch notifications.
Storm's use of ZooKeeper is relatively lightweight by design and does not incur a heavy resource burden.
For heavier-weight data transfer operations, such as a one-time (at deployment time) transfer of topology JAR files, Storm relies on Thrift for communication.
And as we'll see, data transfer operations between components in a topology—where performance matters most—is handled at a low level and optimized for performance.
A common pattern among Storm applications involves the desire to leverage Storm's parallelization and distributed computation capabilities within a request-response paradigm where a client process or application submits a request and waits for a response synchronously.
While such a paradigm may seem to counter the highly asynchronous, long-lived nature of a typical Storm topology, Storm includes a transactional capability that enables such a use case.
To enable this functionality, Storm uses the combination of an extra service (Storm DRPC) and a specialized spout and bolt that work together to provide a highly scalable Distributed RPC capability.
Storm UI is an optional, but very useful, service that provides a web-based GUI to monitor Storm clusters and manage the running topologies to a certain degree.
The Storm UI provides statistics for a given Storm cluster and its deployed topologies and is very useful when monitoring and tuning cluster and topology performance.
Storm UI only reports information gleaned from the nimbus thrift API and does not impart any other functionality to a Storm cluster.
The Storm UI service can be started and stopped at any time without affecting any topology or cluster functionality and is in that respect completely stateless.
It can also be configurated to start, stop, pause, and rebalance topologies for easy management.
Before we jump into installing Storm, let's take a look at the technologies with.
Storm runs on the Java Virtual Machine and is written with a roughly equal.
Java, with the core logic being implemented mostly in Clojure.
Beyond those languages, Storm is a highly polyglot-friendly technology due in.
The components of Storm topologies (spouts and bolts) can be written in.
All Storm daemons and management commands are run from a single.
It is for this reason that a properly configured Python interpreter be installed.
Storm was originally designed to run on Unix-style operating systems, but as.
For our purposes, we will be using Ubuntu 12.04 LTS for its relative ease of.
We'll use the server version which by default does not include a graphical.
The instructions that follow the command work equally well on both the.
Virtualization software is readily available for OSX, Linux, and Windows.
You can begin by booting from the Ubuntu installation disk (or disk image)
This package will allow you to use ssh to remotely log into the server.
In all other cases, you can simply accept the default options unless.
By default, the primary user under Ubuntu will have administrative (sudo)
For our single-node pseudo-cluster, we'll install ZooKeeper alongside all other.
This command will install both the ZooKeeper binaries as well as the service.
Storm's binary release distributions can be downloaded from the Storm.
Storm daemons as a specific user rather than the default or root users:
This approach will allow us to easily install other versions and activate (or revert) the new version by changing a single symbolic.
By default, Storm will log information to $STORM_HOME/logs rather than the /var/logdirectory that most UNIX services use.
To change this, execute the following commands to create the storm directory under /var/log/ and configure Storm to write its log data there:
Finally, we'll move Storm's configuration file to /etc/storm and create a symbolic link so Storm can find it:
With Storm installed, we're now ready to configure Storm and set up the.
All of the Storm daemons are fail-fast by design, meaning the process will halt.
This means that the Storm daemons need to be restarted immediately.
While the Debian upstart system is perfect for this situation, there are simpler.
Under Debian-based Linux distributions, the supervisord package is named supervisor, while other distributions such as Red Hat use the name.
Supervisord's configuration file will automatically include any files matching the.
For each Storm daemon command we want to run under supervision, we'll.
A unique (within the supervisord configuration) name for the service under supervision.
Create the following three files to set up the Storm daemons to be.
Once those files have been created, stop and start the supervisord service with.
The supervisord service will load the new configurations and start the Storm.
Wait a moment or two for the Storm services to start and then verify.
If for some reason the Storm UI does not come up or fails to show an active.
Storm UI: Check the ui.log file under /var/log/storm to check for errors.
Nimbus: Check the nimbus.log file under /var/log/storm to check for errors.
Supervisor: Check the supervisor.log file under /var/log/storm to check for errors.
So far, we've relied on the default Storm configuration that defaults to.
Next, we'll explore the various configuration options Storm provides and how.
The listing below provides a minimal storm.yaml file with entries that you must override:
List of hosts that are Storm DRPC servers (optional) # drpc.servers:
Since we're running a single node ZooKeeper on the same machine as the other Storm daemons, the default value of localhost is acceptable.
Workers need to know which node is the master in order to download topology JAR files and configurations.
It is defined as a list of port numbers that the workers will listen on, and the number of port numbers listed will control how many worker slots are available on the supervisor node.
By default, Storm will use ports 6700-6703, a total of four slots per supervisor node.
This setting determines where the nimbus and supervisor processes will store that information.
The directory specified here must exist with appropriate permissions so the process owner (in our case, the Storm user) can read and write to the directory.
The contents of this directory must persist as long as the cluster is running, so it is best to avoid using /tmp where the contents might be deleted by the operating system.
In addition to the settings that are mandatory for an operational cluster, there.
Some of the more frequently overridden settings are outlined as follows:
Setting this value too low may cause tuples to be replayed repeatedly.
For this setting to take effect, a spout must be configured to emit anchored tuples.
Depending on the execute latency of downstream bolts, the default behavior can overwhelm the topology, leading to message timeouts.
Setting this value to a non-null number greater than 0 will cause Storm to pause streaming.
For this setting to take effect, a spout must be configured to emit anchored tuples.
The Storm executable is a multipurpose command used for everything from.
The basic syntax for the Storm command is as follows:
For running Storm commands that connect to a remote cluster, you will need.
Next, create the storm.yaml file under ~/.storm/with a single line that tells Storm where to find the nimbus server for the cluster with which you.
In order for a Storm cluster to operate properly, it is imperative that the IP address name resolution be set up properly, either through the DNS system or entries in the hosts file under /etc.
While it is possible to use IP addresses instead of hostnames throughout Storm's configuration, using the DNS system is preferred.
Storm's daemon commands are used to launch Storm services, and should be.
Any configuration parameters in this file will override Storm's built-in defaults.
Usage: storm ui This launches the Storm UI daemon that provides a web-based UI for monitoring Storm clusters.
Storm's management commands are used to deploy and manage topologies.
The only required configuration parameter is the hostname of the.
Once submitted, Storm will activate the topology and start processing.
If a topology with that name already exists on the cluster, thejar command will fail.
It is common practice to specify the topology name in the command-line arguments so that the topology can be named at the time of submission.
Storm will then halt the workers and attempt to clean up any saved states.
The functionality of the kill command is also available in the Storm UI.
Usage: storm deactivate topology_name The deactivate command tells Storm to stop streaming tuples from the specified topology's spouts.
Usage: storm activate topology_name The activate command tells Storm to resume streaming tuples from the specified topology's spouts.
The rebalance command instructs Storm to redistribute tasks among workers in a cluster without killing and resubmitting the topology.
For example, this might be necessary when a new supervisor node has been added to a cluster—since it is a new node, none of the tasks of existing topologies would have been assigned to workers on that node.
The rebalance command also allows you to alter the number of workers assigned to a topology and change the number of executors assigned to a given task with the -n and -eswitches respectively.
When the rebalance command is run, Storm will first deactivate the topology, wait for the configured time for outstanding tuples to finish processing, then redistribute workers evenly among supervisor nodes.
After rebalancing, Storm will return the topology to its previous activation state (that is, if it was activated, Storm will reactivate it and vice versa)
Usage: storm remoteconfvalue conf-name The remoteconfvalue command is used to look up a configuration parameter on a remote cluster.
Note that this applies to the global cluster configuration and does not take into account individual overrides made at the topology level.
Usage: storm repl The repl command opens a Clojure REPL session configured with Storm's local classpath.
Usage: storm classpath The classpath command prints the classpath used by the Storm client.
Now that we have a running cluster, let's revisit our earlier word.
The previous example used Storm's LocalCluster class to run in local mode:
Submitting a topology to a remote cluster is simply a matter of using.
When developing Storm topologies, you usually aren't going to want to change.
The standard way to handle this is to add an if/else.
To deploy the updated word count topology to a running cluster, first perform.
Next, run the storm jar command to deploy the topology:
When the command completes, you should see the topology become active in.
So far, we've configured a single-node pseudo-cluster manually from the.
While this approach certainly works with small clusters, it will.
Fortunately, there are a number of technologies available to help address the.
Both Chef and Puppet offer a declarative approach to configuration that allows.
Automating the process of provisioning and configuring servers is a very.
At the heart of Puppet is the concept of a manifest that describes the.
Puppet uses a declarative Ruby-based DSL to describe system configuration in.
This simple manifest can be used to make sure ZooKeeper is installed as a.
Finally, the service block tells Puppet that it should ensure that the zookeeperd system service is running and that the service.
To illustrate how Puppet manifests translate to installed software and system's.
To get the latest version of Puppet, we need to configure apt-get to use the.
Next, save the preceding example manifest to a file named init.pp and use Puppet to apply the manifest:
When the command completes, check to see whether the zookeeper service is.
While standalone Puppet manifests make it easy to define the state of an.
Fortunately, Puppet has the concept of classes and modules that can be.
Consider a situation with Storm where we have multiple classes of nodes.
Puppet classes and modules provide a way to distinguish between.
To illustrate this capability, let's revisit the manifest we used to install the.
In the preceding example, we've redefined the zookeeper manifest to be.
On the second line, the zookeeper class includes another class, jdk, which will include the class definition for a resource that will include the state necessary for a.
Puppet also leverages the Ruby ERB templating system that allows you to.
Consider the following Puppet file declaration that's used to generate.
The conditional logic and variable expansion in the template allow us to define.
We've briefly introduced the concepts of Puppet manifests, classes, and.
At this point, you're probably wondering how to define variables in.
Defining a variable within a puppet class or manifest is easy; simply define it at the beginning of the manifest or class.
Once defined, the java_version variable will be available throughout the class or manifest definition as well as any ERB templates; however, there is a.
It would be better if we could externalize all potentially.
Hiera is a key-value lookup tool that has been integrated into the latest.
For example, consider a situation where we are defining configuration.
All machines will share a common set of key-values such as the version of Java.
So, we'd define those values in a file called "common.yaml." From there on, things start to diverge.
Puppet's Hiera integration allows you to do just that and use built-in Puppet.
The examples in the Chapter 2 source code directory demonstrate how to implement this type of organization.
A typical common.yaml file might define global properties common to all hosts and looks like the following :
Finally, we may want to define host-specific parameters in files that use the.
We've only scratched the surface of what's possible with Puppet and Hiera.
The Chapter 2source code directory contains additional examples and documentation on how to use Puppet to automate deployment and.
In this chapter, we've covered the steps necessary to install and configure.
Storm daemons and command line utilities used to deploy and manage.
Finally, we offered a brief introduction to the Puppet framework and showed.
We'd encourage you to explore the additional code and documentation.
In the next chapter, we will introduce Trident, which is a high-level.
We will use the sensor data as an example to gain a better understanding of.
Often, the sensor data forms streams that are read from many.
Processing event streams from phones is another instance of sensor data.
The sensor data contains events emitted by many devices, often forming a.
To better understand both the Trident topologies, as well as using Storm with.
The topology will process diagnosis events that contain the following pieces of.
Each event will include the Global Positioning System (GPS) coordinates.
The event also contains the ICD9-CM code, which indicates the.
To detect an outbreak, the system will count the occurrences of specific.
In a real system, you would most likely perform more.
Also, for the example, we will group the occurrences by hour since epoch.
Finally, we will use a simple threshold to determine if there is an outbreak.
To maintain a historical record, we will also persist the number of occurrences.
To fulfill these requirements, we will need to count the occurrences in our.
The preceding code shows the wiring between the different Trident functions.
The events are then filtered by theDiseaseFilter function, which filters out occurrences of diseases that we are not concerned with.
Then, the HourAssignment function assigns an hour to the event and adds a key to the tuple, which comprises the city, hour, and disease code.
In the following section, we will take a deeper look.
Let's first take a look at the spout in the topology.
Non-transactional spouts provide no guarantee on the composition of the.
Opaque spouts guarantee that batches are non-overlapping, but the contents.
The interface for a spout looks like the following code snippet:
In Trident, the spout does not actually emit the tuples.
The Emitter function is responsible for emitting the tuples, and.
The generic class is the metadata that is required to replay a batch.
The BatchCoordinator class is implemented as a Storm Bolt operating in a single thread.
For our example, if we do no coordination, the following is the coordination.
The second component in a Trident spout is the Emitter function.
The Emitter functionperforms the function of the Storm spout using a collector to emit tuples.
The interface for an Emitter function looks like the following code snippet:
As shown in the preceding code, the Emitter function has only one job—to emit the tuples for a given batch.
For this example, we will randomly assign a latitude and longitude, keeping it roughly within the.
One of these diagnosis codes is randomly assigned to the event.
In this example, we will use an object to encapsulate the diagnosis event.
There is a balancing act between object encapsulation and use of.
Often, it is a good idea to keep the number of fields down to.
In our example, the DiagnosisEvent class is the key piece of data on which the topology is operating.
Time is stored as a long variable, which is the.
The diagnosisCode class is stored as a string, just in case the system needs to be able to process other types of codes that are not based on ICD-9, such as.
At this point, the topology is able to emit events.
Now that we have events being generated, the next step is to add the logic.
In our topology, we are using two different types of.
Operations are applied to streams via methods on the Stream object.
In this example, we use the following methods on the Stream object:
Note that the methods in the preceding code return forms of.
With this, operations can be chained together using fluent-style Java.
Let's take another look at the critical lines in our example topology:
Typically, operations are applied by declaring a set of input fields and a set of.
From that tuple, CityAssignment will operate on the event field and emit a function field labelledcity, which is appended to the tuple.
Each operation has slightly different fluent-style syntax, which depends on.
The first piece of logic in our topology is a filter, which ignores disease events.
To filter events based on codes, we will leverage a Trident filter.
The BaseFilter class implements the Filter interface, which looks like the following code snippet:
To filter tuples in a stream, the application simply implements this interface.
In the example, we will filter events using the following filter:
In the preceding code, we will extract the DiagnosisEvent class from the tuple and examine the disease code.
Returning True from a Filter operation will result in the tuple flowing along to downstream operations.
If the method returns False, the tuple will not flow to downstream operations.
In our topology, we apply the filter to each tuple in the stream using.
The following line in our topology applies the filter to the stream:
In addition to filters, Storm provides an interface for generic functions.
Functions are similar to Storm bolts in that they consume tuples and.
The values emitted by functions are fields that are added to the tuple.
The interface for a function looks like the following code snippet:
Similar to a Storm bolt, the function implements a single method that.
In this way, functions can also be used to filter tuples.
The first function in our topology is the CityAssignment function that looks like the following code snippet:
In this function, we use a static initializer to create a map of the cities we care.
Forsample data, the function has a map that contains the coordinates.
In the execute() method, the function loops through the cities and calculates the distance between the event and the city.
Once the function determines the closest city, it emits the code for that city in.
The number of function fields declared must align with the number of values.
The next function in our topology, HourAssignment, is used to convert the timestamp into an hour since epoch, which can then be used to group.
We overload this function slightly by emitting both the hours as well as.
The final two functions in our topology detect the outbreak and alert us about.
This function extracts the count for the specific city, disease, and hour.
A CombinerAggregator is used to combine a set of tuples into a single field.
Storm calls the init() method with each tuple, and then repeatedly calls the combine()method until the partition is processed.
The values passed into the combine() method are partial aggregations, the result of combining the values returned by calls to init()
Partitions are discussed more in the following sessions, but a partition is effectively a subset of a stream of tuples.
If a partition is empty, then Storm emits the value returned by.
Storm calls the init() method to retrieve the initial value.
Then reduce() is called with each tuple until the partition is fully processed.
The first parameter into the reduce()method is the cumulative partial aggregation.
The Aggregator interface's aggregate() method is similar to the execute() method of a Function interface, but it also includes a parameter for the value.
This allows theAggregator to accumulate a value as it processes the tuples.
Notice that with anAggregator, since the collector is passed into both the aggregate() method as well as the complete() method, you can emit any arbitrary number of tuples.
In our example topology, we leveraged a built-in aggregator named Count.
The implementation for Count looks like the following code snippet:
We apply both grouping and counting in our example topology to count the.
Recall that Storm partitions the stream across the available hosts.
It groups all the tuples that share the same value for the named field into the same partition.
To do this, Storm must send the like tuples to the same host.
After repartitioning, the aggregate function is run on each group within each partition.
In our example, we are grouping by city, hour, and disease.
Then, theCount aggregator is executed on each group, which in turn emits the occurrence count for downstream consumers.
Now that we have the counts for each aggregation, we want to persist with that.
Trident has a first-level primitive for state, but like the Storm.
API, it makes a few assumptions about what is being stored as state or how.
At the highest level, Trident exposes aState interface as follows:
Like functions, there are methods on the Stream objects that introduce state-based operations into a topology.
On the Stream object, the following methods allow the topology to read and write state information:
The stateQuery() method creates an input stream from state, and the various flavors of the partitionPersist() method allow a topology to update state information from tuples in a stream.
In addition to the methods on the Stream object, the GroupedStream object allows a topology to aggregate statistics from a set of tuples and.
Like the base Stream object, the stateQuery() method creates an input stream from state.
The various flavors of persistAggregate() allow a topology to update state information from tuples in a stream.
This would enable a report similar to the following table:
To achieve this, we want to persist with the counts that we generate in the.
We can use the GroupedStream interface (shown previously) returned by the groupByfunction and call the persistAggregate method.
Specifically, the following is the call we make in the example topology:
To understand persistence, we will first focus on the first parameter to this.
Trident uses a factory pattern to generate instances of State.
The factory returns the State object that Storm uses to persist with information.
Non-Transactional For persistence mechanisms that do not have rollback capabilities and where updates are permanent and commits are ignored.
For persistence that is idempotent, provided the batch contains the same tuples.
Updates are based on the previous value, which makes the persistence resilient to changes in batch composition.
To support counting and state updates in a distributed environment where.
For the Repeat Transactional state, the last committed batch identifier is.
The state is updated if and only if the batch identifier.
To illustrate this approach, consider the following sequence of batches where.
This would result in the following state modifications, where the.
Notice that when batch #3 completes the replay, it has no effect on the state.
Repeat Transactional state to function properly, batch contents cannot change.
The approach used in the Repeat Transactional state relies on the batch.
If the spout is emitting from a source that may have a.
Assume that we have the same batches as in the previous example, but this.
You may wonder why we would reapply the batch if it had already.
The scenario we are concerned with is one whereby the state.
In the case of a Transactional spout, it would need to wait until all the sources.
Since Trident relies on sequential application of batches to state, it is.
Given this approach, the choice of state should be based on the spout so as to.
Returning to our example, since we have no transactional guarantees, we.
As shown in the preceding code, to leverage the MapState objects, we simply pass a backing map.
In our example topology, we do not actually persist with the values.
Simply changing the backing map instance that we pass into the constructor of.
Executing this method will submit the topology to a local cluster.
Notice that the coordinator is notified upon successful completion of the.
In this chapter, we created a topology that processes diagnosis information to.
Later on in this book, we will leverage these same constructs and.
In this chapter, we will introduce you to trend analysis techniques using Storm.
In the previous chapters, the spout implementations used were primarily.
Logging data to Apache Kafka and streaming it to Storm.
Streaming an existing application's log data to Storm for analysis.
Using the XMPP protocol with Storm to send alerts and notifications Use case.
The latency introduced by that process dramatically slows down our reaction.
It is much more desirable to be actively notified of patterns as they.
This use case represents a common theme and has a broad range of.
Application Monitoring: For example, to notify system administrators when certain network errors reach a certain frequency.
Intrusion Detection: For example, to detect suspicious activity such as an increase in failed login attempts.
Supply Chain Management: For example, to identify spikes in sales of specific products and adjusting just-in-time delivery accordingly.
Online Advertising: For example, to recognize popular trends and dynamically changing ad delivery.
The architecture of our application is depicted in the following diagram, and it.
The source application component is any application that uses the logback.
However, as you'll see, any existing application that uses either the logback or.
The logback framework has an extension mechanism that allows you to add.
Like Storm, Kafka is designed to scale horizontally on commodity software to.
The Kafka spout reads data from a Kafka queue and emits it to a Storm or.
Our topology will consist of a collection of both built-in and custom Trident.
When a pattern is detected, the topology will emit a tuple.
We'll begin by installing the necessary software: Apache Kafka and OpenFire.
Although Kafka is a distributed messaging system, it will work just fine.
In a production environment, you will need to set up a cluster of.
Kafka depends on ZooKeeper for storing certain state information, much like.
Since Storm imposes a relatively light load on ZooKeeper, in many.
ZooKeeper server that ships with Kafka and is suitable for a development.
Begin by downloading the 0.7.x release of Apache Kafka from the following.
Next, unpack the source distribution and change the existing directory to the.
Kafka is written in the Scala JVM language (http://www.scala-lang.org) and.
Fortunately, the Kafka source distribution includes sbt and can be built with the following command:
Finally, in a separate terminal window, start the Kafka service with the.
OpenFire is available as an installer for OSX and Windows as well as a.
To install OpenFire, download the installer for your operating system and.
The application component is a simple Java class that uses the Simple.
We will simulate an application that begins by generating warning messages.
Log a warning message every second for 15 seconds (rapid state)
The goal of the application is to generate a simple pattern that our storm.
The logback framework provides a simple extension mechanism that allows.
The AppenderBase class defines a single abstract method as follows:
The eventObject parameter represents a logging event and includes properties such as the date of the event, the log level (DEBUG, INFO, WARN, and so on), as well as the log message itself.
In addition to the append() method, the AppenderBase class defines two additional lifecycle methods that we will need to override:
The start() method is called during the initialization of the logback framework, and thestop() method is called upon deinitialization.
We will override these methods to set up and tear down our connection to the.
The source code for the KafkaAppender class is listed as follows:
As you will see, the JavaBean-style accessors in this class allow us to.
The topic property is used to tell the KafkaConsumer client from which Kafka topic it should read.
It is an interface we've defined that provides an extension point for handling structured (that is, parseable)
A Formatter implementation's job is to take an ILoggingEvent object and turn it into a machine-readable string that can be processed by a consumer.
The following logback configuration file illustrates the usage of the appender.
This example does not define a custom Formatter implementation, so the KafkaAppender class will default to using the MessageFormatter class and just write the log message data to Kafka and discard any additional.
The Storm application we're building is time sensitive: if we're tracking the.
In order to account for this situation, we need to capture the time of the event.
Fortunately, theILoggingEvent class includes a timestamp, in milliseconds since the epoch, that the event occurred.
While we could have used a JSON library to do the work, the JSON data we're generating is simple and adding an additional.
If set to "false", the log message will be treated as a string, and wrapped in quotes.
Otherwise it will be treated as a parseable JSON object.
Since the analytics topology we are building is more concerned with event.
With the means to write our log data to Kafka, we're ready to turn our.
Determine if the moving average has crossed a specified threshold.
The topology is depicted in the following diagram with the Trident stream.
The first step in creating the log analysis topology is to configure the Kafka.
The data our application writes to Kafka is a simple Java string, so we use.
The StringScheme class will read data from Kafka as a string and output it in a tuple field named str.
By default, upon deployment the Kafka spout will attempt to read from the.
Kafka queue where it last left off by querying ZooKeeper for state information.
The time parameter can be one of the following three values:
After setting up the spout configuration, we create an instance of the Opaque.
The data stream coming from the Kafka spout will contain a single field (str) containing the JSON data from the log event.
When the function receives a tuple, it will parse the JSON in the.
The following code creates a Fields object with a list of field names to extract from the JSON.
Consider that the following JSON message is received from the Kafka spout:
This would mean that the function would output the following tuple values:
In order to calculate the rate at which log events occur, without the need to.
A moving average calculation is often used to smooth out short-term.
The smoothing effect of a moving average is achieved by taking into account.
In pseudo code, the calculation would look something like the following code.
Thealpha value determines the amount of smoothing that occurs over time.
The closer thealpha value is to 1, the more the historical.
In other words, an alpha value closer to 0 will result in less smoothing and the moving average will be closer to the current value.
An alpha value closer to 1 will have the opposite effect.
The current average will be less affected by wild fluctuations and the historical.
In some cases, we may want to discount historical values to reduce their.
In the event of a high alpha, however, it may be desirable to counteract the.
We have an event (such as a network error and so on) that occurs infrequently.
Occasionally, small spikes in frequency occur, but that's usually okay.
To counteract this effect, we can introduce the concept of a sliding.
An implementation of an exponentially weighted moving average is listed as.
These correspond to the standard alpha values used to calculate load averages in UNIX.
Thealpha value can also be specified manually, or as a function of an alpha window.
The mark() methods are used to update the moving average.
Without arguments, themark() method will use the current time to calculate the average.
Because we want to use the original timestamp from the log event, we.
The getAverage() method returns the average time between calls to mark() in milliseconds.
As you'll probably notice, using an exponentially weighted moving average can.
Finding the right set of values for an alpha as well as the.
Trident are additive, meaning they add values to the tuples in a stream.
This means that after processing, the tuple might look like the following code.
We apply the function to the stream with theeach() method, selecting the timestamp field as the input, as shown in the following code snippet:
For our use case, we want to be able to define a rate threshold that triggers a.
The job of the function will be to determine whether the new value of the.
We will leverage that value to filter out events that do not represent a state change.
We then compare it to the last state to see if.
Any tuples containing False for the input value will be filtered out of the resulting stream.
We then create a new stream using the averageStream as input to the threshold function, and select the average tuple field as input.
We also assign names (change andthreshold) to the fields added by the function.
Finally, we apply the BooleanFilterclass to create a new stream that will only contain tuples that represent a change in threshold comparison.
At this point, we have everything necessary to implement notifications.
ThefilteredStream we've created will only contain tuples that represent a threshold state change.
The XMPP protocol provides all the typical features you would expect in an.
The XMPP protocol uses an XML format for its communication protocol, but.
The following code snippet demonstrates the usage of the Smack API to send a.
The code connects to the XMPP server at jabber.org and logs in with a.
Based on this simple example, we will create a class.
The class will establish a long-lived connection to an XMPP.
Also, in the execute() method it will create an XMPP message based on the tuple received.
We'll delegate message formatting to an instance of MessageMapper in the XMPPFunctionclass as shown in the following code snippet:
The XMPPFunction class begins by defining several string constants that are used to look up values from the Storm configuration passed to.
In the prepare() method, we look up the configuration parameters (server, username,to address, and so on) for the XMPPConnection class and open the connection.
The final necessary piece of our notification mechanism is to implement.
We now have all the components necessary to build our log analysis topology.
Then, the buildTopology() method creates all the stream connections between the Kafka spout and our Trident functions and filters.
The main() method then submits the topology to a cluster: a local cluster if the topology is being run in the local mode or a remote cluster when run in the.
We begin by configuring the Kafka spout to read from the same topic that our.
This will avoid the replay of all the old messages that we may not be interested in.
Theproject() method is useful for paring down tuple streams to just the essential fields, and it is especially important while repartitioning streams that.
The resulting stream now contains just the data we need.
Finally, we apply the BooleanFilter class and connect the resulting stream to theXMPPFunction class.
The main() method of the topology simply populates a Config object with the properties needed by the XMPPFunction class and submits the topology.
To run the analysis topology, first make sure that ZooKeeper, Kafka, and.
OpenFire are all up and running by using the procedures outlined earlier in.
When the topology activates, the storm XMPP user will connect to the XMPP.
Next, run the RogueApplication class and wait for a minute.
You should receive an instant message notification indicating that the threshold has been.
In this chapter, we've introduced you to real-time analytics by creating a.
The components we've built are generic and can easily be reused.
While the topic of real-time analytics is very broad, and admittedly we've only.
In the next chapter, we'll introduce you to Trident's distributed state.
In this chapter, we will introduce you to graph analysis using Storm to persist.
Graph databases are designed for this type of relationship analysis.
In this chapter, we will build an application that ingests a subset of the Twitter.
By looking at the content of messages, we can use.
Writing a Trident state implementation backed by a graph database Use case.
With Twitter, for example, the obvious relationships consist of those.
By using that word, you are forming a connection with it, and by using it.
If we look at data as "everything is a connection," then we can build a.
As our dataset grows, its value will also grow as the.
When we begin querying our dataset, the value for storing data in a graph.
Twitter client application that reads a subset of the Twitter firehose and writes.
Kafka spout to feed that data into our storm topology.
Twitter provides a comprehensive RESTful API that in addition to a typical.
In the previous chapter, we developed a Logback Appender extension that.
While it would be easy enough to write a Storm.
Kafka Spout gives us transactional, exactly-once semantics, and built-in fault.
Titan is a distributed graph database optimized for storing and querying graph.
Like Storm and Kafka, Titan databases can run as a cluster and can.
Titan stores its data in one of the three configurable storage backends: Apache.
For our use case, consistency is not critical to our application.
A graph is a network of objects (vertices) with directed connections (edges)
In this example, users are represented by vertices (nodes), and relationships.
The ability to associate property metadata to objects and relationships in a.
For example, adding the since property to the Follows edge would.
In contrast to relational databases, relationships in a graph database are.
Under the hood, graph databases' underlying data structures are heavily.
While it is entirely possible to model a graph in.
TinkerPop is a group of open source projects focused on graph technologies.
Blueprints: Graph API Blueprints is a collection of interfaces that provide access to a property graph data model.
Implementations are available for graph databases including Titan, Neo4J, MongoDB, and many others.
Pipes: Dataflow Processing Pipes is a dataflow framework for defining and connecting various data operations as a process graph.
Manipulating data with Pipes' primitives closely resembles data processing in Storm.
Pipes dataflow are directed acyclic graphs (DAG), much like a Storm topology.
It is a Java-based domain specific language (DSL) for graph traversal, query, analysis, and manipulation.
The Gremlin distribution comes with a Groovy-based shell that allows the use of interactive analysis and modification of a Blueprints graph.
Frames: Frames is an object-to-graph mapping framework analogous to an ORM but tailored for graphs.
Furnace: The Furnace project aims to provide implementations of many common graph algorithms for Blueprints property graphs.
Rexster: Rexster is a graph server that exposes Blueprints graphs through a REST API, as well as a binary protocol.
For our purposes, we will be focusing on the Blueprints API for populating a.
Blueprints API to create the graph depicted in the previous diagram:
Later, we will demonstrate how to connect to a distributed graph database.
You may be wondering why we are passing null as a parameter to theaddVertex() and addEdge() methods at the first argument.
This argument is essentially a suggestion to the underlying Blueprints implementation for a unique ID for the object.
Passing in null as the ID simply has the effect of letting the underlying implementation assign an ID to the new object.
Gremlin is a high-level Java API built on the top of the Pipes and Blueprints.
In addition to querying a graph, it is also easy to create and manipulate graphs.
You will learn more about using the Gremlin API and DSL later in the chapter.
The application we're building will utilize Apache Kafka and its dependencies.
If you haven't done so already, set up ZooKeeper and.
Kafka according to the instructions in the ZooKeeper installation section.
To install Titan, download the Titan 0.3.x complete package from Titan's.
Titan's complete distribution package includes everything that is necessary for.
At the time of writing, Storm and Titan use different versions of the Kryo library, which will cause problems when the two are used in conjunction.
To patch Titan in order to properly enable serialization between Storm and.
Titan, replace thekryo.jar file in the Titan distribution with the kryo.jar file that comes with Storm:
At this point, you can test the installation by running the Gremlin shell:
Passing a directory path to the create() method will return a Blueprints graph implementation, specifically.
Since the Gremlin shell is a Groovy REPL, we can.
In order to download and run Cassandra, we need to execute the following.
The default file that comes with the Cassandra distribution will create a.
To run Titan with Cassandra, we need to configure it to connect to our.
As you can probably surmise, this configures Titan to connect to the.
For this project, we may not need to actually run the Titan server.
Since we're using Cassandra, Storm and Gremlin should be able to share the backend without any issues.
With the Titan backend configured, we are ready to create our data model.
The primary entity in our data model is a Twitter user.
The user vertex models a user's Twitter account information, which is shown.
The URL vertex provides a reference point for unique URLs:
The mentions_url edge represents a relationship between the User and URL objects:
In order to connect to the Twitter API, we must first generate a set of OAuth.
The next page will display the details of the OAuth settings for your application.
At the bottom of the page, click on the Create my access token button.
This will generate an OAuth Access token and a secret key.
The Twitter4J client is broken down into a number of different modules that.
These modules can be included in the project by adding the following Maven dependencies:
The easiest way to do this is to create the file in the resourcesfolder of your Maven project.
We're now ready to use the Twitter4J client to connect to Twitter's.
The purpose of our Twitter client is straightforward; it will perform the following functions:
After registering the listener, we create a FilterQuery object to filter the stream based on a set of keywords.
For convenience, we use the program arguments as the list of keywords so the filter criteria can be easily changed from the command line.
The StatusListener class defines several callback methods for events that can occur during the lifetime of a stream.
The onStatus() method is our primary interest, since it is the method that gets calls whenever a new Tweet arrives.
In addition to the raw text of the status message, the Status object includes convenient methods for accessing all the associated metadata, such as user information, the hashtags, URLs, and user mentions contained in the tweet.
The bulk of our onStatus() method builds up the JSON structure before finally logging it to the Kafka queue via the Logback Kafka Appender.
Finally, by using the generic Blueprints API, our Trident state implementation.
The heart of the topology will be a Trident state implementation responsible.
Recall that a Trident state implementation consists of three components:
StateFactory: The StateFactory interface defines the method Trident uses to create the persistent State objects.
State: The Trident State interface defines the beginCommit() and commit()methods that are called before and after a Trident batch partition is written to the backing store.
In addition to these abstractions provided by Trident, we will introduce two.
Before diving in to the Trident state implementation, let's quickly look at these interfaces.
The GraphFactory interface contract is simple: given a Map object that represents theStorm and topology configuration, return.
Later, we will implement this interface to return a connection to a Titan graph database.
Given a graph object, TridentTuple, and TridentCollector, manipulating the graph and optionally emitting additional tuples is the job of.
Later in the chapter, we will implement this interface to populate a graph based on the content of a Twitter status message.
Trident's StateFactory interface represents the entry point for a state implementation.
In our use case, we're not concerned with partitions, so.
The code snippet of the GraphState class is as follows:
If theupdate() method succeeds for all batch partitions, the Trident transaction will complete and the State.commit() method will be called.
Notice that the update() method that actually updates the graph state is simply a public method of the GraphState class and not overridden.
As you will see, we will have the opportunity to call this method directly in.
The GraphUpdater class implements the updateState() method that Storm will call (potentially repeatedly in the case of batch failures/replays)
The GraphFactory interface we defined earlier creates a TinkerPop Graph implementation, where a Map object represents a Storm configuration.
The following code illustrates how to create TitanGraph backed by Cassandra:
In order to populate the graph database with relationships gleaned from.
The following code illustrates parsing the Twitter status message's JSON object and.
Extract and project only the data we are interested in.
Build and connect the Trident GraphState implementation to our stream.
Depending on the popularity of the keywords used for the query, it may.
To query the graph, we need to launch the Gremlin shell and create.
The g variable now contains a Graph object we can use to issue graph traversal queries.
The following are a few sample queries you can use to get.
To find all the users who have tweeted #hadoop hashtag and to show the number of times they have done this, use the following code:
To count the number of times the #hadoop hashtag has been tweeted, use the following code:
The Gremlin DSL is very powerful; covering the complete API could fill.
In this chapter, we introduced you to graph databases by creating a topology.
While graph databases are not perfect for every use case, they represent a.
In earlier chapters, we saw a pattern that combined real-time analytics using.
Typical applications of Storm focus on a never-ending stream of data.
The system includes a queue to accommodate varying amounts of load.
Even the untrained eye will recognize that such a system does not provide true.
To support real-time scenarios more completely, timeouts and Service Level.
Agreements(SLA) must be monitored from the reception of the data to the.
For this reason, when exposing features and functions via HTTP, we.
In this chapter, we will explore Storm's place in an architecture that exposes a.
The "hello world" of the artificial intelligence world is tic-tac-toe.
On a turn, a player places their symbol in any open cell in the grid.
If by placing their symbol, it completes a horizontal, vertical, or diagonal line.
A common approach to developing Artificial Intelligence programs for games.
A game tree is a tree structure whose nodes are game states.
A sample game tree for tic-tac-toe is shown in the following diagram:
The simplest of algorithms that traverses a game tree searching for the best.
A client invokes the algorithm with a game state, a depth, and a Boolean.
In our use case, the game state is fully encapsulated by.
The first few lines of the code are the base case.
In a game of alternating turns, the depth indicates how.
In our use case, the Storm topology need not track the depth.
Typically, each player is given a set amount of time and must make his or her.
After the algorithm checks for the base case, it calls the move() method, which returns boards for all possible moves.
The Negamax algorithm accomplishes the same more succinctly by alternating the sign of the score.
Additionally, in a real-world scenario, we might apply Alpha-Beta pruning, which attempts to trim the branches of the tree that are explored.
The algorithm only considers branches that fall within a threshold.
In our use case, this is not necessary because the search space is small enough to explore in its entirety.
In our simple use case, it is possible to enumerate the entire game tree.
In an extreme case such as Go, experts have calculated the.
The goal of the Minimax algorithm is to traverse the game tree and assign a.
For a leaf node, we must interpret the game state into a.
In our simple use case, there are three possible outcomes:
In our synchronous system, however, we might very well run out of time.
In this case, we need to calculate the score from.
For our simple use case, we will compute the score for any board by.
The preceding table applies only if the remaining cells in the line are empty.
Although there are improvements to the preceding heuristic, it suffices for this.
And, since we expect Storm to work continually on our game tree, we.
Finally, armed with an approach, our algorithm and a scoring function, we are.
Examining the preceding algorithm, there are a number of interesting design.
Storm provides a means of interacting with topologies synchronously, when.
With the advent of Trident, DRPC was deprecated in native Storm and is now.
DRPC, which is what we would require here, it is not a mainstream.
Additionally, that work would rely on the deprecated classes within the native.
Thus, we need to find alternative means to create a recursive structure.
Once we find a construct to implement the recursion, we need to be able to.
If we map our algorithm directly to Storm constructs, we would expect a.
The isLeaf filter decides whether this is an end state (for example, win, loss, or draw)
If the currentBoard field is not an end state, the GenerateBoards function emits all the new boards, replacing the value.
If the isLeaf filter determines that this is an end state, we need to score thecurrentBoard field and then update all the parents to reflect that new score.
TheScoreFunction computes the score of the board and persists that to the GameTree State.
To update the parents, we iterate over each of the parents and query the.
Constructing such a topology is not only impossible, but also not recommended for reasons described in the following sections.
You can already see that this data flow is not as straightforward as our.
There are a few constraints within Trident and Storm that force.
Firstly, notice that we are forced to maintain our own call stack in the form of a list of parents because Storm and Trident do not have any mechanisms to access the results of functions downstream in the topology.
In classic recursion, the results of the recursive method call are immediately available within the function and can be incorporated into the results of that method.
Thus, the preceding data flow resembles a more iterative approach to the problem.
Secondly, in the preceding data flow, we invoke a magical ability to replace the value of a field.
We do that in the recursive emit from the GenerateBoards function.
Replacing thecurrentBoard field with the new board is not possible.
Additionally, adding thecurrentBoard field to the parents list would require updating the value of the parentsfield.
To get around tuple immutability, we could always add additional fields to the tuple—one for each layer of the recursion—but Trident requires that all fields be declared prior to deployment.
We have additional problems when we consider tuple acknowledgement in this data flow.
At what point do we acknowledge the initial tuple that triggered the processing? From a logical data flow perspective, that initial tuple shouldn't be acknowledged until all the children for that node have been considered and the game tree state reflects those scores.
Surely, however, the processing time to compute large subsections of the game tree for any non-trivial game would most likely exceed any tuple timeouts.
Another issue with topology is the multiple paths that emit from the isLeaf filter.
Presently, there is no way to output to multiple streams within Trident.
As we will see, you can work around this by forking the stream and affecting the decision as filters on both streams.
Lastly, because we do not have access to the return values, updating the parent scores requires a read-before-write paradigm.
The following sequence diagram demonstrates the issues that arise in read-before-write constructs in the absence of locking mechanisms:
In the preceding diagram, there are two threads operating independently.
In our use case, this occurs when multiple children complete simultaneously and attempt to resolve the maximum score of a parent node at the same time.
Both threads compare the current maximum to their respective child scores and update the maximum with new values.
Since the second thread's update takes place after the first, the result is an incorrect maximum value for the parent node.
In the next section, we will see how to properly address the preceding constraints to produce a functional system.
To accommodate the constraints outlined in the preceding section, we will.
The system is broken down into two topologies: the Recursion.
To affect the recursion, we introduce two queues in the system.
Recursion Topology consumes from that queue via the Work Spout.
If the node is a leaf node, the board is queued on the Scoring Queue using.
Then, the Scoring Function emits a tuple for the current node and.
In the following design, we will demonstrate how we accommodate.
However, before we move on to the design, notice that because we introduced.
In the second topology, a tuple is acknowledged when the current board and.
Also notice that we do not need to introduce new fields or mutate existing.
The second topology is the same but adds a single additional field to capture the score.
Notice also that we forked the stream coming out of the Work Spout.
Instead, both GenerateBoards and IsEndGame must determine whether the game has ended and react accordingly.
In GenerateBoards, the tuple is filtered to avoid an infinite recursion.
When functions are able to emit to different streams, we will be able to collapse this function into a.
In a real production implementation, we would most likely use a.
We will look at each of the topologies in depth, but first, let's have a look at the.
To simplify things, we've encapsulated the game logic and the.
The Board class encapsulates the board itself in a multidimensional string array as a member variable.
Notice also that the Board class provides a toKey() method.
This key uniquely represents the board and is what we will use as a unique identifier.
To completely represent the game state, we also need to know which player is.
This is the GameState object whose listing is shown in the following code snippet:
There is nothing terribly surprising in this class except for.
This member variable tracks all the previous board states for this path through the game tree.
Finally, we represent the player in the game with the Player class, which is shown in the following code snippet:
With the data model outlined previously, we can create a topology that.
The code for the topology is shown in the following code snippet:
The first section configures the in-memory queues for work and scoring.
The first prong of the fork is filtered for only.
Note that queues are instances of a BlockingQueue instance within a map, which links a queue name to the BlockingQueue instance.
The main method in this class is the emitBatch implementation for the Emitter interface.
This simply reads from the queue while it has data and while the maximum batch size has not been reached.
The enqueue() method is used by our LocalQueueFunction class to complete the recursion.
Note that the function is actually instantiated with the emitter function used by the spout.
This allows the function to enqueue data directly into the spout.
Again, this construct is useful when developing recursive topologies, but real.
Now, we turn our attention to the functions and filters specific to this topology.
The first is a simple filter used to filter out the endgame boards.
Note that this class is not necessary if Trident had support for emitting tuples.
The function adds the current board to the history list, and then queues a.
Alternatively, we could have implemented IsEndGame as a function, adding another field to capture the results; however, it was more constructive to use this as an example to motivate having multiple stream capabilities within functions.
The following is a sample output from the Recursive Topology:
The Scoring Topology is more straightforward in that it is linear.
TheScoreFunction scores the current board and emits that score for each board in the history.
The listing for ScoreFunction is shown in the following code snippet:
The function simply scores the current board and emits a tuple for the current.
Then, the function loops through the player emitting tuples for each.
Notice in the preceding code that we used a mutex to sequence the updates to scores, thereby eliminating the race condition mentioned earlier.
This only works because we are operating in a single/local JVM.
When this topology is deployed to a real cluster, this will not work; however, we do have a few options to address the issue.
As we see in other chapters, it is possible to leverage a distributed locking mechanism such asZooKeeper.
In this approach, ZooKeeper provides a mechanism for maintaining a mutex across multiple hosts.
This is certainly a viable approach, but distributed locks come at a cost to performance.
Every operation incurs overhead to accommodate what in reality might be an infrequent occurrence.
Another pattern that might be useful is the retry when stale approach.
In this scenario, along with the data, we also pull back a version number, timestamp, or checksum.
If the metadata has changed, it indicates that the value on which we based our decision is now stale and we should reselect the data.
With retries, in the extreme case where there is a tremendous amount of contention, a thread may have to be retried a number of times in order to commit an update.
However, with distributed locking, you may run into timeout issues if a single thread gets stuck, loses communication with the server, or fails entirely.
I suggest that you should look at Paxos and Cassandra's use of that algorithm to affect conditional updates at the following URLs:
In our simple case, we are extremely lucky, and we can actually incorporate the logic into the update directly.
As we have resolved our read-before-write issues, the topology is suitable to score all of the boards queued by the Recursive Topology.
The topology assigns a value to the endgame state and propagates that value up the game tree, persisting the proper score with the respective game state.
In a real production system, we would access that state from our DRPC topology to be able to look ahead multiple turns.
It is resolving a tie-game leaf node, shown at the beginning of the listing.
You can see that the value propagates through the parents after that, updating the current score for those nodes.
The final result of combining the Recursive Topology with the Scoring Topology is a set of topologies working together continually to enumerate as much of the problem space as possible.
Most likely, this process would be combined with heuristics that.
Also, we would prune the search space using heuristics to reduce the number of boards we need to evaluate.
Regardless, however, we will need to interact with the system through an interface in order to determine the best move, given a current game state.
This is what we will tackle in the next section.
Now that we have a functioning Recursive Topology that will continually seek.
The DRPC capabilities that Storm provided were ported to Trident and.
This was the major motivation for using Trident in this.
With DRPC, you construct a topology much like you would in the.
Then, we use .groupBy(state) and aggregate the results using anAggregator class's FindBestMove.
We then perform a simple projection to return only the best move to the client.
You might also want to take a look at Spring Breeze, which allows you to wire POJOs together into a Storm topology.
This is another approach to gain reuse, because those same POJOs could be exposed via web services without introducing DRPC.
First, we will have a look at the code for the topology:
This is passed in as an argument to thenewDRPCStream call, which is the crux of a DRPC topology.
From there on, the topology functions as a normal topology.
You can see the actual remote procedure call takes place via.
Presently, the signature for that method takes and returns only strings.
Since the current signature only accepts strings, we need to marshal the input.
This takes place in the ArgsFunction as shown in the following code snippet:
The second parameter to the call we made to client.execute() was a string that contained our input.
In this case, you can see it in the topology.
In order to marshal that string into a board, we.
The next two functions applied in the DRPC topology demonstrate the reuse.
Using the GenerateBoard function, we emit all the children for the current board.
As it was in the Scoring Topology, the output of the ScoreFunction is a triple of board,score, and player.
These are the scores for each of the children boards.
To determine our next best move, we simply need to.
We created an aggregating function named FindBestMove as shown in the following code snippet:
In this case, we want to emit the best possible move, combined with its score.
If you recall, for aggregation, Trident initially calls the init() method, which returns the initial aggregate value.
Note that the score variable of the BestMove class is seeded with the absolute minimum value.
Then, Trident makes subsequent calls to the aggregate() method, which allows the function to incorporate the tuple into the aggregate value.
Finally, Trident calls the complete() method when all values of tuples have been aggregated.
It is in this method that we emit the final best move.
In this example, it is O's turn, and he or she has a scoring opportunity.
What we showed is local invocation of a DRPC topology.
To invoke a remote topology, you need to launch the DRPC server.
You do this, just like any other Storm service, by executing the Storm script with drpc as the parameter as shown in the following code snippet:
The Storm cluster will connect to the DRPC server to receive invocations.
In order for it to do that, it needs to know the location(s) of the DRPC servers.
With the servers configured and the DRPC server started, the topology is submitted like any other topology, and the DRPC client can be used from any Java application that requires large-scale synchronous distributed processing.
To switch from a local DRPC client to a remote, the only line that needs to change is the instantiation of the DRPC client.
Instead of instantiating a local DRPC client, you need to use the following line:
The parameters specify the host and port of the DRPC server and should match the configuration in the YAML file.
In this chapter, we took on an AI use case.
Along the way, we noted a few constraints within Storm that make it more.
Combining synchronous and asynchronous topologies, with shared state, is a.
Trident state capabilities covered in other chapters, you should be able to.
In the next chapter, we integrate Storm with a non-transactional real-time.
In this chapter, we will extend the use of Trident to create a real-time financial.
In the previous example, we used Trident to tally running totals of events over.
It was sufficient for the simple use case that analyzed only a single.
Processing (OLAP) system, which is separated out from the On-line.
Data scientists use languages such as PIG to express their queries.
Then, these queries compile down into jobs that run over large sets of data.
Fortunately, they run on platforms such as Hadoop that distribute the.
Both of these approaches fall short for financial systems, which cannot afford.
In this chapter, we will extend our use of Storm to deliver a flexible system.
In our use case, we will tap into orders for shares of stock in a financial system.
Using this information, we will deliver pricing information over time, which is.
The canonical message format in the financial industry is the Financial.
As shown in the preceding message, tags are identified by.
Each tag has an associated field name and data type.
The important fields for our use case are shown in the following table:
To extend on our previous example, we could develop a framework for the.
We would need to anticipate and support all the different types of.
Druid is an open source, real-time analytical data store that supports fast.
The Master node recognizes the new segment, identifies Compute nodes for.
Thus, an architecture that integrates Storm with Druid looks similar to what is.
As depicted in the preceding diagram, there are three data.
It contains all the metadata information for all of the segments.
Each segment contains a merged index of the events for a specific time period.
The Compute Node is subscribed to the same path, and the.
For our example, the entire sequence of events is as follows:
The preceding diagram lays out the event processing downstream from Storm.
What is important to recognize in many real-time analytics engines is the.
If we re-examine Trident's state classifications, there are three different.
Transactional state requires the contents of each batch to be constant over.
The system is idempotent as long as all batches are identical.
The previous state is stored along with the batch identifier to tolerate changing batch composition in the event of replay.
It is important to realize that introducing state into a topology effectively.
When possible, the best approach is to ensure the entire system is idempotent.
If all writes are idempotent, then you need not introduce transactional storage.
Often, if state persistence is backed by a database over which you control the.
However, this is not always the case, especially in systems that perform.
If a tuple is replayed, the counter is again incremented, and you.
In short, to connect Storm to Druid, we will leverage the characteristics of a.
With the architectural concepts in place, let's return to the use case.
Then, those filtered tuples flow to the DruidState object, which is the bridge to Druid.
Just like the previous chapter, the spout itself is straightforward.
As shown in the preceding code, the Spout declares a single output field: message.
This will contain the FixMessageDto object that is generated by the Emitter, as shown in the following code:
From the preceding code, you can see that we reparse the file for each batch.
As we stated previously, in a real-time system we will probably receive.
In that design, we would parse the text in a function.
Although this Spout is only sufficient for this example, note that the composition of each batch is the same.
Since our state design relies on this characteristic, in a.
It examines the msgType object and filters messages that are not fill orders.
They contain the average price executed for that trade and.
This provides a good opportunity to point out the importance of serializability.
Note that in the preceding code the filter is operating on.
It would have been easier to simply use the SimpleFixMessage object, but SimpleFixMessage is not serializable.
This will not cause any problems when running on a local cluster.
Developers often commit changes to data objects within tuples that are not serializable.
To ensure that all objects in a tuple remain serializable, add unit tests that verify that objects are serializable.
The test is a simple one; use the following code:
Now, let us proceed to the most interesting aspects of this example.
To mitigate the inherent risks of connecting to a non-transactional.
At a high level, Storm creates state objects within worker JVM processes by.
A state object is created for every partition in the batch.
To ensure that every partition is processed at most once, we associate a.
The Firehose persists the identifier in ZooKeeper to maintain the state of.
Limbo This Zookeeper path contains the partition identifiers that Druid consumed in their entirety, but which may not be committed.
Completed This Zookeeper path contains the partition identifiers that Druid successfully committed.
While a batch is in process, the Firehose writes the partition identifier to the.
When Druid has pulled the entirety of a Storm partition, the.
Upon receiving the commit message from Druid, the Firehose moves the.
We are still susceptible to losing data in the event of.
However, if we assume that we can reconstruct the aggregations.
The following state machine captures the different phases of processing:
As depicted in the diagram, there is a loop between Buffering.
The third state is triggered when Druid has written the information to disk.
When that happens (as we will see later), the Firehose is notified and we can.
Until that commit is called, the batches consumed by Druid must.
While in Limbo, no assumptions can be made about the data.
In the event of a failure, Storm may leverage other TridentState instances to complete the processing.
The Firehose must check to see if the partition was already completed.
If so, the partition is a replay, probably due to a downstream failure.
Since the batch is guaranteed to have the same contents as before, it can safely be ignored since.
The Firehose must check to see if the partition is in limbo.
If this is the case, then Druid fully consumed the partition, but never called commit or the system failed after commit was called but before the Firehose updated ZooKeeper.
It should not attempt to complete the batch since it was fully consumed by Druid and we do not know the status of the aggregation.
It simply returns, enabling Storm to continue to the next batch.
The Firehose must check to see if the partition is in progress.
If this is the case, then for some reason, somewhere on the network, the partition is being processed by another instance.
In this case, the system should raise an alert for this partition.
In our simple system, we will simply proceed, leaving it to our offline batch processing to correct the aggregation.
In many large scale real-time systems, the users are willing to tolerate slight.
It is important to note that this approach succeeds because we are using a.
With the design in place, we can turn our attention to the implementation.
The sequence diagram for the implementation is shown as follows:
The preceding diagram implements the state machine shown in the design.
Once the real-time server is started, Druid polls the StormFirehose object using the hasMore()method.
The contract with Druid specifies that the Firehose object's implementation should block until data is available.
While Druid is polling and the Firehose object is blocking, Storm delivers tuples into the DruidState object's message buffer.
When the batch is complete, Storm calls the commit() method on the DruidState object.
Druid begins pulling data from the StormFirehose object via the nextRow() method.
When the StormFirehose object exhausts the contents of the partition, it places the partition in limbo, and releases control.
Finally, when the commit method is called on the StormFirehose, the.
When Druid calls run(), the implementation moves the partition to completion.
First, we will look at the Storm side of the equation.
That abstraction shielded us from the details of sequential batch processing.
In this scenario, we need more control over the persistence process than what.
As evident in the diagram, the DruidStateFactory class manages the embedded real-time node.
Without going into too much detail, the preceding code starts a real-time node.
The factory also implements the StateFactory interface from Storm, which allows Storm to use this factory to create new State objects.
As you can see in the preceding code, the State object is a message buffer.
It delegates the actual commit logic to the Firehose object, which we will examine shortly.
However, there are a few critical lines in this class that.
The conditional logic in the commit() method on the State object checks the ZooKeeper status to determine if this partition was already successfully.
Even though Storm should never call those methods concurrently, we chose to.
As shown in the preceding code, the updater simply loops through the tuples.
Before we turn our attention to the Druid side of the implementation, we.
In our example, this is realtime.spec, as shown in the following code:
For our example, the important elements in the preceding spec file.
The schema element defines the data and the aggregations that Druid should perform on that data.
ThetotalPrice field will be used to calculate the running stock price average over time.
The firehose element contains the configuration for the Firehose object.
As we saw in the StateFactory interface, an implementation registers a FirehoseFactory class with Druid when the real-time server is started.
When the real-time spec file is parsed, the type in the firehose element of the JSON is used to link back to the appropriate FirehoseFactory for a stream of data.
For more information on the JSON polymorphism, refer to the following.
For more information on the spec file, refer to the following website:
Now, we can turn our attention to the Druid side of the.
Firehose is the main interface one must implement to contribute data into a Druid real-time server.
Thus, the name specified as the@JsonTypeName must align with the type specified in the spec file.
The meat of the implementation is in the StormFirehose class.
Within this class, there are four critical methods that we will examine one by.
The sendMessages() method is the entry point into the StormFirehose class.
It is effectively the handoff point between Storm and Druid.
Then, it blocks waiting for Druid to fully consume the batch.
Then, the flow proceeds to the nextRow() method, which is shown as follows:
If there are no remaining messages in the queue, the sendMessages() method that we examined in the preceding code is released.
We are at a risk of losing the data entirely in the event of a.
Druid will then poll the hasMore() method, which is shown in the following code:
Since the queue is empty, the method will block until sendMessage() is called again.
This leaves only one remaining piece of the puzzle, the commit() method.
This method returns Runnable, which is called by Druid after it's finished persisting the messages.
As you can see in the following code, the Runnable does nothing but moves the transactions into the completed state in Zookeeper.
Now that we have examined all of the code, we can take a look at how the state.
When connecting to ZooKeeper through Curator, you supply a namespace.
Effectively, this is the top-level node under which the application data is.
The application then maintains three paths underneath that, where it stores batch.
The paths correspond to the states described in the design and are as follows:
In our implementation, all ZooKeeper's interactions for partition status are.
In the interest of space, we have only shown the constructor and the methods.
ZooKeeper and creates the three base paths as described in the preceding code.
It also provides methods that move a transaction between those.
Enough with the code, let's get on with the demo! We start the topology using.
For a better demo, we introduce random prices between zero and one hundred.
Once the topology is started, you will see the following output:
Using the ZooKeeper client, you can examine the status of transactions.
If ever there is more than one batch in the current path, then alerts should go out.
If ever there are batch identifiers in limbo that are not sequential, or substantially behind the current identifier, alerts should go out.
To clean up the state in ZooKeeper, you can execute the following code:
To monitor the segment propagation, you can use the MySQL client.
Now, the moment we have all been waiting for; we can see average stock.
API, it is not necessary to run a full-blown Druid cluster.
The final parameter of the curl statement references a file, the contents of which will be included as the body of the POST request.
If you recall, we had two aggregations in the spec file:
The events we are aggregating have two fields: symbol and price.
The preceding aggregations are applied at indexing time, and introduce two.
Recall that totalPrice is the sum of the prices on each event for that slice of time.
The orders field contains the total count of events in that slice of time.
Then, when we perform the query, Druid applies a second set of aggregations.
In our query, we group by symbol at a granularity of a minute.
Finally, we introduce a postaggregation method to calculate the average for that slice of time.
Issuing the curl statement to a running server results in the following response:
Since we updated the code to generate random prices between zero and one.
In this chapter, we gained a deeper appreciation for the Trident State API.
For future investigation, it would be beneficial to establish an idempotent.
Some people believe Storm will eventually replace Hadoop as demand.
For these reasons, batch processing infrastructure is often paired with.
In this chapter, we will implement an architecture that supports.
First, from a logical perspective, let's take a look at the Storm-Druid.
From the CAP theorem, we know that it is difficult for any distributed system.
First, Druid consumes the data via the Firehose interface and places that data in the memory.
Finally, this data is pushed to Deep Storage, which makes the data available.
Now, if we consider the implications of inconsistent data to fault tolerance, we.
One obvious solution to this problem is to push the segment to Deep Storage.
However, we still want real-time analytics and are willing to tolerate those.
For this to work, we will first persist the data prior to sending the data to.
Our batch processing system will read the data from that persistence.
Combining these approaches, we can achieve the throughput we need during.
The de facto standard for distributed batch processing is Hadoop.
The following diagram depicts the pattern we will use here:
The preceding pattern shows how we can integrate OLTP and OLAP systems.
The other gap that this approach fills is the ability to introduce new analytics.
Hadoop closes that gap since it can run over the historical data to populate.
Nathan Marz, the original author of Storm, refers to this approach as.
Now, let's apply this pattern to the field of Natural Language.
In this use case, we will search Twitter for relevant.
Twitter API, we will find the most relevant sets of Tweets, T.
Here, the frequency of a word w in a corpus C is as follows:
Since we are only concerned with the relative frequency, and the total count of.
For the denominator, we will use a freely available word frequency list from.
We will use Storm to process the results of the Twitter search and enrich the.
For this use case, we are focusing on a distributed computing pattern that.
While that remains the focus, the other key goal we are trying to achieve is.
In a live system, we would use a distributed storage mechanism for.
Thus, even in a disastrous scenario, whereby a data center is.
For this discussion, assume we are using Cassandra as our persistence.
With Cassandra, which has tunable consistency, writes will use a.
This ensures that a copy of the data is written consistently to all data centers.
Another benefit of using a distributed storage engine such as Cassandra is that.
In the preceding diagram, we have two physical data centers, each with a.
Additionally, we have a third virtual data center supporting the offline batch.
Ring 3 is a Cassandra cluster that is physically collocated.
Since local quorum seeks to gain consensus within the local data center, read traffic from Hadoop will not cross over into our.
In general, this is a great pattern to deploy if your organization has data.
Additionally, and arguably just as important as our ability to tolerate faults in.
For this example, we will again use Trident and build on the topology that we.
The TwitterSpout performs the search against the Twitter API periodically, emitting the tweets that it returns into a Trident stream.
Finally, we let Druid consume that information to perform the aggregations.
Druid partitions the data into temporal slices and persists that data.
In this case, because the persistence mechanism is our means of addressing.
Hadoop should be capable of using the persistence mechanism as an input.
With its tunable consistency and support for Hadoop, Cassandra makes for an.
Let's first examine the real-time portion of the system beginning with the.
In the end, after parsing and enrichment, the tuples have four fields as shown.
In reality, the system would most likely be monitoring multiple search phrases at a time.
Twitter4J API, and the Emitter function is not much more than a thin glue layer between that API and the Storm API.
In a more complex scenario, one might also tap into the Twitter Firehose and use a queue to buffer the live updates before emitting them into Storm.
The following are the key lines in the Emitter portion of the spout:
This function simply parses the tweet and emits one tuple per word in the tweet.
In a more sophisticated NLP system, this function will do more than simply split the tweet by whitespace.
An NLP system would most likely try to parse the tweet, assigning parts of speech to the words and associating them with one another.
Although, instant messages and tweets typically lack the traditional grammatical constructs that parsers are trained on, the system might still use elementary associations such as the distance between the words.
In such systems, instead of word frequencies, systems use n-gram frequencies where each n-gram comprises multiple words.
This is the number of times the word was encountered in a random sampled text.
The key code for this function is shown as follows:
The constructor in the code loads the word counts into the memory.
Each line contains the word and the frequency count for that word.
Again, since we are only worried about relative counts, we need not consider the total counts in the corpus.
However, if we were calculating a true likelihood, we would need to consider the overall total word count as well.
The execute method of the function is straightforward and simply adds the baseline count to the tuple.
However, if we examine the method that retrieves the count from the HashMapclass, notice that it includes a DEFAULT_BASELINE.
This is the value used when the system encounters a word that was not in the original corpus.
Since Twitter feeds contain many abbreviations, acronyms, and other terms that are not found typically in standard text, the DEFAULT_BASELINE becomes an important configuration parameter.
In some cases, unique words are important and unique because they pertain to the searchphrase field.
Others are anomalies because the sample corpus differs from the target corpus.
Ideally, the raw baseline counts would be drawn from the same source that the analytics are targeting.
In this case, it would be ideal to have both word and n-gram counts calculated using the entire Twitter Firehose.
We will not go into the details of a full multidata center Cassandra deployment here.
Instead, for this example, we will keep it simple and use the local file storage.
In the preceding code, the function simply persists the tuple in the native format that Druid expects to consume in the Hadoop indexing job.
This code is inefficient in that we are opening up the file for writing each time.
Additionally, notice that we generate a timestamp here that is not re-emitted with the tuple.
Ideally, we would generate a timestamp and add it to the tuple, which would then be used downstream by Druid to align the temporal partitioning.
Even though this function does not enrich the tuple at all, it must still re-emit the tuple.
Since functions can also act as filters, it is the obligation of the function to declare which tuples are passed downstream.
The function writes the following lines to the nlp.json file:
The Druid integration is the same that was used in the previous chapter.
At the heart of this implementation is the StormFirehose implementation, which maps the tuples into input rows for Druid.
The second contains the dimensions for that row, which is what.
Druid will use to perform the aggregations, and determines what queries you.
This will allow us to perform counts and groupings in our queries, as we will see in a moment.
First, let's look at the Druid configuration for ingesting the data.
Storage, while MySQL is used to write the segment metadata.
This configuration points to the realtime.spec file, which is what specifies the details of the analytics performed by the real-time server.
In addition to the temporal granularities, we also specify the aggregators in.
The wordcount field counts instances of rows that have the same values along the dimensions provided.
Thus, Druid can collapse the rows, adding a field named wordcount, which will contain the total count of the number of instances of that word found for that searchphrase and for that temporal slice.
In reality, the value for this is the same for each row.
We simply use max as a convenient function to propagate the value into an aggregation that we can then use when.
The following is the query we use to retrieve the.
At the bottom of the query, we specify the time interval in which we are interested.
In this use case, the aggregations exactly match the aggregations.
Specifically, we introduce the totalcount field, which contains the sum of wordcount.
This will therefore contain the total number of instances observed for that word andsearchphrase combination.
Additionally, we perform the same trick with baseline to pass that value through.
Finally, in this query, we include a post aggregation, which will combine the.
The following is a simple Ruby file that processes the results of the query and.
Notice that the URL we are using to access the server is the port of the.
If you change the dimensions or metrics you are capturing, be sure to delete the local directory that the real-time server is using to cache the data.
Otherwise, the real-time server may re-read old data that does not have the dimensions and/or metrics needed to fulfill the query; additionally, the query will fail because Druid is unable to find requisite metrics or dimensions.
Now, let's turn our attention to the batch processing mechanism.
Hadoop provides two major components: a distributed file system and a.
We will, however, use the MapReduce portion of Hadoop to.
In our simple example, we will run a local Hadoop job that will read the local.
Druid comes with a Hadoop job that we will use in this example.
Before we jump to loading data, a quick overview of MapReduce is warranted.
Although Druid comes prepackaged with a convenient MapReduce job to.
MapReduce is a framework that breaks processing into two phases: a map.
In the map phase, a function is applied to the entire.
Each application of the map function results in a set of tuples, each containing a key and a value.
The reducefunction emits another set of tuples, typically by combining the values associated with.
The canonical "Hello World" example for MapReduce is the word count.
The following are Ruby functions that express the map and reduce functions for the word count example.
The map function yields the following output, given the supplied input is as follows:
The corresponding reduce function looks like the following code snippet:
The MapReduce function would then group the values for each key and pass.
With Hadoop as the background, let's take a look at our setup for Druid.
The runtime properties for the Master and Compute nodes are largely the.
Also, note that if you are running the Master and Compute servers on the.
Druid packages all the server components and their dependencies into a single.
Using this JAR file, you can start the Master and.
For the Compute node, we use the following code snippet:
For the Master node, we use the following code snippet:
Once both nodes are running, we are ready to load data with the Hadoop job.
With our servers up and running, we can examine the internals of the Druid MapReduce job.
The HadoopDruidIndexer function uses a JSON configuration file much like therealtime.spec file.
The file is specified on the command line when the Hadoop job is started, as shown in the following code snippet:
The following is the batchConfig.json file we used in this example:
The two fields of particular interest are thepathSpec and rollupSpec fields.
The rollupSpec field contains the same aggregation functions that we included in the realtime.spec file during transactional processing.
Additionally, notice that the timestamp column and format are specified, which aligns with the field that we are outputting in the persisted file:
The HadoopDruidIndexer function loads the preceding configuration file and performs themap/reduce functions to construct the index.
If we look more closely at that job, we can see the specific functions it is running.
Druid runs a couple of jobs to index the data, but we will focus on the IndexGeneratorJob.
In the IndexGeneratorJob, Druid configures the job with the following lines:
The preceding properties are set on nearly all Hadoop jobs.
They set the input and output classes for each phase of the processing and the classes that implement the Mapper andReducer interfaces.
For a complete description of Hadoop job configurations, visit the following URL:http://hadoop.apache.org/docs/r0.18.3/mapred_tutorial.html#Job+Configuration.
The job configuration also specifies the input paths, which specify the files or other data sources for processing.
You can see that out-of-the-box, Druid only supports instances of FileInputFormat.
As an exercise for the reader, it might be fun to enhance the DruidHadoopIndexer function to support direct reads from Cassandra, as envisioned in the hypothetical architecture.
We can see that the superclass map method handles rows that do not parse, marking them invalid, and checks to see if the row contains the necessary data to carry out the map.
Specifically, the superclass ensures that the row contains a timestamp.
The map requires the timestamp because it partitions the data into time slices (that is, buckets) as we see in theabstract method call to innerMap, which is shown as follows:
The key line in this method and in any Hadoop-based map function is the call tocontext.write that emits the tuple from the map function.
In this case, the map function is emitting a key of the type SortableBytes, which represents the bucket for the metric and the actual text read from the input source as the value.
At this point, after the map phase completes, we have parsed the file, constructed our buckets, and partitioned the data into those buckets, sorted by timestamp.
Each bucket is then processed via calls to the reduce method, which is shown as follows:
As you can see, the reduce method contains the meat of the analytics.
It constructs the index based on the aggregations in the roll up specification and dimensions specified in the batch configuration file.
The final lines of the method write the segment to a disk.
In the end, when you run the DruidHadoopIndexer class, you will see something similar to the following code snippet:
To query the data loaded by thehistorical / batch processing mechanism, update the query to specify the historical data source and use the port of the Compute node.
Provided everything is loaded properly, you will receive the aggregations we saw originally with the real-time server; an example of this is shown as follows:
Now, if we schedule the Hadoop job to run periodically, the historical index will lag the real-time index but will continually update the index, correcting errors and accounting for any system failures.
In this chapter, we saw that pairing a batch processing mechanism with a.
The chapter also included an introduction to Hadoop, using Druid's.
In the next chapter, we will take an existing batch process that leverages Pig.
At the same time, we will demonstrate how to deploy Storm onto the.
In the previous two chapters, we saw how we might integrate Storm with a.
We will examine a batch processing system that computes the effectiveness of.
We will take the system that was built on Hadoop.
To do this, we will leverage the Storm-YARN project out of Yahoo! The.
Storm-YARN project allows users to leverage YARN to deploy and run Storm.
The running of Storm on Hadoop allows enterprises to consolidate.
In our use case, we will process the logs of an advertising campaign to.
In this chapter, we will convert the Pig script into a topology and deploy that.
In advertising, an impression is an advertising event that represents an.
For our analysis, we will track each impression and use a field to.
Each row in the flat file contains four fields that are described as follows:
We will use this to represent users in the system.
In this context, we will calculate the effectiveness of a campaign by counting.
The number of impressions is simply the total count of impressions for the.
Since we are most likely paying per impression, we want to.
We touched on Hadoop in the previous chapter, but we focused mainly on the.
The recent componentization within Hadoop allows any distributed system to.
Hadoop 2.0 separates out resource management into YARN, allowing other.
In our case, this allows us to run Storm on YARN as shown.
As shown in the preceding diagram, Storm fulfills the same function as.
To understand this better, it is worth examining the nodes in a Hadoop cluster.
Storage takes place on each of the slave nodes that run DataNode processes.
Nimbus starts up and connects to the ZooKeeper when the application is.
The following diagram depicts the Hadoop infrastructure running Storm via.
As shown in the preceding diagram, YARN is used to deploy the Storm.
That, in turn, creates an instance of Storm Nimbus and the.
Each of these supervisor processes can spawn workers within its container.
To complete the architectural picture, we need to layer in the batch and.
Often a queuing mechanism such as Kafka is used to queue work for a Storm.
To simplify things, we will use data stored in HDFS.
Kafka instead of HDFS as shown in the following diagram:
As the preceding diagram depicts, our data will be stored in HDFS.
In each of the systems, the following steps take place:
The Pig script is compiled to MapReduce jobs and submitted as a job.
The analyses reads the data from storage and performs the analyses.
Storm reads the work, typically from Kafka; but in this case, the topology reads it from a flat file.
For more information on the Storm-YARN project, visit the following URL:
To configure a set of machines, you will need a copy of Hadoop residing on.
In this example, we will assume that we have a Master node.
Test the YARN configuration by executing the following command line:
As per the architecture diagram, to configure HDFS you need to start the.
To start the NameNode, you need to specify a host and port.
Configure the host and port in the core-site.xml file by using the following elements:
This configuration is stored in the hdfs-site.xml file, in the dfs.name.dir variable.
To keep the example simple, we will also disable security on the distributed filesystem.
After these edits, the HDFS configuration file looks like the following code snippet:
The final step before starting the NameNode is the formatting of the distributed filesystem.
The last line of the startup will indicate where the logs are located:
Despite the message, the logs will actually be located in another file with the same name but with the suffix log instead of out.
Also, ensure that the name directory you declared in the configuration exists; otherwise, you will receive the following error in the logfile:
Verify that the NameNode has started with the following code snippet:
Additionally, you should be able to navigate to the UI in a web browser.
Clicking on the Live Nodes link will show the nodes available and the space allocation per node, as shown in the following screenshot:
Finally, from the main page, you can also browse the filesystem by clicking on Browse the filesystem.
In general, it is easiest to share the core configuration file between nodes in the cluster.
Thedata nodes will use the host and port defined in the core-site.xml file to locate the NameNode and connect to it.
Additionally, each DataNode needs to configure the location for local storage.
This is defined in the following element within the hdfs-site.xml file:
If this location is consistent across slave machines, then this configuration file can be shared as well.
With this set, you can start the DataNode with the following command:
Once again, verify that the DataNode is running using jps and monitor the logs for any errors.
In a few moments, the DataNode should appear in the Live Nodes screen of the NameNode as previously shown.
With HDFS up and running, it is now time to turn our attention to YARN.
Similar to what we did with HDFS, we will first get the ResourceManager running and then we will attach slave nodes by running NodeManager.
The ResourceManager has various subcomponents, each of which acts as a server that requires a host and port on which to run.
All of the servers are configured within the yarn-site.xml file.
For this example, we will use the following YARN configuration:
The first four variables in the preceding configuration file assign host and ports for the subcomponents.
Since our Pig scripts compile down into MapReduce jobs, they depend on this variable.
Like the NameNode, start the ResourceManager with the following command line:
The NodeManager uses the same configuration file (yarn-site.xml) to locate the respective servers.
Thus, it is safe to copy or share that file between the nodes in the cluster.
After all NodeManagers register with the ResourceManager, you will be able to see them in the ResourceManager UI after clicking on Nodes, as shown in the following screenshot:
With Hadoop in place, we can now focus on the distributed processing.
The first of the distributed processing frameworks that we will examine is Pig.
Although Pig can read data from a few different systems (for example, S3), we.
The preceding commands create a directory for the data file and copy the.
To execute a Pig script against that data, we will need to install Pig.
Just like we did with Hadoop, we will add the following environment variables.
Once you have those variables in your environment, you should be able to test.
By default, Pig will read the Hadoop configuration and connect to the.
Via Pig, you can interact with HDFS in the same way as you would with a.
For example, ls and cat both work as shown in the following code snippet:
Now that we have infrastructure working for batch processing, let's leverage.
Since Storm-YARN is a new project, it is best to build from source and create.
After building the distribution, you need to copy the Storm framework into.
This allows Storm-YARN to deploy the framework to each of the nodes.
By default, Storm-YARN will look for the Storm library as a ZIP.
Assuming that you are in the Storm-YARN directory, you can copy the ZIP file.
You can then verify that the Storm framework is HDFS by browsing the.
With the Storm framework staged on HDFS, the next step is to configure the.
An example of the YAML file is shown in the following code snippet:
To monitor whether Storm-YARN will continue to require a pre-existing ZooKeeper instance, go through the information available at the following link:
With the the Storm framework in HDFS and the YAML file configured, the.
You specify the location of the YAML file, the queue for YARN, a name for the.
Queues in YARN are beyond the scope of this discussion, but by default YARN is configured with a default queue that is used in the preceding command line.
After executing the preceding command line, you should see the application.
Clicking on the application shows where the application master is deployed.
Drilling down one more level, you will be able to see the logfiles for Storm, as.
With any luck, the logs will show a successful startup of Nimbus and the UI.
Examining the standard output stream, you will see Storm-YARN launching.
URLs, you will see the supervisor logs for the respective instances.
Navigate to the UI using the node that hosts the ApplicationMaster, and then.
In a browser, open http://node:7070/, where node is the host for the Application Master.
You should see the familiar Storm UI as shown in the.
In the preceding statement, the appId parameter corresponds to the appId parameter assigned to Storm-YARN, and it is visible in the Hadoop administration screen.
Storm-YARN will use the local Hadoop configuration to locate the master Hadoop node.
If you are launching from a machine that is not a part of the Hadoop cluster, you will need to configure that machine with the Hadoop environment variables and configuration files.
With both the batch and real-time infrastructure in place, we can focus on the.
First, we will take a look at the processing in Pig, and then we will.
The Pig script is shown in the following code snippet:
The first LOAD statement specifies the location of the data and a schema with which to load the data.
Web Services (AWS), this will most likely be an S3 URL.
In the subsequent lines after the Load statement, the script calculates all the distinct click-thru.
In the first line, it filters the dataset for only the rows that.
After filtering, the rows are filtered for only distinct entries.
The second dimension of the problem is then computed in the subsequent.
No filter is necessary since we simply want a count of the impressions by.
The first element in the output is the campaign identifier.
In the preceding topology, we fork the stream into two separate.
Those two streams are then joined using the topology.join method.
Operations such as join are well defined for discrete sets, but it is unclear how to translate their definitions into a real-time world of infinite event streams.
Instead, we will use Trident's state construct to share the counts between the.
This is shown in the corrected topology in the following diagram:
In a real system, the preceding spout would most likely read from a Kafka.
Alternatively, a spout could read directly from HDFS if we sought to.
There is some preliminary work on a spout that can read from HDFS; check out the following URL for more information:
To compute the distinct count of all the click-thru, the topology first filters the.
Without persistent storage, the example would eventually run out of.
There is active work on algorithms to approximate distinct sets against data streams.
For more information on Streaming Quotient Filter (SQF), check out the following URL:
For our example, the Distinct function is shown in the following code snippet:
Once it has all the distinct click-thru, Storm persists that information into.
However, in a real system we would most likely apply a distributed storage mechanism.
The result of processing the initial stream is a TridentState object that contains the count of all the distinct click-thru grouped by the campaign.
The critical line that joins the two streams is shown as follows:
This incorporates the state developed in the initial stream into the analysis.
As shown in the preceding code, this class computes effectiveness by.
To deploy the preceding topology, we must first retrieve the Storm-YAML.
The preceding command interacts with the specified instance of the.
Storm-YARN application to retrieve a storm.yaml file that can be used to deploy topologies by using the standard mechanisms.
Notice that the values are the same as those emitted by Pig.
This stands to reason because we now have a real-time system, which is.
Secondly, and perhaps most importantly, we examined Storm-YARN; it allows.
Finally, as future work, the community is exploring methods to run Pig scripts.
In the next chapter, we will explore automated Storm deployment to the cloud.
In this chapter, we will introduce you to deploying and running Storm in a.
Fortunately, today there are a number of cloud hosting providers that offer.
Most cloud hosting providers offer a wide range of services and.
One of the key benefits of using a cloud provider is the ability to deploy and.
We'll start by provisioning a Storm cluster with a cloud provider.
Using Apache Whirr to automate the provisioning and deployment of.
Using Vagrant to launch and provision virtualized Storm clusters in a.
Amazon EC2 is the central part of many remote compute services offered by.
EC2 allows users to rent virtual compute resources hosted on.
We'll begin by setting up an EC2 account and manually launching a virtual.
Establishing an AWS account is easy but requires an Amazon account.
If you don't already have an Amazon account, sign up for one at http://www.amazon.com/
With your Amazon account established, you can set up an AWS account athttp://aws.amazon.com/
The AWS Management Console acts as the main administrative interface to all the cloud services that Amazon offers.
Before you can launch any EC2 instances, you will need a key pair.
To create a new key pair, click on the Key Pairs link to open the key pair manager, as shown in the following screenshot:
You will be prompted to give the key pair a name.
At this point, depending on which browser you are using, you will be prompted to download your private certificate file or the file will be downloaded automatically.
It's very important that you keep this file safe since the key will give you full administrator access to any EC2 images launched with that key.
Immediately after downloading your private key, you should change its file permissions so it is not publicly readable; for example, with UNIX, use the following command:
Many SSH clients will look at the permissions of the key file and issue a warning or refuse to use a key file that is publicly readable.
Once you have created a key pair, you are ready to launch an EC2 instance.
The first step in launching an EC2 machine is to select an Amazon Machine Image (AMI)
An AMI is a virtual appliance template that can be run as a virtual machine on Amazon EC2
Amazon provides a number of AMIs for popular operating system distributions such as Red Hat, Ubuntu, and SUSE.
For our purposes, we will be using an Ubuntu Server instance as shown in the following screenshot:
Once you've selected an AMI, you will be prompted to select an instance type.
Instancetypes represent virtual hardware profiles with varying memory (RAM), CPU cores, storage, and I/O performance.
The type you select will depend on your use case and budget.
After selecting an instance type, you are ready to launch the virtual machine by clicking on the Review and Launch button, reviewing the instance details, and then.
You will then be prompted to select a key pair for remote login and management of the instance.
After a few minutes, your instance will be up and running as shown in the following screenshot:
When you launch an instance, EC2 will preconfigure SSH with the key pair you selected during the setup, allowing you to remotely log in to the machine.
To log in to the instance remotely, you will need the private key file you downloaded earlier as well as the public DNS name (or public IP address) assigned to the instance.
You can find this information in the EC2 Management Console by clicking on the instance and.
You can now connect to the instance with the following command:
For example, to connect as the "ubuntu" user using the my-keypair.pem private key file:
The Ubuntu user has administrator permissions on the remote host, giving you the ability to configure the machine the way you like.
At this point, you could install Storm or any other services you like.
However, manually configuring instances for anything larger than a trivially sized cluster will quickly become time-consuming and unmanageable.
In the next section, we'll introduce a way to automate this process as part of a more scalable workflow.
Whirr began as a set of shell scripts for running Hadoop on Amazon EC2, and.
Begin by downloading a recent release and unpacking it on the computer you.
For convenience, add Whirr's bin directory to your system's PATH environment variable so you can run the Whirr command from any directory as follows:
Whirr uses SSH to communicate with cloud instances, so we will create a.
In order for Whirr to interact with your cloud provider account, it needs to.
If your AWS account is new, you will need to.
The key file you downloaded will contain your Access Key ID and Secret.
Whirr gives you three options for specifying your cloud credentials:
We'll use the last option as it is the most convenient as follows:
Now that we have Whirr installed, let's turn our attention toward cluster.
Let's start by looking at the minimum configuration necessary to launch a.
With just these two properties defined, we have enough to tell Whirr how to.
However, there are a few options that you will typically want.
For example, we'll want Whirr to use the dedicated key pair we.
Next, we'll configure Whirr with the hardware specification we want and the.
The whirr.image-id property is provider specific and specifies which machine image to use.
Since we're just testing Whirr, we've chosen the smallest (and least expensive)
Finally, we've specified that we want our cluster deployed in the us-east-1region.
For a complete list of public AMIs, perform the following steps:
From the EC2 Management Console, select a region from the drop-down menu in the upper-right corner.
Our configuration file for a ZooKeeper cluster now looks like the following.
When the command completes, Whirr will output the list of instances created.
You can log in to instances using the following SSH commands:
To destroy a cluster, run whirr destroy-cluster with the same options used to launch it.
When you are finished with the cluster, you can terminate all instances with.
To install the Whirr Storm service, simply place the JAR file in.
Next, verify the installation by running the Whirr command without arguments to print a list of instance roles available to Whirr.
In our previous Whirr example, we created a cluster of three nodes where each node had only the ZooKeeper role.
Whirr allows you to assign multiple roles to a node, which we'll need to do for a Storm cluster.
Before we get into the details of configuring Whirr for Storm, let's take a look at the different roles Whirr Storm defines as shown in the following table:
Only one node per cluster should be assigned with this role.
This role should only be assigned to nodes that also have the storm-supervisor role.
You must have at least one ZooKeeper node in a Storm cluster, and for multi-node ZooKeeper clusters, the number of nodes should be odd.
If we wanted to create a multinode cluster with one node running Nimbus and Storm UI, three nodes running the supervisor and logviewer daemons, and a 3-node ZooKeeper cluster, we would use the following configuration:
All other Storm configuration parameters will inherit default values unless specifically overridden.
Although Whirr Storm will automatically calculate and configure thenimbus.host value for the cluster, you will still need to tell the Storm executable the host name of the Nimbus host when running the command locally.
The easiest way to do this, and the most convenient if you have multiple clusters, is to specify a hostname for nimbus with the –c flag as follows:
Other Storm configuration parameters can be specified in the Whirr configuration file by adding a property with a key prefixed with whirr-storm.
The preceding code would result in the following line in storm.yaml:
When a new machine instance is launched on EC2, most of its network ports are blocked by a firewall by default.
To enable network communication between instances, you must explicitly configure firewall rules to allow ingress and egress on specific ports between hosts.
By default, Whirr Storm will automatically create the security groups and firewall rules necessary for Storm components to communicate, such as opening the Nimbus Thrift port for topology submission and opening port 2181 between Nimbus and Supervisor nodes, and ZooKeeper nodes as shown in the following diagram:
However, in many cases, Storm's worker processes will need to communicate with other services on arbitrary ports.
For example, if you have a spout that consumes data from an external queue or a bolt that writes to a database, you will need additional firewall rules to enable that interaction.
Consider a scenario where we have a spout reading data from a Kafka queue and streaming data to a bolt that writes to a Cassandra database.
The property value is a comma-delimited list of role-port pairs as shown in the following code snippet:
For example, to set up the rules for our scenario, we would use the following setting:
Vagrant (http://www.vagrantup.com) is a tool similar to Apache Whirr in that.
Installing VirtualBox is largely just a matter of running an.
Linux packages and Vagrant installers for OS X and Windows are available on.
You can verify the installation by opening a terminal and typing vagrant --version as follows:
If the command fails for any reason, consult the Vagrant website for solutions.
The two arguments to the vagrant init command are name and URL for a Vagrant box.
A Vagrant box is a virtual machine image that is specially.
The name parameter simply provides an identifier for the box, so it can be reused in other Vagrant configurations, while.
The next step is to launch the virtual machine as follows:
If the Vagrant box specified in the vagrant init command is not found on the local disk, Vagrant will download it.
You can then log in to the machine using SSH commands:
The Vagrant user has administrative privileges so you are free to do anything.
When you are finished with the virtual machine, you can shut it.
When we ran the vagrant init command, Vagrant created a file named Vagrantfile inthe directory where we ran the command.
This file describes the type of machine(s) a project requires and how to provision and set up the machines.
Vagrantfiles are written using a Ruby syntax that is easy to learn even if you are not a Ruby developer.
The initial content of theVagrantfile will be minimal and largely made up of documentation comments.
With the comments removed, our Vagrant file looks like the following code snippet:
As you can see, the file simply contains the box name and URL that we passed to thevagrant init command.
We will expand on this later as we build out a Vagrant project to provision a virtualized Storm cluster.
When you launch a machine with vagrant up, by default Vagrant will create a shared folder on the virtual machine (/vagrant) that will be synchronized with the contents of the project directory (the directory containing the Vagrantfile)
You can verify this functionality by logging in to the virtual machine and listing the contents of that directory.
This is where we will store all our provisioning scripts and data files.
While the vagrant destroy command removes all traces of a virtual machine, it leaves the contents of the project directory untouched.
This allows us to store persistent project data that will always be available to our virtual machines.
Vagrant supports provisioning with shell scripts as well Puppet and Chef.
We'll use the shell provisioner since it is the easiest to start with as it does not require any additional knowledge aside from basic shell scripting.
To illustrate how Vagrant shell provisioning works, we'll modify our Vagrant project to install the Apache web server in the Vagrant virtual machine.
We will begin by creating a simple shell script to install Apache2 using Ubuntu's APT package manager.
Next, we'll modify our Vagrantfile to execute our script when Vagrant provisions our virtual machine by adding the following line:
If your virtual machine is still running, kill it now by running vagrant destroy, then execute vagrant up to bring up a new virtual machine.
When Vagrant completes, you should be able to view the default Apache page by pointing your browser tohttp://localhost:8080 on the host machine.
In order to model a virtualized Storm cluster with Vagrant, we need a way to configure multiple machines within a single Vagrant project.
Fortunately, Vagrant supports multiple machines with a syntax that makes it easy to convert our existing single-machine project into a multimachine configuration.
With a multimachine setup, running vagrant up without arguments will bring up every machine defined in the Vagrantfile.
This behavior applies to Vagrant's other management commands as well.
To control an individual machine, add that machine's name to the command.
For example, if we want to launch just the www1 machine, we would use the following command:
Likewise, to destroy virtual machine, we would use the following command:
If you don't understand some of the commands used in the.
ZooKeeper is available pre-packaged for most Linux platforms, which makes.
The Storm installation script is a little more complicated since it is not.
This will allow us to easily switch between different Storm versions.
The install-storm.sh script leverages the existence of the Vagrant shared directory (/vagrant)
This allows us to keep the storm.yaml and logback.xml files in a convenient location right next to the Vagrantfile.
In the storm.yaml file, we will use hostnames instead of IP addresses and let Vagrant configure the name resolution as shown in the following code snippet:
The supervisord service is installed by the install-storm.sh script, but we still need to configure it to manage the Storm daemons.
For our Storm cluster, we will create a cluster with one ZooKeeper node, one Nimbus node, and one or more Supervisor nodes.
Because the Vagrantfile is written in Ruby, we have access to many of Ruby's language features, which will allow us to.
We will, for example, make the number of Supervisor nodes easily configurable.
In the storm.yaml file, we used hostnames rather than IP addresses, which means our machines must be able to resolve names to IP addresses.
Vagrant does not come with a facility for managing entries in the /etc/hosts file, but fortunately, there is a Vagrant plugin that does.
It also has an option to add the name resolution between the host machine and virtual machines.
Next, let's look at the complete Vagrantfile and walk through it line by line:
The first line of the file tells the Ruby interpreter to require the uri module, which we will use for URL parsing.
Next, we set up some variables representing the URL of the Storm distribution archive, the number of Supervisor nodes we want, and the name of the Vagrant box type for our virtual machines.
These variables are intended to be changed by the user.
These values will be passed as arguments to the provisioning scripts.
The next block checks to see whether the Storm distribution archive has already been downloaded; if not, it uses the wget command to download it as shown in the following code snippet:
The preceding code will download the Storm archive to the same directory as theVagrantfile, thus making it accessible to the provisioning scripts in the /vagrant shared directory.
The next two code blocks configure ZooKeeper and Nimbus and are relatively straightforward.
They contain two new directives we have not seen before:
The next line tells Vagrant to set the hostname on the virtual machine to a specific value.
Finally, we invoke the provisioning scripts appropriate for each node.
With our cluster defined in the Vagrantfile and our provisioning scripts in place, we're ready to launch the Vagrant cluster with vagrant up.
With four machines and a considerable amount of software to install on each, this will take a while.
Once Vagrant has finished launching the cluster, you should be able to view the Storm UI from the host machine at http://nimbus:8080
To submit a topology to the cluster, you can do so with the following command:
In this chapter, we've just scratched the surface of deploying Storm in a cloud.
We encourage you to explore both cloud hosting providers such as AWS as.
URL, for account signing up / Setting up an AWS account.
Storm cluster, configuring with / Configuring a Storm cluster with Whirr.
Titan, setting up for / Setting up Titan to use the Cassandra storage.
Furnace project / Accessing the graph – the TinkerPop stack.
Compute node / Integrating a non-transactional system, The Druid setup.
URL, for info / Implementing the partition status in ZooKeeper.
Master node / Integrating a non-transactional system, The Druid setup.
Storm executable, setting up on / Setting up the Storm executable on a.
