For your convenience Apress has placed some of the front matter material after the index.
When we think of the community of Java developers, we are reminded of the hordes of gold rush prospectors of the late 1840s, frantically panning the rivers of North America looking for fragments of gold.
As Java developers, our rivers run rife with open source projects, but, like the prospectors, finding a useful project can be time-consuming and arduous.
A common gripe with many open source Java projects is that they are conceived merely out of the need to fill the gap in the implementation of the latest buzzword-heavy technology or pattern.
Having said that, many high-quality, usable projects meet and address a real need for real applications, and during the course of this book, you will meet a subset of these projects.
You will get to know one in particular rather well—Spring.
Throughout this book, you will see many applications of different open source technologies, all of which are unified under the Spring Framework.
When working with Spring, an application developer can use a large variety of open source tools, without needing to write reams of code and without coupling his application too closely to any particular tool.
In this chapter, as its title implies, we introduce you to the Spring Framework, rather than looking at any solid examples or explanations.
What Is Spring? Perhaps one the hardest parts of actually explaining Spring as a technology is classifying exactly what it is.
Typically, Spring is described as a lightweight framework for building Java applications, but that statement brings up two interesting points.
Second, the lightweight part of the description doesn’t really refer to the number of classes or the size of the distribution, but rather, it defines the principle of the Spring philosophy as a whole—that is, minimal impact.
Spring is lightweight in the sense that you have to make few, if any, changes to your application code to gain the benefits of the Spring core, and should you choose to discontinue using Spring at any point, you will find doing so quite simple.
Notice that we qualified that last statement to refer to the Spring core only—many of the extra Spring components, such as data access, require a much closer coupling to the Spring Framework.
However, the benefits of this coupling are quite clear, and throughout the book we present techniques for minimizing the impact this has on your application.
IoC is a technique that externalizes the creation and management of component dependencies.
Consider an example where class Foo depends on an instance of class Bar to perform some kind of processing.
Traditionally, Foo creates an instance of Bar using the new operator or obtains one from some kind of factory class.
Using the IoC approach, an instance of Bar (or a subclass) is provided to Foo at runtime by some external process.
This behavior, the injection of dependencies at runtime, leads to IoC being renamed by Martin Fowler to the much more descriptive Dependency Injection (DI)
Note As you will see in Chapter 4, using the term Dependency Injection when referring to Inversion of Control is always correct.
In the context of Spring, you can use the terms interchangeably, without any loss of meaning.
Spring’s DI implementation is based around two core Java concepts: JavaBeans and interfaces.
When you use Spring as the DI provider, you gain the flexibility of defining dependency configuration within your applications in different ways (e.g., externally in XML files, Spring Java configuration classes, or Java annotations within your code)
JavaBeans (also known as POJOs, for Plain Old Java Objects) provide a standard mechanism for creating Java resources that are configurable in a number of ways.
In Chapter 4, you will see how Spring uses the JavaBean specification to form the core of its DI configuration model; in fact, any Spring-managed resource is referred to as a bean.
We are sure that no one reading this book will disagree that designing and coding an application to interfaces makes for a flexible application, but the complexity of wiring together an application that is designed using interfaces is quite high and places an additional coding burden on developers.
By using DI, you reduce the amount of code you need to utilize an interface-based design in your application to almost zero.
Likewise, by using interfaces, you can get the most out of DI because your beans can utilize any interface implementation to satisfy their dependency.
Using Spring for DI relies on nothing more than following the JavaBeans naming conventions (a requirement that, as you will see in Chapter 5, you can bypass using Spring’s method injection support) within your classes—there are no special classes from which to inherit or proprietary naming schemes to follow.
If anything, the only change you make in an application that uses DI is to expose more properties on your JavaBeans, thus allowing more dependencies to be injected at runtime.
Note Spring Framework version 3.0 (and newer) has support for Java-based bean metadata in addition to XML configuration files.
Evolution of Dependency Injection In the past few years, thanks to the popularity gained by Spring and other DI frameworks, DI has gained wide acceptance among the Java developer communities.
At the same time, developers were convinced that using DI was a best practice in application development, and the benefits of using DI were also well understood.
Widespread DI practice also influenced the development of the Java Community Process (JCP) led by Sun Microsystems (acquired by Oracle in 2009)
In the meantime, the Enterprise JavaBeans (EJB) architecture (starting from version 3.0) was also revamped dramatically; it adopted the DI model in order to ease the development of various Enterprise JavaBeans apps.
Although we leave the full discussion of DI until Chapter 4, it is worth taking a look at the benefits of using DI rather than a more traditional approach:
Reduced glue code: One of the biggest plus points of DI is its ability to reduce dramatically the amount of code you have to write to glue the different components of your application together.
Often this code is trivial—where creating a dependency involves simply creating a new instance of an object.
However, the glue code can get quite complex when you need to look up dependencies in a JNDI repository or when the dependencies cannot be invoked directly, as is the case with remote resources.
In these cases, DI can really simplify the glue code by providing automatic JNDI lookup and automatic proxying of remote resources.
Simplified application configuration: By adopting DI, the process of configuring an application was greatly simplified.
You can use annotations or XML to configure those classes that were injectable to other classes.
You can use the same technique to express the dependency requirements to the “injector” for injecting the appropriate bean instance or property.
In addition, DI makes it much simpler to swap one implementation of a dependency for another.
Consider the case where you have a data access object (DAO) component that performs data operations against a PostgreSQL database and you want to upgrade to Oracle.
Using DI, you can simply reconfigure the appropriate dependency on your business objects to use the Oracle implementation rather than the PostgreSQL one.
The ability to manage common dependencies in a single repository: Using a traditional approach to dependency management of common services, for example, data source connection, transaction, remote services, etc., you create instances (or lookup from some factory classes) of your dependencies where they are needed—within the dependent class.
This will cause the dependencies to spread across the classes in your application, and changing them can prove problematic.
When you use DI, all the information about those common dependencies is contained in a single repository (with Spring, you have the choice of storing the information in XML files or Java classes), making the management of dependencies much simpler and less error prone.
Improved testability: When you design your classes for DI, you make it possible to replace dependencies easily.
This is especially handy when you are testing your application.
Consider a business object that performs some complex processing; for part of this, it uses a DAO to access data stored in a relational database.
For your test, you are not interested in testing the DAO; you simply want to test the business object with various sets of data.
In a traditional approach, where the business object is responsible for obtaining an instance of the DAO itself, you have a hard time testing this, because you are unable to replace the DAO implementation easily with a mock implementation that returns your test data sets.
Instead, you need to make sure your test database contains the correct data and uses the full DAO implementation for your tests.
Using DI, you can create a mock implementation of the DAO object that returns the test data sets, and then you can pass this to your business object for testing.
Fostering good application design: Designing for DI means, in general, designing against interfaces.
A typical injection-oriented application is designed so that all major components are defined as interfaces, and then concrete implementations of these interfaces are created and hooked together using the DI container.
This kind of design was possible in Java before the advent of DI and DI-based containers such as Spring, but by using Spring, you get a whole host of DI features for free, and you are able to concentrate on building your application logic, not a framework to support it.
As you can see from this list, DI provides a lot of benefits for your application, but it is not without its drawbacks.
In particular, DI can make it difficult for someone not intimately familiar with the code to see just what implementation of a particular dependency is being hooked into which objects.
Typically, this is only a problem when developers are inexperienced with DI; after becoming more experienced and following good DI coding practice (e.g., putting all injectable classes within each application layer into the same package), developers will be able to discover the whole picture easily.
For the most part, the massive benefits far outweigh this small drawback, but you should consider this when planning your application.
Beyond Dependency Injection The Spring core alone, with its advanced DI capabilities, is a worthy tool, but where Spring really excels is in its myriad of additional features, all elegantly designed and built using the principles of DI.
Spring provides features for all layers of an application, from helper application programming interfaces (APIs) for data access right through to advanced Model View Controller (MVC) capabilities.
What is great about these features in Spring is that, although Spring often provides its own approach, you can easily integrate them with other tools in Spring, making these tools first-class members of the Spring family.
Aspect-Oriented Programming with Spring Aspect-oriented programming (AOP)  is one of the “programming models of the moment” in the Java space.
Spring’s approach to AOP is creating “dynamic proxies” to the target objects and “weaving” the objects with the configured advice to execute the crosscutting logic.
However, the good news for Spring and AOP developers is that starting from version 2.0, Spring provides much tighter integration with AspectJ.
Support for @AspectJ annotation style, while still using Spring AOP for weaving.
Both kinds of AOP have their place, and in most cases, Spring AOP is sufficient in addressing an application’s crosscutting requirements.
However, for more complicated requirements, AspectJ can be used, and both Spring AOP and AspectJ can be mixed in the same Spring-powered application.
A typical one given in many of the traditional AOP examples involves performing some kind of logging, but AOP has found uses well beyond the trivial logging applications.
Indeed, within the Spring Framework itself, AOP is used for many purposes, particularly in transaction management.
Spring Expression Language (SpEL) Expression Language (EL) is a technology to allow an application to manipulate Java objects at runtime.
However, the problem with EL is that different technologies provide their own EL implementations and syntaxes.
For example, Java Server Pages (JSP) and Java Server Faces (JSF) both have their own EL, and their syntaxes are different.
To solve the problem, the Unified Expression Language (EL) was created.
Because the Spring Framework is evolving so quickly, there is a need for a standard expression language that can be shared among all the Spring Framework modules as well as other Spring projects.
SpEL provides powerful features for evaluating expressions and for accessing Java objects and Spring beans at runtime.
The result can be used in the application or injected into other JavaBeans.
In this book, you won’t find a chapter dedicated to SpEL.
However, throughout the book, we will use SpEL where appropriate with detailed explanations.
Validation in Spring Validation is another large topic in any kind of application.
The Bean Validation API provides a standard way for defining bean validation rules.
For example, when applying the @NotNull annotation to a bean’s property, it means that the attribute shouldn’t contain a null value before being able to persist into the database.
The time when developers need to program the same validation logic in both the user interface and the backend layer is gone.
Accessing Data in Spring Data access and persistence seem to be the most discussed topics in the Java world.
Spring provides excellent integration with a choice selection of these data access tools.
In addition to this, Spring makes plain vanilla Java Database Connectivity (JDBC) a viable option for many projects with its simplified wrapper APIs around the standard API.
However, in the past few years, because of the explosive growth of the Internet and cloud computing, besides relational database, a lot of other “special-purpose” databases were developed.
Examples include databases based on key-value pairs to handle extremely large volumes of data (generally referred to as NoSQL), graph databases, document databases, and so on.
The project was further split into different categories to support more specific database access requirements.
Note The support of nonrelational databases in Spring will not be covered in this book.
For those who are interested in this topic, the Spring Data project mentioned earlier is a good place to look.
The JDBC support in Spring makes building an application on top of JDBC realistic, even for more complex applications.
The support for Hibernate, MyBatis, JDO, and JPA makes already simple APIs even simpler, thus easing the burden on developers.
When using the Spring APIs to access data via any tool, you are able to take advantage of Spring’s excellent transaction support.
One of the nicest features in Spring is the ability to mix and match data access technologies easily within an application.
For instance, you may be running an application with Oracle, using Hibernate for much of your data access logic.
However, if you want to take advantage of some Oracle-specific features, then it is simple to implement that part of your data access tier using Spring’s JDBC APIs.
Object/XML Mapping (OXM) in Spring in Spring Most applications need to integrate or provide services to other applications.
One common requirement is to exchange data with other systems, either on a regular basis or in real time.
In terms of data format, XML is the most commonly used format.
As a result, there exists a common need to transform a JavaBean into XML format, and vice versa.
Spring supports many common Java-to-XML mapping frameworks and, as usual, eliminates the needs for directly coupling to any specific implementation.
In Chapter 16, when we discuss remotely accessing a Spring application for business data in XML format, you will see how to use Spring’s Object to XML Mapping (OXM) support in your application.
Managing Transactions Spring provides an excellent abstraction layer for transaction management, allowing for programmatic and declarative transaction control.
By using the Spring abstraction layer for transactions, you can make changing the underlying transaction protocol and resource managers simple.
You can start with simple, local, resource-specific transactions and move to global, multiresource transactions without having to change your code.
Simplifying and Integrating with JEE As stated earlier, in the past few years, DI frameworks like Spring have gained wide acceptance, and a lot of developers choose to construct applications using DI frameworks in favor of the JEE’s EJB approach.
For EJB, Spring provides a simple declaration to perform the JNDI lookup and inject into Spring beans.
On the reverse side, Spring also provides simple annotation for injecting Spring beans into EJBs.
For any resources stored in a JNDI-accessible location, Spring allows you to do away with the complex lookup code and have JNDI-managed resources injected as dependencies into other objects at runtime.
As a side effect of this, your application becomes decoupled from JNDI, allowing you more scope for code reuse in the future.
Using Spring, you have maximum flexibility when you are choosing how to implement your web frontend.
For developing web applications, the MVC pattern is the most popular practice.
In recent versions, Spring has gradually evolved from a simple web framework into a full-blown MVC implementation.
In addition to standard support for JSP, which is greatly bolstered by the Spring tag libraries, you can take advantage of fully integrated support for Apache Velocity, FreeMarker, Apache Tiles, and XSLT.
In addition to this, you will find a set of base view classes that make it simple to add Excel and PDF output to your applications.
In many cases, you will find Spring MVC sufficient in fulfilling your web application development needs.
However, Spring can also integrate with other popular web frameworks such as Struts, JSF, Google Web Toolkit (GWT), and so on.
In the past few years, the technology of web frameworks has evolved quickly.
Users have required more responsive and interactive experiences, and that has resulted in the arise of Ajax as a widely adopted technology in developing Rich Internet Applications (RIAs)
On the other hand, users also want to be able to access their applications from any device, including smartphones and tablets.
In Chapter 17, we will discuss developing web applications using Spring MVC with jQuery (a popular JavaScript library supporting Ajax and many other features) and JSP.
The project was developed to address the needs of controlling the page flow, as well as provide more fine-grained control on web application–based data that needs to be maintain across a series of pages (called conversational scope)
Remoting Support Accessing or exposing remote components in Java has never been the simplest of jobs.
Using Spring, you can take advantage of extensive support for a wide range of remoting techniques to quickly expose and access remote services.
In addition to these remoting protocols, Spring also provides its own HTTP-based invoker that is based on standard Java serialization.
By applying Spring’s dynamic proxying capabilities, you can have a proxy to a remote resource injected as a dependency into one of your classes, thus removing the need to couple your application to a specific remoting implementation and also reducing the amount of code you need to write for your application.
Another remote technology that has gained wide acceptance these days is the RESTful Web Services (RESTful-WS)
RESTful-WS is designed around HTTP and greatly simplifies the mechanism in invoking services and getting the result.
The return value can be either in XML, in JavaScript Object Notation (JSON), or in other formats supported by the clients as stated in its HTTP request header.
Starting in version 3.0, the Spring MVC module provides comprehensive support for RESTful-WS.
Mail Support Sending e-mail is a typical requirement for many different kinds of application and is given first-class treatment within the Spring Framework.
Spring provides a simplified API for sending e-mail messages that fits nicely with the Spring DI capabilities.
Spring provides the ability to create a prototype message in the DI container and use this as the base for all messages sent from your application.
This allows for easy customization of mail parameters such as the subject and sender address.
In addition, for customizing the message body, Spring integrates with templating engines, such as Apache Velocity, which allows the mail content to be externalized from the Java code.
Job Scheduling Support Most nontrivial applications require some kind of scheduling capability.
Whether this is for sending updates to customers or performing housekeeping tasks, the ability to schedule code to run at a predefined point in time is an invaluable tool for developers.
Spring provides its own scheduling support that can fulfill most common scenarios.
A task can be scheduled either for a fixed interval or by using a Unix cron expression.
On the other hand, for task execution and scheduling, Spring integrates with other scheduling libraries as well.
For example, in the application server environment, Spring can delegate the execution to the CommonJ library being used by many commonly used application servers.
For job scheduling, Spring also supports libraries including the JDK Timer API and Quartz, a commonly used open source scheduling library.
Dynamic Scripting Support Starting from JDK 6, Java had introduced the dynamic language support, in which you can execute scripts written in other languages in a JVM environment.
Spring also supports the execution of dynamic scripts in a Spring powered application, or you can define a Spring bean that was written in a dynamic scripting language and injected into other JavaBeans.
Spring supported dynamic scripting languages include Groovy, JRuby, and BeanShell.
In Chapter 22, we will discuss the support of dynamic scripting in Spring in detail.
Simplified Exception Handling One area where Spring really helps reduce the amount of repetitive, boilerplate code you need to write is in exception handling.
The core of the Spring philosophy in this respect is that checked exceptions are overused in Java and that a framework should not force you to catch any exception from which you are unlikely to be able to recover—a point of view that we agree with wholeheartedly.
In reality, many frameworks are designed to reduce the impact of having to write code to handle checked exceptions.
However, many of these frameworks take the approach of sticking with checked exceptions but artificially reducing the granularity of the exception class hierarchy.
One thing you will notice with Spring is that because of the convenience afforded to the developer from using unchecked exceptions, the exception hierarchy is remarkably granular.
Throughout the book you will see examples of where the Spring exception handling mechanisms can reduce the amount of code you have to write and, at the same time, improve your ability to identify, classify, and diagnose errors within your application.
The Spring Project One of the most endearing things about the Spring project is the level of activity currently present in the community and the amount of cross-pollination between other projects such as CGLIB, Apache Geronimo, and AspectJ.
One of the most touted benefits of open source is that if the project folded tomorrow, you would be left with the code; but let’s face it—you do not want to be left with a codebase the size of Spring to support and improve upon.
For this reason, it is comforting to know how well established and active the Spring community is.
In this book, Rod presented his own framework called the Interface 21 Framework, a framework he developed to use in his own applications.
Released into the open source world, this framework formed the foundation of the Spring Framework as we know it today.
Since then, Spring has undergone dramatic growth, and at the time of writing, the latest version of Spring Framework is 3.1
The Spring Community The Spring community is one of the best in any open source project we have encountered.
The mailing lists and forums are always active, and progress on new features is usually rapid.
The development team is truly dedicated to making Spring the most successful of all the Java application frameworks, and this shows in the quality of the code that is reproduced.
Much of the ongoing development in Spring is in reworking existing code to be faster, smaller, neater, or all three.
As we mentioned already, Spring also benefits from excellent relationships with other open source projects, a fact that is extremely beneficial when you consider the large amount of dependency the full Spring distribution has.
From a user’s perspective, perhaps one of the best features of Spring is the excellent documentation and test suite that accompany the distribution.
Documentation is provided for almost all the features of Spring, making picking up the framework simple for new users.
The test suite Spring provides is impressively comprehensive—the development team writes tests for everything.
If they discover a bug, they fix that bug by first writing a test that highlights the bug and then getting the test to pass.
What does all this mean to you? Well, put simply, it means you can be confident in the quality of the Spring Framework and confident that, for the foreseeable future, the Spring development team will continue to improve upon what is already an excellent framework.
However, because of the success of the Java version, developers in the .NET world started to feel a little bit left out; thus, Mark Pollack and Rod Johnson started the Spring .NET project.
Aside from Rod, both projects have completely different development teams, so the .NET project should have minimal impact on the Spring Java.
Contrary to popular belief in the Java world, .NET is not a load of garbage produced by the Beast, a fact that we can attest to, having delivered several successful .NET applications to our clients.
This project opens up whole new avenues for cross-pollination, especially since .NET already has the lead in some areas, such as source-level metadata, and should lead to a better product on both fronts.
Another side effect of this project is that it makes the move between platforms much easier for developers, because you can use Spring on both sides.
This is given even more weight by the fact that other projects such as Hibernate and MyBATIS now have .NET equivalents.
Soon after that, SpringSource, the company behind Spring founded by Rod Johnson, created an integrated tool called the SpringSource Tool Suite (STS)
Although it used to be a paid product, the tool is now freely available.
In each new version, more features are being added, such as Groovy scripting language support, Spring Roo support, and SpringSource tcServer (an application server with paid support offered by SpringSource that was built on top of the Tomcat server) support.
The sample source code in this book for each chapter, as well as the code for the sample application, will all be developed in STS, so you need to download STS and import the projects.
In case you want to know more about using STS for Spring application development immediately, feel free to jump ahead to Appendix A.
Spring Security provides comprehensive support for both web application and method-level security.
It tightly integrates with the Spring Framework and other commonly used authentication mechanisms, such as HTTP basic authentication, form-based login, X.509 certificate, SSO product (e.g., SiteMinder), and so on.
It provides role-based access control to application resources, and in applications with more complicated security requirements (e.g., data segregations), Access Control List (ACL) is supported.
Spring Batch and Integration Needless to say, batch job execution and integration are common use cases in applications.
To cope with this need and to make it easy for developers in these areas, Spring created the Spring Batch and Spring Integration projects.
Spring Batch provides a common framework and various policies for batch job implementation, reducing a lot of boilerplate code.
By implementing the Enterprise Integration Pattern (EIP), Spring Integration can make integrating Spring applications with external systems easy.
Many Other Projects We’ve covered the core modules of Spring and some of the major projects within the Spring portfolio, but there still many other projects that have been driven by the need of the community for different requirements.
Alternatives to Spring Going back to our previous comments on the number of open source projects, you should not be surprised to learn that Spring is not the only framework offering Dependency Injection features or full end-to-end solutions for building applications.
In fact, there are almost too many projects to mention.
In the spirit of being open, we include a brief discussion of several of these frameworks here, but it is our belief that none of these platforms offers quite as comprehensive a solution as that available in Spring.
As you can see, the main difference between Seam and Spring is that the Seam framework is built entirely on JEE standards.
JBoss also contributes the ideas in the Seam framework back to the JCP and becomes JSR-299 (“Contexts and Dependency Injection for the Java EE Platform”)
Led by the search engine giant Google, Guice is a lightweight framework that focuses on providing DI for application configuration management.
It was also the reference implementation of the JSR-330 specification (“Dependency Injection for Java”)
Because PicoContainer is nothing more than a DI container, you may find that as your application grows, you need to introduce another framework, such as Spring, in which case you would have been better off using Spring from the start.
However, if all you need is a tiny DI container, then PicoContainer is a good choice, but since Spring packages the DI container separate from the rest of the framework, you can just as easily use that and keep the flexibility for the future.
So, when you are developing an application for JEE 6–compliant application servers, you can use standard DI techniques across all layers.
Summary In this chapter, we presented you with a high-level view of the Spring Framework complete with discussions of all the major features, and we guided you to the relevant sections of the book where these features are discussed in detail.
After reading this chapter, you should have some kind of idea about what Spring can do for you; all that remains is to see how it can do it.
In the next chapter, we discuss all the information you need to know to get up and running with a basic Spring application.
We show you how to obtain the Spring Framework and discuss the packaging options, the test suite, and the documentation.
Also, Chapter 2 introduces some basic Spring code, including the time-honored “Hello World!” example in all its DI-based glory.
Often the hardest part of coming to grips with any new development tool is knowing where to begin.
Typically, this problem is worse when the tool offers as many choices as Spring.
Fortunately, getting started with Spring isn’t actually that hard if you know where to look first.
In this chapter, we present you with all the basic knowledge you need to get off to a flying start.
Obtaining Spring: The first logical step is to obtain or build the Spring JAR files.
However, if you want to be on the cutting edge of Spring developments, check out the latest version of the source code from Spring’s GitHub repository.
If you use Maven for application development, you can simply add the dependencies for Spring into the project’s pom.xml (project object model) file, and Maven will download the JAR files for you.
Please refer to the section “Spring Modules on the Maven Repository” for details.
Spring packaging options: Spring packaging is modular; it allows you to pick and choose which components you want to use in your application and to include only those components when you are distributing your application.
Spring dependencies: The full distribution of Spring includes a voluminous set of dependencies, but in many cases, you need only a subset of these dependencies.
In this section, we look at which Spring features require which dependencies; this information helps you reduce the size of your application to the absolute minimum.
Spring samples: Spring comes with a large selection of sample applications that make ideal reference points for building your own applications.
In this section, we will take a look inside the sample applications to give you a feel for the amount of sample code that is available.
If you couple this with the sample application you build during the course of this book, you should have more than enough of a codebase from which to start building your own applications.
Test suite and documentation: One of the things members of the Spring community are most proud of is their comprehensive test suite and documentation set.
Testing is a big part of what the team does.
The documentation set provided with the standard distribution is also excellent.
Putting a spring into “Hello World!”: All bad punning aside, we think the best way to get started with any new programming tool is to dive right in and write some code.
We are going to look at some simple examples, including a full DI-based implementation of everyone’s favorite, “Hello World!” Don’t be alarmed if you don’t understand all the code examples right away; full discussions follow later in the book.
If you are already familiar with the basics of the Spring Framework, feel free to proceed straight to Chapter 3 for a discussion of the sample application that you will be building during the course of this book.
However, even if you are familiar with the basics of Spring, you may find some of the discussions in this chapter interesting, especially those on packaging and dependencies.
Obtaining the Spring Framework Before you can get started with any Spring coding, you need to obtain the Spring code.
You have a few options for retrieving the code: you can download a packaged distribution from the Spring web site, or you can check out the code from the Spring GitHub repository.
Another option is to use an application dependency management tool such as Maven or Ivy, declare the dependency in the configuration file, and let the tool obtain the required libraries for you.
Visit this page to download the latest release of Spring (version 3.1 at the time of writing)
You can also download milestones/nightly snapshots for upcoming releases or previous versions from the download center.
Starting with release 3.0, the Spring Framework release comes in two flavors: one with the documentation included and one without.
However, Spring now relies on dependency management tools like Maven and Ivy to express its dependency to third-party libraries on each of its module.
So when you declare your project to depend on any Spring module (e.g., spring-context), all the required dependencies will be automatically included.
More about this will be discussed later in this chapter.
Checking Spring Out of GitHub In case you want to get a grip on new features before they make their way even into the snapshots, you can check out the source code directly from SpringSource’s GitHub repository.
To check out the latest version of the Spring code, first install GitHub, which you can download from http://git-scm.com/, and then open the Git Bash tool, and run the following command:
Understanding Spring Packaging After you download the package and extract it, under the dist folder, you will find a list of JAR files that represent each Spring module.
After you understand the purpose of each module, you can then select the modules required in your project and include them in your code.
Figure 2-1 shows the dist folder’s content after extracting the downloaded Spring Framework package.
Table 2-1 describes these JAR files and their corresponding modules.
You also need to include this JAR in your application if you plan to use other features in Spring that use AOP, such as declarative transaction management.
Moreover, classes that support integration with AspectJ are packed in this module too.
Spring depends on this library to analyze the bytecode of Spring beans, dynamically modify them, and generate new bytecode during runtime.
For example, if you are using Java classes for your Spring configuration and need AspectJ-style annotation-driven transaction management, you will need this module.
Most of the classes here support Spring’s bean factory implementation.
For example, the classes required to parse the Spring’s XML configuration file and Java annotations were packed into this module.
You will find that all classes need to use Spring’s ApplicationContext feature (covered in Chapter 5), along with classes for EJB, Java Naming and Directory Interface (JNDI), and Java Management Extensions (JMX) integration.
Also contained in this module are the Spring remoting classes, classes for integration with dynamic scripting languages (e.g., JRuby, Groovy, BeanShell), the Beans Validation (JSR-303) API, scheduling and task execution, and so on.
On the user interface side, there are classes for mail support and integration with templating engines such as Velocity, FreeMarker, and JasperReports.
Also, integration with various task execution and scheduling libraries including CommonJ and Quartz are packaged here.
In this JAR file, you will find all the classes that are shared among all other Spring modules, for example, classes for accessing configuration files.
Also, in this JAR, you will find a selection of extremely useful utility classes that are used throughout the Spring codebase and that you can use in your own application.
This JAR file is required for using load-time weaving with AspectJ in a Spring application.
You will need this module for all applications that require database access.
Classes for supporting data sources, JDBC data types, JDBC templates, native JDBC connections, and so on, are packed in this module.
Many of the classes in this JAR depend on classes contained in spring-jdbc.jar, so you definitely need to include that in your application as well.
Classes for abstraction of XML marshaling and unmarshaling and support for popular tools like Castor, JAXB, XMLBeans, XStream, and so on, are packed into this module.
Many of these mock classes are used within the Spring test suite, so they are well-tested and make testing your applications much simpler.
You will find classes from the transaction abstraction layer to support of the Java Transaction API (JTA) and integration with application servers from major vendors.
If you are using a separate MVC framework for your application, then you won’t need any of the classes from this JAR file.
Choosing Modules for Your Application Without an IDE such as Eclipse or a dependency management tool like Maven or Ivy, choosing which modules to use in your application may be a bit tricky.
For example, if you require Spring’s bean factory and DI support only, you still need several modules including spring-core, spring-beans, spring-context, spring-aop, and spring-asm.
If you need Spring’s web application support, you then need to further add spring-web.
For integration with Struts, you’ll need spring-struts, and so on.
However, when using an IDE, especially SpringSource Tool Suite (STS), which will be used as the default IDE for all examples in this book, managing/visualize those dependencies becomes much easier.
In STS, you have the option to create a Spring template project and choose from a number of project templates that suit your application.
A Spring template project uses Maven for dependency management, and STS also is bundled with m2e, an Eclipse plug-in project for Maven integration.
When you select the project template, Spring will create the project with the appropriate dependencies declared for you.
Thanks to Maven’s transitive dependencies support, all required third-party libraries will also be included automatically.
Figure 2-2 shows STS with a simple Spring utility project.
The screen comes from the project’s pom.xml (Maven Project Object Model) file and m2e plug-in’s dependency hierarchy viewer, which is displaying all the dependencies required for the project.
From the dependency hierarchy diagram, you can see that the project depends on spring-context, which in turns requires spring-aop, spring-beans, spring-core, spring-expression, and spring-asm.
Also, spring-aop further depends on aopalliance, while spring-core depends on commons-logging.
By default, the Spring project use log4j for logging purposes.
Spring’s dependency hierarchy for a simple Spring utility project that utilizes Spring’s bean factory and DI features.
Spring Modules on the Maven Repository Besides downloading them from the Internet, you also can manage Spring libraries via an application dependency management tool, such as Ivy and Maven.
In this section, we will take a look at the Spring modules on the Maven repository.
Founded by Apache Software Foundation, Maven (http://maven.apache.org) has become one of the most popular tools in managing the dependencies for Java applications, from open source to enterprise environments.
Maven is a powerful application building, packaging, and dependency management tool.
It manages the entire build cycle of an application, from resource processing and compiling to testing and packaging.
Almost all open source projects support distribution of their library via the Maven repository.
The most popular one is the Maven Central repository hosted on Apache, and you can access and search for the existence and related information of an artifact on the Maven Central web site (http://search.maven.org)
If you download and install Maven into your development machine, you.
However, in order to be able to access those repositories, you need to add the repository into your Maven’s setting file.
A detailed discussion on Maven is not in the scope of this book, and you can always refer to the online documentation or books that give you a detailed reference to Maven.
However, since Maven is being widely adopted, it’s worth mentioning the structure of Spring’s packaging on the Maven repository.
Each Maven artifact is identified by a group ID, artifact ID, packaging type, and version.
Like other open source libraries, Spring’s Maven artifacts can be found on Apache’s Maven Central.
However, SpringSource also hosts its own Maven repository and provides Spring libraries in the form of Enterprise Bundle Repositories (EBRs), which are OSGi compatible.
To ease your confusion, it’s worth mentioning the naming difference between Spring’s artifacts in Maven Central and its own Maven repository, because your development team should standardize on one of them.
However, if you plan to deploy your application in an OSGi container (e.g., Spring dynamic modules), then use Spring EBR.
Table 2-2 shows the respective naming of Spring’s artifacts on Maven Central and SpringSource EBRs.
From both repositories, the group ID is the same; just the artifact ID is different.
As in Table 2-1, we will include only the module portion of the JAR file names.
If you are building Spring from source, then you are going to need all of these dependencies.
However, at runtime, most likely you will require only a subset of the dependencies, and you can really minimize the size of your distribution by including only the necessary dependencies.
Because of the large number of dependencies, Spring groups them together to make working with them easier.
Table 2-3 describes these groups; it also lists the JAR files in each group and defines what the dependencies are used for.
Table 2-3 reflects only the basic and common dependencies that the Spring framework’s modules depend on.
For example, for Spring XML support (i.e., the oxm module), if you are using Castor as the underlying object-to-XML mapping library, you need to add Castor’s library.
If you use XStream, then you need to add XStream’s library, and so on.
As we move on to later chapters and discussing each specific topic, we’ll mention additional third-party libraries that are being used.
So, please refer to the table as a general overview, instead of a complete reference.
You need this JAR file only if you plan to use any of Spring’s AOP or AOP-based features.
Spring remoting provides support for a wide variety of different protocols, including Caucho’s Burlap and Hessian.
You need the JAR in this group only if you are using the corresponding protocols in your application.
These JAR files are required when you are using Spring’s Hibernate integration and support classes.
If you are using a different ORM tool, such as MyBatis, you can leave these JARs out of your application.
When you are using Hibernate, you must also include the javassist.jar file in your application.
The entity manager and JPA library are required when you use JPA and Hibernate as the persistence provider.
Include this JAR only if your web applications need to generate PDF output.
As you can see, there is a large array of different JEErelated JAR files.
You need the activation.jar and mail.jar files if you want to use the JavaMail implementation of Spring’s mail support.
For web applications you need servlet.jar and jstl.jar if you want to use Spring’s JSTL support.
The jaxws-api.jar file is required for JAX-WS support in Spring remoting, and jta.jar is used for JTA transaction support.
Many of the components from the Apache Commons project are used by Spring.
FileUpload is required if you want to use the corresponding Spring wrapper to handle file uploads in your web applications.
Finally, logging is used throughout Spring, so you need to include it in every Spring-based application.
In addition to this, Spring provides classes to support the use of Velocity as the view provider in the web tier.
If you are using any of these features, you need to include the Velocity JAR file in your distribution.
As you can see, Spring’s dependencies are quite varied, and for most applications, you need only a fraction of the full dependency set.
It is worthwhile spending the time to pick out exactly what dependencies you need and only adding those to your application.
In this way, you can keep the size of your application down; this is a particular benefit to those of you who frequently need to deploy to remote locations.
Keeping the size of your application as small as possible is especially important if you plan to distribute your application over the Web to people who may be downloading with a slow Internet connection.
The Sample Applications An area where many open source, and indeed commercial, products fail is in providing enough welldocumented sample code to make it easy for people to get started.
Thankfully, Spring comes with a complete set of nifty sample applications that demonstrate a wide selection of the features in Spring.
The sample applications are treated as first-class citizens of the framework by the development team, and they are constantly being improved and worked on by the team.
For this reason, you will generally find that, after you get what you can from the test suite, the samples are a great place to get started when you are looking at new features.
To get the source code, invoke the following command in any empty directory:
Figure 2-3 shows a sample applications folder upon checkout from this link.
The Petclinic Application Petclinic (under the folder petclinic) is an interesting sample application that was built to showcase Spring’s data access support.
In it, you find a web-based application for querying and updating the database of a fictional veterinary office.
The interesting thing about this application is that it comes with a selection of interchangeable DAO implementations that highlight how easy it is to decouple your application from the data access logic when you are using Spring.
The Hibernate DAO implementation really shows off Spring’s Hibernate support by implementing each of the eight DAO methods with a single line or two.
First, it showcases the use of SimpleJdbcTemplate and SimpleJdbcInsert to eliminate the needs of redundant code for common JDBC operations.
On the other hand, it is very interesting to see how data access is handled in a much more object-oriented way.
By using the RowMapper interface and its various implementations, the query result set can be directly mapped into value objects and returned to the caller.
This project also contains a very solid example of how to build a web application using Spring’s MVC support, so if you are planning to use Spring MVC for one of your own applications, make sure you take a look at this sample first.
Groovy is a dynamic scripting language that runs on JVM, and Grails is a rapid development framework that enables the development of Groovy-based web applications.
The controllers in the Spring MVC layer were all developed in the Groovy language.
The jPetStore Application The jPetStore sample (under the folder jpetstore) is based on the jPetStore sample created by Clinton Begin for iBATIS.
As far as sample applications go, this one is huge.
The business tier is fully Spring managed, and coupled with the DAO layer, it presents a good example of Spring-managed transactions.
Also included with this application is a solid example of how to use both Spring MVC and Struts.
This application also highlights how to use Spring remoting using JAXRPC.
In the project, there are no XML files; all the Spring-related configuration is declared in a Java class (AppConfig.java) with various annotations.
Spring Task and Scheduling Application The task-basic project (under the folder task-basic) demonstrates the use of Spring’s task executor and scheduling support.
The use of the @Controller annotation to declare Spring MVC controllers.
After Git is installed, issue the following command to clone the project.
The project mvc-basic (under the folder mvc-basic) is a very simple Spring MVC project with a single controller.
The mvc-ajax project (under the folder mvc-ajax) demonstrates how to use Spring MVC to build web applications with Ajax support.
The server side was built using Spring MVC, and using its build-in RESTful-WS support, requests were mapped and data was returned in JSON format.
On the client side, jQuery, a popular JavaScript library with Ajax support, was used to interact with Spring MVC to provide a rich user experience.
The Spring Petcare Application The petcare sample (under the folder petcare) is another interesting project.
It is a full-blown web application that showcase a lot of different features of the Spring Framework and other Spring projects.
On the web side, it uses Spring MVC with Spring Security for securing those protected resources.
Another interesting feature is the integration with the Spring Integration project in broadcasting application messages.
Another Spring project, Spring Roo, was used to generate the JavaBeans base on the backend database schema.
Spring Webflow integrates with many view technologies; one of them is Java Server Faces (JSF)
Spring Faces is a module in Spring Webflow that provides tight integration with JSF.
Both Primefaces and JBoss Richfaces are popular JSF libraries, and their latest versions comply with JSF 2.0 standards.
Spring Documentation One of the aspects of Spring that makes it such a useful framework for real developers who are building real applications is its wealth of well-written, accurate documentation.
In every release, the Spring Framework’s documentation team works hard to ensure that all the documentation is finished and polished by the development team.
This means that every feature of Spring is not only fully documented in the JavaDoc but is also covered in the Spring reference manual included in every distribution.
If you haven’t yet familiarized yourself with the Spring JavaDoc and the reference manual, do so now.
This book does not aim to be a replacement for either of these resources; rather, it aims to be a complementary reference, demonstrating how to build a Spring-based application from the ground up.
Putting a Spring into “Hello World!” We hope by this point in the book you appreciate that Spring is a solid, well-supported project that has all the makings of a great tool for application development.
However, one thing is missing—we haven’t shown you any code yet.
We are sure you are dying to see Spring in action, and because we cannot go any longer without getting into the code, let’s do just that.
Do not worry if you do not fully understand all the code in this section; we go into much more detail on all the topics as we proceed through the book.
As far as examples go, this one is pretty simple—it does the job, but it is not very extensible.
What if we want to change the message? What if we want to output the message differently, maybe to stderr instead of stdout or enclosed in HTML tags rather than as plain text?
We are going to redefine the requirements for the sample application and say that it must support a simple, flexible mechanism for changing the message, and it must be simple to change the rendering behavior.
In the basic “Hello World!”example, you can make both of these changes quickly and easily by just changing the code as appropriate.
However, in a bigger application, recompiling takes time, and it requires the application to be fully tested again.
No, a better solution is to externalize the message content and read it in at runtime, perhaps from the command-line arguments shown in Listing 2-2
This example accomplishes what we wanted—we can now change the message without changing the code.
However, there is still a problem with this application: the component responsible for rendering the message is also responsible for obtaining the message.
Add to this the fact that we still cannot change the renderer easily; doing so means changing the class that launches the application.
If we take this application a step further, away from the basics of “Hello World!” a better solution is to refactor the rendering and message retrieval logic into separate components.
Plus, if we really want to make our application flexible, we should have these components implement interfaces and define the interdependencies between the components and the launcher using these interfaces.
By refactoring the message retrieval logic, we can define a simple MessageProvider interface with a single method, getMessage(), as shown in Listing 2-3
As you can see in Listing 2-4, the MessageRenderer interface is implemented by all components that can render messages.
As you can see, the MessageRenderer interface has a method, render(), and also a JavaBean-style property, MessageProvider.
Any MessageRenderer implementations are decoupled from message retrieval and delegate it instead to the MessageProvider with which they are supplied.
Creating simple implementations of these interfaces is easy (see Listing 2-5)
In Listing 2-5, you can see that we have created a simple MessageProvider that always returns “Hello World!” as the message.
Now all that remains is to rewrite the main() of our entry class, as shown in Listing 2-7
Figure 2-4 shows the output from this example, as expected.
Now this example is more like what we are looking for, but there is one small problem.
Changing the implementation of either the MessageRenderer or MessageProvider interface means a change to the code.
To get around this, we can create a simple factory class that reads the implementation class names from a properties file and instantiates them on behalf of the application (see Listing 2-8)
Make a simple modification to the main() method (as shown in Listing 2-9), and we are in business.
Before we move on to see how we can introduce Spring into this application, let’s quickly recap what we have done.
Starting with the simple “Hello World!” application, we defined two additional requirements that the application must fulfill.
The first was that changing the message should be simple, and the second was that changing the rendering mechanism should also be simple.
To meet these requirements, we introduced two interfaces: MessageProvider and MessageRenderer.
The MessageRenderer interface depends on an implementation of the MessageProvider interface to be able to retrieve a message to render.
Finally, we added a simple factory class to retrieve the names of the implementation classes and instantiate them as applicable.
Create Spring Project in STS Before we discuss how to refactor the “Hello World!” application with Spring, we’ll show you how to use STS for Spring-based application development.
So, let’s download and install STS first and create the project for refactoring the “Hello World!” application.
This is also the version we used for developing all the example code presented in this book, as well as the sample application.
Next, after installation, start STS, and create a new Spring template project.
Afterward, STS will ask you for the basic project information, such as project name, base package name, and so on (see Figure 2-6)
You don’t need to include the Spring libraries manually for the project.
Now we are ready to refactor the previous “Hello World!” application in Spring.
Refactoring with Spring The final example shown earlier met the goals we laid out for our sample application, but there are still problems with it.
The first problem is that we had to write a lot of glue code to piece the application together, while at the same time keeping the components loosely coupled.
The second problem was that we still had to provide the implementation of MessageRenderer with an instance of MessageProvider manually.
Don’t worry too much about this interface; for now it is enough to know that this interface is used by Spring for storing all the environmental information with regard to an application being managed by Spring.
Don’t worry too much about the getBean() method for now; just know that this method reads the application configuration (in this case an XML file), initializes Spring’s ApplicationContext environment, and then returns the configured bean instance.
The previous file shows a typical Spring ApplicationContext configuration file.
First, Spring’s namespaces are declared, and the default namespace is beans, which is used to declare the beans that need to be managed by Spring, and its dependency requirements (for the above example, the renderer bean’s messageProvider property is referencing the provider bean) for Spring to resolve and inject those dependencies.
Afterward, we declare the bean with the ID "provider" and the corresponding implementation class.
When Spring sees this bean definition during ApplicationContext initialization, it will instantiate the class and store it with the specified ID.
Then the “renderer” bean is declared, with the corresponding implementation class.
Remember that this bean depends on the MessageProvider interface for getting the message to render.
To inform Spring about the DI requirement, we use the p namespace attribute.
The bean to be injected into the property should reference a bean with the ID "provider"
When Spring sees this definition, it will instantiate the class, look up the bean’s property named messageProvider, and inject it with the bean instance with the ID "provider"
Now let’s see the Spring DI–powered “Hello World!” application in action.
The execution result will be displayed on the Console tab (see Figure 2-7)
Summary In this chapter, we presented you with all the background information you need to get up and running with Spring.
We showed you how to obtain both the Spring release distribution and the current development version directly from GitHub.
We described how Spring is packaged and the dependencies you need for each of Spring’s features.
Using this information, you can make informed decisions about which of the Spring JAR files your application needs and which dependencies you need to distribute with your application.
Spring’s documentation, sample applications, and test suite provide Spring users with an ideal base from which to start their Spring development, so we took some time to investigate what is available in the Spring distribution.
Finally, we presented an example of how, using Spring DI, it is possible to make the traditional “Hello World!” a loosely coupled, extendable messagerendering application.
The important thing to realize is that we only scratched the surface of Spring DI in this chapter, and we barely made a dent in Spring as a whole.
In the next chapter, we take an in-depth look at the sample application that we will be building, paying particular attention to how we can use Spring to solve common design issues and how we have made our application simpler and more manageable using Spring.
The examples in each chapter of this book are tailored to the current discussion and are designed to elaborate on the implementation of each feature in an easy-to-understand manner.
For the most part, these examples provide a sufficient explanation for the topic they are demonstrating.
That said, the examples appear in isolation and are not based on a real-world scenario, which can make understanding how the different Spring features work together difficult.
To overcome this, we have built a basic blog application, SpringBlog, that highlights most of the topics discussed in this book and shows how the different Spring features work together.
You should note that this application is purposely very simple, and indeed, many of its features were conceived so we could highlight a particular piece of Spring functionality.
Despite its simplicity, the SpringBlog application demonstrates how a Spring-based application is constructed and how the components are glued together.
In this chapter, you get to take a peek at the finished SpringBlog application.
We then discuss the Spring features used to implement different parts of the application.
This chapter also highlights some of the decisions we made when designing the SpringBlog application and why we made them.
More than anything, this chapter serves as a road map to the rest of the book, allowing you to highlight an area that is important to your own application and immediately identify where that area is covered in the book.
Requirements of the SpringBlog application: In this section, we discuss the requirements of the SpringBlog application and sneak a peek at the finished product of these requirements.
We also discuss why we chose to include certain requirements and why we ignored others when we built the sample application.
Implementing the SpringBlog application: In this section, we take a high-level look at how the requirements discussed in the previous section are implemented using Spring.
This section does not go into any detail on the individual Spring features; instead, it discusses the features generally and points you to other chapters that contain more complete descriptions.
If you are already comfortable with the design of Spring applications or you already know which topics are most important to your application, feel free to skip this chapter.
If you are completely new to Spring, reading this chapter will give you a good idea of where the different Spring components fit into your applications.
Requirements of the SpringBlog Application When defining the requirements for the SpringBlog application, our main goal was to highlight certain Spring Framework features in the context of a full application.
This section provides a full rundown of the features included in the SpringBlog application.
Security and Authentication Like most other blog applications, the SpringBlog application provides security controls that prevent unauthorized users from creating and editing blog entries.
As you can see in Figure 3-1, the SpringBlog application provides a login form for users to sign in and identify themselves as valid and registered users of the application.
Using the login function, you can validate your details against the user list in the database and assign yourself a different identity.
Internally, SpringBlog uses this identity for security access control, and the user information will also be used in the audit process.
Users with the user role (ROLE_USER) assigned can perform the following actions:
Post a blog entry or comment on an existing entry.
Users with the admin role (ROLE_ADMIN) assigned can perform the following actions:
Viewing Blog Entries An obvious requirement for any blog system is that it can display blog entries to users.
As Figure 3-2 shows, the SpringBlog application displays all postings to the blog on the home page, in reverse chronological order.
Users can configure the number of entries per page to be displayed; filter the blog entries by subject, category, and post date; and control the display order of the blog entries.
Clicking a particular blog entry displays just that entry, along with the list of comments posted for that entry and the files that have been attached to it, as shown in Figure 3-3
Posting Blog Entries Without the ability to post blog entries, there would be nothing to display.
After logging in as a valid user, you can post a new blog entry using the entry form shown in Figure 3-4, which you can access using the New Blog Posting link on the home page.
When posting/editing a blog entry, you can enter the details, as well as select the category and subcategory of the blog entry so visitors can easily filter out those blog entries that they don’t want to see.
In addition, validation rules will be applied to the blog entry during posting.
Once you have created a blog entry, you can edit it by clicking the Edit link on the entry’s detail page (a blog entry can be edited only by the user who posted it)
Behind the scenes, SpringBlog uses the same HTML form both for creating and for editing a blog entry, but it uses different Spring Controller methods to handle each action.
Commenting on a Blog Entry As with most blog applications, SpringBlog allows users to express their opinions about particular entries by posting comments (login is also required for posting comments)
Users can post comments, as shown in Figure 3-5, using the “Post a comment” link on an entry’s detail page.
As is the case with the entry posting functionality, this functionality also allows you to edit comments.
Filtering Out Obscenities One of the features of the Spring Framework we really wanted to highlight in SpringBlog was AOP, but we did not want to use the traditional example of logging, and AOP-based transaction management is already built into the Spring Framework.
Although most blogs do not use any kind of obscenity filter, we decided that ours would.
During design, it seemed that using AOP was the best way to apply this feature across the application.
Attaching Files to a Blog Entry or Comment Unlike many blog applications used on the World Wide Web, SpringBlog allows files to be uploaded with blog entries and comments.
In reality, this feature poses quite a large security risk, but it does allow us to demonstrate Spring Framework’s excellent file upload handling.
Figure 3-8 shows a file being uploaded for an existing entry.
Auditing Blog Actions One feature that we included purely to demonstrate a particular Spring feature is auditing.
By introducing the need for all blog operations to be logged for auditing purposes, we made each blog operation require multiple database operations; this requires the use of a database transaction that, obviously, we manage using Spring’s transaction management features.
You can view the audit history of a blog posting, as shown in Figure 3-9, by clicking the View Audit History link on the blog entry detail page.
As discussed, only users with the administrator role can see the link and view the audit history.
The SpringBlog application will provide the blog entries via RESTful-WS.
Because of this service, consumers are able to retrieve the blog entries in XML or JSON format.
Upload Blog from an XML File Some users may want to write their blogs offline and then submit them to SpringBlog.
Users can write their blogs, save them in an XML file with predefined tags, and upload the file to a particular location on the server.
SpringBlog will poll the folder regularly and import them when new files are found.
Implementing SpringBlog One of the best reasons for using Spring is that it makes designing and building an application using traditional OOP practices much simpler.
Moreover, recently Spring’s maturity and comprehensive feature set has made it a strong backbone for a JEE application.
With Spring, you are free to design your applications as you see fit and have Spring worry about wiring the different components together.
In this section, we present a high-level overview of the design and implementation decisions of the SpringBlog application with pointers to where each topic is discussed in detail.
Development Tool and Dependency Management Before going into the design, let’s decide how we are going to implement the SpringBlog application.
For developing Spring-based applications, the most appropriate tool is SpringSource Tool Suite (STS)
As discussed previously, the entire Spring Framework is composed of many modules, and each module depends on other Java libraries as well.
Although you can sort out the required Spring modules and third-party dependencies and include them into your project manually, it’s much easier to use a dependency management tool to handle it for you.
The SpringBlog application will use Maven to manage the dependencies, as well as the build life cycle.
For version control, Git will be used, and besides downloading the source code of the sample application from the book’s page, you can also check out the latest version of the application from GitHub (http://github.com)
Application Design The design of SpringBlog is very simple, with each tier defined in terms of interfaces rather than concrete classes.
In each tier, the interfaces that correspond to that tier define only the methods exposed by that tier to other tiers classified as client tiers.
Parameters for configuring SpringBlog will not be hard-coded in the application.
Instead, the configuration methods are declared on the classes that implement the interfaces in each tier, and configuration data is injected using Spring’s IoC-based configuration mechanisms.
Chapter 21 presents a full discussion of the different interfaces that make up SpringBlog, how they are wired together using Spring, and factors affecting interface granularity.
The SpringBlog application also contains a basic Domain Object Model (DOM) that encapsulates both data and behavior.
In Chapter 12, we take the time to look at the different flavors of the DOM you may have seen in projects that you have worked on, and we discuss the factors you must consider when deciding whether to encapsulate behavior in the DOM or in separate service objects.
Application Configuration Management In the SpringBlog application, we will use the latest Spring Framework (at the time of writing, version 3.1) for DI configuration.
Starting from version 3.0, Spring supports the configuration management via either XML files or Java annotations.
First, all the infrastructure setup (for example, the data source, transaction manager, and so on) will be defined in various XML configuration files for easier maintenance.
For those injectable beans and beans that require DI, we will use Java annotations to express the DI requirements.
Second, the requirements of transaction support will be defined using Java annotations too.
We will then rely on Spring’s component scan and autowire features for scanning those classes for those annotations and manage the beans and their requirements on various resources under the cover.
SpringBlog’s Layered Application Architecture Before we dive into the implementation of each layer, let’s take a higher-level look of the layers that we are going to implement in SpringBlog.
Figure 3-10 depicts the SpringBlog application’s layered architecture, and the following list describes the layers within SpringBlog application (from backend to frontend):
Persistence layer: This layer interacts directly with the underlying persistence data store (RDBMS in this case) and transforms the retrieved data into Java domain objects for service layer use.
However, MySQL will be supported too, and instructions will be provided in the sample application in case you want to use MySQL as the backend database.
Service layer: This layer is the core layer within the application.
Any application service request, no matter from which channel it comes (for example, browser interface, RESTfulWS request, batch job, and so on) should route through this layer to perform the required business processing.
For example, the validation of bean attributes will happen here.
Also, this layer relies on the persistence layer via DI for database access.
Batch job and integration layer: This layer provides integration with external parties.
For example, it will poll for XML files (from a configurable folder location) that contain blog entries from users and import them into SpringBlog via batch processing.
It interacts with the service layer for uploading blog entries.
Presentation layer: This is the layer for the web application, which provides the frontend for SpringBlog users.
It also handles the RSS feed to generate XML data to consumers.
It interacts with the service layer for data processing and business logic execution.
For example, anonymous users are allowed only to view blog entries.
Login functions will be provided, and role-based access will then be given to the users to ensure that they can only access the functions assigned to the roles to which they belong.
Having discussed the layered architecture, let’s look at how each layer will be implemented in the SpringBlog application.
Implementing the Persistence Layer Data access is a topic close to many developers’ hearts, and it is often the subject of many heated discussions on developer forums across the Internet.
In recent times, the focus in the Java world has been on object-relational mapping (ORM) tools as a replacement for JDBC, which many see as an overcomplicated mess.
A big part of Spring’s feature set lies in its support for data access technologies.
With the SpringBlog application, we wanted to show how easy it is to switch between data access implementations, so we built two different implementations of the persistence layer, one using JPA (using Hibernate as the underlying persistence service provider) and the other using MyBatis.
Hibernate is perhaps the most well-known ORM tool in the Java world, and it has enjoyed a great success because of the ease with which it can be used to develop high-performance persistence logic.
Although Hibernate has quite a simple API, the error-handling code you need to use Hibernate is quite verbose; Spring simplifies this greatly, reducing most Hibernate operations to just a single line of code.
Also, because of the significant success ORM tools like Hibernate have achieved and Hibernate’s wide acceptance by developers for data access, JCP has formulized the technology into JEE’s technology stack.
Starting from EJB 3.0, the entity bean specification has been replaced by the Java Persistence API (JPA)
These two chapters combined show how we use Spring and JPA 2, using Hibernate as the persistence service provider, to build the implementation of our data access tier.
For Spring with JPA and Hibernate, we will also discuss how to use the Spring Data JPA to implement logging for users who create blogs or comment and how to use Hibernate’s Envers (Entity Versioning System) to implement the audit log function.
Strictly speaking, MyBatis is not an ORM tool but a DataMapper framework that does not remove all responsibility from the developer for creating the SQL statements needed to map Java objects to data in the RDMBS.
MyBatis introduces the concept of a SQL map, allowing you to specify a variety of SQL queries and how these queries map to both input and output parameters.
MyBatis is quite powerful in some aspects of data access.
Chapter 11 discusses MyBatis in detail and shows how we built the second data access implementation.
In all cases, we use Spring’s infrastructure classes for each data access tool.
Implementing the Service Layer The SpringBlog application is fairly simple, and aside from the basic storage and retrieval of blog data, there are very few business rules in the system.
However, there are two particular business functions in the SpringBlog application that exploit two of the most interesting Spring features: the AOP-based obscenity filter and the audit log.
Using AOP for Obscenity Filtering AOP is a hot topic in the Java world at the moment, and as a result, Java developers are fortunate to have a wide range of AOP implementations available to them.
Spring AOP support comes in two forms: the Spring native AOP framework and integration with the AspectJ AOP framework.
For the SpringBlog application, we wanted to provide a practical example of AOP usage rather than the traditional (and boring) logging example.
One of the features that we were working on for the sample application was an obscenity filter, and during design, it became apparent that AOP was the ideal mechanism for implementing this filter.
In Chapter 21, you will see how we built the obscenity filter and how we used AOP to apply the filter selectively to the relevant methods.
Using Spring Transaction Support As developers, one of the features of Spring that we found most impressive was the transaction support.
Spring’s transaction support provides a simple mechanism to control transactions across one or more resource providers, either programmatically or declaratively.
Chapter 13 discusses the transaction framework in detail, focusing specifically on database transactions using both local and distributed transactions.
For the SpringBlog application, we defined a requirement that all operations in the blog be audited and logged to the database.
To ensure that an operation is rolled back if the audit process fails, we used the Spring transaction framework to encapsulate each operation and its audit process in a single transaction.
Bean Validation One thing developers want the most is a centralized validation rules engine, in which all the validation rules are applied and checked against the data, no matter where the data comes from (e.g., a user enters the information via the web application or from an XML file during batch job processing)
The ideal case is that those validation rules need to be defined only once, and then the data can be validated against those rules on any layer when required.
The Bean Validation API (JSR-303) was created to serve this purpose.
Two Different Service Layers Implementation Traditionally, in the data access layer, developers will implement data access objects (DAOs) to separate the data access logic from the business logic.
Those DAOs will be injected into the objects within the service layer.
The intention is to make the switch from one data access implementation to another easier.
However, the DAO pattern introduces one more layer between the service layer and backend database, which has proven to be quite cumbersome in most scenarios.
In addition, by using standards like JPA, the persistence context can be injected directly into the service layer for data access, using the standard API as defined by JPA.
You then have the flexibility to switch from one JPA persistence provider to another (such as from Hibernate to Eclipselink) easily.
As a result, most applications these days do not use DAO, and all the business and data access logic is encapsulated into the service layer.
For the SpringBlog application, the service layer includes a number of interfaces that reflect the business services that the layer can provide.
And as discussed earlier, we will provide two different implementations of the service layer using different persistence technologies; one uses JPA and Hibernate, while the other uses MyBatis.
We will also show you how to specify which service implementation to use in the application by using a new configuration feature in Spring 3.1 called profiles.
Implementing the Batch and Integration Layer Most applications need to integrate with other systems for exchanging information, either through a batch or on a real-time basis.
Two Spring projects, Spring Batch and Spring Integration, can work together and provide a powerful and standard platform for the implementation of batch jobs and basic Enterprise Integration Pattern (EIP)
We will use the two Spring projects to implement a batch job to import blog entries from an XML file.
We will use Spring Integration’s file polling support to trigger the batch job whenever a file arrives into the specific folder.
Implementing the Presentation Layer As with support for data access technologies, Spring is well known for its support of a wide range of different web application frameworks and tools.
Spring MVC Currently there are many web frameworks on the market, and each has its pros and cons.
Standardizing on a single framework and hoping it can address all the requirements of web applications with different natures and business purposes is almost impossible.
In SpringBlog, we will implement the web layer using a more common and simple approach.
The MVC pattern will be adopted, and Spring MVC will be used as the framework.
On the view side, we will use standard JSP pages.
For Ajax features, we will use jQuery JavaScript library and Spring MVC’s comprehensive RESTful-WS support for implementation.
Using Tiles With most web applications, only a portion of the screen changes each time a new request is processed, and common elements such as the header and navigation bar remain the same.
Using Tiles, you can assemble your pages from individual parts called tiles, enabling common elements to be defined once and reused across the application.
Chapter 17 looks at using Tiles with a Spring application and shows how we used Tiles to build the sample application.
RESTful-WS and OXM Another feature that Spring provides is an RSS feed in XML format.
Implementing the Security Layer Security is another major concern for any application, especially web applications.
Without a proper security control, your web application may suffer from web attacks and loss of important business data.
Its comprehensive support for both declarative and programmatic security access control and tight integration with Spring greatly simplifies the code developers need to implement.
For the SpringBlog application, we will use Spring Security 3.1 to protect the web application and ensure that users are only allowed to do what they are granted to do based on the roles assigned.
As the user information and their roles assigned are stored in SpringBlog database, we will implement a user detail service class for Spring Security to retrieve the information and apply the security measures accordingly.
Summary In this chapter, you looked at the SpringBlog application that we discuss throughout the book, and you were introduced to various features of SpringBlog, how they are implemented, and where in the book they are discussed.
In the next chapter, we will discuss the core of the Spring Framework—its Inversion of Control (IoC) container.
In Chapter 1, we covered the basic principles of Inversion of Control (IoC) and Dependency Injection (DI)
Practically, DI is a specialized form of IoC, although you will often find that the two terms are used interchangeably.
In this chapter, we take a much more detailed look at IoC and DI, formalizing the relationship between the two concepts and looking in great detail at how Spring fits into the picture.
After defining both and looking at Spring’s relationship with them, we will explore the concepts that are essential to Spring’s implementation of DI.
Inversion of Control concepts: In this section, we discuss the various kinds of IoC including Dependency Injection and Dependency Lookup.
This section looks at the differences between the various IoC approaches and presents the pros and cons of each.
Inversion of Control in Spring: This section looks at IoC capabilities available in Spring and how these capabilities are implemented.
For bean definition and DI requirements, BeanFactory is the main interface an application interacts with.
However, other than the first few samples, all the rest of the sample codes provided in this chapter will focus on using Spring’s ApplicationContext interface, which is an extension of BeanFactory and provides much more powerful features than enterprise applications would require.
We will cover the difference between BeanFactory and ApplicationContext in later sections.
Configuring Spring application context: The final part of this chapter focuses on using both the XML-based configuration and the Java annotation approach for the ApplicationContext configuration.
Inversion of Control and Dependency Injection At its core, IoC, and therefore DI, aims to offer a simpler mechanism for provisioning component dependencies (often referred to as an object’s collaborators) and managing these dependencies throughout their life cycles.
A component that requires certain dependencies is often referred to as the dependent object or, in the case of IoC, the target.
This is a rather grand way of saying that IoC provides services through which a component can access its dependencies and services for interacting with the dependencies throughout their life.
These subtypes are further decomposed into concrete implementations of the IoC services.
From this definition, you can clearly see that when we are talking about DI, we are always talking about IoC, but when we are talking about IoC, we are not always talking about DI (for example, Dependency Lookup is also a form of IoC)
Types of Inversion of Control You may be wondering why there are two different types of IoC and why these types are split further into different implementations.
There seems to be no clear answer to this question; certainly the different types provide a level of flexibility, but to us, it seems that IoC is more of a mixture of old and new ideas; the two different types of IoC represent this.
Dependency Lookup is a much more traditional approach, and at first glance, it seems more familiar to Java programmers.
Dependency Injection is a newer, less well-established approach that, although it appears counterintuitive at first, is actually much more flexible and usable than Dependency Lookup.
With Dependency Lookup–style IoC, a component must acquire a reference to a dependency, whereas with Dependency Injection, the dependencies are injected into the component by the IoC container.
Note For the discussions in this section, we are not concerned with how the fictional IoC container comes to know about all the different dependencies, just that at some point, it performs the actions described for each.
In Dependency Pull, dependencies are pulled from a registry as required.
Anyone who has ever written code to access an EJB (2.1 or prior versions) has used Dependency Pull (i.e., via the JNDI API to look up an EJB component)
Figure 4-1 shows the scenario of Dependency Pull via the lookup mechanism.
Listing 4-1 shows a typical Dependency Pull lookup in a Spring-based application.
Not only is this kind of IoC prevalent in JEE-based applications (using EJB 2.1 or prior versions), which make extensive use of JNDI lookups to obtain dependencies from a registry, but it is also pivotal to working with Spring in many environments.
Contextualized Dependency Lookup Contextualized Dependency Lookup (CDL) is similar, in some respects, to Dependency Pull, but in CDL, lookup is performed against the container that is managing the resource, not from some central registry, and it is usually performed at some set point.
By implementing this interface, a component is signaling to the container that it wants to obtain a dependency.
The Container is usually provided by the underlying application server (e.g., Tomcat, JBoss) or framework (e.g., Spring)
Listing 4-3 shows a simple Container interface that provides a Dependency Lookup service.
When the container is ready to pass dependencies to a component, it calls performLookup() on each component in turn.
The component can then look up its dependencies using the Container interface, as shown in Listing 4-4
Note that in Listing 4-4, Dependency is an empty class.
Constructor Dependency Injection Constructor Dependency Injection is Dependency Injection where a component’s dependencies are provided to it in its constructor(s)
The component declares a constructor or a set of constructors taking as arguments its dependencies, and the IoC container passes the dependencies to the component when it instantiates it, as shown in Listing 4-5
A component’s setters expose the set of dependencies the IoC container can manage.
Within the container, the dependency requirement exposed by the setDependency() method is referred to by the JavaBeans-style name, dependency.
In practice, Setter Injection is the most widely used injection mechanism, and it is one of the simplest IoC mechanisms to implement.
Lookup Choosing which style of IoC to use—injection or lookup—is not usually a difficult decision.
In many cases, the type of IoC you use is mandated by the container you are using.
For instance, if you are using EJB 2.1 or prior versions, then you must use lookup-style IoC (via JNDI) to obtain the EJB from the JEE container.
In Spring, aside from initial bean lookups, your components and their dependencies are always wired together using injection-style IoC.
Note When you are using Spring, you can access EJB resources without needing to perform an explicit lookup.
Spring can act as an adapter between lookup and injection-style IoC systems, thus allowing you to manage all.
The real question is this: given the choice, which method should you use, injection or lookup? The answer to this is most definitely injection.
The Dependency Pull code, on the other hand, must actively obtain a reference to the registry and interact with it to obtain the dependencies, and using CDL requires your classes to implement a specific interface and look up all dependencies manually.
When you are using injection, the most your classes have to do is allow dependencies to be injected using either constructors or setters.
Using injection, you are free to use your classes completely decoupled from the IoC container that is supplying dependent objects with their collaborators manually, whereas with lookup, your classes are always dependent on the classes and interfaces defined by the container.
Another drawback with lookup is that it becomes very difficult to test your classes in isolation from the container.
Using injection, testing your components is trivial, because you can simply provide the dependencies yourself using the appropriate constructor or setter.
Lookup-based solutions are, by necessity, more complex than injection-based ones.
Although complexity is nothing to be afraid of, we question the validity of adding unneeded complexity to a process as core to your application as dependency management.
All of these reasons aside, the biggest reason to choose injection over lookup is that it makes your life easier.
You write substantially less code when you are using injection, and the code that you do write is simple and can, in general, be automated by a good IDE.
You will notice that all of the code in the injection samples is passive, in that it doesn’t actively try to accomplish a task.
The most exciting thing you see in injection code is objects getting stored in a field only; no other codes were involved in pulling the dependency from any registry or container.
Therefore, the code is much simpler and less error prone.
Passive code is much simpler to maintain than active code, because there is very little that can go wrong.
In this code, plenty could go wrong: the dependency key could change, the container instance could be null, or the returned dependency might be the incorrect type.
We refer to this code as having a lot of moving parts because plenty of things can break.
Constructor Injection Now that we have established which method of IoC is preferable, you still need to choose whether to use Setter Injection or Constructor Injection.
Constructor Injection is particularly useful when you absolutely must have an instance of the dependency class before your component is used.
Many containers, Spring included, provide a mechanism for ensuring that all dependencies are defined when you use Setter Injection, but by using Constructor Injection, you assert the requirement for the dependency in a container-agnostic manner.
If the component is exposing its dependencies to the container but is happy to provide its own defaults, then Setter Injection is usually the best way to accomplish this.
Another benefit of Setter Injection is that it allows dependencies to be declared on an interface, although this is not as useful as you might first think.
If, in addition to this method, you define a setter for injection such as setEncylopedia(), then you are mandating that all implementations must use or at least be aware of the encyclopedia dependency.
However, you don’t need to define setEncylopedia() in the business interface.
Instead, you can define the method in the classes implementing the business interface.
While programming in this way, all recent IoC containers, Spring included, can work with the component in terms of the business interface but still provide the dependencies of the implementing class.
Notice that the business interface does not define any setters for Dependency Injection.
This interface could be implemented as shown in Listing 4-8
As you can see, the BookwormOracle class not only implements the Oracle interface but also defines the setter for Dependency Injection.
Spring is more than comfortable dealing with a structure like thisthere is absolutely no need to define the dependencies on the business interface.
The ability to use interfaces to define dependencies is an often-touted benefit of Setter Injection, but in actuality, you should strive to keep setters used solely for injection out of your business and DAO interfaces.
Unless you are absolutely sure that all implementations of a particular business interface require a particular dependency, let each implementation class define its own dependencies and keep the business interface for business methods.
Although you shouldn’t always place setters for dependencies in a business interface, placing setters and getters for configuration parameters in the business interface is a good idea and makes Setter Injection a valuable tool.
We consider configuration parameters to be a special case for dependencies.
Certainly your components depend on the configuration data, but configuration data is significantly different from the types of dependency you have seen so far.
We will discuss the differences shortly, but for now, consider the business interface shown in Listing 4-9
The NewsletterSender interface is implemented by classes that send a set of newsletters via e-mail.
The send() method is the only business method, but notice that we have defined two JavaBean properties on the interface.
Why are we doing this when we just said that you shouldn’t define dependencies in the business interface? The reason is that these values, the SMTP server address and the address the e-mails are sent from, are not dependencies in the practical sense; rather, they are configuration details that affect how all implementations of the NewsletterSender interface function.
Spring’s Dependency Injection capabilities form the ideal solution to the external configuration of application components, not for dependency provision but as a mechanism for externalizing component configuration settings.
The question here then is this: what is the difference between a configuration parameter and any other kind of dependency? In most cases, you can clearly see whether a dependency should be classed as a configuration parameter, but if you are not sure, look for the following three characteristics that point to a configuration parameter:
In the NewsletterSender example shown in Listing 4-8, the SMTP server parameter is an example of a passive dependency.
Passive dependencies are not used directly to perform an action; instead, they are used internally or by another dependency to perform their actions.
In the MessageRenderer example from Chapter 2, the MessageProvider dependency was not passive—it performed a function that was necessary for the MessageRenderer to complete its task.
By this we mean that a configuration parameter is usually some piece of information that a component needs to complete its work.
Configuration parameters are usually simple values or collections of simple values.
This is really a by-product of the previous two points, but configuration parameters are usually simple values.
In Java this means they are a primitive (or the corresponding wrapper class) or a String or collections of these values.
This means you can’t do much with a String other than manipulate the data it represents; and you almost always use these values for information purposes—for example, an int value that represents the port number that a network socket should listen on, or a String that represents the SMTP server through which an e-mail program should send messages.
When considering whether to define configuration options in the business interface, also consider whether the configuration parameter is applicable to all implementations of the business interface or just one.
For instance, in the case of implementations of NewsletterSender, it is obvious that all implementations need to know which SMTP server to use when sending e-mails.
However, we would probably choose to leave the configuration option that flags whether to send secure e-mail off the business interface, because not all e-mail APIs are capable of this, and it is correct to assume that many implementations will not take security into consideration at all.
Note Recall that in Chapter 2, we chose to define the dependencies in the business purposes.
This was for illustration purposes and should not be treated in any way as a best practice.
Setter injection also allows you to swap dependencies for a different implementation on the fly without creating a new instance of the parent component.
Perhaps the biggest benefit of Setter Injection is that it is the least intrusive of the injection mechanisms.
If you are defining constructors for injection on a class that would otherwise just have the default constructor, then you are affecting all code that uses that class in a non-IoC environment.
Extra setters that are defined on a class for IoC purposes do not affect the ability of other classes to interact with it.
In general, setter-based injection is the best choice, because it has the least effect on your code’s usability in non-IoC settings.
Constructor injection is a good choice when you want to ensure that dependencies are being passed to a component, but bear in mind that many containers provide their own mechanism for doing this with Setter Injection.
Most of the code in the sample application uses Setter Injection, although there are a few examples of Constructor Injection.
Inversion of Control in Spring As we mentioned earlier, Inversion of Control is a big part of what Spring does, and the core of Spring’s implementation is based on Dependency Injection, although Dependency Lookup features are provided as well.
When Spring provides collaborators to a dependent object automatically, it does so using Dependency Injection.
In a Spring-based application, it is always preferable to use Dependency Injection to pass collaborators to dependent objects rather than have the dependent objects obtain the collaborators via lookup.
Although Dependency Injection is the preferred mechanism for wiring together collaborators and dependent objects, you need Dependency Lookup to access the dependent objects.
In many environments, Spring cannot automatically wire up all of your application components using Dependency Injection, and you must use Dependency Lookup to access the initial set of components.
For example, in stand-alone Java applications, you need to bootstrap Spring’s container in the main() method and obtain the dependencies (via the ApplicationContext interface) for processing programmatically.
However, when you are building web applications using Spring’s MVC support, Spring can avoid this by gluing your entire application together automatically.
Wherever it is possible to use Dependency Injection with Spring, you should do so; otherwise, you can fall back on the Dependency Lookup capabilities.
You will see examples of both in action during the course of this chapter, and we will point them out when they first arise.
An interesting feature of Spring’s IoC container is that it has the ability to act as an adaptor between its own Dependency Injection container and external Dependency Lookup containers.
Spring supports both Constructor and Setter Injection and bolsters the standard IoC feature set with a whole host of useful additions to make your life easier.
The rest of this chapter introduces the basics of Spring’s DI container complete with plenty of examples.
Dependency Injection with Spring Spring’s support for Dependency Injection is comprehensive and, as you will see in Chapter 5, goes beyond the standard IoC feature set we have discussed so far.
The rest of this chapter addresses the basics of Spring’s Dependency Injection container, looking at Setter, Constructor, and Method Injection, along with a detailed look at how Dependency Injection is configured in Spring.
A BeanFactory is responsible for managing components, including their dependencies as well as their life cycles.
In Spring, the term bean is used to refer to any component managed by the container.
Typically your beans adhere, at some level, to the JavaBeans specification, but this is not required, especially if you plan to use Constructor Injection to wire your beans together.
If your application needs only DI support, you can interact with the Spring DI container via the BeanFactory interface.
In this case, your application must create an instance of a class that implements the BeanFactory interface and configures it with bean and dependency information.
After this is complete, your application can access the beans via the BeanFactory and get on with its processing.
All of the examples in this chapter require manual setup of the BeanFactory implementation.
Although a BeanFactory can be configured programmatically, it is more common to see it configured externally using some kind of configuration file.
Internally, bean configuration is represented by instances of classes that implement the BeanDefinition interface.
The bean configuration stores not only information about a bean itself but also about the beans that it depends on.
So you can identify your beans within the BeanFactory, each bean can be assigned either an ID or a name, or both.
A bean can also be instantiated without any ID and name (known as an anonymous bean) or as an inner bean within a specific bean.
Each bean has at least one name but can have any number (additional names are separated by commas)
Any names after the first are considered aliases for the same bean.
You use bean IDs or names to retrieve a bean from the BeanFactory and also to establish dependency relationships—that is, bean X depends on bean Y.
BeanFactory Implementations The description of the BeanFactory might make using it seem overly complex, but in practice, this is not the case.
Let’s say you have an implementation that mimics an oracle that can tell you the meaning of life.
Now let’s see, in a stand-alone Java program, how we can initialize Spring’s BeanFactory and obtain the oracle bean for processing (see Listing 4-12)
Once the BeanFactory implementation is created and configured, we retrieve the Oracle bean using its name, oracle, which is configured in the XML configuration file.
Don’t worry too much about the configuration at the moment; we will discuss the details in later sections.
Although properties are ideal for small, simple applications, they can quickly become cumbersome when you are dealing with a large number of beans.
For this reason, it is preferable to use the XML configuration format for all but the most trivial of applications.
Of course, you are free to define your own BeanFactory implementations, although be aware that doing so is quite involved; you need to implement a lot more interfaces than just BeanFactory to get the same level of functionality you have with the supplied BeanFactory implementations.
In developing Spring-based application, it’s recommended that you interact with Spring via the ApplicationContext interface.
From this point onward, all the sample code in this book will use ApplicationContext.
Configuring ApplicationContext Having discussed the basic concepts of IoC and DI and gone through a simple example of using Spring’s BeanFactory interface, let’s dive into the details on how to configure a Spring application.
In the following sections, we will go through various aspects of configuring Spring applications.
Specifically, we will focus our attention on the ApplicationContext interface, which provides many more configuration options than the traditional BeanFactory interface.
Originally, Spring supports defining beans either through properties or an XML file, and the XML file was used by most Spring application developers for quite some time.
So, which one is better, XML or annotations? There have been lots of debates on this topic, and you can find numerous discussions about this topic on the Internet (for example, try the Spring Community Forum at http://forum.springsource.org)
There is no definite answer, and each approach has its pros and cons.
Using XML file can externalize all configuration from Java code, while annotations allow the developer to define and view the DI setup from within the code.
Spring also supports a mix of the two approaches in a single ApplicationContext (the XML file configuration will override the annotation ones)
However, no matter which option you choose, stick to it and deliver the message clearly across the entire development team.
Agreeing on the style to use and keeping it consistent across the application will make ongoing development and the maintenance activities much easier.
To facilitate your understanding of both the XML and annotation configuration, we’ll provide sample code for XML and annotations side by side whenever appropriate.
Basic Configuration Overview For XML configuration, you need to declare the required namespace base provided by Spring that your application requires.
Listing 4-13 shows the most basic sample, which declares only the beans namespace for you to define the Spring beans.
Besides beans, Spring provides a large number of other namespaces for different purposes.
In the section on Spring configuration, we will prepare two configuration files throughout the samples.
From the previous namespace declaration, we have made beans the default namespace.
Spring also provides a lot of namespace for various purpose, such as aop for AOP support, tx for transaction support, and so on.
Moreover, the tag support inclusion and exclusion of components scan for more fine-grained control.
The previous tag tells Spring to scan the package as specified but omit the classes that were assignable to the type as specified in the expression (can be either a class or an interface)
Besides the exclude filter, you can also use an include filter.
Declare Spring Components After you develop some kind of service classes and want to use it in a Spring base application, you need to tell Spring that those beans are eligible for injection to other beans and have Spring manage them for you.
Consider the sample in Chapter 2, where the MessageRender outputs the message and depends on the MessageProvider to provide the message to render.
Listing 4-17 recaps the interfaces and implementations of the two services.
From the previous code sample, you use Spring’s @Service annotation to specify that the bean provides services that other beans may require, passing in the bean name as the parameter.
When bootstrapping Spring’s ApplicationContext with the XML configuration in Listing 4-15, Spring will seek out those components and instantiate the beans with the specified names.
Using either approach doesn’t affect the way you obtain the beans from ApplicationContext.
Listing 4-20 shows the example code to obtain the message provider.
From this code, you can see that we are assigning the messageProvider bean to the messageProvider property.
You can use the <ref> tag to assign a bean reference to a property (discussed in more detail shortly)
If you are using Spring 2.5 or later and have the p namespace declared in your XML configuration file, you can declare the injection as shown here:
The p namespace provides a simplified way for defining Setter Injection.
You just need to add an @Autowired annotation to the setter.
Now let’s verify the result by using the code in Listing 4-25
In the Spring configuration file, you can easily create a configurable MessageProvider that allows the message to be defined externally, as shown in Listing 4-26
This is exactly what we want, and this class is ideally suited for use with Constructor Injection.
It is always best to use the index attribute whenever you are dealing with constructors that have multiple arguments to avoid confusion between the parameters and ensure that Spring picks the correct constructor.
Like the p namespace, in Spring 3.1, you can also use the c namespace, as shown here:
From the previous listing, you can see that we use another annotation, @Value, to define the value to be injected into the constructor.
This is the way in Spring you inject values into a bean.
Besides simple strings, you can also use the powerful SpEL for dynamic value injection (more on this later in this chapter)
However, hard-coding the value in the code is not a good idea, since to change it, you would need to recompile the program.
Even if you choose annotation-style DI, a good practice is to externalize those values for injection.
To externalize the message, let’s define the message as a Spring bean in the annotation configuration file, as in Listing 4-29
Notice that we also used the c namespace for Constructor Injection to set the string value, and _0 indicates the index for constructor argument.
Since we declared the message bean and its ID are the same as the name of the argument specified in the constructor, Spring will detect the annotation and inject the value into the constructor method.
Avoiding Constructor Confusion In some cases, Spring finds it impossible to tell which constructor you want it to use for Constructor Injection.
This usually arises when you have two constructors with the same number of arguments and the types used in the arguments are represented in exactly the same way.
Which of the constructors is called in this case? Running the example yields the following output:
This shows that the constructor with the String argument was called.
This is not the desired effect, since we want to prefix any integer values passed in using Constructor Injection with Number:, as shown in the int constructor.
Notice now that the <constructor-arg> tag has an additional attribute, type, that specifies the type of argument Spring should look for.
Running the example again with the corrected configuration yields the correct output:
For annotation-style Construction Injection, the confusion can be avoided by applying the annotation directly to the target constructor method, as we’ve done in Listing 4-34
By applying the @Autowired annotation to the desired constructor method, Spring will use that method to instantiate the bean and inject the value as specified.
Like before, you should externalize the value into the configuration.
Note You can apply the @Autowired annotation to only one of the constructor methods.
If you apply the annotation to more than one constructor method, Spring will complain during bootstrapping the ApplicationContext.
Injection Parameters In the two previous examples, you saw how to inject other components and values into a bean using both Setter Injection and Constructor Injection.
Spring supports a myriad of options for injection parameters, allowing you to inject not only other components and simple values but also Java Collections, externally defined properties, and even beans in another factory.
Injecting Simple Values Injecting simple values into your beans is easy.
To do so, simply specify the value in the configuration tag, wrapped inside a <value> tag.
By default, not only can the <value> tag read String values, but it can.
Listing 4-35 shows a simple bean that has a variety of properties exposed for injection.
In addition to the properties, the InjectSimple class also defines the main() method that creates an ApplicationContext and then retrieves an InjectSimple bean from Spring.
The property values of this bean are then written to the console output.
Here is the output created by running this example as expected:
For annotation-style simple value injection, we can apply the @Value annotation to the bean properties.
This time, instead of the setter method, we apply the annotation to the property declaration statement, as you can see in Listing 4-37
Spring supports the annotation either at the setter method or in the properties.
SpEL enables you to evaluate an expression dynamically and then use it in Spring’s ApplicationContext.
One use case is to use the result for injection into Spring beans.
In this section, we take a look at how to use SpEL to inject properties from other beans, by using the example presented in the previous sample.
Suppose now we want to externalize the values to be injected into a Spring bean in a configuration class, as in Listing 4-38
When using annotation-style value injection, we just need to substitute the value annotations with the SpEL expressions (see Listing 4-41)
Listing 4-42 shows the annotation version of the InjectSimpleConfig class.
Both annotations were instructing Spring that the annotated class is a candidate for autodetection using annotation-based configuration and classpath scanning.
However, since the InjectSimpleConfig class is storing the application configuration, rather than providing a business service, using @Component makes more sense.
Using SpEL, you can access any Spring-managed beans and properties and manipulate them for application use by Spring’s support of sophisticated language features and syntax.
Injecting Beans in the Same XML Unit As you have already seen, it is possible to inject one bean into another using the <ref> tag.
Listing 4-43 shows a class that exposes a setter to allow a bean to be injected.
To configure Spring to inject one bean into another, you first need to configure two beans: one to be injected and one to be the target of the injection.
Once this is done, you simply configure the injection using the <ref> tag on the target bean.
Running the class in Listing 4-43 will produce the following output:
Encyclopedias are a waste of money - use the Internet.
An important point to note is that the type being injected does not have to be the exact type defined on the target; the types just need to be compatible.
Compatible means that if the declared type on the target is an interface, then the injected type must implement this interface.
If the declared type is a class, then the injected type must be either the same type or a subtype.
In this example, the InjectRef class defines the setOracle() method to receive an instance of Oracle, which is an interface, and the injected type is BookwormOracle, a class that implements Oracle.
This is a point that causes confusion for some developers, but it is really quite simple.
Injection is subject to the same typing rules as any Java code, so as long as you are familiar with how Java typing works, then understanding typing in injection is easy.
In the previous example, the id of the bean to inject was specified using the local attribute of the <ref> tag.
As you will see later, in the section “Understanding Bean Naming,” you can give a bean more.
When you use the local attribute, it means that the <ref> tag only ever looks at the bean’s id and never at any of its aliases.
Moreover, the bean definition should exist in the same XML configuration file.
To inject a bean by any name or import one from other XML configuration files, use the bean attribute of the <ref> tag instead of the local attribute.
Listing 4-45 shows an alternative configuration for the previous example using an alternative name for the injected bean.
In this example, the oracle bean is given an alias using the name attribute, and then it is injected into the injectRef bean by using this alias in conjunction with the bean attribute of the <ref> tag.
Don’t worry too much about the naming semantics at this point—we discuss this in much more detail later in the chapter.
Running the InjectRef class again (Listing 4-43) will produce the same result as the previous example.
Injection and ApplicationContext Nesting So far, the beans we have been injecting have been located in the same ApplicationContext (and hence the same BeanFactory) as the beans they are injected into.
However, Spring supports a hierarchical structure for ApplicationContext so that one context (and hence the associating BeanFactory) is considered the parent of another.
In that case, you simply replace the bean attribute of the <ref> tag with parent, and you are on your way.
Listing 4-48 shows a sample configuration file for the parent BeanFactory (parent.xml)
As you can see, this configuration simply defines two beans: injectBean and injectBeanParent.
The injectBean in this listing is similar to the injectBean in the parent except that the String it represents has a different value, indicating that it is located in the child ApplicationContext.
Because this bean exists only in the parent BeanFactory, target1 receives a reference to that bean.
This makes it easy to reference the beans transparently, allowing you to move beans between configuration files as your application grows.
The second point of interest is that you can’t use the local attribute to refer to beans in the parent ApplicationContext.
The XML parser checks to see that the value of the local attribute exists as a valid element in the same file, preventing it from being used to reference beans in the parent context.
The code in Listing 4-46 also demonstrates the semantics discussed here by retrieving each of the three targetX beans from the child BeanFactory and outputting the value of the val property in each case.
Using Collections for Injection Often your beans need access to collections of objects rather than just individual beans or values.
Therefore, it should come as no surprise that Spring allows you to inject a collection of objects into one of your beans.
The <props> tag only allows for Strings to be passed in as the value because the Properties class allows only for property values to be Strings.
This allows you to pass in a List of Maps, a Map of Sets, or even a List of Maps of Sets of Lists! Listing 4-50 shows a class that can have all four collection types injected into it.
That is quite a lot of code, but it actually does very little.
This method just outputs the contents of the Map, Properties, Set, and List instances that will be injected from Spring.
For the map property, we have injected a Map instance using the <map> tag.
Notice that each entry is specified using an <entry> tag, and each has a String key and then an entry value.
In Listing 4-51, you can see that we have added a String value and a bean reference to both the List and the Set.
As expected, it simply lists the elements added to the collections in the configuration file.
This is quite a powerful concept because you are not limited just to injecting collections of primitive values; you can also inject collections of beans or other collections.
Using this functionality, it is much easier to modularize your application and provide different, user-selectable implementations of key pieces of application logic.
Consider a system that allows corporate staff to create, proofread, and order their personalized business stationery online.
In this system, the finished artwork for each order is sent to the appropriate printer when it is ready for production.
The only complication is that some printers want to receive the artwork via e-mail, some via FTP, and still more using Secure Copy Protocol (SCP)
Using Spring’s collection injection, you can create a standard interface for this functionality, as shown in Listing 4-52
In Listing 4-52, the Recipient class is an empty class.
From this interface, you can create multiple implementations, each of which is capable of describing itself to a human, such as the ones shown in Listing 4-53
Imagine that you then develop an ArtworkManager class that supports all available implementations of the ArtworkSender interface.
With the implementations in place, you simply pass a List to your ArtworkManager class, and you are on your way.
Using the getFriendlyName() method, you can display a list of delivery options for the system administrator to choose from when you are configuring each stationery template.
In addition, your application can remain fully decoupled from the individual implementations if you just code to the ArtworkSender interface.
We will leave the implementation of the ArtworkManager class as an exercise for you.
Besides the XML configuration, we can also use annotation for collections injection.
However, we would also like to externalize the values of the collections into the configuration file for easy maintenance.
Let’s also develop an annotation version of the BookwormOracle class.
In the configuration in Listing 4-54, we make use of the util namespace provided by Spring to declare our beans for storing collection properties.
It greatly simplifies the configuration when comparing to previous versions of Spring.
Run the test program, and you will get the same result as the sample using XML configuration.
It’s because the @Autowired annotation is semantically defined in a way that it always treats arrays, collections, and maps as sets of corresponding beans, with the target bean type derived from the declared collection value type.
Lookup Method Injection provides another mechanism by which a bean can obtain one of its dependencies, and Method Replacement allows you to replace the implementation of any method on a bean arbitrarily, without having to change the original source code.
To provide these two features, Spring uses the dynamic bytecode enhancement capabilities of CGLIB.
If you want to use Lookup Method Injection or Method Replacement in your application, make sure you have the CGLIB JAR file on your classpath.
In this situation, both Setter and Constructor Injection result in the singleton maintaining a single instance of what should be a nonsingleton bean.
In some cases, you will want to have the singleton bean obtain a new instance of the nonsingleton every time it requires the bean in question.
Consider a scenario where there is a LockOpener class that provides the service of opening any locker.
The LockOpener class relies on a KeyHelper class for opening the locker, which was injected into LockOpener.
However, the design of KeyHelper class involves some internal states that make it not suitable for reuse.
Every time the openLock() method is called, a new KeyHelper instance is required.
However, if we inject the KeyHelper class using the normal mechanism, the same instance of the KeyHelper class (that was instantiated when Spring performed the injection the first time) will be reused.
To make sure that a new instance of the KeyHelper instance was passed into the openLock() method every time it was invoked, we need to use a Lookup Method Injection.
Then, using the ApplicationContext instance, the singleton bean can look up a new instance of the nonsingleton dependency every time it needs it.
Lookup Method Injection allows the singleton bean to declare that it requires a nonsingleton dependency and that it receive a new instance of the nonsingleton bean each time it needs to interact with it, without needing to implement any Spring-specific interfaces.
Lookup Method Injection works by having your singleton declare a method, the lookup method, which returns an instance of the nonsingleton bean.
When you obtain a reference to the singleton in your application, you are actually receiving a reference to a dynamically created subclass on which Spring has implemented the lookup method.
A typical implementation involves defining the lookup method, and thus the bean class, as abstract.
This prevents any strange errors from creeping in when you forget to configure the Method Injection and you are working directly against the bean class with the empty method implementation instead of the Spring-enhanced subclass.
This topic is quite complex and is best shown by example.
In this example, we create one nonsingleton bean and two singleton beans that both implement the same interface.
One of the singletons obtains an instance of the nonsingleton bean using “traditional” Setter Injection; the other uses Method Injection.
Listing 4-57 shows the MyHelper bean, which in our example is the nonsingleton bean.
This bean is decidedly unexciting, but it serves the purposes of this example perfectly.
In Listing 458, you can see the DemoBean interface, which is implemented by both of the singleton beans.
The sample application uses the getMyHelper() method to get a reference to the MyHelper instance and, in the case of the method lookup bean, to perform the actual method lookup.
The someOperation() method is a simple method that depends on the MyHelper class to do its processing.
This code should all look familiar, but notice that the someOperation() method uses the stored instance of MyHelper to complete its processing.
Notice that the getMyHelper() method is declared as abstract and that this method is called by the someOperation() method to obtain a MyHelper instance.
In Listing 4-61, you can see the configuration code required for this example (lookup.xml)
The configuration for the helper and standardLookupBean beans should look familiar to you by now.
The name attribute of the <lookup-method> tag tells Spring the name of the method on the bean that it should override.
This method must not accept any arguments, and the return type should be that of the bean you want to return from the method.
In this case, the method should return a class of type MyHelper, or its subclasses.
The bean attribute tells Spring which bean the lookup method should return.
Listing 4-62 shows the final piece of code for this example.
The first part of the displayInfo() method creates two local variables of MyHelper and assigns them each a value by calling getMyHelper() on the bean passed to it.
Using these two variables, it writes a message to stdout indicating whether the two references point to the same object.
For the abstractLookupBean class, a new instance of MyHelper should be retrieved for each call to getMyHelper(), so the references should not be the same.
Note The StopWatch class used in the previous example is a utility class available with Spring.
You’ll find StopWatch very useful when you need to perform simple performance tests and when you are testing your.
The final part of the displayInfo() method runs a simple performance test to see which bean is faster.
Clearly, the standardLookupBean should be faster because it returns the same instance each time, but it is interesting to see the difference.
Before we can run the example, we need to add the CGLIB dependency into the project, which is shown in Table 4-1
For details in adding project dependencies in STS, please refer to Appendix A.
We can now run the LookupDemo class (Listing 4-62) for testing.
As you can see, the helper instances are, as expected, the same when we use standardLookupBean and different when we use abstractLookupBean.
Method Lookup Injection is intended for use when you want to work with two beans of different life cycles.
Avoid the temptation to use Method Lookup Injection when the beans share the same life cycle, especially if they are singletons.
Listing 4-62 shows a noticeable difference in performance between using Method Injection to obtain new instances of a dependency and using standard DI to obtain a single instance of a dependency.
Also, make sure you don’t use Method Lookup Injection needlessly, even when you have beans of different life cycles.
Consider a situation in which you have three singletons that share a dependency in common.
You want each singleton to have its own instance of the dependency, so you create the dependency as a nonsingleton, but you are happy with each singleton using the same instance of the collaborator throughout its life.
In this case, Setter Injection is the ideal solution; Method Lookup Injection just adds unnecessary overhead.
When you are using Method Lookup Injection, there are a few design guidelines that you should bear in mind when building your classes.
In the earlier examples, we declared the lookup method in an interface.
The only reason we did this was we did not have to duplicate the displayInfo() method twice for two different bean types.
As we mentioned earlier, generally you do not need to pollute a business interface with unnecessary definitions that are used solely for IoC purposes.
Another point to bear in mind is that although you don’t have to make your lookup method abstract, doing so prevents you from forgetting to configure the lookup method and then using a blank implementation by accident.
Method Replacement Although the Spring documentation classifies method replacement as a form of injection, it is very different from what you have seen so far.
So far, we have used injection purely to supply beans with their collaborators.
Using method replacement, you can replace the implementation of any method on any beans arbitrarily without having to change the source of the bean you are modifying.
However, since you are not able to change the source code because it was provided by that third party, one solution is to use method replacement to just replace the logic for that method with your own implementation.
Internally you achieve this by creating a subclass of the bean class dynamically.
You use CGLIB and redirect calls to the method you want to replace to another bean that implements the MethodReplacer interface.
In Listing 4-63 you can see a simple bean that declares two overloads of a formatMessage() method.
You can replace any of the methods on the ReplacementTarget class using Spring’s method replacement functionality.
To replace a method, you first need to create an implementation of the MethodReplacer interface; this is shown in Listing 4-64
The MethodReplacer interface has a single method, reimplement(), that you must implement.
Three arguments are passed to reimplement(): the bean on which the original method was invoked, a Method instance that represents the method that is being overridden, and the array of arguments passed to the method.
The reimplement() method should return the result of your reimplemented logic, and, obviously, the type of the return value should be compatible with the return type of the method you are replacing.
It is not necessary to check to see whether the message is correct, but this can be useful if you are using a few MethodReplacers with similar arguments.
Using a check helps prevent a situation where a different MethodReplacer with compatible arguments and return types is used accidentally.
As you can see from Listing 4-65, the MethodReplacer implementation is declared as a bean in the ApplicationContext.
The name attribute of the <replaced-method> tag specifies the name of the method to replace, and the replacer attribute is used to specify the name of the MethodReplacer bean that we want to replace the method implementation.
In cases where there are overloaded methods such as in the ReplacementTarget class, you can use the <arg-type> tag to specify the method signature to match.
You should be very familiar with this code by now, so we won’t go into any detail on it.
On our machine, running this example yields the following output:
As expected, the output from the replacementTarget bean reflects the overridden implementation that the MethodReplacer provides.
Interestingly, though, the dynamically replaced method is more than three times slower than the statically defined method.
Removing the check for a valid method in the MethodReplacer made a negligible difference across a number of executions, so we can conclude that most of the overhead is in the CGLIB subclass.
Method replacement can prove quite useful in a variety of circumstances, especially when you want to override only a particular method for a single bean rather than all beans of the same type.
That said, we still prefer using standard Java mechanisms for overriding methods rather than depending on runtime bytecode enhancement.
If you are going to use method replacement as part of your application, we recommend you use one MethodReplacer per method or group of overloaded methods.
Avoid the temptation to use a single MethodReplacer for lots of unrelated methods; this results in lots of unnecessary String comparisons while your code works out which method it should reimplement.
We have found that performing simple checks to ensure that the MethodReplacer is working with the correct method is useful and doesn’t add too much overhead to your code.
If you are really concerned about performance, you can simply add a boolean property to your MethodReplacer, which allows you to turn the check on and off using Dependency Injection.
Understanding Bean Naming Spring supports quite a complex bean naming structure that allows you the flexibility to handle many different situations.
Every bean must have at least one name that is unique within the containing ApplicationContext.
Spring follows a simple resolution process to determine what name is used for the bean.
If you give the <bean> tag an id attribute, then the value of that attribute is used as the name.
If no id attribute is specified, Spring looks for a name attribute, and if one is defined, it uses the first name defined in the name attribute.
We say the first name because it is possible to define multiple names within the name attribute; this is covered in more detail shortly.
If neither the id nor the name attribute is specified, Spring uses the bean’s class name as the name, provided, of course, that no other bean is using the same class name.
Listing 4-67 shows a sample configuration that uses all three naming schemes.
Each of these approaches is equally valid from a technical point of view, but which is the best choice for your application? To start with, avoid using the automatic name by class behavior.
This doesn’t allow you much flexibility to define multiple beans of the same type, and it is much better to define your own names.
That way, if Spring changes the default behavior in the future, your application continues to work.
When choosing whether to use id or name, always use id to specify the bean’s default name.
Prior to Spring 3.1, the id attribute is the same as the XML identity (i.e., xsd:ID), which posts a restriction in the characters that you can use.
As of Spring 3.1, Spring uses xsd:String for the id attribute, so the previous restriction on the characters that you can use is gone.
However, Spring will continue to ensure that the id is unique across the entire ApplicationContext.
As a general practice, you should give your bean a name using id and then associate the bean with other names using name aliasing, as discussed in the next section.
Bean Name Aliasing Spring allows a bean to have more than one name.
You can do this in place of, or in conjunction with, using the id attribute.
Besides using the name attribute, you can also use the <alias> tag for defining aliases for Spring bean names.
As you can see, we have defined six names: one using the id attribute and the other four as a list using all allowed bean name delimiters in the name attribute (this is just for demonstration purposes and is not recommended for real-life development)
In real-life development, it’s recommended you standardize on the delimiter to use for separating bean names’ declarations within your application.
Listing 4-69 shows a sample Java routine that grabs the same bean from the ApplicationContext six times using different names and verifies that they are the same bean.
This code prints true five times to the console output for the configuration contained in Listing 4-68, verifying that the beans accessed using different names are in fact the same bean.
The list of aliases, other than the one you specified, will then be returned as a String array.
Bean name aliasing is a strange beast because it is not something you tend to use when you are building a new application.
If you are going to have many other beans inject another bean, then they may as well use the same name to access that bean.
However, as your application goes into production and maintenance work gets carried out, modifications are made, and so on, bean name aliasing becomes more useful.
Consider the following scenario: you have an application in which 50 different beans, configured using Spring, all require an implementation of the Foo interface.
Twenty-five of the beans use the StandardFoo implementation with the bean name standardFoo, and the other 25 use the SuperFoo implementation with the superFoo bean name.
Six months after you put the application into production, you decide to move the first 25 beans to the SuperFoo implementation.
The first is to change the implementation class of the standardFoo bean to SuperFoo.
The drawback of this approach is that you have two instances of the SuperFoo class lying around when you really need only one.
In addition, you now have two beans to make changes to when the configuration changes.
The second option is to update the injection configuration for the 25 beans that are changing, which changes the beans’ names from standardFoo to superFoo.
This approach is not the most elegant way to proceed—you could perform a find and replace, but then rolling back your changes when management isn’t happy means retrieving an old version of your configuration from your version control system.
The third, and most ideal, approach is to remove (or comment out) the definition for the standardFoo bean and make standardFoo an alias to the superFoo.
This change requires minimal effort, and restoring the system to its previous configuration is just as simple.
We demonstrated this in the previous example shown in Listing 4-64, where we were able to use identity comparison (==) rather than the equals() comparison to check whether the beans were the same.
The term singleton is used interchangeably in Java to refer to two distinct concepts: an object that has a single instance within the application, and the Singleton design pattern.
We refer to the first concept as singleton and to the Singleton pattern as Singleton.
The problem arises when people confuse the need for singleton instances with the need to apply the Singleton pattern.
Listing 4-70 shows a typical implementation of the Singleton pattern in Java.
This pattern achieves its goal of allowing you to maintain and access a single instance of a class throughout your application, but it does so at the expense of increased coupling.
In reality, the Singleton pattern is actually two patterns in one.
The first, and desired, pattern involves maintenance of a single instance of an object.
The second, and less desirable, is a pattern for object lookup that completely removes the possibility of using interfaces.
Using the Singleton pattern also makes it very difficult to swap out implementations arbitrarily, because most objects that require the Singleton instance access the Singleton object directly.
This can cause all kinds of headaches when you are trying to unit test your application because you are unable to replace the Singleton with a mock for testing purposes.
Fortunately, with Spring you can take advantage of the singleton instantiation model without having to work around the Singleton design pattern.
All beans in Spring are, by default, created as Singleton instances, and Spring uses the same instances to fulfill all requests for that bean.
Of course, Spring is not just limited to use of the singleton instance; it can still create a new instance of the bean to satisfy every dependency and every call to getBean()
It does all of this without any impact on your application code, and for this reason, we like to refer to Spring as being instantiation mode agnostic.
If you start off with an object that is a singleton but then discover it is not really suited to multithread access, you can change it to a nonsingleton without affecting any of your application code.
Note Although changing the instantiation mode of your bean won’t affect your application code, it does cause some problems if you rely on Spring’s life-cycle interfaces.
As you can see, the only difference between this bean declaration and any of the declarations you have seen so far is that we added the scope attribute and set the value to prototype.
The prototype scope instructs Spring to instantiate a new instance of the bean every time a bean instance was requested by the application.
Listing 4-72 shows the effect this setting has on your application.
You can see from this that although the values of the two String objects are clearly equal, the identities are not, despite that both instances were retrieved using the same bean name.
Choosing an Instantiation Mode In most scenarios, it is quite easy to see which instantiation mode is suitable.
Typically we find that singleton is the default mode for our beans.
In general, singletons should be used in the following scenarios:
Shared objects with no state: When you have an object that maintains no state and has many dependent objects.
Because you do not need synchronization if there is no state, you do not really need to create a new instance of the bean each time a dependent object needs to use it for some processing.
Shared object with read-only state: This is similar to the previous point, but you have some read-only state.
In this case, you still do not need synchronization, so creating an instance to satisfy each request for the bean is just adding additional overhead.
Shared object with shared state: If you have a bean that has state that must be shared, then singleton is the ideal choice.
In this case, ensure that your synchronization for state writes is as granular as possible.
High throughput objects with writable state: If you have a bean that is used a great deal in your application, then you may find that keeping a singleton and synchronizing all write access to the bean state allows for better performance than constantly creating hundreds of instances of the bean.
When using this approach, try to keep the synchronization as granular as possible without sacrificing consistency.
You will find that this approach is particularly useful when your application creates a large number of instances over a long period of time, when your shared object has only a small amount of writable state, or when the instantiation of a new instance is expensive.
Objects with writable state: If you have a bean that has a lot of writable state, then you may find that the cost of synchronization is greater than the cost of creating a new instance to handle each request from a dependent object.
Objects with private state: In some cases, your dependent objects need a bean that has private state so that they can conduct their processing separately from other objects that depend on that bean.
In this case, singleton is clearly not suitable, and you should use nonsingleton.
The main benefit you gain from Spring’s instantiation management is that your applications can immediately benefit from the lower memory usage associated with singletons, with very little effort on your part.
Then, if you find that singleton does not meet the needs of your application, it is a trivial task to modify your configuration to use nonsingleton mode.
Bean Scopes In addition to the singleton and prototype scopes, other scopes also exist when defining a Spring bean for more specific purposes.
You can also implement your own custom scope and register it in Spring’s ApplicationContext.
The following are the bean scopes that are supported as of version 3.1:
Prototype: A new instance will be created by Spring when requested by application.
When using Spring MVC for web application, beans with request scope will be instantiated for every HTTP request and then destroyed when the request is completed.
When using Spring MVC for web applications, beans with session scope will be instantiated for every HTTP session and then destroyed when the session is over.
The global session scope beans can be shared among all portlets within the same Spring MVC–powered portal application.
Thread: A new bean instance will be created by Spring when requested by a new thread, while for the same thread, the same bean instance will be returned.
Resolving Dependencies During normal operation, Spring is able to resolve dependencies by simply looking at your configuration file or annotations in your classes.
In this way, Spring can ensure that each bean is configured in the correct order so that each bean has its dependencies correctly configured.
If Spring did not perform this and just created the beans and configured them in any order, a bean could be created and configured before its dependencies.
This is obviously not what you want and would cause all sorts of problems within your application.
Unfortunately, Spring is not aware of any dependencies that exist between beans in your code.
For instance, take one bean, called bean A, which obtains an instance of another bean, called bean B, in the constructor via a call to getBean()
In this case, Spring is unaware that bean A depends on bean B, and, as a result, it may instantiate bean A before bean B.
You can provide Spring with additional information about your bean dependencies using the depends-on attribute of the <bean> tag.
Listing 4-73 shows how the scenario for bean A and bean B would be configured.
In this configuration, we are asserting that bean beanA depends on bean beanB.
Spring takes this into consideration when instantiating the beans and ensures that beanB is created before beanA.
When developing your applications, avoid designing your applications to use this feature; instead, define your dependencies by means of Setter and Constructor Injection contracts.
However, if you are integrating Spring with legacy code, then you may find that the dependencies defined in the code require you to provide extra information to the Spring Framework.
Autowiring Your Bean In all the examples so far, we have had to define explicitly, via the configuration file, how the individual beans are wired together.
If you don’t like having to wire all your components together, then you can have Spring attempt to do so automatically.
To enable it, you specify which method of autowiring you want to use by using the autowire attribute of the bean you want to autowire.
Different Modes of Autowiring Spring supports four modes for autowiring: byName, byType, constructor, default, and no (which is the default)
When using byName autowiring, Spring attempts to wire each property to a bean of the same name.
When using byType autowiring, Spring attempts to wire each of the properties on the target bean automatically using a bean of the same type in the ApplicationContext.
The constructor autowiring mode functions just like byType wiring, except that it uses constructors rather than setters to perform the injection.
Spring attempts to match the greatest numbers of arguments it can in the constructor.
In default mode, Spring will choose between constructor and byType modes automatically.
If your bean has a default (no-arguments) constructor, then Spring uses byType; otherwise, it uses constructor.
Listing 4-74 shows a simple configuration that autowires three beans of the same type using each of the different modes (autowiring.xml)
Notice that each of the Target beans has a different value for the autowire attribute.
Moreover, the lazy-init attribute was set to true to inform Spring to instantiate the bean only when it is first requested, rather than at startup, so that we can output the result in the correct place in the testing program.
Listing 4-75 shows a simple Java application that retrieves each of the Target beans from the ApplicationContext.
In this code, you can see that the Target class has three constructors: a no-argument constructor, a constructor that accepts a Foo instance, and a constructor that accepts a Foo and a Bar instance.
In addition to these constructors, the Target bean has three properties: two of type Foo and one of type Bar.
Each of these properties and constructors writes a message to console output when it is called.
From the output, you can see that when Spring uses byName, the only property that is set is the foo property, because this is the only property with a corresponding bean entry in the configuration file.
When using byType, Spring sets the value of all three properties.
When using constructor, Spring uses the twoargument constructor, because Spring can provide beans for both arguments and does not need to fall back to another constructor.
When to Use Autowiring In most cases, the answer to the question of whether you should use autowiring is definitely “no!” Autowiring can save you time in small applications, but in many cases, it leads to bad practices and is inflexible in large applications.
Using byName seems like a good idea, but it may lead you to give your classes artificial property names so that you can take advantage of the autowiring functionality.
The whole idea behind Spring is that you can create your classes how you like and have Spring work for you, not the other way around.
The same argument applies to the use of constructor autowiring.
In some cases, autowiring can save you time, but it does not really take that much extra effort to define your wiring explicitly, and you benefit from explicit semantics and full flexibility on property naming and on how many instances of the same type you manage.
For any nontrivial application, steer clear of autowiring at all costs.
Bean Inheritance In some cases, you many need multiple definitions of beans that are the same type or implement a shared interface.
This can become problematic if you want these beans to share some configuration settings but not others.
The process of keeping the shared configuration settings in sync is quite error-prone, and on large projects, doing so can be quite time-consuming.
To get around this, Spring allows you to define a <bean> definition that inherits its property settings from another bean in the same ApplicationContext.
You can override the values of any properties on the child bean as required, which allows you to have full control, but the parent bean can provide each of your beans with a base configuration.
In this code, you can see that the <bean> tag for the inheritChild bean has an extra attribute, parent, which indicates that Spring should consider the inheritParent bean the parent of the bean.
Because the inheritChild bean has its own value for the age property, Spring passes this value to the bean.
However, inheritChild has no value for the name property, so Spring uses the value given to the inheritParent bean.
Listing 4-77 shows the code for the SimpleBean class used in a previous configuration.
As you can see, the main() method of the SimpleBean class grabs both the inheritChild and inheritParent beans from the ApplicationContext and writes the contents of their properties to stdout.
As expected, the inheritChild bean inherited the value for its name property from the inheritParent bean but was able to provide its own value for the age property.
Child beans inherit both constructor arguments and property values from the parent beans, so you can use both styles of injection with bean inheritance.
This level of flexibility makes bean inheritance a powerful tool for building applications with more than a handful of bean definitions.
If you are declaring a lot of beans of the same value with shared property values, then avoid the temptation to use copy and paste to share the values; instead, set up an inheritance hierarchy in your configuration.
When you are using inheritance, remember that bean inheritance does not have to match a Java inheritance hierarchy.
It is perfectly acceptable to use bean inheritance on five beans of the same type.
Think of bean inheritance as more like a templating feature than an inheritance feature.
Be aware, however, that if you are changing the type of the child bean, then that type must be compatible with the type of the parent bean.
Summary In this chapter, we covered a lot of ground with both the Spring core and IoC in general.
We showed you examples of the different types of IoC and presented a discussion of the pros and cons of using each mechanism in your applications.
We looked at which IoC mechanisms Spring provides and when and when not to use each within your applications.
This chapter also introduced you to the basics of Spring’s IoC feature set including Setter Injection, Constructor Injection, Method Injection, autowiring, and bean inheritance.
This chapter only scratched the surface of Spring and Spring’s IoC container.
In the next chapter, we look at some IoC-related features specific to Spring, and we take a more detailed look at other functionality available in the Spring core.
In the previous chapter, we took a detailed look at the concept of Inversion of Control (IoC) and how it fits into the Spring Framework.
However, as we said at the end of the previous chapter, we have really only scratched the surface of what the Spring core can do.
Spring provides a wide array of services that supplement and extend the basic IoC capabilities.
A number of projects provide IoC containers, but none so far provides the same comprehensive feature set Spring provides.
In this chapter, we are going to look in detail at some additional IoC-related features offered in Spring along with other functionality offered by the Spring core.
Managing the bean life cycle: So far, all the beans you have seen have been fairly simple and completely decoupled from the Spring container.
In this section, we look at some strategies you can employ to enable your beans to receive notifications from the Spring container at various points throughout their life cycle.
You can do this either by implementing specific interfaces laid out by Spring, by specifying methods that Spring can call via reflection, or by using JSR250 JavaBeans life-cycle annotations.
Making your beans “Spring aware”: In some cases, you want a bean to be able to interact with the ApplicationContext that configured it.
This section of the chapter looks at implementing these interfaces and gives some practical considerations for using them in your application.
Using FactoryBeans: As its name implies, the FactoryBean interface is intended to be implemented by any bean that acts as a factory for other beans.
The FactoryBean interface provides a mechanism by which you can easily integrate your own factories with the Spring BeanFactory.
Working with JavaBeans PropertyEditors: The PropertyEditor interface is a standard interface provided in the java.beans package.
PropertyEditors are used to convert property values to and from String representations.
Spring uses PropertyEditors extensively, mainly to read values specified in the BeanFactory configuration and convert them into the correct types.
In this section of the chapter, we discuss the set of PropertyEditors supplied with Spring and how you can use them within your application.
The ApplicationContext interface provides a useful set of additional functionality, including internationalized message provision, resource loading, and event publishing.
In this chapter, we take a detailed look at the features in addition to IoC that the ApplicationContext offers.
We also jump ahead of ourselves a little and look at how the ApplicationContext simplifies the use of Spring when you are building web applications.
Configuration using Java classes: Prior to 3.0, Spring supported only the XML base configuration with annotations for beans and dependency configuration.
Starting with 3.0, Spring offers another option for developers to configure the Spring ApplicationContext using Java classes.
We take a look at this new option in Spring application configuration.
In this section, we take a look at those features and show how to use them to address specific configuration needs.
Spring’s Impact on Application Portability Most of the features discussed in this chapter are specific to Spring and, in many cases, are not available in other IoC containers.
Although many IoC containers offer life-cycle management functionality, they probably do so through a different set of interfaces than Spring.
If the portability of your application between different IoC containers is truly important, then you might want to avoid using some of the features that couple your application to Spring.
Remember, however, that by setting a constraint—that your application is portable between IoC containers—you are losing out on the wealth of functionality Spring offers.
Because you are likely to be making a strategic choice to use Spring, it makes sense that you use it to the best of its ability.
Although using these features may couple your application to the Spring Framework, in reality you are increasing the portability of your application in the wider scope.
Consider that you are using a freely available, open source framework that has no particular vendor affiliation.
An application built using Spring’s IoC container runs anywhere Java runs.
For Java enterprise applications, Spring opens up new possibilities for portability.
Spring provides many of the same capabilities as JEE and also provides classes to abstract and simplify many other aspects of JEE.
In many cases, it is possible to build a web application using Spring that runs in a simple servlet container but with the same level of sophistication as an application targeted at a full-blown JEE application server.
By coupling to Spring, you can increase your application’s portability by replacing many features that either are vendor-specific or rely on vendor-specific configuration with equivalent features in Spring.
Bean Life-Cycle Management An important part of any IoC container, Spring included, is that beans can be constructed in such a way that they receive notifications at certain points in their life cycle.
This enables your beans to perform relevant processing at certain points throughout their life.
The pre-destruction event is fired just before Spring destroys the bean instance.
However, for beans with prototype scope, the pre-destruction event will not be fired by Spring.
The design of Spring is that the initialization life-cycle callback methods will be called on objects regardless of bean scope, while for beans with prototype scope, the destruction life-cycle callback methods will not be called.
Spring provides three mechanisms a bean can use to hook into each of these events and perform some additional processing: interface-based, method-based, and annotation-based mechanisms.
Using the interface-based mechanism, your bean implements an interface specific to the type of notification it wants to receive, and Spring notifies the bean via a callback method defined in the interface.
For the method-based mechanism, Spring allows you to specify, in your ApplicationContext configuration, the name of a method to call when the bean is initialized and the name of a method to call when the bean is destroyed.
For the annotation mechanism, you can use JSR-250 annotations to specify the method that Spring should call after construction or before destruction.
In the case of both events, the mechanisms achieve exactly the same goal.
The interface mechanism is used extensively throughout Spring so that you don’t have to remember to specify the initialization or destruction each time you use one of Spring’s components.
However, in your own beans, you may be better served using the method-based or annotation mechanism because your beans do not need to implement any Spring-specific interfaces.
Although we stated that portability often isn’t as important a requirement as many books lead you to believe, this does not mean you should sacrifice portability when a perfectly good alternative exists.
That said, if you are coupling your application to Spring in other ways, using the interface method allows you to specify the callback once and then forget about it.
If you are defining a lot of beans of the same type that need to take advantage of the life-cycle notifications, then using the interface mechanism can avoid the need for specifying the life-cycle callback methods for every bean in the XML configuration file.
Using JSR-250 annotations is also another viable option, since it’s a standard defined by the JCP and you are also not coupled to Spring’s specific annotations.
Just make sure that the IoC container you are running your application on supports the JSR-250 standard.
Overall, the choice of which mechanism you use for receiving life-cycle notifications depends on your application requirements.
If you are concerned about portability or you are just defining one or two beans of a particular type that need the callbacks, then use the method-based mechanism.
If you use annotation-type configuration and certain that you are using an IoC container that supports JSR-250, then use the annotation mechanism.
If you are not too concerned about portability or you are defining many beans of the same type that need the life-cycle notifications, then using the interface-based mechanism is the best way to ensure that your beans always receive the notifications they are expecting.
If you plan to use a bean across many different Spring projects, then you almost certainly want the functionality of that bean to be as self-contained as possible, so you should definitely use the interfacebased mechanism.
Figure 5-1 shows a high-level overview of how Spring manages the life cycle of the beans within its container.
Hooking into Bean Creation By being aware of when it is initialized, a bean can check to see whether all its required dependencies are satisfied.
Although Spring can check dependencies for you, it is pretty much an all-or-nothing approach, and it doesn’t offer any opportunities for applying additional logic to the dependency resolution procedure.
Consider a bean that has four dependencies declared as setters, two of which are required and one of which has a suitable default in the event that no dependency is provided.
Using an initialization callback, your bean can check for the dependencies it requires, throwing an exception or providing a default as needed.
A bean cannot perform these checks in its constructor because at this point, Spring has not had an opportunity to provide values for the dependencies it can satisfy.
The initialization callback in Spring is called after Spring finishes providing the dependencies that it can and performs any dependency checks that you ask of it.
You are not limited to using the initialization callback just to check dependencies; you can do anything you want in the callback, but it is most useful for the purpose we have described.
In many cases, the initialization callback is also the place to trigger any actions that your bean must take automatically in response to its configuration.
For instance, if you build a bean to run scheduled tasks, the initialization callback provides the ideal place to start the scheduler—after all, the configuration data is set on the bean.
Note You will not have to write a bean to run scheduled tasks because this is something Spring can do automatically through its built-in scheduling feature or via integration with the Quartz scheduler.
Execute a Method When a Bean Is Created As we mentioned previously, one way to receive the initialization callback is to designate a method on your bean as an initialization method and tell Spring to use this method as an initialization method.
As discussed, this callback mechanism is useful when you have only a few beans of the same type or when you want to keep your application decoupled from Spring.
Another reason for using this mechanism is to enable your Spring application to work with beans that were built previously or were provided by third-party vendors.
Specifying a callback method is simply a case of specifying the name in the init-method attribute of a bean’s <bean> tag.
Notice that we have defined a method, init(), to act as the initialization callback.
The init() method checks to see whether the name property has been set, and if it has not, it uses the default value stored in the DEFAULT_NAME constant.
Notice that in the getBean() method, if the bean is obtained successfully, then its details are written to console output.
The getBean() method catches these exceptions and writes a message to the console output informing us of the error, as well as returns a null value.
As you can see, the <bean> tag for each of the three beans has an init-method attribute that tells Spring that it should invoke the init() method as soon as it finishes configuring the bean.
The simpleBean1 bean has values for both the name and age properties, so it passes through the init() method with absolutely no changes.
The simpleBean2 bean has no value for the name property, meaning that in the init() method, the name property is given the default value.
Finally, the simpleBean3 bean has no value for the age property.
From this output you can see that simpleBean1 was configured correctly with the values that we specified in the configuration file.
For simpleBean2, the default value for the name property was used because no value was specified in the configuration.
Finally, for simpleBean3, no bean instance was created because the init() method raised an error because of the lack of a value for the age property.
As you can see, using the initialization method is an ideal way to ensure that your beans are configured correctly.
By using this mechanism, you can take full advantage of the benefits of IoC without losing any of the control you get from manually defining dependencies.
The only constraint on your initialization method is that it cannot accept any arguments.
You can define any return type, although it is ignored by Spring, and you can even use a static method, but the method must accept no arguments.
The benefits of this mechanism are negated when using a static initialization method, because you cannot access any of the bean’s state to validate it.
If your bean is using static state as a mechanism for.
If you use Spring’s singleton management capabilities, the end effect is the same, but you have a bean that is much simpler to test, and you also have the increased effect of being able to create multiple instances of the bean with their own state when necessary.
Of course, there are instances in which you need to use static state shared across multiple instances of a bean, in which case you can always use a static initialization method.
Implementing the InitializingBean Interface The InitializingBean interface defined in Spring allows you to define inside your bean code that you want the bean to receive notification that Spring has finished configuring it.
In the same way as when you are using an initialization method, this gives you the opportunity to check the bean configuration to ensure that it is valid, providing any default values along the way.
Listing 5-3 shows a reimplementation of the previous example using the InitializingBean interface in place of the initialization method.
As you can see, not much in this example has changed (the changed codes are highlighted in bold)
The noticeable difference is the omission of the init-method attribute.
As you can see, the output is the same as the method mechanism.
The program is exactly the same as the SimpleBean; just apply the @PostConstruct annotation before the init() method.
Note that you can assign any name to the method.
For the configuration, we can use the one used by the interface mechanism (Listing 5-4)
Afterward, run the program, and you will see the same output as other mechanisms.
As we discussed earlier, all three approaches have their benefits and drawbacks.
Using InitializingBean, you have the benefit of being able to specify the initialization callback once for all instances of your bean class, but you have to couple your application to do so.
Using annotations, you need to apply the annotation to the method and make sure that the IoC container supports JSR-250
In the end, you should let the requirements of your application drive the decision about which approach to use.
If portability is an issue, then use the initialization or annotation method; otherwise, use the InitializingBean interface to reduce the amount of configuration your application needs and the chance of errors creeping into your application because of misconfiguration.
Order of Resolution You can use all mechanisms on the same bean instance.
This can be useful if you have an existing bean that performs some initialization in a specific method but you need to add some more initialization code when you use Spring.
Typically, you do this when your application shuts down, and it allows you to clean up any resources that your beans might be holding open, thus allowing your application to shut down gracefully.
This callback also provides the perfect place to flush any data you are storing in memory to persistent storage and to allow your beans to end any longrunning processes they may have started.
In many cases, you create and configure a resource in the initialization callback and then release the resource in the destruction callback.
Executing a Method When a Bean Is Destroyed To designate a method to be called when a bean is destroyed, you simply specify the name of the method in the destroy-method attribute of the bean’s <bean> tag.
Spring calls it just before it destroys the singleton instance of the bean (as stated before, Spring will not call this method for those beans with prototype scope)
This code also defines a destroy() method, in which the FileInputStream is closed and set to null, releasing the resource and allowing it to be garbage collected.
Both the initialization and destruction callbacks write a message to console output informing us that they have been called.
Notice that we have specified the destroy() method as the destruction callback using the destroymethod attribute.
As you can see, Spring first invokes the initialization callback, and the DestructiveBean instance creates the FileInputStream instance and stores it.
Next, during the call to destroy(), Spring iterates over the set of singletons it is managing, in this case just one, and invokes any destruction callbacks that are specified.
This is where the DestructiveBean instance closes the FileInputStream and sets the reference to null.
Implementing the DisposableBean Interface As with initialization callbacks, Spring provides an interface, in this case DisposableBean, that can be implemented by your beans as a mechanism for receiving destruction callbacks.
The DisposableBean interface defines a single method, destroy(), which is called just before the bean is destroyed.
Using this mechanism is orthogonal to using the InitializingBean interface to receive initialization callbacks.
Listing 5-8 shows a modified implementation of the DestructiveBean class that implements the DisposableBean interface.
Again, there is not much difference between the code (highlighted in bold) that uses the callback method mechanism and the code that uses the callback interface mechanism.
In this case, we even used the same method names.
As you can see, aside from the different class name; the only difference is the omission of the destroy-method attribute.
Again, the output from the two different mechanisms is exactly the same.
Running the program will give the same output as the other two mechanisms.
The destruction callback is an ideal mechanism for ensuring that your applications shut down.
However, you still have to decide whether to use the destruction method callback, the DisposableBean interface, or the @PreDestroy annotation.
Again, let the requirements of your application drive your decision in this respect; use the method callback where portability is an issue, and use the DisposableBean interface or a JSR-250 annotation to reduce the amount of configuration required.
Order of Resolution As with the case of bean creation, you can use all mechanisms on the same bean instance for bean destruction.
When your application runs as a servlet, you can simply call destroy() in the servlet’s destroy() method.
However, in a stand-alone application, things are not quite so simple, especially if you have multiple exit points out of your application.
Java allows you to create a shutdown hook, a thread that is executed just before the application shuts down.
The method automatically instructs Spring to register a shutdown hook of the underlying JVM runtime.
As you can see, the destroy() method is invoked, even though we didn’t write any code to invoke it explicitly as the application was shutting down.
Making Your Beans “Spring Aware” One of the biggest selling points of Dependency Injection over Dependency Lookup as a mechanism for achieving Inversion of Control is that your beans do not need to be aware of the implementation of the container that is managing them.
To a bean that uses constructor or setter injection, the Spring container is the same as the container provided by Google Guice or PicoContainer.
However, in certain circumstances, you may need a bean that is using Dependency Injection to obtain its dependencies so it can interact with the container for some other reason.
An example of this may be a bean that automatically configures a shutdown hook for you, and thus it needs access to the ApplicationContext.
That said, this feature is really intended for internal Spring use.
Giving the name some kind of business meaning is generally a bad idea and can lead to configuration problems where bean names have to be artificially manipulated to support their business meaning.
However, we have found that being able to have a bean find out its name at runtime is really useful for logging.
Consider a situation where you have many beans of the same type running under different configurations.
The bean name can be included in log messages to help you differentiate between which one is generating errors and which ones are working fine when something goes wrong.
Spring calls the setBeanName() method after it has finished configuring your bean but before any life-cycle callbacks (initialization or destroy) are called (refer to Figure 5-1)
In most cases, the implementation of the setBeanName() interface is just a single line that stores the value passed in by the container in a field for use later.
Listing 5-13 shows a simple bean that obtains its name using BeanNameAware and then later uses this bean name when writing log messages.
As you can see, no special configuration is required to take advantage of the BeanNameAware interface.
This example generates the following log output—notice the inclusion of the bean name in the log message for the call to someOperation():
Using the BeanNameAware interface is really quite simple, and it is put to good use when you are improving the quality of your log messages.
Avoid being tempted to give your bean names business meaning just because you can access them; by doing so, you are coupling your classes to Spring for a feature that brings negligible benefit.
If your beans need some kind of name internally, then have them implement an interface such as Nameable (which is specific to your application) with a method setName()
This way, you can keep the names you use for configuration concise, and you won’t need to manipulate your configuration unnecessarily to give your beans names with business meaning.
The main reason this interface was created was to allow a bean to access Spring’s ApplicationContext in your application, such as acquire other Spring beans programmatically, using getBean()
You should, however, avoid this practice and use Dependency Injection to provide your beans with their collaborators.
If you use the lookup-based getBean() approach to obtain dependencies when you can use Dependency Injection, you are adding unnecessary complexity to your beans and coupling them to the Spring Framework without good reason.
Of course, the ApplicationContext isn’t just used to look up beans; it performs a great many other tasks.
As you saw previously, one of these tasks is to destroy all singletons, notifying each of them in turn before doing so.
In the previous section, you saw how to create a shutdown hook to ensure that the ApplicationContext is instructed to destroy all singletons before the application shuts down.
Most of this code should seem familiar to you by now.
Listing 5-18 shows a simple example application that uses the ShutdownHookBean to manage the destruction of singleton beans.
As you can see, even though no calls to destroy() are in the main application, the ShutdownHookBean is registered as a shutdown hook, and it calls destroy() just before the application shuts down.
Use FactoryBeans One of the problems that you will face when using Spring is how to create and then inject dependencies that cannot be created simply by using the new operator.
To overcome this problem, Spring provides the FactoryBean interface that acts as an adaptor for objects that cannot be created and managed using the standard Spring semantics.
Typically, you use FactoryBeans to create beans that you cannot use the new operator to create such as those you access through static factory methods, although this is not always the case.
Simply put, a FactoryBean is a bean that acts as a factory for other beans.
FactoryBeans are used to great effect in Spring; the most noticeable uses are the creation of transactional proxies, which we cover in Chapter 13, and the automatic retrieval of resources from a JNDI context.
However, FactoryBeans are useful not just for building the internals of Spring; you’ll find them really useful when you build your own applications, because they allow you to manage many more resources using IoC than would otherwise be available.
In Java, the MessageDigest class provides functionality for creating a digest of any arbitrary data.
For instance, if we want to use the MD5 algorithm to create a digest, we use the following code to create the MessageDigest instance:
Using a FactoryBean, we can encapsulate this logic inside a bean.
Then any beans that require a MessageDigest instance can simply declare a property, messageDigest, and use the FactoryBean to obtain the instance.
Listing 5-19 shows an implementation of FactoryBean that does just this.
The FactoryBean interface declares three methods: getObject(), getObjectType(), and isSingleton()
Spring calls the getObject() method to retrieve the object created by the FactoryBean.
This is the actual object that is passed to other beans that use the FactoryBean as a collaborator.
The getObjectType() method allows you to tell Spring what type of object your FactoryBean will return.
This can be null if the return type is unknown in advance (for example, the FactoryBean creates different types of objects depending on the configuration, which will be determined only after the FactoryBean is initialized), but if you specify a type, Spring can use it for autowiring purposes.
We return MessageDigest as our type (in this case a class, but try to return an interface type and have the FactoryBean instantiate the concrete implementation class, unless necessary)
The reason is that we do not know what concrete type will be returned (not that it matters because all beans will define their dependencies using MessageDigest anyway)
The isSingleton() property allows you to inform Spring whether the FactoryBean is managing a singleton instance.
Remember that by setting the singleton attribute of the FactoryBean’s <bean> tag, you tell Spring about the singleton status of the FactoryBean itself, not the objects it is returning.
Now let’s see how the FactoryBean is employed in an application.
In Listing 5-20, you can see a simple bean that maintains two MessageDigest instances and then displays the digests of a message passed to its digest() method.
For the defaultDigest bean, since the algorithmName property was not specified, no injection will happen, and the default algorithm (i.e., MD5) that was coded in the class will be used.
In Listing 5-22, you see a basic example class that retrieves the MessageDigester bean from the BeanFactory and creates the digest of a simple message.
FactoryBeans are the perfect solution when you are working with classes that cannot be created using the new operator.
If you work with objects that are created using a factory method and you want to use these classes in a Spring application, then create a FactoryBean to act as an adaptor, allowing your classes to take full advantage of Spring’s IoC capabilities.
Accessing a FactoryBean Directly Given that Spring automatically satisfies any references to a FactoryBean by the objects produced by that FactoryBean, you may be wondering whether you can actually access the FactoryBean directly.
Accessing the FactoryBean is actually very simple: you simply prefix the bean name with an ampersand in the call to getBean(), as shown in Listing 5-23
This feature is used in a few places in the Spring code, but your application should really have no reason to use it.
The FactoryBean interface is intended to be used as a piece of supporting infrastructure to allow you to use more of your application’s classes in an IoC setting.
Avoid accessing the FactoryBean directly and then invoking its getObject() manually, and let Spring do it for you; if you do this manually, you are making extra work for yourself and are unnecessarily coupling your application to a specific implementation detail that could quite easily change in the future.
Using the factory-bean and factory-method Attributes Sometimes you need to instantiate JavaBeans that were provided by a non-Spring-powered third-party application.
You don’t know how to instantiate that class, but you know that the third-party application did provide a class that can be used to get an instance of the JavaBean that your Spring application required.
In this case, Spring bean’s factory-bean and factory-method attributes in the <bean> tag can be used.
Notice that two digest factory beans were defined, one using SHA1 and the other using the default algorithm.
Then for the beans shaDigest and defaultDigest, we instructed Spring to instantiate the beans by using the corresponding message digest factory bean (factory-bean), and we specified the method to use to obtain the bean instance (factory-method)
JavaBeans PropertyEditors For those of you not entirely familiar with JavaBeans concepts, a PropertyEditor is an interface that converts a property’s value to and from its native type representation into a String.
Originally, this was conceived as a way to allow property values to be entered, as String values, into an editor and have them transformed into the correct type.
However, because PropertyEditors are inherently lightweight classes, they have found uses in many different settings, including Spring.
Because a good portion of property values in a Spring-based application start life in the BeanFactory configuration file, they are essentially Strings.
However, the property that these values are set on may not be String-typed.
So, to save you from having to create a load of String-typed properties artificially, Spring allows you to define PropertyEditors to manage the conversion of String-based property values into the correct types.
In Listing 5-28, you can see a simple BeanFactory configuration specifying values for all of these properties (pe/builtin.xml)
As you can see, although all the properties on the PropertyEditorBean are not Strings, the values for the properties are specified as simple Strings.
As you can see, Spring has, using the built-in PropertyEditors, converted the String representations of the various properties to the correct types.
ClassEditor The ClassEditor converts from a fully qualified class name into a Class instance.
CustomDateEditor Convert a string representation of date into a java.util.Date value.
You need to register the CustomDateEditor in Spring’s ApplicationContext with the desired date format.
CustomNumberEditor Convert a string into the target number value, which can be Integer, Long, Float, and Double.
Spring does not check to see whether the file exists.
Pattern Converts a string into the JDK Pattern object or the other way round.
URLEditor The URLEditor converts a String representation of a URL into an instance of java.net.URL.
This set of PropertyEditors provides a good base for working with Spring and makes configuring your application with common components such as files and URLs much simpler.
Creating a Custom PropertyEditor Although the built-in PropertyEditors cover some of the standard cases of property type conversion, there may come a time when you need to create your own PropertyEditor to support a class or a set of classes you are using in your application.
Let’s take a simple example to see implementing custom property editor in action.
Suppose we have a Name class with just two properties, first name and last name.
To simplify the application configuration, let’s develop a custom editor that converts a string with a space separator into the Name class’s first name and last name, respectively.
In the method, we simply split the String into a string array with a space as the delimiter.
Afterwards, an instance of Name class is instantiated, passing in the String before the space character as the first name and passing the String after the space character as the last name.
Finally, the converted value is returned by calling the setValue() method with the result.
To use the NamePropertyEditor in our application, we need to register the editor in Spring’s ApplicationContext.
The second point is that each entry in the Map represents a single PropertyEditor with the key of the entry being the name of the class for which the PropertyEditor is used.
The final point of interest here is that we used an anonymous bean declaration as the value of the single Map entry.
No other bean needs to access this bean, so it needs no name, and as a result, you can declare it inside the <entry> tag.
Run the example, and you will see the following output:
This is the output from the toString() method we implemented in the Name class, and you can see that the first name and last name of the Name object were correctly populated by Spring by using the configured NamePropertyEditor.
Starting from version 3, Spring introduced the Type Conversion and Field Formatting SPI, which provide a simpler and well-structured API in performing type conversion and field formatting.
In Spring, various implementations of the BeanFactory interface are responsible for bean instantiation, providing Dependency Injection and life-cycle support for beans managed by Spring.
However, as stated, being an extension of the BeanFactory, ApplicationContext provides other useful functionalities as well.
The main function of the ApplicationContext is to provide a much richer framework on which to build your applications.
The biggest benefit of using ApplicationContext is that it allows you to configure and manage Spring and Spring-managed resources in a completely declarative way.
This means that wherever possible, Spring provides support classes to load an ApplicationContext into your application auto-matically, thus removing the need for you to write any code to access the ApplicationContext.
In practice, this feature is currently available only when you are building web applications with Spring, which allows you to initialize Spring’s ApplicationContext in the web application deployment descriptor.
When using a stand-alone application, you can also initialize Spring’s ApplicationContext by simple coding.
In addition to providing a model that is focused more on declarative configuration, the ApplicationContext supports the following additional features:
In the following sections, we will discuss some of the most important features in ApplicationContext besides DI.
Although you don’t need to use ApplicationContext to use MessageSource, the ApplicationContext interface actually extends MessageSource and provides special support for loading messages and for making them available in your environment.
The automatic loading of messages is available in any environment, but automatic access is provided only in certain Spring-managed scenarios, such as when you are using Spring’s MVC framework to build a web application.
This is key to the way ApplicationContext works with MessageSources.
ApplicationContext takes this MessageSource and nests it within itself, allowing you to access the messages using the ApplicationContext.
This can be hard to visualize, so take a look at the following example.
Listing 5-33 shows a simple application that accesses a set of messages for both the English and Czech locales.
Don’t worry about the calls to getMessage() just yet; we return to those shortly.
For now, just know that they retrieve a keyed message for the locale specified.
When looking for a message for a particular Locale, the ResourceBundle looks for a file that is named as a combination of the base name and the locale name.
Running the MessageSourceDemo class in Listing 5-33 yields the following output:
Note The translation of the Czech is “Terribly yellow horse was groaning devilish odes.”
The getMessage() Method The MessageSource interface defines three overloads for the getMessage() method.
This overload works in the same way as getMessage(String, Object[], Locale), other than the second String argument, which allows you to pass in a default value in case a message for the supplied key is not available for the supplied Locale.
Why Use ApplicationContext As a MessageSource? To answer this question, we need to jump a little ahead of ourselves and look at the web application support in Spring.
The answer, in general, to this question is that you shouldn’t use the ApplicationContext as a MessageSource when doing so couples your bean to the ApplicationContext unnecessarily (this is discussed in more detail in the next section)
You should use the ApplicationContext when you are building a web application using Spring’s MVC framework.
Unlike frameworks like Struts that require you to implement your controllers by inheriting from a concrete class, Spring simply requires that you implement the Controller interface (or annotate your controller class with the @Controller annotation)
Having said that, Spring provides a collection of useful base classes that you will use to implement your own controllers.
Remember that in a web application setting, the ApplicationContext is loaded automatically.
This form of “auto injection” is quite beneficial; it removes the need for all of your controllers to expose a MessageSource property.
However, this is not the best reason for using ApplicationContext as a MessageSource in your web application.
All of these benefits mean that it is better to use the MessageSource support in ApplicationContext when you are building a web application, rather than manage an instance of MessageSource separately.
This is especially true when you consider that all you need to do to take advantage of this feature is configure a MessageSource bean with the name messageSource.
Add to this the fact that you complicate testing without any discernible benefit, and it is clear that you should stick to using Dependency Injection to access MessageSource objects in a stand-alone setting.
This interface is most widely used in the Spring validation libraries to link Error objects to their internationalized error messages.
Application Events Another feature of the ApplicationContext not present in the BeanFactory is the ability to publish and receive events using the ApplicationContext as a broker.
In this section we will take a look at its usage.
In a web application, this is simple because many of your classes are derived from Spring Framework classes that allow access to the ApplicationContext through a protected method.
Listing 5-37 shows an example of a basic event class.
This code is quite basic; the only point of note is that the ApplicationEvent has a single constructor that accepts a reference to the source of the event.
In Listing 5-38 you can see the code for the listener.
If a MessageEvent was received, it writes the message to stdout.
Here you can see that the Publisher class retrieves an instance of itself from the ApplicationContext and then, using the publish() method, publishes two MessageEvents to the ApplicationContext.
Received: Hello World! Received: The quick brown fox jumped over the lazy dog.
Considerations for Event Usage There are many cases in an application where certain components need to be notified of certain events.
Often you do this by writing code to notify each component explicitly or by using a messaging technology such as JMS.
The drawback of writing code to notify each component in turn is that you are coupling those components to the publisher, in many cases unnecessarily.
Consider a situation where you cache product details in your application to avoid trips to the database.
Another component allows product details to be modified and persisted to the database.
To avoid making the cache invalid, the update component explicitly notifies the cache that the user details have changed.
In this example, the update component is coupled to a component that, really, has nothing to do with its business responsibility.
A better solution would be to have the update component publish an event every time a product’s details are modified and then have interested components, such as the cache, listen for that event.
This has the benefit of keeping the components decoupled, which makes it simple to remove the cache if you need or to add another listener that is interested in knowing when a product’s details change.
Using JMS in this case would be overkill, because the process of invalidating the product’s entry in the cache is quick and is not business critical.
The use of the Spring event infrastructure adds very little overhead to your application.
Typically, we use events for reactionary logic that executes quickly and is not part of the main application logic.
In the previous example, the invalidation of a product in cache happens in reaction to the updating of product details, it executes quickly (or it should), and it is not part of the main function of the application.
For processes that are long running and form part of the main business logic, it is recommended to use JMS or similar messaging systems such as RabbitMQ.
The main benefits of using JMS is that it is more suited to long-running processes, and as the system grows, you can, if necessary, factor the JMS-driven processing of messages containing business information onto a separate machine.
Accessing Resources Often an application needs to access a variety of resources in different forms.
You might need to access some configuration data stored in a file in the file system, some image data stored in a JAR file on the classpath, or maybe some data on a server elsewhere.
This means your application can access a file resource in the same way, whether it is stored in the file system, in the classpath, or on a remote server.
The Resource interface defines ten self-explanatory methods: contentLength(), exists(), getDescription(), getFile(), getFileName(), getURI(), getURL(), isOpen(), isReadable(), and lastModified()
In addition to these ten methods, there is one that is not quite so self-explanatory: createRelative()
The createRelative() method creates a new Resource instance using a path that is relative to the instance on which it is invoked.
You can provide your own Resource implementations, although that is outside the scope of this chapter, but in most cases, you use one of the built-in implementations for accessing file (the FileSystemResource class), classpath (the ClassPathResource class), or URL resources (the UrlResource class)
Listing 5-41 shows a sample application that accesses three resources using ApplicationContext.
You should note that the configuration file used in this example is unimportant.
Notice that in each call to getResource() we pass in a URI for each resource.
The classpath: protocol we use for res2 is Springspecific and indicates that the ResourceLoader should look in the classpath for the resource.
Notice that for both the file: and http: protocols, Spring returns a UrlResource instance.
It’s because Spring’s default resource-loading strategy treats the URL and file as the same type of resource with difference protocols (i.e., file: and http:)
Once a Resource instance is obtained, you are free to access the contents as.
For this reason, we recommend that you use getInputStream() to access resource contents because it is likely to function for all possible resource types.
Spring JavaConfig used to be a separate project, but starting with Spring 3.0, its major features for configuration using Java classes was merged into the core Spring Framework.
In this section, we will take a look at how to use Java classes to configure a Spring’s ApplicationContext and its equivalent when using XML configuration.
Listing 5-42 recaps the message provider interface and a configurable message provider.
When using a Java class instead of XML to configure the previous message provider and renderer, we just need to implement a normal JavaBean as usual, with the appropriate annotations for Spring’s Java configuration.
In the previous AppConfig class, you can see that we first use the @Configuration annotation to inform Spring that this is a Java-based configuration file.
Afterward, the @Bean annotation was used to declare a Spring bean and the DI requirements.
To help you understand the XML equivalent of the Java annotation and code, we added comments to the corresponding method.
Listing 5-47 shows how to initialize the ApplicationContext from Java configuration file.
Note that Spring requires CGLIB to support Java configuration classes.
Add the dependency in Table 5-3 to the project in STS.
Having seen the basic usage of Java configuration class, let’s proceed to more configuration options and their XML equivalents.
Let’s see the revised testing program, which loads the properties files by using the @PropertySource annotation and then injects them into the message provider implementation.
In Listing 5-48, we also added a lot of various annotations that Spring supports for a base Java configuration and their XML equivalents.
In the listing, you can see a lot of common annotations for configuration in Java classes; we also provided their XML tag equivalents for your easy reference.
Mixing XML and Java configuration will make your application harder to maintain, because you need to scan through both XML files and Java classes to search for a specific bean.
The @ComponentScan defines the packages that Spring should scan for annotations for bean definitions.
Application infrastructure services can also be defined in Java classes.
You may also notice the @Autowired property of the env variable, which is of the Environment type.
This is the Environment abstraction feature that Spring 3.1 provides.
Java or XML Configuration? As you already saw, using Java classes can achieve the same level of ApplicationContext configuration as XML.
So, which one should you use? The consideration is quite like the one of whether we should use XML or Java annotations for DI configuration.
However, the recommendation is the same; that is, when you and your team decide on the approach to use, stick to it and keep the configuration style persistent, instead of scattered around between Java class and XML files.
Profiles Another interesting feature that Spring 3.1 brings to us as developers is the concept of configuration profiles.
Basically, a profile instructs Spring to configure only the ApplicationContext that was defined when the specified profile was active.
In this section we’ll demonstrate the usage of profiles in a simple program.
A lunch set is a list of Food objects, which is very simple class that has only a name attribute.
Now suppose that there are two different providers for the lunch set, one for kindergarten and one for high school.
The lunch set produced by them is different, although the service they provide is the same, that is, to provide lunch to school students.
So, now suppose a kindergarten wants the provider to deliver the lunch set for their students; let’s see how we can use Spring’s profile configuration to achieve this.
We will create two different XML configuration files, one for the kindergarten profile and the other for the high-school profile.
It actually tells Spring that those beans in the file should be instantiated only when the specified profile is active.
Now let’s see how to activate the correct profile when using Spring’s ApplicationContext in a stand-alone application.
Note that multiple profiles can be activated for the same context (i.e., you can pass multiple profile names into the setActiveProfile() method via its varargs support)
This is exactly what the implementation of the kindergarten provider will produce for the lunch set.
Now change the profile string in the previous listing to "highschool", and the output will change to the following:
Another interesting thing is that instead of programmatically activating a profile, you can also specify it by passing in the following JVM argument:
Figure 5-2 shows how to configure the JVM argument in STS.
By passing this argument in, we can take away the line that sets the active profile and runs the program.
You can change the JVM argument to "highschool" and run the program again.
In Chapter 21, we will discuss how to use and activate profiles in web applications.
You can also use profiles when using a Java configuration instead of XML.
You can see the two classes just mimic the two XML files that we presented earlier, with the @Profile annotation specifying the corresponding application profile to which it belongs.
Let’s implement another testing program to see the Java profile configuration in action.
Run the program, and you will see the lunch set for kindergarten.
The sample source code is included with the book’s source code.
Considerations for Using Profiles The profiles feature in Spring 3.1 creates another way for developers to manage the application’s running configuration, which used to be done in build tools (e.g., Maven’s profile support)
Spring’s profile feature lets us as application developers define the profiles by ourselves and activate them either programmatically or by passing in the JVM argument.
By using Spring’s profile support, you can now use the same application archive and deploy to all different environments, by passing in the correct profiles as an argument during JVM startup.
For example, you can have applications with different profiles such as (dev, hibernate), (prd, jdbc), and so on, with each different combination representing the running environment (development or production) and the data access library to use (Hibernate or JDBC)
For example, some may argue that putting all the configuration for different environments into application configuration files or Java classes and bundling them together will be error prone if not handled carefully (e.g., the administrator forgot to set the correct JVM argument in their application server environment)
Packing files for all profiles together will also make the package a bit larger than usual.
Again, let the application and configuration requirements drive you to select the approach that best fits your project.
Environment and PropertySource Abstraction From the previous section, you already saw the usage of Spring’s profile feature.
To set the active profile, we need to access the Environment interface.
The Environment interface is a new abstraction layer introduced in Spring 3.1; it serves to encapsulate the environment of the running Spring application.
Besides the profile, other key pieces of information encapsulated by the Environment interface are properties.
Properties are used to store the application’s underlying environment configuration, such as the location of the application folder, database connection information, and so on.
The Environment and PropertySource abstraction features in Spring 3.1 assist us as developers in accessing various configuration information from the running platform.
Under the abstraction, all system properties, environment variables, and application properties are served by the Environment interface, which Spring populates when bootstrapping the ApplicationContext.
Let’s run the program, and the following will be printed:
For the first two lines, the JVM system property user.home and the environment variable JAVA_HOME was retrieved as we did before (by using the JVM’s System class)
However, for the last three lines, you can see that all the system properties, environment variables, and application properties can all be accessed via the Environment interface.
You can see how the Environment abstraction can help us manage and access all the various properties within the application’s running environment.
For the PropertySource abstraction, Spring will access the properties in the following default order:
If you run the program, you will still see that the user.home was still retrieved from the JVM properties, not yours.
However, Spring allows you to control the order of how the Environment should retrieve the properties.
Let’s revise Listing 5-59 a bit and see how it works.
Listing 5-60 shows the revised version (the differences are highlighted in bold)
When you run the program, you will see the following output:
The first two lines remain the same because we still use the getProperty() and getenv() methods of the JVM System class to retrieve them.
However, when using the Environment interface, you will see that the user.home property we defined takes precedence, since we defined it as the first one to search for property values.
Suppose we had a class to store all the application properties loaded from a property file.
Note that the property file also declared the user.home property.
Let’s take a look at the Spring XML configuration (see Listing 5-63, the env/env.xml file)
We also use the placeholders to inject the values into the AppProperty bean.
Let’s run the program, and you will see the following output:
You will see the application.home placeholder was properly resolved, while the user.home property was still retrieved from the JVM properties, which is correct because it’s the default behavior.
The local-override attribute instructs Spring to override the existing properties with the properties defined in this placeholder.
From the previous two sections, you can see that profiles and property source abstraction by the Environment interface in Spring 3.1 give us a powerful and centralized way to manage the configurations of the application environment.
Again, let’s take the message renderer and message provider as an example and implement it using JSR-330 annotations.
The interface classes (MessageRenderer and MessageProvider) are the same, so we’ll save some space and not list them.
You will notice that all annotations belong to the javax.inject package, which is the JSR-330 standard.
Second, we use constructor injection by using the @Inject annotation before the constructor that accepts a string value.
Then, we use @Named to specify that we want to inject the value that had the name message assigned.
It’s worth noting that in the JSR-330 standard, a bean’s default scope is nonsingleton, which is like Spring’s prototype scope.
However, using this annotation in Spring actually doesn’t have any effect, because Spring’s default scope for bean instantiation is already singleton.
We just put it here for demonstration, and it’s worth noting the difference between Spring and other JSR-330 compatible containers.
For the messageProvider property, we use @Inject for setter injection this time and specify that a bean with the name messageProvider should be used for injection.
You don’t need any special tags to use JSR-330; just configure your application like a normal Spring application.
However, Spring’s annotations are much more feature rich and flexible than JSR-330 annotations.
Moreover, Spring provides the @Qualifier annotation, which allows more fine-grained control for Spring to perform autowiring of dependencies based on qualifier name.
JSR-330 supports only singleton and nonsingleton bean scopes, while Spring supports more scopes, which is very useful for web applications.
In Spring, you can use the @Lazy annotation to instruct Spring to instantiate the bean only when requested by the application.
You can also mix and match Spring and JSR-330 annotations in the same application.
However, it is recommended that you settle on either one to maintain a consistent style for your application.
One possible way is to use JSR-330 annotations as much as possible and use Spring annotations when required.
However, this brings you fewer benefits because you still need to do quite a bit of work in migrating to another DI container.
In conclusion, Spring’s annotations approach is recommended over JSR-330 annotations given the fact that Spring’s annotations are much more powerful, unless there is a requirement that your application should be IoC container independent.
Summary In this chapter, you saw a wide range of Spring-specific features that complement the core IoC capabilities.
You saw how to hook into the life cycle of a bean and to make it aware of the Spring environment.
We introduced FactoryBeans as a solution for IoC-enabling a wider set of classes.
We also looked at how you can use PropertyEditors to simplify application configuration and to remove the need for artificial String-typed properties.
Moreover, we finished with an in-depth look at some additional features offered by the ApplicationContext including i18n, event publication, and resource access.
So far, we have covered the main concepts of the Spring Framework and its features as a DI container as well as other services that the core Spring Framework provides.
In the next chapter and onward, we will discuss using Spring in different specific areas such as AOP, data access, transaction support, web application support, and so on.
Besides Dependency Injection (DI), another core feature that the Spring Framework brings to the developer community is Aspect-Oriented Programming (AOP)
Although it used to be difficult to learn, understand, and implement, thanks to Spring’s intensive use of AOP within the framework and a simplified AOP programming model that Spring provides, AOP has become a technique that developers use on day-to-day development, especially when developing Spring-based applications.
When you “cut through” the unfamiliar terminology, you use AOP for modularizing individual pieces of logic, known as concerns, and you apply these concerns to many parts of an application.
Logging and security are typical examples of crosscutting concerns that are present in many applications.
Consider an application that logs the start and end of every method for debugging purposes.
You will probably refactor the logging code into a special class, but you still have to call methods on that class twice per method in your application in order to perform the logging.
Using AOP, you can simply specify that you want the methods on your logging class to be invoked before and after each method call in your application.
It is important that you understand that AOP complements OOP, rather than competes with it.
However, if you look at the logging example again, it is quite plain to see that OOP is lacking when it comes to implementing crosscutting logic on a large scale.
Using AOP on its own to develop an entire application is practically impossible, given that AOP functions on top of OOP.
Likewise, although it is certainly possible to develop entire applications using OOP, you can work smarter by employing AOP to solve certain problems that involve crosscutting logic.
We are going to cover AOP in this chapter and the next.
Most of the concepts covered in this section are not specific to Spring and can be found in any AOP implementation.
If you are already familiar with another AOP implementation, then feel free to skip this section.
Types of AOP: There are two distinct types of AOP: static and dynamic.
In static AOP, like that provided by AspectJ’s (http://eclipse.org/aspectj/) compile-time weaving mechanisms, the crosscutting logic is applied to your code at compile time, and you cannot change it without modifying the code and recompiling.
With dynamic AOP, like Spring AOP, crosscutting logic is applied dynamically, at runtime.
This allows you to make changes in the distribution of crosscutting without recompiling the application.
These types of AOP are complementary, and, when used together, they form a powerful combination that you can use in your applications.
Note Static and dynamic AOP are distinct from the static and dynamic crosscutting concepts.
The differentiation between static and dynamic crosscutting is largely academic and is of no relevance to Spring AOP.
For more information on this topic and on AOP as a whole, we recommend you read AspectJ in Action: Enterprise.
Spring AOP architecture: In this section, we get down to the nitty-gritty of Spring’s AOP implementation.
Spring AOP is only a subset of the full AOP feature set found in other implementations like AspectJ.
In this section, we take a high-level look at which features are present in Spring, how they are implemented, and why some features are excluded from the Spring implementation.
Proxies in Spring AOP: Proxies are a huge part of how Spring AOP works, and you must understand them to get the most out of Spring AOP.
In this section, we look at the two kinds of proxy: the JDK dynamic proxy and the CGLIB proxy.
In particular, we look at the different scenarios in which Spring uses each proxy, the performance of the two proxy types, and some simple guidelines to follow in your application to get the most from Spring AOP.
Using Spring AOP: In this section, we present some practical examples of AOP usage.
We start off with a simple “Hello World” example to ease you into Spring’s AOP code, and we continue with a detailed description of the different AOP features that are available in Spring, complete with examples.
In this chapter, we cover Spring AOP in isolation from much of the rest of the framework.
It is important that you understand what these terms mean before we explain how to use AOP in an application.
Joinpoints: A joinpoint is a well-defined point during the execution of your application.
Typical examples of joinpoints include a call to a method, the Method Invocation itself, class initialization, and object instantiation.
Joinpoints are a core concept of AOP and define the points in your application at which you can insert additional logic using AOP.
Advice: The code that is executed at a particular joinpoint is the advice.
There are many different types of advice, such as before, which executes before the joinpoint, and after, which executes after it.
In OOP, an advice comes in the form of a method within a class.
Pointcuts: A pointcut is a collection of joinpoints that you use to define when advice should be executed.
By creating pointcuts, you gain fine-grained control over how you apply advice to the components in your application.
As mentioned previously, a typical joinpoint is a Method Invocation.
A typical pointcut is the collection of all Method Invocations in a particular class.
We discuss pointcut composition in more detail in the next chapter.
Aspects: An aspect is the combination of advice and pointcuts.
This combination results in a definition of the logic that should be included in the application and where it should execute.
Weaving: This is the process of actually inserting aspects into the application code at the appropriate point.
For compile-time AOP solutions, this is, unsurprisingly, done at compile time, usually as an extra step in the build process.
Likewise, for runtime AOP solutions, the weaving process is executed dynamically at runtime.
AspectJ supports another weaving mechanism called load-time weaving (LTW), in which it intercepts the underlying JVM class loader and provides weaving to the bytecode when it is being loaded by the class loader.
Target: An object whose execution flow is modified by some AOP process is referred to as the target object.
Often you see the target object referred to as the advised object.
Introduction: This is the process by which you can modify the structure of an object by introducing additional methods or fields to it.
You can use introduction to make any object implement a specific interface without needing the object’s class to implement that interface explicitly.
Don’t worry if you find these concepts confusing; this will all become clear when you see some examples.
Also, be aware that you are shielded from many of these concepts in Spring AOP, and some are not relevant because of Spring’s choice of implementation.
We will discuss each of these features in the context of Spring as we progress through the chapter.
Types of AOP As we mentioned earlier, there are two distinct types of AOP: static and dynamic.
The difference between them is really the point at which the weaving process occurs and how this process is achieved.
Static AOP Many of the first AOP implementations were static.
In static AOP, the weaving process forms another step in the build process for an application.
In Java terms, you achieve the weaving process in a static AOP implementation by modifying the actual bytecode of your application, changing and extending the application code as necessary.
Clearly, this is a well-performing way of achieving the weaving process because the end result is just Java bytecode, and you do not perform any special tricks at runtime to determine when advice should be executed.
The drawback of this mechanism is that any modifications you make to the aspects, even if you simply want to add another joinpoint, require you to recompile the entire application.
AspectJ’s compile-time weaving is an excellent example of a static AOP implementation.
Dynamic AOP Dynamic AOP implementations, like Spring AOP, differ from static AOP implementations in that the weaving process is performed dynamically at runtime.
The slight drawback of dynamic AOP is that, typically, it does not perform as well as static AOP, but the performance is steadily increasing.
The major benefit of dynamic AOP implementations is the ease with which you can modify the entire aspect set of an application without needing to recompile the main application code.
Choosing an AOP Type Choosing whether to use static or dynamic AOP is actually quite a hard decision.
There is no reason for you to choose a single implementation exclusively, because both have their benefits.
As a matter of fact, starting from version 2.0, Spring already provided a tight integration with AspectJ, allowing you to use both types of AOP with ease.
In general, the static AOP implementations have been around longer, and they tend to have more feature-rich implementations, with a greater number of available joinpoints.
Indeed, Spring supports only a subset of the features available with AspectJ.
Typically, if performance is absolutely critical or you need an AOP feature that is not implemented in Spring, then you will want to use AspectJ.
In most other cases, Spring AOP is ideal for what you are trying to achieve.
Make sure you are aware that many AOP-based features are already available in Spring, such as declarative transaction management.
Reimplementing these using AspectJ is a waste of time and effort, especially since Spring has tried-and-tested implementations ready for you to use.
Most importantly, let the requirements of your application drive your choice of AOP implementation, and don’t restrict yourself to a single implementation if a combination of implementations would better suit your application.
In general, we have found that Spring AOP is less complex than AspectJ, so it tends to be our first choice.
If we find that Spring AOP won’t do what we want it to do or we discover during application tuning that performance is poor (for example, when profiling the application using a Java profiler, the profiling result indicates that much time was spent in Spring in generating the dynamic proxy for the defined aspects), then we move to AspectJ instead.
The first part is the AOP core, which provides fully decoupled, purely programmatic AOP functionality (Spring called it the Spring AOP API)
The second part of the AOP implementation is the set of framework services that make AOP easier to use in your applications.
On top of this, other components of Spring, such as the transaction manager and EJB helper classes, provide AOP-based services to simplify the development of your application.
In this chapter, we focus solely on the basics of the AOP core.
Spring AOP is really a subset of the full AOP feature set, implementing only a handful of the constructs available in implementations like AspectJ.
Don’t be fooled into thinking Spring AOP is not useful, however.
Indeed, one of the most powerful aspects of Spring AOP is that it is so simple to use because it is unencumbered with extraneous features that you often do not need.
The implementation of only a subset of the AOP feature set is a specific design goal of Spring, allowing Spring to focus on simple access to the most common features of AOP.
To make sure you are not left without the AOP features you need, Spring’s designers designed Spring to fully integrate with AspectJ.
The AOP Alliance The AOP Alliance (http://aopalliance.sourceforge.net/) is a joint effort between representatives of many open source AOP projects, including Rod Johnson of Spring, to define a standard set of interfaces for AOP implementations.
The AOP Alliance is being very conservative, resisting the temptation to overconstrain AOP while it is still growing, and as a result, it has defined interfaces for only a subset of AOP features.
Wherever applicable, Spring uses the AOP Alliance interfaces rather than defining its own.
In this example, we take a simple class that outputs the message “World,” and then using AOP, we transform an instance of this class at runtime to output “Hello World!” instead.
The MessageWriter class is nothing special; it has just one method that writes the message “World” to console output.
We want to advise—that is, add some advice to—this class so that the writeMessage() method actually writes “Hello World!” instead.
To do this, we need to execute some code before the method body executes to write “Hello,” and we need to execute some code after the method body executes to write “!” to this.
In AOP terms, what we need is an around advice—that is, advice that executes around a joinpoint.
In this case, the joinpoint is the invocation of the writeMessage() method.
Listing 6-2 shows the implementation of the around advice, the MessageDecorator class.
The MethodInterceptor interface is the AOP Alliance standard interface for implementing around advice for Method Invocation joinpoints.
The MethodInvocation object represents the Method Invocation that is being advised, and using this object, we control when the Method Invocation is actually allowed to proceed.
Because this is around advice, we are essentially capable of performing some actions before the method is invoked and some actions after it is invoked but before it returns.
The final step in this sample is to weave the MessageDecorator advice (more specifically, the invoke() method) into the code.
To do this, we create an instance of MessageWriter, the target, and then create a proxy of this instance, instructing the proxy factory to weave in the MessageDecorator advice.
The important part here is that we use the ProxyFactory class to create the proxy of the target object, weaving in the advice at the same time.
We pass the MessageDecorator advice to the ProxyFactory with a call to addAdvice() and specify the target for weaving with a call to setTarget()
Once the target is set and some advice is added to the ProxyFactory, we generate the proxy with a call to getProxy()
Finally, we call writeMessage() on both the original target object and the proxy object.
Before we run the program, we need to add the dependency on CGLIB into the project, as shown in Table 6-1
After the dependency is added, we can now run the program in Listing 6-3
As you can see, calling writeMessage() on the untouched target object resulted in a standard Method Invocation, and no extra content is written to console output.
However, the invocation of the proxy caused the code in the MessageDecorator to execute, creating the desired output of “Hello World!” From this example, you can see that the advised class had no dependencies on Spring or the AOP Alliance interfaces; the beauty of Spring AOP, and indeed AOP in general, is that you can advise almost any class, even if that class was created without AOP in mind.
The only restriction, in Spring AOP at least, is that you can’t advise final classes, because they cannot be overridden and therefore cannot be proxied.
When you want to create an advised instance of a class, you must use the ProxyFactory class to create a proxy of an instance of that class, first providing the ProxyFactory with all the aspects that you want to be woven into the proxy.
Using ProxyFactory is a purely programmatic approach to creating AOP proxies.
For the most part, you don’t need to use this in your application; instead, you can rely on the declarative AOP configuration mechanisms provided by Spring (the ProxyFactoryBean class, the aop namespace, and @AspectJ-style annotations) to provide declarative proxy creation.
However, it is important to understand how proxy creation works.
For the rest of this chapter, we will use the programmatic approach to proxy creation.
In the next chapter, we discuss using Spring’s declarative AOP configurations.
At runtime, Spring will analyze the cross-cutting concerns defined for the beans in the ApplicationContext and generate proxy beans (which wraps the underlying target bean) dynamically.
Instead of calling the target bean directly, callers are injected with the proxied bean, and any calls to the target are received by the proxy bean.
Figure 6-1 shows a high-level view of a Spring AOP proxy in action.
Internally, Spring has two proxy implementations: the JDK dynamic proxy and the CGLIB proxy.
By default, when the target object to be advised implements some sort of an interface, Spring will use a JDK dynamic proxy to create proxy instances of the target.
However, when the advised target object doesn’t implement an interface (e.g., it’s a concrete class), CGLIB will be used for proxy instance creation.
We will discuss proxies in detail in the section “Understanding Proxies.”
Joinpoints in Spring One of the more noticeable simplifications in Spring AOP is that it supports only one joinpoint type: Method Invocation.
At first glance, this might seem like a severe limitation if you are familiar with other AOP implementations like AspectJ, which supports many more joinpoints, but in fact this actually makes Spring more accessible.
The Method Invocation joinpoint is by far the most useful joinpoint available, and using it, you can achieve many of the tasks that make AOP useful in day-to-day programming.
Remember that if you need to advise some code at a joinpoint other than a Method Invocation, you can always use Spring and AspectJ together.
Aspects in Spring In Spring AOP, an aspect is represented by an instance of a class that implements the Advisor interface.
Spring provides a selection of convenience Advisor implementations that you can use in your applications, thus removing the need for you to create lots of different Advisor implementations for your example.
The PointcutAdvisor interface is implemented by all Advisors that use pointcuts to control the applicability of advice to joinpoints.
In Spring, introductions are treated as special kinds of advice.
We cover this in more detail in the next chapter.
We discuss the different PointcutAdvisor implementations in detail later in this chapter in the section “Advisors and Pointcuts in Spring.”
Before you can actually create a proxy, you must specify the advised or target object.
You can do this, as you saw earlier, using the setTarget() method.
We discuss proxy creation in more detail later in this chapter.
Using the ProxyFactory class, you control which aspects you want to weave into the proxy.
As mentioned earlier, you can weave only an aspect—that is, advice combined with a pointcut—into advised code.
However, in some cases you want an advice to apply to the invocation of all methods in a class, not just a selection.
For this reason, the ProxyFactory class provides the addAdvice() method that you saw in Listing 6-3
When you want more control over the Advisor that is created, or when you want to add an introduction to the proxy, create the Advisor yourself and use the addAdvisor() method of the ProxyFactory()
You can use the same ProxyFactory instance to create many different proxies, each with different aspects.
To help with this, ProxyFactory has removeAdvice() and removeAdvisor() methods, which allow you to remove any advice or Advisors from the ProxyFactory that you previously passed to it.
To check whether a ProxyFactory has a particular advice attached to it, call adviceIncluded(), passing in the advice object for which you want to check.
Creating Advice in Spring Spring supports six different flavors of advice, described in Table 6-2
Using before advice, you can perform custom processing before a joinpoint executes.
Because a joinpoint in Spring is always a Method Invocation, this essentially allows you to perform preprocessing before the method executes.
A before advice has full access to the target of the Method Invocation as well as the arguments passed to the method, but it has no control over the execution of the method itself.
In case a before advice throws an exception, further execution of the interceptor chain (as well as the target method) will be aborted, and the exception will propagate back up the interceptor chain.
After-returning advice is executed after the Method Invocation at the joinpoint has finished executing and has returned a value.
The after-returning advice has access to the target of the Method Invocation, the arguments passed to the method, and the return value as well.
Because the method has already executed when the after-returning advice is invoked, it has no control over the Method Invocation at all.
In case the target method throws an exception, the after-returning advice will not be run, and the exception will be propagated up to the call stack as usual.
After-returning advice is executed only when the advised method completes normally.
However, the after (finally) advice will be executed no matter the result of the advised method.
The advice is executed even when the advised method fails and an exception is thrown.
In Spring, around advice is modeled using the AOP Alliance standard of a method interceptor.
Your advice is allowed to execute before and after the Method Invocation, and you can control the point at which the Method Invocation is allowed to proceed.
You can choose to bypass the method altogether if you want, providing your own implementation of the logic.
Throws advice is executed after a Method Invocation returns, but only if that invocation threw an exception.
It is possible for a throws advice to catch only specific exceptions, and if you choose to do so, you can access the method that threw the exception, the arguments passed into the invocation, and the target of the invocation.
Using an introduction interceptor, you can specify the implementation for methods that are being introduced by the advice.
Introductions are covered in more detail in the next chapter.
We have found that these advice types, coupled with the Method Invocation joinpoint, allow us to perform about 90 percent of the tasks we want to perform with AOP.
For the other 10 percent, which we use only rarely, we fall back on AspectJ.
Interfaces for Advice From our previous discussion of the ProxyFactory class, recall that advice is added to a proxy either directly, using the addAdvice() method, or indirectly by using an Advisor, with the addAdvisor() method.
The main difference between Advice and Advisor is that an Advisor carries an Advice with the associated Pointcut, which provides more fine-grained control on which joinpoints the Advice will intercept.
With regard to advice, Spring created a well-defined hierarchy for advice interfaces.
This hierarchy is based on the AOP Alliance interfaces and is shown in detail in Figure 6-2
This kind of hierarchy has the benefit of not only being sound OO design but also that you can deal with advice types generically, such as by using a single addAdvice() method on the ProxyFactory, and you can add new advice types easily without having to modify the ProxyFactory class.
Create Before Advice Before advice is one of the most useful advice types available in Spring.
A before advice can modify the arguments passed to a method and can prevent the method from executing by raising an exception.
In the next chapter, you will see before advice used frequently when we look at how AOP is used in the SpringBlog application.
In this section, we show you two examples of using before advice: a simple example that writes a message to console output containing the name of the method before the method executes and a simple security advice that you can use to restrict access to methods on an object.
In Listing 6-4, you can see the code for the SimpleBeforeAdvice class.
In this code, you can see that we have advised an instance of the MessageWriter class that we created earlier with an instance of the SimpleBeforeAdvice class.
Remember that, for now, we are using the default pointcut provided by the addAdvice() method, which matches all methods in a class.
The before() method is passed three arguments: the method that is to be invoked, the arguments that will be passed to that method, and the Object that is the target of the invocation.
The SimpleBeforeAdvice class uses the Method argument of the before() method to write a message to console output containing the name of the method to be invoked.
As you can see, the output from the call to writeMessage() is shown, but just before it, you can see the output generated by the SimpleBeforeAdvice.
Securing Method Access Using Before Advice The previous example was fairly trivial and didn’t really show the power of AOP.
In this section, we are going to build a before advice that checks user credentials before allowing the Method Invocation to proceed.
If the user credentials are invalid, an exception is thrown by the advice, thus preventing the method from executing.
It allows users to authenticate with any password, and it also allows only a single, hard-coded user access to the secured methods.
However, it does illustrate how easy it is to use AOP to implement a crosscutting concern such as security.
Note This is just an example of demonstrating the usage of before advice.
For securing the method execution of Spring beans, the Spring Security project already provides comprehensive support; you don’t need to implement.
This is the class that we will be securing using AOP.
The SecureBean class imparts a small pearl of wisdom from Homer Simpson, wisdom that we don’t want everyone to see.
Because this example requires users to authenticate, we are somehow going to need to store their details.
Listing 6-6 shows the UserInfo class we use to store a user’s credentials.
There is nothing really of interest in this class; it simply holds data about the user so that we can do something useful with it.
Listing 6-7 shows the SecurityManager class, which is responsible for authenticating users and storing their credentials for later retrieval.
The application uses the SecurityManager class to authenticate a user and, later, to retrieve the details of the currently authenticated user.
In a real application, the login() method would probably check the supplied application against a database or LDAP directory, but here we assume all users are allowed to authenticate.
The login() method creates a UserInfo object for the user and stores it on the current thread using a ThreadLocal.
The logout() method sets any value that might be stored in the ThreadLocal to null.
Finally, the getLoggedOnUser() method returns the UserInfo object for the currently authenticated user.
The code for this advice, SecurityAdvice, is shown in Listing 6-8
The SecurityAdvice class creates an instance of SecurityManager in its constructor and then stores this instance in a field.
You should note that the application and the SecurityAdvice don’t need to share the same SecurityManager instance, because all data is stored with the current thread using ThreadLocal.
In the before() method, we perform a simple check to see whether the user name of the authenticated user is clarence.
If so, we allow the user access; otherwise, an exception is raised.
Also notice that we check for a null UserInfo object, which indicates that the current user is not authenticated.
In Listing 6-9, you can see a sample application that uses the SecurityAdvice class to secure the SecureBean class.
In the getSecureBean() method, we create a proxy of the SecureBean class that is advised using an instance of SecurityAdvice.
When the caller invokes any method on this proxy, the call is first routed to the instance of SecurityAdvice for a security check.
Because the SecurityAdvice allows method calls to proceed only if the currently authenticated user is clarence, we expect that the only successful scenario in Listing 6-9 is the first of these scenarios.
Exception Caught: You must login before attempting to invoke the method: writeSecureMessage.
The remaining invocations were prevented by the SecurityException thrown by the SecurityAdvice.
This example is simple, but it does highlight the usefulness of the before advice.
Security is a typical example of before advice, but we also find it useful when a scenario demands the modification of arguments going into the method.
In Chapter 7, we show you how to use before advice to create an obscenity filter for the SpringBlog application.
Creating After-Returning Advice As its name implies, after-returning advice is executed after the Method Invocation at the joinpoint returns.
Given that the method has already executed, you can’t change the arguments that are passed to it.
Although you can read these arguments, you can’t change the execution path, and you can’t prevent the method from executing.
These restrictions are expected; what is not expected, however, is the fact that you cannot modify the return value in the after-returning advice.
Although after-returning advice cannot modify the return value of a Method Invocation, it can throw an exception that can be sent up the stack instead of the return value.
In this section, we look at two examples of using after-returning advice in an application.
The first example simply writes a message to console output after the method has been invoked.
The second example shows how you can use after-returning advice to add additional error checking to a method.
Consider a class, KeyGenerator, that generates keys for cryptographic purposes.
Many cryptographic algorithms suffer from the problem that a small number of keys in the keyspace are considered weak.
A weak key is any key whose characteristics make it significantly easier to derive the original message without knowing the key.
For the DES algorithm, there are a total of 256 possible keys.
In the second example of this section, we build an after-returning advice that checks for weak keys generated by the KeyGenerator and raises an exception if one is found.
Note For more information on weak keys and cryptography at large, we recommend you read Applied Cryptography by Bruce Schneier (Wiley, 1995)
This example is really not that different from the SimpleBeforeAdvice class you saw earlier.
The output is very similar to that of the before advice example except that, as expected, the message written by the advice appears after the message written by the writeMessage() method.
A good use of after-returning advice is to perform some additional error checking when it is possible for a method to return an invalid value.
In the scenario we described earlier, it is possible for a cryptographic key generator to generate a key that is considered weak for a particular algorithm.
Ideally, the key generator would check for these weak keys, but since the chance of these keys arising is often very small, many generators do not check.
By using an after-returning advice, we can advise the method that generates the key and performs this additional check.
It is plain to see that this key generator is ridiculously insecure, but we didn’t want you to have to wait around for years while a real key generator produced a weak key, so we created this generator, which has a one-in-three chance of producing a weak key.
In Listing 6-12, you can see the WeakKeyCheckAdvice that checks to see whether the result of the getKey() method is a weak key.
In the afterReturning() method, we check first to see whether the method that was executed at the joinpoint was the getKey() method.
If so, we then check the result value to see whether it was the weak key.
If we find that the result of the getKey() method was a weak key, then we throw a SecurityException to inform the calling code of this.
Listing 6-13 shows a simple application that demonstrates the use of this advice.
After creating an advised proxy of a KeyGenerator target, the AfterAdviceExample class attempts to generate ten keys.
If a SecurityException is thrown during a single generation, then a message is written to console output informing the user that a weak key was generated; otherwise, the generated key is displayed.
A single run of this on our machine generated the following output:
As you can see, the KeyGenerator class sometimes generates weak keys, as expected, and the WeakKeyCheckAdvice ensures that a SecurityException is raised whenever a weak key is encountered.
Creating Around Advice Around advice functions like a combination of before and after advice, with one big difference—you can modify the return value.
Not only that, but you can prevent the method from actually executing.
This means that using around advice, you can essentially replace the entire implementation of a method with new code.
Around advice in Spring is modeled as an interceptor using the MethodInterceptor interface.
There are many uses for around advice, and you will find that many features of Spring are created using method interceptors, such as the remote proxy support and the transaction management features.
Method interception is also a good mechanism for profiling the execution of your application, and it forms the basis of the example in this section.
We are not going to build a simple example for method interception; instead, we refer to the first example in Listing 6-2, which shows how to use a basic method interceptor to write a message on either side of a Method Invocation.
However, you can get access to this data using the MethodInvocation object that is passed to invoke()
You will see a demonstration of this in the following example.
For this example, we want to achieve some way to advise a class so that we get basic information about the runtime performance of its methods.
Specifically, we want to know how long the method took to execute.
To achieve this, we can use the StopWatch class included in Spring, and we clearly need a MethodInterceptor, because we need to start the StopWatch before the Method Invocation and stop it right afterward.
Listing 6-14 shows the WorkerBean class that we are going to profile using the StopWatch class and an around advice.
The doSomeWork() method accepts a single argument, noOfTimes, and calls the work() method exactly the number of times specified by this method.
This prevents the compiler from optimizing out the work() method and thus the call to work()
We use this interceptor to profile the WorkerBean class shown in Listing 6-14
As soon as the Method Invocation has ended and the return value has been captured, we stop the StopWatch and pass the total number of milliseconds taken, along with the MethodInvocation object, to the dumpInfo() method.
In this case, we did not want to disrupt the call stack in any way; we were simply acting as an eavesdropper on the Method Invocation.
If we had wanted, we could have changed the call stack completely, redirecting the method call to another object or a remote service, or we could simply have reimplemented the method logic inside the interceptor and returned a different return value.
The dumpInfo() method simply writes some information about the method call to console output, along with the time taken for the method to execute.
In the first three lines of dumpInfo(), you can see how you can use the MethodInvocation object to determine the method that was invoked, the original target of the invocation, and the arguments used.
You should be more than familiar with this code by now.
Running this example on our machine produces the following output:
From this output, you can see which method was executed, what the class of the target was, what arguments were passed in, and how long the invocation took.
Creating Throws Advice Throws advice is similar to after-returning advice in that it executes after the joinpoint, which is always a Method Invocation, but throws advice executes only if the method throws an exception.
Throws advice is also similar to after-returning advice in that it has little control over program execution.
If you are using a throws advice, you can’t choose to ignore the exception that was raised and return a value for the method instead.
The only modification you can make to the program flow is to change the type of exception that is thrown.
This is actually quite a powerful idea and can make application development much simpler.
Consider a situation where you have an API that throws an array of poorly defined exceptions.
Using a throws advice, you can advise all classes in that API and reclassify the exception hierarchy into something more manageable and descriptive.
Of course, you can also use throws advice to provide centralized error logging across your application, thus reducing the amount of error logging code that is spread across your application.
As you saw from the diagram in Figure 6-1, throws advice is implemented by the ThrowsAdvice interface.
Unlike the interfaces you have seen so far, ThrowsAdvice does not define any methods; instead, it is simply a marker interface used by Spring.
The reason for this is that Spring allows typed throws advice, which allows you to define exactly which Exception types your throws advice should catch.
Spring achieves this by detecting methods with certain signatures using reflection.
Listing 6-17 shows a simple bean with two methods that both simply throw exceptions of different types.
In Listing 6-18, you can see the SimpleThrowsAdvice class that demonstrates both of the method signatures that Spring looks for on a throws advice.
We are sure that you understand the code in the main() method, so now we will just focus on the two afterThrowing() methods.
The first thing Spring looks for in a throws advice is one or more public methods called afterThrowing()
The return type of the methods is unimportant, although we find it best to stick with void because this method can’t return any meaningful value.
The first afterThrowing() method in the SimpleThrowsAdvice class has a single argument of type Exception.
You can specify any type of Exception as the argument, and this method is ideal when you are not concerned about the method that threw the exception or the arguments that were passed to it.
Note that this method catches Exception and any subtypes of Exception unless the type in question has its own afterThrowing() method.
In the second afterThrowing() method, we declared four arguments to catch the Method that threw the exception, the arguments that were passed to the method, and the target of the Method Invocation.
The order of the arguments in this method is important, and you must specify all four.
Spring invokes a single afterThrowing() method only for each Exception, and as you saw from the example in Listing 6-18, Spring uses the method whose signature contains the best match for the Exception type.
In the situation where your after-throwing advice has two afterThrowing() methods, both declared with the same Exception type but one with a single argument and the other with four arguments, Spring invokes the four-argument afterThrowing() method.
As we mentioned earlier, after-throwing advice is useful in a variety of situations; it allows you to reclassify entire Exception hierarchies as well as build centralized Exception logging for your application.
We have found that after-throwing advice is particularly useful when we are debugging a live application, because it allows us to add extra logging code without needing to modify the application’s code.
Choosing an Advice Type In general, the choice of which advice type you want to use is driven by the requirements of your application, but you should choose the most specific advice type for your need.
That is to say, don’t use an around advice when a before advice will do.
In most cases, an around advice can accomplish everything that the other three advice types can, but it may be overkill for what you are trying to achieve.
By using the most specific type of advice, you are making the intention of your code clearer, and you are also reducing the possibility of errors.
When you are using before advice, all you need to code is the counter, but with an around advice, you need to remember to invoke the method.
These small things can allow spurious errors to creep into your application.
By keeping the advice type as focused as possible, you reduce the scope for errors.
In this way, the advice is deemed to apply to all methods on the target.
In some cases, such as when you are using AOP for logging purposes, this may be desirable, but in other cases you may want to limit the methods to which an advice applies.
Of course, you could simply perform the checking in the advice itself that the method being advised is the correct one, but this approach has several drawbacks.
First, hard-coding the list of acceptable methods into the advice reduces the advice’s reusability.
By using pointcuts, you can configure the methods to which an advice applies, without needing to put this code inside the advice; this clearly increases the reuse value of the advice.
The second and third drawbacks with hard-coding the list of methods into the advice are performance related.
To check the method being advised in the advice, you need to perform the check each time any method on the target is invoked.
When you use pointcuts, the check is performed once for each method, and the results are cached for later use.
These optimizations are covered in greater detail when we discuss proxies later in the chapter.
We strongly recommend that you avoid the temptation to hard-code method checks into your advice and instead use pointcuts wherever possible to govern the applicability of advice to methods on the target.
That said, in some cases it is necessary to hard-code the checks into your advice.
Consider the earlier example of the after-returning advice designed to catch weak keys generated by the KeyGenerator class.
This kind of advice is closely coupled to the class it is advising, and it is wise to check inside the advice to ensure that it is applied to the correct type.
We refer to this coupling between advice and target as target affinity.
In general, you should use pointcuts when your advice has little or no target affinitythat is, it can apply to any type or a wide range of types.
When your advice has strong target affinity, try to check that the advice is being used correctly in the advice itself; this helps reduce head-scratching errors when an advice is misused.
As you will see, this results in a noticeable drop in invocation speed that can have a large impact on the overall performance of your application.
The Pointcut Interface Pointcuts in Spring are created by implementing the Pointcut interface, as shown in Listing 6-19
When creating your own pointcuts from scratch, you must implement both the ClassFilter and MethodMatcher interfaces as well.
Thankfully, as you will see in the next section, this is usually unnecessary because Spring provides a selection of Pointcut implementations that cover almost if not all of your use cases.
As you can see, the ClassFilter interface defines a single method, matches(), that is passed an instance of Class that represents the class to be checked.
As you have no doubt determined, the matches() method returns true if the pointcut applies to the class and false otherwise.
The MethodMatcher interface is more complex than the ClassFilter interface, as shown in Listing 6-21
Spring supports two different types of MethodMatcher, static and dynamic, determined by the return value of isRuntime()
Before using a MethodMatcher, Spring calls isRuntime() to determine whether the MethodMatcher is static, indicated by a return value of false, or dynamic, indicated by a return value of true.
For a static pointcut, Spring calls the matches(Method, Class<T>) method of the MethodMatcher once for every method on the target, caching the return value for subsequent invocations of those methods.
In this way, the check for method applicability is performed only once for each method, and subsequent invocations of a method do not result in an invocation of matches()
With dynamic pointcuts, Spring still performs a static check using matches(Method, Class<T>) the first time a method is invoked to determine the overall applicability of a method.
However, in addition to this and provided that the static check returned true, Spring performs a further check for each invocation of a method using the matches(Method, Class<T>, Object[]) method.
In this way, a dynamic MethodMatcher can determine whether a pointcut should apply based on a particular invocation of a method, not just on the method itself.
In this case, the matches(Method, Class<T>, Object[]) method can be coded to perform further checking on the argument for each invocation.
Clearly, static pointcuts—that is, pointcuts whose MethodMatcher is static—perform much better than dynamic pointcuts because they avoid the need for an additional check per invocation.
In general, we recommend you use static pointcuts wherever you can.
However, in cases where your advice adds substantial overhead, it may be wise to avoid any unnecessary invocations of your advice by using a dynamic pointcut.
In general, you rarely create your own Pointcut implementations from scratch because Spring provides abstract base classes for both static and dynamic pointcuts.
We look at these base classes, along with other Pointcut implementations, over the next few sections.
Available Pointcut Implementations As of version 3.1, Spring provides eight implementations of the Pointcut interface: two abstract classes intended as convenience classes for creating static and dynamic pointcuts, and six concrete classes, one for each of the following:
Defining pointcuts that look for specific annotations at the class or method level.
Pointcut that looks for specific Java annotation on a class or method.
Pointcut that uses AspectJ weaver to evaluate a pointcut expression in AspectJ syntax.
The ComposablePointcut class is used to compose two or more pointcuts together with operations such as union() and intersection()
This class is covered in more detail in the next chapter.
Figure 6-3 shows the UML diagram for the Pointcut implementation classes.
We cover the six basic implementations in detail in the following sections.
Remember from our earlier discussions that an Advisor is Spring’s representation of an aspect (in the section “Aspects in Spring” in this chapter), a coupling of advice and pointcuts that governs which methods should be advised and how they should be advised.
For this example, we have two classes, BeanOne and BeanTwo, with identical methods defined in both.
The implementation simply returns true if the name of the method is foo; otherwise, it returns false.
Notice that we have also overridden the getClassFilter() method to return a ClassFilter instance whose matches() method returns true only for the BeanOne class.
With this static pointcut, we are saying that only methods of the BeanOne class will be matched, and furthermore, only the foo() method of that class will be matched.
Listing 6-24 shows the SimpleAdvice class that simply writes out a message on either side of the Method Invocation.
Finally, both the foo() and bar() methods are invoked on the two proxies.
As you can see, the only method for which the SimpleAdvice was actually invoked was the foo() method for the BeanOne class, exactly as expected.
Restricting the methods that an advice applies is quite simple and, as you will see when we discuss the different proxy options, is key to getting the best performance out of your application.
For this example, we create a dynamic pointcut for the class shown in Listing 6-26
This removes the need to check the class in the method-matching methods—something that is especially important for the dynamic check.
Although we are required to implement only the dynamic check, we implement the static check as well.
The reason for this is that we know the bar() method will never be advised.
By indicating this using the static check, Spring makes it so it never has to perform a dynamic check for this method.
This is because when a static check method was implemented, Spring will first check against it, and if the checking result is a not a match, Spring will just stop the further dynamic checking.
Moreover, the result of static check will be cached for better performance.
But if we neglect the static check, Spring performs a dynamic check each time the bar() method is invoked.
This will make your pointcut much easier to understand and maintain, and performance will be better too.
Note that in the dynamic check, we know that we are dealing with the foo() method, because no other method makes it past the static check.
In Listing 6-28, you can see an example of this pointcut in action.
Notice that we have used the same advice class as in the static pointcut example.
However, in this example, only the first two calls to foo() should be advised.
The dynamic check prevents the third call to foo() from being advised, and the static check prevents the bar() method from being advised.
As we expected, only the first two invocations of the foo() method were advised.
Notice that none of the bar() invocations is subject to a dynamic check, thanks to the static check on bar()
An interesting point to note here is that the foo() method is actually subject to two static checks: one during the initial phase when all methods are checked and another when it is first invoked.
As you can see, dynamic pointcuts offer a greater degree of flexibility than static pointcuts, but because of the additional runtime overhead they require, you should use a dynamic pointcut only when absolutely necessary.
Using Simple Name Matching Often when creating a pointcut, you want to match based on just the name of the method, ignoring method signature and return type.
Notice that we have added two names to the pointcut, foo and bar, using the addMethodName() method.
As expected, the foo(), foo(int), and bar() methods are advised, thanks to the pointcut, but the yup() method is left unadvised.
Creating Pointcuts with Regular Expression In the previous section, we discussed how to perform simple matching against a predefined list of methods.
The code in Listing 6-31 shows a simple class with three methods.
Using a regular expression-based pointcut, we can match all methods in this class whose name starts with foo.
This is a powerful concept because it allows you to match all methods within a given package, without needing to know exactly which classes are in that package and what the names of the methods are.
Creating Pointcuts with AspectJ Pointcut Expression Besides JDK regular expressions, you can also use AspectJ’s pointcut expression language for pointcut declaration.
In the next chapter, you will see that when we declare the pointcut in XML configuration using the aop namespace, Spring defaults to use AspectJ’s pointcut language.
Moreover, when using Spring’s @AspectJ annotation-style AOP support, you also need to use AspectJ’s pointcut language.
So when declaring pointcuts using expression language, using AspectJ pointcut expression is the best way to go.
In STS, you can simply add the dependencies shown in Table 6-4 to your project.
Let’s take the previous example using JDK regular expression again and see how to use AspectJ expression to achieve the same result.
Using an AspectJ expression-based pointcut, we also can easily match all methods in this class whose names start with foo.
Running the program will get the same result as the previous example using JDK regular expressions.
Creating Annotation Matching Pointcuts If your application is annotation-based, you may want to use your own specified annotations for defining pointcuts, that is, apply the advice logic to all methods or types with specific annotations.
Again, let’s reuse the previous example and see how we did it when using an annotation as a pointcut.
Let’s define an annotation interface called AdviceRequired, which is an annotation that we will use for declaring a pointcut.
Listing 6-36 shows a simple bean with annotations in it.
For the previous bean, the foo() method was annotated with @AdviceRequired, to which we want the advice to be applied.
This indicates that we want to apply the advice to all the methods annotated with the given annotation.
As you can see, since we annotated the foo() method, only that method was advised.
Convenience Advisor Implementations For many of the Pointcut implementations, Spring also provides a convenience Advisor implementation that acts as the Pointcut.
There is no noticeable performance difference between the two approaches, and aside from there being slightly less code in the second approach, there is very little difference in the actual coding approach.
We prefer to stick with the first approach because we feel the intent is slightly clearer in the code.
At the end of the day, the style you choose comes down to personal preference.
Understanding Proxies So far, we have taken only a cursory look at the proxies generated by ProxyFactory.
We mentioned that two types of proxy are available in Spring: JDK proxies created using the JDK Proxy class and CGLIB-based proxies created using the CGLIB Enhancer class.
You may be wondering exactly what the difference between the two proxies is and why Spring needs two different types of proxy.
In this section, we take a detailed look at the differences between the proxies.
The core goal of a proxy is to intercept Method Invocations and, where necessary, execute chains of advice that apply to a particular method.
The management and invocation of advice is largely proxy independent and is managed by the Spring AOP framework.
However, the proxy is responsible for intercepting calls to all methods and passing them as necessary to the AOP framework for the advice to be applied.
In addition to this core functionality, the proxy must also support a set of additional features.
It is possible to configure the proxy to expose itself via the AopContext class (which is an abstract class) so that you can retrieve the proxy and invoke advised methods on the proxy from the target object.
In addition to this, all proxy classes implement the Advised interface by default, which allows for, among other things, the advice chain to be changed after the proxy has been created.
A proxy must also ensure that any methods that return this—that is, return the proxied target—do in fact return the proxy and not the target.
As you can see, a typical proxy has quite a lot of work to perform, and all of this logic is implemented in both the JDK and CGLIB proxies.
Using JDK Dynamic Proxies JDK proxies are the most basic type of proxy available in Spring.
Unlike the CGLIB proxy, the JDK proxy can generate proxies only of interfaces, not classes.
In this way, any object you want to proxy must implement at least one interface.
In general, it is good design to use interfaces for your classes, but it is not always possible, especially when you are working with third-party or legacy code.
When you are using the JDK proxy, all method calls are intercepted by the JVM and routed to the invoke() method of the proxy.
This method then determines whether the method in question is advised (by the rules defined by the pointcut), and if so, it invokes the advice chain and then the method itself using reflection.
In addition to this, the invoke() method performs all the logic discussed in the previous section.
The JDK proxy makes no determination between methods that are advised and unadvised until it is in the invoke() method.
This means that for unadvised methods on the proxy, the invoke() method is.
Obviously, this incurs runtime overhead each time the method is invoked, even though the proxy often performs no additional processing other than to invoke the unadvised method via reflection.
You can instruct the ProxyFactory to use a JDK proxy by specifying the list of interfaces to proxy using setInterfaces() (in the AdvisedSupport class that the ProxyFactory class extends indirectly)
Using CGLIB Proxies With the JDK proxy, all decisions about how to handle a particular Method Invocation are handled at runtime each time the method is invoked.
When you use CGLIB, CGLIB dynamically generates the bytecode for a new class on the fly for each proxy, reusing already generated classes wherever possible.
When a CGLIB proxy is first created, CGLIB asks Spring how it wants to handle each method.
This means that many of the decisions that are performed in each call to invoke() on the JDK proxy are performed just once for the CGLIB proxy.
Because CGLIB generates actual bytecode, there is also a lot more flexibility in the way you can handle methods.
For instance, the CGLIB proxy generates the appropriate bytecode to invoke any unadvised methods directly, reducing the overhead introduced by the proxy.
In addition to this, the CGLIB proxy determines whether it is possible for a method to return this; if not, it allows the method call to be invoked directly, again reducing the runtime overhead.
The CGLIB proxy also handles fixed advice chains differently than the JDK proxy.
A fixed-advice chain is one that you guarantee will not change after the proxy has been generated.
By default, you are able to change the advisors and advice on a proxy even after it is created, although this is rarely a requirement.
The CGLIB proxy handles fixed advice chains in a particular way, reducing the runtime overhead for executing an advice chain.
Comparing Proxy Performance So far, all we have done is discuss in loose terms the differences in implementation between the different proxy types.
In this section, we are going to run a simple performance test to compare the performance of the CGLIB proxy with the JDK proxy.
Let’s create an ISimpleBean interface and its implementation class, SimpleBean, which we will use as the target object for proxying.
Listing 6-41 shows the TestPointcut class, which provides static checking on the method under advise.
Listing 6-42 shows the NoOpBeforeAdvice class, which is just a simple before advice without any operation.
Test 5: testing method on Advised Advised advised = (Advised)bean;
In this code, you can see that we are testing three kinds of proxy: a standard CGLIB proxy, a CGLIB proxy with a frozen advice chain (i.e., when a proxy is frozen by calling the setFrozen() method in the ProxyConfig class that ProxyFactory extends indirectly, CGLIB will perform further optimization; however, further advice change will not be allowed), and a JDK proxy.
For each proxy type, we run the following five test cases:
The advice type used in the test is a before advice that performs no processing, so it reduces the effects of the advice on the performance tests.
Unadvised method (test 2): A method on the proxy that is unadvised.
Often your proxy has many methods that are not advised.
This test looks at how well unadvised methods perform for the different proxies.
The equals() method (test 3): This test looks at the overhead of invoking the equals() method.
This is especially important when you use proxies as keys in a HashMap or similar collection.
The hashcode() method (test 4): As with the equals() method, the hashCode() method is important when you are using HashMaps or similar collections.
Executing methods on the Advised interface (test 5): As we mentioned earlier, a proxy implements the Advised interface by default, allowing you to modify the proxy after creation and to query information about the proxy.
This test looks at how quick methods on the Advised interface can be accessed using the different proxy types.
When running the test, we set the initial heap size of the JVM to 2048MB to reduce the effects of heap resizing on test results.
From the results in this table, you can see that the performance between standard CGLIB and JDK dynamic proxy for both advised and unadvised methods don’t have much difference.
If you read the previous version of this book, you will find that the performance of JDK proxy was much slower for unadvised methods.
This was because in the previous version of this book, the tests were run on JDK 1.4, and at that time, the performance of reflection was still very poor.
This time the previous tests were run under JDK 6, for which the performance of the reflection mechanism is greatly improved.
However, there is a noticeable difference when you are using a CGLIB proxy with a frozen advice chain.
Similar figures apply to the equals() and hashCode() methods, which are noticeably faster when.
For methods on the Advised interface, you will notice that they are also faster on the CGLIB proxy.
The reason for this is that Advised methods are handled early on in the intercept() method so they avoid much of the logic that is required for other methods.
Which Proxy to Use? Deciding which proxy to use is typically an easy decision.
The CGLIB proxy can proxy both classes and interfaces, whereas the JDK proxy can proxy only interfaces.
In terms of performance, there is no significant difference between JDK and CGLIB standard mode (at least in running both advised and unadvised methods), unless you use CGLIB in frozen mode, in which case the advice chain can’t be changed and CGLIB performs further optimization when in frozen mode.
When proxying a class, the CGLIB proxy is the default choice because it is the only proxy capable of generating a proxy of a class.
To use the CGLIB proxy when proxying an interface, you must set the value of the optimize flag in the ProxyFactory to true using the setOptimize() method.
Note Besides CGLIB, there is another bytecode manipulation library called Javassist, which is being used by some other popular projects (e.g., Hibernate)
Some developers prefer Javassist over CGLIB and have raised a JIRA issue (http://jira.springsource.org/browse/SPR-5654) requesting the migration of the Spring AOP.
The Spring development team is considering it during the Spring 3.2 timeline.
There also exists an intermediate solution provided by the community.
Summary In this chapter, we introduced the core concepts of AOP and then looked at how these concepts translate into the Spring AOP implementation.
We discussed the features that are and are not implemented in Spring AOP, and we pointed to AspectJ as an AOP solution for those features that Spring does not implement.
We spent some time explaining the details of the advice types available in Spring, and you saw examples of the four types in action.
We also looked at how you limit the methods to which an advice applies using pointcuts.
In particular, we looked at the six basic pointcut implementations available with Spring.
Finally, we covered the details of how the AOP proxies are constructed, the different options, and what makes them different.
We concluded the discussion of proxies with a comparison of the performance between three different proxy types and highlighted some major differences and restrictions for choosing between a JDK vs.
We will spend some time looking at how you utilize Spring’s AspectJ integration to extend the AOP feature set available to your application.
We will also look at how AOP is supported by Spring Framework services, which means you can define and configure advice declaratively rather than programmatically.
In this chapter, we go into more detail about the AOP features available in Spring.
In particular, we look at the topic in a much more real-world light: we explore the framework services in Spring that allow for transparent application of AOP, we cover real-world usage of AOP in the context of the sample application, and we also discuss overcoming the limitations of Spring AOP using Spring/AspectJ integration.
This section also summarizes the whole pointcut discussion and looks at the appropriate techniques you should employ when you are using pointcuts in your application.
Introductions: Mentioned briefly in the previous chapter, introductions allow you to add interface implementations dynamically to any object on the fly using the familiar interceptor concept.
However, in true Spring fashion, the framework fully supports configuring AOP transparently and declaratively.
In this section, we look at three ways (the ProxyFactoryBean class, the aop namespace, and @AspectJ-style annotations) to inject declaratively defined AOP proxies into your application objects as collaborators, thus making your application completely unaware that it is working with advised objects.
The main difference between AspectJ and Spring AOP is that AspectJ applies advice to target objects via weaving (either compile-time or load-time weaving), while as discussed in the previous chapter, Spring AOP is based on a proxy.
The feature set of AspectJ is much greater than that of Spring AOP, but it is much more complicated to use than Spring.
AspectJ is a good solution when you find that Spring AOP lacks a feature you need.
Starting from version 2.0, you can take full advantage of Spring features when configuring your AspectJ aspects.
To run some of the examples in this chapter, you need to obtain AspectJ.
We used version 1.6.11 of AspectJ for the examples in this chapter.
You can also add the Maven dependencies in Table 7-1 into your STS project.
Advanced Use of Pointcuts In the previous chapter, we looked at six basic Pointcut implementations Spring provides; for the most part, we found that these meet the needs of our applications.
Essentially, a control flow pointcut in Spring pointcuts all method calls below a given method or below all methods in a class.
This is quite hard to visualize and is better explained using an example.
Listing 7-1 shows a SimpleBeforeAdvice that writes a message out describing the method it is advising.
In Listing 7-2, you can see a simple class with one method—the method that we want to advise.
In Listing 7-2, you can see the simple foo() method that we want to advise.
We have, however, a special requirement—we want to advise this method only when it is called from another, specific method.
Listing 7-3 shows a simple driver program for this example.
You also need to add the dependency for CGLIB into your project, which was shown in Table 7-2
Running the example in Listing 7-3 yields the following output:
As you can see, when the foo() method is first invoked outside of the control flow of the test() method, it is unadvised.
Note that if we had called another method from within the test() method, one that was not on the advised proxy, it would not have been advised.
Control flow pointcuts can be extremely useful, allowing you to advise an object selectively only when it is executed in the context of another.
However, be aware that you take a substantial performance hit for using control flow pointcut over other pointcuts.
Figures from the Spring documentation indicate that a control flow pointcut is typically five times slower than other pointcuts on a 1.4 JVM.
Suppose we have a transaction processing system, which contains a TransactionService interface as well as an AccountService interface.
However, e-mail will not be sent under any other circumstances.
In this case, the control flow pointcut will be useful.
Figure 7-1 shows the UML sequence diagram for this scenario.
Using Composable Pointcut In previous pointcutting examples, we used just a single pointcut for each Advisor.
In most cases, this is usually enough, but in some cases, you may need to compose two or more pointcuts together to achieve the desired goal.
Consider the situation where you want to pointcut all getter and setter methods on a bean.
You have a pointcut for getters and a pointcut for setters, but you don’t have one for both.
Of course, you could just create another pointcut with the new logic, but a better approach is to combine the two pointcuts into a single pointcut using ComposablePointcut.
By default, ComposablePointcut is created with a ClassFilter that matches all classes and a MethodMatcher that matches all methods, although you can supply your own initial ClassFilter and MethodMatcher during construction.
The union() and intersection() methods are both overloaded to accept ClassFilter and MethodMatcher arguments.
The result of an union operation is that the ComposablePointcut will add an “or” condition into its call chain for matching with the joinpoints.
You can imagine it as the “where” clause in a SQL query, with the union() method like the “or” operator and the intersection() method like the “and” operator.
As with control flow pointcuts, this is quite difficult to visualize, and it is much easier to understand with an example.
With this example, we are going to generate three different proxies using the same ComposablePointcut instance, but each time, we are going to modify the ComposablePointcut using either the union() or intersection() method.
Following this, we will invoke all three methods on the SampleBean proxy and look at which ones have been advised.
The first thing to notice in this example is the set of three private MethodMatcher implementations.
This is the default MethodMatcher that we use to assemble the ComposablePointcut.
Because of this, we expect that the first round of invocations on the SampleBean methods will result in only the getAge() and getName() methods being advised.
At this point, we have a union of two MethodMatchers: one that matches all methods starting with get and one that matches all methods starting with set.
To this end, we expect that all invocations during the second round will be advised.
This MethodMatcher is combined with the ComposablePointcut using intersection() for the third round for invocations.
As expected, the first round of invocations on the proxy saw only the getAge() and getName() methods being advised.
Although this example demonstrated the use of MethodMatchers only in the composition process, it is just as simple to use ClassFilter when you are building the pointcut.
Indeed, you can use a combination of MethodMatchers and ClassFilters when building your composite pointcut.
Composition and the Pointcut Interface In the previous section, you saw how to create a composite pointcut using multiple MethodMatchers and ClassFilters.
You can also create composite pointcuts using other objects that implement the Pointcut interface.
The intersection() and union() methods both take two pointcuts as arguments to construct a composite pointcut.
On the other hand, a matches(Pointcut, Method, Class, Object[]) method also is provided for performing a quick check on whether a pointcut matches with the provided method, class, and method arguments.
So, if you need to combine MethodMatcher and ClassFilter with Pointcut, you need to use the ComposablePointcut class.
However, when you just need to combine two pointcuts, the Pointcuts class will be more convenient.
Pointcutting Summary From the discussions in this chapter and in the previous chapter, you can see that Spring offers a powerful set of Pointcut implementations that should meet most, if not all, of your application’s.
Remember that if you can’t find a pointcut to suit your needs, you can create your own implementation from scratch by implementing Pointcut, MethodMatcher, and ClassFilter.
The first pattern, the one we have used so far, involves having the pointcut implementation decoupled from the advisor.
The second option, one that is adopted by many of the examples in the Spring documentation, is to encapsulate the Pointcut inside your own Advisor implementation.
We find that the first approach is the most flexible, allowing you to use different Pointcut implementations with different Advisor implementations.
However, the second approach is useful in situations where you are going to be using the same combination of Pointcut and Advisor in different parts of your application, or, indeed, across many different applications.
The second approach is useful when each Advisor must have a separate instance of a Pointcut; by making the Advisor responsible for creating the Pointcut, you can ensure that this is the case.
If you recall the discussion on proxy performance from the previous chapter, you will remember that unadvised methods perform much better than methods that are advised.
For this reason, you should ensure that, by using Pointcuts, you only advise the methods that are absolutely necessary.
This way, you reduce the amount of unnecessary overhead added to your application by using AOP.
Getting Started with Introductions Introductions are an important part of the AOP feature set available in Spring.
By using introductions, you can introduce new functionality to an existing object dynamically.
In Spring, you can introduce an implementation of any interface to an existing object.
You may well be wondering exactly why this is useful—why would you want to add functionality dynamically at runtime when you can simply add that functionality at development time? The answer to this question is easy.
You add functionality dynamically when the functionality is crosscutting and is not easily implemented using traditional advice.
Introduction Basics Spring treats introductions as a special type of advice, more specifically, as a special type of around advice.
Because introductions apply solely at the class level, you cannot use pointcuts with introductions; semantically, the two don’t match.
An introduction adds new interface implementations to a class, and a pointcut defines which methods an advice applies.
Figure 7-2 shows this structure along with the methods of both interfaces.
As you can see, the MethodInterceptor interface defines an invoke() method.
Using this method, you provide the implementation for the interfaces that you are introducing and perform interception for any additional methods as required.
Implementing all methods for an interface inside a single method can prove troublesome, and it is likely to result in an awful lot of code that you will have to wade through just to decide which method to invoke.
Don’t worry if this seems a little unclear; you will see an example of it in the next section.
When using standard advice—that is, not introductions—it is possible for the same advice instance to be used for many different objects.
The Spring documentation refers to this as the per-class life cycle, although you can use a single advice instance for many different classes.
For introductions, the introduction advice forms part of the state of the advised object, and as a result, you must have a distinct advice instance for every advised object.
This way, you only need to ensure that a new instance of your advisor class is created for each object, because it will automatically create a new instance of the introduction.
For example, we want to apply a before advice to the setFirstName() method on all instances of the Contact class.
Figure 7-3 shows the same advice that applies to all objects of the Contact type.
Now let’s say we want to mix an introduction into all instances of Contact class, and the introduction will carry information for each Contact instance (e.g., an attribute isModified that indicates whether the specific instance was modified)
In this case, the introduction will be created for each instance of Contact class and tied to that specific instance, as shown in Figure 7-4
We will now discuss how you can use introductions to solve the problem of object modification detection.
Object Modification Detection with Introductions Object modification detection is a useful technique for many reasons.
Typically you apply modification detection to prevent unnecessary database access when you are persisting object data.
If an object is passed to a method for modification but it comes back unmodified, there is little point in issuing an update statement to the database.
Using a modification check in this way can really increase application throughput, especially when the database is already under a substantial load or is located on some remote network making communication an expensive operation.
Unfortunately, this kind of functionality is difficult to implement by hand because it requires you to add to every method that can modify object state to check whether the object state is actually being modified.
When you consider all the null checks that have to be made and the checks to see whether the value is actually changing, you are looking at around eight lines of code per method.
You could refactor this into a single method, but you still have to call this method every time you need to perform the check.
Spread this across a typical application with many different classes that require modification checks, and you have a disaster waiting to happen.
We do not want to have to make it so each class that requires modification checks inherits from some base implementation, losing its only chance for inheritance as a result, nor do we really want to be adding checking code to each and every statechanging method.
Using introductions, we can provide a flexible solution to the modification detection problem without having to write a bunch of repetitive, error-prone code.
In this example, we are going to build a full modification check framework using introductions.
The modification check logic is encapsulated by the IsModified interface, an implementation of which will be introduced into the appropriate objects, along with interception logic to perform modification checks automatically.
For the purposes of this example, we use JavaBeans conventions, in that we consider a modification to be any call to a setter method.
Of course, we don’t just treat all calls to a setter method as a modification—we check to see whether the value being passed to the setter is different from the one currently stored in the object.
The only flaw with this solution is that setting an object back to its original state will still reflect a modification if any one of the values on the object changed.
For example, you have a Contact object with the firstName attribute.
Let’s say that during processing the firstName attribute was changed from Peter to John.
However, it will still be marked as modified, even if the value is then changed back from John to its original value Peter in later processing.
One way to keep track of such changes is to store the full history of changes in the object’s entire life cycle.
However, the implementation here is nontrivial and suffices for most requirements.
Implementing the more complete solution would result in an overly complex example.
The IsModified Interface Central to the modification check solution is the IsModified interface, which our fictional application uses to make intelligent decisions about object persistence.
We do not look at how the application would use IsModified; instead, we focus on the implementation of the introduction.
There’s nothing special here—just a single method, isModified(), indicating whether an object has been modified.
Creating a Mixin The next step is to create the code that implements IsModified and that is introduced to the objects; this is referred to as a mixin.
The first thing to notice here is the implementation of IsModified, which consists of the private modified field and the isModified() method.
This example highlights why you must have one mixin instance per advised object—the mixin introduces not only methods to the object but also state.
If you share a single instance of this mixin across many different objects, then you are also sharing the state, which means all objects show as modified the first time a single object becomes modified.
You do not actually have to implement the invoke() method for a mixin, but in this case, doing so allows us to detect automatically when a modification occurs.
We start by performing the check only if the object is still unmodified; we do not need to check for modifications once we know that the object has been modified.
Next, we check to see whether the method is a setter, and if it is, we retrieve the corresponding getter method.
Note that we cache the getter/setter pairs for quicker future retrieval.
Finally, we compare the value returned by the getter with that passed to the setter to determine whether a modification has occurred.
Notice that we check for the different possible combinations of null and set the modifications appropriately.
You can implement as many interfaces as you like in your mixin, each of which is automatically introduced into the advised object.
Creating an Advisor The next step is to create an Advisor to wrap the creation of the mixin class.
This step is optional, but it does help ensure that a new instance of the mixin is being used for each advised object.
Putting It All Together Now that we have a mixin class and an Advisor class, we can test the modification check framework.
Listing 7-9 shows a simple class that we use to test the IsModifiedMixin.
This bean has a single property, name, that we use when we are testing the modification check mixin.
Listing 7-10 shows how to assemble the advised proxy and then tests the modification check code.
Notice in the code that we test first to see whether the proxy is an instance of TargetBean and then to see whether it is an instance of IsModified.
Both tests return true when you are using the CGLIB proxy, but only the IsModified test returns true for the JDK proxy.
Finally, we test the modification check code by first setting the name property to its current value and then to a new value, checking the value of the isModified flag each time.
Is TargetBean?: true Is IsModified?: true Has been modified?: false Has been modified?: false Has been modified?: true.
Notice that the first call to isModified(), before any modification occurred, returns false.
The next call, after we set the value of name to the same value, also returns false.
For the final call, however, after we set the value of name to a new value, the isModified() method returns true, indicating that the object has in fact been modified.
Introduction Summary Introductions are one of the most powerful features of Spring AOP; they allow you not only to extend the functionality of existing methods but also to extend the set of interfaces and object implements dynamically.
Using introductions is the perfect way to implement crosscutting logic that your application interacts with through well-defined interfaces.
In general, this is the kind of logic that you want to apply declaratively rather than programmatically.
By using the IsModifiedMixin defined in this example and the framework services discussed in the next section, we can declaratively define which objects are capable of modification checks, without needing to modify the implementations of those objects.
Obviously, because introductions work via proxies, they add a certain amount of overhead, and all methods on the proxy are considered to be advised, because you cannot use pointcuts in conjunction with introductions.
However, in the case of many of the services that you can implement using introductions such as the object modification check, this performance overhead is a small price to pay for the reduction in code required to implement the service, as well the increase in stability and maintainability that comes from fully centralizing the service logic.
Framework Services for AOP Up to now, we have had to write a lot of code to advise objects and generate the proxies for them.
Although this in itself is not a huge problem, it does mean that all advice configuration is hard-coded into your application, removing some of the benefits of being able to advise a method implementation transparently.
Thankfully, Spring provides additional framework services that allow you to create an advised proxy in your application configuration and then inject this proxy into a target bean just like any other dependencies.
Using the declarative approach to AOP configuration is preferable to the manual, programmatic mechanism.
When you use the declarative mechanism, not only do you externalize the configuration of advice, but you also reduce the chance of coding errors.
You can also take advantage of DI and AOP combined to enable AOP so it can be used in a completely transparent environment.
Using ProxyFactoryBean: In Spring AOP, the ProxyFactoryBean provides a declarative way for configuring Spring’s ApplicationContext (and hence the underlying BeanFactory) in creating AOP proxies based on defined Spring beans.
Using Spring aop namespace: Introduced in Spring 2.0, the aop namespace provides a simplified way (when compared to the ProxyFactoryBean) for defining aspects and their DI requirements in Spring applications.
However, the aop namespace also uses the ProxyFactoryBean behind the scenes.
Although the syntax it uses is based on AspectJ and you need to include some AspectJ libraries when using this option, Spring still uses the proxy mechanism, i.e., creates proxied objects for the targets, when bootstrapping the ApplicationContext.
Let’s go through the option one by one in the following sections.
Using ProxyFactoryBean The ProxyFactoryBean class is an implementation of FactoryBean that allows you to specify a bean to target, and it provides a set of advice and advisors for that bean that are eventually merged into an AOP proxy.
Because you can use both advisor and advice with the ProxyFactoryBean, you can configure not only the advice declaratively but the pointcuts as well.
The values for these flags are passed directly to the underlying ProxyFactory, which allows you to configure the factory declaratively as well.
You define a bean that will be the target bean, and then using ProxyFactoryBean, you define the bean that your application will actually access, using the target bean as the proxy target.
Where possible, define the target bean as an anonymous bean inside the proxy bean declaration.
This prevents your application from accidentally accessing the unadvised bean.
However, in some cases, such as the sample we are about to show you, you may want to create more than one proxy for the same bean, so you should use a normal top-level bean for this case.
For this example, we are going to create two proxies for a single MyDependency instance, both with the same basic advice shown in Listing 7-13
The first proxy will just advise the target using the advice directly; thus, all methods will be advised.
To test the advice, we will create two bean definitions of type MyBean, each of which will be injected with a different proxy.
Then we will invoke the execute() method on each of these beans and observe what happens when the advised methods on the dependency are invoked.
Notice that we are not really doing anything special; we are simply setting the properties that we set in code using Spring’s DI capabilities.
The only points of interest are that we use an anonymous bean for the pointcut and we use the ProxyFactoryBean class.
The important point to realize when you are using ProxyFactoryBean is that the ProxyFactoryBean declaration is the one to expose to your application and the one to use when you are fulfilling dependencies.
The underlying target bean declaration is not advised, so you should use this bean only when you want to bypass the AOP framework, although in general, your application should not be aware of the AOP framework and thus should not want to bypass it.
For this reason, you should use anonymous beans wherever possible to avoid accidental access from the application.
Listing 7-15 shows a simple class that grabs the two MyBean instances from the ApplicationContext and then runs the execute() method for each one.
Running the example in Listing 7-15 results in the following output:
As expected, both the foo() and bar() methods in the first proxy are advised, because no pointcut was used in its configuration.
For the second proxy, however, only the foo() method was advised because of the pointcut used in the configuration.
Using ProxyFactoryBean for Introductions You are not limited in using the ProxyFactoryBean class for just advising an object but also for introducing mixins to your objects.
The same rule applies when you are using ProxyFactoryBean with introductions.
When you are using ProxyFactoryBean, it becomes much easier to configure your proxies if you created a custom Advisor for your mixin as discussed earlier.
As you can see from the configuration, we use the IsModifiedAdvisor class as the advisor for the ProxyFactoryBean, and because we do not need to create another proxy of the same target object, we use an anonymous declaration for the target bean.
Listing 7-17 shows a modification of the previous introduction example that obtains the proxy from the ApplicationContext.
Running this example yields exactly the same output as the previous introduction example, but this time the proxy is obtained from the ApplicationContext and no configuration is present in the application code.
ProxyFactoryBean Summary When you use ProxyFactoryBean, you can configure AOP proxies that provide all the flexibility of the programmatic method without needing to couple your application to the AOP configuration.
Unless you need to perform decisions at runtime as to how your proxies should be created, it is best to use the declarative method of proxy configuration over the programmatic method.
Using the aop Namespace The aop namespace provides a greatly simplified syntax for declarative Spring AOP configurations.
To show you how it works, let’s reuse the previous example on using ProxyFactoryBean, with a slightly modified version in order to demonstrate its usage.
In the previous listing, we modified the foo() method of the MyDependency class to accept an integer value as an argument.
And in the MyBean class, the foo() method was called twice with different parameters.
You will see that the advice class no longer needs to implement the MethodBeforeAdvice interface.
Also, the before advice accepts the JoinPoint as an argument but not the method, object, and arguments.
Actually, for the advice class, this argument is optional, so you can leave the method with no argument.
However, if in the advice you need to access the information of the joinpoint being advised (in this case we want to dump the information of the calling type and method name), then we need to define the acceptance of the argument.
When the argument is defined for the method, Spring will automatically pass the joinpoint into the method for your processing.
Listing 7-21 shows the Spring XML configuration with the aop namespace (aopns.xml)
First, we need to declare the aop namespace in the <beans> tags.
Second, all the Spring AOP configuration was put under the tag <aop:config>
Under <aop:config>, you can then define the pointcut, aspects, advisors, and so on, and reference other Spring beans as usual.
From the previous configuration, we defined a pointcut with the ID fooExecution.
Also, the foo() method should receive one argument with the integer type.
Afterward, for the aspect, it was declared by using the <aop:aspect> tag, and the advice class is referencing the Spring bean with the ID "advice", which is the MyAdvice class.
Just initialize the ApplicationContext as usual, retrieve the bean, and call its execute() method.
As you can see, the two calls to the foo() method were advised but not the bar() method.
It exactly works as we expected, and you can see the configuration was greatly simplified when compared to the ProxyFactoryBean configuration.
Let’s further revise the previous sample into a bit more complicated case.
To runs the advice only when the argument is not 100, we need to modify the advice.
First, the argument intValue was added into the signature of the before advice.
To pass the argument to the advice, we also need to revise the XML configuration a bit.
In this case, we need to modify the point expression.
First, the args(intValue) instructs Spring to also pass the argument with the name intValue into the before advice.
This is a powerful feature; if you have a well-defined structure of Spring beans naming, you can easily advise the objects that you want.
You can see that only the foo() with arguments not equal to 100 are advised.
Let’s see one more example of using the aop namespace for around advice.
We also added the intValue argument to display the value in the advice.
For the XML configuration, we just need to add one line to it.
We just added a new tag <aop:around> to declare the around advice and reference the same pointcut.
Run the testing program again, and you will have the following output:
First, you see that the around advice was applied to both invocations of the foo() method, since it doesn’t check the argument.
Second, for the foo() method with 101 as an argument, both the before and around advice were executed, and by default the before advice takes precedence.
Note When using the aop namespace or the @AspectJ style, there are two types of after advice.
Another one is the “after” advice (using the <aop:after> tag), which takes place whether the method was completed normally or the method runs into an error and an exception is thrown.
However, as stated before, Spring still uses its own proxying mechanism for advising the target methods, not AspectJ’s weaving mechanism.
In this section, we will go through how to implement the same aspects like the one in aop-namespace, by using @AspectJ style annotations.
For the examples in this section, we will also use annotation for other Spring beans as well.
We annotate both classes with the @Component annotation and assign them with the corresponding name.
In the MyBean class, the setter method of the property myDependency was annotated with @Autowired for automatic injection by Spring.
We will implement the pointcuts and the before and around advice altogether in one shot.
You will notice that the code structure is quite like the one we used in the aop namespace, just in this case we used annotations instead.
The @Aspect is to declare that it’s an aspect class.
In the class, we defined two pointcuts; both are annotated with @Pointcut.
We intentionally split the pointcut expression in the aop namespace example into two.
The other one (indicated by the method inMyDependency()) is to define another pointcut that defines all method executions with Spring beans’ names prefixed by myDependency.
Also note that we need to use && to define the “and” condition in the pointcut expression, while for the aop namespace, we need to use the and operator.
For both advice, we pass in the value that uses the two pointcuts defined in the class.
The before advice and around advice logic is the same as the one in the aop namespace example.
With all the annotations in place, the XML configuration becomes very simple.
We also need to annotate the advice class with @Component to indicate that it’s a Spring component.
The default is false, which means that Spring will create standard interface-based proxies using a JDK dynamic proxy.
If set to true, Spring will use CGLIB to create class-based proxies.
Running the program will yield the same results as the aop namespace example:
Considerations for Declarative Spring AOP Configuration So far, we have discussed three different ways of declaring Spring AOP configuration, including the ProxyFactoryBean, the aop namespace, and @AspectJ-style annotations.
We believe you will agree that the aop namespace is much simpler than the ProxyFactoryBean.
So, the general question is, do you use aop namespace or @AspectJ-style annotations?
If your Spring application is XML configuration based, then using the aop namespace approach is a natural choice, because it keeps the AOP and DI configuration styles consistent.
On the other hand, if your application is mainly annotation based, then use the @AspectJ annotation.
The @AspectJ annotation approach also has the advantage that all the aspect-related information is encapsulated in one module, which is easier to manage.
Moreover, there are some other differences between the aop namespace and @AspectJ annotation approaches:
The aop namespace approach supports only the “singleton” aspect instantiation model.
In the aop namespace, you can’t “combine” multiple pointcut expressions.
But you can’t do this when using the aop namespace, and you need to create a new pointcut expression that combines the matching conditions.
Note When you refer to Spring’s reference manual, you will also see another mechanism called automatic proxying.
Basically, it provides a few ways for you to define and apply the advice to a number of Spring beans within the ApplicationContext.
However, both mechanisms can now be easily handled by the powerful pointcut expression.
AspectJ Integration AOP provides a powerful solution to many of the common problems that arise with OOP-based applications.
When using Spring AOP, you can take advantage of a select subset of AOP functionality that, in most cases, allows you to solve problems you encounter in your application.
However, in some cases, you may want to use some AOP features that are outside the scope of Spring AOP.
From the joinpoint perspective, Spring AOP only supports pointcuts matching on the execution of public nonstatic methods.
However, in some cases, you may need to apply advice to protected/private methods, during object construction or field access, and so on.
In those cases, you need to look at an AOP implementation with a fuller feature set.
Our preference, in this case, is to use AspectJ, and because you can now configure AspectJ aspects using Spring, AspectJ forms the perfect complement to Spring AOP.
About AspectJ AspectJ is a fully featured AOP implementation that uses a weaving process (either compile-time or loadtime weaving) to introduce aspects into your code.
In AspectJ, aspects and pointcuts are built using a Java-like syntax, which reduces the learning curve for Java developers.
We are not going to spend too much time looking at AspectJ and how it works because that is outside the scope of this book.
Instead, we present some simple AspectJ examples and show you how to configure them using Spring.
Note We are not going to cover how to weave AspectJ aspects into your application.
Refer to the AspectJ documentation for details on how to achieve this.
Alternatively, Eclipse users can download the Eclipse AspectJ Development Tools (AJDT) and take advantage of full IDE integration and autocompilation.
Using Singleton Aspects By default, AspectJ aspects are singletons, in that you get a single instance per classloader.
The problem Spring faces with any AspectJ aspect is that it cannot create the aspect instance because that is handled by AspectJ itself.
Using the aspectOf() method and a special feature of Spring configuration, you can have Spring configure the aspect for you.
You can take full advantage of AspectJ’s powerful AOP feature set without losing out on Spring’s excellent DI and configuration abilities.
This also means you do not need two separate configuration methods for your application; you can use the same Spring ApplicationContext approach for all your Spring-managed beans and for your AspectJ aspects.
There is actually nothing particularly special or difficult about configuring AspectJ aspects using Spring, as the following example shows.
In Listing 7-31, you can see a basic class, MessageWriter, that we will advise using AspectJ.
For this example, we are going to use AspectJ to advise the writeMessage() method and write out a message before and after the method invocation.
However, if you now build the project, there will be a build error reported by AspectJ that is about the previous example, the MyAdvice class in Listing 7-28
The error is that in the @AspectJ annotation support example, we use the bean() pointcut designator, which is not supported by AspectJ.
The bean() pointcut designator is a Spring extension added to AspectJ, and the purpose is to support providing bean name as the pointcut for @AspectJ-style annotation.
To have AspectJ tooling and the bean() pointcut designator coexist, there are two options:
For the bean() pointcut designator, use the aop namespace in the XML configuration for declaration instead of the @AspectJ-style annotation.
Do not use bean() pointcut designator when you want to use AspectJ in your project.
To get rid of the error, just delete the MyAdvice class at the moment.
Essentially we create an aspect called MessageWrapper, and, just like a normal Java class, we give the aspect two properties, suffix and prefix, which we will use when advising the writeMessage() method.
Next, we define a named pointcut, doWriting(), for a single joinpoint, in this case, the execution of the writeMessage() method.
AspectJ has a huge number of joinpoints, but coverage of those is outside the scope of this example.
Finally, we define two lots of advice: one that executes before the doWriting() pointcut and one that executes after it.
The before advice writes a line containing the prefix, and the after advice writes a line containing the suffix.
Listing 7-33 shows how this aspect is configured in Spring (aspectj.xml)
As you can see, much of the configuration of the aspect bean is very similar to standard bean configuration.
The only difference is the use of the factory-method attribute of the <bean> tag.
The factory-method attribute is intended to allow classes that follow a traditional Factory pattern to be integrated seamlessly into Spring.
For instance, if you have a class Foo with a private constructor and then a static factory method, getInstance(), using factory-method allows a bean of this class to be managed by Spring.
The aspectOf() method exposed by every AspectJ aspect allows you to access the instance of the aspect and thus allows Spring to set the properties of the aspect.
Listing 7-34 shows a simple driver application for this example.
Notice that first we load the ApplicationContext to allow Spring to configure the aspect.
Next we create an instance of MessageWriter and then invoke the writeMessage() and foo() methods.
As you can see, the advice in the MessageWrapper aspect was applied to the writeMessage() method, and the prefix and suffix values specified in the ApplicationContext configuration were used by the advice when writing out the before and after messages.
Typical examples in this field are logging and security, and we have looked at these, albeit briefly, over the course of this chapter and the last.
In this section, we will give you an overview about how we use Spring AOP in the sample SpringBlog application to solve a problem involving crosscutting logic.
Filtering Obscenities in SpringBlog One of the problems we faced when building the SpringBlog application was how to filter obscenities uniformly out of postings on the blog.
This includes top-level blog entries as well as any comments made about a particular entry.
We needed to ensure that neither an entry nor a comment could be created containing obscenities and that existing entries and comments could not be modified to contain obscenities.
Specifically, we wanted the ability to obfuscate obscenities contained in postings automatically with inoffensive alternatives.
Taking this further, we decided that in some cases, the blog owner might actually want to be able to add obscenities to their entries, acting as their own moderator, but want to restrict blog readers from posting comments containing obscenities.
The traditional approach to this problem would be to define an interface (for example, an ObscenityFilter interface) and then build an implementation of this interface and make it accessible through some factory class.
Then, in each method where an entry or comment is created or modified, you invoke the ObscenityFilter to remove obscenities from the posting.
However, the main problem with this approach is that all business logic that involves processing of blog entries and comments are going to have to remember to implement this check.
Using Spring AOP, we can create a much more elegant solution to this problem by factoring the obscenity check into a before advice that we can apply to any method that accepts a blog entry or comment domain object as an argument.
An interesting point about this implementation is that, for the most part, we just followed good OOP practice as suggested in the traditional approach.
We defined an interface, ObscenityFilter, and then built an implementation.
Thanks to Spring DI, we were able to avoid the need to create a factory class, but by following good practices, we were able to build an obscenity filter that can be used equally well in both AOP and non-AOP settings.
The BlogPosting Interface Within the blog, there are two distinct types of postings: a main blog entry, represented by an Entry object, and a comment about an entry, represented by a Comment object.
Although these two objects represent different kinds of posting, they do share similar characteristics, such as body, subject, attachments, and date of posting.
For this reason, we created an interface, BlogPosting, that allows Comments and Entries to be manipulated at the same time.
Because all the String-typed properties of Comment and Entry are exposed on the BlogPosting interface, we use the BlogPosting interface in our obscenity filter advice.
Implementing ObscenityFilter For the SpringBlog application, we decided to create an implementation of ObscenityFilter that allows the list of obscenities to filter to be specified as a List and that replaces the obscenities using the ROT13 algorithm.
Because we only need to look at the arguments passed to a method and perhaps modify them, a before advice is ideal for this.
In addition, we decided to use the @AspectJ-style annotations to implement the advice.
Obscenity Filter Summary As you can see from the example in this section, AOP has plenty of practical uses in a real application.
We found that by using AOP for the obscenity filter, we were able to keep the code for the service layer of the SpringBlog application much cleaner and were also able to reduce the amount of code duplication within the application.
When you build your own applications with Spring, it is worth it to take the time to identify crosscutting logic.
Once you have done this, define the interfaces to interact with it, build the implementations, and then instead of using a factory and embedding calls against your interfaces throughout your code, use Spring AOP to weave the logic into your application transparently.
Summary In this chapter, we concluded our discussion on AOP.
We looked at the advanced options for pointcutting, as well as how to extend the set of interfaces implemented by an object using introductions.
A large part of this chapter focused on using Spring framework services to configure AOP declaratively, thus avoiding the need to hard-code AOP proxy construction logic into your code.
We spent some time looking at how Spring and AspectJ are integrated to allow you to use the added power of AspectJ without losing any of the flexibility of Spring.
In the next chapter, we move on to a completely different topic—how we can use Spring’s JDBC support to radically simplify the creation of JDBC-based data access code.
In the previous chapters, you saw how easy it is to build a fully Spring-managed application.
You now have a solid understanding of bean configuration and Aspect-Oriented Programming (AOP)—in other words, you know how to wire up the entire application using Spring.
However, one of the parts of the puzzle is missing: how do you get the data that drives the application?
Apart from simple throwaway command-line utilities, almost every application needs to persist data to some kind of data store.
The most usual and convenient data store is a relational database.
In terms of RDBMS features being provided, both databases are about the same.
MySQL is generally more widely used for web application development, especially on the Linux platform.
On the other side, PostgreSQL is friendlier to Oracle developers, because its procedural language, PL/pgSQL, is very close to Oracle’s PL/SQL language.
Even if you choose the fastest and most reliable database, you cannot afford to lose the offered speed and flexibility by using a poorly designed and implemented data access layer.
Applications tend to use the data access layer very frequently; thus, any unnecessary bottlenecks in the data access code impact the entire application, no matter how well-designed it is.
In this chapter, we show you how you can use Spring to simplify the implementation of data access code using JDBC.
We start by looking at the horrendous amount of code you would normally need to write without Spring and then compare it to a data access class implemented using Spring’s data access classes.
The result is truly amazing—Spring allows you to use the full power of human-tuned SQL queries while minimizing the amount of support code you need to implement.
Comparing traditional JDBC code and Spring JDBC support: We explore how Spring simplifies the old-style JDBC code while keeping the same functionality.
You will also see how Spring accesses the low-level JDBC API and how this lowlevel API is mapped into convenient classes such as JdbcTemplate.
Connecting to the database: Even though we do not go into every little detail of database connection management, we do show you the fundamental differences between a simple Connection and a DataSource.
Naturally, we discuss how Spring manages the DataSources and which data sources you can use in your applications.
Retrieving and mapping the data to Java objects: We show you how to retrieve data and then effectively map the selected data to Java objects.
You also learn that Spring JDBC is a viable alternative to object-relational mapping (ORM) tools.
Inserting, updating, and deleting data: Finally, we discuss how you can implement the insert, update, and delete operations so that any changes to the database you are using do not have a devastating impact on the code you have written.
In recent years, because of the explosive growth of the Internet and cloud computing technologies, a lot of purpose-specific web applications such as social networks, search engine, maps, video, and so on, have arisen.
To serve those applications’ specific data access requirements, a lot of different categories of “databases” have also been developed.
Some examples include key-value pair databases (generally referred to as NoSQL databases), graphics databases, document-centric databases, and so on.
However, a discussion of those nonrelational databases is not within the scope of this book, and we are referring to RDBMSs when we mention databases throughout this book.
Sample Data Model for Example Code Before proceeding with the discussion, we would like to introduce a very simple data model that will be used for the examples throughout this chapter, as well as the next few chapters when discussing other data-accessing techniques (we will expand the model accordingly to fulfill the needs of each topic as we go)
Each contact can have zero or more telephone numbers; in other words, it’s a one-to-many relationship between CONTACT and CONTACT_TEL_DETAIL.
A contact’s information includes their first name, last name, and date of birth, while a piece of telephone detail information includes the telephone type (mobile, home, and so on) and the corresponding phone number.
As you can see, both tables have an ID column that will be automatically assigned by the database during insert.
The unlicensed version can be used freely to create data models for free and open source databases including MySQL, PostgreSQL, HSQL, Derby, and so on.
You don’t need the plug-in to run the sample code, because the table creation scripts were provided.
Listing 8-1 shows the database creation script (which is MySQL compatible)
In later sections of this chapter, you will see examples to retrieve the data via JDBC from the database and directly map the resultset into Java objects (i.e., POJOs)
Let’s start with a very simple interface for ContactDao that encapsulates all the data access services for contact information.
In the previous interface, we define two finder methods and the insert, update, and delete methods, respectively.
Finally, to facilitate testing, let’s modify the log4j properties to turn the log level to DEBUG for all classes.
At the DEBUG level, the Spring JDBC module will output all the underlying SQL statements being fired to database so you know what is exactly going on; it is especially useful for troubleshooting SQL statement syntax errors.
Note In STS, after a Spring template project is created, STS will generate a log4j.properties file in the folder src/test/resources.
You can simply move the file into the folder src/main/resources and modify it, or you can delete the one in src/test/resources and create the log4j.properties file in the.
Exploring the JDBC Infrastructure JDBC provides a standard way for Java applications to access data stored in a database.
The core of the JDBC infrastructure is a driver that is specific to each database; it is this driver that allows Java code to access the database.
This class manages a list of drivers and provides static methods for establishing connections to the database.
This interface allows you to run SQL statements against the database.
The JDBC framework is quite complex and well-tested; however, with this complexity comes difficulty in development.
The first level of complexity lies in making sure your code manages the connections to the database.
A connection is a scarce resource and is very expensive to establish.
Generally, the database creates a thread or spawns a child process for each connection.
Also, the number of concurrent connections is usually limited, and an excessive number of open connections slows down the database.
We will show you how Spring helps manage this complexity, but before we can proceed any further, we need to show you how to select, delete, and update data in pure JDBC.
Let’s create a plain form of implementation of the ContactDao interface for interacting with the database via pure JDBC.
Keeping in mind what we already know about database connections, we take the cautious and expensive (in terms of performance) approach of creating a connection for each statement.
This greatly degrades the performance of Java and adds extra stress to the database because a connection has to be established for each query.
However, if we kept a connection open, we could bring the database server to a halt.
Listing 8-7 shows the code required for managing a JDBC connection, using MySQL as an example.
Listing 8-9 shows a main testing program with the previous DAO implementation in action.
To run the program, you need to add the dependency for MySQL Java into your project, as shown in Table 8-1
As shown in the output, the first block of lines shows the initial data.
The second block of lines shows that the new record was added.
The final block of lines shows that the newly created contact was deleted.
As you can see from Listing 8-8, a lot of code needs to be moved to a helper class or—even worseduplicated in each DAO class.
This is the main disadvantage of JDBC from the application programmer’s.
Instead, you want to concentrate on writing code that actually does what you need the DAO class to do: select, update, and delete the data.
The more helper code you need to write, the more checked exceptions you need to handle, and the more bugs you may introduce in your code.
This is where a DAO framework and Spring come in.
A framework eliminates the code that does not actually perform any custom logic and allows you to forget about all the housekeeping that needs to be performed.
In addition, Spring’s extensive JDBC support makes your life a lot easier.
Spring JDBC Infrastructure The code we discussed in the first part of the chapter is not very complex, but it is annoying to write, and because there is so much of it to write, the likelihood of coding errors is quite high.
It is time to take a look at how Spring makes things easier and more elegant.
Overview and Used Packages JDBC support in Spring is divided into the five packages detailed in Table 8-2; each handles different aspects of JDBC access.
It includes the core JDBC class, JdbcTemplate, which simplifies programming database operations with JDBC.
Several subpackages provide support of JDBC data access with more specific purposes (e.g., a JdbcTemplate class that supports named parameters) and related support classes as well.
Several subpackages provide support for embedded databases, database initialization, and various datasource lookup mechanisms.
These objects and lists are plain Java objects and therefore are disconnected from the database.
This allows Spring to recognize error codes used by the database and map them to higher-level exceptions.
Let’s start the discussion of Spring JDBC support by looking at the lowest-level functionality.
The first thing you need to do before you can even think about running SQL queries is establish a connection to the database.
The difference between a DataSource and a Connection is that a DataSource provides and manages Connections.
By looking at the class name, you can guess that it simply calls the DriverManager to obtain a connection.
You most likely recognize the bold properties in the listing.
They represent the values you normally pass to JDBC to obtain a Connection interface.
The database connection information typically is stored in a properties file for easy maintenance and substitution in different deployment environments.
Listing 8-11 shows a sample jdbc.properties from which Spring’s property placeholder will load the connection information.
You could use a DataSource in the plain JDBC code and get the same pooling benefits; however, in most cases, you would still miss a central place to configure the datasource.
Another way to configure a dataSource bean is to use JNDI.
If the application you are developing is going to run in a JEE container, you can take advantage of the container-managed connection pooling.
Starting from version 2.5, Spring provides the jee namespace, which further simplifies the configuration.
If you take the JNDI approach, you must not forget to add a resource reference (resource-ref) in the application descriptor file (see Listing 8-15)
The <root-node> is a placeholder value; you need to change it depending on how your module is packaged.
Most likely, you will need to configure the resource-ref in an application server–specific descriptor file as well.
As you can see, Spring allows you to configure the DataSource in almost any way you like, and it hides the actual implementation or location of the datasource from the rest of the application’s code.
In other words, your DAO classes do not know and do not need to know where the DataSource points.
The connection management is also delegated to the dataSource bean, which in turn performs the management itself or uses the JEE container to do all the work.
Embedded Database Support Starting from version 3.0, Spring also offers embedded database support, which automatically starts an embedded database and exposes it as a DataSource for the application.
In the previous listing, we first declared the jdbc namespace in the <beans> tag.
Within the tag, we also instruct Spring to execute the scripts specified to create the database schema and populate testing data accordingly.
Note that the order of the scripts is important, and the file that contains Data Definition Language (DDL) should always appears first, followed by the file with Data Manipulation Language (DML)
For the type attribute, we specify the type of embedded database to use.
The embedded database support is extremely useful for local development or unit testing.
Throughout the rest of this chapter, we will use the embedded database to run the sample code, so your machine doesn’t require a database to be installed in order to run the samples.
Using DataSources in DAO Classes Let’s restart with an empty ContactDao interface and a simple implementation of it.
We will add more features as we go along and explain the Spring JDBC classes as we do so.
For the simple implementation, first we will add a dataSource property to it.
The reason we want to add the dataSource property to the implementation class rather than the interface should be quite obvious: the interface does not need to know how the data is going to be retrieved and updated.
By adding get/setDataSource methods to the interface, we—in the best-case scenario—force the implementations to declare the getter and setter stubs.
Take a look at the simple JdbcContactDao class in Listing 8-18
Spring now creates the contactDao bean by instantiating the JdbcContactDao class with the dataSource property set to the dataSource bean.
It is good practice to make sure that all required properties on a bean have been set.
This way, you make sure that all required properties have been set on your JdbcContactDao.
The code we have looked at so far uses Spring to manage the data source and introduces the ContactDao interface and its JDBC implementation.
We also set the dataSource property on the JdbcContactDao class in the Spring ApplicationContext file.
Now we expand the code by adding the actual DAO operations to the interface and implementation.
Exception Handling Because Spring advocates using runtime exceptions rather than checked exceptions, you need a mechanism to translate the checked SQLException into a runtime Spring JDBC exception.
Spring’s SQL exceptions are runtime exceptions, they can be much more granular than checked exceptions.
By definition, this is not a feature of runtime exceptions, but it is very inconvenient to have to declare a long list of checked exceptions in the throws clause; hence, checked exceptions tend to be much more coarse-grained than their runtime equivalents.
At the same time, we need to add the dependency on spring-jdbc into the project, as shown in Table 8-4
To use the custom translator, we need to pass it into JdbcTemplate in the DAO classes.
Listing 8-22 shows a sample code snippet for this purpose.
Having the custom SQL exception translator in place, Spring will invoke it upon SQL exceptions detected when executing SQL statements against the database, and custom exception translation will happen when the error code is -12345
For other errors, Spring will fall back to its default mechanism for exception translation.
Don’t worry if you don’t remember reading about the JdbcTemplate class; we are going to discuss it in more detail.
In the most simplistic view, you can classify the data definition and data manipulation statements.
Data definition statements cover creating various database objects (tables, views, stored procedures, and so on)
Data manipulation statements manipulate the data and can be classified as select and update statements.
A select statement generally returns a set of rows; each row has the same set of columns.
An update statement modifies the data in the database but does not return any results.
The JdbcTemplate class allows you to issue any type of SQL statement to the database and return any type of result.
In this section, we will go through several common use cases for JDBC programming in Spring with the JdbcTemplate class.
Initializing JdbcTemplate in a DAO Class Before we discuss how to use JdbcTemplate, let’s take a look at how to prepare JdbcTemplate for use in the DAO class.
It’s very straightforward; most of the time you just need to construct the class by passing in the data source object (which should be injected by Spring into the DAO class)
Listing 8-23 shows the code snippet that will initialize the JdbcTemplate object.
The general practice is to initialize the JdbcTemplate within the set data source method so that once the data source was injected by Spring, the JdbcTemplate will also be initialized and ready for use.
That means you can also choose to initialize a single instance of JdbcTemplate in Spring’s XML configuration and have it inject into all DAO beans.
It wraps the JdbcTemplate class, and you can have your DAO classes extend the JdbcDaoSupport class.
Retrieving Single-Value-Use JdbcTemplate Class Let’s start with a simple query that returns a single value.
For example, we want to be able to retrieve the first name of a contact by its ID.
In the previous listing, we use the queryForObject() method of JdbcTemplate to retrieve the value of the first name.
The first argument is the SQL string, and the second argument consists of the parameters to be passed to the SQL for parameter binding in object array format.
The last argument is the type to be returned, which is String in this case.
Besides Object, you can also query for other types like Long and Integer.
As you also see, we need to pass the parameters as an Object array.
When using a normal placeholder, the order is very important, and the order that you put the parameters into the array should be the same as the order of the parameters in the query.
Some developers (like me) prefer to use named parameters to ensure that the parameter is being bound exactly as wanted.
For example, this time we want to add another method to find the last name by ID, so let’s add the method to the ContactDao interface:
First, you will see that instead of the ? placeholder, the named parameter (prefix by a semicolon) was used instead.
Second, a SqlParameterSource was initialized, which is a Map-based SQL parameter source with the key as the named parameter’s name and the value as the value of the parameter.
To test the code, just add the method into the main testing class in Listing 8-25 and run it.
Retrieving Domain Objects with RowMapper<T> Rather than retrieving a single value, most of the time you will want to query one or more rows and then transform each row into the corresponding domain object.
Let’s see it in action by implementing the findAll() method of the ContactDao interface using the RowMapper<T> interface.
In the previous listing, we define a static inner class called ContactMapper that implements the RowMapper<T> interface.
The class needs to provide the mapRow() implementation, which transforms the values in a specific record of the resultset into the domain object you want.
Making it a static inner class allows you to share the RowMapper<T> among multiple finder methods.
Afterward, the findAll() method just needs to invoke the query method and pass in the query string and the row mapper.
In case the query requires parameters, the query() method provides a overload that accepts the query parameters.
Running the program yields the following result (other outputs were omitted):
The previously mentioned RowMapper<T> is suitable only for row base mapping to a single domain object.
For a more complicated object structure, we need to use the ResultSetExtractor interface.
The method should populate the list of contacts with their telephone details.
The code looks quite like the RowMapper sample, but this time we declare an inner class that implements ResultSetExtractor.
Then we implement the extractData() method to transform the resultset into a list of Contact objects accordingly.
The result is a Cartesian product of the two tables.
Run the testing program again, and it will yield the following output (other outputs were omitted):
You can see the contacts and their telephone details were listed accordingly.
The data is based on the data population scripts in Listing 8-2
So far, you have seen how to use JdbcTemplate to perform some common query operations.
However, the update() method is quite self-explanatory, so we decide not to cover it in this section.
On the other side, as you will see in later sections, we will use the Spring-provided SqlUpdate class to perform data update operations.
Spring Classes That Model JDBC Operations In the preceding section, you saw how JdbcTemplate and the related data mapper utility classes had greatly simplified the programming model in developing data access logic with JDBC.
Built on top of JdbcTemplate, Spring also provides a number of useful classes that model JDBC data operations and let developers maintain the query and transformation logic from resultset to domain objects in a more object-oriented fashion.
SqlUpdate: The SqlUpdate class allows you to wrap any SQL update statement into it.
It also provides a lot of useful functions for you to bind SQL parameters, retrieve the RDBMS-generated key after a new record is inserted, and so on.
BatchSqlUpdate: As the name implies, the class allows you to perform batch update operations.
For example, you can loop through a Java List object and have the BatchSqlUpdate queue up the records and submit the update statements for you in a batch.
You can set the batch size and flush the operation anytime as you want.
Another class, StoredProcedure, also exists that helps you invoke stored procedures.
Note In previous sections, all the sample code uses the XML type configuration.
So, in the following sections, we will use Spring annotations for ApplicationContext configuration.
Setting Up JDBC DAO Using Annotations First let’s take a look on how to set up the DAO implementation class using annotations first.
Listing 8-32 shows the ContactDao interface class with a more complete listing of the data access services it provides.
We also declare the log variable using Apache commons-logging to log the message within the program.
In the next screen, all methods under the ContactDao interface should be already checked, as shown in Figure 8-3
Just click OK, and an empty implementation of all the selected methods will be created automatically.
Afterward, you will see the empty implementation methods were generated.
Having the infrastructure in place, we can now proceed to the implementation of JDBC operations.
Basically, we construct a MappingSqlQuery<T> class using the data source and the query string.
On the other hand, we implement the mapRow() method to map each resultset record into the corresponding domain object.
We begin by creating the SelectAllContacts class (which represents the query operation for selecting all contacts) that extends the MappingSqlQuery<T> abstract class.
In Listing 8-35, within the SelectAllContacts class, the SQL for selecting all contacts is declared.
In the class constructor, the super() method is called to construct the class, using the DataSource as well as the SQL statement.
Having the SelectAllContacts class in place, we can implement the findAll() method in the JdbcContactDao class.
In Listing 8-36, in the setDataSource() method, upon the injection of the DataSource, an instance of the SelectAllContacts class is constructed.
Listing 8-37 shows the sample program to test the logic.
In STS, since we set the logging properties to the DEBUG level, from the console output, you will also see the query that was submitted by Spring (see Figure 8-4)
Let’s proceed to implement the findByFirstName() method, which takes one named parameter.
First, the SQL statement is different and carries a named parameter called first_name.
Let’s proceed to implement the findByFirstName() method in the JdbcContactDao class.
Afterward, in the findByFirstName() method, a HashMap is constructed with the named parameters and values.
Running the program will produce the following output from the findByFirstName() method:
One point worth noting here is that MappingSqlQuery<T> is suitable only for mapping a single row to a domain object.
Listing 8-41 shows the UpdateContact class that extends the SqlUpdate class for update operation.
An instance of SqlUpdate class is constructed with the query, and the named parameters are declared too.
Listing 8-42 shows the implementation of the update() method in the JdbcContactDao class.
In Listing 8-42, upon data source injection, an instance of UpdateContact is constructed (note the lines in bold)
In Listing 8-43, we simply construct a Contact object and then invoke the update() method.
Running the program will produce the following output from the last listContacts() method:
In the output, you can see that the contact with an ID of 1 was updated accordingly.
However, one interesting point here is about the primary key, the id column, which will be available only after the insert statement has completed, while the RDBMS generated the identity value for the record.
The column ID was declared with the attribute AUTO_INCREMENT and is the primary key, which means the value was assigned by the RDBMS during the insert operation.
If you are using Oracle, you will probably get an unique ID first from an Oracle sequence and then fire the insert statement with the query.
However, for our case, how can we retrieve the key generated by the RDBMS after the record is inserted?
In old versions of JDBC, the method is a bit tricky.
We start by creating the InsertContact class for the insert operation, which extends the SqlUpdate class.
The InsertContact class is almost the same as the UpdateContact class.
Listing 8-45 shows the implementation of the insert() method in the JdbcContactDao class.
From Listing 8-45, upon data source injection, an instance of InsertContact was constructed (note the lines in bold)
However, we also pass in an instance of KeyHolder to the method, which will have the generated ID stored.
After the data is inserted, we can then retrieve the generated key from the KeyHolder.
Running the program will produce the following output from the last listContacts() method:
You can see that the new contact was inserted with an ID of 4 and retrieved correctly.
The use is basically the same as the SqlUpdate class; we just need to do a few more things.
To demonstrate its usage, let’s add a new method into the ContactDao interface:
The new insertWithDetail() method will insert both the contact and its telephone details into the database.
Listing 8-48 shows the implementation of the insertWithDetail() method in the JdbcContactDao class.
The reason is that the BatchSqlUpdate class is not thread safe.
However, the BatchSqlUpdate class will queue up the insert operations and submit to the database in batch.
Every time the number of records equals the batch size, Spring will fire a bulk insert operation to the database for the pending records.
Running the program will produce the following output from the last listContacts() method:
You can see that the new contacts with the telephone details were all inserted into the database.
In this section, we will show you a simple function using the SqlFunction class to call a SQL function in the database.
We will use MySQL as an example, create a stored function, and call it using the SqlFunction<T> class.
It simply accepts the ID and returns the first name of the contact record with the ID.
Let’s create a new interface called ContactSfDao for this example.
The second step is to create the SfFirstNameById class to represent the stored function operation, which extends the SqlFunction<T> class.
Then we declare the SQL to call the stored function in MySQL.
Afterward, in the constructor, the parameter is declared, and then we compile the operation.
Now the class is ready for our use in the implementation class.
Listing 8-53 shows the JdbcContactSfDao class, which implements the ContactSfDao interface.
In Listing 8-53, upon data source injection, an instance of SfFirstNameById is constructed.
Then in the getFirstNameById() method, its execute() method was called, passing in the contact ID.
The method will return a list of Strings, and we need only the first one, because there should be only one record returned in the resultset.
To run the program, the dependency on commons-dbcp should be added to the project, as shown in Table 8-5
In the program, we pass an ID of 1 into the stored function.
This will return Clarence as the first name if you ran the test-data.sql against the MySQL database.
You can see that the first name was retrieved correctly.
What is presented here is just a simple sample to demonstrate Spring JDBC module’s functions.
Spring also provides other classes (e.g., StoredProcedure) for you to invoke complex stored procedures that return complex data types.
We recommend you refer to Spring’s reference manual in case you need to access stored procedures using JDBC.
Using the Java Configuration In case you prefer using the Java configuration class instead of the XML configuration, Listing 8-56 shows the Spring configuration class.
You can also use the @Profile feature to specify that the configuration is the target only for a specific environment (for example, dev)
Spring Data Project: JDBC Extensions As mentioned at the beginning of this chapter, in recent years database technology has evolved so quickly with the rise of so many purpose-specific databases, nowadays RDBMS is not the only choice as an application’s backend database management system.
The major objective of the project is to provide useful extensions on top of Spring’s core data access functionality to address the needs of Spring developers who are interacting with database backends other than RDBMSs.
Advanced features to data access standards (e.g., JDBC, JPA) are also provided.
The Spring Data project comes with a lot of extensions.
As its name implies, the extension provides some advanced features to facilitate the development of JDBC applications using Spring.
At the time of writing, the first release (version 1.0.0) is still in its milestone stage.
The main features that the extension provides are listed here:
Advanced support for Oracle Database: The extension provides a lot of advanced features for Oracle Database users.
On the database connection side, it supports Oracle-specific session settings, as well as Fast Connection Failover technology when working with Oracle RAC.
Also, classes that integrate with Oracle Advanced Queueing are provided.
On the data-type side, native support for Oracle’s XML types, STRUCT and ARRAY, and so on, are provided.
If you are developing JDBC applications using Spring with Oracle Database, the JDBC Extensions is really worth a look.
Considerations for Using JDBC From the previous discussions, you can see how Spring can make your life much easier when using JDBC to interact with the underlying RDBMS.
However, there is still quite a lot of code you need to develop, especially when transforming the resultset into the corresponding domain objects.
On top of JDBC, a lot of open source libraries have been developed to help close the gap between the relational data structure and Java’s OO model.
For example, MyBatis (formerly known as iBATIS) is a popular DataMapper framework that is also based on SQL mapping.
MyBatis lets you map objects with stored procedures or queries to an XML descriptor file (Java annotation is supported too)
Like Spring, MyBatis provides a declarative way to query object mapping, greatly saving you the time it takes to maintain SQL queries that may be scattered around various DAO classes.
There are also many other ORM frameworks that focus on the object model, rather than the query.
In recent years, those ORM tools and mapping frameworks have become much more mature so that most developers will settle on one of them, instead of using JDBC directly.
However, in cases where you need to have absolute control over the query that will be submitted to the database for performance purposes (e.g., using a hierarchical query in Oracle), Spring JDBC is really a viable option.
And when using Spring, one great advantage is that you can mix and match different data access technologies.
For example, you can use Hibernate as the main ORM and then JDBC as a supplement for some of the complex query logic or batch operations; you can mix and match them in a single business operation and then wrap them under the same database transaction.
Summary This chapter showed you how to use Spring to simplify JDBC programming.
You learned how to connect to a database and perform selects, updates, deletes, and inserts, as well as call stored functions.
How to use the core Spring JDBC class, JdbcTemplate, was discussed in detail.
In addition, we covered other Spring classes that are built on top of JdbcTemplate and that help you model various JDBC operations.
In the next few chapters, we will discuss how to use Spring with popular ORM technologies when developing data access logic.
In the previous chapter, you saw how to use JDBC in Spring applications.
However, even though Spring goes a long way toward simplifying JDBC development, you still have a lot of code to write.
In this chapter, we cover one of the object-relational mapping (ORM) libraries that has wide support in Spring—Hibernate.
If you have experience developing data access applications using EJB entity beans (prior to EJB 3.0), you may remember the painful process.
Tedious configuration of mappings, transaction demarcation, and much boilerplate code in each bean to manage its life cycle greatly reduced the productivity when developing enterprise Java applications.
Just like Spring was developed to embrace POJO base development and declarative configuration management rather than EJB’s heavy and clumsy setup, the developer community realize that a simpler, lightweight, and POJO base framework could ease the development of data access logic.
Since then, many different libraries have appeared; they are generally referred to as ORM libraries.
The main objective of an ORM library is to close the gap between the relational data structure in the RDBMS and the OO model in Java so that developers can focus on programming with the object model and at the same time easily perform actions related to persistence.
Of the ORM libraries available in the open source community, Hibernate is one of the most successful.
Its features, such as POJO base approach, ease of development, and support of sophisticated relationship definitions, have won the heart of the mainstream Java developer community.
Hibernate’s popularity has also affected the JCP, which developed the Java Data Objects (JDO) specification as one of the standard ORM technologies in Java EE.
Starting from EJB 3.0, the EJB entity bean was even replaced with the Java Persistence API (JPA), within which a lot of the ideas were influenced by popular ORM libraries such as Hibernate, TopLink, and JDO.
Gavin King, the founder of Hibernate, represented JBoss as one of the JCP expert group members in defining the JPA specification.
Starting from version 3.2, Hibernate has provided an implementation of JPA.
So, when you develop applications with Hibernate, you can choose to use either Hibernate’s own API or the JPA with Hibernate as the persistence service provider.
Having discussed a rough history of Hibernate, this chapter will cover how to use Spring with Hibernate when developing data access logic.
Hibernate is such an extensive ORM library, so covering every aspect of Hibernate in just one chapter is simply not possible, and numerous books are dedicated to discussing Hibernate.
This chapter will cover the basic ideas and main use cases of using Hibernate in Spring.
In particular, we are going to discuss the following topics:
Configuring the Hibernate SessionFactory: The core concept of Hibernate revolves around the Session interface, which is managed by the SessionFactory.
We will discuss how to configure Hibernate’s session factory to work in a Spring application.
Major concepts of ORMs using Hibernate: We will go through the major concepts of how to use Hibernate to map a POJO to the underlying relational database structure.
Some commonly used relationships, including one-to-many and manyto-many, will also be discussed.
Data operations: We will go through a number of examples of how to perform data operations (query, insert, update, delete) using Hibernate in the Spring environment.
When working with Hibernate, its Session interface is the major interface that we will interact with.
Nowadays, the annotation approach is a much more popular one.
So, in this chapter, we will focus on using the annotation approach for object-relational mapping.
For the mapping annotation, we will use the JPA standards.
Create a Hibernate Utility Project in STS Just like Spring, Hibernate is a big library and is packaged into a number of modules (such as Hibernate Core, Entity Manager, and so on)
Sometimes you may find it difficult to identify which Hibernate modules are required in your application.
Fortunately, STS provides a simple way for you to create common types of projects based on Spring, and a template project with Hibernate is also provided.
Then, enter the project name and top-level package name, as in Figure 9-2
Upon completion, STS will create a Maven-based project with the required dependencies.
When you take a look at the file pom.xml (which is the Maven’s project object model file) in the project’s root folder, you will see Spring has added a dependency to the project.
When compared to a simple Spring utility project, just one dependency is added.
However, thanks to Maven’s transitive dependencies feature, all the other required dependencies will be discovered and added by Maven into the project automatically.
In STS, if you open pom.xml, the POM file editor will be displayed, and when you click the tab Dependencies Hierarchy, you will see the rest of the dependencies required by Hibernate (see Figure 9-3)
So, you will have a quick understanding of what is being included in your project.
However, for a production application, you may still need to fine-tune the pom.xml file to make sure that only the libraries and their correct versions were included.
Sample Data Model for Example Code In Chapter 8, you saw a simple data model for demonstrating the code samples.
In this chapter, in order to demonstrate some of the more complicate relationships, we will extend the data model a bit.
Figure 9-4 shows the data model that will be used in this chapter.
On the other hand, a VERSION column was added to the CONTACT and CONTACT_TEL_DETAIL tables for optimistic locking, which we will discuss in detail later.
In the examples in this chapter, we will use the embedded H2 database, so the database name is not required.
Configuring Hibernate SessionFactory As mentioned earlier in this chapter, the core concept of Hibernate is based on the Session interface, which is obtained from the SessionFactory.
Spring provides a number of classes to support the configuration of Hibernate’s session factory as a Spring bean with the desired properties.
In the previous configuration, several beans were declared in order to be able to support Hibernate’s session factory.
The dataSource bean: We declared the data source with an embedded database using H2
The transactionManager bean: The Hibernate session factory requires a transaction manager for transactional data access.
By default, Spring will look up the bean with the name transactionManager within its ApplicationContext whenever transaction management is required.
Hibernate SessionFactory bean: The sessionFactory bean is the most important part.
First, as you might expected, we need to inject the data source bean into the session factory.
There are many configuration parameters, and we define only several important properties that should be provided for every application.
Table 9-1 lists the major configuration parameters for the Hibernate session factory.
This setting prevents Hibernate from fetching too much data with a lot of nested associations.
For example, a query was submitted to the database, and the resultset contains 500 records.
This is very useful for performing batch job operations in Hibernate.
Obviously, when we are doing a batch job updating hundreds of thousands of records, we would like Hibernate to group the queries in batches, rather than submit the updates one by one.
You should turn this on in a development environment, which can greatly help in the testing and troubleshooting process.
For the full list of properties that Hibernate supports, please refer to Hibernate’s reference manual (http://docs.jboss.org/hibernate/core/3.6/reference/en-US/html/session-configuration.html)
The first one is to design the object model first and then generate the DB scripts based on the object model.
The second approach is to start with the data model first and then model the POJOs with the desired mappings.
We prefer the latter approach, because we can have more control on the data model, which is very useful in optimizing the performance of data access.
Based on the data model, Figure 9-5 shows the corresponding OO model with a class diagram.
You can see there is a one-to-many relationship between Contact and ContactTelDetail, while there’s a many-to-many relationship between the Contact and Hobby objects.
Simple Mappings Let’s begin with the mapping of simple attributes first.
From the class diagram, there exists simple attributes in all three classes.
Listing 9-5 shows the Contact class with the mapping annotations.
First, we annotate the type with @Entity, which means that this is a mapped entity class.
The @Table annotation defines the table name in the database that this entity was being mapped to.
For each mapped attribute, we annotate with the @Column annotation, with the column names provided.
You can skip the table and column names in case the type and attribute names are exactly the same as the table and column names.
About the mappings, we would like to highlight a few points:
For the birth date attribute, we annotate it with @Temporal, with the TemporalType DATE assigned.
So, we can access the attribute birthDate in Contact object using java.util.Date as usual in our application.
Hibernate will use it as the unique identifier when managing the contact entity instances within its session.
On the other hand, the @GeneratedValue annotation tells Hibernate how the id value was generated.
The IDENTITY (we can use it directly within the annotation because of the import static statement) strategy means that the id was generated by the backend (the ID column of the CONTACT table is the primary key, with AUTO_INCREMENT specified, which means that the value will be generated and assigned by the database during insert operation) during insert.
This instructs Hibernate that we would like to use an optimistic locking mechanism, using the version attribute as a control.
Every time Hibernate updates a record, it will compare the.
If both versions are the same, it means that no one updated the data before, and Hibernate will update the data and increment the version column.
In the example, we used an integer for version control.
Instead of an integer, Hibernate supports using a timestamp as well.
However, using an integer for version control is recommended because when using an integer, Hibernate will always increment the version number by 1 after each update.
When using timestamp, Hibernate will update the latest timestamp after each update.
A timestamp is slightly less safe, because two concurrent transactions may both load and update the same item in the same millisecond.
Another mapped object is ContactTelDetail, which is shown in Listing 9-6
Let’s proceed to see how we model the associations between the Contact and ContactTelDetail classes.
One-to-Many Mappings Hibernate has the capability to model a lot of different kinds of associations.
For each Contact, they will have zero or more telephone numbers, so it’s a one-to-many association (in ORM terms, the one-to-many association is used to model both zero-to-many and one-to-many relationships within the data structure)
Listing 9-8 shows the code snippet for the Contact class for mapping with the ContactTelDetail class.
The mappedBy attribute indicates the property in the ContactTelDetail class that provides the association (i.e., linked up by the foreign key definition in the CONTACT_TEL_DETAIL table)
The cascade attribute means that update operation should cascade to the child.
The orphanRemoval means that after the contact telephone details have been updated, those entries that no longer exist in the set should be deleted from the database.
Listing 9-9 shows the corresponding code snippet in the ContactTelDetail class for the association mapping.
From the previous listing, we annotated the getter method of the contact attribute with @ManyToOne, which indicates it’s the other side of the association from Contact.
We also specified the @JoinColumn annotation for the underlying foreign key column name.
Finally, the toString() method was overridden to facilitate testing the example code later.
Many-to-Many Mappings Let’s move on to see the many-to-many mapping between the Contact and Hobby classes.
Every contact has zero or more hobbies, and each hobby will also be linked up with zero or more contacts.
Listing 9-10 shows the code snippet in the Contact class to model the relationship.
We also provide the @JoinTable to indicate the underlying join table that Hibernate should look for.
The name is the join table’s name, the joinColumns defines the column that is the FK to CONTACT table, and the inverseJoinColumns defines the column that is the FK to the other side of the association, i.e., the HOBBY table.
Listing 9-11 shows the corresponding code snippet in the Hobby class.
The mapping is more or less the same as Listing 9-10, but the joinColumns and inverseJoinColumns attributes are reversed to reflect the association.
The Hibernate Session Interface In Hibernate, when interacting with the database, the major interface you need to deal with is the Session interface, which is obtained from the SessionFactory.
Listing 9-12 shows that the ContactDaoImpl class contains the samples in this chapter.
As usual, we declare the DAO class as a Spring bean with data access logic using the @Repository annotation.
The sessionFactory attribute was set to be injected by using the @Resource annotation.
Database Operations with Hibernate In this section, we will discuss how to perform database operations in Hibernate.
Listing 9-13 shows the ContactDao interface, which indicates the contact data access services we are going to provide.
The interface is very simple; it has just three finder methods, one save method, and one delete method.
The save() method will perform both the insert and update operations.
So, after the mappings are defined, we don’t need to construct SQL to interact with the database.
Instead, for Hibernate, we use the Hibernate Query Language (HQL) to define our queries.
When interacting with the database, Hibernate will translate the queries into SQL statements on our behalf.
When coding HQL queries, the syntax is quite like SQL.
However, you need to think on the object side rather than data side.
We will go through several examples in the following sections.
Simple Query with Lazy Fetching Let’s begin with the findAll() method, which simply retrieves all the contacts from the database.
The statement from Contact c simply retrieves all contacts from the database.
An alternative syntax for the statement is select c from Contact c.
Setting that attribute for finder methods will result in better performance.
However, what about the telephone and hobby details? Let’s create a new method in the testing class to dump the details information.
If you run the program again, you will see the following exception:
The rationale behind this is for performance consideration, since as you can imagine, if a query is retrieving thousands of records and all the associations were retrieved, there will be a massive amount of data transfer.
Query with Associations Fetching To have Hibernate fetch the data from associations, there are two options.
First, you can define the association with the fetch mode EAGER.
This tells Hibernate to fetch the associated records in every query.
The other option is to force Hibernate to fetch the associated records in the query when required.
When using NamedQuery, you can use the “fetch” operator to instruct Hibernate to fetch the association eagerly.
The NamedQuery can be externalized into an XML file or declared using annotation in the entity class.
Listing 9-17 shows the revised Contact domain object with the named query defined using annotations.
Pay attention to the left join fetch clause, which instructs Hibernate to fetch the association eagerly.
Listing 9-19 shows the Contact class with the new named query added.
Listing 9-20 shows the implementation of the findById() in ContactDaoImpl.
But then we also call the setParameter() method, passing in the named parameter with its value.
For multiple parameters, you can use the setParameterList() or setParameters() method of the Query interface.
There also exists some more advanced query methods, like native query and criteria query, which we will discuss in the next chapter when we talk about JPA.
Running the program will produce the following output (other output was omitted):
One other fancy thing is retrieving the database-generated primary key.
In the previous chapter on JDBC, we needed to explicitly declare that we wanted to retrieve the generated key, pass in the KeyHolder, and get the key back from it after executing the insert statement.
Hibernate will cleverly retrieve the generated key and populate the domain object after insert.
We also log the ID of the saved contact object that will be populated by Hibernate after the object is persisted.
Listing 9-23 shows the code snippet for inserting a new contact record.
As shown in Listing 9-23, we create a new contact, add two telephone details, and save the object.
From the INFO log record, you can see that the id of the newly saved contact was populated correctly.
Hibernate will also show all the SQL statements being fired to the database so you know what is actually happening behind the scenes.
Updating Data Updating a contact is as easy as inserting data.
Suppose for the contact with an ID of 1, we want to update its first name and remove the home telephone record.
Then we loop through the telephone objects, retrieve the one with type "Home", and remove it from the contact’s telephone detail property.
When you run the program, you will see the following output (the other output was omitted):
You will see the first name was updated, and the home telephone was removed.
The telephone can be removed because of the orphanRemoval=true attribute we pass into the one-to-many association, which instructs Hibernate to remove all orphan records that exist in the database but are no longer found in the object when persisted.
Just call the Session.delete() method and pass in the contact object.
Listing 9-26 shows the code snippet for testing the delete method.
The previous listing retrieves the contact with an ID of 1 and then calls the delete method to delete the contact information.
Running the program will produce the following output (other output was omitted):
You can see that the contact with an ID of 1 was deleted.
In the past few years, Hibernate has been evolving quickly and has been widely adopted by Java developers as the data access layer library, both in the open source community and in enterprises.
However, there are some points you need to bear in mind.
First, because you don’t have control over the generated SQL, you should be very careful when defining the mappings, especially the associations and their fetching strategy.
Then observe the SQL statements generated by Hibernate to verify that all perform as you expect.
Understanding the internal mechanism of how Hibernate manages its session is also very important, especially in batch job operations.
Hibernate will keep the managed objects in session and will flush and clear them regularly.
Poorly designed data access logic may cause Hibernate to flush the session too frequently and greatly impact the performance.
If you want absolute control over the query, you can use a native query, which we will discuss in next chapter.
You should define them in your session factory and adjust them while load testing your application to identify the optimal value.
After all, Hibernate, and its excellent JPA support that we will discuss in next chapter, is a natural decision for Java developers looking for an OO way to implement data access logic.
Summary In this chapter, we discussed the basic concepts of Hibernate and how to configure it within a Spring application.
Then we covered common techniques for defining ORM mappings, and we covered associations and how to use the HibernateTemplate class to perform various database operations.
With regarding to Hibernate, we covered only a small piece of its functionalities and features.
For those interested in using Hibernate with Spring, we highly recommend you study Hibernate’s standard documentation.
In the next chapter, we will take a look at the Java Persistence API (JPA) and how to use it when using Spring.
Hibernate provides excellent support for JPA, and we will continue to use Hibernate as the persistence provider for the examples in next chapter.
So, in the next chapter, we will discuss some advanced topics including native and criteria query and how we use Hibernate and its JPA support in the sample application.
In the previous chapter, we discussed how to use Hibernate in Spring applications when implementing data access logic with the ORM approach.
We demonstrated how to configure Hibernate’s SessionFactory in Spring’s configuration and how to use Hibernate’s Session interface for various data access operations.
However, what we discussed in the previous chapter was just one aspect of Hibernate’s usage.
Another way of adopting Hibernate in a Spring application is to use Hibernate as a persistence provider of the JCP standard, the Java Persistence API (JPA)
As discussed earlier, Hibernate’s POJO base mapping and its powerful query language (HQL) have gained great success and have influenced the development of data access technology standards in the Java world.
The Spring Data project also provides a subproject called Spring Data JPA, which provides advanced support for using JPA in Spring applications.
The main features of the Spring Data JPA project include the concepts of Repository and Specification, support for the Query Domain Specific Language (QueryDSL), and so on.
In this chapter, we will discuss how to use JPA (specifically JPA 2) with Spring, using Hibernate as the underlying persistence provider.
You will learn how to implement the various database operations using JPA’s EntityManager interface and JPQL (which is similar to HQL)
Then we will discuss how Spring Data JPA can further help simplify JPA development.
Finally, we will discuss some advanced topics related to ORM, including native queries and criteria queries.
Core concepts of JPA: We will cover some of the major concepts of JPA.
Creating a simple Spring JPA utility project: We will go through the steps for creating a Spring-based JPA project using STS.
Although STS creates the project with required dependencies, we still need to fine-tune the project configurations in order to support all the features discussed in this chapter.
As we move on to more advanced topics, additional third-party libraries will be required, so we will demonstrate how to add them in STS.
Data operations: We will go through how to implement basic database operations in JPA.
We will also discuss eliminating the DAO layer in JPA applications.
Advanced query operations: We will discuss how to use native queries in JPA and the strongly typed criteria API in JPA for more flexible query operations.
Introducing Spring Data JPA: We will discuss the Spring Data JPA project and demonstrate how it can help simplify the development of data access logic.
Tracking entity changes and auditing: In database update operations, it’s a common requirement in keep track of the date an entity was created or last updated and who made the change.
Also, for critical information such as a customer, a history table that stores each version of the entity is always required.
Using JPA with Hibernate in the sample application: In the sample application, for the JPA implementation, we have chosen to eliminate the DAO layer and inject the entity manager directly into the service layer for executing the business logic.
We will discuss how JPA will be adopted in the sample application.
Note Like Hibernate, JPA supports the definition of mappings either in XML or in Java annotations.
In this chapter, we will focus on the annotation type of mapping, because its usage is much more popular than the.
When programming to the JPA standard, developers have the option of switching the underlying provider at will, just like switching to another JEE-compliant application server for applications developed on the JEE standards.
The main job of EntityManager is to maintain a persistence context, in which all the entity instances under management will be stored.
The configuration of an EntityManager is defined as a persistence unit, and there can be more than one persistence unit in an application.
In Hibernate, the managed entities are stored in the session, which you can directly interact with via Hibernate’s SessionFactory or Session interface.
However, in JPA, you can’t interact with the persistence context directly.
Instead, you need to rely on EntityManager to do the work for you.
However, in JPA 2, a strongly typed criteria API was introduced, which relies on the.
In this section, we will discuss the basic concepts of JPA, the sample data model that will be used in this chapter, and how to configure Spring’s ApplicationContext to support JPA.
Upon completion, STS will create a Maven-based project with the required dependencies.
If you open the project’s pom.xml file, you will see the default dependencies defined for the project.
Figure 10-3 shows a partial listing of the dependencies in STS.
As you can see from Figure 10-3, Spring defaults to using Hibernate as the JPA provider for the JPA template project.
Another step you need to take is to update the pom.xml file to use JDK 6 as the target runtime and update the project’s configuration.
At the time of this writing, the JPA template project will add Hibernate version 3.6.0.Final as the dependency.
Please change it to 3.6.8.Final within the pom.xml file, since the newer version provides bug fixes to the samples discussed in this chapter.
However, when we discuss how to implement the auditing features, we will add a few columns and a history table for demonstration.
So, we will start with the same database creation scripts used in the previous chapter.
If you skipped Chapter 9, take a look at the data model presented in that chapter’s “Sample Data Model for Example Code” section, which can help you understand the sample code in this chapter.
It’s the simplest one, which requires only the persistence unit name.
However, since it doesn’t support the injection of a datasource and hence isn’t able to participate in global transactions, it’s suitable only for simple deployment.
The second option is for use in a JEE 6–compliant container, in which the application server bootstraps the JPA persistence unit based on the information in the deployment descriptors, so Spring will be able to look up the entity manager via JNDI lookup.
Listing 10-1 shows a code snippet for looking up an entity manager via JNDI.
However, Spring 3.1 provides a new feature that eliminates this need.
It supports the injection of a datasource and can participate in both local and global transactions.
The dataSource bean: We declared the datasource with an embedded database using H2
Because it’s an embedded database, the database name is not required.
The transactionManager bean: The entity manager factory requires a transaction manager for transactional data access.
The bean is declared with an ID of transactionManager assigned.
First, as you might expected, we need to inject the datasource bean.
Finally, the jpaProperties property provides configuration details for the persistence provider, Hibernate.
For the mapping annotations, they are so close that the annotations we used in Chapter 9 for mapping the domain objects to the database are the same in JPA.
Please refer to Chapter 9 for the mappings and explanations.
The intention of the DAO pattern is to wrap the different implementations of data access logic into its own layer so that those details are totally hidden from the service layer and the service layer is not aware of whether we are using JDBC or Hibernate in getting the data access job done.
However, after JPA was born, the justification of the existence of a DAO layer for data access logic becomes questionable.
Because JPA was designed to be a standard in which the underlying persistence provider can be switched easily, there’s simply no strong reason to maintain the data access logic in a separate DAO layer.
So, nowadays, many JEE developers who standardized on JPA as the data access layer have chosen to eliminate the DAO layer and have the EntityManager directly injected into the service layer.
The justification of the existence of a DAO layer in JEE applications is still under hot debate, but one fact is that getting rid of the DAO layer simplifies the application architecture a lot, which is one of the main benefits.
In this chapter and in the sample application, we have chosen to eliminate the DAO layer for the JPA implementation and instead provide the implementation of service layer by directly injecting the entity manager into the service layer classes.
However, it will not make a big difference if you or your development team still prefer the existence of the DAO layer.
You can still program all the JPA logic into a separate DAO layer and have it injected into the service layer.
Injecting EntityManager into Service Layer Classes For JDBC and Hibernate support, Spring provides the corresponding template classes JdbcTemplate and HibernateTemplate (although they are explicitly deprecated in favor of using Hibernate’s Session interface directly, as we discussed in Chapter 9), which greatly simplifies the code we need to develop.
For JPA, Spring also used to provide the JpaTemplate class.
However, as JPA 2 has become much more mature, the Spring development team has found that it is unnecessary to provide such a template.
Listing 10-3 shows the code snippet for the ContactServiceImpl class, which we will use as the sample for performing database operations using JPA.
As shown in Listing 10-3, several annotations were applied to the class.
The @Service annotation is to identify that it’s a Spring component that provides business services to another layer and assigns the Spring bean the name jpaContactService.
As you will be already familiar, the @Transactional annotation is for defining transaction requirements.
If you have multiple persistence units in your application, you can also add the unitName attribute to the annotation to specify which persistence unit you want to be injected.
Upon the injection of EntityManager, we are now ready to perform database operations, which will be discussed in the next section.
Database Operations with JPA In this section, we will discuss how to perform database operations in JPA.
Listing 10-4 shows the ContactService interface, which indicates the contact information services we are going to provide.
The interface is very simple; it has just three finder methods, one save method, and one delete method.
The save method will serve both the insert and update operations.
Query Data Using the Java Persistence Query Language The syntax for JPQL and HQL is very similar, and in fact, all the HQL queries that we used in Chapter 9 are reusable to implement the three finder methods within the ContactService interface.
Let’s recap the named queries defined for the Contact entity class.
When you compare the queries with those in Chapter 9, you will find no difference at all.
So, if you are using Hibernate, migrating to JPA is relatively easy.
Let’s begin with the findAll() method, which simply retrieves all the contacts from the database.
Note For associations, the JPA specification states that, by default, the persistence providers must fetch the association eagerly.
However, for Hibernate’s JPA implementation, the default fetching strategy is still lazy.
The default fetching strategy of Hibernate is different from the JPA specification.
It’s the same as the findAll() method, but it uses a different named query with left join fetch enabled.
Listing 10-9 shows the revised testing program to list the contact details.
If you run the program again, you will see the following output:
Let’s see the findById() method, which demonstrates how to use a named query with named parameters in JPA.
We will leave the testing of the method as an exercise for you.
Query with Untyped Results In many cases, you would like to submit a query to the database and manipulate the results at will, instead of storing them in a mapped entity class.
One typical example is a web-based report that lists only a certain number of columns across multiple tables.
For example, say you have a web page that shows the summary information of all the contact information.
The summary information contains each contact’s first name, last name, and home telephone number only.
Those contacts without home telephone numbers will not be listed.
In this case, we can implement the function with a query and manually manipulate the resultset.
When we explicitly specify the columns to be selected within JPQL, JPA will return an iterator, and each item within the iterator is an array of objects.
Then we loop through the iterator, and for each value in the object array, the value is displayed.
Each object array corresponds to a record within the resultset.
In JPA, there is a more elegant solution rather than playing around with the object array returned from the query, which will be discussed in next section.
Query for a Custom Result Type with a Constructor Expression In JPA, when querying for a custom result like the one in the previous section, you can instruct JPA to directly construct a POJO from each record for you.
For the example in the previous section, let’s create a POJO called ContactSummary that stores the results of the query for the contact summary.
The previous ContactSummary class has the properties for each contact summary, with a constructor method that accepts all the properties.
Having the ContactSummary class in place, we can revise the method and use a constructor expression within the query to instruct the JPA provider to map the resultset to the ContactSummary class.
As shown in Listing 10-15, in the JPQL statement, the new keyword was specified, together with the fully qualified name of the POJO class that will store the results and pass in the selected attributes as the constructor argument of each ContactSummary class.
Finally, the ContactSummary class was passed into the createQuery() method to indicate the result type.
As you can see, the constructor expression is very useful for mapping the result of a custom query into POJOs for further application processing.
Like Hibernate, JPA also supports retrieving a database-generated primary key.
As shown in Listing 10-17, the save() method first checks whether the object is a new entity instance, by checking the id value.
When calling the persist() method, the EntityManager will persist the entity and make it a managed instance within the current persistence context.
When the merge() method is called, the EntityManager will merge the state of the entity into the current persistence context.
Listing 10-18 shows the code snippet for insert a new contact record.
As shown in Listing 10-18, we create a new contact, add two telephone details, and save the object.
Running the program yields the following output (the output of existing contacts was omitted):
From the INFO log record, you can see that the id of the newly saved contact was populated correctly.
Hibernate will also show all the SQL statement being fired to the database.
Updating Data Updating contacts is as easy as inserting data.
Suppose for a contact with an ID of 1, we want to update its first name and remove the home telephone record.
To test the update operation, add the code snippet in Listing 10-19 into the main() method of the JpaSample class.
Then we loop through the telephone objects and retrieve the one with type "Home" and remove it from the contact’s telephone detail property.
When you run the program, you will see the following output (other output was omitted):
You will see the first name was updated, and the home telephone was removed.
The telephone can be removed because of the orphanRemoval=true attribute that was defined in the one-to-many association, which instructs the JPA provider (i.e., Hibernate) to remove all orphan records that exist in database but are no longer found in the object when persisted.
To test the delete operation, add the code snippet in Listing 10-21 into the main() method of the JpaSample class.
The previous listing retrieves the contact with an ID of 1 and then calls the delete() method to delete the contact information.
Running the program will produce the following output (other output was omitted):
You can see that the contact with an ID of 1 was deleted.
Native Query Having discussed performing trivial database operations using JPA, now let’s proceed to some more advanced topics.
Sometimes you may want to have absolute control over the query that will be submitted to the database.
One example is using a hierarchical query in an Oracle database.
This kind of query is database-specific and referred to as a native query.
You may wonder why we don’t use JDBC directly if JDBC supports direct submission of queries to the database.
Spring also provides nice support for programming JDBC access logic and performs row mapping back to Java POJOs.
One main benefit of using JPA native queries is the mapping of the resultset back to the ORMmapped entity classes.
The following two sections discuss how to use a native query to retrieve all contacts and directly map the resultset back to the Contact objects.
Simple Native Query To demonstrate how to use a native query, let’s implement a new method to retrieve all the contacts from the database using a native query.
Listing 10-22 shows the new method in the ContactService interface.
As shown in Listing 10-23, you can see the native query is just a simple SQL statement to retrieve all the columns from the CONTACT table.
The result type should be a mapped entity class (in this case the Contact class)
The JPA provider will execute the query and transform the resultset into the entity instances, based on the JPA mappings defined in the entity class.
Executing the previous method produces the same result as the findAll() method.
A SQL resultset mapping can have one or more entity and column mappings.
Let’s define a simple SQL resultset mapping in the Contact entity class (see Listing 10-24)
A SQL resultset mapping called contactResult was defined for the entity class, with the entityClass attribute in the Contact class itself.
As you can see, JPA also provides strong support for executing native queries, with a flexible SQL resultset mapping facility provided.
Criteria Query Using the JPA 2 Criteria API Most applications will provide a frontend for users to search for information.
Most likely a large number of searchable fields will be displayed, and the users will enter only some of them and do the search.
It’s very difficult to prepare a large number of queries with each possible combination of the parameters that users may choose to enter.
In this situation, the criteria API query feature comes to the rescue.
In JPA 2, one major new feature introduced was a strongly typed criteria API query.
In this new criteria API, the criteria being passed into the query is based on the mapped entity classes’ metamodel.
As a result, each criteria specified is strongly typed, and errors will be discovered at compile time, rather than runtime.
In the JPA criteria API, an entity class’s metamodel is represented by the entity class name with a suffix of an underscore (_)
For example, the metamodel class for the Contact entity class will be Contact_
Within the class are the declaration of each attribute and its related types.
It would be tedious to code and maintain those metamodel classes.
However, tools can help generate those metamodel classes automatically based on the JPA mappings within the entity classes.
Using the tool with some configurations in STS, the metamodel classes will be generated/updated automatically every time your project is built.
Let’s go through the procedure to enable the autogeneration of metamodel classes for your JPA entity classes.
First, we need to have the JAR files in Table 10-1 ready for our project.
Both JAR files can be found in the download package from the previously mentioned web site.
Then click the option Factory Path (on the left-side menu), select “Enable project specific settings,” then click the Add JARs button, and choose the two JAR files mentioned earlier into the factory path.
After completion, click the OK button, and STS will prompt you whether to rebuild the project.
Clicking Yes will rebuild the project, and annotation processing will generate the metamodel classes.
After generating the metamodel classes, we can proceed to implement more flexible queries using a JPA 2 strongly typed criteria API query.
Let’s define a query that accepts both the first name and last name for searching contacts.
The result is a query root object (i.e., the Root<Contact> interface) corresponding to the specified entity.
The query root object forms the basis for path expressions within the query.
The two Root.fetch() method calls enforce the eager fetching of the associations relating to telephone details and hobbies.
Calling the Root.fetch() method with JoinType.LEFT as the second argument is equivalent to specifying the left join fetch join operation in JPQL.
The distinct() method with true means that duplicate records should be eliminated.
A Predicate can be a simple or compound predicate, and a predicate is a restriction that indicates the selection criteria defined by an expression.
The method equal() is to specify an equal restriction, within which the Root.get() was called, passing in the corresponding attribute of the entity class’s metamodel to which the restriction applies.
The EntityManager will then construct the query based on the CriteriaQuery passed in, execute the query, and return the result.
To test the criteria query operation, add the code snippet in Listing 10-29 to the main() method of the JpaSample class.
Running the program will produce the following output (other output was omitted):
You can try a different combination or pass null value to either of the arguments to observe the output.
The main objective of the Spring Data JPA project is to provide additional features for simplifying application development with JPA.
The first one is the Repository abstraction, while the other one is the entity listener for keeping track of basic audit information of entity classes.
In STS, you can use the POM editor to add the dependencies easily.
In the POM editor, click the Dependencies tab and enter the additional dependencies.
Figure 10-9 shows the list in STS after all the dependencies were added.
After adding the dependencies, we can proceed to explore Spring Data JPA’s features.
In Spring Data JPA, the repository abstraction wraps the underlying JPA EntityManager and provides a simpler interface for JPA-based data access.
The CrudRepository interface provides a number of commonly used methods.
Listing 10-30 shows the interface declaration, which is extracted from Spring Data Commons project source code.
It’s better to show how the Repository abstraction works by going through a simple example.
Let’s revise the ContactService interface a bit, down to just three finder methods.
Just delete these two classes and proceed with the implementation of the interface using Spring Data JPA.
The next step is to prepare the ContactRepository interface, which extends the CrudRepository interface.
As shown in Listing 10-32, the ContactRepository interface extends the CrudRepository interface, passing in the entity class (Contact) and the ID type (Long)
Instead, Spring Data JPA will “infer” and construct the query for you based on the method name.
For example, for the findByFirstName() method, Spring Data JPA will automatically prepare the query select c from Contact c where c.firstName = :firstName for you and set the named parameter firstName from the argument.
To use the Repository abstraction, we have to define it in Spring’s configuration.
First, we need to add the jpa namespace in the configuration file.
Then, the <jpa:repositories> tag was used to configure Spring Data JPA’s Repository abstraction.
Listing 10-34 shows the implementation of the three finder methods of the ContactService interface.
You can see that instead of the EntityManager, we just need to inject the ContactRepository interface into the service class, and Spring Data JPA will do all the dirty work for us.
Running the program will yield the contact listing as expected.
You have seen how Spring Data JPA can help simplify the development.
For more information, please refer to SpringSource’s reference documentation listed here:
Keeping Track of Changes on the Entity Class In most applications, we need to keep track of basic audit activities for the business data being maintained by users.
The audit information typically includes the user who creates the data, the date it was created, the date it was last modified, and the user who last modified it.
The Spring Data JPA provides a function in the form of a JPA entity listener, which helps you keep track of those audit information automatically.
Listing 10-36 shows the Auditable interface that was extracted from Spring Data’s reference documentation.
To show how it works, let’s create a new table called CONTACT_AUDIT in our database schema, which is based on the CONTACT table, with four audit-related columns added.
In Listing 10-37, the four columns with bold characters indicate the audit-related columns.
The next step is to create the entity class called ContactAudit.
It’s basically the same as the Contact entity class; we just added the mapping for the four audit columns.
Listing 10-38 shows the code snippet that was added on top of the Contact class.
Audit fields private String createdBy; private DateTime createdDate; private String lastModifiedBy; private DateTime lastModifiedDate;
In Listing 10-38, the ContactAudit entity class implements the Auditable interface and implements the methods by mapping the four auditing columns.
The @Column annotations were applied to map to the actual column in the table.
The annotation @Transient means that the field doesn’t need to persist.
Spring Data JPA uses this function to identify whether it’s a new entity in order to determine whether we need to set the createdBy and createdDate attribute.
In the implementation, we just check the ID, and if the value is null, then we return true, it means it’s a new entity instance.
The listener will be picked by the JPA provider during persistence (i.e., save and update events) for audit fields processing.
We also need to define the listener in Spring’s configuration.
The tag <jpa:auditing> is to enable the Spring Data JPA auditing feature, while the bean auditorAwareBean is the bean providing the user information.
The AuditorAwareBean implements the AuditorAware<T> interface, passing in the type String.
In real situations, this should be an instance of user information, for example, a User class, which represents the logged-in user who is performing the data update action.
In real situations, the user should be obtained from the underlying security infrastructure.
In Listing 10-45, we list the contact audit information both after a new contact was inserted and after it’s later updated.
In the previous output, you can see that after the new contact is created, the create date and last modify dates are the same.
However, after the update, the last modified date is updated.
Auditing is another handy feature that Spring Data JPA provides so that you don’t need to implement the logic yourself.
Let’s move on to see another useful function that Hibernate provides for keeping entity versions.
Keeping Entity Versions by Using Hibernate Envers In an enterprise application, for business-critical data, it is always a requirement to keep “versions” of each entity.
For example, in a customer relationship management (CRM) system, each time a customer record is inserted, updated, or deleted, the previous version should be kept in a history or auditing table to fulfill the firm’s auditing or other compliance requirements.
The first one is to create database triggers that will clone the pre-update record into the history table before any update operations, and the second is to develop the logic in the data access layer (e.g., by using AOP)
The trigger approach is tied to the database platform, while implementing the logic manually is quite clumsy and error prone.
Hibernate Envers (Entity Versioning System) is a Hibernate module specifically designed to automate the versioning of entities.
In this section, we will discuss how to use Envers to implement the versioning of the ContactAudit entity.
We mention it here because we believe it’s more appropriate to cover this after we have discussed some basic auditing feature that you can do with Spring Data JPA.
As a matter of fact, maintaining history records of critical business data (e.g., customer, transaction, and so on) is a basic feature in an enterprise application.
Envers supports two different auditing strategies, which are shown in Table 10-3
Default Envers will maintain a column for the revision of the record.
Every time a record is inserted or updated, a new record will be inserted into the history table with the revision number retrieved from a database sequence or table.
Validity Audit This strategy stores both the start and end revisions of each history record.
Every time a record is inserted or updated, a new record will be inserted into the history table with the start revision number.
At the same time, the previous record will be updated with the end revision number.
It’s also possible to configure Envers to record the timestamp at which the end revision was updated into the previous history record.
In this section, we will demonstrate the validity audit strategy.
Although it will trigger more database updates, retrieving the history records becomes much faster.
Because the end revision timestamp is also written to the history records, it will be easier to identify the image of a record at a specific point of time when querying the data.
Adding Hibernate Envers Dependencies We need to add the Maven dependency listed in Table 10-4 to our project.
Adding Tables for Entity Versioning To support entity versioning, we need to add a few tables.
First, for each table that the entity (in this case, it’s the ContactAudit entity class) will be versioning, we need to create the corresponding history table.
To support the validity audit strategy, we need to add four columns for each history table (the bold columns in Listing 10-46)
Hibernate Envers requires another table for keeping track of the revision number and the timestamp at which each revision was created.
The REV column is for storing each revision number, which will be autoincremented when a new history record is created.
The REVTSTMP column stores the timestamp (in a number format) when the revision was created.
The listener intercepts the events post-insert, post-update, or post-delete and clones the pre-update image of the entity class into the history table.
Envers is capable of keeping the history of the entities within an association (e.g., one-to-many, many-to-many, and so on)
The history table’s column for storing the end revision number for each history record.
Whether to store the timestamp when the end revision number for each history record is updated.
The history table’s column for storing the timestamp when the end revision number for each history record is updated.
Required only when using the validity audit strategy and the previous property is set to true.
Coding Changes for Entity Versioning and History Retrieval To enable the versioning of an entity, just annotate the entity class with @Audited.
Listing 10-49 shows the ContactAudit entity class with the annotation applied.
By default, Envers will also try to keep a history of the associations.
So, it also will try to keep the history of the contact’s telephone details and hobbies.
In case we don’t want to keep versions of the association entities, we need to annotate them with the @NotAudited annotation.
To retrieve a history record, one option is to pass in the entity’s ID and the revision number.
As shown in Listing 10-51, the EntityManager was injected into the class, which was passed to the AuditReaderFactory to retrieve an instance of AuditReader.
Testing Entity Versioning Let’s take a look at how entity versioning works.
In Listing 10-52, the code for bootstrapping ApplicationContext and the listContacts() function is the same as the one in the SpringJpaSample class.
From Listing 10-52, we first create a new contact and then update it.
From the previous output, you can see that after the update operation, the ContactAudit’s first name was changed to Tom.
However, when looking at the history, at revision 1, the first name is Michael.
Also notice that the last modified date of revision 2 reflects the updated date-time correctly.
Considerations When Using JPA Although this chapter is long, it covered only a small portion of JPA.
For example, using JPA to call database stored procedures was not covered.
So, it’s a compelling choice for adopting JPA as the data access standard.
If you require absolute control over the query, you can use JPA’s native query support, instead of using JDBC directly.
In conclusion, for developing JEE applications with Spring, we recommend using JPA to implement the data access layer.
When desired, you can still mix in JDBC for some special data access needs.
Always remember that Spring allows you to mix and match different data access technologies easily with the transaction management transparently handled for you.
Using JPA in the Sample Application In this section, we will discuss the relationships between the topics discussed in this chapter and the sample application that we will develop.
Topics include the backend database and the JPA implementation for various database operations.
We will also highlight how we adopt the features in Spring Data JPA to help simplify the data access logic and keep track of the basic audit information.
Finally, we will discuss how the entity versioning feature of the sample application was implemented using Hibernate’s Envers module.
Database Backend For database backend, the JDBC embedded database with H2 will be used.
However, the scripts (database creation script, initial data population script) will be designed to be compatible with MySQL too.
So, when desired, the application is able to use MySQL as the backend database.
Using JPA for Persistence Layer Implementation As mentioned in Chapter 3, for the persistence layer, two different implementations will be provided.
One will use JPA, while the other will use MyBatis.
For the JPA implementation, we will use JPA 2, with Hibernate as the persistence provider.
In addition, we will use Spring Data JPA to simplify the various database operations.
Moreover, in order to support browsing blog entries in the web application frontend, pagination support will be implemented.
In terms of database operations, querying is the most complicated part.
In the frontend, users can choose to filter entries by posting dates, categories, and subcategories, and so on.
To fulfill this requirement, we will use JPA 2’s strongly typed criteria query API.
Auditing and Entity Versioning In the sample application, all blog entries and comments will have auditing features enabled.
With the help of Spring Data JPA’s auditing feature, we will keep track of basic audit information (created by, created date, last modified by, last modified date) for blog posting and comments.
When a blog posting entry or comment is updated, Hibernate’s Envers module will be used for keeping versions of each record.
History tables will be created for blog posting and comment tables to keep the history records.
Then, we discussed using JPA to perform basic database operations.
Advanced topics included native queries and the strongly typed JPA criteria API.
Then we demonstrated how Spring Data JPA’s Repository abstraction can help simplify JPA application development, as well as how to use its entity listener to keep track of basic auditing information for entity classes.
For full versioning of entity classes, using Hibernate Envers to fulfill the requirement was also covered.
In the next chapter, we will discuss another popular data access library: MyBatis (formerly known as iBATIS)
In the previous three chapters, you saw how Spring supports seamless integration with different libraries and techniques for implementing data access logic, from the traditional JDBC approach to ORM solutions including Hibernate and the JEE standard JPA.
Formerly known as iBATIS (which was hosted on the Apache Software Foundation and was retired), MyBatis is a Java library (a .NET version is also available) that provides a data mapper framework for mapping the database relational structure into Java’s OO model.
However, instead of focusing on programming to the OO model like ORM does, MyBatis is more focused on the SQL side.
You can think of MyBatis as the hybrid approach between JDBC and ORM.
The MyBatis development team classifies MyBatis as a SQL-based data mapping solution for object-oriented software development.
In this chapter, we are going to focus on implementing the data access layer of a Spring application using MyBatis.
Configuration: We will discuss how to configure MyBatis with Spring, including the Maven dependencies required and the configuration of MyBatis’s SqlSessionFactory in Spring’s ApplicationContext.
MyBatis SQL mapping: In this section, you will learn how to define SQL mappings with MyBatis for transforming the resultset of SQL queries into the properties of the corresponding Java domain objects.
You will also learn how to implement select operations that represent major types of data relationships.
Using MyBatis in the sample application: In the sample application, for the MyBatis implementation, we will eliminate the DAO layer and have the MyBatis mappers being directly injected into the service layer for executing business logic.
We will discuss how MyBatis will be adopted in the sample application.
Getting Started with MyBatis in Spring In this section, we will cover how to set up MyBatis to work with Spring.
First we will provide a brief introduction to MyBatis, and then we will demonstrate how to create a project in STS for working with MyBatis.
Also, we will present the data model that will be used for implementing the samples in this chapter.
Finally, we will discuss the Spring configuration required for working with MyBatis.
Based on its SQL mapping focus, simple infrastructure, and easy-to-understand mapping definitions from SQL queries to the Java OO model, iBATIS gained popularity quickly and became one of the most used data access libraries in the Java developer community.
After staying in ASF for six years, the iBATIS development team realized that data-accessing technologies in the open source world had changed dramatically.
Consequently, the team decided to introduce numerous significant changes into the library.
Starting with version 3, the project also changed its name to MyBatis, left ASF, and became an independent open source framework.
At the time of this writing, the current version of MyBatis is 3.0.6
To deal with this situation, the MyBatis team has started the MyBatis Spring Integration Project (called mybatis-spring)
At the time of this writing, the current version of mybatis-spring is 1.0.2
Creating a Simple Utility Project with MyBatis Support in STS In STS, there is no template project provided for using Spring with MyBatis, so we need to create a simple Spring utility project in STS and then add the required dependencies manually.
First create a simple Spring utility project in STS (please refer to Appendix A for details)
Upon project creation, open the pom.xml file in the POM editor and add the dependencies listed in Table 11-1
Figure 11-1 shows STS with the Maven dependencies after all the dependencies have been defined.
To have MyBatis display all the SQL queries fired to the database, we need to turn on the DEBUG log level.
Let’s put the log4j properties file into the folder src/main/resources with the root logger level set to DEBUG.
Note In STS, after a Spring template project is created, STS will generate a log4j.properties file in the folder src/test/resources.
You can simply move the file into the folder src/main/resources and modify it, or.
Sample Data Model for Example Code For the sample data model for the examples in this chapter, we will use the same model as presented in Chapter 9, when we discussed using Hibernate with Spring, with some minor modifications.
The main reason for this is that MyBatis doesn’t provide optimistic locking support with the VERSION column like Hibernate does.
However, you will be able to see in the sample application how to implement optimistic locking using MyBatis.
Both the SqlSession and SqlSessionFactory interfaces belong to the mybatis-3.0.6 library.
Another important concept in MyBatis is the mapper interfaces, which are simple Java interface classes, that will be processed by MyBatis for mapping configuration between SQL queries and domain object properties.
The mapping can be defined in either XML files (having the same name as the interface class) or annotations within the mapper interface.
The mapper interfaces will be discussed in detail later, and you will see how it can help simplify the development of database operations without the need to interact with the SqlSession interface directly.
As you might expect, the factory requires the data source bean.
Also, the property typeAliasesPackage defines the packages storing the domain objects that MyBatis should look for when perform mapping from SQL resultset into POJOs.
It’s similar to the mapped entity classes in Hibernate and JPA.
Note that, in the configuration, the same instance of the dataSource bean is being injected into both Spring’s transactionManager bean and MyBatis’s sqlSessionFactory bean.
Once a Spring transaction manager is configured, you can configure transactions in Spring as you normally would.
The mybatis-spring module will transparently manage transactions once they are set up.
You just need to ensure that the same instance of dataSource was injected into both the transactionManager and SqlSessionFactory beans.
The class accepts the package name, from which MyBatis will scan for mapper interfaces.
Having the configuration in place, we can proceed to the next step, which is to define the SQL mapping in MyBatis between queries and the POJO model.
The mapping is closely related to what operations are required and their underlying queries.
So, for the contact information service, let’s define the ContactService interface that we will implement first.
It consists of a few finder methods for retrieving summary or detail contact information, within which some accept parameters as searching criteria, while other methods include insert, update, and delete operations.
Later we will implement the service in the class ContactServiceImpl.
Mapper Interfaces and SQL Mapping Files The mapper interfaces and the mapping files make up the heart of how MyBatis works.
They work together with the domain objects to perform mapping between query results to domain objects, and vice versa.
For mapping each domain object, three main files are involved.
Table 11-2 describes the files and shows an example of each.
Domain object The POJO that queries will be mapped to.
Mapper interface The Java interfaces that MyBatis will scan for and register as MapperFactoryBeans.
All the database operations supported for the relating domain object will be defined here.
The XML configuration file that stores the details of mapping between SQL queries and domain objects.
The file should be in the project’s classpath and have the same name as the mapper interface.
For example, to implement the findAll() method of the ContactService interface, the files and their content will look like the one in Figure 11-3
Upon the completion of all mappings, the project structure will look like the STS screen shown in Figure 11-4
Table 11-3 highlights some of the most frequently used tags.
The query to be submitted, named parameters, and which result map to use are defined here.
The domain object properties will be mapped to the insert statement’s named parameters.
A database-generated key can be set to be retrieved by MyBatis after the insert statement.
Database Operations with MyBatis In this section, we discuss how to perform various CRUD operations with MyBatis in Spring.
For querying data, we will discuss how to perform mappings from SQL to POJOs, as well as model the relationships between domain objects.
Moreover, topics including named parameters and dynamic SQL support in MyBatis will also be covered.
Querying Data MyBatis provides intensive support for querying data in a database.
Basically, for each select operation, we will define the SQL statement, the parameters, the result type (Java type), and the result mapping to use.
Various relationships (one-to-one, one-to-many, and many-to-many) can be mapped easily.
Another powerful feature in MyBatis is the support of dynamic SQL, which we will discuss in the following sections.
Simple Selects Let’s start with the simplest method of ContactService, the findAll() method.
The method simply retrieves all contact information from the database, without their telephone and hobby details.
Let’s begin with a Contact domain object without any association first.
The class is a simple POJO, with nothing we need to specify here.
The next step is to define the contact’s mapper interface (and the findAll() method), which was shown in Listing 11-7
The next step is the most important part, the XML mapping file.
The following are the main points for the mapping configuration:
The file begins with a <mapper> tag with a namespace attribute defined.
The <resultMap> defines a unique result mapping of a select operation.
Depending on an application’s needs, many result maps can be defined.
As shown in Listing 11-8, we specify that the domain object to be mapped is the Contact object.
Here we don’t need to provide the package name of the domain object, because it was already provided in the sqlSessionFactory bean’s typeAliasesPackage property in Spring ApplicationContext (see app-context.xml in Listing 11-4)
Then we use the <id> tag to define the property for the id field and the corresponding column name in the query.
Afterward, we use a number of <result> tags to map the domain object property to the selected columns.
Note that the id attribute should be in line with the method name defined in the ContactMapper interface.
Then, the attribute resultMap specifies the mapping to use for transforming the resultset to a Contact domain object.
The body of the tag is the SQL statement to use.
After defining the mapping, we can proceed with the implementation.
Listing 11-9 shows the implementation of the findAll() ContactService interface.
As shown in Listing 11-9, the mapper interface is injected into the service class, and the findAll() method simply calls the corresponding method in the ContactMapper interface.
Running the program will yield the output in STS shown in Figure 11-5
As shown in Figure 11-5, we turned the DEBUG log on, so besides the contact information, the select statement that was submitted by MyBatis to the database was also displayed.
Defining the Mapping Using MyBatis Annotations In addition to XML-based configuration, MyBatis also supports mapping definitions using Java annotations, just as many other tools do.
When using annotations, they should apply to the mapper interface.
Listing 11-11 shows the ContactMapper interface with annotations used for the mapping definition.
You can see the annotation structure is quite like the XML style in Listing 11-8
In this case, the method name findAll becomes the id attribute within the <select> tag.
So, you can choose the annotation approach and totally get rid of the XML mapper files.
However, for complex queries and mappings, a lot of code will be embedded into the interface class.
So, in this chapter, we will focus on the XML-style mapping definition in MyBatis.
One-to-Many and Many-to-Many Selects in MyBatis Let’s proceed to see the mapping of associations in MyBatis by looking at the relationships within the Contact domain object.
For the association with the ContactTelDetail domain object, it’s a one-to-many association.
For the association with the Hobby domain object, it’s a many-to-many association.
For mapping associations, MyBatis provides two options: nested selects and nested results.
Let’s take a look at both options and see their differences.
As you might be able to guess from the name, the nested select approach mean firing additional queries for each contact to retrieve the telephone details.
The following are the main points for the mapping configuration in Listing 11-15:
In this result map, a <collection> tag is added and mapped to the contactTelDetails property of the Contact class.
This statement receives a parameter ID, which indicates the ID of each contact record.
Running the MyBatisSample program will produce the following output (the other output was omitted):
As shown in the output (the other DEBUG messages were removed), you will see that four select statements were fired: one for the contact and one for each of the three selected contacts.
Another, more elegant way is to use a nested result, which we will discuss in next section.
Another way to model associations in MyBatis is to use nested results.
Basically, instead of submitting separate queries for each parent object, the query was rewritten to join the tables.
Then, in the result map, the properties of the nested objects are mapped accordingly, and MyBatis will populate the object graph properly for you.
To save a little space, let’s also model the many-to-many relationship between the Contact and Hobby objects.
For example, for the contactTelDetails property, each property of the corresponding ContactTelDetail object was mapped to the corresponding column within the select statement.
Similarly, the many-to-many mapping for the property hobbies is just the same.
Listing 11-22 shows the revised method in the MyBatisSample class.
The difference with the previous version is highlighted in bold.
Running the MyBatisSample class again will produce the following output (other output was omitted):
In the output, you can see that only one query is fired and six records are returned, while MyBatis will map the object graph properly, and the contact with detail information is displayed correctly.
Selects in MyBatis with Named Parameters Let’s see another select example with a named parameter, which is the findById() method.
The method accepts a named parameter called id and needs to pass it to the query in MyBatis.
Listing 11-23 shows the method added to the ContactMapper interface.
The method accepts the ID and returns the contact record found.
The select operation uses the same result map as the previous findAllWithDetail operation, which populates the Contact object graph.
The query is the same too; just a named parameter called id was added to the query.
Listing 11-25 shows the implementation of the findById() method in the ContactServiceImpl class.
To test the findById() method, add the code snippet in Listing 11-26 into the main() method of the MyBatisSample class.
Selects in MyBatis Using Dynamic SQL One powerful feature in MyBatis for programming select operations is dynamic SQL, which eases the development of more complex queries a lot.
From Listing 11-27, instead of accepting two parameters (first name and last name), we defined a Java class to store the searching criteria.
The class simply stores the possible search criteria into the attributes.
Let’s see how the search criteria were substituted into the dynamic SQL in MyBatis.
For example, it will first test whether the firstName attribute in the SearchCriteria being passed in is null.
If not, it will add the clause WHERE FIRST_NAME = and the attribute into the query accordingly.
One fancy thing is that if you do not provide the first name, MyBatis will intelligent remove the AND operator from the WHERE clause using the last name.
If both attributes are null, MyBatis will simply drop the WHERE clause entirely.
As shown in Listing 11-30, the method is still accepting the first name and last name as the parameters.
However, it will construct the SearchCriteria instance and pass to the ContactMapper for data retrieval.
You can try different combinations and observe the SQL statement being generated by MyBatis.
Besides <where>, MyBatis provides a lot of different tags for building very flexible dynamic SQL statements.
Also, for constructing dynamic SQL within Java code, MyBatis provides classes like SqlBuilder and SelectBuilder.
Please refer to the official documentation at the MyBatis web site for details.
Inserting Data Let’s see how we insert new contact information into the database using MyBatis.
From the select operations, we defined only the mapper interface ContactMapper.
However, to support the insert operation of the associations (i.e., ContactTelDetail and Hobby), we also need to define the mapper interface and XML configuration files for them.
Also, the attribute useGeneratedKeys instructs MyBatis to retrieve the record key generated by the database during insert, and the property for the key value should be stored back in the id attribute of the Contact object.
Now we can implement the save() method in the ContactServiceImpl class.
As shown in Listing 11-39, the mapper for the associations is autowired into the service class.
In addition, the save() method will check for the existence of the id attribute within the Contact instance.
If it does not exist, then it’s an insert operation, and the private insert() method will be called.
In the insert() method, first the contact record is saved with the ID retrieved into the Contact object.
The ID is then used for insert operations of the corresponding telephone and hobby details.
To test the insert operation, add the code snippet in Listing 11-40 to the main() method of the MyBatisSample class.
In Listing 11-40, a new contact is constructed, and two telephone records and one hobby record are created too.
Running the program will produce the following output (other output was omitted):
You can see that a new contact with an ID of 4 was created, and the data was populated correctly.
Updating Data Updating contact data is a bit complicated, mostly for the one-to-many telephone and many-to-many hobby associations.
Let’s implement the update method with the following sequence of operations:
Before updating the telephone details, retrieve the existing telephone details for the contact, and store the list of IDs for removing orphan records.
Also, remove the ID from the list of orphan records.
After updating all the telephone details, check the list of IDs for any orphan telephone detail records.
This sequence is just a typical handling mechanism; you can fine-tune it to suit your specific needs.
First we need to add the update operation in the ContactMapper interface and XML file.
The second one is to update an existing telephone detail, and the third one is to remove orphan telephone records by a list of IDs.
Now we can proceed to implement the update() method in the ContactServiceImpl class.
In Listing 11-47, the update logic was implemented in the sequence as described in the beginning of this section.
To test the update operation, add the code snippet in Listing 11-48 to the main() method of the MyBatisSample class.
Then, the first name is updated, the home telephone record is removed, and a new hobby is added.
Next, the save() method is called to save the contact.
Running the program will produce the following output (other output was omitted):
There’s just one thing new here, where the <delete> tag was used to indicate a delete operation.
Now we can proceed to implement the delete() method in the ContactServiceImpl class.
First we delete the child records, including the telephone and hobby details.
To test the delete operation, add the code snippet in Listing 11-54 to the main() method of the MyBatisSample class.
Considerations When Using MyBatis As you can see from the samples presented in this chapter, MyBatis is an excellent data access library focused on SQL mapping.
When developing applications with MyBatis, most of the time you will be focused on the design and mapping of the result maps and various select, insert, update, and delete operations.
In terms of mapping, MyBatis provides a rich set of tags that can help you build dynamic and complicated queries and map to the corresponding domain objects easily.
As you also saw from the samples, we don’t need to directly interact with the SqlSession interface.
Most of the time the mapper interfaces will be able to fulfill your needs.
However, if you want, you can choose to interact with the SqlSession interface and construct the queries in a programmatic way.
In conclusion, if you prefer to have more control over the SQL statements being submitted to the database and want a flexible and easy way to define the mapping of the resultset to the domain objects, MyBatis provides a much more elegant solution than JDBC.
For example, you need to implement the record locking mechanism (for example, a VERSION column for optimistic locking) and keep versions of history records manually.
Also, if the data model changes frequently, you will need to review all those queries that will be affected by the change.
In terms of ongoing maintenance, the effort of using MyBatis will be higher than that of using ORM libraries such as Hibernate and JPA.
Using MyBatis in the Sample Application In this section, we will discuss the topics in this chapter in relation to the sample application that we will develop.
Topics include the backend database and the MyBatis implementation for various database operations.
We will also highlight how we adopt the features in MyBatis to help us simplify the data access logic.
Finally, we will discuss how we keep track of the basic audit information and how the entity.
Database Backend For the database backend, the JDBC embedded database with H2 will be used.
However, the scripts (database creation script, initial data population script) will be designed to be compatible with MySQL too.
So, when desired, the application is able to use MySQL as the backend database.
Using MyBatis for Persistence Layer Implementation As mentioned in Chapter 3, for the persistence layer, two different implementations will be provided.
One will use JPA, while the other will use MyBatis.
More specifically, the MyBatis mapper interfaces and XML-style mapping configurations will be adopted.
Moreover, to support browsing blog posting entries in the web application frontend, pagination support will be implemented as well.
In terms of database operations, query is the most complicated part since in the frontend users can choose to filter posting entries by posting dates, categories and subcategories, and so on.
To fulfill this requirement, we will use MyBatis’s dynamic SQL feature.
Auditing and Entity Versioning In the sample application, all blog posting entries and comments will have auditing features enabled.
For keeping track of basic audit information (created by, created date, last modified by, last modified date) for blog posting and comments, as well as keeping versions of each record, we will utilize MyBatis’s plug-in mechanism to intercept the calls to the update operation and populate the basic audit information (created by, created date, last modified by, last modified date) accordingly.
On the other hand, a copy of the preupdate record will be saved into the history table.
Summary In this chapter, we discussed how Spring integrates with MyBatis (formerly iBATIS) when developing data access logic.
Topics included the core concepts, configuration, and mapping definition, and so on.
Then, we discussed how to perform various database operations using MyBatis.
We covered various techniques in retrieving data with different associations and how to use dynamic SQL.
In this chapter, we covered only a small portion of the features available in MyBatis when implementing most common database operations.
In previous chapters, we discussed various topics related to application development with Spring, including Spring’s ApplicationContext configuration, various DI mechanisms, AOP support for crosscutting concerns, and how Spring integrates with different data access technologies for interacting with backend relational databases.
When discussing implementations of data access logic, you saw how to use different implementation patterns.
For example, in Chapter 8, which covered data access with JDBC, the data access logic was encapsulated in DAOs.
In those chapters, we also mentioned the design of domain objects (or the entity classes, in JPA terms) and showed how their attributes and relationships were modeled and mapped to the database structure.
Before we proceed, let’s take a short break from programming topics and discuss some of the main principles in designing and implementing Spring-based applications.
We believe that taking a step back and revisiting the application design practice for JEE applications here will help you better correlate the topics as we proceed with the overall application architecture.
Application design is a big topic, and we do not intend to cover all aspects of it.
In this chapter, we will discuss some tried-and-tested OOP practices that result in applications that have clearly defined component responsibilities and that are also easy to test and maintain.
This chapter looks at the impact Spring has on application design, paying particular attention to patterns and practices that you will find easy to apply when you are building your application with Spring.
Much of this chapter focuses on the design decisions we made when building the SpringBlog application, and we use that application as the basis for our examples and discussions.
In addition to the application design principles, we will discuss how you can use many of the Spring technologies covered so far to implement the data access and service layers of the SpringBlog application.
Interface-driven design: Interface-driven design is a traditional OOP best practice.
When you use interface-driven design, the main components of your application are defined in terms of interfaces rather than concrete classes.
Java offers firstclass support for this kind of design with its notion of interfaces separate from classes.
In this section of the chapter, we discuss interface-driven design in general terms and why you should use it in your applications.
Building a Domain Object Model: In this section of the chapter, we look at the notion of a Domain Object Model (DOM), a collection of objects that provides an.
By creating a DOM for your application, you are creating a set of objects for modeling application data and behavior that matches some abstract ideas of your problem domain.
The data access layer: Most applications nowadays need to access some kind of persistent data store, typically a relational database.
In this section of the chapter, we look at the design issues related to building a data access layer to service the rest of your application.
Building the service layer: An application’s service layer is where all of the business logic that makes up the application is encapsulated.
In this section, we look at how the service layer interacts with the Domain Object Model and data access layer to provide a unified interface to access application functionality.
We also look at the business requirements of the SpringBlog application and how this translates into an interface design and an implementation of that interface.
In particular, we do not cover how the SpringBlog service layer is utilized by the web frontend, nor do we explore how Spring uses the validation logic to support data validation and error reporting in the frontend.
Designing to Interfaces Designing to interfaces is a common practice when architecting and implementing an application, no matter which framework or standard (Spring, JBoss Seam, Guice, EJB, and so on) you are working on.
One of the main design goals of Spring is to further ease the development of applications that are designed and implemented around a set of well-defined interfaces.
Before we can look at designing a Spring-based application in any detail, we should explore exactly why designing to interfaces is such a big thing and how Spring goes about making it easier.
Why Design to Interfaces There are many reasons you should design and code your applications to interfaces rather than to a concrete class hierarchy, but perhaps the biggest reason is to reduce coupling.
If components in your application communicate with each other in terms of interfaces rather than concrete types, it becomes very easy to swap out a component if it becomes problematic.
This capability allows you to switch from one implementation to another, without having to touch the rest of the application code; indeed, it is possible for your application to work with many different implementations of the same interface without even being aware that it is doing so.
For example, when using profile support in Spring, you can provide different concrete implementations of the same interface, without any impact on the rest of the application.
Remember also that, in Java, a class has only one shot at concrete inheritance but can implement as many interfaces as necessary.
By defining application components in terms of interfaces rather than classes, you are not going to constrain an implementing class to a particular base class unnecessarily.
One other benefit, as we discussed in Chapter 7, is that using interfaces makes it possible to adopt AOP’s introduction support to “mix in” specific interfaces into target beans when addressing cross-cutting concerns, without introducing additional complexity into the source code of the target components.
On the testing side, one of the main benefits gained by this loose coupling is the increase in testability.
As the heads of a busy development team, we are constantly seeking new ways to improve the test coverage in the applications we produce as a direct way of improving the quality of the product we send to.
By designing to interfaces, we can swap out an implementation of an interface for a mock implementation, which allows us more flexibility when testing.
For example, when unit testing a web controller, we definitely want to focus on whether the controller is behaving correctly, assuming that the service classes it depends on are working properly.
In this case, it will be very useful to provide a “mocked” version of the service class that always return the expected results to the web controller under test.
The Factory Pattern One of the key problems you will encounter when implementing an application where all the components are defined in terms of interfaces is how your application goes about locating instances of classes that implement the interfaces.
A traditional solution to this is to use the Factory Pattern.
The Factory Pattern defines a class whose responsibility is to provide application components with implementations of other application components; in this case, the available components are defined in terms of interfaces, not concrete implementations.
Consider a system that has a business interface called OrderService.
Other components in the system want to obtain implementations of this interface without knowing ahead of time which implementation they need.
To implement such a system, we can build a Factory class like the one shown in Listing 12-1
This is a simplistic Factory implementation, but it does illustrate the basic Factory Pattern approach.
Now any application that wants to get access to an implementation of OrderService simply uses the getOrderService() method of the BasicFactory class.
There is no way to change an implementing class without a recompile.
There is no way to make multiple implementations available transparently to different components.
This is part of a larger problem in that the Factory class requires each component to have some knowledge of the Factory and which method on the Factory to invoke.
These drawbacks are discussed in detail in the next three sections.
Externally Configurable Factories From the example in Listing 12-1, you can see that changing the implementation class means changing the BasicFactory class and recompiling.
One of the benefits of interface-based design is that you can swap out implementations for new ones very easily.
However, having to recompile the Factory removes some of the ease with which this can be done.
This solved the initial problem, but it added more development burden to our project, and it did not really help out with the two remaining problems.
Supporting Multiple Implementations Transparently Supporting multiple implementations transparently is perhaps the biggest drawback of the traditional Factory Pattern.
The basic method on the BasicFactory class, getOrderService(), can return only one particular implementation (or a random choice), but it cannot choose which implementation to return based on the caller.
This leads, naturally, to an implementation such as that shown in Listing 12-2
However, this approach just negates the benefit of a factory.
Although the components are not coupled by class to a particular implementation, they are coupled by the method they call on the factory.
Another drawback to this approach is that each new implementation requires a change to the Factory code and a change to the component that needs the new implementation.
Having to add a new method for each new implementation makes this approach very difficult to configure externally.
Another implementation that tries to solve the problem of transparent support for multiple implementations requires components that invoke the getOrderService() method to pass in their class to the getOrderService() method so that the factory can decide, based on the class of the caller, which implementation to return.
This implementation suffers from numerous problems, not least of which is that it works only with classes, meaning two instances of the same class cannot have different implementations of the OrderService.
You will also find that the implementation of the getOrderService() method quickly becomes messy when you have many components that need an OrderService implementation.
A little more elegant approach to this problem is to use a lookup-style approach by having each component look up the implementation with a key.
The drawback of this approach is that in order to maintain full flexibility, each component must use a separate key so that its implementation can be changed separately from the others.
When the dependent object wants a different implementation of the same business service, it still needs to change the code to use the key of the corresponding implementation.
The root of this problem lies in the fact that a component actively has to ask for an implementation class, and to gain full flexibility and ensure that each component can get the appropriate concrete implementation class that it needs, the request has to be completely unique.
This is a problem that is not solved using the traditional Factory Pattern.
Supporting Multiple Instantiation Modes Another problem is supporting multiple instantiation modes of an implementation class for different components.
This problem suffers from many of the issues discussed in the preceding section, and again, the core of this problem is that a component actively has to ask for an implementation class.
This problem is also not solved using the traditional Factory Pattern.
Thankfully, Spring solves all of these problems; we discuss how in the next section.
Impact of Spring on Interface-Based Design Spring has a huge impact on applications that are designed using interfaces.
Because Spring takes care of wiring all the components together, you no longer have to worry about creating Factory classes that consider every possible situation.
On the surface, when you are building interface-based applications, the biggest benefit from Spring is the reduction in glue code that you have to write.
This benefit is further enhanced by the excellent out-of-the-box support for external configuration of component dependencies.
However, the biggest benefit comes from Spring’s use of Dependency Injection.
Because Spring removes the responsibility for dependency location from the components themselves and simply asks that components allow it to provide them with the dependencies, Spring is able to solve the last two of the three problems discussed previously.
Dependency Injection means that Spring can provide any instance of any implementation class to any instance of any application component without requiring any special coding in the application component whatsoever.
This is coupled with the fact that Spring can freely manage the life cycle of any instance of any dependency that it is managing for an application component.
Basically, this means that Spring has all the features that we need to design interface-based applications, and we don’t have to worry about how we are going to glue the components together during implementation.
Building a Domain Object Model A Domain Object Model (DOM) is a set of classes that model concepts from the problem domain.
Again, the DOM is a big topic, and we will just cover the main concepts of the DOM in this section.
Although we do not go into great detail on this pattern, we do show you why we chose to create a DOM for the SpringBlog application and how we built our DOM.
Spring and the Domain Object Model Given that this is a book on Spring, you might find it strange that we dedicate considerable space to a topic that is not directly related to Spring in any way.
Of the applications that we have built using Spring, the only objects that are consistently not managed by Spring are domain objects.
Even though in Spring it’s possible to have Spring manage domain objects by applying the @Component annotation to the classes and assigning them with prototype scope, most of the time we will choose to manage domain objects within the application.
The reason for this is that, practically, Spring does not need to be involved with domain objects.
Generally, you create many instances of your domain objects using the new() operator and perform processing either in the service or data access layer.
Although Spring also supports the injection of new instance of domain objects every time it was requested (by using the bean scope prototype), generally developers will not adopt this approach since typically domain objects do not take advantage of Dependency Injection, because they generally have few dependencies outside of the DOM itself, and they don’t require much configuration.
You might well be wondering, then, why so much attention is paid to the DOM.
The DOM is the most critical area that affects so many other parts of the application, parts that are managed by Spring, that getting it right is very important to getting your whole application right.
The Value Object Pattern was created to overcome a shortcoming in the original EJB specification that meant that all calls to an EJB were remote.
Configuring the state of an EJB typically means many calls, all of which are remote.
Using a value object, object state is transferred in bulk using a single remote call, thus reducing the performance hit of making many remote calls.
Martin Fowler defines a value object as “a small simple object, like money or a date range, whose equality isn’t based on identity.” You can find details at http://martinfowler.com/bliki/ValueObject.html.
A DOM is an object-based representation of the application problem domain, intended to allow the programmer to code in terms of objects that exist in the problem domain.
While a value object purely encompasses state, it is perfectly acceptable for a domain object to encompass both state and behavior (although you may choose not to encapsulate behavior inside domain objects)
Another key difference between domain objects and value objects is that a value object’s structure is driven by the need to transfer data remotely, whereas a domain object is modeled to represent a realworld concept and is not driven by some need of the application infrastructure.
As we discuss later, we believe there are no hard-and-fast rules for modeling domain objects; you have to choose a level of granularity that matches your application and the functions it will perform.
It is possible for an application to have both domain objects and value objects.
In this approach, value objects are used by the service layer to communicate with other layers, such as the presentation layer and the data access layer.
These value objects are then converted as appropriate into domain objects and passed into the presentation layer for rendering.
One reason is that maintenance will be complicated, because changes to domain objects also mean changes to the related value objects.
The other reason is that with Spring, the data access and web framework is so powerful that it is simple to map data directly to domain objects, both for processing and for presentation.
Why Create a Domain Object Model Creating a DOM requires some up-front effort in order to identify domain objects and then create an incode representation of these objects.
However, this up-front effort is far outweighed by the time you will save and the bugs you will avoid when it comes to implementing business logic to do something with your domain objects.
We find that using a good DOM makes creating the code to solve business problems much easier, since you are able to code in terms of the problem rather than in terms of the machine the application runs on.
A good DOM makes it easier for developers to transform application requirements into application features.
Modeling Domain Objects There are a great many different methodologies and approaches to domain object modeling.
Some practices advocate letting the underlying data store drive your object model, whereas some practices say, “Let the business domain drive the object model.” In practice, we have found that a happy medium between these two approaches results in a DOM that is both easy to work with and well-performing.
For small applications with only five or six database tables, it is often easier just to create one domain object that corresponds to each database table.
Although these objects are not strictly domain objectsin that their creation is not driven by the problem domain but rather the data structure—they are close enough for the purposes of such a simple application.
Indeed, in many small applications, the result of an extensive domain modeling process is an object model that matches the database structure entirely.
For larger applications, much more attention has to be put into the real-world problem domain and the underlying data store.
When we are building a DOM for an application, we usually focus on three main points:
What we are looking for is a DOM that is as close to the ideal model as possible without affecting the performance of the data store too much and without having too great an impact on code that has to use the domain objects.
Typically, a DOM is quite granular, and you might end up with more than one class for a single logical concept.
For instance, consider the concept of an order in a purchasing system.
Typically an order is modeled as a single Order object with one or more OrderLine objects that represent each line item of the order.
Trying to model an order using a single object leads to an object model that is unnecessarily coarse and unwieldy and difficult to implement and maintain.
You should always look for opportunities to increase the granularity of your domain objects when it makes working with the DOM easier.
You will also find that your DOM contains objects that do not exist in your datastore.
For instance, a typical purchasing system has some notion of a shopping cart, perhaps represented by Cart and CartItem objects.
Unless you are required to persist content across user sessions, chances are these domain objects do not have corresponding tables for data storage.
Remember, you are not simply building an object-oriented representation of your database; you are modeling the business domain.
We have seen plenty of projects that created a pseudo-DOM derived directly from the datastore, and inevitably these projects suffered from the lack of abstraction that can be gained from a well-defined DOM.
We have found that a solid DOM comes from taking the time to look at your problem domain, identifying the objects in the domain, and then looking at how the natural granularity of these objects fits into the requirements of your application.
Although we take both the utilization of the domain objects and the underlying data store into consideration, we don’t like to let these have undue influence on our DOM.
It is important to remember that the goal of building a DOM is to create a set of classes that help you and other developers build the application at a level of abstraction that is closer to the application’s problem domain.
In general, we consider all other concerns secondary when building a DOM.
For example, if you find that performance is suffering because of the design of your DOM, feel free to finetune the model.
However, make sure that the problem is caused by the design of the DOM (e.g., a single domain object was found containing a large number of long text fields like CLOB or TEXT, which impact the performance of data retrieval)
You don’t want to reduce the benefits of your DOM out of the mistaken belief that it is performing badly.
Database Modeling and Domain Object Modeling Although database modeling and domain object modeling are quite similar, the results you get from each are rarely the same, and indeed, you rarely want them to be.
When modeling a database, you are looking for the structure that allows you to store and retrieve data in the most efficient and consistent manner.
When you are building a DOM, performance is obviously important, but so is building an application on top of an object-oriented model that is easy to work with and makes assembling your business logic simple.
In general, we have found that it is best to model the database in the way that is best for the database and to model the DOM, initially at least, in a way that is best for the DOM.
You can make any changes later, if and when you identify performance bottlenecks.
Modeling Domain Object Relationships The most common mistake we see in a DOM, especially when the DOM is driven by the design of the database, is that domain objects are created to represent relationships among table entities.
This comes from the fact that a many-to-many relationship between two tables in a database must have a join table to construct the relationship.
Relationships in a DOM should be modeled in a much more OOP-style way, with domain objects maintaining references to other domain objects or lists of domain objects.
A common mistake when populating domain object data from a database, such as what would be done in the data access layer of an application, is to assume that all related domain objects (e.g., when retrieving data from the ORDER table into the Order domain object, the list of Item objects within the Order object should be retrieved from the ORDER_ITEM table together) must be loaded from the database as well—this is not so.
See the section “Domain Object Relationships” for a more detailed discussion of this problem.
To Encapsulate Behavior or Not? You are not forced to have your domain objects encapsulate any behavior at all; indeed, you can choose to have your domain objects represent just the state of your problem domain.
In most cases, we have found that it is better to factor out much of the business logic into a set of service objects that work with domain objects rather than encapsulate this logic inside the domain objects.
Typically, we place all logic that interacts with components outside of the DOM into the service objects.
In this way, we are reducing the coupling between the DOM and components involved in application logic.
This allows the DOM to be used in a wider variety of scenarios, and often, you will find that the DOM can be reused in other applications that solve problems in the same domain.
Where we like to encapsulate behavior in the DOM is in situations where the logic is implemented purely in interactions between domain objects.
The JPetStore sample application included with Spring provides a great example of this that can be mapped to our purchasing system example.
In this scenario, a user has a shopping cart, represented by a Cart object, and a list of CartItem objects.
When the user is ready to purchase the items in her cart and create an order, the application has to create an Order object along with a list of OrderLine objects that corresponds to the data modeled by the Cart and CartItem objects.
This is a perfect example of when behavior should be encapsulated inside the DOM.
The conversion from Cart to Order is coded purely in terms of domain objects with no dependencies on other components in your application.
In JPetStore, the Order class has an initOrder() method that accepts two arguments, Account and Cart.
All the logic required to create an Order based on the Cart object for the user represented by the Account object is represented in this method.
As with most things related to modeling, there are no hard-and-fast rules about when to put logic inside a domain object and when to factor it out into a service object.
You should avoid placing logic inside your domain objects when it causes your domain objects to depend on other application components outside of the DOM.
In this way, you are ensuring that your DOM is as reusable as possible.
On the flipside of this, logic that involves only domain objects is ideally placed in the DOM, which allows it to be used wherever the DOM is used.
Although the DOM is not very complicated, it does highlight some of the points we have been talking about.
Inheritance in the SpringBlog DOM Central to the SpringBlog application is the concept of a posting.
Postings come in two types: entries, which are top-level postings to the blog, and comments, which are comments about a particular blog entry.
We have decided to define common posting characteristics in an interface, BlogPosting, shown in Listing 12-3, and have both Entry and Comment implement this interface.
However, this results in undue code duplication, with both Entry and Comment having their own implementations of BlogPosting.
By extending this base class, we move all the BlogPosting implementation details out of Entry and Comment, reducing code duplication.
As an example of this, Listing 12-5 shows the code for the Entry class.
This is a pattern that is used extensively in Spring and throughout the SpringBlog application.
Common functionality is defined in interfaces rather than abstract classes, but we provide a default implementation of the interface as an abstract class.
The reason for this is that, where possible, we can take advantage of the abstract base class as with Entry and Comment, thus removing the need for each class to implement the BlogPosting interface directly.
However, should a requirement arise for the Entry class to extend the Foo class, then we can simply implement the BlogPosting interface directly in Entry.
The main point to remember here is that you do not define common functionality in terms of abstract classes because doing so restricts you to a set an inheritance hierarchy.
Instead, you define common functionality in terms of interfaces, along with default implementations of these interfaces as abstract base classes.
This way, you can take advantage of the inherited implementation wherever possible, but you are not artificially constraining your inheritance hierarchy.
A point worth noting here is that we did not reflect this inheritance tree in the database.
That is to say, we didn’t create a BLOG_POSTING table to store the shared data and then two tables, ENTRY and COMMENT, to store the entity-specific data.
The main reason for this is that we didn’t think that an application the size of SpringBlog warranted the complexity of that structure; plus, this example highlights our point about having a DOM that is different in structure than the database.
The main reason for defining this inheritance hierarchy, besides that it is a good design, is to allow the SpringBlog application to work with the common data in the Entry and Comment objects, without having to differentiate between the two.
Domain Behavior in SpringBlog Although the SpringBlog domain model is simplistic, we still need to encapsulate some logic in the domain model.
Because the body of a blog posting could potentially be very long, we wanted a mechanism to get a snippet of the body to use when it displays a list of blog postings.
Here you can see that to build the short body, we take the first 80 characters of the body and simply append three dots to the end.
This is a simplistic implementation, but it does highlight a typical scenario for encapsulating logic in the DOM.
Domain Object Relationships In the DOM represented in Figure 12-1, notice that we defined an association between Entry and Attachment and between Comment and Attachment.
As part of the SpringBlog requirements, we want to be able to upload and store files with both types of posting.
In the database, we have a table to store the attachments called ATTACHMENT.
A common mistake we see is that people create domain objects to model these relationships, rather than using standard Java features to relate the objects together.
When you have a one-to-one relationship in your database, you can model this in the DOM by having one object maintain a reference to the other.
For one-to-many or many-tomany relationships, using Java collections makes it simple to represent these complex relationships in a familiar manner that is simple to work with in code.
Listing 12-7, a snippet from the Entry class, shows how we use a Set to store the Attachment objects for each posting.
Rather than using additional objects to model relationships, we use a simple Set to model the oneto-many relationship.
Aside from reducing the amount of code we need to type, this method prevents the DOM from becoming polluted with needless classes and allows familiar Java concepts such as Iterator to be used when navigating relationships.
Domain Object Model Summary In this section, we looked at the DOM for the SpringBlog application, and we spent some time discussing the basics of domain object modeling and implementation.
There is no doubt that the scope of this topic is much broader than what we have covered here.
Indeed, a whole range of books is available that discusses the topic in detail (one excellent book about this topic is Domain-Driven Design: Tackling Complexity in the Heart of Software, Addison-Wesley Professional)
We only scratched the surface here, and we focused on why you want to build a DOM, what the focus is when building one, and some general topics related to the SpringBlog application.
Although it is certainly possible to build applications without defining and building a DOM, it is our experience that taking the time to do so pays off in reduced complexity, lower maintenance costs, and fewer bugs.
Designing and Building the Data Access Layer Having discussed the DOM, let’s proceed to the layer that is dedicated to performing the interaction between the database and transforming the retrieved data to the DOM for processing by the service layer.
For example, in some cases where the performance of data access is critical, the data access layer should be capable of firing tuned native queries to the database to maximize the performance on data retrieval.
However, because today the persistence frameworks have become much more mature and the rise of adopting JPA and its EntityManager that already hides the persistence provider from the developer, it is a common practice to eliminate the DAO layer.
Instead, the persistence provider Service Provider Interface (SPI) will be injected into the service layer directly when retrieving data.
For example, for JDBC, the access logic still involves writing a lot of queries within the code, and for this case, it’s still better to put that code in the DAO class to hide the service layer from those SQL statements.
Figure 12-4 shows another diagram within which the persistence providers (e.g., EntityManager in JPA, mapper interfaces in MyBatis) are injected into the service layer directly.
Practical Design Considerations Thanks to the evolution and maturity of various persistence technologies and Spring’s flexibility in integrating with those technologies, the task of designing and building a data access layer is much simpler these days.
Practically, the most difficult and time-consuming task is to perform mapping between the underlying database structure and the DOM in the application.
However, you should bear in mind a few practical considerations when creating your data access layer that will help you build data access logic that is simpler to use and easier to extend.
Domain Objects or Data Transfer Objects? Most of the time you don’t need to rely on DTO for shipping data between different layers.
As discussed earlier this chapter, nowadays all popular persistence technologies and JEE itself supports using POJO as the underlying DOM, making it possible for the service layer, presentation layer only, and data access layer to communicate using domain objects directly.
Since all domain objects are now POJOs, they can be easily supported by frontend presentation frameworks (e.g., Spring MVC, JSF, Adobe Flex, to name a few) to directly interact with the service layer via domain objects.
However, in some cases, the DTO Pattern is still worth considering.
For example, a domain object contains many long text data attributes that may not be required to send to the frontend for every request.
In this case, it is worth considering whether to create a value object that stores only the exact attributes required by the corresponding frontend in order to minimize the data transfer between the presentation layer and service layer.
When writing code in your service objects to work with your DAOs, code to the interfaces, not the implementation classes.
Remember that when you are using Spring, it is a trivial job to pass an instance of the appropriate DAO implementation to your service layer, so using interfaces for your DAOs places very little additional coding burden on you.
Sometimes, these structures appear naturally after thoughtful design, but don’t assume that either one of these structures is necessarily the best.
A big problem we often see with projects is the “one DAO per table” problem.
When you define a structure like this, you end up with DAOs representing join tables that serve no purpose other than to join two other tables in a many-to-many relationship.
Plus, you often find that you have to pass a single domain object to lots of different DAOs to have the data persisted.
This is a classic example of letting the database drive the design of your DAO layer.
This is something that, in practice, we have found to be a bad idea.
The purpose of a DAO is to map domain objects to the database, and vice versa.
Because the bulk of your application is interacting with the domain objects, not the database, it makes sense to let the DOM drive database design.
Let your DAOs hide the complexity of mapping the data in your domain objects to the database; that is their job.
You are trying to avoid the situation where persisting a domain object requires you to interact with many different DAOs.
Situations like this arise naturally, such as when a domain object has a reference to another domain object of a different type and both have been modified and thus need to be persisted.
In this case, you can encapsulate that logic in your service layer, but you do not need to create this problem artificially.
So, then you might wonder if you should let the DOM drive the design of the DAOs.
Yes, in that the purpose of the DAO is to get DOM data into and out of the persistent data store, so it makes sense to let the DOM act as the driver.
No, in that blindly creating one DAO per domain object leads to a situation where the persistence of one logical unit of data leads to calls to many different DAOs.
Consider the earlier example of the Order and OrderLine objects that are created from the Cart and CartItem objects.
Because it is unlikely that you are going to want to save or retrieve OrderLine objects without doing the same to an Order object, it makes sense to encapsulate persistence logic for both domain objects in a single OrderDao, rather than create OrderDao and OrderLineDao.
Data Access Layer Summary Creating a data access layer for your application provides the rest of your application components with a standard mechanism for storing and retrieving data.
Without a data access layer, you will find that data access code becomes spread out through your application, often resulting in code duplication that is hard to maintain.
In the long term, this poorly managed code inevitably leads to bugs and developer headaches.
Depending on the technology decision of implementing the data access layer, most of the time you won’t need to adopt the DAO Pattern anymore.
Many popular persistence technologies and standards already do a very good job of hiding all the database access details for you.
So, it’s recommended that you inject those persistence providers to the service layer directly.
This will simplify the application architecture, as well as result in code that is easier to trace and maintain.
In case you decided to use DAO or it’s the standard that your team or company has standardized on, you should always define DAOs as interfaces and then implement these interfaces using your chosen data access technology.
When you are using Spring, working with interfaces is trivial, and you can easily provide concrete implementations of your DAO interfaces to other components in your application.
In this section, we looked at some of the main design-related issues that are present when you are building a data access layer for your application.
In reality, much of the complexity in a data access layer comes from implementation, not design.
Designing the Service Layer At this point in our application design discussion, we have a way of representing the data in our problem domain so that we can manipulate it in code, and we have a way of storing this data in a database and then getting it back out later.
However, currently we are not doing much with this data.
Unless your application is especially simplistic, chances are some kind of logic needs to be implemented.
Earlier, we discussed cases where you should encapsulate logic inside your domain objects.
In this section, we look at providing a layer of service objects to provide a standard interface to the rest of your application logic.
Why Have a Service Layer As with the question as to why you should have a data access layer, the answer to this question is plain and simple once you have implemented a few applications without one.
If you do not bring together all the business logic in a single place, it ends up spread out through your presentation code, typically resulting in lots of code duplication, not to mention creating code that lacks clearly defined boundaries for responsibilities.
Code duplication issues aside, failing to define clear boundaries between code with different responsibilities often results in code that is difficult to trace and maintain, because it becomes hard to pinpoint the location of a given function.
A well-defined service layer acts as a sort of gateway into your application, providing your presentation code with a simple, unified way to get at business logic.
A significant drawback of not having a service layer comes about when you decide to have two kinds of user interface for the same logic.
Perhaps you built a web application, but now you want to provide a desktop-based application for users who use the application often.
If your business logic code is embedded within your web presentation code, you are going to have to either refactor the code out of the presentation layer, which requires a significant amount of effort in rework and testing, or simply reproduce the business logic code again, this time embedded within the code of the rich client (e.g., Swing, RCP, and so on)
Nowadays, besides various frontends, your business services will also probably be accessible from other systems.
For example, your application may provide real-time stock quote information to some other third-party business partners.
Mostly likely, you will need to support the access by those partners to your real-time data via web services (e.g., web services, RESTful-WS, and so on)
Also, when processing data in batches (e.g., from a file), the data manipulation logic should not have much difference from that of a user entering the data via the web interface.
A centralized service layer as the entry point for data coming from all possible sources becomes a critical part in keeping your application maintainable.
Designing Business Interfaces As with most components in your application, you should start by defining a set of interfaces for the service objects in your application.
Any code that interacts with your service layer should do so through these interfaces.
For components that Spring manages, you can supply implementations using DI.
If you have to support components that Spring does not manage, you may want to supply a simple Factory class to allow for implementation lookup.
Service Layer Dependencies As with all the interfaces we have talked about, you should avoid defining dependencies in the interfaces of your service objects.
A welldefined service object interface has only those methods that serve business functions.
Avoid exposing types from your data access layer through your service objects.
Your service objects should insulate the presentation code from the underlying data access layer completely.
For example, one of your service objects might access all its data using web services or via a JMS queue.
A good way to ensure that your service object interface is as accessible as possible is to ensure that return and argument types do not couple the presentation code to anything other than the DOM.
You are going to be passing domain objects through all the layers of your application, but other components such as DAOs should stay well within their own layer.
Service Object Granularity When designing the objects required in the service layer, try to relate them with the possible use cases in the business requirements.
A common practice is to group the logic that manipulates highly related domain objects into the same service object interface.
For example, in the SpringBlog application, the design of the service layer is composed of the interfaces listed in Table 12-1
Bear in mind that in application design, there is no definitely right or wrong approach.
A good design should be easy to document and understandable by both the technical team as well as the business analyst.
Finally, make sure your service layer doesn’t couple to any special type of consumer.
Service Layer Summary In this section, we discussed the issues you should consider when designing and building a service layer for your Spring application.
Then, by looking at the SpringBlog’s service layer, we demonstrated how to design the interfaces within the service layer by grouping operations for closely related domain objects into the same service interface.
Summary In this chapter, we looked at a lot of problems associated with traditional applications, and you saw how Spring can help you solve these problems.
We discussed a variety of problems that occur during application development, and we looked at sensible ways in which these problems can be solved effectively.
Throughout the chapter, we examined how the practices we discussed were used when we design the SpringBlog application.
This chapter only scratched the surface of application design as a whole, but we covered some major considerations that are specific to Spring-based applications and problems that you can fix easily when using Spring.
In the next chapter, we present a detailed look at transaction support, including full examples of both local and distributed transactions and some useful tips for testing transactional methods.
Transactions are one of the most critical parts of building a reliable enterprise application.
The most common type of transaction is a database operation.
In a typical database update operation, a database transaction begins, data is updated, and then the transaction is committed or rolled back, depending on the result of the database operation.
However, in many cases, depending on the application requirements and the backend resources that the application needs to interact with (such as an RDBMS, message-oriented middleware, an ERP system, and so on), transaction management can be much more complicated.
In the early days of Java application development (after JDBC was created but before the JEE standard or an application framework like Spring was available), developers programmatically controlled and managed transactions within application code.
When JEE and, more specifically, the EJB standard became available, developers were able to use container-managed transactions (CMTs) to manage transactions in a declarative way.
But the complicated transaction declaration in the EJB deployment descriptor was difficult to maintain and introduced unnecessary complexity for transaction processing.
Some developers favored having more control over the transaction and chose bean-managed transactions (BMT) to manage transactions in a programmatic way.
However, the complexity of programming with the Java Transaction API (JTA) also hindered developers’ productivity.
The most appropriate way to implement transaction management is to allow developers to define transaction requirements in a declarative way and have frameworks such as Spring, JEE, or AOP weave in the transaction processing logic on our behalf.
Spring provides support for both declarative and programmatic transaction management.
Spring offers excellent support for declarative transactions, which means you do not need to clutter your business logic with transaction management code.
All you have to do is declare those methods (within classes or which layers) that must participate in a transaction, together with the details of transaction configuration details, and Spring will take care of handling the transaction management.
To be more specific, in this chapter we look at the following:
Spring transaction abstraction layer: We discuss the base components of Spring transaction abstraction classes and explain how to use these classes to control the properties of the transactions.
Declarative transaction management: We show you how to use Spring to implement declarative transactional management using just plain Java objects.
We offer examples for declarative transaction management using the XML configuration files as well as Java annotations.
Global transactions with JTA: For global transactions that need to span multiple backend resources, we will show an example of how to configure and implement global transactions in Spring using JTA.
Exploring the Spring Transaction Abstraction Layer When developing your applications, no matter whether you choose to use Spring or not, you have to make a fundamental choice when you use transactions about whether to use global or local transactions.
Local transactions are specific to a single transactional resource (a JDBC connection, for example), whereas global transactions are managed by the container and can span multiple transactional resources.
Transaction Types Local transactions are easy to manage, and if all operations in your application need to interact with just one transactional resource (such as a JDBC transaction), using local transactions will be sufficient.
However, if you are not using an application framework such as Spring, you have a lot of transaction management code to write, and if in the future the scope of the transaction needs to be extended across multiple transactional resources, you have to drop the local transaction management code and rewrite it to use global transactions.
In the Java world, global transactions were implemented with the Java Transaction API (JTA)
In this scenario, a JTA-compatible transaction manager connects to multiple transactional resources via respective resource managers, which are capable of communicating with the transaction manager over the XA protocol (an open standard defining distributed transactions), and the 2 Phase Commit (2PC) mechanism was used to ensure that all backend datasources were updated or rolled back altogether.
If either of the backend resources fails, the entire transaction will roll back, and hence the updates to other resources will be rolled back too.
Figure 13-1 shows a high-level view of global transactions with JTA.
As shown in Figure 13-1, four main parties participate in a global transaction (also generally referred to as distributed transactions)
The first party is the backend resource, such as an RDBMS, messaging middleware, an enterprise resource planning (ERP) system, and so on.
The second party is the resource manager, which was generally provided by the backend resource vendor and is responsible for interacting with the backend resource.
For example, when connecting to a MySQL database, we will need to interact with the MysqlXADataSource class provided by MySQL’s Java connector.
Other backend resources (e.g., MQ, ERP, and so on) will provide their resource managers too.
The third party is the JTA transaction manager, which is responsible for managing, coordinating, and synchronizing the transaction status with all resource managers that are participating in the transaction.
The XA protocol will be used, which is an open standard widely used for distributed transaction processing.
The JTA transaction manager also supports 2PC so that all changes will be committed together, and if any resource update fails, the entire transaction will be rolled back, resulting in none of the resources being updated.
The entire mechanism was specified by the Java Transaction Service (JTS) specification.
Either the application itself or the underlying container or Spring framework that the application runs on will manage the transaction (begin, commit, roll back a transaction, and so on)
At the same time, the application will interact with the underlying backend resources via various standards defined by JEE.
As shown in Figure 13-1, the application connects to the RDBMS via JDBC, MQ via JMS, and an ERP system via Java Connector Architecture (JCA)
As for standalone applications or web containers (e.g., Tomcat, Jetty, and so on), there also exists open source and commercial solutions that provide support for JTA/XA in those environments (e.g., Atomikos, JOTM, Bitronix, and so on)
The actual implementation of these interfaces must have detailed knowledge of the transaction manager.
Spring also provides several JTA transaction manager classes that are specific to particular application servers.
Analyzing Transaction Properties In this section, we will discuss the transaction properties that Spring supports, focusing on interacting with RDBMS as the backend resource.
You cannot control the atomicity, consistency, and durability of a transaction, but you can control the transaction propagation and timeout, as well as configure whether the transaction should be read-only and specify the isolation level.
The TransactionStatus interface is used to control the transaction execution, more specifically to set the transaction result and to check whether the transaction is completed or whether it is a new transaction.
The simple and obvious methods of this interface are getTimeout(), which returns the time (in seconds) in which the transaction must complete, and isReadOnly(), which indicates whether the transaction is read-only.
The transaction manager implementation can use this value to optimize the execution and check to make sure that the transaction is performing only read operations.
Table 13-1 lists the transaction isolation levels you can use and explains what changes made in the current transaction other transactions can access.
However, the data that was read by one transaction can be updated by other transactions.
However, if other transactions insert new data, you can still select the newly inserted data.
Choosing the appropriate isolation level is very important for the consistency of the data, but making these choices can have a great impact on performance.
If there is no transaction, it starts a new one.
The TransactionStatus Interface The TransactionStatus interface, shown in Listing 13-2, allows a transactional manager to control the transaction execution.
The code can check whether the transaction is a new one or whether it is a readonly transaction and it can initiate a rollback.
The methods of the TransactionStatus interface are fairly self-explanatory; the most notable one is setRollbackOnly(), which causes a rollback and ends the active transaction.
The hasSavePoint() method returns whether the transaction internally carries a save point (i.e., that transaction was created as a nested transaction based on a save point)
The flush() method flushes the underlying session to a datastore if applicable (e.g., when using with Hibernate)
The isCompleted() method returns whether the transaction has ended (i.e., committed or rolled back)
Sample Data Model and Infrastructure for Example Code This section provides an overview of the data model and the infrastructure that will be used in the examples of transaction management.
In this chapter, we will use JPA with Hibernate as the persistence layer for implementing data access logic.
In addition, the Spring Data JPA and its repository abstraction will also be used to simplify basic database operations development.
Then, enter the project details, as shown in Figure 13-3
Upon project creation, we also need to add the required dependencies to the project for the examples in this chapter.
Required for the example of the aop-namespace for transaction declaration.
To observe the detailed behavior of the example code as we modify the transaction attributes, let’s also turn on the DEBUG-level logging in log4j.
Sample Data Model and Common Classes To keep things simple, we will use just one table, the CONTACT table, that we used throughout the chapters about data access.
The entity class is simple too; Listing 13-6 shows the Contact class.
As shown in Listing 13-7, no additional method is required, because those methods provided by the CrudRepositoy interface already are sufficient for the examples in this chapter.
Finally, let’s take a look at the ContactService interface, which defines all the business logic in relation to the Contact entity class.
In the next section, we will discuss how to implement transaction management in various ways by implementing the ContactService interface.
Declarative and Programmatic Transactions with Spring In Spring, there are three options for transaction management.
Two of them are for declarative transaction management, with one using Java annotations and the other using XML configuration.
We will go through the three of them one by one in the following sections.
Using Annotations for Transaction Management Currently, using annotations is the most common way to define transaction requirements in Spring.
The main benefit is that the transaction requirement, together with the detail transaction properties (timeout, isolation level, propagation behavior, and so on), were defined within the code itself, which makes the application easier to trace and maintain.
If you have read Chapter 10, the previous configuration should be familiar to you.
First, an embedded H2 database was defined with the database creation and data population scripts.
Finally, the <jpa:repositories> tag was used to enable Spring Data JPA’s repository abstraction.
Listing 13-10 shows the ContactServiceImpl class with the findAll() method implemented.
When using annotation-based transaction management, the only annotation that we need to deal with is the @Transactional annotation.
The @Transactional annotation supports a number of attributes that you can provide to override the default behavior.
Table 13-4 shows the available attributes, together with the possible and default values.
An integer value larger than zero; indicates the number in seconds for transaction timeout.
This will override the default annotation applied at the class level, with all other attributes unchanged, but the transaction is set to read-only.
Listing 13-11 shows the testing program for the findAll() method.
As shown in the previous output, the irrelevant output statements were removed for clarity.
The notable log messages relating to transaction processing are in bold.
Then, the query is submitted, and upon completion and without any errors, the transaction is committed.
We need to implement both the findById() and save() methods in the ContactService interface.
Generally, the readOnly=true attribute should be applied to all finder methods.
The main reason is that most persistence providers will perform a certain level of optimization on read-only transactions.
For example, Hibernate will not maintain the snapshots of the managed instances retrieved from the database with read-only turned on.
This means the class-level annotation will be used, which is a read-write transaction.
Let’s modify the TxAnnotationSample class for testing the save() method, as shown in Listing 13-13
You can see that for the transaction for the save() method, the default attributes are inherited from the class-level @Transactional annotation.
We will investigate two different transaction configurations for this method.
It’s mainly because the methods defined by the CrudRepository interface in Spring Data were already marked with the appropriate transaction attributes.
Listing 13-14 shows the new method countAllContacts() defined in the ContactRepository interface.
Listing 13-15 shows the implementation of the countAll() method in the ContactServiceImpl class.
As shown in the previous output, you can see that the transaction for the countAll() was created with read-only equaling true as expected.
But for the countAll() function, we don’t want it to be enlisted in a transaction at all.
The reason is that we don’t need the result to be managed by the underlying JPA EntityManager.
Instead, we just want to get the count and forget about it.
Run the testing code in Listing 13-16 again, and you will find that the transaction will not be created for the countAll() method.
This section covered some major configurations that you will deal with when processing transactions on a day-to-day basis.
For special cases, you may need to define the timeout, isolation level, rollback (or not) for specific exceptions, and so on.
Instead, it will always use the default isolation level for the underlying datastore.
However, ever since version 2, Spring provides a much simpler way by introducing aop-namespace and using the common AOP configuration technique for defining transaction requirements.
In this section, the example we will use is the same as the annotation one.
We will just modify it to the XML configuration style.
The configuration is quite similar to the annotation one in Listing 13-9 (the differences are in bold)
The advice is referencing the bean with an ID of txAdvice, which is defined by the <tx:advice> tag.
In the <tx:advice> tag, we configure the transaction attributes for various methods that we want to participate in a transaction.
As shown in the tag, we specify that all finder methods (i.e., methods with the prefix find) will be read-only, and we specify that the count methods (i.e., methods with the prefix count) will not participate in transaction.
For the rest of the methods, the default transaction behavior will be applied.
This configuration is the same as the one we did in the annotation example.
Listing 13-19 shows the implementation class for XML declarative transaction management.
Using Programmatic Transactions The third option is to control the transaction behavior programmatically.
As shown in Listing 13-21, the AOP transaction advice was removed.
Let’s take a look on the implementation of the countAll() method, which is shown in Listing 13-22
We will leave it to you to run the program and observe the result.
Try to tweak the transaction attributes and see what happens in the transaction processing of the countAll() method.
Considerations on Transaction Management So, having discussed the various ways for implementing transaction management, which one should you use? The declarative approach is recommended in all cases, and you should avoid implementing transaction management within your code as far as possible.
Most of the time when you find it necessary to code transaction control logic in the application, it is because of bad design, and in this case, you should consider refactoring your logic into manageable pieces and have the transaction requirements defined on those pieces declaratively.
For the declarative approach, using XML and using annotations both have their own pros and cons.
Some developers prefer not to declare transaction requirements in code, while others prefer using annotations for easy maintenance, because you can see all the transaction requirement declaration within the code.
Again, let the application requirements drive your decision, and once your team or company has standardized on the approach, stay consistent with the configuration style.
Global Transactions with Spring Many enterprise Java applications will need to access multiple backend resources.
For example, a piece of customer information received from an external business partner will need to update the databases for multiple systems (CRM, ERP, and so on)
Some will even need to produce a message and send it to an MQ server via JMS for all other applications within the company that are interested in customer information.
Transactions that span multiple backend resources are referred to as global (or distributed) transactions.
A main characteristic of a global transaction is the guarantee of atomicity, which means that involved resources are all updated or none is updated.
This includes complex coordination and synchronization logic that should be handled by the transaction manager.
In the Java world, JTA is the de facto standard for implementing global transactions.
Spring supports JTA transactions equally well as local transactions and hides that logic from the business code.
In this section, we will demonstrate how to implement global transactions by using JTA with Spring.
Infrastructure for Implementing the JTA Sample We are using the same table as the previous samples in this chapter.
However, the embedded H2 database doesn’t fully support XA (at least at the time of writing), so in this example, we will use MySQL as the backend database.
We also want to show how to implement global transactions with JTA in a stand-alone application or web container environment.
To show how global transactions work, we need at least two different backend resources.
To make things simple, we will use one MySQL database but two JPA entity managers to simulate the use case.
The effect is the same because you have multiple JPA persistence units to distinct backend databases.
The version we are using in developing this sample is the MySQL 5.1.58 Community Server edition.
In the MySQL database, we will create two schemas, as shown in Table 13-5
However, you can use whatever tools you feel familiar with to set up the schemas and users.
Then, we will need to add the required dependencies on MySQL and Atomikos to the project.
After the setup has completed, we can proceed to the Spring configuration and implementation.
First, two datasource beans are defined to indicate the two different database resources.
Note that the poolSize attribute defines the number of connections within the connection pool that Atomikos need to maintain.
The implementation classes are provided by Atomikos, which implements the standard JEE’s TransactionManager and UserTransaction interfaces, respectively.
Those beans provide the transaction coordination and synchronization services required by JTA and communicate with the resource managers over the XA protocol in supporting 2PC.
This instructs Spring to use Atomikos JTA for transaction management.
The emfBase bean is an abstract parent bean, which wraps the common JPA properties.
The emfA and emfB beans both inherit the configuration from the parent bean emfBase, and the only difference between the two beans is that they were injected with the corresponding datasource (i.e., dataSourceA injected into emfA, and dataSourceB injected into emfB)
These two properties are very important, because they are used by Hibernate to look up the underlying UserTransaction and TransactionManager interfaces in order to participate in the persistence context that it’s managing into the global transaction.
Note that for simplicity only the save() method is implemented.
From Listing 13-25, the two entity managers defined are injected into the ContactServiceImpl class.
In the save() method, we will persist the contact object to the two different schemas, respectively.
Ignore the throw exception statement at the moment; we will use it later to verify that the transaction was rolled back when saving to the schema prospring3_ch13b fails.
The implementation will try to persist the same object to two databases.
Running the program will produce the following output (the other output was omitted):
From the output, you will see that Atomikos creates a composite transaction, communicates with the XA datasource (MySQL in this case), performs synchronization, commits the transaction, and so on.
From the database, you will see that the new contact is persisted to both schemas of the database, respectively.
As shown in the code in Listing 13-25, instead of calling emB.persist(), we just throw an exception.
As shown in the previous output, the first contact is persisted (note the insert statement)
However, when saving to the second datasource, because an exception is thrown, Atomikos will roll back the entire transaction.
You can take a look at the schema prospring3_ch13a to check that the new contact was not saved.
Considerations on Using JTA Transaction Manager Whether to use JTA for global transaction management is under hot debate.
For example, the Spring development team generally does not recommend using JTA for global transactions, and SpringSource’s Dr.
As a general principle, when your application is deployed to a full-blown JEE application server, there is no point not using JTA because all the vendors of the popular JEE application servers have optimized their JTA implementation for their platforms.
For stand-alone or web container deployment, let the application requirements drive your decision and perform load testing as early as possible to verify that the performance is not being impacted by using JTA.
One piece of good news is that Spring works seamlessly with both local and global transactions in most major web and JEE containers, so code modification is generally not required when you switch from one transaction management strategy to another.
There is another excellent article from Spring’s team discussing using Spring with JTA (http://blog.springsource.org/2011/08/15/configuring-spring-and-jta-without-fulljava-ee)
Summary Transaction management is a key part of ensuring data integrity in almost any type of application.
In this chapter, we discussed how to use Spring to manage transactions with almost no impact on your source code.
You also learned how to use local and global transactions.
We provided various examples of transaction implementation, including declarative ways of using XML configuration and annotation, as well as the programmatic approach.
Local transactions are supported inside/outside of a JEE application server, and only simple configuration is required to enable local transaction support in Spring.
However, setting up a global transaction environment involves more work and greatly depends on which JTA provider and corresponding backend resources your application needs to interact with.
The purpose of validation is to verify that the data being processed fulfills all predefined business requirements as well as to ensure the data integrity and usefulness in other layers of the application.
In application development, data validation is always mentioned along with conversion and formatting.
The reason is that most likely the format of the source of data is different from the format being used in the application server.
For example, in a web application, a user enters information in the web browser frontend.
When the user saves the data, the data is sent to the server (after the local validation has completed)
On the server side, a data-binding process will be performed, in which the data from the HTTP request will be extracted, converted, and bound to the corresponding domain objects (for example, users enter contact information in an HTML form that will be bound to a Contact object in the server), based on the formatting rules defined for each attribute (for example, the date format pattern is yyyy-MM-dd)
When the data binding is complete, the validation rules are applied to the domain object to check for any constraint violation.
If everything runs fine, the data is persisted, and a success message is displayed to the user.
Otherwise, validation error messages are populated and displayed to the user.
In the first part of this chapter, you will learn how Spring provides sophisticated support for type conversion, field formatting, and validation.
We will show you how the new services can be used to replace the previous PropertyEditor support and how they convert between any Java types.
Validation in Spring: We will discuss how Spring supports domain object validation.
First, we will provide a short introduction to Spring’s own Validator interface.
Creating a Project in STS for Samples Let’s create the project for the samples in this chapter.
In addition, upon project creation, add the other required dependencies , as shown in Table 14-1
In this chapter, we will use it in our domain objects.
Spring Type Conversion System In Spring 3, a new type conversion system was introduced, providing a powerful way to convert between any Java types within Spring-powered applications.
In this section, we will discuss how this new service can perform the same functionality provided by the previous PropertyEditor support, as well as how it supports the conversion between any Java types.
We will also demonstrate how to implement a custom type converter using the Converter SPI.
Conversion from a String Using PropertyEditors In Chapter 5, we covered how Spring handles the conversion from a String in the properties files into the properties of POJOs by supporting PropertyEditors.
Let’s do a quick review here, and then we will cover how Spring’s Converter SPI (available since 3.0) provides a more powerful alternative.
Consider a Contact class with a couple of attributes, as in Listing 14-1
As shown in Listing 14-1, for the birth date attribute, we use JodaTime’s DateTime class.
In addition, there is a URL type field that indicates the contact’s personal web site if applicable.
As shown in Listing 14-2, we construct two different beans of the Contact class.
The clarence bean is constructed with values provided in the configuration file, while for the myContact bean, the attributes are externalized into a properties file.
In addition, a custom editor is defined for converting from a String to JodaTime’s DateTime type, and the date-time format pattern is externalized in the properties file too.
Listing 14-4 shows the custom editor for converting String values into the JodaTime DateTime type.
As shown in Listing 14-5, the two different Contact beans are retrieved from ApplicationContext and printed.
As shown in the output, the properties are converted and applied to the Contact beans.
Figure 14-1 shows the logical view on how the conversion by PropertyEditors was done.
In addition to providing an alternative to PropertyEditor support, the type conversion system can also be configured to convert between any Java types and POJOs (while PropertyEditor is focused on converting String representations in the properties file into Java types)
Implementing a Custom Converter To see the type conversion system in action, let’s revisit the previous example and use the same Contact class.
Suppose this time we want to use the type conversion system to convert the date in String format into the Contact’s birthDate property, which is of JodaTime’s DateTime type.
Then, in the initialization method (the init() method annotated with @PostConstruct), an instance of JodaTime’s DateTimeFormat class is constructed, which will perform the conversion based on the specified pattern.
Finally, the convert() method is implemented to provide the conversion logic.
By default, the type conversion service supports conversion between common types including strings, numbers, enums, collections, maps, and so on.
For the conversionService bean, a custom converter is configured for conversion from a String to DateTime.
As you can see, the clarence bean’s property conversion result is the same as when we use PropertyEditors.
Converting Between Arbitrary Types The real strength of the type conversion system is the ability to convert between arbitrary types.
To see it in action, suppose we have another class, called AnotherContact, that is the same as the Contact class.
We want to be able to convert any instance of the Contact class to the AnotherContact class, but the firstName and lastName of Contact will become lastName and firstName of AnotherContact, respectively.
The class is simple; just swap the firstName and lastName attributes between the Contact and AnotherContact classes.
The order of the beans within the converters property is not important.
To test the conversion, we use the same testing program as the previous sample, which is the.
In Listing 14-12, look at the bold line, in which a handle to the ConversionService interface is obtained from the ApplicationContext.
Because we already registered the ConversionService in ApplicationContext with our custom converters, we can use it to convert the Contact object, as well as convert between other types that the conversion service already supports.
As shown in the output, you will see that Contact and AnotherContact are converted correctly, as well as the String to Array and the List to Set.
With Spring’s type conversion service, you can create custom converters easily and perform conversion at any layer within your application.
One possible use case is that you have two different systems with the same contact information that you need to update.
However, the database structure is different (for example, the last name in system A means the first name in system B, and so on)
You can use the type conversion system to convert the objects before persisting to each individual system.
Starting with Spring 3.0, Spring MVC makes heavy use of the conversion service (as well as the formatter SPI that we will discuss in the next section)
Field Formatting in Spring 3 Besides the type conversion system, another great feature that Spring brings to developers is the Formatter SPI.
As you might expect, this SPI can help configure the field-formatting aspects.
Spring provides a few implementations of commonly used types, including CurrencyFormatter, DateFormatter, NumberFormatter, and PercentFormatter.
Implementing a Custom Formatter Implementing a custom formatter is easy too.
We will use the same Contact class and implement a custom formatter for converting the DateTime type of the birthDate attribute to and from a String.
The parse() method parses the String format into the DateTime type (the locale was also passed for localization support), while the print() method is to format a DateTime instance into a String.
The date pattern can be injected into the bean (or the default will be yyyy-MM-dd)
Also, in the init() method, the custom formatter is registered by calling the setFormatters() method.
In the output, you can see Spring uses our custom formatter’s parse() method to convert the property from a String to the DateTime type of the birthDate attribute.
Validation in Spring Validation is a critical part of any application.
Validation rules applied on domain objects ensure that all business data is well structured and fulfills all the business definitions.
The ideal case is that all validation rules are maintained in a centralized location and the same set of rules are applied to the same type of data, no matter which source the data comes from (for example, user input via a web application, from a remote application via web services, from a JMS message, from a file, and so on)
When talking about validation, conversion and formatting are important too, because before a piece of data can be validated, it should be converted to the desired POJO according to the formatting rules defined for each type.
For example, a user enters some contact information via the web application within the browser and then submits the data to the server.
On the server side, if the web application was developed in Spring MVC, Spring will extract the data from the HTTP request and perform the conversion from a String to the desired type based on the formatting rule (for example, a String representing a date will be converted into a Date field, with the formatting rule yyyy-MM-dd)
When the data binding is complete and the domain object constructed, validation will then be applied to the object, and any errors will be returned and displayed to the user.
If validation succeeds, the object will be persisted to the database.
We will go through both of them in the coming sections.
Using Spring Validator Interface Using Spring’s Validator interface, we can develop some validation logic by creating a class to implement the interface.
For the Contact class that we’ve worked with so far, suppose the first name cannot be empty.
To validate Contact objects against this rule, we can create a custom validator.
As shown in Listing 14-16, the validator class implements the Validator interface and implements two methods.
The supports() method indicates whether validation of the passed-in class type is supported by the validator.
The last argument is the error code, which can be used for looking up validation messages from resource bundles for displaying localized error messages.
Listing 14-18 shows the testing program for the validator class.
As shown in Listing 14-18, a Contact object is constructed with first name set to null.
The validation produces one error, and the error code is displayed correctly.
In addition, custom validators (for example, class-level validators) can be developed and applied using annotation.
Using the Bean Validation API frees you from coupling to a specific validation service provider.
By using the Bean Validation API, you can use standard annotations and the API for implementing validation logic to your domain objects, without knowing the underlying validation service provider.
For example, the Hibernate Validator (http://hibernate.org/subprojects/validator) is a popular JSR-303
If you created the simple Spring JPA utility project in Chapter 10, the dependency on Hibernate Validator was already added for you.
Let’s go through them one by one in the following sections.
Defining Validation Constraints on Object Properties Let’s begin with applying validation constraints to domain object properties.
Listing 14-19 shows a Customer class with validation constraints applied to the firstName and customerType attributes.
In Listing 14-19, the validation constraints applied are shown in bold.
The first one is governed by the @NotNull annotation, which indicates that the value should not be null.
Moreover, the @Size annotation governs the length of the firstName attribute.
The @NotNull constraint is applied to the customerType attribute too.
The customer type indicates whether a customer is an individual or a company, while the gender should be applied for only individual customers.
By default, Spring will search for the existence of the Hibernate Validator library in the classpath.
Now, let’s create a service class that provides a validation service for the Customer class.
As shown in Listing 14-24, a Customer object is constructed with firstName and customerType violating the constraints.
As you can see, there are two violations, and the messages are shown.
In the output, you will also see that Hibernate Validator had already constructed default validation error messages based on the annotation.
You can also provide your own validation error message, which we will demonstrate in the next section.
Creating a Custom Validator Besides attribute-level validation, we can apply class-level validation.
For example, for the Customer class, for individual customers, we want to make sure that the lastName and gender attributes are not null.
In this case, we can develop a custom validator to perform the check.
In the Bean Validation API, developing a custom validator is a two-step process.
First create an Annotation type for the validator, as shown in Listing 14-25
The second step is to develop the class that implements the validation logic.
The @Constraint annotation indicates that it’s a validator, and the validatedBy attribute specifies the class providing the validation logic.
Within the body, three attributes are defined (in the form of a method), as follows:
The message attribute defines the message (or error code) to return when the constraint is violated.
It’s possible to assign validators to different groups and perform validation on a specific group.
It allows you to attach additional information to the constraint (for example, a payload object can indicate the severity of a constraint violation)
The isValid() method is implemented, and the underlying validation service provider (for example, Hibernate Validator) will pass the instance under validation to the method.
In the method, we verify that if the customer is an individual, then the lastName and gender properties should not be null.
The result is a boolean value that indicates the validation result.
Running the program produces the following output (the other output was omitted):
In the output, you can see that the value under check (which is the Customer object) violates the validation rule for individual customers, because the gender attribute is null.
Note also that in the output, the property path is empty, because it’s a class-level validation error.
Using AssertTrue for Custom Validation Besides implementing a custom validator, another way to apply custom validation in the Bean Validation API is using the @AssertTrue annotation.
When invoking validation, the provider will invoke the checking and make sure that the result is true.
Now run the testing program (Jsr303Sample) again, and you will get the same output as produced by the custom validator.
However, for validators with more complicated logic (for example, you need to inject a service class, access a database, and check for some valid values), then implementing a custom validator is the way to go, because you never want to inject service-layer objects into your domain objects.
Also, custom validators can be reused across similar domain objects.
Which Validation API to Use? Having discussed Spring’s own Validator interface and the Bean Validation API, which one should you use in your application? JSR-303 is definitely the way to go.
JSR-303 provides a standard validation API that hides the underlying provider, so you are not tied to a specific provider.
Validation with Type Conversion and Formatting in the Sample Application In the SpringBlog application, Spring 3’s new type conversion and formatting system will be adopted.
For validation, the JSR-303 Bean Validation API will be used, with Hibernate Validator as the underlying validation service provider.
The class stores the common properties such as the subject, body, and post date, among others.
The postDate field will be automatically populated by the application, and when it is displayed to the frontend, we will use the format yyyy-MM-dd (the default date pattern defined by ISO)
By defining the message this way, i18n can be implemented easily.
Those annotations belong to Spring 3’s type conversion and formatting system.
For postDate, the pattern is defined as ISO.DATE, which stands for the pattern yyyy-MM-dd.
Enabling the validation, type conversion, and formatting support for Spring 3 is very easy.
You’ll learn more about this in Chapter 17, when we discuss data validation in developing web applications.
Summary In this chapter, we covered the Spring 3 type conversion system as well as the field formatter SPI.
You saw how the new type conversion system can be used for arbitrary type conversion, in addition to the PropertyEditors support.
Task scheduling mainly is composed of three parts: the task (which is the piece of business logic needed to run at a specific time or on a regular basis), the trigger (which specifies the condition under which the task should be executed), and the scheduler (which executes the task based on the information from the trigger)
We’ll also cover scheduling scenarios such as fixed-interval scheduling and cron expressions.
Create a Project in STS for the Sample Projects Let’s create the sample project for this chapter.
The reason of choosing this project template is that we will develop a sample job that will update the data in the backend RDBMS.
Upon project creation, other dependencies are required, as shown in Table 15-1
In this chapter, we will use it in our domain objects too.
Task Scheduling in Spring Enterprise applications often need to schedule tasks.
As mentioned, task scheduling consists of three parts: the schedule definition (trigger), the task execution (scheduler), and the task itself.
There are many different ways to trigger the execution of a task in a Spring application.
One way is to trigger a job externally from a scheduling system that already exists in the application deployment environment.
For example, many enterprises use commercial systems, such as Ctrl-M or CA Autosys, for scheduling tasks.
If the application is running on a Linux/Unix platform, the crontab scheduler can be used.
The job triggering can be done by sending a RESTful-WS request to the Spring application and having Spring’s MVC controller trigger the task.
Another way is to use the task scheduling support in Spring.
Spring’s own TaskScheduler abstraction: Spring 3 introduces the TaskScheduler abstraction, which provides a simple way to schedule tasks and supports most typical requirements.
In this section, we will focus on using Spring’s TaskScheduler abstraction for task scheduling.
The CronTrigger class supports triggering based on a cron expression, while the PeriodicTrigger class supports triggering based on an initial delay and then a fixed interval.
The task: The task is the piece of business logic that needs to be scheduled.
In Spring, a task can be specified as a method within any Spring bean.
Both classes support task execution from a shared thread pool.
To schedule tasks using Spring’s TaskScheduler abstraction, you have two options.
One is to use the task-namespace in Spring’s XML configuration, and the other is to use annotations.
Sample Task To demonstrate task scheduling in Spring, let’s implement a simple job first, namely, an application maintaining a database of car information.
Listing 15-1 shows the Car class, which is implemented as a JPA entity class.
We will use Spring Data’s JPA and its repository abstraction support.
Two methods were provided; one retrieves information about all cars, and the other persists an updated Car object.
The third method, updateCarAgeJob(), is the job that needs to be run regularly to update the age of the car based on the manufacture date of the car and the current date.
Now let’s proceed to schedule the car age update job in Spring.
Task Scheduling Using task-namespace Like the support for other namespaces in Spring, task-namespace provides a simplified configuration for scheduling tasks using Spring’s TaskScheduler abstraction.
As shown in Listing 15-8, the context for the car application was imported.
In the <task:scheduled> tag, a task can reference a Spring bean (the carService bean in this case) and a specific method within the bean (in this case the updateCarAgeJob() method)
The attribute fixed-delay will instruct Spring to instantiate a PeriodicTrigger as the Trigger implementation for the TaskScheduler.
The class is simple; just bootstrap the ApplicationContext and then keep looping.
If the application is deployed to an application server environment, the scheduler will keep running.
Running the program will produce the following batch job output every ten seconds:
From the output, you can see the cars’ age attributes were updated.
Besides a fixed interval, a more flexible scheduling mechanism is to use a cron expression.
After the change, run the ScheduleTaskSample class again, and you will see the job will run every minute.
Task Scheduling Using Annotation Another option for scheduling tasks using Spring’s TaskScheduler abstraction is to use an annotation.
To schedule a specific method in a Spring bean, just annotate the method with @Scheduled and pass in the scheduling requirements.
Listing 15-11 shows the code snippet of the revised CarServiceImpl class.
Running the program will produce the same output as using task-namespace.
You can try different triggering mechanisms by changing the attribute within the @Scheduled annotation (i.e., fixedDelay, fixedRate, cron)
Asynchronous Task Execution in Spring In version 3.0, Spring also supports using annotations to execute a task asynchronously.
To use it, you just need to annotate the method with @Async.
Let’s go through a simple example to see it in action.
The asyncTask() is a simple task that logs information to the logger.
From Listing 15-16, we call the asyncTask() method five times and then the asyncWithReturn() three times with different arguments, and then we retrieve the result after sleeping for six seconds.
From the output, you can see that all the calls were started at the same time.
The three calling with return values complete first and are displayed on the console output.
Task Scheduling in the Sample Application In the SpringBlog application, we will store the history records for both blog posting entries and comments for auditing purposes.
However, we also decided to keep only those history records for 30 days in order not to consume too much database storage.
To fulfill the requirement, we will adopt Spring 30 days.
First we will define an interface for the housekeeping job.
The interface defines the auditPurgeJob() method for the audit record housekeeping task.
The cron expression means that the job should run at midnight every day.
For the number of days that the audit records will be kept, we will externalize it into a properties file for easy maintenance.
Summary In this chapter, we covered Spring’s support for task scheduling.
We focused on Spring’s built-in TaskScheduler abstraction and demonstrated how to use it to fulfill task scheduling needs with a sample batch data update job.
We also covered how Spring 3 supports annotation for executing tasks asynchronously.
An enterprise application typically needs to communicate with other applications.
Take, for example, for a company selling products; when a customer places an order, an order-processing system processes the order and generates a transaction.
During the order processing, an inquiry is made to the inventory system to check whether the product is available in stock.
Upon order confirmation, a notification is sent to the fulfillment system to deliver the product to the customer.
Finally, the information is sent to the accounting system; an invoice is generated and the payment is processed.
Most of the time, this business process is not fulfilled by a single application but a number of applications working together.
Some of the applications may be developed in-house, and others may be purchased from external vendors.
Moreover, the applications may be running on different machines in different locations and implemented with different technologies and programming languages (for example, Java, .NET, C++, and so on)
Performing the handshaking between applications in order to build an efficient business process is always a critical task when architecting and implementing an application.
As a result, remoting support via various protocols and technologies is needed for an application to participate well in an enterprise environment.
In the Java world, remoting support has existed since it was first created.
In early days (Java 1.x), most remoting requirements were implemented using traditional TCP sockets or Java Remote Method Invocation (RMI)
After J2EE came on the scene, EJB and JMS became common choices for interapplication server communications.
The rapid evolution of XML and the Internet gave rise to remote support using XML over HTTP , including the Java API for XML-based RPC (JAX-RPC), the Java API for XML Web Services (JAX-RPC), and HTTP-based technologies (for example, Hessian, Burlap, and so on)
Spring also offers its own HTTP-based remoting support, called the Spring HTTP invoker.
In recent years, to cope with the explosive growth of the Internet and more responsive web application requirements (for example, via Ajax), more lightweight and efficient remoting support of applications has become critical for the success of an enterprise.
Consequently, the Java API for RESTful Web Services (JAX-RS) was created and quickly gained popularity.
Other protocols, such as Comet and HTML5 WebSocket, also attracted a lot of developers.
Needless to say, remoting technologies keep evolving at a rapid pace.
In terms of remoting, as mentioned, Spring provides its own support (for example, the Spring HTTP invoker), as well as supports a lot of technologies mentioned earlier (for example, RMI, EJB, JMS, Hessian, Burlap, JAX-RPC, JAX-WS, JAX-RS, and so on)
It’s not possible to cover all of them in this chapter.
So, here we will focus on those that are most commonly used.
Spring HTTP invoker: If both applications that need to communicate are Spring based, the Spring HTTP invoker provides a simple and efficient way for invoking the services exposed by other applications.
We will show you how to use the Spring HTTP invoker to expose a service within its service layer, as well as invoking the services provided by a remote application.
Using JMS in Spring: The Java Messaging Service (JMS) provides another asynchronous and loosely coupled way of exchanging messages between applications.
We will show you how Spring simplifies application development with JMS.
Using RESTful web services in Spring: Designed specifically around the HTTP protocol, RESTful web services are the most commonly used technology for providing remote support for an application, as well as supporting highly interactive web application frontends using Ajax.
We will show you how Spring 3 MVC provides comprehensive support for exposing services using JAX-RS and how to invoke services using the RestTemplate class.
We will also discuss how to secure the services for protecting unauthorized access to the services.
Creating the Project in STS for the Samples Let’s create the project for the samples in this chapter.
Since we will expose the developed services via HTTP, we need to create a web-based project with Spring MVC.
In STS, create a new Spring template project and choose Spring MVC Project, as shown in Figure 16-1
On the next screen, enter the information for the project for the samples in this chapter, as shown in Figure 16-2
Upon completion, STS will create a web project with the required dependencies, including the Spring MVC module.
Implementing the Service Layer for the Samples We want to show you some more practical samples instead of a simple “Hello World” application.
So, we will implement a simple contact information service (like the one in previous chapters) using JPA and then expose its services to remote clients.
Adding Required Dependencies for the JPA Backend We need to add the required dependencies to the project.
In addition, verify that the project is using Spring 3.1
In this chapter, we will use it in our domain objects too.
Verifying the Project Let’s verify that the application is working before we proceed.
In STS, in the Servers view, verify that a tc Server instance (a specialized version of Tomcat provided by VMware SpringSource) exists, as shown in Figure 16-4
If you don’t see it, then you will need to create one.
We can now configure the project to run on the server and deploy and test it.
Choose the tc Server (if it’s not the only one you see on the screen), as shown in Figure 16-6
On the next screen, the project should have been added by STS for you, as shown in Figure 16-7
Click Finish, and STS will build the project, deploy to the server, and then bring up the welcome page that was automatically created with the template project, as shown in Figure 16-8
It’s a simple JSP page that shows the “Hello World” message and the server time.
Don’t worry about the question marks; they are because of the developer machine’s locale setup (mine is zh_HK for Hong Kong)
If your machine is running English as the locale, then you should see the time format correctly.
This page indicates that the project was created normally, and we can now proceed to implement the service layer and expose it for remote access.
Data Model for Samples For the data model in the samples in this chapter, we will use a very simple one, which contains only a single CONTACT table for storing contact information.
As you can see, the CONTACT table stores only a few basic fields of a contact’s information.
Implementing and Configuring ContactService Having the template project created and sample data model and scripts ready, we can start to implement and configure the service layer for our samples in this chapter.
In the following sections, we will discuss the implementation of the ContactService using JPA 2, Spring Data JPA, and Hibernate as the persistence service provider.
Then, we will cover how to configure the service layer in the Spring project.
Implementing ContactService In the samples, we will expose the services for various operations on the contact information to remote clients.
First we need to create the Contact entity class, which is shown in Listing 16-3
As shown in Listing 16-3, standard JPA annotations are used.
We also use JodaTime’s DateTime class for the birthDate attribute.
Let’s proceed to the service layer; Listing 16-4 shows the ContactService interface, with the services we want to expose.
Because we will use Spring Data JPA’s repository support, we will implement the ContactRepository interface, as shown in Listing 16-5
Listing 16-6 shows the implementation class of the ContactService interface.
The implementation is basically completed, and the next step is to configure the service in Spring’s ApplicationContext within the web project, which will be discussed in the next section.
First the context namespace is added to the configuration file.
Now, the service layer is completed and ready to be exposed and used by remote clients.
Using the Spring HTTP Invoker If the application you are going to communicate with is also Spring-powered, using the Spring HTTP invoker is a good choice.
The procedures for exposing and accessing the service are elaborated in the following sections.
Exposing the Service To expose the service, in the root-context.xml configuration file, add the bean definition in Listing 16-9
The first one is the service property, indicating the bean providing the service.
Listing 16-10 shows the code snippet to add into the web.xml file.
Note the servlet name (contactExporter) should match with the bean name of the exporter (see Listing 16-9; the bean name is also contactExporter)
Until now, if you are using the STS project’s default setting, the project should have been rebuilt and deployed to the tc Server.
Now we can proceed to develop the client to invoke the service.
Invoking the Service Invoking a service via the Spring HTTP invoker is very simple.
The serviceUrl specifies the location of the remote service, which is http://localhost:8080/ch16/remoting/ContactService.
The second property is the interface of the service (i.e., ContactService interface)
If you are developing another project for the client, you need to have the ContactService interface and the Contact entity class within your client application’s classpath.
Listing 16-12 shows a main class for invoking the remote service.
As shown in Listing 16-12, the program is just like any other stand-alone Spring application.
The ApplicationContext is initialized, and then the contactService bean is retrieved.
Then we just call its methods like a local application.
In the previous output, you can see the findAll() and findByFirstName() methods are called, and the results are returned.
Using JMS in Spring Using message-oriented middleware (generally referred to as an MQ server) is another popular way to support communication between applications.
The main benefits of a message queue (MQ) server is that it provides an asynchronous and loosely coupled way for application integration.
In the Java world, JMS is the standard for connecting to an MQ server for sending or receive messages.
An MQ server maintains a list of queues and topics for which applications can connect to and send and receive messages.
The following is a brief description of the difference between a queue and a topic:
Queue: A queue is used to support a point-to-point message exchange model.
When a producer sends a message to a queue, the MQ server keeps the message within the queue and delivers it to one and only one consumer the next time the consumer connects.
Topic: A topic is used to support the publish-subscribe model.
Any number of clients can subscribe to the message within a topic.
When a message arrives for that topic, the MQ server delivers it to all clients that have subscribed to the message.
This model is particularly useful when you have multiple applications that will be interested in the same piece of information (for example, a news feed)
In JMS, a producer connects to an MQ server and sends a message to a queue or topic.
A consumer also connects to the MQ server and listens to a queue or topics for messages of interest.
In JMS 1.1, the API was unified so the producer and consumer don’t need to deal with different APIs for interacting with queues and topics.
In this section, we will focus on the point-to-point style for using queues, which is a more commonly used pattern within an enterprise.
To develop and test a JMS application, an MQ server is required.
To prepare for the sample, several new Maven dependencies are required, as listed in Table 16-2
Setting up an ActiveMQ server and using JMS with Spring are discussed in the following sections.
At the time of this writing, the latest release is 5.5.1
Upon extraction, navigate to the bin folder, and run the activemq command (for Windows, it’s activemq.bat, while for Unix/Linux, it’s activemq)
The server will be started, and upon completion, you will see the output like the one in Figure 16-9
On the screen, you will see that the ActiveMQ server is listening to port 61616 for a JMS connection.
Open a web browser and access the administration web site.
The first page you see will be like the one in Figure 16-10
In the top menu, click Queues; then in the text box, enter prospring3 as the queue name and click the Create button.
Upon completion, the queue will be created, as shown in Figure 16-11
Up to this point, the setup of ActiveMQ server has been completed, and we can proceed to develop a JMS client using Spring to connect to the server and receive messages.
For a list of possible message formats, please refer to JEE’s online documentation (http://docs.oracle.com/javaee/6/api/javax/jms/Message.html)
Having the message listener in place, the next step is to define the Spring ApplicationContext configuration.
Note that the property brokerURL should be the same as the one when you start up ActiveMQ, as shown in Figure 16-9
Listing 16-15 shows the main testing program to test the receiving message.
Just run the program, and it will connect to ActiveMQ and wait for messages to arrive in the prospring3 queue.
Now let’s try to send a message to the prospring3 queue.
In ActiveMQ admin web site, click the Send option in the top menu, enter the queue name and message body, and then click Send, as shown in Figure 16-12
After the Send button is clicked, you will see the message output by the listener in STS’s output console:
You can see how easy it is to set up a JMS listener in Spring for remote communication.
In a JEE application server environment, you just need to configure the connection factory using JNDI lookup within the Spring configuration file.
As shown in Listing 16-17, an instance of JmsTemplate is injected.
In the MessageCreator instance, the createMessage() method is implemented to create a new instance of TextMessage that will be sent to ActiveMQ.
As shown in Listing 16-18, the connectionFactory bean is defined as usual.
Listing 16-19 shows the main testing program for sending messages.
Running the program will send the message to the queue.
If the JmsListenerSample class is still running (or you can run it now), you will get the message with the following output:
In real life, the message will most likely be in XML format, representing a piece of business information (for example, an online order, transaction, booking, and so on)
This section covers only the basic usage scenarios of JMS.
For details, please refer to the online JEE tutorial at http://docs.oracle.com/javaee/5/tutorial/doc/bncdq.html.
Using RESTful-WS in Spring Nowadays, RESTful-WS is perhaps the most widely used technology for remote access.
From remote service invocation via HTTP to supporting an Ajax-style interactive web frontend, RESTful-WS is being adopted intensively.
There are a number of reasons for the popularity of RESTful web services:
Easy to understand: RESTful web services are designed around the HTTP protocol.
The URL, together with the HTTP method, specifies the intention of the request.
Lightweight: RESTful is much more lightweight when compared to SOAP-based web services, which include a large amount of metadata to describe which service the client wants to invoke.
For a RESTful request and response, it’s simply an HTTP request and response like any other web application.
Firewall friendly: Because RESTful web services are designed to be accessed via HTTP (or HTTPS), the application becomes much more firewall friendly and easily accessed by remote clients.
In this section, we will discuss the basic concepts of RESTful-WS and Spring’s support of RESTful-WS through its Spring MVC module.
The main concepts of the “uniform interface” include the identification of resources and the manipulation of resources through representations.
For the identification of resources, a piece of information should be accessible via a Uniform Resource Identifier (URI)
Another example, http://www.somedomain.com/api/contacts, is a URI that represents a resourcethat is a list of contact information.
Those identifiable resources will be able to be managed through various representations, as shown in Table 16-3
For a detail description of RESTful web services, we recommend the book Ajax and REST Recipes, A Problem-Solution Approach (Apress, 2006)
Adding Required Dependencies for Samples To develop the samples in this section, a number of dependencies are required, as listed in Table 16-4
The HTTP client library will be used for RESTful-WS invocation.
The Contact RESTful Web Service When developing a RESTful-WS application, the first step is to design the service structure, which includes what HTTP methods will be supported, together with the target URLs for different operations.
For our contact RESTful web services, we want to support query, create, update, and delete operations.
For querying, we want to support retrieving all contacts or a single contact by ID.
The services will be implemented as a Spring MVC controller.
The URL pattern, HTTP method, description, and corresponding controller methods are shown in Table 16-5
In terms of data format, both XML and JSON will be supported.
The corresponding format will be provided according to the accept media type of the client’s HTTP request header.
Using Spring MVC to Expose RESTful Web Services In this section, we will show you how to use Spring MVC to expose the contact services as RESTful web services as designed in the previous section.
First we will create another domain object, the Contacts class.
As shown in Listing 16-20, the Contacts class has a single property, which is a list of Contact objects.
The purpose is to support the transformation from a list of contacts (returned by the listData() method within the ContactController class) into XML or JSON format.
Configuring Castor XML To support the transformation of the returned contact information into XML format, we will use the Castor XML library (http://castor.codehaus.org)
Castor supports several modes between POJO and XML transformation, and in this sample, we will use an XML file to define the mapping.
In addition, to support the transformation from JodaTime’s DateTime type (for Contact’s birthDate attribute), we implement a custom Castor field handler.
Within the methods, we implement the logic to perform the transformation between DateTime and String for use by Castor.
In addition, we also define a properties file for use with Castor.
As shown in Listing 16-23, the property instructs Castor to generate XML with an indent, which is much easier to read when testing.
Implementing the ContactController The next step is to implement the controller class, ContactController.
The class is annotated with @Controller, indicating that it’s a Spring MVC controller.
In this sample, all URLs under http://localhost:8080/ch16/contact will be handled by this controller.
The ContactService within the service layer implemented earlier this chapter is autowired into the controller.
This instructs that all the return value from the methods should be written to the HTTP response stream directly.
For methods that accept path variables (for example, the findContactById() method), the path variable is annotated with @PathVariable.
This instructs Spring MVC to bind the path variable within the URL (for example, http://localhost:8080/ch16/contact/1) into the id argument of the findContactById() method.
Note that for the id argument, the type is Long, while Spring 3’s type conversion system will automatically handle the conversion from String to Long for us.
For the create() and update() method, the Contact argument is annotated with @RequestBody.
This instructs Spring to automatically bind the content within the HTTP request body into the Contact domain object.
Configuring the RESTful Servlet After the controller is completed, we can define it in Spring MVC.
In addition, JSR-303 validation support is also enabled under the definition of this tag.
Because we will support both JSON and XML as the data format, two converters are declared.
If your tc Server is on, the project would have been built and deployed to the server automatically.
You may find that while starting the web application, errors will be reported by Spring, because of the previous implemented samples.
Using curl to Test RESTful-WS Let’s do a quick test of the RESTful web services that we implemented.
One easy way is to use curl (http://curl.haxx.se), which is a command-line tool for transporting data with URL syntax.
To use the tool, just download it from the web site and extract in onto your computer.
For example, to test the retrieval of all contacts, open a command prompt in Windows or a terminal in Unix/Linux, and fire the command shown in Listing 16-27
The command in Listing 16-27 will send an HTTP request to the server’s RESTful web service; in this case, it will invoke the listData() method in ContactController to retrieve and return all contact information.
Also, the –H option declares an HTTP header attribute, meaning that the client wants to receive data in JSON format.
Running the command will produce the output shown in Figure 16-13
In Figure 16-13, you can see that the data in JSON format for the initially populated contact information was returned.
Now let’s take a look at the XML format; the command is shown in Listing 16-28
Running the command will produce the output shown in Figure 16-14
As shown in Figure 16-14, the data in XML format was correctly returned.
In this section, we will discuss how to use the class to access the contact service on the server.
As shown in Listing 16-29, a restTemplate bean is declared using the RestTemplate class.
The mapping file will be shared among both the server and client sides.
As a result, the client is always expecting XML as the return data format, and Castor will help perform the conversion between POJO and XML.
As shown in Listing 16-30, the URLs for accessing various operations are declared, which will be used in later samples.
Add the code snippet in Listing 16-32 into the main() method of the.
As shown in Listing 16-32, first we retrieve the contact we want to update.
Running the program again produces the following output (other output was omitted):
If now you take a look at tc Server’s console output, since we set Hibernate to show SQL and log the information during update, you will also see the following output:
Then, all contacts are retrieved and displayed again to verify the deletion.
Running the program again produces the following output (other output was omitted):
As you can see, the contact with an ID of 1 was deleted.
Add the code snippet in Listing 16-34 into the main() method of.
As shown in Listing 16-34, a new instance of the Contact object was constructed.
Running the program again (please restart tc Server first to reinitialize the contact data) will produce the following output:
The contact was created on the server and returned to the client.
Securing RESTful-WS with Spring Security Any remoting service requires security to restrict unauthorized parties from accessing the service and retrieving business information or acting on it.
In this section, we will demonstrate how to use the Spring Security project (http://static.springsource.org/springsecurity/site/index.html) to secure the RESTful-WS on the server.
Using Spring Security to secure RESTful-WS is a three-step process.
First, in the web application deployment descriptor (web.xml), we need to declare a filter; the code snippet is shown in Listing 16-35
As shown in Listing 16-35, a filter is declared to enable Spring Security to intercept the HTTP request for an authentication and authorization check.
In Listing 16-36, we declare the security namespace (note the line xmlns="http://www.springframework.org/schema/security") and use it as the default namespace for.
The attribute create-session, which was new in Spring Security 3.1.0, was introduced to allow us to configure whether the HTTP session will be created upon authentication.
Since the RESTful-WS we are using is stateless, we set the value to stateless, which instructs Spring Security not to create an HTTP session for all RESTful requests.
This can help improve the performance of the RESTful services.
The <http-basic/> specifies that only HTTP Basic Authentication is supported for RESTful services.
Here we define a simple authentication provider with a hard-coded user and password (both set to remote) with the ROLE_REMOTE role assigned.
In an enterprise environment, most likely the authentication will be done by either a database or an LDAP lookup.
You will get the HTTP status code 401, which means you are not authorized to access the service.
Now let’s config the client’s RestTemplate to provide the credential information to the server.
First the configuration for the RESTful client program needs to be revised.
First, in the restTemplate bean, a constructor argument with a reference to the httpRequestFactory bean is injected.
With the httpRequestFactory constructed and injected into the RestTemplate, all RESTful requests fired using this template will carry the credential provided.
When using RESTful-WS, we can also apply the defined validation rule to the request arguments.
Let’s revisit the Contact entity class and define a constraint on the firstName attribute.
Listing 16-39 shows the code snippet of the revised getFirstName() method.
Listing 16-40 shows the code snippet of the revised create() method of the ContactController class.
With the annotation in place, Spring will perform JSR-303 validation to the Contact domain object after data binding, and exceptions will be thrown if violations are found.
In Listing 16-41, the differences from the previous version are in bold.
When setting the first name, we intentionally set it to two characters only, which violates the rule (minimum three characters) defined for the attribute.
When it fails validation, Spring MVC will return the HTTP status code 400 automatically, which indicates that the data in the request body is getting an error.
If you take a look at the server output console, you will see the following output (other output was omitted):
In the previous output, you can see the JSR-303 validation error message is displayed.
In real life, you should let the client know this error.
This can be done by designing a POJO that stores the errors and then returns them to the client so the client knows what’s wrong within the request.
Remoting in the Sample Application In the SpringBlog application, the main remoting functionality is the retrieval of blog posting entries by the clients.
To fulfill the requirement, we will use Spring MVC’s comprehensive RESTful-WS support.
The main highlights of the implementation of the blog feed service are as follows:
A RESTful servlet will be defined for remote retrieval of blog posting entries via RESTful-WS.
A controller will be implemented in the web layer to accept requests (with a predefined URL and HTTP GET method) and return the most recent blog posting entries to the client.
In terms of data formats, JSON and XML will be supported, and the techniques discussed in this chapter will be used in the sample application.
Summary In this chapter, we covered the most commonly used remoting techniques in Spring-based applications.
If both applications are running Spring, then using the Spring HTTP invoker is a viable option.
If an asynchronous mode or loosely coupled mode of integration is required, then JMS is a commonly used approach.
Finally, we discussed how to use RESTful-WS in Spring for exposing services or accessing services using the RestTemplate class.
In the next chapter, we will discuss using Spring to implement the web layer.
In an enterprise application, the presentation layer is a critical layer that significantly affects the acceptance level of the application by the users.
The presentation layer is the front door into your application.
It lets the users perform business functions provided by the application, as well as provides a visual view of the information that is being maintained by the application.
How the user interface performs greatly contributes to the success of the application.
Because of the explosive growth of the Internet (especially via cloud computing these days and the rise of different kinds of devices that people are using), developing an application’s presentation layer is a very challenging task.
The following are some of the major considerations when developing web applications:
Performance: Performance is always the top requirement of a web application.
If users choose a function or click a link and it takes a long time to execute (in the world of Internet, ten seconds is like a century), users will definitely not be happy with the application.
User-friendly: The application should be easy to use and easy to navigate with clear instructions without confusing the user.
Interactive and richness: The user interface should be highly interactive and responsive.
In addition, the presentation should be rich in terms of visual presentation, such as charting, dashboard type of interface, and so on.
Accessibility: Nowadays, users require that the application is accessible from anywhere via any device.
In the office, they will use their desktop for accessing the application.
On the road, users will use various mobile devices including laptops, tablets, smartphones, and so on, to access the application.
Developing a web application to fulfill the previous requirements is not easy, but they are considered mandatory for business users.
Fortunately, many new technologies and frameworks have also been developed to address those needs.
Recently, many web application frameworks and librariessuch as Spring MVC, Struts, Tapestry, Java Server Faces (JSF), Adobe Flex, Google Web Toolkit (GWT), jQuery, and Dojo, to name a few—provide tools and rich component libraries that can help you develop highly interactive web frontends.
In addition, many frameworks provide tools or corresponding widget libraries targeting mobile device including smartphones and tablets.
In terms of web application development, Spring provides comprehensive and intensive support.
The Spring MVC module provides a solid infrastructure and Model View Controller (MVC) framework for web application development.
In addition, Spring MVC integrates with many common web frameworks and toolkits (for example, Struts, Adobe Flex, GWT, and so on)
Other Spring projects help address specific needs for web applications.
For example, Spring MVC, when combined with the Spring Web Flow project and its Spring Faces module, provides comprehensive support for developing web applications with complex flows and using JSF as the view technology.
Simply speaking, there are so many choices out there in terms of presentation layer development.
This chapter will focus on Spring MVC and will discuss how we can use the powerful features provided by Spring MVC to develop highly performing web applications.
Spring MVC: We will discuss the main concepts of the MVC pattern and introduce Spring MVC.
We will discuss how to use Spring MVC to develop web applications that support those requirements.
View and Ajax support: Spring MVC supports many view technologies.
In this chapter, we will focus on using JavaServer Pages (JSP) as the view part of the web application.
On top of JSP, JavaScript will be used to provide the richness part.
There are many outstanding and popular JavaScript libraries such as jQuery, Dojo, and so on.
In this chapter, we will focus on using jQuery, with its subproject jQuery UI library that supports the development of highly interactive web applications.
Pagination and file upload support: When developing the samples in this chapter, we will discuss how we can use Spring Data JPA and the frontend jQuery component to provide pagination support when browsing grid-based data.
In addition, how to implement file upload in Spring MVC will be covered.
Instead of integration with Apache Commons File Upload, we will discuss how we can use Spring MVC with the Servlet 3.0 container’s built-in multipart support for file upload.
We will discuss how we can use Spring Security to help protect the application and handle logins and logouts.
Spring MVC and the sample application: Many topics discussed in this chapter will be used in developing the sample application for this book.
We will give a highlevel overview of the relationship between the topics in this chapter and the sample application.
Create Project in STS for Samples As usual, the first step is to create the project for the samples in this chapter.
Because we are discussing web applications, we need to create a Spring MVC project.
In addition, we will create a service layer using JPA 2 with Hibernate and Spring Data JPA as the persistence service provider.
To create the project in STS, please refer to Chapter 16, which also details the required dependencies.
After you have created the project, verify that you can see the default home page created by the template project, which indicates that the initial project works correctly.
However, the service layer and the data model will be a bit more complicated than the one we developed in Chapter 16 in order to show you some web application features such as file upload support.
In this section, we will discuss the data model and the implementation of the service layer that will be used throughout this chapter.
Data Model for Samples For the data model in the samples in this chapter, we will use a very simple one, which contains only a single CONTACT table for storing contact information.
As you can see, the CONTACT table stores only a few basic fields of a contact’s information.
One thing worth mentioning is the PHOTO column, of the BLOB (binary large object) data type, which will be used to store the photo of a contact using file upload.
This time, more testing data was populated in order to show you the pagination support later.
Implementing and Configuring ContactService Having the project created and sample data model and scripts ready, we can start to implement and configure the service layer for our samples in this chapter.
In the following sections, we will first discuss the implementation of the ContactService using JPA 2, Spring Data JPA, and Hibernate as the persistence service provider.
Then we will cover the configuration of the service layer in the Spring project.
Implementing ContactService In the samples, we will expose the services for various operations on the contact information to the presentation layer.
First we need to create the Contact entity class, which is shown in Listing 17-3
As shown in Listing 17-3, standard JPA annotations are used.
We also use JodaTime’s DateTime class for the birthDate attribute.
A new transient property (by applying the @Transient annotation to the getter method) called birthDateString is added, which will be used for frontend presentation in later samples.
For the photo attribute, we use a byte array as the Java data type, which corresponds to the BLOB data type in the RDBMS.
The former annotation indicates to JPA provider that it’s a large object column, while the latter indicates that the attribute should be fetched lazily in order to avoid a performance impact when loading a class that does not require photo information.
Listing 17-4 shows the ContactService interface with the services we would like to expose.
Because we will use Spring Data JPA’s repository support, we will implement the ContactRepository interface, as shown in Listing 17-5
Listing 17-6 shows the implementation class of the ContactService interface.
The implementation is basically completed, and the next step is to configure the service in Spring’s ApplicationContext within the web project, which will be discussed in next section.
First the context namespace is added to the configuration file.
Now the service layer is completed and ready to be exposed and used by remote clients.
Introducing MVC and Spring MVC Before we move on to implement the presentation layer, let’s go through some major concepts of MVC as a pattern in web applications and how Spring MVC provides comprehensive support in this area.
In the following sections, we will discuss these high-level concepts one by one.
Finally, we will discuss the request life cycle within Spring MVC.
Introducing MVC MVC is a commonly used pattern in implementing the presentation layer of an application.
The main principle of the MVC pattern is to define an architecture with clear responsibilities for different components.
As its name implies, there are three participants within the MVC pattern:
Model: A model represents the business data as well as the “state” of the application within the context of the user.
For example, in an e-commerce web site, the model will include the user profile information, shopping cart data, and order data if users purchase goods on the site.
View: This presents the data to the user in the desired format, supports interaction with users, and supports client-side validation, i18n, styles, and so on.
Controller: The controller handles requests for actions performed by users in the frontend, interacting with the service layer, updating the model, and directing users to the appropriate view based on the result of execution.
Because of the rise of Ajax-based web applications, the MVC pattern has been enhanced to provide a more responsive and rich user experience.
For example, when using JavaScript, the view can “listen” to events or actions performed by the user and then submit an XMLHttpRequest to the server.
On the controller side, instead of returning the view, the raw data (for example, in XML or JSON format) is.
Figure 17-1 illustrates a commonly used web application pattern, which can be treated as an enhancement to the traditional MVC pattern.
On the server side, most frameworks (for example, Spring MVC, Struts, and so on) will have a dispatcher (in the form of a servlet) to handle the request.
Invokes: The dispatcher dispatches the request to the appropriate controller based on the HTTP request information and the web application configuration.
Response: The controller updates the model and, based on the execution result, returns the corresponding view to the user.
For example, say the user is browsing data within a grid.
When the user clicks the next page, instead of a full page refresh, the following flow will happen:
Request: An XMLHttpRequest is prepared and submitted to the server.
The dispatcher will dispatch the request to the corresponding controller.
Response: The controller interacts with the service layer, and the response data will be formatted and sent to the browser.
The browser receives the data and performs a partial update of the existing view.
Introducing Spring MVC In the Spring Framework, the Spring MVC module provides comprehensive support for the MVC pattern, with support for other features (for example, theming, i18n, validation, type conversion and formatting, and so on) that ease the implementation of the presentation layer.
In the following sections, we will discuss the main concepts of Spring MVC.
One servlet is to support the user interface (we call it the application servlet), and the other is to provide services in the form of RESTful-WS to other applications (we call it the RESTful servlet)
Figure 17-3 shows the main components involved in handling a request in Spring MVC.
The figure is based on the one described in the Spring Framework forum (http://forum.springsource.org/showthread.php?21639-Spring-MVC-Request-LifecycleDiagram), with modifications.
Several commonly used filters and their purposes are described in the next section.
Dispatcher servlet: The servlet analyzes the requests and dispatches them to the appropriate controller for processing.
Common services: The common services will apply to every request to provide supports including i18n, theme, file upload, and so on.
Handler mapping: This maps the request to the handler (a method within a Spring MVC controller class)
Handler interceptor: In Spring MVC, you can register interceptors for the handlers for implementing common checking or logic.
For example, a handler interceptor can check and ensure that only the handlers can be invoked during office hours.
This resolver handles certain standard Spring MVC exceptions by setting a specific response status code.
You can also implement your own exception handler by annotating a controller method with the @ExceptionHandler annotation and passing in the exception type as the attribute.
There are many implementation classes to support various view resolving mechanisms.
These descriptions cover only a few commonly used handlers and resolvers.
For a full description, please refer to the Spring Framework reference documentation and its Javadoc.
To configure Spring MVC support for web applications, we need to perform the following configurations in the web deployment descriptor:
In the Spring MVC template project, the web.xml file it generates supports Servlet 2.5
A number of servlet filters provided by Spring MVC are defined, and all filters are mapped to the web application root context URL.
We use the one generated by the template project for the contact application’s presentation layer.
This filter is used to specify the character encoding for request.
This filter provides support for HTTP methods other than GET and POST (for example, PUT)
This filter binds the JPA EntityManager to the thread for the entire processing of the request.
It can help restore the same EntityManager for subsequent requests of the same user so that JPA features such as lazy fetching will be able to work.
Create the First View in Spring MVC Having the service layer and Spring MVC configuration in place, we can start to implement our first view.
In this section, we will implement a simple view to display all contacts that were initially populated by the script test-data.sql.
As mentioned earlier, we will use JSPX to implement the view.
The main advantages of JSPX over JSP are as follows:
For example, you can’t place Java scriptlets in JSPX document.
Tools might perform instant validation (on the XML syntax), so mistakes can be caught earlier.
To prepare for the first view, one new Maven dependency is required, as listed in Table 17-2
Configure the DispatcherServlet The next step is to configure the DispatcherServlet.
To implement this simple view, we need to make some minor modifications to the default configuration file generated by Spring template project.
As shown in Listing 17-10, the mvc namespace is declared as the default namespace.
Also, support for JSR-303 Bean Validation is enabled by this tag.
The <resources> tag defines the static resources (for example, CSS, JavaScript, images, and so on) and their locations so Spring MVC can improve the performance in serving those files.
However, for the suffix, we will change it to .jspx.
The @RequestMapping annotation at the class level indicates the root URL that will be handled by the controller.
In this case, all URLs with the prefix /ch17/contacts will be dispatched to this controller.
In the list() method, the @RequestMapping annotation is also applied, but this time the method is mapped to the HTTP GET method.
This means that the URL /ch17/contacts with the HTTP GET method will be handled by this method.
Within the list() method, the list of contacts are retrieved and saved into the Model interface passed in to the method by Spring MVC.
If you have developed JSP before, Listing 17-12 should be familiar to you.
But since this is a JSPX page, the page content is embedded under the <div> tag.
In addition, the tag libraries being used are declared as XML namespaces.
Second, the tag <c:if> detects whether the model attribute contacts is empty.
Because we already populated some contact information in the database, the contacts attribute should contain data.
As a result, the <c:forEach> tag will render the contact information in the table within the page.
Note the use of the <joda:format> tag to format the birthDate attribute, which is of JodaTime’s DateTime type.
Testing the Contact List View Now we are ready to test the contact list view.
First verify that the context root of the web application is ch17
To do this, select the project, right-click, and select Properties.
If you are using the default setting within your STS workspace, the project should be built automatically and published to the target tc Server.
To test the contact list view, open a web browser and visit the URL http://localhost:8080/ch17/contacts.
You should be able to see the contact listing page, as shown in Figure 17-5
In the upcoming sections, we will enrich the application with more views and enable support of i18n, themes, and so on.
Spring MVC Project Structure Overview Before we dive into the implementation of the various aspects of a web application, let’s take a look at what the project structure in our sample web application developed in this chapter looks like.
Typically, in a web application, a lot of files are required to support various features.
For example, there are a lot of static resource files, such as style sheets, JavaScript files, images, component libraries, and so on.
Then there are files that support presenting the interface in various languages.
And of course, there are the view pages that will be parsed and rendered by the web container, as well as the layout and definition files that will be used by templating framework (for example, Apache Tiles) for providing a consistent look and feel of the application.
It’s always a good practice to store files that serve different purposes in a well-structured folder hierarchy to give you a clear picture of the various resources being used by the application and ease ongoing maintenance work.
Figure 17-6 shows the folder structure of the sample web application that will be developed in this chapter.
The purpose of each folder (under the root folder /src/main/webapp) is listed in Table 17-3
Note that the structure presented here is not mandatory but is commonly used in the developer community for web application development.
In the upcoming sections, we will need various files (for example, CSS files, JavaScript files, images, and so on) to support the implementation.
The source code of the CSS and JavaScript will not be shown here.
So, we recommend you download a copy of the source code for this chapter and extract it to a temporary folder so that you can copy the files required into the project directly.
We will use it to enable rich-text editing of a contact’s description.
Copy the folder from the sample source code into the folder of your project.
We will use this library for implementing the grid in order to display contacts, as well as to support Ajax-style pagination.
Copy the folder from the sample source code into the folder of your project.
For the samples in this chapter, jQuery (http://jquery.org) and jQuery UI (http://jqueryui.com) JavaScript libraries will be used to implement a rich user interface.
Copy the folder from the sample source code into the folder of your project.
Copy the folder from the sample source code into the folder of your project.
In the sample, we will support both English (US) and Chinese (HK)
Copy the folder from the sample source code into the folder of your project.
Those files will be used by the Apache Tiles (http://tiles.apache.org) templating framework.
Both the root-level and dispatcher servlet–level context configurations are stored here.
WEB-INF/views This folder stores the views (in our case, JSPX files) that will be used by the application.
The main work is to externalize the user interface text and messages into properties files.
Even though you won’t have i18n requirements on day one, it’s good to externalize the languagerelated settings so that it will be easier later when you need to support more languages.
Because we will support both English (US) and Chinese (HK), we will need four files.
In Listing 17-13, the differences from the previous version are highlighted in bold.
First, the p namespace is added, and the resource definition is revised to reflect the new folder structure as presented in Table 17-3
This tag defines the locations of the static resource files, which enable Spring MVC to handle the files within those folders efficiently.
Within the tag, the location attribute defines the folders for the static resources.
The interceptor supports locale switching with a configurable request parameter.
From the interceptor configuration, the URL param with the name lang is defined for changing the locale for the application.
This property instructs Spring MVC whether to fall back to the locale of the system that the application is running on when a special resource bundle for the client locale isn’t found.
This class supports the storage and retrieval of locale settings from the user browser’s cookie.
As shown in Listing 17-14, the differences from the previous version are highlighted in bold.
Then, the <spring:message> tag is used to load the messages required by the view in the corresponding variables.
Finally, the page title and the labels are changed to use the i18n messages.
To switch to English (US), you can append the URL in your browser with ?lang=en_US, and the page will switch back to English (US)
Theming and Templating Besides i18n, a web application requires an appropriate look and feel (for example, a business web site needs a professional look and feel, while a social web site needs a more vivid style), as well as a consistent layout so that users will not get confused while using the web application.
In a web application, the styles should be externalized in style sheets, instead of hard-coded into the view page.
In addition, the style names should be consistent so that various “themes” can be prepared by simply switching the style sheet file.
Spring MVC provides comprehensive support for the theming of web applications.
In addition, in order to provide a consistent layout, a templating framework is required.
In this section, we will use Apache Tiles (http://tiles.apache.org), a popular page templating framework, for view templating support.
Spring MVC tightly integrates with Apache Tiles in this aspect.
In the following sections, we will discuss how to enable theming support in Spring MVC, as well as how to use Apache Tiles to define our page layout.
Theming Support Spring MVC provides comprehensive support for theming, and enabling it in web applications is easy.
For example, in the sample contact application in this chapter, we want to create a theme and name it standard.
As shown in Listing 17-15, the properties file contains a property named styleSheet, which points to the style sheet to use for the standard theme.
This properties file is the ResourceBundle for the theme, and you can add as many components for your theme as you want (for example, the logo image location, background image location, and so on)
As shown in Listing 17-16, the new interceptor is highlighted in bold (the order is not important)
The property defaultThemeName defines the default theme to use, which is the standard theme.
Now the standard theme is configured and ready for use in our views.
In Listing 17-18, the new code is highlighted in bold.
Finally, the link to the style sheet is added into the view.
Using Spring MVC’s theme support, you can easily add new themes or change the existing theme within your application.
View Templating with Apache Tiles For view templating using JSP technology, Apache Tiles (http://tiles.apache.org) is the most popular framework in use.
In order to use Tiles, we need to add the required dependencies in the project, as shown in Table 17-4
In the following sections, we will discuss how to implement page templates, including page layout design, definition, and implementation of the components within the layout.
Template Layout Design First we need to define how many templates are required in our application and, for each different template, what the layout looks like.
In the contact sample in this chapter, we require only one template.
The layout is rather trivial, as shown in Figure 17-9
As you can see from Figure 17-9, the template requires the following page components:
We will use Apache Tiles to define the template, and we need to develop the page template file as well as the layout definitions file, as listed here:
Implement Page Layout Components Having the layout defined, we can implement the page components.
First we will develop the page template file and the layout definition files required by Apache Tiles.
There is one page template definition, with the name default.
Within the page, three components are defined, named header, menu, and footer.
The content of the components will be loaded from the file provided by the value attribute.
For a detailed description of the Tiles definition, please refer to the project documentation page (http://tiles.apache.org/2.2/framework/tiles-core/dtddoc/index.html)
The <spring:theme> tag is placed in the template, which supports theming at the template level.
Now for contact list view, we can modify it to fit into the template.
Basically, we just need to remove the <head> section, because it’s now in the template page (default.jspx)
Now the template, definition, and components are ready; the next step is to configure Spring MVC to integrate with Apache Tiles.
Listing 17-25 shows the revisions that need to be made to the configuration file.
In Listing 17-25, the bean you need to remove is in italics, while the new bean definitions are in bold.
Finally, a tilesConfigurer bean is defined that provides the layout configurations required by Tiles.
As shown in Listing 17-26, the logical view name is mapped to the corresponding body attribute of the view to display.
As in the ContactController class in Listing 17-11, the list() method returns the logical view name contacts/list, so Tiles will be able to map the view name to the correct template and the view body to display.
Make sure that the project was rebuilt and deployed to the server.
Implement the Views for Contact Information Now we can proceed to implement the views that allow users to view the details of a contact, create new contacts, or update existing contact information.
In the following sections, we will discuss the mapping of URLs to the various views, as well as how the views are implemented.
We will also discuss how to enable JSR-303 validation support in Spring MVC for the edit view.
Mapping of URLs to the Views First we need to design how the various URLs are to be mapped to the corresponding views.
In Spring MVC, one of the best practices is to follow the RESTful-style URL for mapping views.
Table 17-5 shows the URLs-to-views mapping, as well as the controller method name that will handle the action.
Implementing the Show Contact View Now we implement the view for showing a contact’s information.
Listing 17-27 shows the show() method implementation of the ContactController class for displaying a contact’s information.
The page is simple; it simply displays the model attribute contact within the page.
To test the show contact view, upon rebuild and deploy, open the contact list view again.
The list should now include the hyperlink to the show contact view, as shown in Figure 17-11
Clicking any link will bring you to the show contact view.
Figure 17-12 shows the screen after clicking the first link.
Implementing the Edit Contact View Let’s implement the view for editing a contact.
It’s the same as the show view; first we add the methods updateForm() and update() to the ContactController class.
Listing 17-31 shows the code snippet for the two methods.
The MessageSource interface is autowired into the controller for retrieving messages with i18n support.
For the updateForm() method, the contact is retrieved and saved into the Model, and then the logical view contacts/update is returned, which will display the edit contact view.
The update() method will be triggered when user updates contact information and clicks the Save button.
First, Spring MVC will try to bind the submitted data to the Contact domain object and perform the type conversion and formatting automatically.
If the binding is successful, the data will be saved, and the logical view name will be returned for the display contact view by using redirect: as the prefix.
The Message class is a custom class that stores the message retrieved from MessageSource and the type of message (i.e., success or error) for the view to display in the message area.
The UrlUtil is a utility class for encoding the URL for redirect.
The <spring:eval> tag is used, which uses the Spring Expression Language to test whether the contact id is null.
If yes, then it’s a new contact; otherwise, it’s an update.
Various Spring MVC <form> tags are used within the form for displaying the label, the input field, and errors in case binding was not successful on form submission.
The edit view will be displayed, as shown in Figure 17-13
If binding was success, then you will see the success message, and the show contact view will be displayed, as shown in Figure 17-14
Implementing the Add Contact View Implementing the add contact view is much like the edit view.
Because we will reuse the edit.jspx page, we only need to add the methods in the ContactController class and the view definition.
Listing 17-36 shows the code snippet for the two new methods for the add contact function in the ContactController class.
After you rebuild and deploy the project, click the New Contact link in the menu area in Figure 17-10
The add contact view will be displayed, as shown in Figure 17-15
First, apply the validation constraints to the Contact domain object.
In this sample, we define constraints only for the firstName and lastName attributes.
Listing 17-38 shows the code snippet for the annotations applied to the firstName and lastName attributes.
In Listing 17-38, the constraints applied are highlighted in bold.
Note that for the validation message, we use a code by using the curly braces.
This will cause the validation messages to retrieve from the ResourceBundle and hence support i18n.
We also want the JSR-303 validation message to use the same ResourceBundle as for the views.
Bring up the add contact view, and just click the Save button.
The validation messages will be displayed, as shown in Figure 17-16
Switch to the Chinese (HK) language, and do the same thing.
This time, the messages will be displayed in Chinese, as shown in Figure 17-17
Now the views are basically complete, except the delete action.
We will leave that one to you as an exercise.
Next, we will start to give our application more richness.
Using jQuery and jQuery UI Although the views for our contact application work well, the user interface is quite raw.
For example, for the birth date field, it would be much better if we could add a date picker when the user enters the birth date of the contact, instead of inputting the date string manually.
To provide a richer interface to the users of a web application, unless you are using rich Internet application (RIA) technologies that require special runtimes on the web browser client (for example, Adobe Flex requires Flash, JavaFX requires JRE, Microsoft Silverlight requires Silverlight, and so on), you need to use JavaScript to implement the features.
However, developing web frontends with raw JavaScript is not easy.
The syntax is very different from Java, and you also need to deal with cross-browser compatibility issues.
As a result, a lot of open source JavaScript libraries are available that can make the process easier, such as jQuery, Dojo Toolkit, and so on.
In the following sections, we will discuss how to use jQuery and jQuery UI to develop more responsive and interactive user interfaces.
We will also discuss some commonly used jQuery plug-ins for specific purposes, such as rich-text editing support, and discuss some grid-based components for browsing data.
Introducing jQuery and jQuery UI jQuery (http://jquery.org) is one of the most popular JavaScript libraries being used for web frontend development.
Built on top of jQuery, the jQuery UI library (http://jqueryui.com) provides a rich set of widgets and effects.
Main features include widgets for commonly used user interface components (a date picker, autocomplete, accordion, and so on), drag and drop, effects and animation, theming, and so on.
There also are a lot of jQuery plug-ins developed by the jQuery community for specific purposes, and we will discuss two of them in this chapter.
What we cover here only scratches the surface of jQuery.
Enable jQuery and jQuery UI in a View To be able to use jQuery and jQuery UI components in our view, we need to include the required style sheets and JavaScript files.
If you read the section “Spring MVC Project Structure Overview” earlier in this chapter, the required files should have been already copied into the project.
The main files that we need to include in our view are as follows:
Listing 17-41 shows the code snippet that needs to be added to the page.
In Listing 17-41, the code that needs to be added is highlighted in bold.
First, the <spring:url> tag is used to define the URLs for the files and store them in variables.
Then, in the <head> section, the reference to the CSS and JavaScript files is added.
This is because JSPX will autocollapse tags without a body.
With these scripts included, we can add some fancier stuff into our view.
For the edit contact view, let’s make our buttons looks a bit better and enable the date picker component for the birth date field.
Now reload the page, and you will see the new button style, and when you click the birth date field, the date picker component will be displayed, as shown in Figure 17-18
Rich-Text Editing with CKEditor For the description field of the contact information, we use the Spring MVC’s <form:textarea> tag to support multiline input.
Suppose we want to enable rich-text editing, which is a common requirement for long text inputs such as user comments.
To support this feature, we will use the rich-text component library CKEditor (http://ckeditor.com), which is a common rich-text JavaScript component, with integration with jQuery UI.
First we need to include the required JavaScript files into the template page (default.jspx)
Listing 17-43 shows the code snippet you need to add to the page.
In Listing 17-43, the code to be added is highlighted in bold.
We included two scripts, the core CKEditor script and the adapter with jQuery.
The next step is to enable the CKEditor in the edit contact view.
Listing 17-44 shows the change required for the page (edit.jspx)
The contact description field is decorated with CKEditor when the document is ready.
Reload the add contact page, and the description field will be enabled with rich-text editing support, as shown in Figure 17-19
For complete documentation on using and configuring CKEditor, please refer to the project documentation site (http://docs.cksource.com/CKEditor_3.x/Developers_Guide)
Data Grid with Pagination using jqGrid The current contact list view is fine if only a few contacts exist in the system.
However, as the data grows to thousands and even more records, performance will become a problem.
A common solution is to implement a data grid component, with pagination support, for data browsing so that the user just browses a certain number of records, which avoids a large amount of data transfer between the browser and the web container.
In this section, we will demonstrate the implementation of a data grid with jqGrid (http://www.trirand.com/blog), a popular JavaScript-based data grid component.
For the pagination support, we will use jqGrid’s built-in Ajax pagination support, which fires an XMLHttpRequest for each page and accepts JSON data format for page data.
So, we need to add the JSON library dependency into our project, as shown in Table 17-6
In the following sections, we will discuss how to implement the pagination support on both the server and client sides.
First, we will cover implementing the jqGrid component in the contact list view.
Then, we will discuss how to implement pagination on the server side by using Spring Data Commons module’s comprehensive pagination support.
Enable jqGrid in the Contact List View To enable jqGrid in our views, first we need to include the required JavaScript and style sheet files in the template page (default.jspx)
In Listing 17-45, the new code is highlighted in bold.
The next step is to modify the contact list view (list.jspx) to use jqGrid.
Under the table, a <div> section with an ID of pager is defined, which is the pagination part for jqGrid.
Within the JavaScript, when the document is ready, we instruct jqGrid to decorate the table with an ID of list into a grid and provide detail configuration information.
The url attribute specifies the link for sending XMLHttpRequest, which gets the data for the current page.
The datatype attribute specifies the data format, in this case JSON.
The mtype attribute defines the HTTP method to use, which is GET.
The colNames attribute defines the column header for the data to be displayed in the grid, while the colModel attribute defines the detail for each data column.
The jsonReader attribute defines the JSON data format that the server will be returning.
The onSelectRow attribute defines the action to take when a row was selected.
In our case, we will direct the user to the show contact view with the contact ID.
Enable Pagination on the Server Side On the server side, there are several steps to take to implement pagination.
First we will use the Spring Data Commons module’s pagination support.
The next step is to add a new method in the ContactService interface to support retrieving the data by page.
As shown in Listing 17-48, a new method findAllByPage() is added, taking an instance of the Pageable interface as an argument.
Listing 17-49 shows the implementation of the findAllByPage() method in the ContactServiceImpl class.
In Listing 17-49, the method implementation is highlighted in bold.
The next step is to implement the method in the ContactController class to take the Ajax request from jqGrid for page data.
In Listing 17-50, the new method listGrid() is highlighted in bold.
Then, an instance of the ContactGrid class is constructed and returned to jqGrid in JSON format.
Now we are ready to test the new contact list view.
Make sure the project is rebuilt and deployed, and then invoke the contact list view.
You should see a view like the one shown in Figure 17-20
You can play around with the grid, browse the pages, change the number of records per page, change the sort order by clicking the column headers, and so on.
For example, we can filter data by first names containing “clarence” or when the birth date is between a date range.
File Upload Handling The contact information has a field of BLOB type to store a photo, which can be uploaded from the client.
In this section, we will discuss how to implement file upload in Spring MVC.
For a long time, the standard servlet specification didn’t support file upload.
However, from Servlet 3.0, file upload has become a built-in feature of the web container.
Table 17-7 shows the dependency that requires deletion and the two new dependencies we need to add.
Configuring File Upload Support In a Servlet 3.0–compatible web container with Spring MVC, configuring file upload support is a twostep process.
First, in the web deployment descriptor (web.xml) for the DispatchServlet definition, we need to add a <multipart-config> section.
Modify Views for File Upload Support We need to modify two views for file upload support.
The first one is the edit view (edit.jspx) to support photo upload for a contact, and the second one is the show view (show.jspx) for displaying the photo.
Listing 17-54 shows the changes required for the edit view.
In the <form:form> tag, we need to enable the multipart file upload support by specifying the attribute enctype.
Next, the file upload field is added to the form.
We also need to modify the show view to display the photo for a contact.
Listing 17-55 shows the changes required to the view (show.jspx)
A new row is added to the table for displaying the photo by pointing to the URL for photo download, as specified in Table 17-5
The first change is to the create() method to accept the upload file as a request parameter.
The second change is to implement a new method for photo download based on the supplied contact ID.
Then the method will get the content saved into the photo property of the Contact object.
Then, a new method downloadPhoto() is added to handle the file download.
The method just retrieves the photo field from the contact object and directly writes into the response stream, which corresponds to the <img> tag in the show view.
To test the file upload function, reload the page and add a new contact with photo, as shown in Figure 17-21
Upon completion, you will be able to see the photo in the show view, as shown in Figure 17-22
We also need to modify the edit function for changing the photo, but we will skip it here.
Securing a Web Application with Spring Security Suppose now we want to secure our contact application.
Only those users who logged into the application with a valid user ID can add a new contact or update existing contacts.
Other users, known as anonymous users, can only view contact information.
Spring Security is the best choice for securing Spring-based applications.
Although mostly used in the presentation layer, Spring Security can help secure all layers within the application, including the service layer.
In the following sections, we will demonstrate how to use Spring Security to secure the contact application.
Configuring Spring Security To configure Spring Security, first we need to configure a filter in the web deployment descriptor (web.xml)
Listing 17-57 shows the code snippet you need to add to the web.xml file.
In Listing 17-57, the filter for Spring Security is highlighted in bold.
Since our requirement is simple, the configuration is simple too.
First, the <http> tag defines the security configuration for HTTP requests.
The attribute use-expressions means that we want to use Spring Expression Language (SpEL) for the expressions.
The <intercept-url> tag specifies that all users are allowed to enter the application.
We will see how we can protect the function by hiding the editing options in the view using Spring Security’s tag library and controller method security.
As we discussed in the layout, the login form will display on the left.
In the configuration, we hard-code a single user with the role ROLE_USER assigned.
In a production environment, the user should be authenticated against the database, LDAP, or an SSO mechanism.
Listing 17-59 shows the revised root-context.xml file to import the security configuration file.
Adding Login Functions to the Application We need to modify two page components: the header (header.jspx) and the menu (menu.jspx)
Listing 17-60 shows the revised header.jspx file to display the user information if the user is logged in.
In Listing 17-60, the changes from the previous version are highlighted in bold.
First, the tag library with the prefix sec is added for Spring Security tag library.
If yes (i.e., the isAuthenticated() expression returns true), the user name will be displayed, as well as a logout link.
Listing 17-61 shows the revised menu.jspx file, which has the login form added; the New Contact option will display only if the user is logged in.
In Listing 17-61, the changes from the previous version are highlighted in bold.
Second, if the user is not logged in (the second <sec:authorized> tag, when the expression isAnonymous() returns true), then the login form will be displayed.
Reload the page, and it will display the login form, as shown in Figure 17-23
Enter user in both the user name and password fields and click Login button.
The user information will be displayed in the header area, as shown in Figure 17-24
We also need to modify the show view (show.jspx) to show the edit contact link for only logged-in users, but we will skip that here.
So, we need to implement a controller to handle this login fail scenario.
The controller class will handle all URLs with the prefix security, while the method loginFail() will handle the login fail scenario.
In the method, we store the login fail message in the Model and then redirect to the home page.
Now reload the page and enter the wrong user information; the home page will be displayed again with the login fail message, as shown in Figure 17-25
Using Annotations to Secure Controller Methods Hiding the new contact link in the menu is not enough.
For example, if you enter the URL in the browser directly (http://localhost:8080/ch17/contacts?form), you can still see the add contact page, even though you are not logged in yet.
The reason is that we haven’t protected the application at the URL level.
However, doing this will block all other users from seeing the contact list view.
An alternative for solving the problem is to apply security at the controller method level, using Spring Security’s annotation support.
As shown in Listing 17-63, the security namespace is added.
Now we can use the @PreAuthorize annotation for the controller method we want to protect.
Listing 17-64 shows an example of protecting the createForm() method.
First, remove the following servlet and servlet mapping definition in Listing 17-65 from the web.xml file.
Using this approach, when combined with the Java code-based configuration of Spring, it’s possible to implement a pure Java code-based configuration of a Spring-based web application, without the need to declare any Spring configuration in web.xml or other Spring XML configuration files.
Spring MVC in the Sample Application Many topics discussed in this chapter will be adopted in the sample application for implementing the presentation layer, and their relationships will be covered in this section.
The usage of Spring MVC and related libraries are as follows:
In SpringBlog, support of English (US) and Chinese (HK) will be provided.
Theming: We will use the theming support in Spring MVC.
For example, the <spring:theme> tag will be used in a page template to load the active theme being used.
Page templating: In the SpringBlog application, Apache Tiles will be used for page templating.
The page layout will be much like the one we presented in this chapter, with standard components including a header, menu, footer, body, and so on.
Spring MVC’s built-in support for using Tiles as the view resolver will be used also.
Validation, type conversion, and formatting: All frontend validation in the SpringBlog application will rely on JSR-303 Bean Validation.
Spring 3’s new type conversion and formatting support will be used too.
Rich User Interface and Ajax All JavaScript libraries discussed in this chapter will be used to provide richness to the SpringBlog application.
User interface: jQuery and jQuery UI will be used for implementing SpringBlog’s user interface.
For example, when searching blog entries by a date range, the date picker widget will be used.
Rich-text editing: CKEditor will be used to provide rich-text editing support for users when posting blog entries and comments.
Data grid with pagination: jqGrid will be used for browsing the blog entries in a grid-based interface.
Pagination support will be provided, and users will be able to sort the entries by various attributes, as well as change the number of records displayed per page.
Moreover, we will use jqGrid’s filter support to allow users to search for entries by subject, post date range, and so on.
User and role: The SpringBlog database will have tables to store the defined users and roles.
For each user, roles granted will also be stored for authentication and authorization.
Users can only act on what they were allowed to do based on the roles granted.
For example, only the user who posted the entry can modify the entry.
In addition, only users with the administrator role granted can view the audit history of an entry.
User interface: The user interface will be rendered based on the roles using the techniques demonstrated in this chapter.
In the views, Spring Security’s JSP tag library will be used to display user information, as well as display the functions that the users are allowed to do.
In addition, method-level security will applied at the controller level wherever required, using Spring Security’s annotation support.
File upload: One feature in SpringBlog is that users can upload attachments to their blog entries or comments.
Summary In this chapter, we covered many topics related to web frontend development using Spring MVC.
First we discussed the high-level concepts of the MVC pattern.
Next we developed a sample contact application using Spring MVC, with JSPX as the view technology.
During the course of developing the samples, different areas were elaborated on.
Main topics included i18n, theming, and template support with Apache Tiles.
Moreover, we used jQuery, jQuery UI, and other JavaScript libraries to enrich the interface.
Samples included the date picker, richtext editor, data grid with pagination support, and so on.
How to secure a web application with Spring Security was discussed too.
Also, the new support for code-based configuration instead of configuration in web.xml file was covered.
In the next chapter, we will discuss more features that Spring brings us in terms of web application development.
In the previous chapter, we discussed developing web application with Spring MVC, using JSPX and JavaScript as the view technologies.
In terms of web application development, there are numerous options, including native clients (for example, Adobe Flex, JavaFX, Microsoft Silverlight, and so on), MVC frameworks (for example, Spring MVC, JBoss Seam, Struts, and so on), and view technologies (for example, JSP, Velocity, JavaScript, JSF, and so on)
Moreover, Spring Web Flow tightly integrates with Spring MVC for supporting web application features such as i18n, theming, and validation.
In this chapter, we will discuss how the Spring Web Flow project can help you develop a flow-based web application.
Moreover, we will demonstrate how Spring Web Flow works with JSF (a componentbased view technology, which is also the standard view technology within the JEE stack) using the Spring Faces module (under Spring Web Flow) and PrimeFaces (http://primefaces.org), a popular JSF component library.
Spring Web Flow: We will introduce Spring Web Flow and the main features that it provides, including its support for developing flow-based application, its more fine-grained scope of Java beans, and the view technologies that Spring Web Flow integrates with.
JSF: We will present a high-level description of JSF (specifically, JSF 2)
Its main concepts, including the component-based model, view-handling life cycle, templating support, and so on, will be discussed.
In addition, we will also briefly describe some commonly used JSF component libraries.
Project for Sample Backend It’s always better to develop a web application with a concrete backend, other than some simple “Hello World” examples.
As a result, a sample backend project was prepared in the sample source code so that you can just import the project and the backend will be ready.
In the following sections, we will briefly describe the sample backend and how to import the project for developing the frontend samples in this chapter.
The Sample Backend Service Layer The backend for the samples in this chapter is a simple contact application.
Each contact has basic information, including first name, last name, and date of birth.
In addition, a contact also has zero or more hobbies.
For the backend, we will use JPA 2 and Hibernate as the persistence service provider.
Figure 18-2 shows a class diagram of the service layer.
Import the Sample Backend in STS Because this chapter focuses on the frontend development, we have prepared a project with the service layer implemented so that you can just import it and then proceed to implement the frontend.
From the sample code, extract the file ch18-backend.zip into your STS workspace.
Then, in the Import Projects dialog, choose the project extracted from the sample source code, and then click Finish (see Figure 18-4)
Up to this point, the project setup is complete, and we are ready to start to implement the frontend using Spring Web Flow and PrimeFaces.
Before that, though, let’s take a look at the high-level concepts of Spring Web Flow and JSF.
Introducing Spring Web Flow Building on top of Spring MVC’s foundation, Spring Web Flow was designed to provide advanced support for organizing the flows inside a web application.
Additionally, extended functionalities are provided in various web application areas.
In the following sections, we will present a high-level overview of Spring Web Flow.
The main features, modules, integration with view technologies such as JavaScript libraries and JSF, and so on, will be discussed.
For example, in this chapter, we will discuss using Spring Faces (a module within Spring Web Flow) with the JSF component library PrimeFaces to develop a flow-based web application.
Later we will add the dependency of Spring Faces into the project.
Figure 18-5 shows the dependency hierarchy after importing the Spring Faces module in the project in STS.
Spring Web Flow (spring-webflow): This is the core module in Spring Web Flow; it provides the infrastructure for managing flows and, for each flow, its conversation, state, and views.
Spring Faces (spring-faces): Spring Web Flow provides first-class support for JSF, and the supporting components are packaged within the Spring Faces module.
For example, in the rendered HTML view, JavaScript can be used for Ajax communication with servers and partial view updates.
Spring Binding (spring-binding): As its name implies, the Spring Binding module is responsible for binding the view state to the underlying model.
Spring Web Flow Features Spring Web Flow is an extension to the MVC pattern; it provides support for developing flow-based applications and supports more fine-grained bean scopes.
The architecture of Spring Web Flow is built around the following three main concepts:
Flow: A flow is a business process representing a use case.
In Spring Web Flow, a flow consists of a series of steps called states.
Each state is typically presented to the user within a view (there are also other states that are not view related; for example, the decision state determines the next state of the flow depending on the runtime condition)
Within the view, user events occur that are handled by the state.
These events can trigger transitions to other states that result in view navigation within the entire flow.
Spring Web Flow provides a domain-specific language (DSL) that can be used to implement very complex flows for your application.
View: The same as in the MVC pattern, a view is a user interface that presents the state of the model to the user and provides user interaction with Ajax support and partial view updates.
Conversation: In a web application, in terms of bean scopes, there are three types, namely, request, session, and application.
The request and session scopes are used intensively for the presentation layer.
However, in many web applications, especially flow-based, the model beans should maintain their state across multiple requests until the flow is finished.
However, using session scope would be overkill, because the state would be kept in the user’s HttpSession for the entire session.
To address this, Spring Web Flow introduces the concept of a conversation, which holds the data until a flow is completed.
The main purpose of this is to avoid putting too much data into.
When using Spring Web Flow, understanding the scopes of beans and variables that it maintains is very important.
Flow The variables with flow scope are allocated when the flow starts and are destroyed when the flow ends.
It’s the scope to use if you want the variable, which usually stores the interaction state as well as the underlying model, to be maintained during the entire flow.
A flow scope variable is not accessible in its subflows.
View The variables with view scope are allocated when the flow enters a view (called the view-state) and destroyed when the state exits.
In other words, view scope variables survive only within a view.
When you need to display information (for example, a list of contacts) that is required only within a certain view within the flow, you should use the view scope to minimize the memory consumption.
Request Variables with request scope are created when the flow is called and destroyed when the flow returns.
Flash Variables with flash scope are allocated when the flow starts.
Then, they will be cleared after each view is rendered and destroyed when the flow completes.
It’s useful for those variables that exist in every view, but the value will be different in each view.
One example is the status message that will be displayed in every step of the flow to indicate the flow status or display messages to users.
Conversation The conversation scope is the same as the flow scope.
The only difference with flow scope is that the variables with the conversation scope will be available for its flows.
For example, an order application provides a flow for entering order information.
Within the flow, one step is to invoke a flow called select-customer to select the customer who places the order.
However, in the subflow, when selecting the customer, the information about the order should be available because it contains some filter criteria (for example, an international order can be placed only by customers living in certain countries)
For this case, the order should be placed under the conversation scope.
Introducing JSF JavaServer Faces (JSF) is another popular view technology used for developing the presentation layer of an enterprise application.
Generally speaking, JSF is a request-driven MVC web framework based on a component-driven UI design model.
However, the first generation of JSF (called JSF 1) has been criticized for its steep learning curve, complexity in building custom components, and lack of support for Ajax.
Furthermore, there are a lot of open source and commercial projects that provide JSF component libraries, such as JBoss RichFaces, PrimeFaces, ICEfaces, and so on.
These four components will be discussed in the following sections.
View In JSF, as with the MVC pattern, a view is a page that presents data to the user.
However, because JSF is a component-based framework, a view is represented by a tree of UI components, which are exposed in the view as markup tags.
As of JSF 2, Facelets is the standard technology for all JSF pages.
Facelets, which adopts the XHTML syntax, provides built-in support of page templating, without the need of other templating frameworks like Apache Tiles.
Model Interaction In JSF, the view stores a tree of UI components with values and provides user interactions.
When a user takes an action, the request will be submitted to the server for processing.
On the server side, the values in the UI component tree will be transformed back into the model for processing.
This process represents the action between the UI components and the underlying model.
When the response is rendered to the user, the UI components get their values from the associated model properties.
During the interaction, type-safe conversion and server-side validation occur automatically.
To support highly interactive web pages in JSF, model objects are usually implemented as “backing beans” on a page basis.
In this case, the model object represents the state of the model properties stored by the view.
For example, when using JSF with Spring Web Flow, the standard Spring beans can be used as JSF managed beans, using the standard DI mechanism provided by the Spring Framework.
Navigation JSF provides a framework for defining page navigation rules.
For example, in a view, when a user performs an action, the request is submitted to the server.
On the server side, an “action controller” will process the request by interacting with the service layer, and then depending on the outcome and the navigation rules defined in the faces-config.xml file, the corresponding view will be displayed to the user.
However, when using Spring Web Flow, the JSF navigation mechanism is not required.
As described in the section “Spring Web Flow Features” earlier in this chapter, Spring Web Flow provides built-in support for flow definition, which can replace the navigation model provided by JSF.
Application Life Cycle The most critical part of JSF to understand is its application life cycle.
The entire life cycle starts when the web application running JSF receives a request, runs through six phases, and then renders a response and displays it to the user.
When a user takes an action in the view and sends a request to the server, the first phase in JSF is to restore the view back from its state.
Apply requests: After the component tree is restored, each component in the tree extracts its new value from the request parameters by using its decode method.
Process validations: In this phase, the JSF implementation processes all validators registered on the components in the tree.
It examines the component attributes that specify the rules for the validation and compares these rules to the local value stored for the component.
Update model values: Upon validation completion, the JSF implementation will walk through the component tree and set the corresponding server-side object properties to the components’ local values.
Only the bean properties pointed at by an input component’s value attribute will be updated.
In this binding process, type conversion and formatting also occurs, and in case the conversion failed, the life cycle advances directly to the render response phase so that the page is rerendered with errors displayed.
Invoke application: In this phase, the JSF implementation invokes the application to handle form submissions.
At this point, the component values will have been converted, validated, and applied to the model objects, so they can be used to execute the application’s business logic.
During the execution, the JSF implementation will handle any application-level events, such as submitting a form or linking to another page.
In addition, if the view being processed was reconstructed from state information from a previous request, and if a component has fired an event, these events are broadcast to interested listeners.
Render response: In this final phase, the resulting view is displayed with all of its components in their current state.
A phase listener has full access to the entire JSF framework, including manipulating the view.
The Sample Spring Web Flow Application In this chapter, to demonstrate using the combination of Spring Web Flow and JSF for flow-based applications, we will develop a simple flow to implement a function for creating new contacts.
In the following sections, we will discuss the design of the overall flow for creating new contacts and the project structure for the sample in this chapter.
Design of the Sample Flow As described earlier in this chapter, a contact consists of basic information about a user (first name, last name, date of birth), as well as their hobbies.
When creating new contacts, a wizard-like approach will be used, which allows the users to enter the information in different pages, review the overall information, and then confirm by submitting the information for processing.
The process is much like registering on many web sites.
Figure 18-7 shows the overall flow of creating contacts and their associated views that we need to implement.
In the figure, the arrow labels represent buttons on the pages.
For example, each page has a Back button, and the pages in the Add process all have an Exit button.
As shown in Figure 18-7, the first page that users will see is a list of all contacts.
When a user selects a row and clicks the View Selected button, the show contact view will be displayed.
In the show contact view, the user can navigate back to the list contact page by clicking the Back button.
When a user clicks the Add Contact button, it triggers the add contact flow.
Clicking the Next button will navigate to the view for selecting hobbies.
The next step is the review page where the user reviews all the information entered.
When the user confirms the information, the contact is persisted, and the complete view is displayed.
At any page within the flow, the user can navigate to the previous page by clicking the Back button or end the flow and return to the list contact view by clicking the Exit button.
Project Structure Before we implement the add contact flow, let’s take a look at the project folder structure.
Figure 18-8 shows the folder structure of the sample web flow application that will be developed in this chapter.
Table 18-2 lists the purpose of each folder (under the root folder /src/main/webapp)
We will use the theming support of PrimeFaces for this sample.
WEB-INF/flows This folder stores all the flows within the application.
Each flow folder stores the files required for supporting that particular flow.
For example, the contacts folder stores the files for the add contact flow.
All the view files, together with the flow definition file, will be stored in this folder.
WEB-INF/layouts This folder stores the layout template that will be used by Facelets.
Both the root-level and dispatcher servlet–level context configurations are stored here.
Spring Web Flow configuration will be stored in this folder too.
Configuring JSF For a JSF application, we need to specify a JSF-dedicated configuration file (the faces-config.xml file under the /WEB-INF folder)
This file typically stores the general JSF configurations, information on the managed beans (not required if you use the annotation style), and the navigation rules.
However, we will use Spring Web Flow, which integrates with Spring Framework’s IoC for DI, so the configuration required in this file is minimal.
The <var> tag specifies that the messages will be available to the EL under the variable name msg, which we will see in action when developing the views.
Configuring Web Deployment Descriptor The next step is to configure the web.xml file for JSF support.
In Listing 18-2, the JSF-related configurations are highlighted in bold.
The value of Development causes more output messages to be displayed to the web browser to facilitate troubleshooting.
Setting the value to 1 means the change will be checked every second, so when we make frequent changes to the page templates during development, each change can be detected immediately.
In the production environment, set the value to -1 so that all compiled templates will not be checked for changes.
The servlet is used only to bootstrap the JSF environment.
You will also see the definition of a DispatcherServlet for the contact application that was mapped to the URL pattern /app/*
Since Spring Web Flow tightly integrates with Spring MVC, we use the DispatcherServlet to dispatch the request to the underlying Spring Web Flow executor for request processing.
For Spring Web Flow, we will prepare an individual configuration file.
When using Spring MVC, the configuration file usually resides in the same folder as the DispatcherServlet configuration file.
Second, the <flow-registry> tag defines a registry for the flow definitions within the application.
From the listing, the flow definitions are stored in files named flow.xml, under the parent folder /WEBINF/flows.
In Listing 18-4, most of the beans should be familiar to you.
It maps the URL path to the id of the registered flow definitions.
Finally, the bean with ID messageSource is the same as the one for Spring MVC.
Implementing the Sample Flow Now the infrastructure and configurations are complete, and we can start to implement the add contact flow.
In the following sections, we will go through the steps to implement the flow.
Various steps, including the flow definition, template view, various contact views, controller class, backing bean classes, and so on, will be discussed.
Define the Flow Definition Let’s begin with defining the contact application flow, which was illustrated in Figure 18-7
There is a convenient way to create a web flow definition file in STS.
Listing 18-5 reflects the complete flow of the contact application.
The corresponding views, controller methods, and backing beans will be developed later.
As in the webflow.xml configuration, the flow registry bean is configured with the base path /WEB-INF/flows, and this flow definition file resides under the folder contacts.
This flow will be automatically registered in Spring Web Flow with the ID contacts, accessible via the URL /ch18/app/contacts.
In the flow definition, besides the namespace declarations, a start-state attribute is also provided with the value start, which indicates the state of the flow when this flow starts.
In our case, the start state is the state with the ID start.
The start state specifies the view attribute with list.xhtml, which indicates the file to render for this state.
The resulting contact list (stored in the ContactListBean class, to be implemented later) is stored as a view scope variable.
The <transition> tags defines the possible navigation paths within the flow based on the action taken by the user.
For the start state in the contact list view, when a user selects a contact and clicks the View Selected button, it will navigate to the show contact view.
When the Add Contact button is clicked, it will navigate to the first step of the add contact flow.
The other <view-state> tags are defined according to the designed add contact flow.
Within each state, the user can choose to proceed or step backward.
In this case, a global rule is specified so that whenever the user clicks the Exit button, the exit transition will be triggered, and the flow will always navigate back to the start state, which is the contact list view.
For the view state with the IDs review and show, note that an argument called flowRequestContext was passed into the corresponding methods.
The flowRequestContext argument is an implicit EL variable within Spring Web Flow, which enables access to the RequestContext API, a representation of the current flow request.
By default, when a flow ends, a new flow will be created, and Spring Web Flow will navigate to the start state of the flow.
If the end state happens in a subflow, it will return to the parent flow.
Spring Web Flow supports a lot of other features, such as many other states (for example, decisionstate, action-state, and so on) and the definition of subflows, with input/output parameters passing between the flows.
For a full description, please refer to Spring Web Flow’s online documentation (http://static.springsource.org/spring-webflow/docs/2.3.x/reference/html/index.html)
In STS, it’s also possible to view the flow in a graphical format.
First make sure that the Spring Project nature is active for the project and the flow.xml file is added as a flow definition within the project.
You can then right-click the flow.xml file, choose Open With, and then choose Spring Web Flow XML Editor, as shown in Figure 18-9
Then, click the flow-graph tab, and the flow definition will be presented in the editor area with a graphical format, giving you a more user-friendly view of the flow definition, as shown in Figure 18-10
Implementing the Template Page Before we implement each individual view, we need to implement the template page, which will be used by all the views in the samples in this chapter.
In Listing 18-6, the layout of the template page is quite simple.
In JSF, there are three main tag libraries: h-namespace, f-namespace, and ui-namespace:
Within this tag, all the UI components, including their hierarchy and state, will be stored by the JSF runtime environment.
The ui-namespace is used by Facelets to define the elements within the template.
For example, the <ui:insert> tag specifies that content should be inserted here.
The views using this template should provide the content for this template to include.
Implementing a Custom Converter For a contact’s date of birth attribute, we use JodaTime.
However, JSF and PrimeFaces don’t support the display of JodaTime natively.
As a result, we need to implement a custom JSF converter to serve the purpose of displaying the date of birth of a contact in the frontend.
Also note that the class is annotated with @FacesConverter to indicate to the JSF.
The attribute defined within the annotation is the ID of the converter.
We will see how to use it when we implement the list contact view.
Implementing the Controller and Backing Bean The next step is to implement the controller class, as well as the backing bean for the list contact view.
This class is used to store the list of contacts, as well as the selected contact when a user clicks a row in the data table.
The bean is a simple POJO bean, with the attributes to store the list of retrieved contacts and the contact selected by the user in the frontend.
Note that the backing bean should implement the Serializable interface.
We just define it as a Spring bean (by using the @Component annotation), and Spring Web Flow will be able to locate it and execute the method when entering the start state.
As you can see, the method simply invokes the method from the service layer, stores the contact lists into a new instance of the ContactListBean class, and then returns the instance.
In the flow definition, the returned object will be stored in the view scope variable, available to JSF when rendering the response.
This is because in this chapter we use Spring Web Flow to control the application flow, not Spring MVC’s controller.
So, we just need to declare it as a trivial Spring bean implementing the list contact view.
Now we can implement the list contact view, which is the start state of the flow.
In Listing 18-10, one new namespace (the p-namespace) was defined, which corresponds to the PrimeFaces JSF components.
The Facelets’ <ui:composition> tag is used to define a composition of view components, using standard.xhtml as the template file.
The <ui:define> tags define the contents for including in the template.
You can see that the two variables (title and content) required by the template (specified by the <ui:insert> tag in standard.xhtml) are provided.
For the content area, we use PrimeFaces’ DataTable component to display the list of contacts in a table format.
In the <p:dataTable> tag, configuration parameters are provided, such as the support of pagination, rows per page, selection.
Within the table, the <p:column> tags define each contact property to display.
Note that for the birthDate attribute, we use the <f:converter> tag with the id attribute referencing the custom converter implemented for the JodaTime’s DateTime type.
In the footer of the table, a View Selected button is defined for viewing the selected contact’s information.
You can also enable a code-assist feature when developing the view with JSF and PrimeFaces tags.
The procedure is easy in STS; you just right-click the project and select Properties.
Then in the left menu, select the option Project Facets.
Then, on the right, check the Project Facet option JavaServer Faces, as shown in Figure 18-11
At the bottom, you will notice that there is a notification that indicates that further configuration is required.
Clicking the link will invoke the dialog for JSF configuration.
Because we already added the dependencies for JSF and defined the faces-config.xml file, we don’t need to define anything here.
Just uncheck all the options, as shown in Figure 18-12
Now the code-assist feature for the JSF view is enabled.
In the XHTML editor page, when you press Ctrl+spacebar or type the tag library prefix, a code-assist dialog will be displayed, as shown in Figure 18-13
Before we can test the view, we also need to update the project settings for the web project properties.
Now we are ready to test the list contact view, although the other components of the flow are still not implemented.
After the project is built and deployed, open a browser and enter the URL http://localhost:8080/ch18/app/contacts.
The list contact view (which is the start state of the flow) will be displayed, as shown in Figure 18-15
Implementing the Show Contact View Let’s implement the show contact view, which will be displayed when the user selects a row and clicks the View Selected button.
In Listing 18-11, the navigation to the contact show view and the show state was highlighted in bold.
Within the <transition> tag in the start state, a variable called contactId with the request scope was set (based on the id of the contact of the selected row) and then transitioned to the show state.
The returned Contact object is stored as a view scope variable for rendering the show contact view.
In Listing 18-13, the contact information is rendered based on the properties stored in the contact variable.
Note that for rendering the hobbies information, the Contact object’s transient method getHobbiesAsList() is called.
The reason is that JSF is not able to render detail information stored in a Set.
So, the helper method getHobbiesAsList() is implemented to return the hobbies as a List.
To test the show contact view, select a row and then click the View Selected button.
Then the contact information will be displayed, as shown in Figure 18-16
Implement the Add Contact Flow Having the contact list view and show contact view ready, we can proceed to implement the add contact flow.
In the following sections, we will discuss the implementation of the views in the add contact flow.
Step 1: Enter Basic Information The add contact flow will be started when the user clicks the Add Contact button in the list contact view.
The first state is step 1, in which the user will enter the basic information of a contact, including the first name, last name, and date of birth.
This makes the variable available to all the steps within the add contact flow.
Listing 18-15 shows the ContactBean class, which stores the entered information across the flow and contains properties that facilitates user interaction by using PrimeFaces components.
One is the contact property, which stores the contact information.
Listing 18-16 shows the implementation of the newContactBean() method in the ContactController class.
In Listing 18-17, fields are provided with PrimeFaces’ input components.
Note the use of the <p:calendar> tag, which uses PrimeFaces’ Calendar component and supports a pop-up date picker.
After the project is built and deployed, test the view by clicking the Add Contact button in the list contact view.
The Contact class already is annotated with constraints on both the firstName and lastName properties.
During the update process, JSR-303 validation will be triggered automatically during the JSF application life cycle.
To see it in action, in the step 1 view, click the Next button without having entered anything.
The same view will be displayed again but with the validation messages displayed, as shown in Figure 18-18
In Listing 18-18, note the use of the PrimeFaces’ PickList component for selecting hobbies.
The PickList is bound to the hobbies property of the ContactBean class, which is of the DualListModel class.
The available hobbies are stored in the source property, while the selected hobbies are stored in the target property.
For the hobby property, we also need to implement a custom converter for transformation between the String and Hobby classes.
To test the view, enter information in step 1, and then click the Next button.
To test the view, select the hobbies for the contact, and then click the Next button.
The review page will be displayed, as shown in Figure 18-20
In Listing 18-21, which enables the transition from review to complete state, the complete and end states are highlighted in bold.
In Listing 18-22, in the saveContact() method, the flow scope variable contactBean is retrieved from Spring Web Flow’s RequestContext, the contact property is retrieved, the hobbies property is populated, and then the Contact object is persisted.
Upon completion, a success message is constructed and put into the MessageContext, and the complete view is rendered.
In Listing 18-4, in the Spring MVC configuration, we defined the messageSource bean with the message file paths specified.
We just need to put the following line into the file for the success message:
After the project is built and deployed, you can try the entire flow.
Click the Next or Back button in any state, and you will see that the value was kept for the entire flow.
Figure 18-21 shows what it looks like after a contact is saved successfully.
Summary In this chapter, we covered using Spring Web Flow and JSF 2 when implementing a flow-based web application.
Then, the first-class support of JSF in Spring Web Flow was covered, with the required dependencies and configurations.
Then we designed a sample flow for adding a contact.
The design of the flow, including state transitions, views, variables, and so on, was elaborated on.
Finally, we went through the steps to implement the flow.
Steps included the development of the flow definition, controller class, backing beans, custom converters, views using JSF, and PrimeFaces components.
When developing applications for enterprise use, testing is an important way to ensure that the completed application performs as expected and fulfills all kinds of requirements (architectural, security, user requirements, and so on)
Every time a change is made, you should ensure that the changes that were introduced don’t impact the existing logic.
Maintaining an ongoing build and test environment is critical for ensuring highquality applications.
Reproducible tests with high coverage for all your code allow you to deploy new applications and changes to applications with a high level of confidence.
In an enterprise development environment, there are many different kinds of testing that target each layer within an enterprise application, and each kind of testing has its own characteristics and requirements.
In this chapter, we will discuss the basic concepts involved in the testing of various application layers, especially in the testing of Spring-powered applications.
We also will cover the ways in which Spring makes implementing the test cases of various layers easier for developers.
Enterprise testing framework: We will briefly describe an enterprise testing framework.
We will discuss various kinds of testing and their purposes.
In this chapter, we will focus on unit testing, targeting various application layers.
Logic unit test: The finest unit test is to test only the logic of the methods within a class, with all other dependencies being “mocked” with the correct behavior.
In this chapter, we will discuss the implementation of logic unit testing for the Spring MVC controller classes, with the help of a Java mock library to perform the mocking of a class’s dependencies.
Integration unit test: In an enterprise testing framework, integration testing refers to testing the interaction of a group of classes within different application layers for a specific piece of business logic.
Typically, in an integration testing environment, the service layer should test with the persistence layer, with the backend database available.
However, as application architecture evolves and the maturity of lightweight in-memory databases evolves, it’s now a common practice to “unit test” the service layer with the persistence layer and backend database as a whole.
In this architecture, it’s of less importance to “mock” Hibernate and Spring Data JPA when testing the service layer.
As a result, in this chapter, we will discuss testing of the service layer together with the persistence layer and the H2 in-memory database.
This kind of testing is generally referred to as integration unit testing, which sits in the middle of unit testing and full-blown integration testing.
Frontend unit test: Even if we test every layer of the application, after the application is deployed, we still need to ensure that the entire application works as.
More specifically, for a web application, upon deployment to the continuous build environment, we should run “frontend” testing to ensure that the user interface is working properly.
For example, for a contact application, we should ensure that each step of the normal functionality works properly, and we also should test exceptional cases (e.g., how the application functions when information doesn’t pass the validation phase)
In this chapter, we will discuss how to use an open source framework to help automate the testing of the frontend of a web application.
Project for Sample Web Application For the test cases in this chapter, we will take use contact web application that we implemented in Chapter 17 as the target application under test.
Import the Sample Backend in STS Because this chapter focuses on unit test development, we have prepared a project for the sample web application so that you can just import it and then proceed to implement the test cases.
From the sample code, extract the file ch19-notest.zip into your STS workspace.
Then, in the Import Projects dialog, choose the project extracted from the sample source code, and then click Finish (see Figure 19-2)
Upon project import completion, build and deploy to the tc Server in STS.
At this point, the sample application setup is complete, so we can proceed to implementing the test cases.
Introducing an Enterprise Testing Framework An enterprise testing framework refers to the testing activities in the entire application’s life cycle.
In various phases, different testing activities will be performed to verify that the functionalities of the application are working as expected according to the defined business and technical requirements.
Some will be automated, while some will be performed manually.
In each case, the result will be verified by the corresponding personnel (e.g., business analysts, application users, and so on)
Table 19-1 describes the characteristics and objectives of each type of testing, as well as common tools and libraries that are used for implementing the test cases.
Logic unit test A logic unit test takes a single object and tests it by itself, without worrying about the role it plays in the surrounding system.
Integration unit test An integration unit test focuses on testing the interaction between components in a “near real” environment.
These tests will exercise the interactions with the container (embedded DB, web container, and so on)
Frontend unit test A frontend unit test focuses on testing the user interface.
The objective is to ensure that each user interface reacts to users’ actions and produces the output to the users as expected.
The application code base should be built on a regular basis to ensure that the code quality complies with the standard (e.g., comments were all in place, no empty exception catch block, and so on)
Also, test coverage should be as high as possible to ensure that all developed lines of codes are tested.
System integration test The system integration test verifies the accuracy of the communication among all programs in the new system and between the new system and all of the external interfaces.
The integration test must also prove that the new system performs according to the functional specifications and functions effectively in the operating environment without adversely affecting other systems.
Functional test Use cases and business rules are tested by functional tests.
The goals of these tests are to verify that inputs are accepted properly and outputs are generated properly, where “properly” means in accordance both with the use case specifications and with the business rules.
This is black-box testing by interacting with the application via the GUI and analyzing the results.
System quality test The system quality test is to ensure that the developed application meets those nonfunctional requirements.
Most of the time, this tests the performance of the application to ensure that the target requirements for concurrent users of the system and workload are met.
Other nonfunctional requirements include security, high availability features, and so on.
User acceptance test The user acceptance test simulates the actual working conditions of the new system, including the user manuals and procedures.
Extensive user involvement in this stage of testing provides the user with invaluable training in operating the new system.
It also benefits the programmer or designer to see the user experience with the new programs.
This joint involvement encourages the user and operations personnel to approve the system conversion.
In this chapter, we will focus on the implementation of the three kinds of unit test (logic unit test, integration unit test, and frontend unit test) and see how the Spring TestContext framework and other supporting tools and libraries can help in developing those test cases.
Instead of presenting the full details and list of classes that the Spring Framework provides in the testing area, we will discuss the usage of the most commonly used patterns and the supporting interfaces and classes within the Spring TestContext framework as we implement the sample test cases in this chapter.
Implementing Logic Unit Test As previously discussed, a logic unit test is the finest level of testing.
The objective is to verify the behavior of an individual class, with all the class’s dependencies being “mocked” with expected behavior.
In this section, we will demonstrate a logic unit test by implementing the test cases for the ContactController class, with the service layer being “mocked” with expected behavior.
To help mock the behavior of the service layer, we will use Mockito (http://code.google.com/p/mockito), which is a popular mocking framework.
Adding Required Dependencies First we need to add the dependency on Mockito into the project, as shown in Table 19-2
Add the dependency in Table 19-2 to the project in STS.
Unit Testing Spring MVC Controller In the contact web application we implemented in Chapter 17, Spring MVC was used as the presentation layer.
In the presentation layer, controller classes provide the integration between the user interface and the service layer.
Methods in controller classes will be mapped to the HTTP requests.
Within the method, the request will be processed, will bind to model objects, and will interact with the service layer (which was injected into the controller classes via Spring’s DI) to process the data.
Upon completion, depending on the result, the controller class will update the model and the view state (e.g., user messages, and so on) and return the logical view (or the model with the view together) for Spring MVC to resolve the view to be displayed to the user.
For unit testing controller classes, the main objective is to make sure that the controller methods update the model and other view states properly and return the correct view.
In addition, when an error happens, testing ensures that the correct exception is thrown and the error messages are saved into the state for displaying to the user.
As we only want to test the controller classes’ behavior, we need to “mock” the service layer with the correct behavior.
For the ContactController class in the sample application, we would like to develop the test cases for the list() and create() methods.
In the following sections, we will discuss the steps for this, including the development of some common infrastructure classes that support controller class testing and the implementation of the test cases.
Implement the Infrastructure Classes For a group of common tests (e.g., test cases for controller classes, service layer testing classes, and so on), it’s always a best practice to develop a common abstract parent class that has the mandatory testing infrastructure set up correctly.
In this chapter, we will use Java classes for configuring Spring’s TestContext.
In addition, we will use the profile feature in Spring 3.1 for configuring the components specific to the test environment.
Then, the @Profile annotation was applied to the class to indicate the profile (in this case the test profile) that the beans configured in this class belong to.
However, it’s always a good practice to maintain a configuration class so that when the need arises in future (e.g., the Spring MVC layer needs to integrate with an external FTP server), then the mocked bean for the FTP server can be defined in this configuration class.
In Listing 19-2, we applied several annotations to the abstract base class.
Within the annotation, we specified the classes attribute, which indicates that configuration was defined in the provided Java classes.
It’s also possible to load the context from XML files by providing the locations attribute, but you can’t provide both locations and classes attributes together.
Finally, the @ActiveProfiles annotation is applied, passing in the profile name test as the attribute.
This indicates to Spring that beans belonging to the test profile should be loaded.
In this test case, we want to make sure that when the method is called, after the list of contacts is retrieved from the service layer, the information is saved correctly into the model, and the correct logical view name is returned.
In the method, a list of contacts is initialized with hard-coded information.
Second, the testList() method is applied with the @Test annotation, which indicates to JUnit that it’s a test case that JUnit should run.
Upon invocation, the result is verified by calling the various assert methods (provided by JUnit) to ensure that the correct logical view name is returned, and the list of contact information is saved correctly in the model for used by the view.
Testing the create() Method Listing 19-4 shows the code snippet for testing the create() method.
Moreover, a mocked instance of the MessageSource interface is mocked with Mockito.
Then an instance of ContactController class is constructed, and its dependencies to ContactService and MessageSource are set with the mocked implementation.
In addition, besides ExtendedModelMap, instances of RedirectAttributes and HttpServletRequest are constructed.
Run the result again, and note the result in the JUnit view.
For the create() method, we should create more test cases to test various scenarios.
For example, we need to test when data access errors are encountered during the save operation.
Implementing an Integration Unit Test In this section, we will implement the integration unit test for the service layer.
When unit testing the service layer, we will use the H2 in-memory database to host the data model and testing data, with the JPA providers (Hibernate and Spring Data JPA’s repository abstraction) in place.
The objective is to ensure that the ContactServiceImpl class is performing the business functions correctly.
In the following sections, we will show how to test some of the finder methods and the save operation of the ContactServiceImpl class.
Adding Required Dependencies For implementing test cases with the database in place, we need a library that can help populate the desired testing data in the database before executing the test case and that can perform the necessary database operations easily.
Moreover, in order to make it easier to prepare the test data, we will support the preparation of test data in Microsoft Excel format.
On the database side, DBUnit (http://dbunit.sourceforge.net) is a common library that can help implement database-related testing.
In addition, the Apache POI (http://poi.apache.org) project’s library will be used to help parse the test data that was prepared in Microsoft Excel.
Add the dependencies in Table 19-3 into the project in STS.
Configuring the Profile for Service Layer Testing The bean definition profiles feature introduced in Spring 3.1 is very useful for implementing a test case with the appropriate configuration of the testing components.
To facilitate the testing of the service layer, we will also use the profile feature for the ApplicationContext configuration.
For the contact application, we would like to have two profiles, as follows:
Development profile (“dev”): Profile with configuration for the development environment.
For example, in the development system, the backend H2 database will have both the database creation and the initial data population scripts executed.
Testing profile (“test”): Profile with configuration for the testing environment.
For example, in the testing environment, the backend H2 database will have only the database creation script executed, while the data will be populated by the test case.
We would like to configure the data source in the file for dev profile only.
To do this, we need to wrap the data source bean with the profile configuration.
Listing 19-5 shows the code snippet for the change required.
As shown in the code snippet, the dataSource bean is wrapped with the <beans> tag and given the profile attribute with the value dev, which indicates that the data source is applicable only for the development system.
To bootstrap the web application with the development profile, we add the parameter in the web deployment descriptor (another way is to modify the web container startup script)
Implementing the Infrastructure Classes Before implementing the individual test case, we need to implement the infrastructure classes, including the Java configuration class and the base class for service layer testing.
In addition, we also need to implement some classes to support the population of test data in the Excel file.
Moreover, to ease the development of the test case, we want to introduce a custom annotation called @DataSets, which accepts the Excel file name as the argument.
We will develop a custom test execution listener (a feature supported by the Spring testing framework) to check for the existence of the annotation and load the data accordingly.
In the following sections, we will discuss how to implement the various infrastructure classes and the custom listener that loads data from the Excel file.
In testing the service layer, we will implement a custom listener for the newly introduced @DataSets annotation.
The objective is to support the population of test data with a simple annotation on the test case.
First we need to define the custom annotation, which is shown in Listing 19-8
However, in our case, we are interested only in the methods beforeTestMethod() and afterTestMethod(), in which the population and cleanup of the testing data before and after the execution of each test method will be performed.
Note that within each method, Spring will pass in an instance of the TestContext class so the method can access the underlying testing ApplicationContext bootstrapped by the Spring Framework.
First, it will check for the existence of the @DataSets annotation for the test method.
If the annotation exists, the test data will be loaded from the specified Excel file.
The IDatabaseTester interface is provided by DBUnit and supports database operations based on a given database connection or data source.
Second, an instance of the XlsDataFileLoader class was obtained from the TestContext.
The XlsDataFileLoader class is DBUnit’s support of loading data from the Excel file.
It uses the Apache POI library behind the scenes for reading file in Microsoft Office format.
Implementing the Configuration Class Let’s proceed to implement the configuration class for the testing environment.
In Listing 19-10, the ServiceTestConfig class defines the ApplicationContext for service layer testing.
Then the @ComponentScan annotation is applied to instruct Spring to scan the service layer beans that we want to test.
The @Profile annotation specifies that the beans defined in this class belong to the test profile.
Second, within the class, another dataSource bean was declared that executes only the schema.sql script to the H2 database without any data.
Implementing the Base Test Class Listing 19-11 shows the abstract base class for service layer testing.
Note that in Spring’s testing environment, Spring will roll back the transaction upon execution of each test method so that all database update operations will be rolled back.
To control the rollback behavior, you can use the @Rollback annotation at the method level.
Finally, within the abstract base class, the EntityManager is autowired, which can then be used within test cases.
Unit Testing Service Layer Having the configuration and infrastructure classes in place, we can implement the unit test for the service layer.
First we need to prepare the testing data in Excel format.
A common practice is to put the file into the same folder as the test case class, with the same name.
As shown in Figure 19-6, the testing data was prepared in a worksheet.
The worksheet’s name is the table’s name, while the first row is the column name within the table.
You can see that we specified the ID column, but no value was provided.
This is because the ID will be populated by the database.
We had only one contact record in the file, so the findAll() method should return one contact.
Listing 19-12 shows the test class with test cases for the two finder methods.
All the finder methods are applied with the @DataSets annotation with the contact test data file in Excel.
In addition, the ContactService is autowired into the test case from the ApplicationContext.
Various assert statements are applied in each test case to make sure that the result is as expected.
In our case, we would like to test two scenarios.
One is the normal situation in which a valid contact is saved successfully, and the other is a contact have an error that should cause the correct exception being thrown.
Listing 19-13 shows the code snippet for the two test cases.
In Listing 19-13, take a look at the testAddContact() method.
Within the method, to ensure that no data exists in the CONTACT table, we call the convenient method deleteFromTables() provided by the.
Run the test class again and verify the result in the JUnit view.
Note that we covered only the most commonly used classes within Spring’s testing framework.
Spring’s testing framework provides a lot of support classes and annotations that allow us to apply fine control during the execution of the test case life cycle.
For a more detailed description of the various aspects of Spring’s testing framework, kindly refer to Spring’s reference documentation.
Implementing a Frontend Unit Test Another testing area of particular interest is testing the frontend behavior as a whole, upon the deployment of the web application to a web container like Apache Tomcat.
The main reason is that even though we test every layer within the application, we still need to make sure that the views behave correctly with different actions from users.
Automating frontend testing is very important in saving time for developers and users when repeating the actions on the frontend for a test case.
However, developing a test case for a frontend is a challenging task, especially for those web applications with a lot of interactive, rich, and Ajax-based components.
In the following sections, we will discuss implementing frontend unit testing with Selenium (http://seleniumhq.org), a popular open source framework for automated frontend testing.
Adding Required Dependencies To use Selenium, we need to add the dependency into our project, as shown in Table 19-4
Introducing Selenium Selenium is a powerful and comprehensive tool and framework target for automating web-based frontend testing.
The main feature is that by using Selenium, we can “drive” the browsers, simulating user interactions with the application, and perform verification of the view status.
Selenium is also designed with Ajax and rich Internet applications (RIAs) in mind, making automated testing of modern web applications possible.
In case your application has a lot of frontend user interfaces and needs to run a large number of frontend tests, the selenium-server module provides built-in grid functionality that supports the execution of frontend tests among a group of computers.
The Selenium IDE is a Firefox plug-in that can help “record” the user interactions with the web application.
It also supports replay and exports the scripts into various formats that can help simplify the development of test cases.
Starting from version 2.0, Selenium integrates the WebDriver API, which addresses a number of limitations and provides an alternative, and simpler, programming interface.
The result is a comprehensive object-oriented API that provides additional support for a larger number of browsers along with improved support for modern advanced web application testing problems.
In this sample, we will use Selenium with its WebDriver API support to implement the frontend test cases for the contact application.
Implementing a Test Case for a Frontend UI For the frontend testing, we would like to develop the test case for the add contact interface.
Both a normal scenario (i.e., a user enters information correctly and the contact is saved successfully) and an exceptional case (i.e., a validation error occurs, and the messages are displayed) will be implemented.
Implementing the simple test case in Selenium is pretty easy.
In Listing 19-14, the class extends the SeleneseTestBase class, which provides many handy methods to ease the implementation of a test case.
In the setup() method, an instance of the WebDriver interface is prepared, with the FirefoxDriver class, which will invoke the Firefox browser installed on the testing machine for test case execution.
Drivers also exist for Chrome, IE, HtmlUnit, and so on.
If your web application needs cross-browser support, you can run the same test again with different web drivers to ensure the application behaves consistently across different browsers.
Next, take a look at the loginAs() and logout() methods, which will be reused by multiple test cases for login and logout actions.
In the form, the elements should have the correct names assigned.
For example, take a look at the login form in the view file menu.jspx in Listing 19-15
The form fields with names assigned are highlighted in bold.
The testAddContact() method is the test case for a normal add contact operation.
After login, the new contact URL is called (using the open() method), and then the contact information is entered, and the Save button is clicked.
Afterward, the verifyTrue() method is called to verify that the add operation completed successfully with the contact information present on the page.
As a result, the save operation should fail, and the verifyTrue() method will be called to verify that the error message is displayed in the page.
To run the test, just right-click the test class and run it as a JUnit test.
Make sure that the web application is deployed and the tc Server is up and running.
Then you will see that the test cases will invoke a copy of Firefox automatically, and the login, contact information input, and verification logic will be executed accordingly.
From this simple example, you can see how Selenium can help automate the user interaction with the web application frontend with cross-browser compatibility.
For more details, please refer to Selenium’s online documentation (http://seleniumhq.org/docs)
Verifying Test Case Code Coverage The test cases that we developed should cover most of the business logic and user interfaces that were developed, which is referred to as code coverage.
In an ideal case, the code coverage percentage should be 100 percent, which means that each line of code written is tested thoroughly.
In Eclipse (which STS is running on), there are a lot of plug-ins that can help you in visualizing the code coverage of the test cases written.
In this section, we will present you with a tool called CodePro Analytix (http://code.google.com/intl/en/javadevtools/codepro/doc/index.html)
Just choose all the components (although in this section, we use only the Code Coverage tool), and click the Next button to install the plug-in.
After the installation is completed and STS has restarted, we can start to measure the code coverage.
First, we need to enable the instrument for code coverage testing.
Right-click the project, select CodePro Tools, and then select Instrument for Code Coverage, as shown in Figure 19-9
Then, run the unit test, and upon completion, CodePro tool will automatically bring up the Code Coverage view with the code coverage result presented.
In the lower part, the Code Coverage view presents you with the code coverage of all the classes.
Since the test class was testing the ContactServiceImpl class, we can click the class and verify the detailed code coverage information on the right side.
Double-click the class, which will open it in the editor area.
In the editor view, the tested code will have a green indicator on the left side, while red indicates that the code was not called during testing.
Consequently, you can visualize how much code your test case has covered and see which methods or lines of code were not tested.
It’s a handy tool to help you increase your code coverage.
Summary In this chapter, we covered how to develop various kinds of unit testing in Spring-based applications with the help of commonly used frameworks, libraries, and tools including JUnit, DBUnit, Mockito, Selenium, and so on.
First, we presented a high-level description of an enterprise testing framework, which shows what tests should be executed in each phase of the application development life cycle.
Second, we developed three types of test, including the logic unit test, integration unit test, and frontend unit test, respectively.
Finally, we discussed how to use the CodePro Analytix tool to measure the code coverage of the test classes.
Testing an enterprise application is a huge topic, and if you want to have a more detailed understanding of the JUnit library, we recommend the book JUnit in Action, Second Edition (Manning, 2010 )
In previous chapters, we covered how the Spring Framework provides a solid framework with DI and AOP to help you develop enterprise Java applications.
We also covered a few other Spring projects (for example, Spring Data JPA, Spring Security, Spring Web Flow, and so on) that can help further enhance the capability of Spring-based applications in specific areas.
As a matter of fact, the massive adoption of the Spring Framework in both open source and enterprise environments has created a huge development ecosystem, which has created a need for extensions to the Spring Framework.
Consequently, on top of the Spring Framework, a lot of other Spring projects targeting more specific application aspects have been developed.
For example, the Spring Social project supports the integration of Spring-based applications with popular social networks like Facebook and Twitter, while the Spring Mobile project aims to simplify the development of mobile web applications.
All Spring projects were designed with the same rationale, that is, to promote best practices in application development (in other words, programming to interfaces, DI, AOP, and so on) and to integrate seamlessly with the Spring Framework’s ApplicationContext environment.
In this chapter, we will present a high-level discussion of a few popular Spring projects that can help you develop Spring-based applications.
Spring Batch: The Spring Batch project (http://static.springsource.org/springbatch) provides a comprehensive framework and standard skeleton for developing batch jobs within Spring-powered applications.
We will provide a high-level overview of the project, as well as demonstrate its usage by developing a simple contact-importing job.
It provides a lightweight messaging-based platform for implementing many typical enterprise integration patterns (EIPs)
In this chapter, we will briefly describe this project and demonstrate how the Spring Integration and Spring Batch projects can join together to execute batch jobs with a simple EIP.
It’s extremely useful for building application prototypes, and the underlying Java code generated by Spring Roo is fully customizable.
In this chapter, we will give you a taste of what Spring Roo is by using it to generate a simple contact application.
Project for Chapter Samples In this chapter, we will use the backend of the contact web application we implemented in Chapter 18 as the sample and build a batch job for importing contact information in XML format.
Import the Sample Backend in STS The first part of this chapter focuses on integration and batch job development, so we have prepared a project for the sample backend that you can simply import and then proceed to implement the batch job.
Next, in the Import Projects dialog, choose the project extracted from the sample source code, and then click Finish, as shown in Figure 20-2
Introducing Spring Batch Started in 2007, the Spring Batch project has become more and more popular for developing batch jobs in Spring applications.
It’s a collaborative effort between SpringSource and Accenture, and its initial objective was to develop a standard template and framework for implementing and executing various kinds of batch jobs in an enterprise environment.
In version 2, Spring Batch became much more mature as changes were introduced to greatly improve the performance and support of many different kinds of policies (for example, skipping error records, retry, restart, parallel execution, and so on) in batch job execution.
In the following sections, we will look at the fundamental concepts of the Spring Batch project, including the main flow and processing of a batch job, the infrastructure and metadata, and the main execution policies all provided by Spring Batch out of the box.
Batch Job Flow and Process Every enterprise application requires some sort of batch processing that performs business logic on a large set of information.
Although every batch job executes different logic, the high-level flow is similar.
The following is the flow of a typical batch job:
The source can be a file, database, JMS message, web service request, and so on.
This consists of validating, deriving other supporting information, applying business rules, and so on.
The destination can be a file, database, JMS message, web service response, and so on.
Spring Batch provides the execution infrastructure and many out-of-the-box classes that greatly simplify the work of developing a batch job.
In this chapter, we will see how to use Spring Batch to implement a batch job that performs the batch import of contact information in XML format from a file.
This proved to have poor performance when processing a large amount of information.
In this processing, the read -> processing steps are repeated several times as defined by the chunk size.
Every time the chunk size is reached, Spring Batch sends the entire batch of processed information to the write step to perform a bulk update.
This greatly improves the performance when processing a large amount of data.
JobRepository Provides data access operations (CRUD) to the underlying Spring Batch metadata.
Responsible for starting a job execution based on a given job and parameters.
JobOperator (new in version 2) Provides batch job operations (for example, stop a running job, restart a failed or stopped job)
JobExplorer (new in version 2) Retrieves the job execution status information from metadata.
Figure 20-3 shows the high-level overview of the Spring Batch infrastructure components extracted from Spring Batch’s reference documentation.
Spring Batch Metadata Spring Batch maintains all job execution information in its own metadata.
Most likely, the metadata will be maintained in the same database as the enterprise application, although you can choose to have inmemory metadata (however, by using this, you lose the major benefits of Spring Batch, such as restarting a failed job, and so on)
Spring Batch provides DDL scripts for creating the metadata structure in most commonly used RDBMSs.
Table 20-2 describes the category and purpose of each table within Spring Batch’s metadata.
This means that the job together with the job parameters should be unique.
For the contact import job, the name of the job is importContactJob, and the job parameter is the file name.
In this case, for every import contact job, the file name should be unique.
If you try to launch the job with the same file name, Spring Batch will complain that a job instance already exists (because the job parameter was repeated)
A batch job instance can have more than one execution (for example, the first execution was failed, and then was restarted with success in the second execution)
Job Execution Policies Spring Batch supports a lot of different error handling and execution strategies that can fulfill almost any enterprise-level batch job requirements.
Skip failed records It’s possible to instruct Spring Batch to “skip” those problematic records (for example, one record doesn’t pass validation), instead of rejecting the entire chunk of records or file.
Retry on error Spring Batch supports retry policy when error occurs.
For example, an item-processing step can retry a number of times (it may need to invoke some kind of external web service call to validate the data, but under heavy loading, the external service may not respond within a certain time occasionally) before it fails.
Multi-thread Step Processing A step can be configured to run in a multithreaded environment to improve performance.
Parallel processing Steps within a job can configure for parallel execution to further boost the performance.
Step Partitioning Spring Batch provides an SPI that support the partitioning of a step.
In this case, the step is called the master, while the partitioned steps are called the slaves.
The slave steps can be executed either by local threads or remotely for better performance.
Remote chunking In Spring Batch, it’s possible to delegate chunk processing to multiple machines.
For example, the master machine can perform the read process, while multiple slave machines perform chunk-based writing of data (via the ChunkProvider<T> interface)
This provides a very flexible horizontal scaling solution for batch job execution.
Implementing a Batch Job Let’s see Spring Batch in action by implementing a simple batch job.
In the contact application we developed in Chapter 18, each contact contains basic information including the first name, last name, and date of birth.
In addition, each contact associates with zero or more hobbies.
The backend for basic CRUD operations is already available after importing the sample project mentioned earlier in this chapter.
In this section, we will implement a batch job for importing contact information from an XML file into the database.
In the following sections, we will go through the processing of implementing the batch job.
Steps including the required dependencies, batch job configuration, file format, and so on, will be covered.
Adding Required Dependencies First we need to add the dependencies for Spring Batch and Castor into the project, as shown in Table 20-4
Classes that support batch job configuration, job launchers, and so on, are packaged in this module.
For example, classes that support various readers and writers (for example, file, database, and so on) are packaged in this module.
Add the dependencies in Table 20-4 into the project in STS.
First, the schema for creating the metadata tables for storing Spring Batch operational data should be included during the database initialization process.
Listing 20-1 shows the code snippet for the change required for the file.
In Listing 20-1, the change made is highlighted in bold.
There are also existing scripts for most commonly used databases.
At a minimum, the job repository and job launcher beans are required.
By default, a synchronized task executor (the SyncTaskExecutor class) will be instantiated for job launching.
The jobRepository bean will be injected into the jobLauncher bean so that the job execution details can be updated to the underlying Spring Batch metadata storage.
Implementing the Import Contact Job Now we can proceed to implement the batch job.
Listing 20-3 shows the sample XML file with a contact’s information (the contacts.xml file in the project’s root folder)
The root tag is the <contacts> tag, which can accommodate more contact information for import into the database.
We will use Castor to map the XML to the POJO.
If you followed the section “Using RESTful-WS in Spring” in Chapter 16, the mapping definition should be familiar to you.
In addition, the hobbies property of the Contact class, which is a Set of Hobby object, is also mapped.
Since we use JodaTime’s DateTime type for the date of birth property, we need to implement the custom handler, which is shown in Listing 20-5
The custom field handler is basically the same as the one we implemented in Chapter 16, for supporting the RESTful-WS in XML format.
Next is the ApplicationContext configuration, which includes the import contact job.
In Listing 20-6, the batch-namespace is declared to facilitate the job definition.
The batchMarshaller is declared for Castor to perform marshaling and unmarshalling between POJO and XML.
In the job definition, only one step is defined, which contains one tasklet and chunk process.
For the resource property, the job parameter named inputFile (which is the name of the input file) is passed.
The unmarshaller property specifies the XML unmarshaller to use, which in our case is the Castor’s batchMarshaller bean.
In the configuration, you can see the save() method of the contactService bean is used.
You can see how Spring Batch can be seamlessly integrated with the existing ApplicationContext.
In STS, the Spring Config Editor also provides a graphical view of the batch job configuration.
To see it, make sure you open the app-context.xml file with the Spring Config Editor, and click the tab batchgraph in the editor view.
Figure 20-5 shows the tab for the import contacts job.
Within the validate() method, the item, which is of the Contact type, will be passed into the bean to perform validation.
Note that in Listing 20-6, in the importContactsJob bean, a job listener is provided too.
The job listener is a powerful feature provided by Spring Batch so that custom logic can be execute in every phase of the batch job processing life cycle.
Note that the JobExecution class is also passed into the listener so that all job execution information is available for processing.
In Listing 20-9, the job launcher bean and the import contact job beans are obtained from ApplicationContext.
Finally, the batch job is launched with the job and job parameters.
Before running the class, put a copy of the contacts.xml file into the folder C:/temp, as indicated in the job parameter.
Upon running the class, the following output will be logged to the console output (the other, irrelevant output was omitted):
The testing data file (in test-data.sql) contains two contact records, and from the output, you can see that the contact (with id = 3) in the XML file was imported successfully.
Spring Batch provides a solid foundation that can help fulfill complex batch job requirements.
For more details, we recommend the book Pro Spring Batch (Apress, 2011)
Using Spring Batch with Spring Integration While Spring Batch provides a sophisticated batch job execution environment, Spring Integration provides an excellent integration environment for enterprise applications.
With Spring Integration, information exchange with external systems becomes much easier, no matter where the information comes from or needs to be sent to.
Out-of-the-box support for file, e-mail, and JMS-based integration is provided.
Even if your initial batch job execution requirements are very simple, we still recommend that you set up Spring Batch to integrate with Spring Integration to ensure that the application execution environment is flexible enough to cater to more complicated integration requirements in the future.
In the following sections, we will demonstrate how Spring Batch can work with Spring Integration to implement a file polling mechanism so that when a file arrives in a folder, Spring Integration will launch the import contact job automatically.
Channel: Spring Integration is a message-based integration framework, and a channel is the placeholder for messages.
Channels are the glue for linking up the various message producers and consumers within an application.
Message endpoint: In Spring Integration, message endpoint comes in the form of adapters, which connect application components to various channels.
Transformer: As the name implies, a transformer connects different channels and performs the necessary message transformation.
Service activator: In Spring Integration, the service activator is an endpoint that invokes the business process of an application by passing in the appropriate message.
Figure 20-6 provides a graphical view of how the components in Spring Integration and Spring Batch work together to launch the import contact job by using a file polling mechanism.
In Figure 20-6, at the top three channels are defined for storing message, namely, files, requests, and statuses.
First, the inbound channel adapter from Spring Integration’s file support is used for file polling.
When a file arrives, a file message will be created and stored in the files channel.
Second, the transformer will pick up the message from the files channel, perform the transformation (in this case, the file message will be transformed into a job launch request message), and output the transformed message into the requests channel.
The service activator picks up the job launch request message from the requests channel and launches the job accordingly.
The result of the job execution will be output into the statuses channel.
For example, the classes for supporting job launching from Spring Integration are packaged into this library.
Add the dependencies in Table 20-5 into the project in STS.
Listing 20-10 shows the changes that need to be made to the file.
In Listing 20-10, the required changes are highlighted in bold.
First, the integration namespace and file namespace are declared, which belongs to Spring Integration’s components.
The directory attribute defines the input folder, and the channel attribute defines the channel the message should be output to.
The job (indicates the batch job to launch) and fileParameterName (indicates the name of the job parameter for the input file) properties are injected.
Within the method, the passed-in File message is transformed into an instance of the JobLaunchRequest class and returned, which will then be output to the requests channel.
To see it, in the Spring Config Editor’s view, click the tab integration-graph.
In Listing 20-12, we just need to bootstrap the ApplicationContext and then keep looping.
Spring Integration will perform file polling within the C:/temp/contact folder, which is defined in the inbound channel adapter bean.
To test it, put the file contacts.xml into the C:/temp/contact folder, and from the STS console output, you should see that the job will be launched automatically.
Some sample output is shown here (the irrelevant output was omitted)
In the output, you can see that the message was created, the job was launched, and the import contact job completed successfully.
Spring Batch plus Spring Integration provides a powerful batch job execution and enterprise integration environment that integrates with Spring application’s service layer for consistent business logic execution seamlessly.
For more details on Spring Integration, we recommend the book Pro Spring Integration (Apress, 2011)
Spring Roo provides a next-generation rapid application development platform that greatly enhances the productivity of developers of Spring-based applications.
Spring Roo provides an innovative command-line interface with useful hints that can help you define a Domain Object Model (DOM), persistence layer, service layer, and presentation layer quickly.
With Spring Roo, you have the option to have the persistence logic built into the JPA entity classes, or you can instruct Roo to generate a service layer to host your business logic.
On the presentation layer, Roo provides first-class support for Spring MVC and can generate a basic user interface automatically with templating support (with Apache Tiles), theming, i18n, validation, and.
You can also instruct Roo to generate the presentation layer using Spring Web Flow.
For the view side, in version 1.2.0, when using Spring MVC, Roo will generate views in JSPX pages.
Roo also supports the implementation of extensions via its add-on architecture.
At the time of writing, there are many add-ons already (although some of the add-ons are still in the early development stage), including add-ons for GWT, Vaadin, Adobe Flex, jQuery, and so on.
Add-ons that support other Spring projects, including Spring Security, Spring Integration, and so on, are also available.
In STS, there is an option for you to create a Spring Roo project, and a Spring Roo Shell is provided for you in STS too.
If you want to override the default behavior for any layer that was generated by Roo, take back the control on the logic you want to execute, or add your own logic on the classes generated by Roo, you can do so; Roo’s design provides a clean separation of the logic that was generated by Roo and those implemented by developers.
In the following sections, we will present you with a high-level overview of Spring Roo and then see it in action by developing a simple contact application.
However, version 1.2.0 brings a lot of exciting new features, and we will use it for this section.
So, we need to download and install Spring Roo 1.2.0 and configure STS to use the new version of Spring Roo.
Upon completion, make sure that 1.2.0 is the default version and then click OK button.
Now we are ready to create a Spring Roo project.
Then click Next and Finish, and STS will create the project.
Setting up the persistence layer and the corresponding entity classes that are required for the application is the first step.
In this sample, we will set up the persistence layer using the H2 in-memory database as the backend and using Hibernate as the JPA persistence provider.
To do this, enter the following command at the Roo prompt:
The persistence setup command is to instruct Spring Roo to create the persistence layer for our application.
The options specify the H2 database with Hibernate as the provider.
In Roo Shell, all options are prefix with --, and you can always press Ctrl+spacebar for code assistance and hints.
Press Enter, and then Roo will generate the persistence layer.
Upon completion, in the Package Explorer, you will see the project structure, as shown in Figure 20-12
The next step is to create the Contact entity class.
Configuring the Java build path for the Spring Roo project.
Now when you look at the Package Explorer, you will see only the Contact class, not other AspectJ classes generated by Roo.
The reason is that by default the Package Explorer view will filter out those classes from the view.
To see it, in the Package Explorer view, click the View menu (the triangle symbol), and select Filters, as shown in Figure 20-14
Then you will able to see all the classes in the Package Explorer, as shown in Figure 20-16
The AspectJ classes (*.aj files) that Roo generated are AspectJ intertype declarations (ITD) classes.
These ITDs are the magic behind Spring Roo and store all the logic generated and maintained by Roo.
For example, the ITDs will store the getter/setter methods, common properties for JPA (for example, the ID, version, and so on), the toString() method, and so on.
At this point, when you take a look at the Roo Shell view, you will see that the shell is “focused” on the Contact class, as shown in Figure 20-17
In Roo, focus means that all the subsequent class-level commands will be applied to the class that currently has the focus.
The next step is to define the properties for the Contact class.
We will need to create three properties, namely, firstName, lastName, and birthDate.
To do this, enter the following commands one by one:
In the above commands, the field command is used to define the fields for the Contact class.
Because we already focusing on the Contact class, we don’t need to provide the class name.
The attribute after the field is the type, and then the field name and the JSR-303 constraints for the fields appear.
After the field properties are generated, the next step is to configure Spring Data JPA repository abstraction for the Contact class.
The previous command instructs Roo to generate the JPA repository interface that uses Spring Data JPA.
Set Up the Service Layer Starting with version 1.2.0, Roo added support for generating service-layer classes.
To see this in action, let’s create the ContactService interface like we did in previous chapters.
To do this, enter the following command at the Roo prompt:
The service command is used to instruct Roo to create the ContactService interface, which will be used to manipulate the Contact entity class.
Upon completion, in the Package Explorer, you will see that besides the interface class, Roo also generates the implementation class ContactServiceImpl.
At this point, a backend for the Contact entity class with basic CRUD operations support is created.
First we need to instruct Roo to set up Spring MVC for the application.
The next step is to generate the controller class and view files for the Contact entity class.
To do this, enter the following command at the Roo prompt:
The command simply instructs Roo to generate scaffold Spring MVC controllers for all entities in the project without an existing controller class.
Roo with then generate the controller class for the Contact entity, as well as the JSPX view files for maintaining contact information.
Now a basic application is generated, and after building and deploying to the tc Server in STS, start the server, and enter the URL http://localhost:8080/ch20-roo in the browser.
The application will be displayed, as shown in Figure 20-18
Click the link Create new Contact to create a new contact, and you will see the form shown in Figure 20-19
Note that the date field already has the date picker enabled.
If you view the page source, you will notice that the generated view has the Dojo Toolkit JavaScript library included.
The JSPX view with the Dojo Toolkit is the default that Roo will generate for a web application’s frontend.
After the new contact is saved, click the List all Contacts link, and you will see the added contact, as shown in Figure 20-20
In Figure 20-20, you will see that the buttons for viewing, editing, and deleting the contact (the three buttons to the right of the contact) are already provided in the data table.
In the footer, you can also see that support for theming and i18n are already there, too.
The Push In Intertype Declaration dialog will be displayed, with all the methods generated by Roo.
You can choose to “push in” only some of the methods (by expanding the class node and selecting the methods you want to push in) or all methods at once, as shown in Figure 20-22
Upon push in, the logic will be extracted into the ContactController class.
You can then take a look at the ContactController class and the methods that were pushed in.
All the Roo commands that you entered will be stored in the file called log.roo (located in the project’s root folder), so you can use it as the script for creating similar projects.
It’s a very convenient feature; Figure 20-23 shows the log.roo file for the contact application that we generated.
Spring Roo Add-on Another powerful feature of Spring Roo is the add-on architecture, which allows you to create custom add-ons to Roo to fulfill your specific needs.
There are a lot of add-ons already available; some were.
From the Roo Shell, you can list, search, or install add-ons.
At the Roo prompt, type addon, and then press Ctrl+spacebar; you will see the available commands relating to add-ons, as shown in Figure 20-24
For example, the addon list command lists the add-ons currently available for install and use in your Roo application.
Figure 20-25 shows the output of the addon list command.
In the figure, you can see the available add-ons and their descriptions.
For example, you can see that the add-on with ID 44 enables you to develop RIAs in Spring Roo with Vaadin, which is a popular frontend library built on top of GWT.
Conclusion on Spring Roo With the previous sample, you got a little taste of how Roo can help provide a rapid development environment.
The Roo project is still evolving quickly, and many add-ons are being developed.
The Roo project has great potential, so it is worth keeping an eye on its development.
Even though you may find it not good enough to have it generate your JEE application for production use, it is still very useful for generating application prototypes during the initial design phase.
Also, the folder structure and classes that Roo generates are based on industry best practices, and the code style, context configuration, and so on, are all based on the SpringSource team’s recommendations.
It’s also worth taking a look at the application that Roo generates for you and using it as a learning tool to understand the best practices and coding style for Spring-based applications.
If you are interested in learning more about Spring Roo, please refer to the reference documentation (http://static.springsource.org/spring-roo/reference/html/index.html) and the book Spring Roo in Action (Manning, 2012)
Spring Batch and Spring Integration in the Sample Application In the SpringBlog application, we will adopt Spring Batch and Spring Integration to implement the job of importing blog posting entries from an XML file.
The mechanism discussed in this chapter will be used in developing the batch job.
First, the XML file format for blog posting will be defined, together with the corresponding Castor mapping definitions.
Second, Spring Integration’s file polling support will be used for scanning the arrival of a file containing new blog postings.
When a new file arrives, the inbound channel adapter will pick up the file, and then the file message will be output to the file’s channel.
The same transformer developed in this chapter will be used to transform the file message into the job launch request message, and outputting it to the requests channel.
A batch job will be implemented for importing the blog posting entries, which use the same service layer to perform write processing.
The service activator will be used to launch the job.
Summary In this chapter, we covered several interesting and useful Spring projects that can help us fulfill common application requirements.
First, we discussed the Spring Batch project and its chunk-based processing architecture and saw it in action by implementing a contact import job.
Then, we demonstrated how Spring Integration can help perform message-based integration, its support for file-related operations, and how it works with Spring Batch for job launching.
Finally, we discussed the interesting Spring Roo project for rapid application development and prototyping.
We discussed its innovative command-line support for code generation of various application layers, flexibility in taking back the control from the generated code, and the add-on architecture that allows the addition of your preferred tools and libraries.
In Chapter 3, we presented you with an architectural overview of the sample application for this book, including the layered application architecture, main features, and screenshots of the completed application.
Then, in Chapter 12, we discussed a few main topics with regard to designing and implementing Spring applications, with some reference to the sample application, too.
As we have gone through each chapter, we covered the main relationships between the features and discussed their adoption in the sample application.
In this chapter, we will discuss the details of the sample application, called SpringBlog, that was developed for this book.
The objective is to elaborate on the details of the application design and explain the implementation of the main features that were discussed within each relevant chapter, including how they work together in a complete JEE application.
Specifically, in this chapter, we will look at the following:
Project setup: We will discuss how to set up the project and STS so that you can build and get the sample application up and running on your machine.
Application design: We will discuss the main design elements of the application.
The data model, domain object model, and UML model of the major use cases will be covered.
Implementation details: We will discuss how the main features of the sample application are implemented in detail.
Topics include using AOP for the obscenity filter, creating a service layer using Hibernate and JPA 2, implementing validation with conversion and formatting, creating the frontend, using RESTful-WS, creating batch jobs, scheduling a job for purging audit data, and so on.
Although all the SpringBlog features mentioned in the book have been incorporated into the implemented source code, some of those features are still under development as the book goes to print (for example, using the MyBatis implementation to handle comment posts, file uploads, and so on)
We will update the sample application’s source code periodically to implement these features, and that code will be hosted in a repository on GitHub.
Also, as comments are received from readers, existing features may be enhanced and new features added.
So, kindly check out the source code repository on a regular basis for any changes.
The following are the features within the sample application that are still under development at the time of writing:
MyBatis implementations including entry updates, comment posts, file uploads, and maintaining entity versions.
The scheduled job for purging old history records for blog entries and comments.
Setting Up the Sample Application Let’s get the source code and set up the project in STS.
Then, we’ll set up tc Server and deploy the SpringBlog application to see it in action.
It will be much easier to understand the source code when seeing how it works side by side with the text.
In the following sections, we will discuss how to set up the project in STS and get the SpringBlog application up and running.
Topics include obtaining the source code, importing the project, setting up the server, and switching between different RDBMSs and service layer implementations.
To test the MySQL backend, a local instance of MySQL database with version 5.1 or newer and a basic knowledge of managing a MySQL database (for example, creating a user, running a script, and so on) are assumed.
Project Setup To set up the project, we need to get the source code and import it into STS.
Another option is to check out the latest source code from the SpringBlog repository on GitHub.
Then, on the Import Projects screen, choose the project extracted from the sample source code, and then click Finish (see Figure 21-2)
Then, you may need to wait for a while for the Maven plug-in to download the required dependencies and build the project.
Upon project import completion, define a tc Server instance for deploying the SpringBlog application.
You can also choose to deploy on any existing tc Server instance in your STS.
For detailed steps of creating a tc Server instance, please refer to Appendix A.
Also make sure you add your project to the target tc Server and have the project classes and libraries published to the server (in other words, the project was built and deployed to the target tc Server)
For our case, the “base” template of a tc Server instance is good enough for the sample application.
You should see the initial page of the SpringBlog application, like the one in Figure 21-4
At this point, the project has been set up successfully.
Note that, by default, the sample application doesn’t include any sample blog entries.
Please log in to the application (click the Hint button under the Login button for the default user accounts) and post some blog entries and comments to get some hands-on experience with the application.
However, the database scripts and application also work fine with MySQL.
This section lists the procedure for setting up the application with a MySQL database so that you can keep track of the database records as you play around the application.
Each bean is wrapped under the <beans> tag with a profile attribute provided.
This is the new profile feature introduced in Spring Framework 3.1
So, depending on the active profile setting, Spring will initiate the dataSource bean accordingly.
We need to run three scripts (note that the order is important) for the SpringBlog application:
To set up MySQL, as shown in the dataSource bean definition for the mysql profile, in MySQL, set up a database called springblog and then a user with the user name and password both set to springblog (or you can change the datasource settings based on your preference)
Note that the file schema-mysql.sql is for the creation of Spring Batch tables.
In Listing 21-2, there are two profile values for the SpringBlog application.
The first one controls the service layer implementation to use (jpa or mybatis), and the second (in bold) controls the datasource bean to initialize.
To use MySQL, change the second profile value from h2 to mysql.
When the project is rebuilt and deployed to tc Server, the application will run against the MySQL database.
Switching Between the JPA and MyBatis Implementations As shown in the previous section, for the service layer, changing from an JPA 2 implementation to an MyBatis implementation is easy too.
You just need to change the first profile value from jpa to mybatis.
As mentioned in Chapter 5, one other method to set the active profile is using the launch configuration of tc Server.
This will eliminate the need of modifying the web.xml file and repackaging the web application archive file.
To change the launch configuration, in STS’s Servers view, double-click the tc Server that the SpringBlog application is running on, and click the link “Open launch configuration,” as shown in Figure 21-5
After changing the VM argument of the tc Server, the corresponding parameter can be removed from the web.xml file, and you can try the different combinations of service layer and backend RDBMS by simply changing the VM argument of the launch configuration of the tc Server.
Application Design This section gives you an overview on the application design details.
In the following sections, the various design aspects, including the data model, domain object model, UML model for major use cases, and so on, will be covered.
Note that the schema for Spring Batch is not shown in Figure 21-7
APP_USER This table stores the user information for security control with Spring Security.
Users will be authenticated with the information in this table.
USER_ROLE_DETAIL This is the join table that stores the roles granted to each user.
A category can be a subcategory, and in this case, the column PARENT_CATEGORY_ID indicates the parent category.
Domain Object Model Now let’s proceed to the domain object model.
As discussed in Chapter 12, the DOM is an objectbased representation of the application problem domain.
In SpringBlog, the domain is the information related to blog posts.
The DOM is closely related to the data model, and in JEE applications, no matter whether you are using ORM or data mapping technology, there will be a “mapping” process in transforming the data model into Java’s DOM.
However, you will not see a table for the abstract class.
The relationship between the AppUser and Role classes is many-to-many, because an user can be granted multiple roles, and a role can be assigned to many users.
From the data model, you will see a join table (USER_ROLE_DETAIL) that holds the relationship.
While in the DOM, you will not see a class for the join table.
The Category class has a self-referencing relationship to itself to indicate the hierarchy of the parent and subcategories.
The UML Model The UML model contains various diagrams that reflect the behavior of the classes within the application.
There are two main types of UML diagrams, namely, static and dynamic diagrams.
Examples of static diagrams include use case diagrams and class diagrams.
Dynamic diagrams indicate how the classes collaborate and interact with each other to complete a business flow.
Examples include sequence diagrams, activity diagrams, collaboration diagrams, state diagrams, and so on.
In this section, we will focus on using sequence diagrams to reflect the flow and the interaction between the classes in the various application layers.
In the following sections, we will discuss the sequence diagrams of three main use cases within the SpringBlog application, including creating a blog post entry, using RESTful-WS, and creating batch jobs.
Create Blog Post Entry Let’s take a look on the sequence diagram for creating a blog post entry, which is shown in Figure 21-9
In Figure 21-9, the sequence diagram shows the flow of the process of creating a blog post entry, as well as the interactions between the main classes within each layer, from the presentation layer down to the persistence layer.
In this case, the JPA 2 implementation is used, and the flow is as follows:
The user logs into the SpringBlog application, creates a new entry, enters the information, and clicks the Save button.
The browser will then submit a POST request to the server.
Spring MVC’s DispatcherServlet receives the request, analyzes the details of the HTTP request, and identifies the controller method to invoke.
At the same time, binding for the request data into the corresponding domain object will be performed.
If an error occurs, a message will be saved into the Model instance, and the edit page will be redisplayed with the error messages.
At the same time, a before advice will be applied (we will see the details later) to check for obscenities in the blog post.
The EntryServiceImpl class will persist the blog post entry by invoking the persistence provider.
After the saving operation succeeds, the controller will return the logical view (in this case in the show blog page)
The DispatchServlet will pass the logical view name to the ViewResolver.
The ViewResolver will resolve the corresponding view (based on the configuration) for displaying the frontend to the user.
Remember that for simplicity, the interactions with some of the components were skipped.
RESTful-WS for RSS Feed of Blog Post Entries The second use case is the RSS feed that outputs the blog post entries in either XML or JSON format to the HTTP remote clients.
Before we discuss the diagram, let’s take a look at how the feed works first.
To retrieve the RSS feed in XML format, submit the curl command in Listing 21-3 with the SpringBlog application up and running.
In Listing 21-3, the user name for remote access to SpringBlog’s RESTful-WS is provided, together with the URL for the RSS feed.
The request header is set to accept XML as the supported format.
Listing 21-4 shows the command for requesting data in JSON format.
The only difference with the previous command is that the supported media of the request header is set to JSON format.
Now let’s see how RESTful-WS for the RSS feed works.
Figure 21-12 shows the sequence diagram of the RESTful-WS feed in action.
For the backend service interaction, the sequence diagram works the same as the use case for creating a blog post entry, as shown in Figure 21-9
In turn, the controller will invoke the service layer to retrieve the list of blog post entries.
Then, the resulting Entries class (which includes the listing Entry domain objects) will be returned by the controller.
The result will be directly written to the response body.
The Batch Job for Importing Blog Posts from an XML File Another use case is the batch import of blog post entries from XML files.
Listing 21-5 shows the content of entries.xml with a single blog post entry.
Then, when you visit the application frontend, you will notice that the entry was imported into SpringBlog, as shown in Figure 21-13
The entire job import process is composed of two main parts, namely, job launching and job execution.
Figure 21-14 shows the sequence diagram of the job launching process.
The main flow of the job launching process is as follows:
Spring Integration’s inbound channel adapter polls the file for new entries.
Upon the arrival of a file, the transformer will transform the information into a job launch request message.
Spring Integration’s service activator receives the job launch request message and passes it to the corresponding message handler.
The message handler will run the job with the transformed job parameters.
The next phase is job execution, which is shown in Figure 21-15
As you can see from Figure 21-15, Spring Batch will process each item on a chunk basis, which includes the following steps:
Read in each item, and invoke Castor’s marshaler to unmarshal the XML fragment into the corresponding Entry object.
The Entry object is then passed to the item processor, which will perform JSR303 Beans Validation on the Entry object.
After the items within a chunk are processed, the writer will be invoked to write the processed entries.
Configuration Details Having discussed the design details, let’s proceed to the configuration of the SpringBlog application.
The Web Deployment Descriptor Configuration Let’s take a look on the web deployment descriptor (web.xml), which is shown in Listing 21-6
The filters are used by Spring Security and Spring MVC for processing incoming requests.
The blogAppServlet servlet defines the configuration for the web frontend, while the restful servlet is for the RESTful-WS configuration.
The file names and purposes are listed in Table 21-2
Role-based access rules to all protected resources (including web frontend and RESTful-WS) are defined here.
Used for the batch job for importing blog post entries from XML files.
For example, only the Spring beans for the JPA implementation will be scanned.
For example, only the Spring beans for the MyBatis implementation will be scanned.
You can find detailed descriptions of each configuration file by referring to the corresponding chapters.
To enable this support, we need to enable load-time weaving (LTW) support of the Spring Framework for AspectJ in the web container environment.
Because we will use tc Server for running the SpringBlog application, this section will cover the procedure for setting up LTW support for an application in tc Server.
In SpringBlog, the setting is defined in the root-context.xml file, which is shown in Listing 21-7
In Listing 21-7, the LTW-related configuration is highlighted in bold.
Then, we need to copy the Spring Framework’s instrument support of the Tomcat class loader to the web container’s library folder.
Obtain the library and copy it to the lib folder of the Tomcat server.
One bit of good news for STS users is that for tc Server, the library will be there as you create new tc Server instances.
Figure 21-17 shows the folder for the tc Server instance called springblog, which was created for deploying the sample application.
Next, we need to provide information to Tomcat about the LTW mechanism we will use in the SpringBlog application.
We can either do it in the tc Server’s configuration or create related configuration files within the SpringBlog project.
In the sample application, we created the related configuration files in the project so that we don’t need to modify the server’s configuration.
In Listing 21-9, the aop.xml file defines the LTW configuration for AspectJ.
First, we provide the package under which Spring’s AspectJ support should weave the classes.
For the coding side, we will discuss the implementation of the obscenity filter in detail in a later section.
Implementation Details Having discussed the design and configuration details, let’s proceed to the implementation details.
Since the code base is quite large, it’s not possible to cover all the classes in detail.
So, in the following sections, we will focus the discussion on the major implementation classes and a high-level overview of each layer.
Topics include implementing the service layer, implementing AOP, scheduling jobs, implementing the presentation layer, and so on.
The details of the respective implementations will be covered in the following sections.
In this section, we will focus the discussion on the services related to blog post entry.
In Listing 21-10, various finder methods, some with pagination support, and the data update (including insert, update, and delete operations) are defined.
To keep the discussion simple, we will focus on the implementation of the save() method, which is highlighted in bold.
If you haven’t read the chapter, it’s time to take a look at it to understand the design of the domain object model.
In addition, Spring Data JPA’s repository abstraction will be used to simplify the development of persistence logic.
Spring Data JPA’s repository abstraction will be used for persistence logic, so we need to implement the repository interface for the Entry object.
Listing 21-12 shows the code snippet for the implementation of the save() method.
The save() method will be used for both insert and update operations, and first, the id property will be checked.
If it’s null, then it’s a new object, and the postDate property will be set as the current date.
MyBatis Service Implementation For the MyBatis implementation of the service layer, the SQL mapping XML configuration will be used to define the mapping between SQL and the DOM.
The insertEntry mapping constructs the SQL INSERT statement based on the provided Entry object, the attribute useGeneratedKeys instructs MyBatis to use the key generated by the backend RDBMS (H2 or MySQL), and the keyProperty attribute indicates the property for the primary key column.
Listing 21-14 shows the code snippet for the implementation of the save() method.
Then, in the save() method, the id property will be checked for whether it’s a new object.
If it’s a new object, the insertEntry() method will be invoked, and MyBatis will use the mapping definition with an ID of insertEntry to construct the INSERT statement.
As a result, the MyBatis plug-in feature is used to implement the logic to update the fields accordingly before the insert operation.
Listing 21-15 shows the MyBatis plug-in class for updating basic audit information.
The nested @Signature annotation defines the class, method, and argument that we want to intercept.
The main logic for updating the audit properties of the domain object is in the plugin() method.
If that’s the case, we will check whether the domain object contains auditable properties by checking whether the class is assignable to the Spring Data Commons Auditable interface, since all domain objects with those auditing properties implement that interface.
If all the conditions match, then the audit fields will be updated accordingly before MyBatis performs the mapping operation.
As you saw, the MyBatis plug-in system is the trick for intercepting various mapping operations for custom logic.
Obscenity Filter Using AOP In SpringBlog, the obscenity filter is the main feature to showcase the usage of Spring AOP in implementing cross-cutting concerns in an application.
In this section, we will look into the details of its implementation.
For Spring configuration and the corresponding setup in tc Server, please refer to the section “The AspectJ Load-Time Weaving Configuration” in this chapter.
Listing 21-16 shows the ObscenityFilter interface, which defines the methods for the obscenity filter feature.
Listing 21-17 shows the implementation class of the ObscenityFilter interface.
Finally is the advice class, which is a before advice that will perform the filtering for all operations within the service layer with an argument that can be assigned to the BlogPosting interface.
In Listing 21-18, several annotations are applied at the class level.
Finally, the AspectJ’s @Aspect annotation indicates to Spring that it’s an AOP advice and will trigger Spring’s support of AspectJ’s annotation style.
Within the method, the arguments will be checked to see whether they are assignable to the BlogPosting interface.
If that’s the case, then the argument should be either the Entry or Comment object, and the obscenity filter logic will be applied.
To see it in action, you can post a new entry that contains the word crap in either the subject or body field.
Then after you save the entry, you will notice that the word has been translated into penc, which is the result of the ROT13 algorithm.
Scheduling the Job for Purging Audit Data Another feature that we demonstrated in the SpringBlog application is job scheduling, by which we use it to implement a daily job to purge the audit history data for Entry and Comment objects that are older than 30 days.
In this section, we will see the implementation in detail.
As you already saw in Chapter 15, task scheduling in Spring is very easy, and in SpringBlog, we use the annotation style for scheduling the audit data purging job.
Listing 21-19 shows the code snippet in the root-context.xml file that enables annotation-style scheduling support.
Only one auditPurgeJob() method is defined, which contains the logic to purge the old audit history data.
The auditPurgeJob() is applied with the @Scheduled annotation to indicate to Spring that it’s a scheduled task.
The cron expression was used, which means that the job will run every day at midnight.
We leave the logic empty here, but you can imagine it’s very easy to implement.
Presentation Layer For the presentation layer of the SpringBlog application, basically most of the topics discussed in Chapter 17 are applied here.
Spring MVC will be used for implementing the Model View Controller pattern for the presentation layer, with JSPX as the view technology.
Spring MVC support for i18n, theming, and RESTful-WS (for Ajax-style interaction with jQuery) will be used throughout the presentation layer.
Apache Tiles will be used as the page templating technology.
Also, Spring’s integration with Apache Tiles will be used for resolving the view to display based on the logical view names.
For the views, jQuery and jQuery UI will be used to enrich the user interactions.
Moreover, various jQuery plug-ins will be used for specific purposes.
For example, jqGrid will be used for grid-based display of blog entries, with support for page size, pagination, and sorting.
Spring Security will be used for the authentication and authorization of protected resources.
For example, only logged-in users can post new blog entries or comment on existing blog posts, and the administrator can view the audit history of a blog post entry.
In the following sections, we will highlight some of the main implementation details of the SpringBlog presentation layer.
In the following section, the main implementation details of the presentation layer will be provided.
Figure 21-18 shows the folder structure for the SpringBlog application in STS.
The JavaScript resources (including jQuery, jQuery UI, jqGrid, CKEditor, and so on) are stored in the folders scripts, jqgrid, and ckeditor, respectively.
The styles folder stores the CSS files that support theming of SpringBlog, and the images folder stores the images.
The layouts folder stores the page layout template for Apache Tiles.
The views folder stores all the JSPX view files for the frontend.
The views folder stores the template components, such as the header, menu, footer, and so on.
The blogs and comments subfolders store the view files for listing, viewing, adding, and editing blog posts and comment entries, respectively.
Controller Class The controller classes are the central part of the frontend presentation logic.
They handle the requests received from the DispatcherServlet, either from the frontend or from RESTful-WS clients.
Then, the controller classes perform required processing logic based on the request, interact with the service layer, and return the logical view to the DispatcherServlet (or directly write to the response body)
In this section, we will also focus on the EntryController class, which handles the requests with regard to the blog post entries.
Specifically, we will discuss creating a new blog post entry.
Listing 21-22 shows the code snippet for the methods related to creating a new blog post within the EntryController class in the SpringBlog application.
In Listing 21-22, two methods are related to the process of creating a new blog post.
The createForm() method is responsible for creating a new Entry domain object, saving into the Model interface and returning the logical view for displaying the entry update view (defined by the logical view blogs/create)
Note that the method was annotated with @PreAuthorize, which is Spring Security’s support for method-level authorization, since only logged-in users are allowed to create blog posts.
The create() method handles the submission of the form after users enter the blog post entry details.
All constraint violations will be stored in the BindingResult, and if errors are found, a message will be stored into the Model interface and returned to the same view as when editing a blog post entry, with error messages displayed.
Figure 21-19 shows sample validation messages displayed when the user simply clicks the Save button without entering any information.
Type Conversion and Formatting In the SpringBlog application, Spring Framework 3’s new type conversion and formatting system was used for binding, converting, and formatting the data between the frontend views and the controller classes.
After the feature is turned on, Spring will automatically convert between common Java types (for example, int/Integer, long/Long, and so on) to the String representations.
In addition, annotations are provided for defining the desired format.
In this section, we will discuss the use of the @DateTimeFormat annotation for controlling the format for JodaTime’s DateTime type.
In Listing 21-24, the date-time format annotations are highlighted in bold.
This is because for the create date and last modified date, we also want to know the time in addition to the date.
Note that Spring supports the formatting of JodaTime’s DateTime type out of the box.
Figure 21-20 shows the view page of a blog post entry in SpringBlog, and in the figure, you can see the conversion and formatting in action.
In Figure 21-20, the create date and last modified date are shown in the appropriate format.
There are still many other features that were implemented in the SpringBlog application, such as.
However, the implementations were based on Ajax calls between jQuery and the Spring MVC layer, which are basically the same as the implementation of the pagination in the data table using jqGrid; therefore, they are detailed in Chapter 17, and we will skip the discussion here.
Summary In this chapter, we discussed the details of the design and implementation of the sample application for this book, the SpringBlog application.
First, instructions were provided on how to set up the project, as well as switch between different datasources and implementations with Spring Framework 3.1’s support of bean definition profiles.
Second, we elaborated on the design of the SpringBlog application.
Topics included the data model, domain object model, and UML model of the main use cases within the application.
Finally, the detailed implementation of the main features that showcase the Spring Framework’s powerful features were discussed.
The implementation of the service layer, AOP for obscenity filtering, task scheduling, and the presentation layer were discussed in detail.
In previous chapters, we saw how the Spring Framework can help Java developers create JEE applications.
By using the Spring Framework’s DI mechanism and its integration with each layer (via libraries within the Spring Framework’s own modules or via integration with third-party libraries), you can simplify implementing and maintaining business logic.
However, all the logic we have developed so far was with the Java language.
Although one of the most successful programming languages in history, Java is still criticized for some weaknesses, such as its language structure or its lack of comprehensive support in areas like massive parallel processing.
For example, one feature of the Java language is that all variables are statically typed.
In other words, in a Java program, each variable declared should have a static type associated with it (in other words, String, int, Object, ArrayList, and so on)
However, in some scenarios, dynamic typing may be preferred, which is supported by dynamic languages like JavaScript.
To address those requirements, many scripting languages have been developed.
Almost all of those languages support dynamic typing and were designed to provide the features that are not available in Java, as well as targeting specific purposes.
In addition, Groovy (http://groovy.codehaus.org) provides a simplified programming model and supports the implementation of domain-specific languages (DSLs) that make the application code easier to read and maintain.
One other important concept that those scripting languages bring to Java developers is closures (which we will discuss in more detail later in this chapter)
Simply speaking, a closure is a piece (or block) of code wrapped in an object.
It’s executable like a Java method and can receive parameters and return objects and values.
In addition, it’s also a normal object that can be passed with a reference around your application, like any POJO in Java.
In this chapter, we will discuss some main concepts behind scripting languages, with the main focus on Groovy; you’ll see how the Spring Framework can work with scripting language seamlessly to provide specific functionality to Spring-based applications.
We will provide an overview of scripting support in Java.
Groovy: We will provide a high-level introduction to the Groovy language, which is one of the most popular scripting languages being used with Java, specifically using the Spring Framework.
As of version 3.1, out-of-the-box support for Groovy, JRuby, and BeanShell is provided.
In this chapter, we will discuss how to use Groovy with Spring to implement a simple rule engine based on the DSL supported by Groovy.
This chapter is not intended to serve as a detailed reference on using scripting languages.
Each language in books of their own that discuss their design and usage in detail.
The main objective of this chapter is to give you an idea how the Spring Framework supports scripting languages, with a sound example on what the benefit are of using a scripting language in addition to Java in a Spring-based application.
Project for Chapter Samples We will use a simple Spring utility project as our starting point for the samples that will be developed in this chapter.
For using Groovy, an additional procedure is required to install the Groovy plug-in for Eclipse; the steps are detailed in the following sections.
Then, enter the project information, as shown in Figure 22-2
Installing the Groovy Plug-in for Eclipse Groovy provides an Eclipse plug-in that can help manage the development of a project using pure Groovy or Java projects with Groovy classes.
However, by default, the plug-in is not bundled with STS, so we need to install it.
To install the plug-in, in STS, open the Spring dashboard (by clicking the Spring Dashboard menu icon in the Spring perspective)
In the dashboard view, click the tab Extensions, and select Groovy Eclipse.
Then click the Install button, as shown in Figure 22-3
Select all the items and click the Next button to install, as shown in Figure 22-4
After the installation completes and you restart STS, right-click the project in STS, and add the Groovy Project nature to the project, as shown in Figure 22-5
However, we still need to add the relevant Maven dependencies so that the project can be built from Maven.
We will let you know when dependencies need to be added.
Its objective is to provide a standard mechanism for running logic written in other scripting languages on the JVM.
Out of the box, JDK 6 comes bundled with the engine called Mozilla Rhino, which is able to evaluate JavaScript programs.
In JDK 6, the scripting support classes reside in the package javax.script.
First let’s develop a simple program to retrieve the list of script engines.
Running the program will produce the following output in the console:
As shown in the output, two script engines are detected.
The first one is the Groovy engine, since we converted the project to a Groovy project and added the Groovy libraries.
Let’s write a simple program to evaluate a basic JavaScript expression.
Note that the argument can also be a java.io.Reader class, which can read JavaScript from a file.
This should give you an idea of how to run scripts in Java.
However, it’s not of much interest to just dump some output using another language.
In the next section, we will introduce Groovy, a powerful and comprehensive scripting language.
Introducing Groovy Started by James Strachan in 2003, the main objective of Groovy is to provide an agile and dynamic language for the JVM, with features inspired from other popular scripting languages including Python, Ruby, and Smalltalk.
Groovy is built on top of Java, extends Java, and addresses some of the shortcomings in Java.
In the following sections, we will discuss some main features and concepts behind Groovy and how it supplements Java to address specific application needs.
Note that many features mentioned here also are available in other scripting languages (for example, Scala, Erlang, Python, and Clojure)
Dynamic Typing One main difference between Groovy (and many other scripting languages) and Java is the support of dynamic typing of variables.
In Java, all properties and variables should be statically typed.
In other words, the type should be provided with the declare statement.
In Groovy, dynamic typing variables are declared with the keyword def.
Contact contact = new Contact(firstName: 'Clarence', lastName: 'Ho', birthDate: new Date()) Contact anotherContact = new Contact(firstName: 20, lastName: 'Ho', birthDate: new Date())
Listing 22-3 shows a Groovy script, which can be run directly from within STS (right-click the file and choose Run As, and then choose either Groovy Script or Java Application)
The main difference is that a Groovy script can be executed without compilation (Groovy provides a command-line tool called groovy that can execute Groovy scripts directly) or can be compiled to Java bytecode and then executed just like other Java classes.
Also, a class declaration that matches the file name is not required.
In Listing 22-3, a class Contact is defined, with the properties set to dynamic typing with the def keyword.
Then, the toString() method is overridden with a closure that returns a string.
Then, two instances of the Contact object are constructed, with shorthand syntax provided by Groovy to define the properties.
For the first Contact object, the firstName attribute is supplied with a String, while an integer is provided for the second Contact object.
Note that in Groovy, when passing an argument to a method, the parentheses are optional.
From the output, you can see that since the firstName is defined with dynamic typing, the object constructs successfully when passing in either a String or an integer as the type.
In addition, in the last two println statements, the add operation was correctly applied to the firstName property of both objects.
In the first scenario, since firstName is a String, the string 20 is appended to it.
Dynamic typing support of Groovy provides greater flexibility for manipulating class properties and variables in application logic.
Simplified Syntax Groovy also provides simplified syntax so that the same logic in Java can be implemented in Groovy with less code.
So, unless required, you don’t need to declare the public keyword for method declaration.
Within a class, Groovy will automatically generate the getter/setter methods for the declared properties.
So in a Groovy class, you just need to declare the type and name (for example, String firstName or def firstName), and you can access the properties in any other Groovy/Java classes by using the getter/setter methods automatically.
Groovy also provides simplified syntax and many useful methods to the Java Collection API.
Define a list as an ArrayList def list = ['This', 'is', 'Clarence'] assert list.size() == 3 assert list.class == ArrayList.
The listing shows only a very small portion of the features that Groovy offers.
For a more detailed description, please refer to the Groovy online documentation at http://groovy.codehaus.org/JN1015Collections.
Closure One of the most important features that Groovy adds to Java is the support of closures.
A closure allows a piece of code to be wrapped as an object and to be passed freely within the application.
Closure is a very powerful feature that enables smart and dynamic behavior.
However, if you want to enjoy the benefits that closures bring to your application, you need to use a scripting language like Groovy, Python, Scala, Ruby, Clojure, and so on.
Then, the convenient each() method is used for an operation that will iterate through each item in the list.
The argument to the each() method is a closure, which is enclosed in curly braces in Groovy.
As a result, the logic in the closure will be applied to each item within the list.
Within the closure, it is a special variable used by Groovy to represent the item currently in context.
So, the closure will prefix each item in the list with the String "Hello: " and then print it.
As mentioned, a closure can be declared as a variable and used when required.
The closure accepts the key and value of a map’s entry as its arguments, and the logic calculates the square of the value of the key.
In the next section, we will develop a simple rule engine using Groovy and Spring.
For a more detailed description of using closures in Groovy, please refer to the online documentation at http://groovy.codehaus.org/JN2515Closures.
Using Groovy with Spring The main benefit that Groovy and other scripting languages bring to Java-based applications is the support of dynamic behavior.
By using a closure, business logic can be packaged as an object and passed around the application like any other variables.
Another main feature of Groovy is the support for developing DSLs by using its simplified syntax and closures.
As the name implies, a DSL is a language targeted for a particular domain with very specific goals in design and implementation.
The objective is to build a language that is understandable not only by the developers but the business analysts and users as well.
Most of the time, the domain is a business area.
For example, DSLs can be defined for customer classification, sales charge calculation, salary calculation, and so on.
In this section, we will demonstrate using Groovy to implement a simple rule engine with Groovy’s DSL support.
In addition, we will discuss how Spring’s support of refreshable beans enables the update of the underlying rules on the fly without the need to compile, package, and deploy the application.
In this sample, we will implement a rule used for classifying a specific contact into different categories based on their age, which is calculated based on their date of birth property.
Adding Required Dependencies In the sample, we will use Groovy and the JodaTime library, so we need to add the required dependencies in Table 22-1 to our project.
The Contact Domain As mentioned, a DSL targets a specific domain, and most of the time the domain is referring to some kind of business data.
For the rule we are going to implement, it was designed to be applied to the domain of contact information.
So, the first step is to develop the domain object model we want the rule to apply to.
In this sample, the DOM is very simple and contains only one Contact entity class, as shown in Listing 22-7
Note that it’s a POJO class like what we did in previous chapters.
In Listing 22-7, the Contact class is a simple contact information.
For the ageCategory property, we want to develop a dynamic rule that can be used to perform classification.
The rule will calculate the age based on the birthDate property and then assign the ageCategory property (for example, kid, youth, adult, and so on) based on the rule.
Implementing the Rule Engine The next step is to develop a simple rule engine for applying the rules on the domain object.
First we need to define what information a rule needs to contain.
Listing 22-8 shows the Rule class, which is a Groovy class (the file name is Rule.groovy)
The conditions property defines the various conditions that the rule engine should check for with the domain object under processing.
The actions property defines the actions to take when a match on the condition is hit.
The parameters property defines the behavior of the rule, which is the outcome of the action for different conditions.
Finally, the singlehit property defines whether the rule should end its execution immediately whenever a match of condition is found.
Listing 22-9 shows the RuleEngine interface (note it’s a Java interface)
The interface defines only a method run(), which is to apply the rule to the domain object argument.
We will provide the implementation of the rule engine in Groovy.
In Listing 22-10, first the RuleEngineImpl implements the RuleEngine Java interface, and Spring’s annotation is applied like any other POJO.
Within the run() method, the parameters defined in the rule were passed into a closure for processing one by one.
For each parameter (which is a list of values), the conditions (each condition is a closure) are checked one by one with the corresponding item within the parameter’s list and the domain object.
The success indicator becomes true only when all the conditions result in a positive match.
In this case, the actions (each action is a closure too) defined in the rule will be performed on the object, with the corresponding value within the parameter’s list.
Finally, if a match is found for a specific parameter and the singlehit variable is true, the rule execution will be stopped and will exit immediately.
To allow the retrieval of a rule in a more flexible way, let’s define a RuleFactory interface, as shown in Listing 22-11
In Listing 22-11, since there is only one rule for an age category classification for contacts, the interface defines only a single method for retrieving the rule.
To make our rule engine transparent to the consumer, let’s develop a simple service layer to wrap it up.
In Listing 22-13, the required Spring beans are autowired into the service implementation class.
In the applyRule() method, the rule is obtained from the rule factory and then applied to the Contact object.
The result is that the ageCategory property for the Contact will be derived based on the rule’s defined conditions, actions, and parameters.
Implement the Rule Factory as a Spring Refreshable Bean Now we can implement the rule factory and the rule for age category classification.
We want to be able to update the rule on the fly and have Spring check for its changes and pick it up to apply the latest logic.
The Spring Framework provides wonderful support for Spring beans written in scripting languages, called refreshable beans.
We will see how to configure a Groovy script as a Spring bean and instruct Spring to refresh the bean on a regular interval later.
First let’s see the implementation of the rule factory in Groovy.
To allow dynamic refresh, we put the class into an external folder.
Within the rule, a Closure called age is defined to calculate the age based on the birthDate property (which is of JodaTime’s DateTime type) of a Contact object.
The first one is to check whether the age of a contact is larger than or equal to the provided parameter value, while the second check is for the smaller than or equal to condition.
Then, one action is defined to assign the value provided in the parameter to the ageCategory property of the Contact object.
The parameters define the values for both condition checking and action.
So, for each parameter, the first two values will be used by the two conditions to check for age range, while the last value will be used for assigning the ageCategory property.
For defining Spring beans in a scripting language, we need to use langnamespace.
Then, the <lang:groovy> tag is used to declare a Spring bean with a Groovy script.
The script-source attribute defines the location of the Groovy script that Spring will load from.
In this case, we supplied the value of 5000ms, which instructs Spring to check for file changes if the elapsed time from the last invocation is greater than five seconds.
Note that Spring will not check the file every five seconds.
Instead, it will check the file only when the corresponding bean is invoked.
Testing the Age Category Rule Now we are ready to test the rule.
The testing program is shown in Listing 22-16, which is a Java class.
Then, the instance of ContactService interface is obtained to apply the rule onto the Contact object and then output the result to the console.
The program will be paused for user input, before the second application of the rule.
Now press the Enter key in the console area to trigger the second application of the rule to the same object.
After the program continues, the following output will be produced:
Of course, this rule is a simple one, but you should have an idea of how a scripting language like Groovy can help supplement Spring-based Java EE applications in specific areas like rule engine with DSL.
You may be asking, “Is it possible to go one step further by storing the rule into the database and then have Spring’s refreshable bean feature detect the change from the database?” This can help further simplify the maintenance of rule by providing a frontend for users (or administrator) to update the rule into the database on the fly, instead of uploading the file.
In the meantime, providing a user frontend to upload the rule class is also a workable solution.
Of course, extreme care should be taken in this case, and the rule should be tested thoroughly before you upload it to the production environment.
Summary In this chapter, we covered how to use scripting languages in Java applications and demonstrated how the Spring Framework’s support of scripting language can help provide dynamic behavior to the application.
Then, we introduced Groovy, a popular scripting language within the Java developer communities.
We also demonstrated some of its main features when compared to the traditional Java language.
Finally, we discussed the support of scripting languages in the Spring Framework.
We saw it in action by designing and implementing a very simple rule engine using Groovy’s DSL support.
We also discussed how the rule can be modified and have the Spring Framework pick up the changes automatically by using its refreshable bean feature, without the need to compile, package, and deploy the application.
A typical JEE application contains a number of layers and components, such as the presentation layer, service layer, persistence layer, backend data source, and so on.
During the development stage or after the application had been deployed to the quality assurance (QA) or production environment, we want to ensure that the application is in a healthy state without any potential problems or bottlenecks.
In a Java application, various areas may cause performance problems or overload server resources (such as CPU, memory, I/O, and so on)
Examples are inefficient Java code, memory leaks (for example, Java code keeps allocating new objects without releasing the reference and prevents the underlying JVM from freeing up the memory during the garbage collection process), JVM parameters, thread pool parameters, data source configurations (for example, the number of concurrent database connections allowed), database setup, long-running SQL queries, and so on.
Consequently, there is a need to understand an application’s runtime behavior and identify whether there are any potential bottlenecks or problems.
In the Java world, a lot of tools can help monitor the detailed runtime behavior of JEE applications.
Most of them are built on top of the Java Management Extensions (JMX) technology.
In this chapter, we will discuss several common techniques for monitoring Spring-based JEE applications.
Spring support of JMX: We will discuss Spring’s comprehensive support of JMX and demonstrate how to expose Spring beans for monitoring with JMX tools.
In this chapter, we will use VisualVM (http://visualvm.java.net/index.html) as the application monitoring tool.
Monitoring Hibernate statistics and Spring Batch: Hibernate and Spring Batch also provide support classes and infrastructure for exposing the operational status and performance metrics using JMX.
We will take a look at how to enable the JMX monitoring of those commonly used components in Spring-powered JEE applications.
We will discuss how to use Spring Insight to monitor Spring-based JEE applications.
Remember that this chapter is not intended to be an introduction to JMX, and a basic understanding of JMX is assumed.
Project for Chapter Samples In this chapter, we will use the web application we developed in Chapter 17 as the application to monitor.
To show how to monitor Spring Batch jobs, a batch job was added to the application for importing contact information into the database from an XML file.
We prepared a project for the sample application that will be used for monitoring; you can simply import it and then proceed to implement the required classes.
From the sample code, extract the file ch23-nojmx.zip into your STS workspace.
Then, on the Import Projects screen, choose the project extracted from the sample source code, and click Finish (see Figure 23-2)
After completing the project import, build and deploy to tc Server in STS, and start the tc Server.
After the web application starts up successfully, open a browser and enter the URL http://localhost:8080/ch23/contacts to verify the application.
In this chapter, we will focus on exposing Spring beans (which were developed as simple POJOs) as MBeans for JMX monitoring.
In the following sections, we will discuss the procedure for exposing a bean containing applicationrelated statistics as an MBean for JMX monitoring.
In addition, we will also discuss how some metrics relating to Spring Security can be exposed to JMX.
Exporting a Spring Bean to JMX As an example, for the sample web application, which maintains a list of contact information, we would like to expose the count of the contacts in the database for JMX monitoring purposes.
In Listing 23-2, a method is defined to retrieve the total count of contact records in the database.
To expose the Spring bean as JMX, we need to add configuration in Spring’s ApplicationContext.
Listing 23-3 shows the code snippet needed to add to the file.
In Listing 23-3, the bean definition we need to add is highlighted in bold.
First, the bean for the POJO with statistics we want to expose is declared.
Second, the jmxExporter bean with the implementation class MBeanExporter is declared.
The MBeanExporter class is the core class within the Spring Framework’s support for JMX.
When exposing a Spring bean as an MBean, Spring will attempt to locate a running MBeanServer instance within the server and register the MBean with it.
For the tc Server, which is bundled with STS and built on top of Tomcat, an MBeanServer will be created automatically, so no additional configuration is required.
Within the jmxExporter bean, the property beans defines the Spring beans we want to expose.
It’s a Map, and any number of MBeans can be specified here.
In our case, we would like to expose the appStatisticsBean bean, which contains information about the contact application we want to show to administrators.
By default, all public properties of the bean are exposed as attributes, and all public methods are exposed as operations.
Let’s proceed to set up VisualVM and use its JMX client for monitoring purposes.
Setting Up VisualVM for JMX Monitoring VisualVM is a very useful tool that can help in monitoring Java applications in various aspects.
It’s a free tool that bundles with JDK 6 (the jvisualvm.exe file under the bin folder in the JDK installation folder)
A stand-alone version can also be downloaded from the project web site (http://visualvm.java.net/download.html)
We will use the stand-alone version in this chapter; at the time of writing, the version is 1.3.3
To install VisualVM, download the zip install file from the download site and extract it onto your local computer.
Then, under the folder bin, execute the program visualvm.exe on Windows (or execute the visualvm script for Unix/Linux)
After completing the installation, verify that the tc Server is up and the sample application is running.
Then in VisualVM’s left Applications view, you should be able to see that the Tomcat process is running, as shown in Figure 23-5
By default, VisualVM will scan for the Java applications that are running on the JDK 6 platform.
In Figure 23-5, the Tomcat process is the tc Server that was running in STS.
Double-clicking the node will bring up the monitoring screen, as shown in Figure 23-6
After the installation of the VisualVM-MBeans plug-in, you will able to see the MBeans tab.
Feel free to add a new contact in the sample application and refresh the view.
Monitoring Logged-In Users JMX is very useful for monitoring an application’s status and metrics.
One common use case is to expose the number of logged-in users for a web application.
In this section, we will show you how to expose the number of logged-in users in the sample application to JMX.
As discussed in Chapter 17, we used Spring Security for application security management.
Spring Security supports the configuration of a session registry, which can be injected into our Spring bean, and we retrieve the number of logged-in users.
To do this, we need to enable concurrent session control in Spring Security.
So, in the web deployment descriptor (the web.xml file), add a Spring Security listener.
In Listing 23-4, the listener declaration is highlighted in bold.
Its Spring Security’s listener implementation is created for publishing HTTP session-related events, such as a user logging in, and a new HTTP session is created.
Then we need to enable session management in the Spring Security configuration.
In Listing 23-5, the additional configuration is highlighted in bold.
Now we can modify the bean to autowire the session registry and expose the number of logged-in users to JMX.
Let’s add two methods to show the information of logged-in users.
After the project is rebuilt and deployed and the application is reloaded, you will be able to see the two new metrics in the VisualVM screen, as shown in Figure 23-8
In Figure 23-8, you can see the two user-related metrics.
The LoggedInUserCount metric shows the number of logged-in users, which is 0 at the moment.
In addition, the LoggedInUsers metric shows the list of principals, which is currently empty.
Now log into the sample application (using “user” as both the user name and password)
Then, in VisualVM, refresh the view (there is a Refresh button at the bottom), and you will see the login count incremented by one, as shown in Figure 23-9
If you want to see who has logged in, you can click the Operations tab and then the operation getLoggedInUsers, and a pop-up dialog will show the content of the list, which contains the name of the logged-in user, as shown in Figure 23-10
In Figure 23-10, you can see the information of each logged-in user, including the user name.
This is quite useful, for example, when an operator needs to check whether there are still users logging into the application before performing any maintenance actions.
In Listing 23-8, the new properties are highlighted in bold.
Finally, we need to add the MBean into Spring’s MBeanExporter configuration.
A new statisticsBean is declared, with Hibernate’s StatisticsService class as the implementation.
Now the Hibernate statistics are enabled and available via JMX.
After the application is reloaded and the VisualVM is refreshed, you will be able to see the Hibernate statistics MBean.
Clicking the node will display the detail statistics on the right side.
Note that for the information that is not of Java primitive type (for example, a List), you can click in the field, which will expand the field to show the content.
Figure 23-11 shows the MBeans tab, with the mapped entity classes and the executed queries fields expanded.
Those figures are very useful for you to understand the persistence behavior within your application and can assist you in troubleshooting and performancetuning exercises.
Monitoring Spring Batch Jobs If you are using Spring Batch for running batch jobs, you can also use Spring Batch’s JMX support for batch job status monitoring.
First, the dependency to Spring Batch Admin, as shown in Table 23-1, should be added to the project.
The next step is to configure the required bean for Spring Batch and Spring Batch Admin to expose the metrics via JMX.
In Listing 23-10, the new bean definitions are highlighted in bold.
This is the mechanism that Spring Batch Admin uses for exposing its status via JMX.
Second, the batchMBeanExporter bean with the implementation class BatchMBeanExporter is declared.
After the application is rebuilt, redeployed, and reloaded, the metrics for Spring Batch will be available via JMX.
Click to expand it, and you will see the MBeans that are exposed via Spring Batch Admin.
The one of particular interest is JobExecution, which shows the jobs defined and their related execution metrics.
Figure 23-12 shows the application just started, without any job executed (the job name in the sample application is importContactsJob)
Copy the file contacts.xml in the project’s root folder into the folder C:\temp\contact.
You will see from STS’s tc Server console output that the job was triggered and the contact information in the file was uploaded.
Then, the screen in VisualVM will be updated, as shown in Figure 23-13
In the figure, you will see the execution count updated, together with the metrics of the last job execution.
You will also notice that the step readWriteStep of the job has appeared.
Clicking into it will show the details of the step execution metrics (note that this step is the only step in the job), as shown in Figure 23-14
Now you have an idea how Spring’s JMX support can help you monitor many aspects of the application behavior and status, either by JMX MBeans already bundled with a third-party library or by implementing your custom MBean.
Monitoring an Application with Spring Insight Spring Insight is another offering from SpringSource that supports comprehensive monitoring and visualization of Spring-based web applications.
In this section, we will demonstrate using Spring Insight Developer (an edition of Spring Insight targeted for developer use) to monitor the sample web application.
In the following sections, we will discuss the procedure required, including setting up a tc Server instance with Spring Insight enabled and using it to monitor the main aspects of a Spring-based JEE application.
The feature most relevant to application developers is the ability to trace and capture the statistics and performance figures across all layers of a web application.
Some of the main information that Spring Insight can help to capture is as follows:
The response time of various pages within a web application over a designated period of time.
Detailed description of each request, its parameters, and its headers.
Under the hood, Spring Insight use AspectJ to intercept operations in target web applications.
Targeted web applications are loaded with a special classloader that dynamically instruments web applications during runtime.
Configuring Spring Insight The easiest way to understand Spring Insight is to see it in action.
In this section, we will demonstrate how to set up an environment with Spring Insight Developer for monitoring our sample application.
To use it, we just need to configure a tc Server instance with Spring Insight enabled.
Click the Next button, and the tc Server Configuration screen will be displayed.
Select “Create new instance,” and click the Next button, as shown in Figure 23-16
This instructs tc Server to create a new instance with the Spring Insight template (see Figure 23-17)
The tc Server instance with the Spring Insight template selected.
Then, click Next to add the project into the server, as shown in Figure 23-18
Click the Finish button, and wait for the server instance creation to complete.
You will then see the new server with the project added, as shown in Figure 23-19
After it has started, we can explore the web application’s behavior with Spring Insight.
Using Spring Insight Spring Insight provides a web application for visualizing the performance of the applications deployed to that server instance.
To access Spring Insight on the tc Server, enter the URL http://localhost:8080/insight in your browser.
From the figure, you can see that one of the applications is our sample application, under the URL /ch23
Play around with the sample application (in another browser tab or window), and then click the item /ch23
The end points with their high-level throughput figures will be displayed, as shown in Figure 23-21
To see the details of an end point, click it on the left side, and the details will be shown on the right, as shown in Figure 23-22
On the right side, you will see the response time histogram, which shows the various invocations during the monitoring period.
Clicking into any invocation will cause the trace information to display below the histogram.
In Figure 23-23, you will see the details call tree, the time taken, and the database queries that have been fired to the database.
So, you have a full picture of the application interaction among various Spring beans within your application, as well as the execution time for the queries submitted to the database.
With the information, you will be able to identify the bottleneck of your application quickly and perform corresponding remedial actions.
Spring Insight is very useful tool that can help you analyze your application behavior in many different aspects.
You can even use Spring Insight Developer Kit to develop plug-ins to extend Spring Insight for collecting specific metrics about your application.
One example is to analyze traces from Spring Insight and produce new types of end points, such as a JMS message queue.
For details, please refer to SpringSource’s online documentation at http://static.springsource.com/projects/tc-server/2.5/devedition/htmlsingle/devedition.html.
Summary In this chapter, we covered various topics of monitoring a Spring-powered JEE application.
First, we discussed Spring’s support of JMX, the standard in monitoring Java applications.
Second, we covered using Spring Insight to visualize the application’s performance on tc Server.
Topics included setting up a tc Server instance with Spring Insight enabled, as well as some of the main metrics that can be seen from Spring Insight’s web frontend.
The chapters in this book gave specific instructions on using STS when creating projects and implementing the sample code within each chapter.
If you have gone through all the samples, you will already have a fair understanding of STS.
The objective of this appendix is to describe other basic topics when using STS that were not covered in the regular chapters.
This appendix is intended for developers who are not familiar with STS.
However, basic knowledge of using Eclipse for Java application development is assumed.
If you already are an Eclipse power user or are familiar with STS (or the Spring IDE), feel free to skip this appendix and use it for reference only when required.
In this appendix, we will discuss some basic topics related to STS.
Although STS also supports Mac OS X and Linux, we will focus on installing and using STS on the Windows platform.
Project setup and dependency management: We will discuss how to create Spring projects in STS and manage the required dependencies within the project.
We will focus on the Maven dependency management with the m2e plug-in (the official Maven plug-in for Eclipse IDE)
Using STS: We will discuss installing extensions, managing tc Server, and so on.
It includes a number of plug-ins, which provide support for developing Spring-based applications, as well as integrates with other Eclipse plug-ins (such as m2e, AspectJ Development Tool, and so on)
It supports the creation and editing of Spring’s ApplicationContext configuration XML files with code assistance and validation.
It provides graphical views of Spring configuration such as the bean graph, Web Flow diagram, Spring Batch and Integration diagrams, and so on.
It supports the installation of extensions for other features (for example, for the development of Groovy classes and scripts, Grails, and so on)
It supports the management of tc Server Developer Edition for local web application development and testing.
First, SpringSource has prepared a bundled version with Eclipse and the required plug-ins.
Second, if you already have an Eclipse development environment, you can simply extend it with the plug-ins provided by STS.
Either way, make sure you already have a JDK (version 6 or newer) installed in your PC.
Installing the Stand-Alone Version of STS The simplest way to install STS is to download the bundle from the STS web site that has Eclipse bundled with it.
Figure A-1 shows the download site, with the versions available for the Windows platform (note that versions are also available for Mac OS X and Linux)
One is in Windows installer format that you can simply click to install, and the other is a zip file that you can extract and use to set up STS yourself.
Upon completing the download, click the executable file to start the installation.
Accept the license agreement and click the Next button to proceed to the next step, as indicated in Figure A-4
Select the folder in which you want to install STS.
Then, click Next to proceed to the next step, as shown in Figure A-5
Step 4 will display the available optional items for your selection.
Make sure all the options are selected, and then click Next to proceed to the next step, as shown in Figure A-6
Select the JDK installation folder on your computer, and then click the Next button to proceed to the next step, as shown in Figure A-7
Wait until the installation is complete, and then choose whether to create a shortcut for STS, as shown in Figure A-8
Click Next to complete the installation, as shown in Figure A-9
At this point, the installation of the stand-alone version of STS is complete.
Installing STS to an Existing Eclipse Environment Another way to set up STS is to extend an existing Eclipse installation.
In the following example, we will demonstrate installing STS onto an existing Eclipse (version 3.7.1) setup.
Before we can install STS, we need to install some Eclipse plug-ins required by STS.
The next plug-in we need to install is the Jetty runtime environment, which includes an update to the JSP plug-in that is required by STS.
In the Install dialog, click the Add button to open the Add Repository dialog, and enter the name (Jetty Runtime) and the URL http://download.eclipse.org/jetty/updates/3.7 for the update site information.
After the repository is added, the available components will be displayed in the Install dialog.
Choose the components to install, and click the Next button to continue the installation, as shown in Figure A-11
After that is complete, we can proceed to install the STS plug-ins.
Prepare a file called bookmarks.xml with the content, as shown in Listing A-1
Upon completion, you will see that the STS update sites are added, as shown in Figure A-13
Back in the Install dialog, select the components to install, as shown in Figure A-14
We don’t need all the components, and some components require additional plug-ins to be installed first.
Select the components suitable for your environment; Figure A-15 shows the components selected in our sample.
Click the Next button, and follow the instructions to start the installation.
Once the installation is complete, the STS-related functions will be available.
Clicking the project name presents you with a brief description of the purpose of the project.
Then enter the project information, as shown in Figure A-17
Spring and Maven natures are automatically added to the project, as shown in Figure A-18
After project creation, we need to update the configuration generated by STS.
Double-click the pom.xml file, and in the editor, click the pom.xml tab and edit the configuration, as shown in Figure A-19
Dependency Management for a Project With the Maven plug-in, managing the library dependencies for your project becomes much easier.
For example, in the pom.xml file editor view, click the Dependencies tab, as shown in Figure A-22
To add a dependency into your project, click the Add button on the left side to open the Select Dependency dialog.
The Maven dependencies for the project will be updated automatically.
If you click the Dependency Hierarchy tab, you will see the entire dependency hierarchy, as shown in Figure A-24
In Figure A-24, you will notice that after the Hibernate Entity Manager dependency is added, the other required dependencies are also added (for example, the Hibernate Core library)
In various chapters, you will see that different dependencies are required.
For all cases, you can simply follow the procedure here for managing the dependencies.
Using STS Now you have a basic understanding of what STS can do for you.
In this section, we will discuss some other areas of STS, such as installing extensions and managing tc Server.
On top of those plug-ins, STS also provides a lot of extensions that support the development of Spring-based applications or integration with other popular tools and frameworks.
To see the available extensions and install those you require, first open the Spring Dashboard view.
A quick way to open the view is to click the Dashboard icon in the toolbar, as shown in Figure A-25
In the view, click the Extensions tab, and the list of available extensions will be displayed, as shown in Figure A-26
In Figure A-26, you will see a lot of extensions, such as the support for Grails, the Google plug-in for Eclipse, and so on.
Simple check the extension you want, and then click the Install button to install it.
Click the Next button and choose the option Create New instance on the next screen.
In the Create tc Server Instance dialog, enter the name of the instance; then select the template you want to use for the new instance (see Figure A-28)
For a detailed description of the meaning of each template, as well as coverage on how to use tc Server for your development, please refer to its online documentation at http://static.springsource.com/projects/tc-server/2.5/getting-started/htmlsingle/gettingstarted.html.
Summary In this appendix, we showed you how to use STS.
Topics included installing it, using Spring template projects, managing Maven dependencies, updating project configuration, and managing tc Server.
All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.
Exempted from this legal reservation are brief excerpts in connection with reviews or scholarly analysis or material supplied specifically for the purpose of being entered and executed on a computer system, for exclusive use by the purchaser of the work.
Duplication of this publication or parts thereof is permitted only under the provisions of the Copyright Law of the Publisher's location, in its current version, and permission for use must always be obtained from Springer.
Permissions for use may be obtained through RightsLink at the Copyright Clearance Center.
Violations are liable to prosecution under the respective Copyright Law.
Trademarked names, logos, and images may appear in this book.
Rather than use a trademark symbol with every occurrence of a trademarked name, logo, or image we use the names, logos, and images only in an editorial fashion and to the benefit of the trademark owner, with no intention of infringement of the trademark.
The use in this publication of trade names, trademarks, service marks, and similar terms, even if they are not identified as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary rights.
While the advice and information in this book are believed to be true and accurate at the date of publication, neither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or omissions that may be made.
The publisher makes no warranty, express or implied, with respect to the material contained herein.
Apress and friends of ED books may be purchased in bulk for academic, corporate, or promotional use.
Any source code or other supplementary materials referenced by the author in this text is available to readers at www.apress.com.
For detailed information about how to locate your book’s source code, go to http://www.apress.com/source-code/
To all my friends and colleagues that I worked with for giving me invaluable support, advice and wonderful working experience.
To my family, especially my mom, Yeung, for their true love.
Also to the authoring team, including Chris, Manuel and Brent, in providing me extraordinary support in writing this book.
Working in IT for over 20 years, Clarence has been the team leader on many in-house application development projects, as well as providing consultancy services on enterprise solutions to clients.
Rob Harrop is a co-founder of SpringSource, the software company behind the wildly-successful Spring Framework.
Manuel Jordan Elera is an autodidactic developer and researcher who enjoys learning new technologies for his own experiments and creating new integrations.
In his little free time, he reads the Bible and composes music on his guitar.
Read and contact him through his blog at http://manueljordan.wordpress.com/ and follow  him on his Twitter account, @dr_pompeii.
