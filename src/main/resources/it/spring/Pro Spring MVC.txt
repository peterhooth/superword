This book takes you through the entire process of designing, implementing, and deploying a Java web application using Spring MVC and Spring Web Flow.
It includes detailed analysis of the code and functionality, as well as numerous tips and tricks to help you get the most out of Spring MVC, Spring Web Flow, and web development in general.
You’ll gain key practical knowledge and learn how you can apply similar designs and techniques to your own code.
Right from the start, you’ll learn practical applications of the frameworks by using them with an application that is developed throughout the book.
Each chapter defines real-world problems and solutions; solutions which you then use to upgrade the sample application.
Deploy to a local web server and to a remote cloud-based deployment platform.
Pro Spring MVC does more than simply cover the technical details, it fully explains many of the underlying concepts and gives you the practical knowledge you need to succeed.
After reading this book, you’ll fully understand how to use Spring MVC to build your own web application from scratch or create a new web interface for an existing one.
For your convenience Apress has placed some of the front matter material after the index.
Before you can really start your journey into Spring MVC, you need to make sure you have your development environment set up right.
This chapter will begin by walking you through that process.
Next, it will provide some details about the sample bookstore application that ships with this book.
But before going into either the details of the development environment or the sample application, this chapter will provide an overview of the prerequisites for your environment in general.
The sample application that ships with the book is used to explain the concepts of Spring MVC and MVC in general.
It is not intended to be a full-blown, ready-to-use production application; nor is it to be used as a Java or full Spring Framework application.
The main intent of the app is to help explain and express the Spring MVC concepts used throughout the book.
There are no known issues with running the sample application with JDK7, so those who want to “live on the edge” are free to do so.
Those who want the smoothest ride possible should choose JDK6
The JRE is only for running Java applications, whereas the JDK is for compiling Java code.
Servlet Container To run a Java web application, you need a web container.
Tomcat (http://tomcat.apache.org/) is an excellent candidate and widely used in production systems.
There is nothing Tomcat-specific in the sample file, so feel free to use Jetty, JBoss, Glassfish, or any other modern web container or application server.
This is an excellent product built on top of Tomcat, and it offers value for both developer and production environments.
Integrated Development Environment Although Spring itself doesn’t require a particular development environment (over and above the Java Development Kit), becoming familiar with a good IDE is highly recommended.
SpringSource has also invested significant effort into providing its own distribution based upon Eclipse called the SpringSource Tool Suite (STS)
And while the “vanilla” version Eclipse is excellent, STS provides additional levels of polish when it comes to developing Spring-based applications.
The Sample Application This section delves into the sample application you will build throughout the book.
For example, you will learn about the build system selected and used for the sample application.
Next, you will learn how to import the sample application into STS and take your first steps in deploying the first part of the application.
The main intent of the sample application is to show the features and possibilities of Spring MVC.
A Bookstore Sample Application The sample application that will be built and used throughout this book is a simple bookstore.
You will learn how to add functionality for searching, displaying, and buying books.
To buy books, the user of the app needs to have an account with the app’s associated bookstore, so there is also going to be some account registration and a login page.
The sample application will remain more or less the same throughout the book.
In the Spring Web Flow chapters, however, you’ll see some important differences that exist mainly to illustrate some of the Spring Web Flow functionality.
You can find the code for the sample application with the source code for this book.
Note that the top-level directory contains a number of folders entitled chapterX-bookstore.
As you progress through this book, you will continually be adding new functionality to the sample application.
In some cases, you will be revisiting code from previous chapters.
For simplicity and clarity, the authors decided to separate each chapter’s progression into a separate project; to see the relevant code for Chapter X, simply load the project in the chapterX-bookstore folder.
In addition to the directories for each chapter, you can also find two projects that are shared between all the book’s chapters (see Figure 1-1)
One project contains the shared business layer, while the other has the images, stylesheets, and other, similar files.
Note  The project in chapterX-bookstore contains the solution for Chapter X.
The authors tried to create a realistic but simple sample application; to that end, we tried to use the technologies of today.
For the web pages, the primary technology used is Java Server Pages (JSPs)
You can also find a wealth of other resources for this technology, including Oracle’s own tutorial at http://download.oracle.com/javaee/5/tutorial/doc/bnagx.html.
Note  The observant reader probably noticed the JEE5 bit in the tutorial URL.
The Build System The topic of how to build applications has been subject to decades of arguments, fanaticism, and downright stupidity.
We could have taken the easy way out and avoided this discussion by building and deploying entirely with the SpringSource Tool Suite (STS), which we will discuss later in this chapter.
However, the authors felt that was a disservice to you.
Typically, an application is built using one mechanism (the IDE), while an entirely different mechanism is used to deploy it to production.
This is often a source of frustration, and it leads to the wonderful “works on my machine” syndrome.
With this in mind, our strong opinion is that it is the developer’s responsibility to ensure that an application works in an environment as close to production as possible, including the build mechanism itself! You will see how sophisticated build tools make that possible.
The build tool you are going to use in this book is Gradle (http://gradle.org)
This is a fairly new but up-and-coming project-automation tool (project automation is a fancy term for build tool) that has a strong pedigree and has already established a very good reputation.
A full discussion on build tools is outside the scope of this book; however, suffice it to say that Gradle combines the power of Maven’s “configuration over convention” approach with the succinctness of Groovy.
The Gradle infrastructure is driven by a build.gradle script (this is somewhat equivalent to Maven’s pom.xml) and an optional settings.gradle file; both can be found in the SAMPLE_ROOT directory.
Tip  If you prefer to use Maven, please note that Gradle is perfectly capable of generating Maven POMs (project object models)
The wealth of high quality libraries is the currency used to pay for the language’s verbosity and pain.
However, its greatest strength is, as ever, its greatest weakness: it isn’t unusual for small-to-medium projects to have a dependency graph of more than 50 libraries.
This proliferation of libraries is made worse by the correct use of modularization!
The problem with the dependencies is that the dependencies also have dependencies, which also have dependencies, which also...
There are direct dependencies (dependencies for the project) and transitive dependencies (dependencies needed by the direct dependencies)
However, that isn’t the only problem because there is also something that could be called versioning hell.
If there are multiple dependencies and these dependencies have a dependency on both library x and on different versions of that library, this presents an additional challenge.
But, wait, there’s more! You don’t want to sit at your computer and Google for all the missing (transitive) dependencies, download them, redeploy your application, and then notice you have still another missing dependency (or maybe the wrong version of a dependency)
For example, it helps you with downloading and discovering what you need, and it tries to resolve all of the versioning conflicts.
In this case, you can let the computer do the hard work for you, and you can focus at the task at hand, which is solving the business problem—selling books, in this book’s example (not searching for dependencies late into the night)
Note  Gradle’s dependency management infrastructure is compatible with the somewhat industry-standard Maven repositories—and it has excellent support for resolving dependencies.
It is also a build tool; and, as such, it can do a lot for you.
For example, if you open the build.gradle file, you’ll see the dependencies needed by all the subprojects.
Gradle can also help you build (compile, test, and create a war archive) your application, and the Groovy language can be used to easily modify or influence the way you build your application.
To help build the application, there is a plugin that can deploy the application to an embedded Tomcat instance.
This instance can, in turn, be used to run the integration tests (see Chapter 9)
These functions are just the beginning of what Gradle can provide.
Building the Sample Application To build the sample, cd into the SAMPLE_ROOT directory and execute the gradlew script.
Assuming you are on Unix system, this will look something like Figure 1-2
You will notice the first thing that the gradlew script does is download the Gradle distribution itself! This is why there is no “install gradle” step—it is self-installing.
Note  We recommend checking the gradlew script into source control.
The Continuous Integration (CI) server and (as well as other developers) all use this script.
Upgrading to a new version of Gradle is as simple as updating the gradlew script which, when executed, will silently upgrade itself.
After Gradle has downloaded itself, you should build the sample application by executing ../gradlew build (see Figure 1-3)
Notice how Gradle downloaded the sample dependencies and went through the lifecycle of compiling, testing, and packaging the sample application.
Similar to Maven, Gradle contains a local cache of JARs (a .gradle directory in your home folder)
Subsequent executions are much faster because no network access is required (see http://gradle.org/documentation for more information)
Tip  For a list of all tasks that can be executed, type gradlew tasks.
Deploying the Sample Application The next step is to deploy the application to a web container.
Tomcat (http://tomcat.apache.org/) is an excellent candidate, so you could download and install that.
As noted previously, there is nothing Tomcat-specific in the sample file, so feel free to use Jetty, JBoss, Glassfish, or any other modern web container.
Note  With a view toward reducing the number of new things you must learn—if you’re more familiar with another web container, then it probably makes sense to stick with what you know for now.
Now open up your favorite web browser and navigate to http://localhost:8080/chapter1bookstore-1.0.0
If everything went well, you should see the screen in Figure 1-4
However, the point of this sample app is to start really simple and build up, so there is no.
Don’t worry; the application will get much better as you go.
The default naming strategy in Tomcat is to set the context path to be the name of the WAR file.
For example, if the name of the WAR file were bookstore.war, then the context path would be /bookstore.
Congratulations! You have accomplished the critical, but often overlooked step of ensuring that your application can be built and works outside your IDE.
The next step is to install STS and actually look at the sample that you have just so excellently deployed.
Before doing so, make sure to press Control-C to shutdown Tomcat.
SpringSource Tool Suite (STS) As we explained earlier, Spring doesn’t require a specific development environment, but we do recommend that you consider a good IDE.
Leading IDEs like Eclipse and IntelliJ IDEA are excellent choices, but the SpringSource Tool Suite (STS), based on Eclipse, provides additional benefits for developing Spring-based applications.
The first time you do this, STS will download a list of extensions, which can take a few seconds.
Eventually, the Install Extensions page will be ready (see Figure 1-5)
Now select the check box next to Gradle Support and click Install on the bottom right.
Review the prompt and click Next to open the Install dialog (see Figure 1-7)
Click Next to get to the Install Details dialog and click Next again to get to the license.
Finally, read the license agreements (who reads these?) and click Finish.
Once it finishes, you will be asked to restart—click Yes.
As mentioned previously, typical Java applications can have large dependency graphs.
Gradle has already dealt with this, and it would be painful to have to manually resolve the dependencies in order to register them with STS.
Luckily, STS actually understands Gradle projects (just as it understands Maven projects)
Now click Browse and navigate to the directory containing the sample projects.
Note  STS will download its own version of Gradle and, if you skipped the previous step of building the sample application via the command line, STS will also download the application’s dependencies.
You can either select the root bookstore project or click Select All to import all projects.
Afterwards, click Finish to instruct STS to actually import your project.
This might take a while as STS is downloading all missing dependencies and will compile all projects.
However, the projects should eventually appear in STS (see Figure 1-11)
Tip  We suggest that you close the projects you aren’t currently working on.
To do this, select the projects to close, right-click, and then select the menu option, Close Project.
Running the Application on the SpringSource vFabric tc Server Before you can run the application, you must tell STS which web container to run the application on.
You have two choices: use the Tomcat installation you downloaded earlier or use the prebuilt VMware vFabric tc Server.
Choose the VMware vFabric tc Server Developer Edition v2.6 entry (or Tomcat, which will be shown if you decide to use that)
Next, ensure that “Always use this server when running this project” is selected and click Finish.
The application should then be built and deployed onto the tc Server.
Once it starts, the Welcome page should load (see Figure 1-14)
Note  You may notice that tc Server takes considerably longer to start than vanilla Tomcat as it initializes various sub-components.
Editing the Application Congratulations on getting this far! Was it worth it? The authors think so.
To demonstrate the power of STS, let’s do some editing.
Don’t worry about the details at this point; they will be explained in detail later.
Now replace (or modify) the code on the IndexController tab, as shown in Listing 1-1
Next, open up index.jsp by using Control-Shift-R to open resources and then typing index.jsp (see Figure 1-16)
Excellent! No redeployments are necessary here because STS automatically deployed the changes you made.
Summary In this chapter, you learned the prerequisites for building and running the sample bookstore application.
You also learned about the supporting technologies used by the sample application (i.e., Hibernate/JPA 2.0 and JSPs)
Next, you learned about Gradle, the build system used to develop the sample application; you also learned how it will help you in your project.
To write and debug code for this book, it is best to use an IDE (integrated development environment)
The authors chose to use STS (SpringSource Tool Suite), installed the Gradle plugin, and then used that plugin to import and build the sample project.
The project was then deployed to the embedded tc Server instance.
You also wrote your first Java code for your MVC application, slightly modifying the basic code for this chapter and using that to explore the automatic redeploy features of the embedded server.
In the next chapter, you will improve on this application as you get a better understanding of the inner workings of Spring MVC.
The framework combines best practices for Java Enterprise Edition (JEE) development from the industry and integration with the best-of-breed third-party frameworks.
It also provides easy extension points to write your own integration if you need one that doesn’t yet exist.
The framework was designed with developer productivity in mind, and it makes it easier to work with the existing, sometimes cumbersome Java and JEE APIs.
Before we start our journey into Spring MVC and Spring Web Flow, we will provide a quick refresher course on Spring Core (formerly known as the Spring Framework)
Spring is now a longtime de-facto standard for Java enterprise software development.
In this chapter, we will cover dependency injection and AOP.
Specifically, we will cover how the Spring Framework helps us implement dependency injection and how to use programming to our advantage.
To be able to do the things mentioned here, we will explore the Inversion of Control (IoC) container; the application context.
We will only touch on the necessary basics of the Spring Framework here.
Let’s begin by taking a quick look at the Spring Framework and the modules that comprise it.
Tip  You can find the sample code for this chapter in the chapter2-samples project.
Different parts of the sample contain a class with a main method, which you can run to execute the code.
This book was written to explain some of the complexities in JEE and how to overcome them.
And while many of the complexities and problems in JEE have been solved in the newer JEE specifications (especially since JEE 6), the Spring Framework remains very popular.
It also offers a consistent programming model for different kinds of technologies, be they for data access or.
The framework allows developers to target discrete problems and build solutions specifically for them.
The framework consists of several modules (see Figure 2-1) that work together and build on each other.
We can pretty much cherry pick the modules we want to use.
All of the modules from Figure 2-1 are represented as jar files that we can include on the classpath if we need a specific technology.
The name of the actual jar file might differ, depending on how one obtains the module.
Instrumentation spring-instrument Instrumentation classes to be used with a Java agent.
Struts spring-struts Support package for integrating Spring with Struts 1.x applications.
Web spring-web Core web package for use in any web environment.
Servlet spring-webmvc Spring MVC support package for use in a Servlet environment.
Most of the modules have a dependency on some other module in the Spring Framework.
Figure 2-2 gives an overview of the commonly used modules and their dependencies on other modules.
Notice that the instrumentation, aspect, and test modules are missing from the figure; this is because their dependencies depend on the project and what other modules are used.
The Spring Framework has only one required dependency: commons-logging, a logging abstraction framework.
The other dependencies differ based on the needs of the project.
Dependency Injection The concept of dependency injection (DI), objects are given their dependencies at construction time, is one of the foundations of the Spring Framework.
You have also probably heard of Inversion of Control (IoC)1
IoC is a broader, more general concept that can be addressed in different ways.
IoC lets developers decouple and focus on what is important for a given part of an enterprise application, but without having to think about what other parts of the system do.
Programming to interfaces is one way to think about decoupling.
Almost every enterprise application consists of multiple components that need to work together.
In the early days of Java enterprise development, we simply put all the logic of constructing those objects (and the objects those objects needed) in the constructor (see Listing 2-1)
At first sight, there is nothing wrong with that approach; however, as time progressed, object construction became slow, and objects had a lot of knowledge they shouldn’t have had (see the Single Responsibility Principle2)
Those classes became hard to maintain, and they were also quite hard to unit and/or integration test.
The class from Listing 2-1 programs to interfaces, but it still needs to know about the concrete implementation of an interface simply to do object construction.
Applying IoC by decoupling the construction logic (collaborating objects) makes the application easier to maintain and increases testability.
There are seven ways to decouple this dependency construction logic:
When using the factory pattern, service locator pattern, or contextualized lookup, the class that needs the dependencies still has some knowledge about how to obtain the dependencies.
This can make things easier to maintain, but it can still be hard to test.
Listing 2-2 shows a contextualized lookup from JNDI (Java Naming and Directory Interface)
The constructor code would need to know how to do the lookup and handle exceptions.
The immediately preceding code isn’t particularly clean; for example, imagine if there were multiple dependencies from different contexts.
The code would quickly become messy and increasingly hard, if not impossible, to unit test (see Chapter 9 for more information on testing)
We simply pass the object the dependencies it needs to do its work.
This makes our code clean, decoupled, and easy to test (see Listing 2-3)
Dependency injection is a process where objects specify the dependencies they work with.
The IoC container uses that specification; when it constructs an object, it also injects its dependencies.
This way our code is cleaner, and we no longer burden our class with construction logic.
It is easier to maintain and also easier to unit and/or integration test.
Testing is easier because we could inject a stub or mock object to verify the behavior of our object.
As the name implies, constructor-based dependency injection uses the constructor to inject the dependencies in the object.
Setter-based dependency injection uses a setter method to inject the dependency.
If we have a method named setAccountService, then we set a property with the name, accountService.
For this to work, we do not need to specify a constructor argument or a setter method to set the dependencies.
We begin by defining a class-level field that can hold the dependency.
Next, we put an annotation on that field to express our intent to have that dependency injected into our object.
All these annotations more or less work in the same way.
Note that interface-based dependency injection isn’t supported by the Spring Framework.
This means that we need to specify which concrete implementation to inject for a certain interface.
Note  Google Guice4 supports interface-based injection out of the box.
To sum things up, we want to use dependency injection for the following reasons:
The first two reasons make our code easier to maintain.
The fact that the code is easier to test should allow us to write unit tests to verify the behavior of our objects—and thus, our application.
After seeing three different approaches to dependency injection, you may wonder which one we should use.
That is more or less a philosophical discussion, but here’s a rule of thumb we can use: if a.
If we use annotation-based dependency injection and the dependency wouldn’t be injected, we would get an exception at the startup of our application.
This is because, by default, the dependencies are mandatory when using annotation-based dependency injection.
In light of recent developments and additions to Java and JEE, the authors of this book believe that the annotation-based approach is the best way to go.
In this book, we will use a Java-based configuration approach wherever possible.
If a Java-based configuration option isn’t possible or available, we will fall back to an XML-based configuration.
At the time of writing, web flow hasn’t been updated so it can benefit from a Java-based configuration approach.
The application context is responsible for managing the beans defined in it.
It also enables more elaborate things like applying AOP to the beans defined in it.
The most well-known way is to use one or more XML files; however, we could also use a properties file or Java classes.
In general, it is best to stick with a single approach.
Doing so makes it easier to understand and figure out what your configuration is.
This also removes the need to hunt down Java, XML, and properties files.
Each of these implementations provides the same features, but differs in how it loads the application context configuration.
As mentioned previously, the different implementations have different configuration mechanisms (i.e., XML or Java)
Table 2-2 shows the default configuration options and indicates the resource loading location.
The first stereotypes our class as a configuration file, while the second indicates that the result of the method is to be used as a factory to create a bean.
The name of the bean is, by default, the method name.
We could also explicitly specify a bean name by setting the name attribute on the Bean annotation.
Caution  Configuration classes can be abstract; however, they cannot be final.
To parse the class, Spring will create a dynamic subclass of the configuration class.
Having a class with only the Configuration annotation isn’t enough.
The process is similar for an XML-based approach, which loads the XML file from the classpath.
We included both approaches to highlight the differences between the XML- and Java-based configurations; however, nothing changes in the resulting application or its execution.
Finally, note that application contexts can be in a hierarchy.
We can have an application context that serves as a parent for another context (see Figure 2-4)
An application context can only have a single parent, but it can have multiple children.
Child contexts can access beans defined in the parent context; however, parent beans cannot access beans in the child contexts.
For example, if we enable transactions in the parent context, this won’t apply to child contexts (see the “Enabling Features” section later in this chapter)
This feature allows us to separate our application beans (e.g., services, repositories, and infrastructure) from our web beans (e.g., request handlers and views)
For example, assume that multiple servlets need to reuse the same application beans.
Instead of recreating them for each servlet, we can simply reuse the already existing instances.
This can be the case when there is one servlet handling the web UI and another that is handling the web services.
Resource Loading Table 2-2 provided an overview of the different ApplicationContext implementations and the default resource loading mechanisms.
However, this doesn’t mean that we are restricted to loading resources only from the default locations.
We also have the option to load resources from specific locations by including the proper prefix (see Table 2-3)
Listing 2-7 shows bootstrapping code that uses an application context implementation that loads.
We could also have used an implementation that loads from the file system by default, but loads from the classpath when the proper prefix is used (see Listing 2-8)
In addition to being able to specify where to load files from, we can also use ant-style regular expressions to specify which files to load.
This technique will only work when dealing with file resources on the classpath or file system; it will not work for web resources or package names.
This annotation needs to be put on our configuration class to enable component-scanning.
A look at Listing 2-9 reveals that the class has no more content.
One annotation indicates that this class is used for configuration, while the other enables componentscanning.
The component-scan annotation is configured with a package to scan.
Caution  It is considered bad practice to scan the whole classpath by not specifying a package or to use too broad a package (like com.apress)
This can lead to scanning a large part or even all classes, which will severely impact the startup time of your application.
If we’re using component-scanning and a class with the Configuration annotation is found, then it will be used to add more beans to the context.
In general, these are beans that cannot be automatically created, like datasources or JMS configuration.
Scopes By default, all beans in a Spring application context are singletons.
As the name implies, there is a single instance of a bean, and it is used for the whole application.
This doesn’t typically present a problem because our services and repositories don’t hold state; they simply execute a certain operation and (optionally) return a value.
However, a singleton would be problematic if we wanted to keep state inside our bean.
We are developing a web application that we hope will attract thousands of users.
If we have a single instance of a bean and all those users operate on the same instance, then the users will see and modify each other’s data or data from several users combined.
Fortunately, Spring provides several scopes for beans that we can use to our advantage (see Table 2-5)
A single instance of a bean is created and shared throughout the application.
If the request is over, the bean instance is destroyed.
When the session is destroyed, so is the bean instance.
If no such session is available, the scope reverts to the session scope functionality.
Profiles Spring introduced the concept of profiles in version 3.1
Profiles make it easy to create different configurations of our application for different environments.
For instance, we can create separate profiles for our local environment, for testing, and for our deployment to CloudFoundry.
One can think of database configuration; messaging solutions; and for testing environments, stubs of certain beans.
To enable a profile, we need to tell the application context which profiles are active.
This is a comma-separated string containing the names of the active profiles.
In general, we will not be setting the active profiles from our bootstrap code.
Instead, we will set up our environment using a combination of system variables.
This enables us to leave our application unchanged, but still have the flexibility to change our runtime configuration.
This means that our entire configuration is under version control and in the same source code, instead of being spread out over different servers, workstations, and so on.
Of course, we can still load additional files containing some properties (like usernames and passwords)
This can prove useful if a company’s security policy won’t allow us to put these properties into version control.
We are going to use profiles extensively when we cover testing and deploying to the cloud because the two tasks require different configurations for the datasource.
Enabling Features The Spring Framework gives us a lot more flexibility than just dependency injection; it also provides a lot of different features we can enable.
We can enable these features using annotations (see Table 2-6)
Note that we won’t use all of the annotations mentioned in this table; however, our sample application will use transactions, and we will use some AOP.
By default, Spring uses a proxy-based approach to AOP; however, this annotation enables us to switch to load-time weaving.
Enables support for applying dependency injection to non-Spring managed beans.
This feature requires load-time or compile-time weaving because it needs to modify class files.
Enables support for the powerful and flexible annotation-driven controllers with request handling methods.
Note  For more information on these features, we recommend that you examine the Java documentation of the different annotations, as well as the dedicated reference guide chapters.
Aspect-Oriented Programming To enable the features listed in Table 2-4, Spring uses aspect-oriented programming (AOP)
It enables you to modularize things like transaction management or performance logging, features that span multiple types and objects (crosscutting concerns)
In AOP, there are a couple important concepts to keep in mind (see Table 2-7)
Join Point A point during the execution of a program.
This can be the execution of a method, the assignment of a field, or the handling of an exception.
In Spring, a join point is always the execution of a method!
Advice The specific action taken by an aspect at a particular join point.
There are several types of advice: before, after, after throwing, after returning, and around.
In Spring, an advice is called an interceptor because we are intercepting method invocations.
The advice is associated with a pointcut expression and runs at any join point matching the pointcut.
Now let’s take a look at transaction management and how Spring uses AOP to apply transactions.
To do this, Spring creates a wrapper around the actual object, which is known as a proxy (see Figure 2-5)
A proxy acts like an enclosing object, but it allows (dynamic) behavior to be added (in this case the transactionality of the method)
At this point, the interceptor is ready for us to use.
The other annotations for enabling features work in a similar way; they register beans to enable the desired feature, including AOP (and thus proxy creation) for most features.
Web Applications So how does all the aforementioned technology apply to a web application? For example, how do application contexts play a role? And what about all the other things mentioned?
When developing a web application, we have our actual business logic (e.g., our services, repositories, and infrastructure information), and we have our web-based beans.
These things should be separated, so we need to have multiple application contexts and have a relationship between them.
We also need code that bootstraps our application, or else nothing will happen.
This is not something we can do in a web environment.
Let’s take a look at the class that configures DispatcherServlet.
Next, we map the servlet to everything (the “/”) and tell it to load on startup.
This listing also shows our JPA entity manager, including its annotation-based transaction support.
Summary In this chapter, we covered the bare basics of Spring Core.
We reviewed the concept of dependency injection and briefly covered three different versions of dependency injection.
We also explained the different types of application contexts (e.g., XML or Java based) and the resource loading in each of them.
We also covered how, by default, beans in an application context are singleton scoped.
Fortunately, Spring provides us with additional scopes, such as request, session, globalSession, prototype, application, and thread.
To be able to use different configurations in different environments, Spring also includes profiles.
We briefly explained both how to enable profiles and how to use them.
We will use profiles in our sample application when we test it (see Chapter 9) and when we deploy it to Cloud Foundry (see Appendix A)
We also delved into the way several enabling annotations are required for Spring to enable certain features.
These annotations register additional beans in the application context that enable the desired feature.
Most of these features rely on AOP to be enabled (e.g., to do declarative transaction management)
Spring creates proxies to apply AOP to beans registered in our application contexts.
In the next chapter, we will look at the architecture of an MVC web application, the different layers, and what roles they play in our application.
Before we start our journey into the internals of Spring MVC, we first need to understand the different layers of a web application.
And we’ll begin that discussion with a brief introduction of the MVC pattern in general, including what it is and why should we use it.
We will also cover some of the interfaces and classes provided by the Spring Framework to express the different parts of the MVC pattern.
After reviewing the MVC Pattern, we will go through the different layers in a web application and see what role each layer plays in the application.
We will also explore how the Spring Framework can help us out in the different layers and how we can use it to our advantage.
At that time, the pattern was aimed at desktop applications.
This pattern divides the presentation layer into different kinds of components.
Based on a user action, the view triggers the controller, which in turn updates the model.
The model then notifies the view to (re)render itself (see Figure 3-1)
As we mentioned previously, each component has its own role (see Table 3-1)
Separation of concerns is important in the presentation layer because it helps us keep the different components clean.
This way, we don’t burden the actual view with business.
Following this approach keeps everything nicely separated, which makes it easier to maintain and test our application.
Model The model is the data needed by the view so that it can be rendered.
It might be an order placed or a list of books requested by a user.
View The view is the actual implementation, and it uses the model to render itself in a web application.
This could be a JSP or JSF page, but it could also be a PDF or XML representation of a page.
Controller The controller is the component that is responsible for responding to the action the user takes, such as form submission or clicking a link.
The controller updates the model and takes other actions needed, such as invoking a service method to place an order.
The classic implementation of the MVC pattern (as shown in Figure 3-1) involves the user triggering.
This prompts the controller to update the model, which in turn pushes the changes back to the view.
The view then updates itself with the updated data from the model.
This is the ideal implementation of an MVC pattern, and it works very well in desktop applications based on Swing, for example.
However, this approach is not feasible in a web environment due to the nature of the HTTP protocol.
For a web application, the user typically initiates action by issuing a request.
This prompts the app to update and render the view, which is sent back to the user.
This means that we need a slightly different approach in a web environment.
Instead of pushing the changes to the view, we need to pull the changes from the server.
This approach seems quite workable, but it isn’t as straightforward to apply in a web application as one might think.
The Web (or HTTP) is stateless by design, so keeping a model around can be quite difficult.
These controllers handle the incoming request, return the model, and select the view.
The front controller is the component that handles the incoming requests.
When that controller has finished processing and updating the model, the front controller will determine which view to render based on the outcome.
Application Layering In the introduction, we mentioned that an application consists of several layers (see Figure 4-3)
We like to think of a layer as an area of concern for the application.
Therefore, we also use layering to achieve separation of concerns.
For example, the view shouldn’t be burdened with business or data access logic because these are all different concerns and typically located in different layers.
Layers should be thought of as conceptual boundaries, but they don’t have to be physically isolated from each other (in another virtual machine)
For a web application, the layers typically run inside the same virtual machine.
Figure 3-3 is a highly generalized view of the layers of a Spring MVC application.
The data access is at the bottom of the application, the presentation is on top, and the services (the actual business logic) are in the middle.
In this chapter, we will take a look at this architecture and how everything is organized.
Table 3-2 provides a brief description of the different layers.
Service The entry point to the actual system containing the business logic.
It provides a coarsegrained interface that enables use of the system.
This is also the layer that should be the transactional boundary of the system (and probably security, too)
This layer shouldn’t know anything (or as little as possible) about persistence or the view technology used.
Data Access An interface-based layer that provides access to the underlying data access technology, but without exposing it to the upper layers.
This layer abstracts the actual persistence framework (e.g., JDBC, JDO, or JPA)
If you see these kinds of circular dependencies creep into your application, take a few steps back and reconsider your design.
Circular dependencies (or bottom to top dependencies) are almost always a sign of bad design and lead to increased complexity and a harder-to-maintain application.
Many people use tier and layer interchangeably; however, separating the two helps when discussing the application architecture or its deployment.
We like to use layer to indicate a conceptual layer in the application, whereas a tier indicates the physical separation of the layers on different machines at deployment time.
Thinking in layers helps the software developer, whereas thinking in tiers helps the system administrator.
Although Figure 3-3 gives a general overview of the layers for a web application, we could break it down a little further.
In a typical web application, we can identify five conceptual layers (see Figure 3-4)
We can split the presentation layer into a web and user interface layer, but the application also includes a domain layer (see the “Spring MVC Application Layers” section later in this chapter)
Typically, the domain layer cuts across all layers because it is used everywhere from the data access layer to the user interface.
Note  The layered architecture isn’t the only application architecture out there; however, it is the most frequently encountered architecture for web applications.
If we look at the sample application, the architecture shown in Figure 3-4 is made explicit in the package structure.
The packages can be found in the bookstore-shared project (see Figure 3-5)
Separation of Concerns As we mentioned in Chapter 2, it is important to have a clear separation of concerns.
If we look at the architecture from Figure 3-4, the separation of concerns is present in the layers.
Separating the concerns into different layers helps us achieve a clean design, as well as a flexible and testable application.
A rule of thumb is that, if a layer has too many dependencies with other layers, we might want to introduce another layer that incorporates all the dependencies.
On the other hand, if we see a single layer throughout different layers, we might want to reconsider this layer and make it an aspect of the application.
In this case, we can use the AOP functionality from the Spring Framework to apply these aspects at runtime (see Chapter 2)
Coupling layers—for example, the service layer will need to talk to the data access layer—is done by defining clear interfaces.
Defining interfaces and programming to interfaces reduces the actual coupling to concrete implementations.
This reduced coupling and reduced complexity results in an easier-to-test and easier-to-maintain application.
Another benefit of using interfaces is that Spring can use JDK Dynamic Proxies2 to create proxies and apply AOP.
Note  Spring can also apply AOP on class-based proxies; however, this requires the cglib library (http://cglib.sourceforge.net) on the classpath.
The point is this: layering in an application leads to a more maintainable and testable application.
A clear separation of concerns also leads to good application architecture.
Spring MVC Application Layers You might wonder how all the layers fit into a Spring MVC application, as well as how all the different layers help us build our Spring MVC application.
In this section, we will take a look at the five layers depicted in Figure 3-4
We will pay particular attention to the roles the different layers play and what should be in each.
The Domain Layer The domain is the most important layer in an application.
It is the code representation of the business problem we are solving, and it contains the business rules of our domain.
These rules might check whether we have sufficient funds to transfer money from our account or ensure that fields are unique (e.g., usernames in our system)
A popular technique to determine the domain model is to use the nouns in use case descriptions as domain objects (e.g., Account or Transaction)
These objects contain both state (e.g., the username for the Account) and behavior (e.g., a credit method on the Account)
These methods are typically more finegrained then the methods in the service layer.
This is not to be confused with an anemic domain model3, in which our domain objects only hold state and have no behavior.
In general, your domain model will not need dependencies injected; however, it is still possible to do this.
For example, it’s possible to use the Spring Framework and AspectJ to enable dependency injection in our domain objects.
Next, we would need to set up load-time weaving or compile-time weaving, and we would have our dependencies injected.
For more detailed information on the subject, please see the Spring Reference Guide4
It uses a rich domain model, as advocated by Eric Evans6
The User Interface Layer The user interface layer presents the application to the user.
This layer renders the response generated by the server into the type requested by the user’s client.
For instance, a web browser will probably request an HTML document, a web service may want an XML document, and another client could request a PDF or Excel document.
We separated the presentation layer into a user interface and web layer because, notwithstanding the wide range of different view technologies, we wanted to reuse as much code as possible.
There are many different view technologies out there, including JSP(X), JSF, Velocity, and Freemarker, to name a few.
In an ideal world, we would be able to switch our user interface without changing the backend of our application.
Spring MVC helps us in isolating the user interface from the rest of the system.
This interface is responsible for transforming the result of the action from the user (the model) into the type of response the user requested.
The View interface is generic, and it has no dependencies on a particular view technology.
For each supported view technology, there is an implementation provided either by the Spring Framework itself or by the view technologies themselves.
Out of the box, Spring supports the following view technologies:
The user interface in general has a dependency on the domain layer.
Sometimes, it is convenient to directly expose and render the domain model.
This can be especially useful when we start to use forms in our application.
For example, this would let us work directly with the domain objects instead of an additional layer of indirection.
Some argue that this creates an unnecessary or unwanted coupling between layers.
However, the creation of another layer for the sole purpose of decoupling the domain from the view leads to unnecessary complexity and duplication.
In any case, it is important to keep in mind that Spring MVC doesn’t requires us to directly expose the domain model to the view—whether we do so is entirely up to us.
The first responsibility is to guide the user through the web application.
The second is to be the integration layer between the service layer and HTTP.
Navigating the user through the website can be as simple as mapping a URL to views or a full-blown page flow solution like Spring Web Flow.
The navigation is typically bound to the web layer only, and there isn’t any navigation logic in the domain or service layer.
As an integration layer, the web layer should be as thin as possible.
It should be the layer that converts the incoming HTTP request to something that can be handled by the service layer, and then transforms the result (if any) from the server into a response for the user interface.
The web layer should not contain any business logic—that is the sole purpose of the service layer.
The web layer also consists of cookies, HTTP headers, and possibly an HTTP session.
It is the responsibility of the web layer to manage all these things consistently and transparently.
The different HTTP elements should never creep into our service layer.
If they do, the whole service layer (and thus our application) becomes tied to the web environment.
Doing this makes it harder to maintain and test the application.
Keeping the service layer clean also allows us to reuse the same services for different channels.
For example, it enables us to add a web service or JMS-driven solution.
The web layer should be thought of as a client or proxy that connects to the service layer and exposes it to the end users.
In the early days of Java web development, servlets or Java Server Pages mainly implemented this layer.
The servlets had the responsibility of processing and transforming the request into something the service layer could understand.
More often than not, the servlets wrote the desired HTML directly back to the client.
This kind of implementation quickly became hard to maintain and test.
After a couple of years, the Model 2 MVC pattern emerged, and we finally had advanced MVC capabilities for the Web.
Frameworks like Spring MVC, Struts, JSF, and Tapestry provide different implementations for this pattern, and they all work quite differently.
However, we can identify two main types of web layer implementations: request/response frameworks (e.g., struts and Spring MVC) and component-based frameworks (e.g., JSF and Tapestry)
Thus, the fact that they operate on the Servlet API isn’t really hidden from the user.
They try to hide the Servlet API from the programmer and.
Using a component-based framework feels a lot like working with a Swing desktop application.
Spring MVC is quite powerful, and it strikes a good balance between the two.
It can hide the fact that one works with the Servlet API; however, when needed, it is quite easy to access that API (among other things)
The web layer depends on the domain layer and service layer.
In most cases, you want to transform the incoming request into a domain object and call a method on the service layer to do something with that domain object (e.g., update a customer or create an order)
Spring MVC makes it easy to map incoming requests to objects, and we can use dependency injection to access the service layer.
The interface-based approach is historic, and it has been part of the Spring Framework since its inception; however, it is now considered dated.
Regardless, it remains useful for simple use cases, and Spring provides some convenient implementations out of the box.
The new annotation-based approach is more powerful and flexible than the original interface-based approach.
The main focus in this book is on the annotation-based approach.
Caution  Don’t use the Controller annotation on a class with the Controller interface.
These are handled differently, and mixing both strategies can lead to surprising and unwanted results!
The Service Layer The service layer is a very important layer in the architecture of an application.
It can be considered the heart of our application because it exposes the functionality (the use cases) of the system to the user.
It does this by providing a coarse-grained API (as mentioned in Table 3-2)
This listing is considered coarse grained because it takes a simple method call from the client to complete a single use case.
This is in contrast to the code in Listing 3-2 (fine-grained service methods), which requires a couple of calls to perform a use case.
The added benefit of having a single point of entry and coarse-grained methods on the service layer is that we can simply apply transactions and security at this layer.
We don’t have to burden the different clients of our application with the security and transactional requirements.
It is now part of the core of the system and generally applied through the use of AOP.
In a web-based environment, we probably have multiple users operating on the services at the same time.
The service must be stateless, so it is a good practice to make the service a singleton.
In the domain model, state should be kept as much as possible.
Keeping the service layer stateless provides an additional benefit: it also makes the layer thread safe.
Keeping the service layer to a single point of entry, keeping the layer stateless, and applying transactions and security on that layer enable us to use other features of the Spring Framework to expose the service layer to different clients.
For example, we could use configuration to easily expose our service layer over RMI or JMS.
In most cases, it takes a single method call to execute a single use case (e.g., createOrder)
As Listing 3-3 demonstrates, the service layer depends on the domain layer to execute the business logic.
However, it also has a dependency on the data access layer to store and retrieve data from our underlying data store.
The service layer can serve as the glue between one or more domain objects to execute a business function.
The service layer should coordinate which domain objects it needs and how they interact together.
The Spring Framework has no interfaces that help us implement our service layer; however, this shouldn’t come as a surprise.
The service layer is what makes our application; in fact, it is specialized for our application.
Nevertheless, the Spring Framework can help us with our architecture and programming model.
We can use dependency injection and apply aspects to drive our transactions.
All of this has a positive influence on our programming model.
The Data Access Layer The data access layer is responsible for interfacing with the underlying persistence mechanism.
This layer knows how to store and retrieve objects from the datastore.
It does this in such a way that the service layer doesn’t know which underlying datastore is used.
The datastore could be a database, but it could also consist of flat files on the file system.
There are several reasons for creating a separate data access layer.
First, we don’t want to burden the service layer with knowledge of the kind of datastore (or datastores) we use; we want to handle persistency in a transparent way.
In our sample application, we use an in-memory database and JPA (Java Persistence API) to store our data.
We could simply create a new implementation of the interface that knows how to deal with Active Directory—all without changing our service layer.
In theory, we could swap out implementations quite easily; for example, we could switch from JDBC to Hibernate without having to change the service layer.
It is quite unlikely that this will happen, but it is nice to have this ability.
The most important reason for this approach is that it simplifies testing our application.
In general, data access is slow, so it is important that we keep our tests running as fast as possible.
A separate data access layer makes it quite easy to create a stub or mock implementation of our data access layer.
The Spring Framework has great support for data access layers.
For example, it provides a consistent and transparent way to work with a variety of different data access frameworks (e.g., JDBC, JPA, Hibernate, iBATIS, and JDO)
Each of these technologies Spring provides extensive support for the following abilities:
The transaction management is transparent for each technology it supports.
There is a transaction manager that handles the transactions, and it even has support for JTA (Java Transaction API), which enables distributed or global transactions.
This excellent transaction support means that the transaction manager can also manage the resources for us.
We no longer have to worry that a database connection or file handle might be closed; this is all handled for us.
For several use cases, it can even eliminate the need to write our own implementation of a data access object (DAO) or repository.
The Spring Framework includes another powerful feature as part of its data access support: exception translation.
Spring provides extensive exception translation support for all its supported technologies.
For database-driven technologies, it can even take into account the database vendor, version, and error codes received from the database.
The exception hierarchy extends from RuntimeException; and as such, it doesn’t have to be caught because it isn’t a.
Listing 3-4 shows how a data access object or repository might look.
Note that the interface doesn’t reference or mention any data access technology we use (we use JPA for the sample application)
Also, the service layer doesn’t care how or where the data is persisted; it simply wants to know how to store or retrieve it.
More Roads to Rome As noted previously, the architecture discussed here isn’t the only application architecture out there.
Which architecture is best for a given application depends on the size of the application, the experience of the development team, and the lifetime of the application.
The larger a team or the longer an application lives, the more important a clean architecture with separate layers becomes.
A web application that starts with a single static page probably doesn’t require any architecture.
However, as the application grows, it becomes increasingly important that we don’t try to put everything in that single page because that would make it very difficult to maintain or understand the app, let alone test it.
As an application grows in size and age, we need to refactor its design and keep in mind that each layer or component should have a single responsibility.
If we detect some concern that should be in a different layer or touches multiple components, then we should convert it into an aspect (crosscutting concern) of the application and use AOP to apply this aspect to the code.
When deciding how to structure our layers, we should try to identify a clear API (exposed through Java interfaces) for our system.
Thinking of an API for our system makes us think about our design, as well as a useful and useable API.
In general, if an API is hard to use, it is also hard to test and maintain.
In addition, using interfaces between the different layers allows for the separate layers to be built and tested in isolation.
This can be a great advantage in larger development teams (or in teams that consists of multiple smaller teams)
It allows us to focus on the function we’re working with, not on the underlying or higher level components.
When designing and building an application, it’s also important to use good OO practices and patterns to solve problems.
For example, we should use polymorphism and inheritance to our advantage, and we should use AOP to apply system-wide concerns.
The Spring Framework can also help us wire our application together at runtime.
Taken as a whole, the features and approaches described in this chapter can help us to keep our code clean and to achieve the best architecture for our applications.
Summary In this chapter, we covered the MVC pattern, including its origins and what problems it solves.
We also briefly discussed the three components of the MVC pattern: the model, view, and controller.
We identified the five different layers generally available in a web application: domain, user interface, web, service, and data access.
All of these layers play an important role in our application, and we discussed both what these roles are and how they fit together.
We also covered how Spring can help us out in the different layers of an application.
The main take away from this chapter is that the various layers and components in the MVC pattern can help us separate the different concerns.
Each layer should have a single responsibility, be it business logic or the glue between the HTTP world and the service layer.
Separation of concerns helps us both achieve a clean architecture and create maintainable code.
Finally, clean layering makes it easier to test our application.
In the next chapter, we will drill down on the Spring MVC.
Specifically, we will explore the DispatcherServlet servlet, including how it works and how to configure it.
We will also take a closer look at how the different components described in this chapter work in a Spring MVC application.
You will begin by learning how an incoming request is handled by the servlet, as well as how to identify which components play a role in the request handling.
After these components have been identified, you will go deeper into the roles and functions of the different components and the different implementations of those components.
DispatcherServlet Request Processing Workflow In the previous chapter, you learned about the important role the front controller plays in a Model 2 MVC pattern.
The front controller takes care of dispatching incoming requests to the correct handler and prepares the response, so that it can be rendered into something that the user would like to see.
All these components are expressed as interfaces, for which one or more implementations are available.
The next section will explore the general role these components play in the request processing workflow.
Another upcoming section will cover the different implementations of the interfaces.
The Workflow A high-level overview of the request processing workflow is illustrated in Figure 4-1
In the previous chapters, you learned about the importance of separation of concerns.
Within the Spring Framework, the same rules have been applied.
A lot of supporting components have been designed as interfaces with extensibility as well as separation of concerns in mind.
Although the high level overview in Figure 4-1 is correct, there is more happening behind the scenes.
Figure 4-2 shows a more complete view of the request processing workflow.
Figure 4-2 provides a global overview of the request processing workflow inside the DispatcherServlet.
The following sections will zoom in on the different steps in this flow.
Prepare a Request Before the DispatcherServlet will start dispatching and handling the request, it first does some preparation and preprocessing of the request.
This gives the framework code easy access to the current request, instead of passing it around.
This map contains attributes that were explicitly stored in the previous request.
In general, this is used when a redirect is made to go to the next page.
Next, the incoming request is checked for whether it is a multipart HTTP request (this is used when doing file uploads)
After this, the request is ready to be dispatched to the correct handler.
Figure 4-3 shows a flow diagram of the first part of the request processing workflow.
If no handler is found, an HTTP 404 response is send back to the client.
If the code executes successfully, the interceptors are called again; and finally, when needed, the view is rendered (see Figure 4-5)
The execution of the handler is delegated to the selected HandlerAdapter that was determined in the previous step.
The resolver can translate the exception to a view to show the user.
For instance, if there is an exception related to database errors, you could show a page indicating the database is down.
If the exception isn’t resolved, it is rethrown and handled by the servlet container, which generally results in an HTTP 500 response code (internal server error)
Figure 4-6 shows this part of the request processing workflow.
Finish the Processing Each incoming request passes through this step of the request processing flow, regardless of whether there are exceptions.
Only the interceptors where the preHandle method was successfully invoked will have their afterCompletion method called.
Next, these interceptors are executed in the reverse order that their preHandle method was called.
This mimics the behavior seen in servlet filters, where the first filter called is also the last one to be called.
This flexibility comes from the fact that the servlet uses a lot of different components to fulfill its role, and these components are expressed as interfaces.
Table 4-1 gives an overview of all the main component types involved in the request processing workflow.
Strategy for the handler object type to execute the handler.
Strategy to determine a view name when the handler returns none.
Strategy to translate the view name to an actual view implementation.
In the upcoming sections, you will see how to configure the DispatcherServlet.
First, you need to tell the container to load a servlet and map it to one or more Urlpatterns.
The servlet will try to detect the needed components from this application context and if not found, it will use some kind of default (in most cases)
Bootstrapping the DispatcherServlet The Servlet 3.0 specification introduced several options for configuring and registering a servlet:
All these configurations lead to the same runtime setup of the servlet.
Only the mechanism by which you do that is different.
The remainder of the book will use Option 4 to configure the sample application.
The sample application that you are building throughout the book will use Option 4 as much as possible to configure the environment and application.
Nevertheless, you will learn the basic setup for all four options of configuring the servlet.
Using web.xml The web.xml file has been around since the inception of the servlet specification.
It is an XML file that contains all the configuration you need to bootstrap the servlet, listeners, and/or filters.
Listing 4-1 shows the minimal web.xml required to bootstrap the DispatcherServlet.
The web.xml file must be in the WEB-INF directory of the web application (this is dictated by the servlet specification)
Adding this attribute to your web.xml can increase startup times considerably because it will scan the classpath, which can take quite some time in a large application.
Using web-fragment.xml The web-fragment.xml feature has been available since the 3.0 version of the servlet specification, and it allows for a more modularized configuration of the web application.
The web-fragment.xml has to be in the META-INF directory of a jar file.
It isn’t detected in the META-INF of the web application; it has to be in a jar file.
The web-fragment.xml can contain the same elements as the web.xml (see Listing 4-2)
The benefit of this approach is that each module, packaged as a jar files can contribute to the configuration of the web application.
This can also be considered a drawback because now you have scattered your configuration over your code base, which could be troublesome in larger projects.
Using Java gives you all the added benefits of using the Java language instead of XML.
At this point, you have strong typing, can influence the construction of your servlet, and have an easier way of configuring your servlets (in an XML file, this is done by adding init-param and/or context-param elements in the XML file)
The first step is to configure the behavior of the servlet by setting properties directly on the dispatcher servlet (the declaration).The second step is to configure the components in the application context (initialization)
The dispatcher servlet comes with a lot of default settings for components.
This saves you from doing a lot of configuration for basic behavior, and you can override and extend the configuration however you want.
Dispatcher Servlet Properties The dispatcher servlet has a number of properties that can be set.
All these properties have a setter method, and all can be either set programmatically or set when using XML configuration by including a servlet initialization parameter.
Table 4-2 lists and describes the properties available on the dispatcher servlet.
In general, the default suffices, and this property should only be set to false in special cases.
This is useful if the application context is created by some means other than the servlet itself.
This isn’t needed if you pass in an application context by using the constructor.
Indicates the location of the configuration files for the specified application context class.
For example, this is used when the context is logged or sent to System.out.
When set to false, a single one is detected by using the name, handlerAdapter.
When set to false, a single one is detected by using the name, handlerMapping.
When set to false, a single one is detected by using the name, viewResolver.
The default is false; when set to true, you can also handle HTTP OPTIONS requests.
The default is false; when set to true, you can also handle HTTP TRACE requests.
The environment specifies which profile is active and can hold properties specific for this environment.
For production, it is recommended that you set this to false.
You can either let the servlet construct one itself or use the constructor to pass an application context.
In an XML-based configuration file, the first option is used (because there is no way to construct an application context)
To enable Java-based configuration, you need to instruct the servlet to use a Java-based application context (the default is an XML-based one), as well as pass it the configuration classes.
This is the most basic way of configuring the servlet.
This is useful in a web application when you want to configure or set the profile(s) you want to use (again, see Chapter 2 for more information)
For instance, you might have a custom system property you need to set.
Alternatively, you might detect the profile by reading a certain file on the file system or even select a profile based on the operation system.
In Appendix A, you will learn how to deploy your application to CloudFoundry.
This implementation detects that it is running on the cloud and activates a profile named cloud (see Listing 4-6)
Component Resolution When the servlet is configured, it will receive an initialization request from the servlet container.
When the servlet initializes, it uses the logic, as depicted in Figure 4-9, to detect the components needed.
Some components are detected by type, whereas others are detected by name.
For the components detectable by type, you can specify (see Table 4-2) that you don’t want to do this.
In this case, the component will be detected by a well-known name.
Table 4-3 lists the different components involved in request processing and the bean name used to detect it.
The table also indicates whether the dispatcher servlet detects multiple instances automatically (when yes can be disabled, then a single bean is detected by the name, as specified in the table)
The Dispatcher Servlet’s Default Configuration You might feel a bit overwhelmed by all the components involved in the handling of a request.
You might even wonder if you need to configure all of them explicitly.
Luckily, Spring MVC has some sensible defaults that, in a lot of cases, are enough—or at least enough to get started.
As you can see in Table 4-4, the dispatcher servlet has quite a few default settings.
You can find more information on the different implementations in the next section.
This annotation enables the powerful and flexible annotation-based request handling components, and it overrides some of the defaults from the dispatcher servlet.
This is the configuration that is registered when the annotation is used.
The differences might not seem that big, but the new components registered provide significantly.
The Spring MVC Components In the previous sections, you learned about the request processing workflow and the components used in it.
In this section, you will take a closer look at all the components involved in the request processing workflow.
For example, you will explore the APIs of the different components and see which implementations ship with the Spring Framework.
HandlerMapping The HandlerMapping’s responsibility is to determine which handler to dispatch the incoming request to.
A criterion that you could use to map the incoming request is the URL; however, implementations (see Figure 4-10) are free to choose what criteria to use to determine the mapping.
It is possible to have more than one handler mapping configured.
The servlet will call the different handler mappings in sequence until one of them doesn’t return null.
Out of the box, Spring MVC provides six different implementations.
Two of the implementations offer a more sophisticated mapping strategy, which you’ll learn about momentarily.
However before looking at the different implementations, it might help to take a closer look at a URL and which parts are important.
Let’s take a look at the http://www.example.org/bookstore/app/home URL and dissect that.
The name of the application (none, if it is the root application)
The name of the servlet mapping (in the sample app, it is mapped to /)
By default, all the provided handler-mapping implementations use the path relative to the servlet context inside the servlet (the servlet context relative path) to resolve handlers.
Setting the alwaysUseFullPath property to true can change this behavior.
The servlet mapping is then included, which would (for the example at hand) lead to /app/home being used to resolve a request handler; otherwise, /home would be used.
A final feature shared among all implementations is that a default handler can be configured.
When no handler can be found for an incoming request, it will always be mapped to the default handler.
This is optional, and it should be used with caution, especially when chaining multiple handler mappings.
Only the last handler mapping should specify a default handler, or else the chain breaks.
This implementation treats any bean with a name that starts with a / as a potential request handler.
A bean can have multiple names, and names can also contain a wildcard, expressed as an *
This implementation uses ant-style regular expressions to match the URL of the incoming request to the name of a bean.
Search all registered paths for a match; the most specific one will win.
If no matches are found, return the handler mapped to /* or to the default handler (if configured)
Note  The name of the bean is not the same as the id.
Id is defined by the XML specification, and it cannot contain special characters such as /
This means you need to use the name of the bean.
A bean can have multiple names, and names can be written like an ant-style regular expression.
Listing 4-8 shows how to use a bean name and map it to the /index.htm url.
In the sample application, you could now use http://localhost:8080/chapter4-bookstore/index.htm to call this controller.
You map the /index.htm URL to the controller named indexController.
If you have a lot of controllers, this configuration grows considerably.
The advantage of this approach is that you have all your mapping in a single location.
This mapping detects all controllers in the application context, takes their names, and prefixes them with a /
Optionally, it can also apply a suffix to the generated URL mapping.
Listing 4-10 shows how to map the controller to /index.htm using this handler mapping.
It takes the simple name of the class, strips the controller part, and makes the remainder lowercase (unless configured otherwise)
Listing 4-11 shows a sample configuration of this implementation, and it will map the controller to the /index URL.
This mapping implementation can be very convenient if you have some naming conventions in your controllers, and they are directly mapped to URLs.
Both are very powerful, and both use annotations to detect mappings.
This annotation can be on either the class and/or the method level.
It removes the actual execution logic from the dispatcher servlet, which makes the dispatcher servlet infinitely extensible.
Consider this component the glue between the servlet and the actual handler implementation.
As Listing 4-14 shows, the API consists of several methods.
The supports method is called on each handler in the context by the dispatcher servlet, and this is done to determine which HandlerAdapter can execute the selected handler.
If the handler adapter can execute the handler, the handle method is called to actually execute the selected handler.
However, some implementations always return null, indicating the response has already been sent to the client.
If the incoming request is a GET or HEAD request, the getLastModified method is called to determine the time when the underlying resource was last modified (-1 means the content is always regenerated)
The result is sent back to the client as a Last-Modified request header and compared with the IfModified-Since request header.
If there was a modification, the content will be regenerated and resent to the client; otherwise, an HTTP Response Code 304 (Not Modified) will be sent back to the client.
This is particularly useful when the dispatcher servlet serves static resources, which will save bandwidth.
Out of the box, Spring MVC provides five implementations of the HandlerAdapter (see Figure 4-12)
This handler adapter is mostly used by Spring Remoting to support some of the HTTP remoting options.
One serves static resources, and the other forwards incoming requests to the default servlet of the servlet container (see Chapter 5 for more information on this implementation)
It converts method arguments and gives easy access to the request parameters.
This whole mapping and converting process is quite rigid; however, there are some extension points that enable customizing or adding your own type handling.
It will convert method arguments and give easy access to the request parameters.
The whole binding and converting process is quite configurable and flexible.
The isMultipart method is invoked to determine whether an incoming request is actually a multipart request.
Finally, when the request has been handled, the cleanupMultipart method is invoked to clean up any used resources.
Figure 4-13 shows the two out-of-the-box implementations of the MultipartResolver.
It enables easy configuration of several aspects of the Commons fileupload library.
In most cases, this is used to resolve validation messages or labels in the application.
The different implementations are shown in Figure 4-14 and described in the following subsections.
The setLocale method is called when you want to change the current locale.
The resolveLocale method is used by the Spring Framework—usually internally—to resolve the current locale.
It uses the Accept-Language HTTP Header to determine the language.
The client sets this header value; this resolver doesn’t support changing the locale.
This is particularly useful in cases where you want an application to be as stateless as possible.
The actual value is stored on the client side, and it is sent to you with each request.
This resolver allows the locale to be changed (you can find more information on this in Chapter 6)
This resolver also allows you to configure the name of the cookie and a default locale to use.
It allows you to configure a locale to use throughout the whole application.
This configuration is fixed; as such, it cannot be changed.
The name of the attribute, as well as a default locale, can be configured.
This resolver also lets you change the locale (see Chapter 6 for more information)
There are several implementations; these are shown in Figure 4-15 and explained in the following subsections.
If no theme name can be resolved, then this resolver uses the hardcoded default theme.
You call the setThemeName method when you want to change the current theme.
The Spring Framework invokes the resolveThemeName method when it needs to resolve the current theme.
This is mainly done by using the theme jsp tag.
This is particularly useful where you want your application to be as stateless as possible.
The actual value is stored on the client side and will be sent to you with each request.
This resolver also allows you to configure the name of the cookie and a theme locale to use.
It allows you to configure a theme to use throughout the whole application.
This configuration is fixed; as such, it cannot be changed.
The name of the attribute, as well as a default theme, can be configured.
Figure 4-16 shows the different implementations provided by the Spring Framework.
Each works in a slightly different way, just as each is configured differently (see Chapter 6 for more information)
This resolver does not provide an actual implementation or added functionality; instead, it merely acts as a wrapper around multiple implementations (when multiple implementations are configured)
ViewResolver Spring MVC provides a very flexible view resolving mechanism.
The actual implementation could be a JSP, but it could just as easily be an Excel spreadsheet or PDF file.
This API (see Listing 4-20) is pretty simple and consists of a single method.
This method takes the view name and currently selected locale (see also the LocaleResolver)
This can be used to resolve to an actual View implementation.
Out of the box, Spring provides several implementations (see Chapter 8 for more information)
You can use this mechanism to put attributes in a flash map that are then retrieved after a redirect (the flash map survives a request/response cycle)
The flash map is cleared after the view is rendered.
Note  The flash “scope” mentioned here has no relation to the “flashscope” used in Spring Web Flow.
Summary This chapter started by looking at the request processing workflow, identifying which components play a role in this.
The DispatcherServlet can be considered the main component in Spring MVC, and it plays the most crucial role, that of the front controller.
The MVC pattern in Spring MVC is quite explicit; you have a Model, a View, and also a Controller (handler)
The controller processes the request, fills the model, and selects the view to render.
While processing a request, the DispatcherServlet uses a lot of different components to play its role.
The most important components are the HandlerMapping and HandlerAdapter; these components are the core components used to map and handle requests, respectively.
After handling a request, a view needs to be rendered.
A handler can return an View or the name of a view to render.
In the latter situation, this name is passed to an ViewResolver to resolve to an actual view implementation.
To make this possible, there is the notion of an FlashMapManager.
Sometimes, the request processing doesn’t progress the way you’d like it to.
The final components that play a role here are the LocaleResolver and ThemeResolver.
This chapter also touched on the fact that the dispatcher servlet includes some components that are configured by default and contrasted those defaults against those of the Spring @MVC, which can be enabled by using the EnableWebMvc annotation.
We also explored the different default components of the two approaches.
Upcoming chapters will explain how to build controllers to handle requests and take a closer look at how to configure Spring MVC.
Controllers play a crucial role in a web application: they execute the actual request, prepare the model, and select a view to render.
In conjunction with the dispatcher servlet, controllers also play a crucial role in the request processing workflow.
The controller is the glue between the core application and the web interface to the application.
In this chapter, we will take a look at the two different controller approaches and cover the out-of-the-box implementations provided with the Spring Framework.
This chapter will also take a look at the supporting components for request processing.
Introducing Controllers The controller is the component that is responsible for responding to the action the user takes.
This action could be a form submission, clicking a link, or simply accessing a page.
The controller selects or updates the data needed for the view.
It also select the name of the view to render or can render the view itself.
With Spring MVC, we have two options when writing controllers.
We can either implement an interface or put an annotation on the class.
The main focus of this book is the annotation-based approach (aka Spring @MVC) for writing controllers.
However, we feel that we still need to mention the interface-based approach.
Although both approaches work for implementing a controller, there are two major differences between them.
The first difference is about flexibility, and the second is about mapping URLs to controllers.
Annotation-based controllers allow for very flexible method signatures, whereas the interface-based approach has a predefined method on the interface that we must implement.
Having all of the URLs in a single location is one advantage the interface-based approach has over the annotation-based approach.
The annotation-based approach has its mappings scattered throughout the codebase, which makes it harder to see which URL is mapped to which request-handling method.
The advantage of annotation-based controllers is that, when you open a controller, you can see which URLs it is mapped to.
In this section, we will show how to write both types of controllers, as well as how to configure basic view controllers.
Interface-based Controllers To write an interface-based controller, we need to create a class that implements the Controller interface.
When implementing this interface, we must implement the handleRequest method.
We implement the handleRequest method and return an instance of ModelAndView with a view name.
In that case, we would need to check whether the request is a GET or POST request; based on that, we would need to execute different controller logic.
Table 5-1 shows the Controller implementations that ship with the framework.
Many of these are deprecated (as of Spring 3.0) or can be considered deprecated in favor of the newer annotation-based controllers.
It can be configured to append a prefix and/or suffix to the view name.
The named servlet can be a servlet without any mapping.
This is useful if you want to use the Spring MVC infrastructure for dispatching requests and to apply interceptors.
This is useful if you want to use the Spring MVC infrastructure to dispatch requests and apply interceptors.
Subclasses need to add the methods that can be invoked.
This approach enables slightly more flexible method signatures than the normal interface.
Note: This can be considered deprecated as of Spring 3.0 in favor of annotation-based controllers.
The first request (typically a GET request) renders the form to be filled in, while the second request (POST) translates the form to an object, performs validation, and executes the submit action.
Note: This controller is deprecated as of Spring 3.0 in favor of annotation-based controllers.
Note: This controller is deprecated as of Spring 3.0 in favor of annotation-based controllers.
This controller allows the use of multiple pages to fill the model and will only execute a submission on the last page.
Note: This controller is deprecated as of Spring 3.0 in favor of annotation-based controllers and Spring Web Flow.
Annotation-based Controllers To write an annotation-based controller, we need to write a class and put the Controller annotation on that class.
The controller contains a method with the RequestMapping annotation, and it specifies that it should be mapped to the /index.htm URL, which is the request-handling method.
The method has no required parameters, and we can return anything we want; for now, we want to return a ModelAndView.
The mapping is in the controller definition, and we need an instance of a HandlerMapping to interpret these mappings.
We will see that power and flexibility throughout the book.
Configuring View Controllers The two controller samples we have written so far are called view controllers.
They don’t select data; rather, they only select the view name to render.
If we had a large application with more of these views, it would become quite cumbersome to maintain and write these.
We would need to configure an instance to return index as a view name and map it to the /index.htm URL.
Listing 5-4 shows what needs to be added to make this work.
So how does it work? We create the controller, set the view name to return, and then explicitly give it the name of /index.htm (see the highlighted parts)
However, if this were to grow significantly larger, then we would need to create quite a few of these methods.
Because we have enabled the new Spring MVC configuration, we can utilize it to our advantage.
However, the second approach is easier and less cumbersome to use than the first one.
All these can influence which method is selected to handle the request.
Next, we need to specify which web request we want to execute the specified handler.
The annotation can be put on both the type (the controller) and the method level.
We can use the one on the type level to do some coarse-grained mapping (e.g., the URL), and then use the annotation on the method level to further specify when to execute the method (e.g., a GET or POST request)
Table 5-2 shows which attributes we can set on the RequestMapping annotation and how they influence the mapping.
We can also use ant-style expressions to specify the URLs.
Narrows on the existence or absence of HTTP request headers.3 Supported expressions include the following:
For instance, text/xml will map all request for the content-type of text or XML, but we could also specify text/* to match all textual content types.
We can also negate it: !text/xml will match all content types except text or XML.
This parameter is recommended over the use of the headers parameter to specify a Content-Type header because it is more explicit.
The same rules that apply to the consumes parameter also apply to this parameter.
This parameter is recommended over the use of the headers parameter to specify an Accept header because it is more explicit.
In Table 5-3, there are a couple of sample mappings that also show the effect of class- and methodlevel matching.
As already mentioned, the RequestMapping annotation on the class applies to all methods in the controller.
This mechanism can be used to do coarse-grained mapping on the class level and finer-grained mapping on the method level.
Maps to all PUT and POST requests to the order.* URL.
Maps to all requests that post JSON and accept XML as a response.
Maps to all POST requests to the order.htm URL that include an addline parameter.
Maps to all requests to the order.htm URL that don’t include a VIA HTTP Header.
Supported Method Argument Types A request-handling method can have various method arguments and return values.
Most arguments mentioned in Table 5-4 can be used in arbitrary order.
That argument has to follow a model object that we use to bind request parameters to.
The request object that triggered this method only works for multipart requests.
This wrapper allows for easy access to the uploaded files(s)
This is useful if we need to write the response ourselves.
This is useful if we need to write the response ourselves.
Allows for more generic access to request and session attributes without ties to an underlying native API (e.g., Servlet, Portlet, or JSF)
WebRequest extension that has accessor methods for the underlying request and response.
This can be used to write a response directly to the user.
This can be used to write a response directly to the user.
Model implementations have methods to add objects to the model for added convenience.
When adding objects allows method chaining as each method returns the Model.
The ModelMap is a Map implementation that includes some methods to add objects to the model for added convenience.
Binds the uploaded file(s) to a method parameter (multiple files are only supported by the multipart support of Spring)
This works only when the request is a multipart form submission.
This works only when the request is a multipart form submission.
Enables specification of the exact list of attributes in case we want to issue a redirect.
This argument is used instead of the implicit model in the case of a redirect.
The binding and validation results for a preceding model object.
The binding and validation results for a preceding model object.
Has accessor methods for the model and underlying infrastructure for type conversion.
See the “Using SessionAttributes” section later in this chapter for more information.
A URI builder for preparing a URL relative to the current request URL.
It consists of headers and a body of the request or response.
Command or Form objects Binds request parameters to bean properties using type conversion.
By default, all model attributes are exposed when doing a redirect.
Because a redirect always leads to a GET request, all primitive model attributes (or collections/arrays of primitives) will be encoded as request parameters.
However, with the annotated controllers, there are also objects in the model (like the path variables and other implicit values) that don’t need to be exposed and that are outside of our control.
When this is used as a method argument and a redirect is being issued, only the attributes added to the RedirectAttributes instance are going to be added to the URL.
In addition to specifying attributes encoded in the URL, it is also possible to specify so called flash attributes.
Flash attributes are attributes that are stored before the redirect and retrieved and made available as model attributes after the redirect.
The use of flash attributes is useful for objects that cannot be encoded (non-primitive objects) or to keep URLs clean.
It can take a URL pattern and replace or extend variables.
This mechanism is particularly useful when creating URLs, as opposed to cases where we need to think about encoding parameters or doing string concatenation ourselves.
This component handles all these things in a consistent manner for us.
The sample given is quite simple; however, it is possible to specify more variables (e.g., bookId) and replace them (e.g., specify the port or host)
For example, we might use it to replace, not only path variables, but also request parameters.
Supported Method Argument Annotations In addition to explicitly supported types (as mentioned in the previous section), there are also a couple of annotations that we can use to annotate our method arguments (see Table 5-5)
Some of these can also be used with the method argument types mentioned in Table 5-4
In that case, they are used to specify what the name of the attribute in the request, cookie, header, or response must be, as well as whether the parameter is required.
All the parameter values are converted to the argument type by using type conversion.
RequestParam Binds the argument to a single request parameter or to all request parameters.
RequestHeader Binds the argument to a single request header or all request headers.4
RequestBody Gets the request body for arguments with this annotation.
RequestPart Binds the argument to the part of a multipart form submission.
The parameters from the incoming request are bound to the given object.
PathVariable Binds the method parameter to a path variable as specified in the URL mapping (the value attribute of the RequestMapping annotation)
All these different method argument types and annotations allow us to write very flexible requesthandling methods.
However, we could extend this mechanism by extending the framework.
If we want, we can create our own implementation of this interface and register it with the framework.
Let’s take a closer look at all the different annotation types we can use.
All these annotations have a few attributes that we can set and that have default values or may be required.
All of the annotations mentioned in Table 5-5 have a value attribute.
This value attribute refers to the name of the object to use (what it applies to depends on the annotation)
If this value isn’t filled, then the fallback is to use the name of the method argument.
This fallback is only usable if the classes are compiled with debug information.5 An exception to this rule occurs when using the ModelAttribute annotation.
Instead of the name of the method argument, it infers the name from the type of argument, using the simple classname as the argument name.
If the type is an array or collection, it makes this plural by adding List.
RequestParam The RequestParam annotation can be placed on any argument in a request-handling method.
When present, it is used to retrieve a parameter from the request.
When put on a Map, there is some special handling, depending on whether the name attribute is set.
If the name is set, the value is retrieved and converted into a Map.
For conversion (see the “Data Binding” section in this chapter for more information), if no name is given, all request parameters are added to the map as key/value pairs.
Setting a default value is implicitly setting required to false.
The value can either be a hardcoded value or a SpEL expression.
If no name is specified, then the name is derived from the method argument name.
RequestHeader The RequestHeader annotation can be placed on any method argument.
It is used to bind a method argument to a request header.
When placed on a Map, all available request headers are put in the map as key/value pairs.
When set to false, null is used as the value; alternatively, the defaultValue is used when specified.
Setting a default value is implicitly setting required to false.
The value can either be a hardcoded value or a SpEL expression.
If no name is specified, then the name is derived from the method argument name.
RequestBody The RequestBody annotation is used to mark a method parameter we want to bind to the body of the web request.
You can find more information on validation in the “Validation of Model Attributes” section later in this chapter.
When set to false, null is used as a value; alternatively, the defaultValue is used when specified.
If no name is specified the name is derived from the method argument name.
ModelAttribute The ModelAttribute annotation can be placed on method arguments, as well as on methods.
When placed on a method argument, it is used to bind this argument to a model object.
When placed on a method, that method is used to construct a model object, and this method will be called before requesthandling methods are called.
These kinds of methods can be used to create an object to be edited in a form or to supply data needed by a form to render itself.
If no name is specified the name is derived from the method argument type.
If no name is specified, then the name is derived from the method argument name.
CookieValue This CookieValue annotation can be placed on any argument in the request-handling method.
Otherwise, the value of the cookie is converted into the argument type.
When set to false, null is used as a value; alternatively, the defaultValue is used when specified.
Setting a default value is implicitly setting required to false.
The value can either be a hardcoded value or a SpEL expression.
If no name is specified, the name is derived from the method argument name.
Supported Method Return Values In addition to all the different method argument types, a request handling method can also have one of several different return values.
Table 5-12 lists the default supported and handling of method return values for request handling methods.
It should contain the full model to use and the name of a view to render (the latter is optional)
Objects in this model are added to the controller’s implicit model and made available for view rendering.
The elements in the map are added to the controller’s implicit model and made available for view rendering.
If annotated with ModelAttribute, it is added to the model.
Specifies the headers and entity body to return to the user.
Optionally, the HttpEntity can also set a status code to send to the user.
Any other return type All other return types are used as model attributes.
When an arbitrary object is returned and there is no ModelAttribute annotation present, the.
It basically takes the simple name of the class (the classname without the package) and lowercases the first letter.
When the return type is a collection or array, it becomes the simple name of the class, suffixed with List.
This same logic is applied when we use a Model or ModelMap to add objects without an explicit name.
This also has the advantage of using the specific objects, instead of a plain Map to gain access to the underlying implicit model.
Although the list of supported return values is already quite extensive, we can use the flexibility and extensibility of the framework to create our own handler.
Writing Annotation-based Controllers Let’s take some of the theory we’ve developed thus far and apply it to our controllers.
For example, all the menu options we have on our page lead to a 404 error, which indicates that the page cannot be found.
In this section, we are going to add some controllers and views to our application.
We will start by creating a simple login controller operating with the request and request parameters.
Next, we will add a book search page that uses an object.
And finally, we will conclude by building a controller that retrieves and shows the details of a book.
A Simple Login Controller Before we can start writing our controller, we need to have a login page.
In the WEB-INF/views directory, we create a file named login.jsp.
The resulting structure should look like the one shown in Figure 5-2
The login page needs some content, as shown in Listing 5-9
In addition to the page, we need to have a controller and map it to /login.
After the application has been redeployed and we click the Login button, we should see a page like the one shown in Figure 5-3
If we now enter the username and password (jd/secret) and press the Login button, we are greeted with an error page (error code 405) that indicates that the method (POST) is not supported.
This is correct because our controller doesn’t yet have a method that handles a POST request.
So, let’s add a method to our controller that actually handles our login.
Before we move on, let’s drill down on how the handleLogin method works.
The username and password parameters are retrieved from the request, and these are used to call the login method on the AccountService.
If the correct credentials are supplied, we get an Account instance for the user (which we store in the session), and then we redirect to the index page.
The exception is stored as a request attribute, and we return the user to the login page.
Although the current controller does its work, we are still operating directly on the HttpServletRequest.
This is a quite cumbersome (but sometimes necessary) approach; however, we would generally want to avoid this and use the flexible method signatures to make our controllers simpler.
With that in mind, let’s modify the controller and limit our use of directly accessing the request (see Listing 5-12)
However, our exception handling dictates that we still need access to the request.
This will change in the next chapter when we implement exception handling.
There is still one drawback with this approach, and that is our lack of support for the Back button in a browser.
If we go back a page, we will get a nice popup asking if we want to resubmit the form.
It is a common approach to do a redirect after a POST6 request; that way, we can work around the double submission problem.
Listing 5-13 highlights the final modifications to our controller in bold.
When the application is redeployed and we log in, typing in the wrong username/password combination will still raise an error message; however, when we press the Back button, the popup request for a form submission is gone.
Until now, everything we have done is quite low level.
However, we work in an object-oriented programming language, and where possible, we want to work with objects.
Book Search Page We have a bookstore, and we want to sell books.
At the moment, however, there is nothing in our web application that allows the user to search for or even see a list of books.
Let’s address this by creating a book search page, so that the users of our application can search for books.
First, we create a directory book in the /WEB-INF/views directory.
This file is our search form, and it will also display the results of the search.
The code for this can be seen in Listing 5-14
The page consists of a form with a field to fill in a (partial) title that will be used to search for books.
When there are results, we will show a table to the user containing the results.
Now that we have a page, we also need a controller that can handle the requests.
As mentioned earlier, working with the HttpServletRequest directly isn’t necessary in most cases.
With Spring MVC, this is what we call data binding.
Alternatively, it could use RequestParam to retrieve the parameters and set them on the object.
This will force Spring to use data binding on the criteria method argument.
Doing so will map all request parameters with the same name as one of our object’s properties to that object (i.e., the request parameter title will be mapped to the property title)
Using data binding will greatly simplify our controller (you can find more in-depth information on this in the “Data Binding” section of this chapter)
Book Detail Page Now let’s put some more functionality into our search page.
For example, let’s make the title of a book a link that navigates to a book’s details page that shows an image of and some information about the book.
We’ll start by modifying our search.jsp and adding links (see Listing 5-18)
The highlighted line is the only change we need to make to this page.
Let’s create a controller to react to this URL and extract the id from the URL (see Listing 5-19)
If we click one of the links from the search page after redeployment, we should be greeted with a details page that shows an image of and some information about the book (see Figure 5-5)
Data Binding In this section, we will explore the benefits and possibilities of using data binding, including how we can configure and extend it.
However, we’ll begin by explaining the basics of data binding.
It is a simple object with two properties: title and category.
In this case, the title property receives the value of Agile.
Behind the scenes, Spring calls the setTitle method on our JavaBean, which we specified as a method argument in the list method on our controller.
To bind to indexed collections, we must use a notation with square brackets in which we enclose the index.
When using a map, this index doesn’t have to be a numeric.
For instance, list[2].name would bind a name property on the third element in the list.
Similarly, map['foo'].name would bind the name property to the value under the key foo in the map.
Customizing Data Binding We have two options for customizing the behavior of data binding: globally or per controller.
Of course, we can mix both strategies together by performing a global setup, and then fine-tuning it per controller.
An instance of the interface must be registered with the handler mapping implementation, so that it can be used.
The provided implementation allows us to set a couple of properties.
If we were to want to specify more properties, it would be quite easy to extend the default implementation and add the desired behavior.
It is possible to set the same properties here as in the controller (see Table 5-13)
Moreover, this default value will be used for further traversal of the expression.
This property also controls auto growing of collections when an out-of-bounds index is accessed.
This is useful when we have old-style PropertyEditors that we want to use for type conversion.
When we want to extend the configuration provided by Spring @MVC, we need to do some.
The method can have the same arguments as a request-handling method.
This is because the model is available after binding; and in this method, we are going to configure how we bind.
The default is to apply to all model attributes and request parameters.
This object has several configuration options (setter methods) that we can use, as shown in Table 5-14
This is a socalled white list; only fields included in this list will be used for binding.
Field names can also contain an * for matching field names with a certain pattern.
See the disallowedFields attribute for information on excluding fields from binding.
This setting can be used to prevent out of memory errors when binding on large collections.
This default object value will in turn be used for further traversal of the expression.
This property also controls auto growing of collections when an out-of-bounds index is being accessed.
If this isn’t desired and you want null instead, then turn this property off.
This is a blacklist of request parameter names to ignore during binding.
In general, it is wise to put fields like the id and version fields in there.
Like allowedFields, this property can contain an * for matching field names with a certain pattern.
By default, the old values are kept in the binding result.
It is also useful to set this to false if you have getters that have side effects (e.g., they set other properties or default values)
A checkbox that isn’t checked isn’t submitted as part of the request.
Note that this mechanism still lets us receive a value.
Should we ignore bind parameters that have corresponding fields in our model object, but which aren’t accessible? Generally this happens with a nested path, when part of that path resolves to null.
The default is false (i.e., it will not ignore these fields)
When set to false, all the parameters that are submitted must be represented on our model objects.
When a required field is not set, this leads to a bind error.
The advantage of direct field access is that we don’t have to write getter/setters for each field we want to use for binding.
ModelAttributes To fully utilize data binding, we have to use model attributes.
Furthermore, we should use one of these model attributes as the object our form fields are bound to.
However, it is possible to have more control over our objects and how we create objects.
This annotation can be put both on a method and on method arguments.
Using ModelAttribute on Methods We can use the ModelAttribute annotation on methods to create an object to be used in our form (e.g., when editing or updating) or to get reference data (i.e., data that is needed to render the form like a list of categories)
Caution  When a ModelAttribute annotation is put on a method, this method will be called before the requesthandling method is called!
Methods annotated with ModelAttribute have the same flexibility in method argument types as the request-handling methods.
Of course, they shouldn’t operate on the response and cannot have ModelAttribute annotation method arguments.
The annotation can also be placed on request-handling methods, indicating that the return value of the method is to be used as a model attribute.
Using ModelAttribute on Method Arguments When using the annotation on a method argument, the argument is looked up from the model.
If it isn’t found, an instance of the argument type is created using the default constructor.
Using SessionAttributes It can be beneficial to store a model attribute in the session between requests.
For example, imagine we need to edit a customer record.
It is then edited in the application, and the changes are submitted back and applied to the customer.
If we don’t store the customer in the session, then the customer record must be retrieved again from the database.
In Spring @MVC, you can tell the framework to store certain model attributes in the session.
You should use this annotation to store model attributes in the session, so they survive multiple HTTP requests.
The session attributes are also only usable from within the same controller, so you should not use them as a transport to move objects between controllers.
If you need something like that, we suggest that you use Spring Web Flow (see Chapters 10-12)
All attributes in the model of this type will be stored in the session, regardless of their attribute name.
When we finish using the attributes, we need to call the setComplete method on the interface.
To access that interface, we can simply include it as a method argument (see Table 5-4)
Form Tag Library To be able to use all the data binding features provided by the framework, we also need to use the tag library to write forms.
We can use the general-purpose library to write our forms (this was how it worked with the Spring Framework before 2.0)
This is a very powerful approach, but it is also quite cumbersome (albeit it can still be used as a fallback in those corner cases where the form tag library isn’t sufficient)
If set, this tag overrides the value set in the defaultHtmlEscape context-parameter.
It is enhanced so the URL can contain URL template parameters.
Note that you can’t use radiobutton or checkbox for those types.
The option and/or options tag are used to specify the options to render.
It can be used to either specify the path for field-specific error messages or to specify an * to display all error messages.
When using the form tag library, we need to specify which model attribute property we want to bind.
We do this by specifying the path attribute on our form element.
There are several properties we can set on the various form tags, but Table 5-18 shows the main properties.
For the form tags that use a collection of items (e.g., select, checkboxes, and radiobuttons), there are a few additional shared attributes (see Table 5-19)
This can be useful when used with JavaScript because it enables us to always know the name of an element.
We can apply this logic to our order JSP page.
In this case, we simply need to replace the normal input element tags with the form element tags, and then supply the path to bind to.
Of course, we also need to add the taglib declaration to the top of the JSP.
If we redeploy and issue a new search at this point, we see that our title field keeps the previously entered value (see Figure 5-6)
This is due to our use of data binding in combination with the form tags.
Now it’s time to make things a bit more interesting by adding a dropdown box (a HTML select) to select a category to search for in addition to the title.
We already have the categories in our model (see Listing 5-23)
We add a select tag and tell it which model attribute contains the items to render.
We also specify the value and label to show for the each of the items.
The value is bound to the model attribute used for the form.
Type Conversion An important part of data binding is type conversion.
When we receive a request, the only thing we have are String instances.
However, in the real world we use a lot of different object types, not just text representations.
Therefore, we want to convert those String instances into something we can use, which is where type conversion comes in.
In Spring MVC, there are three ways to do type conversion:
Property editors are the old-style of doing type conversion, whereas converters and formatters are the new way of doing type conversion.
Converters and formatters are more flexible; as such, they are also more powerful than property editors.
In addition, relying on property editors also pulls in the whole java.beans package, including all its support classes, which we just don’t need in a web environment.
Property Editors Support for property editors has been part of the Spring Framework since its inception.
Property editors take a String and convert it into a strongly typed object—and vice versa.
Spring provides several implementations for accomplishing this out of the box (see Table 5-20)
An editor that parses Strings representing classes into actual classes and vice versa.
CurrencyEditor An editor for Currency that translates currency codes into Currency objects.
It also exposes the currency code as the text representation of a Currency object.
CustomMapEditor Property editor for Map that converts any source Map into a given target Map type.
CustomDateEditor A customizable property editor for Date that supports a custom DateFormat.
This is not registered by default, and it must be user registered as needed with the appropriate format.
CustomNumberEditor A customizable property editor for any Number subclass like Integer, Long, Float, and so on.
It is registered by default, but can be overridden by registering a custom instance of it as a custom editor.
FileEditor An editor capable of resolving Strings to java.io.File objects.
Note that the default usage will not close the InputStream for you! It is registered by default.
PatternEditor An editor capable of resolving Strings to JDK 1.5 Pattern objects and vice versa.
PropertiesEditor An editor capable of converting Strings (formatted using the format as defined in the Javadoc for the Properties class) to Properties objects.
Optionally, it allows transforming an empty String into a null value.
It is not registered by default; it must be registered by the user as needed.
Note that it does not expose a text representation for TimeZone objects.
URIEditor An editor for java.net.URI that directly populates a URI property instead of using a String property as a bridge.
URLEditor An editor capable of resolving a String representation of a URL into an actual java.net.URL object.
Converters The converter API in Spring 3 is a general purpose type-conversion system.
Within a Spring container, this system is used as an alternative to property editors to convert bean property value strings into the required property type.
We can also use this API to our advantage in our application whenever we need to do type conversion.
The converter system is a strongly typed conversion system and uses generics to enforce this.
Listing 5-29 shows the Converter API, which is very straightforward.
The source and target types are expressed by the S and T generic type arguments.
Listing 5-30 shows the ConverterFactory API that is useful when you need to have conversion logic for an entire class hierarchy.
For this, we can parameterize S to be type we are converting from (the source), and we parameterize R as the base type we want to convert to.
We can then create the appropriate converter inside the implementation of this factory.
It is more flexible, but less strongly typed than the previous converter types.
During a conversion, we have access to the source and target type descriptions, which can be useful for complex conversion logic.
This also allows for type conversion to be driven by annotation (i.e., we can parse the annotation at runtime to determine what needs to be done)
An example of this type of conversion logic would be a converter that converts from an array to a collection.
A converter would first inspect the type of element being converted, so that we could apply additional conversion logic to different elements.
Listing 5-32 shows a specialized version of the GenericConverter that allows us to specify a condition for when it should execute.
For example, we could create a converter that uses one of the BigDecimals valueOf methods to convert a value, but this would only be useful if we could actually invoke that method with the given sourceType.
Formatters The Converter API is a general purpose type-conversion system.
It is strongly typed and can convert from any object type to another object type (if there is a converter available)
However, this is not something we need in our web environment because we only deal with String objects there.
On the other hand, we probably want to represent our objects as String to the client, and we might even want to do so in a localized way.
This is where the Formatter API comes in (see Listing 5-34)
It is an alternative to property editors, but it is also lighter (e.g., it doesn’t depend on the java.beans package) and more flexible (e.g, it has access to the Locale for localized content)
For example, imagine we had a formatter that could convert Date instances to text, and vice-versa.
We would specify T as Date and use the Locale to determine the specific date format to use for performing the conversion (see Listing 5-35)
Formatters can also be driven by annotations instead of by field type.
We need to parameterize A with the annotation type we want to associate with it.
We can then use these to convert from or to the annotation type.
We could then implement the factory shown in Listing 5-37
The addFormatters method can be overridden to register additional converters and/or formatters.
In addition to the category conversion, we also need to do date conversions.
Using Type Conversion Now that we have covered type conversion, let’s see it in action.
Next, we need to create a customer directory and place a register.jsp file in it.
The content is included only in part of Listing 5-41 because there is a lot of repetition in this page for all the different fields.
In this controller, we will use a couple of data binding features.
First, we will disallow the submission of an id field (to prevent someone from editing another user)
Second, we will preselect the user’s country based on the current Locale.
It disallows the setting of the id property and sets some required fields.
We also have a method that prepares our model by adding all the available countries in the JDK to the model.
Finally, we have two request-handling methods, one for a GET request (the initial request when we enter our page) and one for POST/PUT requests when we submit our form.
This is what we can use to detect errors; and based on that, we can redisplay the original page.
Also remember that the error tags in the JSP those are used to display error messages for fields or objects (we’ll cover this in more depth in the upcoming sections)
When the application is redeployed and we click the Register link, we should see the page shown in Figure 5-7
If we now enter an invalid date; leave the username, password and e-mail address fields blank; and then submit the form; the same page redisplays with some error messages (see Figure 5-8)
The error messages are created by the data binding facilities in Spring MVC.
Later in this chapter, we will see how we can influence the messages displayed.
If we fill in proper information and click Save, we are redirected to an account page (for which we already have provided the basic controller and implementation)
Validating Model Attributes We’ve already mentioned validation a couple of times.
Validating our model attributes is quite easy to accomplish with the validation abstraction from the Spring Framework.
Validation isn’t bound to the web; it is about validating objects.
Therefore, validation can also be used outside the web layer; in fact, it can be used anywhere.
The supports method is used to determine if the validator.
The validate method is used to actually validate the object (see Listing 5-43)
The supports method is called to see if a validator can validate the current object type.
When doing validation, it is a good idea to include an Errors or BindingResult (the latter extends Errors) method attribute.
This way, we can handle situations where there is a bind or validation error.
When using Spring @MVC, we have two options for triggering validation.
The first is to inject the validator into our controller and to call the validate method on the validator ourselves.
The annotation from the Spring Framework is more powerful than the one from the javax.validation package.
Validation and bind errors lead to message codes that are registered with the Errors instance.
In general, simply showing an error code to the user isn’t very informative, so the code has to be resolved to a message.
The error codes are passed as message codes to the configured message source and used to retrieve the message.
If we don’t configure a message source, we will be greeted with a nice stacktrace indicating that a message for code x cannot be found.
So, before we proceed, let’s configure the MessageSource shown in Listing 5-44
When a message is not found, we return the code as the message.
This is especially useful during development because we can quickly see which message codes are missing from our resource bundles.
We want to validate whether an account is valid; and for that, we need a username, password and a valid email address.
To be able to handle shipping, we also need an address, city, and country.
Now let’s see how we can use the validation framework to our advantage.
In our case, however, we have all the validation logic in one place, rather than having it spread over two places.
This validator implementation will check if the fields are not null and non-empty.
If the field is empty, it will register an error for the given field.
The order in the table is also the order in which the error codes are resolved to a proper message.
The final part of this validation is that we need to configure our validator and tell the controller to validate our model attribute on submission.
We only want to trigger validation on the final submission of our form.
If we submit illegal values after redeployment, we will be greeted with some error codes, as shown in Figure 5-9
Instead of implementing our own validator, we could also the JSR-303 annotations to add validation.
When using these annotations, the error code used is slightly different than the one used in our custom validator (see Table 5-22)
However, the registration page doesn’t need to change, so it remains the same as before.
In our init-binder method, we do not need to set the validator because a JSR-303 capable validator is automatically detected (the sample project uses the one from Hibernate)
When using JSR-303 annotations, if we submit the form with invalid values, we get a result like the.
As we can see, there are messages displayed instead of codes.
How is that possible? There are some default messages shipped with the validator implementation we use.
We can override these if we want by specifying one of the codes from Table 5-22 in our resource bundle (see the next section)
Message Source The message source is the component that actually resolves our message based on a code and the locale.
Two of those implementations are implementations that we can use, while the other implementations simply delegate to another message source.
It allows for the resources to be anywhere on the file system it uses the resource loading mechanism in Spring.
We configure both beans more or less the same way.
For example, we could even create our own implementation that uses a database to load the messages.
The following snippets show two properties files (actually resource bundles) that are loaded.
Several different implementations ship with Spring that can make our lives easier.
The locale resolver is a strategy that is used to detect which Locale to use.
The different implementations each use a different way of resolving the locale (see Table 5-24)
All the users of our website use the same locale, so changing the locale isn’t supported.
The attribute used to store the locale can be configured, as well as the default locale to use if no locale is present.
The drawback to this is that the locale isn’t stored between visits, so it must be set at least once on the user’s session.
In general, this is the locale of the operating system of the user, so changing the locale isn’t supported.
It is also the default LocalResolver used by the DispatcherServlet.
The advantage of this resolver is that the locale is kept on the client’s machine, so it will be available on subsequent visits to the website.
The cookie name and timeout can be configured, as well as the default locale.
If this is present, the interceptor uses the earlier configured locale resolver to change the current user’s Locale.
If something goes wrong, we want to inform the user in the correct language.
If we redeploy our application, we should get localized error messages if we switch the language (of course, this works only if we add the appropriate error codes to the resource bundles)
However, using the MessageSource for error messages isn’t its only use; we can also use MessageSource to retrieve our labels, titles, error messages, and so on from our resource bundles.
Listing 5-52 shows a modified book search page, which uses the message tag to fill the labels, titles, and headers.
Summary This chapter covered all things we need to write controllers and handle forms.
We began by exploring the RequestMapping annotation and how that can be used to map requests to a method to handle a request.
We also explored flexible method signatures and covered which method argument types and return values are supported out of the box.
Next, we dove into the deep end and started writing controllers and modifying our existing code.
We also introduced form objects and covered how to bind the properties to fields.
And we explained data binding and explored Spring’s type-conversion system and how that is used to convert from and to certain objects.
We also wrote our own implementation of a Converter to convert from text to a Category object.
There are two ways of doing validation: we can create our own implementation of a Validator interface, or we can use the JSR-303 annotations on the objects we want to validate.
Enabling validation is done with either the Valid or the Validated annotation.
To make it easier to bind certain fields to attributes of a form object, there is the Spring Form Tag library, which helps us to write HTML forms.
This library also helps us to display bind and validation errors to the user.
In the next chapter, we are going to explore some more advanced features of Spring MVC.
Along the way, we will see how we can further extend and customize the existing infrastructure.
In this chapter, we are going to take a look at some of the more advanced parts of Spring MVC, and then see how we can tap into the framework itself to extend it to suit our needs.
We’ll begin by examining scoped beans and how we can use them to our advantage.
Next, we’ll explore how we can add generic functionality (so-called crosscutting concerns) to our application.
For this, we are going to take a look at interceptors, including how to create them and how to wire them into our application.
No matter how robust or well-thought out our application is, there is going to be a time when our application doesn’t behave as expected (e.g., maybe someone will trip over the wire to our database server), and this will result in exceptions in our application.
In general, we want to prevent the user from seeing the often cryptic stack traces; and for this, we are going to explore the exception-handling facilities in Spring MVC.
After we cover all these topics, we are going to dive into the internals of Spring @MVC and explore a couple of APIs we can extend; we’ll then use these extended APIs to augment the functionality of the framework.
Using Scoped Beans In Chapter 2, we noted the different scopes for beans that are supported by the Spring Framework.
In this section, we are going to use scopes to our advantage.
A single instance of a bean is created and shared throughout the application.
The lifecycle of the bean is tied to the application context it is constructed in.
If the request is over, the bean instance is destroyed.
When the session is destroyed, so is the bean instance.
If a global session is not available, it falls back to the session scope functionality.
We’ve already worked with the singleton scope—that is the default for bean creation in the Spring.
This annotation can be used as a type-level or method-level annotation.
When you use Scope as a type-level annotation, all beans of this type will have the scope specified by the annotation.
When you use it as a method-level annotation, beans created by this annotated method will have the scope specified by the annotation.
Adding Something to the Cart In this section, we are going to take the first step in actually enabling site visitors to buy books from our bookstore.
Specifically, we are going to implement logic that lets us add books to our shopping cart.
For this, we first need to define a session-scoped Cart bean.
Listing 6-1 shows how to define a bean (our shopping cart) with session scope.
This bean can be injected into other beans, just like any other bean in the framework.
Spring will handle the complexity of managing the lifecycle of the bean.
The lifecycle of the bean depends on the scope of the bean (see Table 6-1)
In this case, we have a bean declaration with the annotation, and we are using session scope.
We can now simply have this bean injected into other beans and use it like any other bean.
Note  To be able to use class-based proxies, Spring requires an additional library called CGLIB.1
In this case, we simply autowire the session-scoped bean cart, just as we would for any other bean.
The addToCart method contains the logic for adding a book to the cart.
After the book has been added, we redirect to the page from which we came (the referer request header)
After redeploying our application, we should have an Add to Cart link on the Books page (see Figure 6-1)
If we click that link, we should stay on the Books page.
If we switch to our logging output (see Figure 6-2), we can see that there is actually something in the shopping cart.
Cart logging that shows the books added to the cart.
Implementing the Checkout To finalize the ordering process, we will give our customers an opportunity to check out their cart.
The checkout is a combination of a lot of things we covered in the previous chapter and the previous section.
The first method called on the controller when we click checkout is the show method, it takes our cart and uses the Account stored in the session to create an order and add that to the model.
The order is stored in the session in between requests; this due to the use of SessionAttributes.
When this is done, the checkout page is rendered (see Figure 6-3)
When the form is filled in, the customer can do two things: he can press the Order button or the Update button.
When the Update button is pressed, the update method is called.
This submits the form and then updates the order (and recalculates the total price)
In any errors occur, the page is redisplayed and error messages are shown to the customer.
Finally, before redirecting to the index page again, we need to clear the shopping cart.
We do this so that the customer can add new books to the cart.
Because we cannot simply replace the session-scoped object, we need to call a method to clear it.
If we were to replace the cart with a fresh instance we would basically destroy the scoped proxy object.
Crosscutting Concerns When developing an enterprise application, we are often faced or challenged with crosscutting concerns.
Examples of crosscutting concerns include transaction management and security, but also actions such as exposing generic data for each incoming web request.
In general, these concerns are hard to implement in our codebase by using traditional objectoriented approaches.
If we were to implement them in traditional ways, it would lead to code duplication and hard-to-maintain code.
For our general objects, we can use aspect-oriented programming (AOP) to address these crosscutting concerns; however when it comes to applying it to requests, we need a slightly different approach.
Spring MVC gives us two ways of implementing crosscutting concerns.
The first approach uses interceptors to implement generic logic, while the second relies on exception handling.
In this section, we are going to take a look at both techniques of applying crosscutting concerns in our web application.
Interceptors Interceptors are to request handlers what filters are to servlets.
According to the servlet specification,2 a filter is a reusable piece of code that can transform the content of HTTP requests, responses, and header information.
Filters modify or adapt the requests for a resource, and modify or adapt responses from a resource.
Filters and interceptors both implement common functionality (crosscutting concerns) to apply to all (or a selection) of incoming HTTP requests.
Filters are more powerful than interceptors because they can replace (or wrap) the incoming request/response, whereas this cannot be done by an interceptor.
The interceptor, on the other hand, has more lifecycle methods than the filter (see Table 6-3)
This can be used to place shared objects in the model.
This method is always called on interceptors where the preHandle method has been called successfully, even when there was an error during request processing.
As is often the case within the Spring Framework, both strategies are expressed as interfaces for which we could provide an implementation.
It can be used in a JSF or Servlet environment without changing the implementation.
An advantage of the HandlerInterceptor is that we can use it to prevent the handler from being called.
We do this by returning false from the preHandle method.
Configuring Interceptors To use an interceptor, we need to configure it in our configuration.
Connecting an interceptor to our handlers can be done in two ways.
It is possible to use both approaches together, but we don’t recommend this.
First, we can explicitly add the interceptors to our handler mappings in our configuration.
To register the interceptors with the handler mapping, we first need to get the handler mappings involved.
To do this, we need to either explicitly add them or extend the Spring base classes to get a reference to them (see Listing 6-7)
When using multiple handler mappings, this can be quite cumbersome, especially if we want to apply the interceptor only to certain URLs.
The interceptors added to this registry are added to all configured handler mappings.
Additionally, mapping to certain URLs is very easy to accomplish with this approach.
This interface has several callback methods that are called during the configuration of Spring @MVC.
We can use ant-style path patterns3 to configure a fine-grained mapping for the registered interceptor.
If we don’t supply a pattern, the interceptor will be applied to all incoming requests.
At this point, we have configured an interceptor to change the locale, and this interceptor is being applied to all incoming requests (we didn’t specify a URL pattern to match against)
Next, we configure the interceptor and use the addInterceptor method to add it to the registry.
The framework will take care of the additional details for registering the interceptors with the configured handler mappings.
Listing 6-10 shows a snippet of code in which we change the mapping from all URLs to only URLs starting with /customer.
Implementing an Interceptor Thus far, we have covered different types of interceptors and how to register them, so that they can be used.
The first will add some commonly used data to our model, so that we can show it to the user.
The second will address a security need: we want the account and checkout page to be accessible only by registered users.
If we look at our web page in Figure 6-4, we can see a section called Random Books.
This section on our web page has remained empty thus far.
Now we are going to create an interceptor that will add some random books to the model.
For this, we are going to implement the postHandle method (see Listing 6-11)
Note  In a real web shop, we would probably call this section “New Books” or “Suggested Books.”
The postHandle method adds some random books to the model, but only when this model is available.
The model can be null when we are going to do AJAX or write the response ourselves.
To have our interceptor applied to incoming request, we need to register it.
The interceptor needs to be called for every incoming request, so it doesn’t require much additional configuration (see the highlighted line in Listing 6-12)
Now when we redeploy our application and access a page, we should see random books displayed in the Random Books section on our page (see Figure 6-5)
The logic used in our template for selecting the random books is shown in Listing 6-13
The welcome page with titles in the Random Books section.
For example, someone could simply change the id in the URL to see the content of another account.
Let’s use the interceptor approach to apply security to our pages.
We are going to create an interceptor that checks whether we are already logged in (our account is available in the HTTP session)
We will also store the original URL in a session attribute; that way, we can redirect the user to the URL he wants to visit after he logs in.
For this interceptor, our configuration is a bit more complex because we want to map it to certain URLs (see the highlighted part in Listing 6-15)
Currently, we expect an id as part of the URL.
However, instead of retrieving the account from the database, we are going to restore it from the session.
When we redeploy our application and click Account in the menu bar, we will be greeted with an error page (see Figure 6-6)
We use the default exception-handling mechanism to send an error code back to the client, so that the browser can act upon it.
In the next section, we are going to cover exception handling in more detail.
While we have protected our resources, it would be nicer if we could show the login page to the user with a message that she needs to log in to see the requested page.
This is what we are going to do in the next section.
Exception Handling As mentioned in Chapter 4, when an exception occurs during request processing, Spring will try to handle the exception.
This method is called when an exception occurs during the request processing workflow.
When multiple resolvers are detected, the dispatcher servlet will consult each of them until a viewname is returned or the response is written.
If the exception cannot be handled, then the exception is rethrown, so that the servlet container can handle it.
The servlet container will use the error-pages configuration from its configuration or simply propagate the exception to the user.
In most cases, you will get an error 500 with a stacktrace on screen.
Table 6-4 gives a short overview on how the different implementations work.
Searches the current controller for methods annotated with @ExceptionHandler and selects the best exception-handling method to handle the exception.
Translates well-known exceptions to a proper response for the client.
Returns an empty ModelAndView and sends the appropriate HTTP Response Code to the client.
Maps exceptions to view names by the exception class name or part (substring) of that class name.
This implementation can be configured either globally or for certain controllers.
Used internally by the @MVC configuration to chain exception resolvers.
As the class diagram in Figure 6-7 illustrates, all usable implementations for resolving exceptions.
This is a convenient superclass that provides common features and configuration options to all implementations.
The default value is false, which allows browsers to cache the error pages.
The default is no category, which translates to no logging.
In Table 6-6, we can see the exception to the HTTP response code and description mapping.
If that is the case, it will handle the exception, send the HTTP response code from the annotation to the client, and then return an empty ModelAndView indicating the exception was handled.
If that annotation isn’t present, it simply returns null to indicate that the exception wasn’t handled.
This annotation has two properties we can use to specify information (see Table 6-7)
For example, we can map (partial) exception class names to a view.
We say partial here because matching is done based on the name of the class and not on its concrete type.
The matching is done with a simple substring mechanism; as such, wildcards (ant-style regular expressions) aren’t supported.
We also set a HTTP response code to send with the login view.
The matching is done based on the class name, rather than the concrete type.
If the class name of the exception thrown matches the specified pattern, then the corresponding view name will be used.
The pattern doesn’t support wildcards; it is merely a substring that matches the class name.
For instance, Exception will match almost all exceptions thrown (because most exceptions have Exception as part of their class name)
If we click Account on the menu bar after redeployment, we will be greeted with a login page (see Figure 6-8)
This is also a drawback because this pair of exception resolvers only operates on methods in the currently assigned controller.
If you use this technique, it isn’t possible to define an exception handler for the whole application.
The method in Listing 6-21 will handle all exceptions thrown in the controller it is defined in.
It will cause an error code 500 to be sent back to the client, along with the given reason.
This is the most basic exception-handling method we can write.
As mentioned previously, we can use multiple parameters in the method signature.
This goes for the method arguments, as well as the method return types.
Extending Spring @MVC In previous chapters, we explained how Spring MVC works and how we can write controllers.
However, there might come a time when the support from the framework out-of-the-box isn’t sufficient, and we will want to change or add to the behavior of the framework.
In general, the Spring Framework is quite flexible due to the way it is built.
It uses a lot of strategies and delegation, and this is also something we can use to extend or modify the behavior of the framework.
In this section, we will dive into the internals of request mapping, request handling, and form rendering.
First, we need an implementation of the interface (see Listing 6-23 for the API)
This class contains two callback methods that act as factory methods for our custom request method (see Listing 6-24)
There is more or a less an implementation for each of the supported method-argument types or annotations (see the Chapter 5 section, “Supported Method Argument Types”)
The API is quite simple, as we can see in Listing 6-25
The one that returns true will be used to detect or create the actual value to use for that method argument.
There is an implementation for each of the supported return values or annotations (see the Chapter 5 section, “Supported Return Values”)
This API is also quite simple, as we can see in Listing 6-26
The one that returns true will be used to actually handle the return value.
For this, we first need an annotation to mark a method argument or return type as something we want to retrieve or put in the HttpSession.
However, all by itself adding an annotation isn’t much help because we still need a class that uses that annotation.
Before we can use the processor, we need to configure it.
Specifically, we need to add the processor as a bean and make the environment aware of the bean’s existence (see Listing 6-29)
Now that we have configured our processor, we are finally ready to use it.
Let’s begin by modifying the controllers for accounts, as shown in Listing 6-30
We removed the need for directly accessing the session and the need for adding the account to the model, this is now all handled by the processor.
Bold font reflects the changes; it is simply an annotation on a method argument.
At this point, we no longer need direct access to the HTTP session.
If we now relaunch the application and click Account (after logging in), we are greeted by our Account page (see Figure 6-10)
We can use this interface to do some interesting things.
For example, we might create a checksum over the not editable fields (like id) in the controller (or an interceptor), and then review this checksum to see whether any fields have been tampered with.
The processUrl method is used by the Url tag; and on a redirect, we could use it to encode or add extra parameters to the URL to secure our URLs (for instance, we could add a checksum to check the validity of our parameters)
Therefore, an implementation needs to be tailored for our application (the HDIV website has a plugin to protect a site from a whole range of vulnerabilities)
This is the name the framework uses to detect the registered instance.
Summary In this chapter, we covered some more advanced techniques that we can use to build web applications.
For example, we started by looking at scoped beans and how we can use them to our advantage.
To that end, we implemented a shopping cart in our sample application.
At times we find ourselves in need of the ability to reuse code or to execute code across a large amount of classes or URLs.
These so-called crosscutting concerns can be addressed by using aspect oriented programming; however, in a web application, this isn’t always a good fit.
In Spring MVC, we can use interceptors and an advanced exception-handling strategy to address those crosscutting concerns.
For example, we can use interceptors to execute a piece of code for a large number of controllers.
When configuring these interceptors, we can specify whether to map to all controllers or only to certain controllers based on the URL.
Although we all try to build our applications to be as robust as possible, there is always a chance that things will go wrong.
When things do go wrong, we want to be able to handle the problems gracefully.
For example, we might want to show the user an error page or login page when we need the user’s credentials.
For this, we took an in-depth look at the exception-handling strategies inside Spring MVC.
We followed this by diving deeper into the infrastructure classes of Spring MVC and examined how to extend the framework, if the need arises.
We also explained how to expand the request matching by.
Next, we explained (and showed) how to write a processor to handle method-argument types and return values for request-handling methods.
Finally, we ended the chapter with a brief introduction to the request data value processor, covering how to use this to protect against CSFR and provide data integrity.
Until now we have been building quite a classic web application: we send a request to the server, the server processes the request, and we render the result and show it to the client.
Over the last decade, however the way we build web applications has changed considerably.
Now we have JavaScript and JSON/XML, which allow for AJAX-based web applications and also push more and more behavior push to the client, including validation, rendering parts of the screen, and so on.
In this chapter we start with REST1 (Representational State Transfer), a concept or architectural style that has influenced how we as developers think of web resources and how we should handle them.
We next discuss AJAX and consider it in combination with REST.
You will see how to do file uploading with the Spring Framework and how to handle the task in our controllers.
However before we get into this let’s take a look at REST.
The concept essentially has two parts: first the resources and how we identify them, and then the way we operate or work with these resources.
For REST this doesn’t really change; however, the URL is important as it points to a unique resource.
Table 7-1 gives a couple of samples of resource locations.
In REST it is all about a representation of a resource, and hence the URL/URI is important.
What we see in our web browser isn’t the actual resource but a representation of that resource.
The next section explains how we can use this resource location to work with (modify, delete, and so on) that resource.
Working with Resources The HTTP protocol specifies several methods (HTTP methods3) to work with information from our application.
Useful to identify if something has changed and if a GET request needs to be send.
If a user issues the same PUT request multiple times, the result should always be the same.
A POST is useful for creating new resources (such as a user) or for triggering an action (in our example, create a new book)
Issuing the same request multiple times does not produce the same result (that is, the book would be created twice)
The server should do nothing more than reflect the request data back to the client.
The TRACE and OPTIONS methods aren’t actually used in REST but are mentioned here for completeness.
In the previous section, “Identifying Resources,”we mentioned how a URL points to a resource.
The list of HTTP methods is larger than most web browsers support.
It uses a request parameter to determine which method to use for the incoming request.
By default it uses a request parameter with the name _method; however, this name can be configured.
A GET request is processed as is and will not be transformed into another type of.
This is because a GET request, unlike the other types, has all parameters encoded in the URL.
By contrast the POST and PUT requests have them encoded in the request body.
Now that we have configured the filter, we need to modify our account page.
Open up the account.jsp file and make sure there is a hidden field with the name _method and the value PUT.
Listing 7-2 shows the start of the page; as you can see, the opening of the form has this hidden field defined.
The controller was already written with this in mind; see Listing 7-3 for the update method.
Here we reused the same method for both POST and PUT, but we could have handled them separately.
The use of the filter is still a workaround to make REST possible with browsers and normal forms, which can be useful if we choose to use progressive enhancement or graceful degradation for our website.
Progressive enhancement means adding rich behavior to a basic page and first making sure our basic page works as we want it to.
Graceful degradation is the other way around—we develop a rich website and try to make sure the whole site still works even if certain features aren’t available.
Dynamic display and interaction by using the Document Object Model (DOM)
Although the acronym stands for Asynchronous JavaScript and XML, it is often used with JavaScript Object Notation (JSON) to pass data between the client and server.
As AJAX has already been in use for a couple of years, there are quite a lot of JavaScript frameworks out there that make it easier to create a rich user experience.
For Spring MVC, it doesn’t matter which JavaScript library you choose, and it is beyond the scope of the book to discuss the abundance of JavaScript libraries out there.
For our example we use jQuery,6 as at the moment of writing it is one of the most widely used libraries out there.
To be able to use jQuery, we need to load the JavaScript file containing this library.
For this we modify the template.jsp file to include jQuery (see Listing 7-4)
This adds the jQuery JavaScript library to all of our pages; however, by itself it doesn’t do much.
In the next sections we are going to add AJAX behavior to our sample.
We will start with a simple form submit and along the way explore the features that Spring MVC offers to work with AJAX and how it helps us building REST applications.
Adding AJAX to Our Application Thanks to the flexibility of Spring MVC, it is quite easy to add AJAX behavior to our application and integrate it nicely with Spring MVC.
In this section we will see how we can change our form submit into an AJAX-based form submit (with and without the use of JSON)
However a form submit isn’t the only possible use for AJAX; it merely serves our sample application, it is also quite possible to create autocompletion fields, automatic field/form validation, and so on.
We will start by changing the normal form submit into an AJAX form submit.
Open the search.jsp file and add the script as shown in Listing 7-5 right after the form or at the bottom of the page.
It first prevents the actual submit from happening, and then builds an AJAX request that will pass the data to the server.
If we now redeploy our application, navigate to our book search page, and press Submit, it looks like nothing happens.
At least we don’t see anything change on the screen.
If we debug our application, we can see the request arrive at the server and the search being issued.
At the beginning of this section, we mentioned that AJAX is a collection of technologies, and one of those is asynchronous data retrieval using the XMLHttpRequest.
We send a request to the server but we haven’t included anything to handle the response from the server.
Listing 7-6 shows the modified script (see the highlighted part) to actually render the returned page.
We added the success handler for this script and what it does is render the result we receive from the server.
The result is the whole page as it would normally be rendered.
We select the table with the results and we replace the current table on screen with the detected table.
If the application is redeployed and a search is issued, the page would work again.
We send data to the server and we get the full page as we would normally render back.
It would be better if we could simply return the data we need to render and process that on the client.
For this we need to change a little in our JavaScript but we also need to extend our server side.
We need an additional method to return JSON-encoded data to the client (see Listing 7-7)
The method does the same as the original list method on the same controller; however, there are two important differences, which are highlighted.
The first is that this method is invoked whenever an incoming request has specified that it wants to receive JSON (by setting the Accept headers as explained in Chapter 4)
In addition to the controller, we also need to modify our JavaScript a little, to specify that we want to receive JSON from the server.
Because we’ll receive JSON, we also need to use JSON to replace the content of our result table.
In Listing 7-8 you can see the result for the search.jsp file.
When the application is redeployed and a search is issued, our new method will be invoked and JSON will be returned to the client.
The client will use the JSON objects to create a new table body, and when the body is created it will replace the current table body.
Sending and Receiving JSON It is possible to send JSON to the server as well as to receive JSON from the server.
The advantage of sending JSON is that it is quite compact and therefore faster to send and process (both client and server side) than XML.
A drawback can be that you need some hand-coding to prepare the JSON for sending to the server, especially when reusing existing objects (as we can see in our sample)
To make this possible, we need to modify our client-side JavaScript and also make some changes to our request handling method.
The controller needs to know that we aren’t using a normal model attribute but instead want to use JSON for our BookSearchCriteria.
To enable this, we are going to annotate our method argument with RequestBody; it is analogous to ResponseBody, but for incoming requests.
Listing 7-9 highlights the changes that need to be made to the controller.
Notice the change from a GET request to a POST request; this is needed because we are using the RequestBody annotation.
As the name of the annotation implies, it operates on the body of a request, but a GET request in general encodes the data in the URL instead of the body.
Note  When using the RequestBody and ResponseBody annotations, Spring MVC doesn’t use the type conversion system to convert from an id to an actual object (like our category)
That’s because in REST, everything to represent/build the resource should be part of the request.
Having modified our controller, we also need to modify our JavaScript again.
We need to convert the data from the form into a JSON string that we can send to the server.
The first highlighted block is the conversion of our form data into a JSON object.
This is needed because the content is the body of the request, and a GET request doesn’t have a body but encodes everything into the URL.
The last highlighted line is the conversion of the JSON object into a JSON string which can be sent to the server.
If the application is redeployed and we issue a search, the search results will be shown to the user again.
Note  jQuery has a plugin architecture, and there are a couple of plugins out there that make form-to-JSON conversion easier.
We choose not to use a plugin, as that would focus too much on the plugin.
Combining AJAX and REST We briefly covered REST and we also touched on the subject of AJAX, but we covered each topic separately.
However, it is also very easy to combine the two.
In the REST section, we changed the account update form into a form that was issued with a PUT request, but this was a simulation using POST.
With the JavaScript library we use, it is actually possible to create a real PUT request instead of a POST request that is being used as a PUT request.
To be able to issue and handle PUT requests, we need to do two things: the form must be submitted by AJAX as a PUT request, and we need to prepare the server to be able to handle PUT requests.
There are some differences between the POST and PUT requests.
A major difference is that a POST request must have the form data available (this is required by the specification), but for the PUT request that is not the case.
Next we also need to add some JavaScript to our account.jsp file.
It is quite similar to the script we first added to our book search page, with one major difference—we now use a PUT instead of a GET.
See Listing 7-12 for the JavaScript that is added right after the form or at the end of the page.
The controller method (see Listing 7-3) remains the same, as it still is a PUT request for the controller.
Progressive Enhancement The way we have been applying the AJAX features is a technique called progressive enhancement.
It means that one builds a simple web page that functions as is, and then add dynamic and rich behavior to the page with JavaScript.
The opposite approach is also possible; this technique is called graceful degradation, which means that we start with a page with all the behavior we want and depending on the features offered by the browser we scale down on the rich behavior used.
The trend nowadays is to use progressive enhancement because, in general, it is easier to build and maintain.
Out of the box, Spring provides two ways of handling file uploads.
The first implementation can only be used in a Servlet 3.0 environment with multipart enabled on the servlet, and the second uses commons-fileupload.
When put on anything else as described above, Spring uses the type conversion system to transform the content of the file.
We will first discuss the configuration for the two different strategies.
After that, we will look at how to handle file uploads inside a controller.
Configuration The first step in enabling file uploads is to configure our environment.
As Spring provides two different technologies out of the box, each of these requires a different set of configuration items.
We will look at the Servlet 3.0 multipart support and afterward at commons-fileupload.
If the application is strictly to run in a Servlet 3.0 environment, use the standard multipart support as specified by the Servlet specification.
If the application needs to run in older containers also, choose the commons-fileupload support.
Configuring Apache Commons File Uploading In older servlet containers or for a more portable way of file uploading, we can use the commons file upload support in Spring MVC.
We don’t have the multipart parsing on the servlet anymore, and so we need to do configuration for max file size and the like on the multipart resolver.
Request Handling Method for File Upload In addition to configuring the upload, we also need a page with a form that can submit a file.
This form doesn’t change if we change the different techniques available; it is only the way the uploads are handled that changes.
When adding an input element with the type file, it is important to give it a name, especially if we do a single file upload.
This name is also needed to retrieve the file from the request.
We add this form to the account.jsp file right after the already existing form.
When we now render the account page, it will look like Figure 7-1
In the following sections we will explore the different ways of handling file uploads in a controller.
Most of the methods are portable between the two different file upload technologies; however, the last one is only available when using the Servlet 3.0 multipart support.
Each of the different request handling methods has the same output when a file is uploaded; it will print the name of the uploaded file and the size of the file, as shown in Figure 7-2
Writing a Request Handling Method with Multipart File When writing a request handling method, if we want to do file upload and use the multipart file abstraction from Spring, we need to create a method, annotate it, and make sure it has a MultipartFile as a method argument.
When there are multiple files uploaded with the same name, we can also receive a collection of files instead of a single element.
Listing 7-17 shows a controller with a method that can handle file uploads using this technique.
This interface defines some methods to get access to the files.
Using a Form Object to Handle Upload Instead of handling the upload directly, we could also make it part of a form object (model attribute)
This can be convenient if the upload is part of a form that includes more fields (like our customer account page, which includes a picture)
To be able to do this we need to create a class that can be used as the form object, with an attribute of type MultipartFile (Listing 7-19)
We need to modify the controller to take the form as a method argument (see Listing 7-20)
We simply create a method that takes the Part as an argument (see Listing 7-21) We need to create a method, annotate it, and give it a method argument.
This technique only works in a Servlet 3.0 environment and is in that regard less portable than using the MultipartFile argument.
The file could be too large to handle (larger than the configured maximum file size), or our disks could be full.
If possible, we want to handle the errors and show a nice error page to the users.
We can use the exception handling (as explained in Chapter 6) to handle the exception for us and show a nice error page.
Summary This chapter covered Representation State Transfer (REST), as explained by Roy Thomas Fielding, and you saw how we can configure Spring MVC to facilitate the different methods as used by REST.
Next we briefly explained Asynchronous JavaScript and XML (AJAX) and how we can use that on the client and have controllers react to those requests.
Although AJAX was originally about XML, nowadays it is about JSON; and we explored the JSON features offered by Spring MVC by using the RequestBody and ResponseBody annotation.
It is also very useful to combine AJAX and REST and it allows for creating a REST-based API for our application.
The final part of this chapter looked at uploading files to our application.
For this purpose we looked at the configuration needed for Servlet 3.0 multipart support and commons-fileupload support and then explored the different ways of writing a controller that can handle file uploads.
So far we have mainly used Java Server Pages (JSP) as our view technology; however, Spring MVC provides a very powerful and flexible mechanism to resolve and implement views.
We looked briefly at the view resolving mechanism in Chapter 4; in this chapter we will take a closer look at the different ViewResolver implementations and see how we can create and use our own implementation.
We will also see which view technologies are supported by Spring MVC out-of-the-box, and we will create some custom implementations.
Before we dive into the internals, however, let’s recap the view rendering process and API.
View Resolvers and Views In Chapter 4 we discussed the request processing workflow of the dispatcher servlet.
Resolving and rendering a view is part of that process.
In the latter case the ViewResolvers configured are consulted to translate the reference into a concrete implementation.
The ViewResolver (see Listing 8-1) has only a single method that is used to resolve to a View.
When a view has been selected, the dispatcher servlet will call the render method (see Listing 8-2) on the view instance.
The getContentType method is used to determine the type of content.
View Resolvers In Chapter 4 we showed the hierarchy for the different ViewResolver implementations.
Let’s take a closer look at the generic usable implementations, how they work, and how they can be configured.
The implementations specific to particular view technologies are explained in the “View Technologies” section.
If there is, the resolver will return it; otherwise, it returns null.
This view resolver is useful in small(er) applications; however, it has one big drawback in that each view needs to be configured in the application context.
It has a single property that can be configured, and that is the order in which it is being called (see Table 8-1)
In Listing 8-3, you can see how and what we would need to configure to have our index page served.
The higher the number, the lower the order in the chain.
The location of the resource bundles defining the view beans.
Can be used to configure shared properties and have them applied automatically.
By default this is null, allowing for lazy initialization of views.
The higher the number, the lower the order in the chain.
It can optionally modify the URL by adding a prefix and/or suffix to the view name.
In general this class serves as a base class to the different view technologies like JSP and template-based view technologies (see section “View Technologies” later in this chapter)
In Table 8-4 we can see the properties for this type of view resolver.
The higher the number, the lower the order in the chain.
When this property is set to false, the URL will be resolved relative to the current URL.
The default is null, which means you are not exposing the RequestContext.
Exposing a RequestContext can be useful when using standard JSP tags like useBean or for technologies that don’t have access to the request, like Velocity.
In Listing 8-8 we see a sample configuration for this view resolver.
The result is essentially the same as in Listing 8-8
To work with this view resolver and views we need an XSLT template for transforming our model to a view.
Although this mechanism can be powerful, it is the author’s belief that this isn’t something to be used to create a view layer for a web application.
It in general is easier to return XML (or JSON) from the controller and directly process that on the client with JavaScript.
It works by first determining which contenttype is requested, which it does by checking the file extension, checking the Accept header, or checking a request parameter (this is configurable; see Table 8-5)
After the content-type is determined, the resolver consults all configured view resolvers to collect the candidate views by name.
Finally, it selects the best matching view by checking if the requested content-type is supported.
Table 8-5 shows the configurable properties of the view resolver.
Very useful when using a marshaling view or to return JSON.
This property is optional; when not specified it will fall back to the Java Activation Framework (JAF) (if available) to determine filetypes.
By default it detects all view resolvers in the application context.
This is already set by default, but if you change the order keep this in mind.
Implementing Your Own ViewResolver This section explains how to implement our own view resolver.
We will create a simple implementation that resolves the view name from a map of configured views.
Implementing your own view is quite easy to do; you just create a class and let it implement the ViewResolver interface (see Listing 8-1) and provide the necessary implementation.
We are going to use this implementation in the next section when we need to add views for PDF and Excel.
In this section we will discuss several view technologies and see how Spring MVC supports them.
For some there is extensive support; for others very little.
Figure 8-3 shows the View class hierarchy, where we can see some of the supported view technologies.
For some of the technologies we need to specify a specific a ViewResolver to work, others work hand-in-hand with the already configured view resolvers.
The next part of this section briefly covers some of the supported view technologies.
It will show the support classes and how to set up Spring to work with the specified technology.
It does not provide indepth coverage of all the different supported view technologies; there are books available for most of the technologies mentioned here.
Note  The TilesViewResolver has order 2 in most listings in this section.
If you want to use JSF, it is suggested to use Spring Web Flow with JSF as the view layer; that approach provides for a rich environment.
The Spring support for JSF is simply that we can reuse our beans from the application context.
If a name cannot be resolved, the resolver will then delegate to the look up to the root application context.
This allows for reuse of services and other general components within JSF.
Listing 8-11 shows the configuration for the JSF part of the application.
This is useful when using scoped beans from the application context in JSF.
This utility class provides two convenience methods to gain access to the application context and retrieve beans from it, which in turn can be used from the custom component.
Tiles Apache Tiles2 is a powerful page composition framework that allows you to compose your page of different page components (the tiles)
These page components can be reused and configured in different page layouts.
Originally it was designed as a JSP composition framework; however, it can also be used to compose Velocity and Freemarker-based views.
To get started with Tiles we must configure and bootstrap the engine for it.
Next we also need to configure the view resolver to be able to return Tiles-based views, and finally we need to specify our page composition and add the different templates (tiles)
Finally, we also need to specify our page compositions and add the templates.
Configuring Tiles Before we can start using the tiles support we need to bootstrap Tiles.
The TilesConfigurer by default loads a file called tiles.xml from the WEB-INF directory; this file contains the page definitions.
Before we take a look at the definition file, let’s look at the properties of the configurer in Table 8-6
It renders the other properties of this configurer class useless.
When setting a custom implementation, the initializer should initialize Tiles completely, as setting this property renders the other properties on this class useless.
The TilesViewResolver has no additional properties to set; it has the same set of properties as the.
It is a convenience subclass that automatically configures the correct view type to return.
Configuring and Creating Templates Tiles requires one or more files to define our pages; these are called the definitions files.
We have created three definitions: the definition with the name template is the general layout configuration, the other definitions extend this general layout (and could override the predefined attributes)
For Spring to select the correct definition, our definition name has to match the name of the view (or a * wildcard as we did in our sample)
Listing 8-15 shows our template.jsp, which is used for the general layout.
Listing 8-16 shows our index.jsp, which is used as the body for the welcome page.
Tip  The highlighted code sets a variable based on the content of the title attribute from our tiles.xml.
That way, we can specify a key on the configuration and use the Spring message tag to resolve the actual value.
You can use them, among others, to create templates for HTML pages.
They are text-based templating engines and both are widely used in applications for all kind of templating solutions.
Velocity and FreeMarker templates aren’t compiled into Java code as JSPs are.
They are interpreted at runtime by their templating engines; this is much like the XSLT processing we discussed earlier.
One might think that this interpretation instead of compilation could lead to performance degradation of our application, but this is often not true.
Both engines have extensive caching of interpreted templates, which make them quite fast.
Another advantage of using a templating approach over JSP is that in the latter case you might be tempted to put Java code in your JSPs.
Putting Java code in your pages, although possible, is not an approach that one should take.
It generally leads to pages that are hard to maintain and modify.
The disadvantage is that we need to add some extra configuration to our application.
We first need to configure the templating engine of our choice, and next we need to configure view resolving for that templating engine.
Configuring the Template Engine The Spring Framework extensively supports both Velocity and FreeMarker, and there are some helper classes to make configuring the engines easier.
It is allowed to mix different resource paths (see “Resource Loading” in Chapter 2)
Can be used to override properties from the configuration file or to fully configure the template engine, using either Properties or a Map.
Can be used to override properties from the configuration file or to fully configure the template engine.
These objects will be passed as variables to the FreeMarker configuration.
Sets the path to the FreeMarker templates; this can be a comma-separated list of paths.
It is allowed to mix different resource paths (see “Resource Loading” in Chapter 2)
The most important properties in these tables are the ones that set the location from which to load.
For Velocity this is the resourceLoaderPath and for FreeMarker the templateLoaderPath.
It is a best practice to make them inaccessible for web clients, which can be done by putting them inside the WEB-INF directory.
These are for bootstrapping the engines for use as non-web templates, like email.
In addition to setting up the different engines, we also need to configure a view resolver to resolve to correct view implementations.
It isn’t required to use these specialized view resolvers; an.
However, using these specialized view resolvers makes our life easier.
Table 8-9 describes the different properties for the view resolvers.
The default is false, which would lead to an exception when an attribute with the same name is encountered.
The default is false, which would lead to an exception when an attribute with the same name is encountered.
It will be exposed in the model under that name.
It will be exposed in the model under that name.
The Templating Language Now that we have configured our environment, we also need to write a template that shows the page to us.
Looking at the templates, we can see that they are similar to the JSPs we wrote in the previous chapters.
Both libraries offer more or less the same support as the Spring Form Tag library for JSP.
Table 8-10 provides an overview of the different tags, or better macro libraries, for both Velocity and FreeMarker.
The parameters to any of the macros listed have consistent meanings:
The keys to the map represent the values that will be POSTed back from the form and bound to the command object.
The values belonging to the key are used as the labels to show to the user.
Usually such a map is supplied as reference data by the controller.
Any Map implementation can be used, depending on required behavior.
If no information is supplied (or the value is empty), the errors will be wrapped in <b></b> tags.
Tip  The two macros marked (*) in the table exist for FreeMarker; however, they are not actually required, as you can use the normal formInput macro specifying hidden or password as the value for the fieldType parameter.
The difference between the FreeMarker and Velocity macros is that with FreeMarker you can, as in JSP, specify which library to use.
This isn’t possible with Velocity macros, because they are global and are included (and accessible) on every page.
For FreeMarker we need to specify the library by using the import directive (see top of Listing 8-20)
Dates and Numbers Velocity has several useful tools available for formatting dates and numbers.
Spring can also integrate with those tools so that they can use the current selected locale.
Setting these properties will expose the tools to the model so that they can be used in the view template.
When we extend this class we must implement the buildPdfDocument method.
We are going to create a PDF that gives an overview of one of our orders on our account page.
This is also where we will start using our custom view resolver (see the discussion of implementing your own view resolver)
We do this because we also want to be able to resolve an order view for an Excel document (see the “Excel” section )
After these changes we need to redeploy our application, if we log in and navigate to our account page we can now click the PDF link and actually get a PDF instead of the HTML version.
Figure 8-5 shows the result of clicking the PDF link.
Although this approach is very flexible, the drawback is that we would need to code the construction of PDFs for each PDF we want.
If we have some complex PDF or need to apply a certain style, this will be quite cumbersome and hard to maintain.
In such cases, it might be worthwhile to look at solutions like JasperReports (see the section “JasperReports”)
Next to the view we need to add a view resolver.
In our sample application we are going to add this, just like the PDF view, to our ViewConfiguration class.
It will determine which of the resolved views best matches the content-type requested.
So without changing our controller and by simply adding some configuration (and view implementations), we can differentiate which view is being served.
To test, click the xls link and an Excel document will be downloaded for you to view.
The XMLbased view uses the Spring XML support to marshall our model to XML.
We can quite easily configure our view resolver to also expose XML and/or JSON to our clients.
We simply can add a default view for XML and JSON (we can also add additional view resolvers, as we did for the PDF and Excel documents)
Listing 8-25 is the modified configuration (see the highlighted parts)
We choose here to use the XStream8 library because that is quick and easy to use.
More information on marshalling and XML can be found in the Spring Reference guide.
Caution  When using these type of views together with an ORM implementation (like in our sample) one could get issues like lazy loading or loading half the database due to collections getting initialized.
If we now change the URL in the browser to end in either .json or .xml, we will get a JSON or XML representation of our order (Figure 8-6 is the JSON sample)
We have now five different ways of viewing our order (HTML, PDF, Excel, JSON and XML) without touching our controller and by simply changing our configuration.
JasperReports Spring MVC provides support for the reporting engine called JasperReports.9 This reporting engine uses report designs in XML and can output different formats based on that XML.
There is a powerful report designer called iReport Designer which can be used to create the report designs.
One could use an XML or text editor to create the designs, but that isn’t recommended because the XML is very verbose.
Spring supports JasperReports with a view resolver and six different view implementations.
The view implementations can be found in the same package.
The first four implementations produce a predefined format, either CSV, HTML, PDF, or Excel.
The last view implementation acts as a wrapper around the first four views or can be configured with specific implementations.
To use one of the views, we need to add the view and configure the URL of the report design.
Either way, internally a compiled version of the report is needed for performance reasons.
It can be wise to precompile the reports for production usage.
By default there should be a key named format in the model that tells us which format to render.
This allows you to configure the views without modifying your controllers.
The multi-format view needs our controller to be modified, and we need to put logic in there to determine what to render.
Filling the Report Just as in the PDF and Excel examples earlier, it would be nice if there were something to show to our users.
Like the other view implementations, the View implementations for Jasper Reports use the data from the model for rendering.
However, Jasper does this a little differently than other view technologies.
If the attribute is a Collection or array, it will be converted into a usable JRDataSource implementation.
If our model contains multiple attributes, we need to specify which attribute we want to use.
We do this by setting the reportDataKey property on the view.
Failing to do so might lead to unexpected results, as the first JRDataSource, Collection or array detected is used to fill the report.
There are several implementations available from JasperReports for different data sources, ranging from databases to Excel documents.
Summary This chapter covered the view part of Spring MVC.
We looked at view resolving by covering several general-purpose ViewResolver implementations.
We also covered several view technologies supported by Spring MVC and explained how to configure Spring to use them.
We started with JSPs and we briefly touched on JSF and how you can integrate Spring into a JSF application.
Next we looked at several templating solutions; specifically, we covered Tiles, Velocity, and FreeMarker.
In the previous chapter we covered JSON, and in this chapter we covered another way of exposing (part) of our model as JSON or XML.
Finally we looked at JasperReports for creating reports based on a templating language.
One important thing to take away from this chapter is the separation of controller logic and view logic (which was demonstrated by the different representations of our order)
This shows the power of applying separation of concerns and the flexibility it gives one.
We will probably never use all the technologies in a single application.
It will probably be limited to two or three different technologies (for our pages and probably creating a PDF or Excel file)
But it is nice to have the flexibility to change or simply add a new view layer to our application.
Testing is in most projects a bit of a struggle point.
We all know testing is important, but we also know that testing takes time and writing good tests is difficult.
It doesn’t involve producing flashy UIs with cool effects, and it doesn’t require you to make brilliant designs either (don’t get us wrong, testing requires good design, but it is mostly repetitive and not as engaging as production code can be)
Maybe the biggest challenge is that your project doesn’t seem to move forward when you are writing tests.
It feels like you are wasting time while you could be building functionality instead.
Because of this, testing is sometimes “forgotten,” or promises are made to write tests later on.
While there are numerous books and even more references to be found on the Internet, we are not going to talk about methodologies and the like.
In this chapter, we want to start by reminding you why tests are really so important, and we’ll also try to define how we are going to approach testing throughout the chapter.
In the code examples, we will introduce you to a way of testing using Spring’s test support that will be appealing and easy to handle.
We will show different methods for testing your application and how to build those tests.
The title of this chapter is “Testing Spring MVC Applications,” and this is meant in the broader sense, as we will discuss testing on every level of the application.
We will start with the easy part, how to test our back-end modules: the repositories and services using Spring’s test support.
We’ll also show you how and when to use mock objects.
Later, we will discuss how to test MVC controllers and finally perform full-fledged browser tests of our pages.
Introducing Testing Before we dive into the code, we want to make sure you are aware why writing tests is so beneficial.
We will also look at some important things you can do to make (and keep) testing attractive within your project.
When writing tests is a pain, you can be sure that the test quality is poor or even worse, no tests are written.
To conclude our introduction we will look at the different kind of tests.
We will explain the differences among them and look deeper into the kind of tests we will be covering in this chapter.
So let’s start by having a look why you should be investing your time in writing tests.
Why Should I Bother Writing Tests? Testing should be a natural reflex that is part of your daily development process, just like writing functionality, delivering builds, fixing bugs, tracking issues and so on.
Writing good test cases sometimes can be more complex than writing the code to implement the actual business case.
This is the first requirement for having successful testing within a project.
If it takes too much trouble to write a test, or a test is never automatically run, people will find excuses not to write them.
A test should be considered a first-level citizen within your project.
We all know the feeling; after you changed some code, how can you be sure the code actually works? Some might argue that depending on your experience, background, and skills this fact alone does not require a test per se.
That might be so, but what about the impact of your change? Your code might work fine, but do you know it doesn’t break any other code depending on it? Also, have you thought about the people coming behind you who will need to change your code? They are looking for some guarantee that what they did is actually OK and did not break anything else.
Without testing, your implementation might look like Figure 9-1 before you even realize it:
This diagram represents the requirements to be implemented and the actual implementation.
It is referred to as the “amoeba effect” in Jaroslav Tulach’s book Practical API Design1 – admittedly in a different context, but the idea is also applicable here.
If we were all perfect developers, writing 100% correct code, the implementation would have the same rectangular shape as the requirements.
Unfortunately, that is not the case, and the implementation will be deformed.
You can also call it “buggy,” or “not compliant” in terms of what has been asked for.
Note  Here we consider the requirements as being the absolute truth, since they are drawn in straight lines forming a rectangular shape.
The requirements will also contain a failure margin beyond to what is really been asked for.
But from the developer’s point of view the requirements are what they are, and the code should resemble them 100% (if not, the requirements should be changed first)
So, wouldn’t it be great to have some kind of robot super developer that is integrated in the project, and that told you every time your implementation was going to deform, so you could have stopped this?
You might have caused it by simply refactoring something in the application, or after changing some functionality.
After performing even the smallest change, you could call the robot developer for free and ask it to check all dependencies and analyze all impacts of your work.
In the first case you will be experiencing the “cozy warm feeling effect.” In the second case you are thankful to the robot pointing out a potential bug.
In that case you continue by changing your code (or your test) so it maintains the rectangular form as closely as possible.
That robot developer exists and is hidden in your tests.
Every time you can write a test case, you should.
Every time you write a test case, you should make the best out of it and you should treat it as important as the code you are testing.
Test cases are investments, and they safeguard the future of your project.
After you have a suitable test harness (a suite of tests), you can make sure that after every change your code still complies with the harness.
The harness is formed after the requirements, which means that each test tests a part of the requirements.
If you add up all the tests, you ideally have tested all the requirements of your project (see Figure 9-2)
Adding a test harness to keep the code in line with the requirements.
In this figure we added a test harness that attempts to map our testing to our requirements.
As you can see, the test harness isn’t a perfect rectangle either, but it is a lot closer than the badly deformed implementation.
A test harness cannot be perfect, because it never truly tests everything and also can contain bugs itself.
However, applying the harness on this deformed implementation will yield a lot of failures that you can fix until your implementation becomes more and more like your requirements.
And above all, after fixing this code to map closely to the requirements, your test harness will act as a monitor for your code.
Every time a new deformation occurs, you will be alerted so you can take proper action.
How you write your tests, before or after your actual production code is up to you.
But it can be said that if you write a test after writing the code, it’s best to keep the interval as short as possible.
In the model shown in Figure 9-2, the implementation that we are testing should be seen as a very small part of your project.
It would represent a single class or even a single method, for which you write a unit test— as soon as possible after writing the code.
Promoting Testing Within Your Project If it is too hard to write a test, or a lot of refactoring has to be done in your code to test a particular module, you can be sure that no single test is going to be written.
Many developers see testing as an extra task that they have to fulfill.
In this section we want to give some tips to promote testing within your project, so that writing tests becomes easier and more appealing.
The project should be as supportive as possible to write tests for.
This section is of course not exhaustive, but we hope it gives an idea about the more important aspects.
Goals: The first thing you can do within a project is setting a testing goal; for example, targeting a high percentage of production code covered by tests is a nice goal to strive for.
EclEmma2 is a very nice plug-in that will do that for you.
We will show you its output after we have written our first test in the next section.
There is also a plug-in for Gradle and Maven to run Emma3 in an automated fashion.
You could even set minimum goals of coverage before a build is considered successful.
Code coverage can work psychologically to make developers have a target; to get the percentage of covered code as high as possible.
This is a form of “gamification”; it helps motivating ourselves to do the best job possible in writing tests by engaging ourselves to obtain a high as possible coverage rate.
However, beware that quantity is not more important than quality, so one should not lose sight of the quality aspect.
Writing a test that gives 100% coverage is not very difficult, but that doesn’t mean the code by itself is well tested.
Code testing coverage is a minimum indicator to get a feel about the test quality.
Infrastructure: We are talking about frameworks and structure within your project.
You should start building out a good platform to write your tests upon.
As mentioned before, writing tests is an investment, and that investment should be well protected.
But if anything happens to your car it will pay for the costs, and oh boy, when this happens you are glad you paid for that insurance! The same is true with tests (only accidents will happen on a daily basis, and using your tests is free once you build them)
They will start to pay off as soon as you start to refactor or change your application.
Importance of testing: Tests are sometimes more important than the code they test, because they are the proof that the code is working.
Without a test the code doesn’t mean anything, as its behavior is an unverifiable state.
Even if you can really be sure that the code will work, you probably have no idea about the impact.
Others are depending on your code and might suddenly notice a change in behavior breaking your project.
If every component was adequately tested, this would immediately show up after running the tests.
Understanding: You should understand the different levels of testing and when to apply which type of test in which situation.
You could test an entire application by using frontend testing, but that would be a bad idea.
You are not required to test Spring, or Hibernate, or whatever library you are using.
Environment: Your tests (both unit and integration) should run on a constant basis.
You should have a dedicated machine just building your project on every commit.
For a CI (Continuous Integration) system, we advise you to check out Jenkins4 (which was called Hudson before they changed the name for legal reasons)
It is extremely simple to set up and works very well.
It will check out THE (?) code from your Version Control System (VCS) and build it.
If your project can be built with a build tool (like Gradle, Ant, Maven, and so on) it will only take a few minutes to schedule an automated build.
They should be able to run even on your Smartphone without requiring any resource or environment dependency.
Tests should also be easy to run, preferably with a single command without requiring any form of configuration or setup.
Note  The best way to verify your project’s test suite is to take a random device that is able to run Java, perform a checkout from your VCS, disable all network interfaces, and enter a single command that should perform a build and run your tests.
There should be no failures, and your test coverage should clearly indicate that the major part of your project is tested.
There is also a great tool called sonar5 (open source) which does exactly that, checking out your code from VCS and applying all kinds of metrics to it, including test coverage.
We would certainly advise you to try this, as it is very easy to set up and the advantages for safekeeping your code quality are major.
It is important that we decide which level of testing we are going to cover, and most of all give a clear definition of it.
In this chapter we will look at unit, integration, and system testing.
We will start by giving an overview of the different types of testing and a word of explanation.
This list is not exhaustive, but it gives an idea of the level of testing we are going to cover.
Unit Testing: The basic definition of a unit test is “a discrete test condition to check correctness of an isolated software module.” A unit test functions at the lowest possible level of a software module, preferably a single method of a class, without having any dependencies (like resources)
We will look into unit testing in more detail in the next sub section.
Integration Testing: Unlike a unit test, integration tests have a larger scope that involves testing several layers of your application.
We will look at integration testing in more detail in the “Integration Tests” section.
System Testing: Like integration testing but using the real resources.
The resources could be scaled-down versions of the actual production resources, but it is important that the environment setup and topology match as closely as possible.
This will make sure that the transition of your project to other environments goes smoothly.
The tests are also written without any internal knowledge of how the application is built; they treat the application to test as a black box.
Front-end testing with a real browser is also a form of system testing.
User Acceptance Testing: Acceptance testing is testing performed by users interacting with the interface of the application.
It is a manual kind of testing that is performed whenever a piece of the software is implemented.
It is a good thing to perform acceptance testing frequently and as early as possible; however, unit and integration tests should locate most of the issues before they ever reach the users.
So acceptance testing should not be seen as a replacement for unit and integration testing.
Performance Testing: Ideally performed on as close as possible a mirror of the production setup where the application will finally be deployed.
By setup we mean everything—the hard- and software, but also the dependencies such as the databases (including data), external services, and so forth.
Performance tests aim at detecting what the throughput of the application will be under normal load.
For web applications it can be the average response time of requests with a predicted user load.
The results of performance testing can verify whether the application will be able to comply with the proposed Service Level Agreements (SLAs)
Stress Testing: Ideally requires the same setup as performance testing.
However here we are putting the application under an abnormal amount of load (or stress)
It aims at detecting weak spots such as transactions that start to break or other failures that do not appear under normal operation.
In general it gives an idea about the stability and robustness of the entire setup when the borders of normal load are crossed.
As explained we will limit ourselves to discussing unit, integration, and system testing.
For system testing we will limit ourselves to automated front-end testing.
These three layers are the ones that should make up 90% or more of your entire (automatic) test set.
They are the ones that will prove that your code is working and will remain working when features are added or code is refactored.
These tests will be able to run automatically and everywhere.
At this level Spring’s test support will also prove itself to be the most useful.
Let’s continue by taking a closer look into unit tests.
Unit Tests A unit test accompanies the code on its lowest level possible and is written at development time.
It can take many forms, from a basic test that verifies the behavior of a domain object to a more compelling test that verifies the behavior of a business service.
Most important, a unit test is system independent and does not depend on any resource whatsoever.
If a piece of code depends on a resource, that resource is “simulated” one way or the other.
We will discuss mock objects, or mocks (which are a form of simulators) in the coming sections, but for now it’s enough to understand that a mock is a code replacement for a resource.
The most important criteria a good unit test should comply with can be listed as follows.
A good unit test should do all of the following:
If it needs to wait for database connections or external server processes, or to parse large files, its usefulness will quickly become limited.
A test should provide an immediate response and instant gratification.
Have zero external configuration: A unit test must not require any external configuration files, not even simple text files.
The test’s configurations must be provided and set by the test framework itself by calling code.
The intent is to minimize both the runtime of the test and to eliminate external dependencies (which can change over time, becoming out of sync with the test)
Test case conditions should be expressed in the test framework, creating more readable test conditions.
Run independent of other tests: A unit test must be able to run in complete isolation.
In other words, the unit test can’t depend on some other test running before or after itself.
In fact, every test method inside a test should be stand-alone and not depend on another method or on the test methods being run in a certain order.
Depend on zero external resources: A unit test must not depend on any outside resources, such as database connections or web services.
Not only will these resources slow the test down, but they are outside the control of the test and thus aren’t guaranteed to be in a correct state for testing.
Leave external state untouched: A unit test must not leave any evidence that it ever ran.
Unit tests are written to be repeatable, so they must clean up after themselves.
Obviously, this is much easier when the test doesn’t rely on external resources (which are often harder to clean up or restore)
Test smallest unit of code possible: A unit test must test the smallest unit of code possible in order to isolate the code under test.
In object-oriented programming, this unit is usually a method of an object or class.
Writing unit tests such that a method is tested independently of other methods reduces the number of code lines that could contain a potential bug.
Integration Tests An integration test accompanies the code and is written at development time, just like a unit test.
However, unlike the unit test, an integration test spans multiple layers and tries to use as many resources as it possibly can.
In our case integration tests are designed to never depend on “real” system resources in such a way that the test depends on a specific environment.
Your tests should be able to run anywhere and anytime.
An example that breaks this rule might be a prepopulated external database.
In that case you can only run the test in the environment where you can access the database.
If the database is down or experiences problems, you will be unable to run your tests.
Otherwise, multiple users will not be able to run the tests at the same time without interfering with each other.
When you are developing remotely and don’t have a VPN connection, you won’t be able to connect to the database and thus won’t be able to run the tests.
All of this makes your life harder than it should be and may quickly demotivate you from writing good and complete tests.
Our integration tests will use in-memory equivalents of these resources: in-memory databases, inmemory directory servers, in-memory browsers, and so forth.
If at a certain point it becomes impossible to fall back on such resources, mock objects are used in the same way as with unit testing.
An integration test is no replacement for system testing using the real resources.
But it tries to simulate the target environment as closely as possible, reducing issues when performing the actual system or user acceptance testing.
Real system testing is usually more resource-intensive and harder to automate.
You will benefit in these latter testing stages if you have created a solid integration testing harness, because many problems will already have been detected and solved thanks to these integration tests.
The important thing to remember is that these tests are all accompanying the project.
If any test fails, your project is “broken.” Also, don’t forget that integration testing that isn’t dependent on actual resources and users enables you to nail down a lot of fundamental problems in an efficient manner early in the project’s lifecycle.
This makes later system testing and user acceptance testing smoother and easier.
It is always better to use a resource (which runs in memory or does not create a dependency) than to use a static simulator or a mock.
As a final word on in-memory resources: it could well be that your project uses special queries that only run on a specific DMBS, and hence there is no use in firing them at another database.
It might also be the case that the statements in question are not even supported.
In most cases these special queries only take up a very small amount (for an average project) of the code base.
It is better to create resourcedependent (system) tests just for those specific cases than to make your entire test set dependent on real resources.
Also, if you are using DBMS-specific features or complex query logic that is impossible to simulate on another resource, are you sure that your Java code is the right place for it? Isn’t a database object such as a (materialized) view, procedure or function a better solution? This point leads into an architectural discussion, but it is important to consider and can have impact not only on your overall architecture and reusability but also the testability of your (Java) project.
Note  There is not always a clear separation between a unit and an integration test, although this discussion has emphasized the idea of a noticeable dividing line.
Sometimes you just need to test that business algorithm without being bugged with “how to get the data.” We would call that a unit test.
In another situation, you want to make sure that an HQL or JPQL query translates to executable SQL and performs what you want.
This is something we would execute against an in-memory database and hence call it an integration test.
Setting Up a Basic Unit Test In this section we will explain how to set up a basic unit test using the JUnit framework6 without any Spring involvement.
If you are already familiar with JUnit,6 feel free to skim this section quickly.
Note  From experience we know that most developers are at least familiar with JUnit.
Since we want to explicitly show you the Spring testing framework, we opted to do this in combination with JUnit.
However, we also advise you to take a look at TestNG.7 While it is not source-compatible with JUnit, they look the same on the surface.
If you know JUnit, using TestNG will be a breeze.
However, TestNG has noticeably more features related to ordering tests, expressing dependencies, and managing greater amounts of tests.
There is also an STS (Eclipse) plug-in (and build plug-in for Gradle and Maven)
See this IBM8 resource for a nice comparison between the two frameworks and see what suits you and your project best.
Our basic setup starts by creating a Java class (which will become our test) in the test class path (src/test/java)
We will be using JUnit4, which uses annotations to denote specific functionality.
We create a DummyDao class in the production classpath (src/main/java), which will serve as our class to test (see Listing 9-1)
The DummyDao will execute operations on a virtual database, in our case a simple ArrayList.
The DummyDao class has three operations: delete an entry from the database, add an entry to the database, and search for entries in the database that contain the given query word.
A simple class representing a DAO (Data Access Object) that we are going to unit-test.
Next we add tests for each of the methods (see Listing 9-2)
The @Test annotation denotes a method as a test method.
This method will be picked up and executed by JUnit.
Inside this test method you will write the code to test your actual production code.
Other methods in the test class not carrying a specific annotation are left alone.
It will make sure our database is populated with our initial data.
If a @Test method changed the data, we will make sure the data is reset to its initial state.
It is important that each method runs as an independent test.
You should not make dependencies between @Test methods, as your test code becomes brittle and hard to understand very fast.
Also, you have no control over the order in which the @Test methods are executed.
Once you have at least one @Test method, you can right-click on the class and select Run As.
These methods allow you to verify the behavior, and let the test stop if the behavior is not what you expect.
This is just a bit of sugar syntax, as it makes your code more fluent to read.
If we take the testDeleteQuery method as an example, we first execute the delete query to delete an entry in our database.
Next we check to see whether the database indeed contains one entry less.
When this is not the case, the assertEquals fails and that particular test method is marked as failed, as shown in Figure 9-3
If all tests succeed, you see a green bar like the one in Figure 9-4
The @After method is run after each test method, even if the method throws an exception or if one of the assertions fails.
If you didn’t specify it, the next test method will run.
BeforeClass and @AfterClass run only once, at the beginning of the test and at the end.
JUnit has a few more extra features such as Suites and Categories, but they are outside the scope of this chapter.
This wraps up our quick introduction to JUnit and how to write a quick test.
This will be sufficient for the remainder of this chapter.
Testing Code Coverage Using the STS plug-in EclEmma, you can get an overview of the code that has been tested by your test.
This is as easy as going to the Spring dashboard, clicking the extension tab on the bottom of the view, and typing eclemma in the search field, and installing the EclEmma plug-in (see Figure 9-6)
We can clearly see that our DummyDao class has been tested 100%, so every line of code has been touched by our test case.
Depending on the type of class you test, it is not always possible to get 100% coverage, but this is the goal you should strive to for each test you create.
Note that in some cases it is not feasible or simply not required to have 100% coverage.
For example, if your object has multiple get/set methods (generated by your IDE), then testing those is a bit superfluous, even though it results in not getting 100% coverage.
If you lose coverage because of code depending on resources, you can use in-memory resources or mocks as we will discuss in the next sections.
After performing the coverage, you can also double-click on the actual production class you have tested: DummyDao in our case.
EclEmma will indicate the lines that have been (or have not been) tested.
In this run everything will turn up green, since every line of code has been tested.
We also performed a second run, removing all references in the test method to the find method of the DummyDao.
We placed the results next to each other in Figure 9-8
EclEmma showing tested (green) and untested (red) lines of code.
On the left you can see the 100% code coverage of our first run (all green)
On the right you see the run where we removed every reference to the find method in our test.
The find method will turn up in red, as it has not been touched by our test.
The diamond icons on the left of some lines indicate whether the loop ran for each element in the list or not.
For example, if we put a break statement after the if, the loop would only run once, and the first diamond would appear yellow and indicate that the branch was not completely covered.
The same goes for the second diamond, which covers the if statement.
If this statement was not executed, the diamond would also show up in orange.
Using Spring’s Test Support In the previous section you saw how we can create a basic unit test using JUnit.
This was a very isolated test, not requiring any dependencies like Spring or other resources, as a unit test should be.
In this section we will introduce Spring’s test support to create integration tests that actually use these dependencies together in the test.
The Spring test support is all about integrating Spring within your tests.
With a couple of annotations, you can load a Spring context and make it available to your unit test.
This allows you to inject dependencies directly in the test using, for, example autowiring.
We start by creating a normal class in the test classpath (see Listing 9-3)
Ideally you place your test in the same package as the class you are going to test, but on the test class path instead of the production classpath (which is src/main/java)
The start of our integration test testing JpaBookRepository, in src/test/java.
To enable the Spring test context, we tell JUnit it has to bootstrap Spring, by adding the following annotation on top of the class, as shown in Listing 9-4
When you indicate you want to run a class as a JUnit test, the test class is passed as a parameter to the JUnit runtime (in our case this is done by the IDE)
The latter are special listeners that can be executed before initialization of a test class, before running a test class, and before running a test method within a test class.
For our purposes here, only the last one is relevant as it will manage our transactions within our tests; we will discuss this later on.
Finally, we have to indicate which (test) context we want to load for our test class.
One way is to load one or more production contexts.
If you want to differentiate between test runs and the actual application run, you can make use of Spring profiles.
You can also opt for setting up specific contexts just for your test.
This way you can specify exactly which resources you need.
Each of these approaches has its pros and cons, so you should weigh them based on your application and what you are going to test to determine which is best.
The more modular your Spring configuration is (either in terms of annotated classes or XML configuration files), the easier it will become to mix both approaches.
When you have a Spring configuration listing your repositories, but a separate configuration for the datasource, you could load the production configuration for the repositories in your test combined with a separate test context for the datasource (which will in that case point to an in-memory database)
Using this annotation you can either specify a context XML file, using the locations attribute (which takes an array of XML config files) or the classes attribute, which takes an array of @Configuration classes to load the context.
If you want to mix XML and classes, you have to load the one from the other.
That means that if you want to work with XML, but also need to load @Configuration classes, you have to load them from one of the XML context files.
We are going to use our production context classes, so we will use the classes attribute (see Listing 9-5)
In our case this means that all repositories and services are loaded into the context, and an in-memory database is started and prepopulated with data.
We will create a matching test for each of them and apply the same annotations to load the context for each test class.
Note  Instead of repeating the annotation configuration for each test class independently, we could have moved it to a common superclass from which each test could extend.
This would have saved us repeating the same annotation configuration in each test class.
However, to make every class complete by itself we duplicated the configuration.
Also, you should not create superclasses merely to avoid repeating annotation configuration.
Only do that if the classes have something more in common.
For example, to test your repositories you could set up a superclass that has the annotation configuration and sets up a minimal data set useful for all repository tests.
Creating superclasses containing only annotation configuration can quickly result in the wild growth of those classes and make your code less clear.
Because this is a small project, the context almost loads instantly.
To make sure the context is not loaded separately for each class independently, the Spring Test Framework provides consistent loading of Spring application contexts and caching of those contexts.
Support for the caching of loaded contexts is important, because startup time can become an issue, not because of Spring itself, but because the objects instantiated by the Spring container take time to instantiate.
For example, a project with many Hibernate mapping files might take several seconds to load because of the parse time required for each of the mapping files.
If the context is only loaded once, an extra load time of 5 seconds won’t be noticeable.
If your tests run slowly, this starts to degrade your infrastructure, which could then result in excuses not to write tests “because they run so slow.” It is important to keep your test set lean and mean, so that it costs as little time as possible to run the test set.
By default, once the configured ApplicationContext is loaded, it is reused for each test.
Thus the setup cost is incurred only once (per test suite), and subsequent test execution is much faster.
In this context, the term test suite means all tests run in the same JVM.
However, when you run tests from STS one by one, this means the application context will be booted separately for each of them.
The solution (using JUnit) is to build a suite, or run them using your build tool, in our case Gradle.
In that case the application context will only be loaded once for all tests that are run.
Building the chapter9 sample project with Gradle will automatically run the tests.
You start the build by first going into the chapter9 sample directory, and then issue following Gradle command:
In the above example all tests were run by Gradle, and thus share a single application context instance.
In the unlikely case that a test corrupts the application context (for example by modifying a bean definition or the state of an application object) and requires reloading, Spring’s test support can be configured to reload the configuration and rebuild the application context before executing the next test.
The latter can be accomplished by putting the @DirtiesContext annotation on the class, or even the test method, that is altering the application context.
The next test class (or test method) will get a refreshed application context.
You can also inject the ApplicationContext directly if that would be required (see Listing 9-6)
Because we enabled Spring’s test support, we now enabled Spring for our test cases with the supplied configuration.
We can for example autowire any bean directly in our tests that is loaded in our Spring configuration.
Managing Transactions from Within the Test Since we are going to write an integration test that will access our in-memory database (through the repository we are testing), we need to manage our transactions from within the test case.
In our production code the transactions are managed by the services and not the repositories themselves.
The repositories take part in the transaction started by the service.
So in this case we need our test case to start the transaction, since we will be testing the repositories directly.
We will do this by putting the @Transactional annotation on the test class, making each test method start a transaction first.
This listener in question will automatically mark the transaction for rollback after the test method ended.
These listeners are not there when you boot your application context the normal way.
So in a normal production scenario the transaction would commit when no exceptions occurred.
It means that CUD operations (Create, Update and Delete) will not modify data in our database.
Allowing them to do so would be the least desirable approach, since that might create data dependencies between tests.
When tests are changed, or for some reason the order in which tests are run is altered, some tests suddenly might start to fail because they depend on data being added by another test that has not yet run.
The best pattern here is to insert the data you need on the method level and let the transaction roll back.
This way the data is not persisted in the database and no traces remain.
Note  When testing a repository, you will probably need some default data setup that can be used for each test method.
Instead of repeating the same data setup over again for each test method, you can safely create this data in an @Before annotated method.
It will also run in the same transaction as the test method itself, and hence data inserted, modified, or deleted will be rolled back the same way as with the test method that is being executed.
This approach of automatically rolling back the transaction at the end of each test method also has a drawback.
When using an ORM (Object Relational Mapping), rolling back works great for Read operations, since all queries have been sent to the database, giving you a complete coverage.
However, when using an ORM like Hibernate (directly or via JPA), CUD operations might not be flushed.
It flushes statements to the database when it thinks the time has come or at least when the transaction commits.
So while you called that method which triggered an update or insert statement, the statement might never be flushed to database when rolling back the transaction.
In that case you never had the certainty the query was actually executed on the database.
You can do this by adding @Rollback(false) on the test method.
You can then create a tear-down method (@After) which removes the data you inserted.
Before the end of the test method, call flush on the EntityManager (in the case of JPA) to let it flush all outstanding statements to database.
Remember that the transaction will roll back, so the changes will not remain persistent.
But they have been received and verified by the database, so you are sure they will work.
Choosing one of the two approaches is a matter of preference; both will yield the same result.
The first approach requires you to have some additional code in the teardown method.
The second approach is more automatic, but requires some more understanding of the ORM you are using.
For the second solution you could also put the flush in a @After method, perhaps inherited from a superclass.
As we mentioned before, the integration test doesn’t give a 100% guarantee.
For starters, we are working against a different RDMBS than your actual target environment.
When rolling back transactions instead of committing them, you’re increasing the possibility that something might go wrong when it actually commits.
However, when applying any of the previously discussed strategies, it is very unlikely that this will happen.
If you flush, all statements have been processed by the database, so there is normally no reason the commit will fail.
Although in very specific scenarios there might still be something that goes wrong, chances of that are very small.
The big advantage is that your tests remain independent and you will never have to figure out why suddenly 10 tests are starting to fail when you.
Note  As you know, a big code base is hard to manage in terms of design, API, consistency and so on.
Do not forget that your tests might even become a bigger code base than your actual production code.
Take care of them and they will take care of you.
Testing the JpaBookRepository We now have all the bits and pieces to start building our test.
For the transaction strategy, we will choose the second option.
That is, we depend on the infrastructure to start and roll back the transaction and we will manually call flush on test method that perform CUD operations.
Next, we continue to define a test method for each of the methods exposed by the BookRepository interface and test them.
For the sample code we will restrict the test to two read methods and one create method of the BookRepository.
The other methods are tested in the same fashion and would not show anything new.
We will also create a setup method (annotated with @Before) which will load the common data used by each of the test methods.
Let’s first look at the test code in Listing 9-7
In this code we make our test transactional by default.
For the read methods we insert additional data using the already discussed JUnit @Before method.
We use the Builder pattern to build our data and it is by default inserted using an EntityManager instance injected in the builders.
This data is also removed when the test method ends because of the transaction rollback.
Note  We said before that one should perform a flush in a test method testing functionality that performs CUD, to make sure all statements are flushed to database.
While testing a read-only method, we first inserted data in the database using JPA.
What about flushing these insert statements? Well, actually, we don’t care.
The ORM will flush them as it sees fit to make sure our read operations work on the latest data.
It might hold back the insertion of the category and book, but from the moment it sees our query to select a book by ID, it will first flush the book and category to database.
The point is that we are not testing any of our CUD operations.
How the ORM manages the write-behind internally to make sure our read operations see the latest data is not our concern.
In our method that tests the creation of new book records, we explicitly flushed before the test method ends.
This way we are sure that the insert statement (generated by the query in the storeBook method of our repository) was send to database (which is probably the only statement)
After that, the test method ends and the transaction is rolled back.
Using Mock Objects In this section we will introduce you to using mock objects.
When creating a unit test, you want to make sure your test is as isolated as possible and does not depend on resources.
In your integration tests, on the other hand, you try to use as many resources as you can, as long as you remain in control and they don’t make your test dependent on a specific resource or environment.
For those cases where you are not able to accomplish this, mock objects will help you.
What Are Mock Objects? As explained in the introduction, in some cases you want to isolate a certain algorithm to unit-test.
That algorithm might depend on a repository feeding it data, and you don’t want to fiddle with setting up data for testing the algorithm.
You want to concentrate the test on the algorithm alone.
A mock object is a good solution here, as it enables you to plug in a replacement of the real resource and preprogram it with data.
Whenever the algorithm makes a call to the mock, it is able to return data that you programmed it with as part of the test setup.
For example, it can be designed to return data only if the parameter of the method call matches a certain value.
When the test is done, you can ask the mock to check if all methods you programmed it with were indeed called with the expected parameters.
Another use case for mock objects is for resources for which there are no easy in-memory alternatives; for example, you have a dependency on a legacy system.
Mock objects fall in the category of so called “test doubles.” There are different kinds of test doubles, but only one of them is a real mock.
In his article “Mocks Aren’t Stubs,”11 Martin Fowler distinguishes the different test doubles and names them appropriately.
If their signature requires them to return a value, it is mostly “null.” Dummies are useful to build objects that you are going to test and have a mandatory dependency on the dummy.
But the dependency in question is not used for testing the given functionality.
A fake is a working replacement for a real resource, such as an in-memory database or an in-memory implementation of a web service.
It is clear that inmemory fakes enjoy real advantages over any external dependency, since those would again break our rule that our tests should be able to run everywhere, while still supplying a high level of guarantee that your code will work against the real resource once the fake is replaced with the real resource.
Stubs are replacement objects that are able to return preprogrammed values when their methods are called.
They normally don’t respond outside the values that they have been programmed with.
The way they capture state is very basic, and the verification process mostly does not allow you to do behavior verification.
Mocks add extra functionality in the training (setting up the preprogrammed data) and verification phase compared to a stub.
A mock will allow you to verify not only that a given method was called on the mock, but also that it was called with the desired parameters.
This is normally built in the mock framework and is not something you have to build yourself (unlike with stubs)
From our experience, all of these deserve a certain place in the project.
While all test doubles can in fact also be replaced by mocks, you probably shouldn’t do so.
A mock object is something that is built on the fly in your test, is programmed with data, expects certain behavior, and is verified before the test.
A dummy is a real class that sits in your project code.
The advantages are that you could use Spring profiles or selective context loading in your test to wire up the one or the other.
This might keep your code base cleaner and tests easier to understand.
Also, when using a mock where you really want a dummy, you will be sending out wrong signals to other developers reading your code.
They will see a mock, which is not programmed and not verified, so they will think it is a developer error.
Using a dummy, you clearly indicate that the dependency is not relevant in the scope of the test you are performing, but the object you are testing has a mandatory dependency on it and so you gave it a dummy implementation.
At certain points you want to build a real integration test.
In the previous section we tested our JpaBookRepository against an in-memory database.
Although we could have mocked the EntityManager, not doing so added an enormous value; it taught us that our JPQL queries were translated to SQL that was actually correct and could be executed by an RDBMS.
Replacing this with a mock would cut critical things from our test and degrade its effectiveness.
Stubs are probably only useful in special integration testing when there is no in easy fake available for a given resource, for example for a legacy system.
The stub could then be wired in as a “dummy with data.”
As a final note, think carefully about which kind of testing double you will be using.
When writing a unit test, think about using dummies first.
If you really need state and behavior verification for the dependency, consider a mock.
If you are integration testing, consider using in-memory fakes as much as you possibly can.
If you are doing integration testing from another interface (front-end testing using an in-memory browser, for example) consider using stubs.
In this discussion we will limit ourselves to using and creating mocks for our unit tests.
In the next section we will dive into the code and test our AccountService, while using a mock for its AccountRepository dependency.
If the credentials are correct, it returns the Account that belongs to the given user.
It does that by loading an Account from the database where the username matches.
So the service first creates a hash from the password parameter and then compares it with the value retrieved from the database (where we store only the hashed values of the passwords)
We are writing a unit test that will test the login method.
We will create a test method that tests a successful login and another that performs a negative test, in which we intentionally supply bad credentials, which should lead produce an exception.
Let’s look at our first version of the test in Listing 9-8
Mockito12 is a state of the art mock framework that we will be using.
Throughout this section we will make you more familiar how you can use Mockito for all your mocking needs.
The line in bold is all that is needed to create a mock using Mockito.
You pass along an interface or class, and Mockito will return a mock object which is not yet programmed.
For the second case we have used Mockito to create a mock.
At this point the test will not run, since we have not yet programmed our mock.
So the next thing to do is program our mock as can be seen in Listing 9-9
We first created the data that our mock will have to return.
In our case it is an instance of an Account.
The last line of code of Listing 9-9 programs the mock.
Whenever the mock receives a call on method findByUsername with the parameter "john", it will return the account.
If it receives calls with other parameters (or other methods that aren’t programmed), null is returned.
The mock will be reprogrammed before a new test execution starts.
It will check that the method we programmed the mock with was indeed called.
Here we will strictly check that the method was called once (exactly once)
After that we reset to mock so it forgets about its programmed data and verification state.
It can then be reprogrammed (which will happen in the @Before method before the next method is executed)
The first line verifies that the findByUsername method was called exactly once.
If it hadn’t been, the verify method would raise an error, letting our test fail.
Normally you create a mock in scope of a single test method.
You create it, program it, verify it, and that’s it.
In the next test method you create a new instance of the mock.
However, in our case the AccountRepository is autowired (by Spring) in the AccountService.
When we create a new instance of the mock, we need to find a clean way to inject it in the AccountService.
In any case we are not violating any rules by resetting the mock this way.
Just be sure you don’t reset a mock in the middle of a test, for example.
In that case you should probably have created two test methods instead.
Note  You can also use static imports for Mockito methods, just as we did with JUnit.
It is in fact a recommended practice, as it keeps your code clean and readable.
In the code examples, we deliberately left the classes visible to make it clear that it is a Mockito object rather than a JUnit object (which might not be obvious if you are new to Mockito or mocks in general)
This concludes the testing of our AccountService using a mocked AccountRepository.
We hope we have shown you how easy it is to set up and verify mocks using Mockito and how useful they are in isolating logic to be tested.
There are plenty of other features that can help you set up the desired mocking environment.
Those are out of scope for this chapter, so we invite you to take a look at the Mockito website for a good starting point.
Testing Your MVC Logic As shown in Figure 9-9, Spring MVC consists of our view layer (JSPs), the controller (Spring internal code), our model, and our application controllers.
It is important that we first decide which of these components we should actually test and which not.
This will be part of our system tests and we will test it later in this chapter in the section “Automated Front-End Testing.” We don’t need to test the controller, as this is Spring Framework internal code.
We explained before how to test the domain using unit and integration tests, so these are already tested.
The only things left to test are our application controllers.
Our first advice is to keep the logic inside the application controllers as limited as possible.
This way they become standalone components which are easy to test without requiring your application controller.
If you apply this rule consistently, you will be able to test 90% (or more) of your code on the frontend using plain unit tests.
This way the application controller will only remain a thin layer between the controller framework and these standalone (easy to test) classes and your model.
Although they are named “Mock” they are more like stubs by our definition of the terms.
We will first show the handle login method, in Listing 9-12, so you can easily follow what we are testing.
The method in Listing 9-12 takes care of handling the login from the login page.
It accepts a username and password submitted from the login form.
It will then authenticate the user using the AccountService and put the result (an Account) on the HTTP session using the constant ACCOUNT_ATTRIBUTE as key.
Next we show the test case (see Listing 9-13) and then discuss some specific code snippets.
As you can see, we use mocking to mock out the AccountService the same way we mocked out the AccountRepository while testing the AccountService, so this should already be familiar to you.
This is actually the URL that was requested before the user was redirected to the login page.
When the user was authenticated successfully, the LoginController also puts an attribute on the session.
This is the account attribute having the Account as value.
The first test simply tests with no value at all.
The last test tests with a value that contains login.
In both cases we verify that the view rendered is the index (home) page.
There is, however, already a usable snapshot which is fairly stable (the 1.0.0 snapshot)
Before we proceed, we have to warn you that depending on snapshots (particularly when there isn’t a prior release) implies some risks, as things still might change.
Therefore we won’t go into detail, but just cover the ideas and the basic setup.
Things will probably change here and there, making in-depth coverage outdated before the module is released into Spring.
However, the ideas that we are showing here should remain stable and should still be applicable in later versions.
Having said that, to be able to use this module we added the dependency in the build.gradle of our chapter9 sample:
Because this is a snapshot dependency, we also added the snapshot repository to the list of repositories in the dependency management configuration.
We did this in build.gradle in the root of the sample directory:
It tries to simulate Spring MVC even better without having to boot an actual Servlet container.
For example; with Spring MVC test you will be able to verify which JSPs were actually selected to render when using Tiles as the view resolver.
This is something that was not possible until now, and could only be verified at runtime (possibly using front-end tests)
The more we can test using unit or integration tests, the better.
The example we will create will show how to use the basics.
This object initializes the MVC infrastructure, and will be your main entry into the API.
Controllers that are required to process the request you fire at them are looked up from the application context.
Also, the MVC environment will be configured as it will be at runtime, with the same view resolvers, resource handlers, interceptors, and so on, just as you have specified in the configuration.
In this mode you supply the application controllers directly, and the minimum set of Spring MVC infrastructure components are instantiatedonly those required for the processing of requests with the registered application controllers.
The set of infrastructure components is very similar to that provided by the MVC namespace or the MVC Java configuration.
Important to note is that the actual Spring MVC configuration will not be tested (because it was never loaded)
The desired method of initialization is the one where the entire Spring MVC configuration is loaded.
However, if you instantiate the MockMvc for every test, it can become expensive.
The configuration is loaded by Spring’s test support as usual.
For the configuration (supplied in the classes attribute) you will use your Spring MVC annotated configuration classes.
After you initialized the MockMvc object (one way or the other), you can start throwing requests at it.
It will process them using actual Spring MVC logic and invoke your controller.
At the end you are able to verify the results.
To keep things simple we constructed the MockMvc object in standalone mode.
The first thing we did is construct the MockMvc object in standalone mode.
We did that by supplying it our LoginController as a constructor argument:
The LoginController is pretty straightforward to test, so all defaults loaded by the standalone mode are sufficient.
You can, however, apply customizations before calling build if that would be required.
For example, a custom view resolver would be set like this:
When the context is initialized we can let it process a request.
Our LoginController only accepts HTTP post requests, so we build a post request with two parameters:
The methods such as post and param are included via static imports on top of the class (see Listing 9-14)
In this case we left this on purpose to show you how compact the syntax becomes when applying this strategy.
In the beginning however it takes some time to get used to the different methods that are available.
We check that the HTTP status code is 200 (isOk), that the account has been set on the session, and that we are being redirect to the index.htm page:
You don’t have to create separate mock objects for request, response, and session, because this is all taken care of by the Spring MVC test module.
By the way, building a MockMvc in managed mode that actually loads the configuration based upon @Configuration classes is not much different and would look as follows:
This wraps up our short introduction to Spring MVC test.
We hope that we have shown you something which will become a very powerful tool in testing your Spring MVC application controllers with a minimum of effort.
We already look forward having this fully integrated in Spring!
Automated Front-End Testing Automated front-end testing is the last piece in the unit testing puzzle.
It helps us test our final untested component, our views.
JSPs can be tested, just like all the other components, in an automated fashion.
You can, for example, test your web application on different browser to check that the look and feel is similar.
You can also test your application for performance, render times, and usability.
All of these are tests which are probably applied in other testing phases possibly using external tools.
The testing that we are after here is to make sure that all our pages render, and that all functionality offered by them also works.
When you have done a good job testing all previous components, this should be a breeze.
This requires a running container, data setup, and possibly fakes or stubs for certain resources and functionality.
The tests also need to run (like any unit test) automatically via your continuous integration system, meaning it should all be integrated in your build system.
This is not as easy as it seems, since you have one little problem: you need to start up a Servlet container that can run your application (see Figure 9-10)
There are plug-ins for Gradle (and Maven) like Cargo,14 which can start a container and deploy your application before these tests are run.
Normally you will have already tested your views by hand when you were designing them.
So normally when every level is well-tested, there should be only minor faults coming out of your front-end testing.
The most important part is that they enforce your “test harness.” Even when you forgot to test something in your services, it could well be tested be one of your frontend tests.
Also, if someone refactors your views later on, you still have the test harness that ensures that your pages are still working.
To set up a front-end test we have chosen Selenium.15 It can be run in two modes, using a real browser like Firefox, and using HtmlUnit, which is an in-memory browser.
This can all run completely in memory and does not have any external dependency, that way it can be considered as an integration test.
This enables Selenium to run tests against a browser of choice out of the box without having the need of additional software.
It required you to have a so called Selenium RC server running between the test case and the browser.
However, the Selenium RC server can still be used in combination with the current version of Selenium.
To explain this, we will first look at how Selenium 1.x works.
With Selenium 1.x the communication between the test case and the Selenium RC server goes over the network (your test commands are translated into HTTP requests being sent to the Selenium RC server)
Potentially the Selenium RC server can be running on another machine than where the actual test is running.
The Selenium RC server then translates the commands received over HTTP to JavaScript calls and injects them into the target browser.
This is a nontrivial process, but it is shielded from the user.
While this setup considered deprecated, it might still be interesting to see how it works.
You can read more about it on the Selenium documentation page.16
Selenium now offers a different method, using WebDriver, which controls the browser directly using the browser’s native API.
So it no longer requires a complex (internal) setup as with Selenium RC that Selenium 1.x used.
Using Selenium you can directly control the browser without having a need for the Selenium RC server.
You simply select the appropriate driver via the API, depending on the browser you want to use.
In that case the RC server will also use WebDriver.
Instead of your test directly using WebDriver to control a browser on your local machine, you now instruct the RC server running on a different machine to communicate with a local browser using WebDriver.
The main difference between the Selenium RC server setup and Selenium 1.x is that the Selenium RC server does much more than that; it also injects JavaScript and acts as proxy, which with WebDriver is no longer needed.
It just functions as a “remote JVM,” enabling you to control a browser on a remote machine.
Tip  Using Selenium RC server is especially interesting for those cases where you want to run the test on machine A but use machine B’s browser.
For example, you could run the test on your CI, which is a Unix-type machine.
To do so, you could set up three virtual machines, each installed with Windows and one of the three browsers, and running a Selenium RC server.
The second time the IP address of the virtual machine running IE 8, and so forth.
You could create Spring test profiles to dynamically inject another IP address depending on the profile with which the tests are run.
Writing a Selenium Test Now that we have seen some theory about Selenium and its predecessor Selenium 1.x, let’s have a look how we can actually use it.
Before we can start we have to add its dependencies in build.gradle.
We will add them in the gradle build file of chapter9-bookstore sample.
We added the core dependency (selenium-java) and a WebDriver dependency for Firefox and HtmlUnit.
Next let’s look at the Selenium test for the LoginController in Listing 9-15
In the setup method we start our browser, which is the actual API to control the browser from within our test case.
If we want to switch to an in-memory browser (HtmlUnit) all code would remain the same.
We just need to assign the HtmlUnitDriver instead of the FirefoxDriver:
Running this will run the tests against the in-memory browser.
There will be no browser popping up when we run the tests like this.
To get an idea of which browsers are supported and their specifics, the best resource is the Selenium documentation.18
To continue with the overview of the test class, we will now proceed to the actual test method startTest.
The first line of the test method tells the browser to which URL to open:
The next lines of code take care of the navigation (clicking on links, entering text, and so forth)
When we click on a link or a button we are using the ID.
You can, however, use more advanced selectors, like CSS and XPath.
You can find more about them in the Selenium reference guide.19
Using the Selenium IDE When you look back at Listing 9-15, you will see that navigation with the browser requires you to look at the JSP source and check the identifiers of the elements you want to use.
For example, to click a button you have to know its ID and then write this line of code:
In this case we are clicking on a button with ID "login"
Our scenario was a very short one, but for longer scenarios this can be become time-consuming and pretty boring.
Fortunately there is a great tool called Selenium IDE which will be able to generate this code for you.
It creates not only Java code, but also other languages as we will see.
According to the Selenium website,20 the Selenium IDE runs only in Firefox at this time.
In order to download the Selenium IDE plug-in, go to the Selenium website21 and follow the instructions.
You basically click the Download link and Firefox will present you with a question to install the software as can be seen in Figure 9-12
After clicking Allow, you will get a display like Figure 9-13, asking for your permission to install.
You can then open Selenium IDE by selecting it from the Tools menu.
After that a separate window should appear, as in Figure 9-14
Selenium IDE will inspect the interactions you do on a page within Firefox and “record” all the events, such as clicking a button, entering text, and so forth.
In order to set this up, you have to add the application for which you want to record in the Base URL text field (See Figure 9-15)
Next you switch back to Firefox and navigate to the application you want to capture a scenario from.
When you are on the home page of the chapter9-bookstore application, you switch back to the Selenium IDE window and click the Record button, which is the round red button on the right top, just below the Base URL input (it looks like an “indicator” but is actually a button you can click)
You can now go back to your browser and perform a test scenario.
We will perform the same actions as we did in the test.
So we will click the Login link, enter username and password, click Login, and then click the Account link.
After that, you can go back to the Selenium IDE window and you will see that lines have appeared in the Table tab, as shown in Figure 9-15
You can click the Record button again to disable recording.
You can now export the captured interactions to Selenium commands for a specific language.
Now, copy all lines in the Table list, by selecting them, right-clicking, and selecting Copy, as can be seen in Figure 9-17
After copying, you can paste this right in your test class file.
The scenario will immediately be in the desired format, as you can see in Listing 9-16
This is almost the same code as we came up with ourselves in the example.
The only difference here is that Selenium also performs an explicit clear of the fields before adding text to them.
Besides using the plug-in to generate code from recorded scenarios, you can also replay scenarios using the plug-in.
For more information we recommend visiting the Selenium IDE documentation page.22
Running the Front-End Tests via Gradle Besides the normal unit and integration tests, we also want to run the front-end tests via our build tool.
When we run the normal build using Gradle (with the command gradle build), the front-end tests are not run.
We created a separate task called systemTest which can be run separately just to run the frontend tests.
The systemTest command makes use of the Cargo plug-in to deploy the application to Tomcat.
It will then run the tests that end in FrontendTest.
The systemTest task looks as follows in our root build.gradle:
The systemTest tasks include every class that ends in FrontendTest.
It also depends on the war task, which means that Gradle will first build a war of the project.
Finally the task cargoStartLocal is executed, which is available because we enabled the Cargo plug-in.
This task will start Tomcat and deploy the war file, which was previously generated by the war task.
In order to exclude these FrontendTests from the normal Gradle test lifecycle, we extended the test task to specifically exclude these files:
Running FrontendTests is as easy as opening a command-line interface, navigating to the chapter 9 sample directory, and typing:
In order for the system tests to work, Firefox should be installed on your system.
The tests will take some time as the application needs to get deployed on Tomcat.
During the tests you will also see Firefox opening and closing, as this is the Selenium test at work.
Note  There are problems reported with the current version of Selenium not being compatible with the latest version of Firefox (which is version 12 at the time of writing)
If you experience problems running the system tests, use Firefox 11 or check the Selenium website for newer versions that fix this issue (which are expected to become available anytime soon)
Summary In this chapter we have seen that it is important to really think about how to handle testing in your project.
It is clear that a project deserves adequate testing to be able to grow and to be maintainable.
Your test should be considered as important as the actual production code.
We have introduced some guidelines; making sure that you test at the right level, and how you can assure that testing remains attractive in your project, as that is one of the key elements to ensure that tests are actually written adequately.
We started with a basic unit test and continued by introducing Spring’s test support, which we used to write an integration test, testing our repositories using an in-memory database.
On the MVC side we showed how you can test an application controller using Spring’s test support and the brand-new Spring MVC test.
With these two tools at hand you are now capable of increasing your overall code coverage even further.
We wrapped up with a full-fledged front-end test, testing our view but also indirectly testing all the logic behind it.
We showed you that it is possible to create a system test using a real browser with Selenium, but that you can also configure it to use an in-memory browser instead (HtmlUnit), making it an integration test.
We hope that the philosophy and techniques introduced here will help you write more and better tests.
The only thing left to do is go out there and put these testing strategies into practice!
In the upcoming three chapters, we will make you familiar with Web Flow and its strengths and weaknesses; we will also cover why, when, and, above all, how you should use it.
In this chapter, we start off explaining what Web Flow is and what it can do for you.
Later on, we will discuss some basic Web Flow elements that you need to understand before you can start building your first flow.
The common thread throughout the Web Flow chapters is the sample application, which we create as we go through these chapters.
We will start in this chapter by illustrating how you can turn a plain MVC sample with a bit of configuration into a Web Flow-enabled application.
Next, we will gradually enhance the bookstore sample application with Web Flow functionality, explaining each feature in detail along the way.
We took special care to ensure that you don’t need the sample application at hand when reading these chapters.
In this chapter, we will limit ourselves to creating a single flow: the create (book) order flow.
In Chapter 11, we will expand the functionality of the sample application, and we will cover some more detailed configuration options.
In Chapter 12, we will make you familiar with some more advanced aspects such as using AJAX, flowmanaged persistence, and so forth.
If you already have some Web Flow experience, you might want to skim this chapter quickly and advance to the next chapter.
If you are new to Web Flow, or want a refresher, then this is the right place to start!
You may wonder why you should bother reading about Web Flow.
You might especially be wondering why you should bother learning Yet Another Framework.
However, within those frameworks, there are still extras that you can add to make your life easier.
By the end of these three chapters, we will have convinced you that using Web Flow can make management of your web applications easier.
Let’s start with some theory first, so we can illustrate what Web Flow can do for you.
Hopefully, this will get you interested enough to read through all three of the Web Flow chapters!
The Flow Concept Despite the many features and advantages Web Flow has to offer, it all revolves around “the flow” (no wonder it is also called Web Flow)
Before going any further, let’s back up and cover what a flow is and what it is modeled after.
This will help a lot in understanding what Web Flow is trying to accomplish and how it will help you.
A flow is something that occurs naturally in most applications (see Figure 10-1)
Imagine a web shop order wizard that requires you to follow several steps to place your order.
You start with Step 1, where you fill in some identification data, such as your first and last name, and then click the Next button.
This takes you to Step 2, which asks you where to ship your order.
Step 3, the last step, allows you to enter delivery options: the type of shipment, whether you would like your package to be sent before a certain date (it’s possible there might be multiple shipments if the package wasn’t complete by that date), and so forth.
If the wizard is any good, it will allow you to navigate back and forward between steps, remembering the state (data) you entered for that specific step in the flow.
Sometimes you could also have the option to skip a step.
At the end of the process, you can finalize your flow.
In our example, this would process your order and make sure your products are delivered as soon as possible.
Web Flow is all about creating these flows, which you accomplish by managing state between the different flow steps, expressing navigation, and so forth.
So far we’ve discussed the core aspects of a flow; however, there are also some other nifty features associated with flows.
Fine-Grained Scoping The first major strength of Web Flow is that it adds extra scopes.
No doubt you already noticed that the servlet specification declares three scopes in which your application can retain state.
A scope is nothing more than a map in which you can store key value pairs, which are, depending on the scope type, stored for a determined amount of time.
There are three scopes defined by the servlet specification: application, session, and request.
In Table 10-1, we will briefly summarize the different scopes and explain how you should use them.
Although this is a very basic topic for anyone who has done Java web development before, we suggest you quickly skim it over, so as not to miss anything.
Application Everything on application scope is visible for the entire web application.
This scope should just contain general initialization stuff or read-only parameters that are shared for your web application.
In 99% of cases, it should not be used to store any user-related state whatsoever.
Most of the time, you will use it as a kind of system properties map, but one that is local to your web application.
Session The session scope is finer grained; for every client, a session is created and maintained.
The session dies if explicitly requested by you, the developer, or the session timeout kicks in.
Because of the stateless nature of the HTTP protocol, a client identifies the session with a so-called session id (handed out by the web container)
Whenever a request is received, the container associates the request with the client’s session based on that id.
Information stored in the session is thus available during the lifetime of the client’s session.
There is no request id because the request does not survive more than a single HTTP call: for each new call, a new request is created.
You might wonder what this has to do with Web Flow.
Just as with any online store, we have an order and checkout process.
In the first step of this process, the user is able to select a category.
The category could be IT, Sci-Fi, Thriller, and so forth.
In the next step, books can be selected from the previously chosen category.
Finally, the user we will be able to select some options, such as the delivery details.
When the user confirms the order, we will need to locate that information (which we gathered in the three previous pages) and create an order.
We need to store this data somewhere in between these different steps; the question is where do we store this data? Let’s look at some options:
Application scope: Obviously, we don’t want information from user x to be visible to user y.
Not only is this unwanted, but it would also create security leaks, where sensitive data from one user might become visible to other users.
Request scope: This is also a bad choice because you would not be able to store the data over multiple pages; the request scope is destroyed after every page render.
You could piggyback data on your pages by adding hidden fields, but this is generally a bad idea.
While this solution offloads data to the client (which might be considered a pro in some situations), it might also trigger security holes (what if you have an internal state that should not be made visible to the client, but is retained?), and you would have to manage this manually within your code.
To put it simply, the lifecycle of the request scope is simply too short to gracefully fulfill our requirement.
Session scope: Well, we have no other options! And while this scope is usually the best of these three options, it has some drawbacks.
We will discuss these drawbacks in the upcoming paragraphs, to give you some background on the issues you will face when using this.
Finally, we will examine how Web Flow can help you overcome the drawbacks of this scope.
The problems with storing such data on the session boil down to clean up and management.
For example, consider what will happen with our data once the user finishes his order and does something else with the application.
Will this data be sitting on the session needlessly until the session times out?
There are a bunch of mechanisms to help you remove data from the session, but none is guaranteed to work.
This might be a bold statement; however, remember that users can do what they want: hit the back button, jump out of your use case, manually type in another URL within your app, and so forth.
Also, how are you going to call your keys in the session map: myData? Are you sure no one else has used that key before? The session can be used by any component within your web application, so you would have to start namespacing your keys (e.g., page.x.data)
So, what do you store on the session? It must be good for something! Consider this example: after a user logs in, you probably want to maintain a security context containing data from the authenticated user.
This information might be needed from anywhere in the application—it might even be required by every page.
For example, you might want to put some personal information (such as the user’s first and last name) in a header section that is automatically shown on every page.
This kind of information deserves to live and die with the user’s session; in this case, the session is clearly the right candidate for storing this kind of context data.
Context data refers to data that is tightly coupled to the session or the application itself; it is data that spans a greater use than a single process or use case within the application.
But in this example, we are talking about plain user data (data captured via a form for a specific process within the application), which is inherently different from context data.
The user walks through multiple screens and enters data in each one of them.
You will need that user data, not only for the current view, but also for subsequent views.
Of course, you may be wondering why we are making a fuss about keeping data on the session longer than needed.
Well, your session should be kept as small as possible; Table 10-2 lists some of the more important reasons for this (albeit others probably exist)
Memory usage The session is kept in the memory of the web container.
The more objects you have (the more data), the more memory the session will consume.
Basically, bigger sessions mean that, for a given amount of memory, your server will be able to handle fewer clients.
When you have multiple servers running in a cluster and your application is load balanced, the cluster might need to replicate the session state.
The bigger the session, the more expensive this kind of synchronization becomes.
Note: When using a cluster with a load balancer in front of it, by definition your sessions are not replicated.
When configuring session affinity, requests for the same session are always redirected by the load balancer to the same cluster instance, thus making replication unnecessary.
Housekeeping As with your house, you want a clean session.
Items put on the session by controller x might be interesting for controller y.
Still, controller y should not start using controller x’s data simply because it can.
Doing so might lead to an uncontrollable dependency between the two controllers and end up in a brittle design.
Whenever you see something useful on the session, you should not need to track back where it’s coming from.
You should be able to rely on the fact that it is something useful for every component.
Unfortunately, this is not possible with standard servlet scopes because you have no options other than putting use case specific data on the session and making it public for other components.
Thus far, we have seen that storing a state is not as easy as it seems.
This might become a problem later in the application’s lifecycle as it continues to grow.
Web Flow offers a solution to this problem by introducing five new scopes: conversation, flow, view, flash, and request (see Figure 10-2)
We won’t cover them into detail here; however, be aware that they are positioned between the session and request scopes.
For example; something put on a flow scope would survive longer than request, but not as long as a session scope.
Flash scope might survive longer than request, but not as long as a flow scope.
Also, the content of these scopes is automatically managed for you with more guarantees than standard session housekeeping.
We will discuss how this works in the upcoming chapters.
However, the Web Flow machinery is specifically designed to make sure you don’t have to worry about the creation and cleanup of these extra scopes.
This is the point where you start to benefit from using Web Flow’s automatic state management.
Automatic State Management Whenever Web Flow executes an action within your flow, it will store the state you used on the different Web Flow scopes in a state snapshot.
Although we haven’t seen any introduction to Web Flow terminology yet, a flow is made up of different actions.
For example, an action could be displaying a page or executing logic on an application controller.
The data that is put on the different Web Flow scopes is automatically managed and versioned for you.
Each time Web Flow returns from executing a requested action, it creates a snapshot of your data, including all its internal state information.
You can compare this process with that of taking pictures.
Before returning to the browser, Web Flow takes a picture of the data and stores it, which means you can potentially refer back to it later, if required.
For example, you can go back to a previous state by using the Back button of your browser.
It is important to realize that this snapshotting feature is built into Web Flow and is automatically at your disposal.
Request Synchronization When designing web applications with Spring MVC (or any other request-driven web framework), sooner or later you are going to feel that you are missing some other important features.
For instance, have you considered what would happen if a user were to click a Submit button on an order books form twice? In theory, there is no good reason why this would happen because clicking a button brings you instantly to the next page.
In practice, this can imply a certain delay, depending on how fast (or how slow) your application responds.
Users tend to be impatient; if there isn’t anything happening within a couple of seconds, the user might even doubt that the first click was successful (maybe he didn’t click correctly?)
So, before you know it, you will have to deal with a double submit coming from the same user and page.
What happens after the double submit depends mostly on sheer luck.
Maybe your form submit was idempotent1 in some way? In this case, being idempotent comes down to executing the operation multiple times without being impacted by any undesirable side effects from the business process point of view.
Creating (and later on, delivering) the same order twice simply because the user double-clicked the Submit button is certainly an unwanted side effect.
Although idempotence is mostly implied by read-only operations, sometimes form submits can be idempotent as well, depending on how you design them.
For example, when creating an account, there will probably be some kind of unique or primary key constraint on the username column in your database table.
If your form is submitted twice, the second submit will fail with a duplicate key, and no harm to your system will occur.
Still, the user probably will probably see an error page.
This is clearly something you want to avoid, but at least you don’t end up creating any duplicate users in your database.
In this example, you are saved by the uniqueness constraint on the table; but with a bit less luck, the opposite could be true, and it would be very easy to trigger undesirable side effects by submitting the form twice.
This might ultimately lead to data corruption or other inconsistencies in your system.
Thus, you typically want to design your application so that submitting a form twice is not possible; or, at a minimum, that it results in no unwanted side effects.
While a simple line of JavaScript might seem to solve this (i.e., you might disable a button after the first click), remember that this will only reduce the possibility of a submitting a form twice.
Disabling the button is far from an ideal or complete solution.
After clicking the Submit button, the user presses F5; this will cause the form to be resubmitted.
The browser will warn the user about this, but it is still possible to submit that form twice.
A user can easily bypass your JavaScript by simulating multithreaded HTTP requests using something as trivial as cURL.2 Or, the user can turn off JavaScript altogether in the browser; you don’t need to be a professional developer to do that!
The point here is that you are looking for something mature that serializes access to a given form submission (for a given session, of course), so your application logic is relieved from handling a duplicate submission (i.e., you don’t want to have to write specific code to deal with this)
Spring Web Flow solves this by serializing access to your flow executions.
After you get the HTTP session id, you’ll get a flow execution key.
The flow execution key is to Web Flow as the HTTP session id is to your Web container.
Web Flow will use this id to identify the execution the user is currently participating in.
But it will also use this id to serialize access to your flow execution (i.e., it will prevent two requests from operating on the same execution at the same time)
But don’t worry: this is also automatically managed for you, and you won’t even notice it.
Whenever a form is submitted twice in your flow, Web Flow guarantees that only one of the two requests (for that flow execution within a given HTTP session) will be executed at a time.
The second request is still pending because the flow execution was locked by the first request.
It will eventually be executed after the first request is processed, unless the first request ends the flow.
In that case, the second request will simply restart the flow, because the flow already ended (see Figure 10-4)
A Web Flow synchronizing multiple requests to the same flow execution.
In Figure 10-4, the top rectangle represents the flow execution dealing with two requests (a double submission from the same browser session)
After processing request1 and before the request ends, it triggers an end state (which we will discuss later on)
In the middle rectangle, you can see the flow execution after the first request has been processed.
The lock is freed, so the second request has a chance to enter the flow execution.
However, the execution is already destroyed; at the bottom rectangle, you can see that a new flow execution is started instead.
In other words, the second request will bring the user back to the entry point of the flow instead of re-executing the action.
This means that a double submission inside a flow execution is still possible.
Web Flow serializes access to the flow execution, but as long as the flow hasn’t ended (as illustrated in the previous paragraph), the second request still executes the exact same logic as the first request, and you still get a double submission.
Normally, you would execute your process transaction just before you end the flow.
In the book order process, we go over the different steps, with each step composing a part of the order.
If the user double-clicks in this process, nothing bad happens (in the worst case, a book is added twice)
But when the user finalizes the order, we perform our create order transaction and commit everything to the data store.
When the first request returns, the flow will already have ended.
This means the second request will not trigger a second create order transaction, but will merely restart the flow.
Note  You may ask yourself whether synchronizing access based on a token (the flow execution key) has any performance impact.
Synchronization happens within a flow execution that executes within an HTTP session.
In other words, it serializes access for the operations sent out by a single client, to the same flow execution.
For example, a client’s double submission would be serialized because a double submission makes multiple requests in parallel within the same HTTP session and to the same flow execution.
However, if two different clients (and thus two different sessions and different flow executions) were to push the same Submit button at the exact same time, nothing would get serialized, and everything would be executed in parallel.
Now let’s return to the issue raised by that F5 (Refresh) button.
Even if the user doesn’t double-click, refreshing a submitted form accidently will trigger the same effect.
It will not be detected as a doubleclick (there is only one request, sequentially after the first request)
This is a complicated name for a very easy-to-understand pattern that solves the “accidental” resubmit.
In the first stage, the HTTP request is received from the browser.
First, it triggers the invocation of the application logic (if any)
Next, Web Flow issues a redirect to the browser before starting the second stage, which is renders and sends back the view.
This makes the browser forget the form and issue an (idempotent) GET request to acquire the view.
Thus, it re-executes only the second stage, rendering and sending back the view (see Figure 10-5)
Remember: If you were to double submit, only one submit would be treated at a time thanks to Web Flow’s serialization mechanism.
The other submit would be processed after the first one completes.
If case the first request ends the flow, the second simply restarts the flow.
When the request (an HTTP POST) enters the web container, it executes the requested logic.
At this point, the flow execution is "paused" and the state is internally stored for you.
The mechanism to store the state between requests is all handled by Web Flow.
The browser will follow the redirect and issue an HTTP GET to the web container.
Here Web Flow picks up the request again and lets the view be rendered.
The view is eventually sent back to the client’s browser and displayed.
Remember: The last action was not a POST, but a GET.
If the user presses F5, the (idempotent) GET is executed without any side effects; it merely returns the last view without (double) processing the same logic again.
Thus there is no chance of an accidental re-submit of a form.
Controlled Navigation Until now, you primarily have used Spring MVC to take care of navigation in your app.
When working within a flow, Web Flow will take over the navigational control.
It will literally be pulled out of your controllers and modeled within your flows.
You will also be able to trigger actions on your application controllers or execute logic directly from within your flows.
Note  You might wonder whether @Controller annotations are still required on your application controllers when working with Web Flow.
What is important to know is that, when applying these annotations, the class in question becomes a Spring-managed bean.
This means you can refer to the application controllers directly from within your flows.
In other words, both do the same thing—@Controller just adds an extra indication that the class in question is an application controller (something that lives on the front end)
It is probably a good idea to continue to use @Controller even if your application controllers are only used by your flow and perhaps not by Spring MVC.
Ultimately, application controllers are an extension of your flow (which can also be considered an application controller)
We’ve already introduced you to some of the pros that Web Flow will deliver for your application.
Now let’s look at situations where it might be inappropriate to use Web Flow.
Fortunately, we can think of only three reasons to avoid using Web Flow.
First, you’ll (obviously) want to avoid using Web Flow when your web application framework has no support for it.
But since we are using Spring MVC, this is not an issue for us.
By the way, Web Flow also supports JSF and portlets, or JSR-1683 environments.
Second, Spring MVC already has some (primitive) support for building wizards (sequential views that share state), so one could say that the Spring MVC infrastructure can be used for simple, interdependent pages.
On the other hand, introducing Web Flow is pretty easy (as we will see)
Web Flow will add a great deal of functionality and other possibilities that won’t bother you if you don’t need them, but are there when you do.
Third, Web Flow is not very useful for places in your application where there are no flows.
If everything is contained in a single page, then Web Flow will only cause overhead.
This page could still be backed by normal Spring MVC controllers and remain Web Flow-unaware.
So, outside of these situations and the fact that it is yet another framework/concept to learn, we see little or no disadvantages to introducing Web Flow to your application.
If you don’t need it for some specific, very easy use cases and can get along with Spring MVC controllers, then do so.
Our Web Flow setup will still allow you to use Spring MVC and Web Flow next to each other in the same application, allowing you to pick the right option for each situation.
This class is now deprecated, and you should use the standard @Controller annotation instead.
While this is still a valid alternative, it is a bit cumbersome.
Be aware that this way of working is very limited and in no way resembles the extra power that Web Flow gives you.
Our advice is to use this approach only as a small helper in case you need to build very discrete and small bits of flow logic for a very small part of your application.
For all other needs, save yourself the trouble and consider using Web Flow.
The Basic Ingredients of a Flow In this section, we will look at the basic building blocks required for building a so-called flow.
We will start off with a simple flow example, and then explain the different elements that this flow consists of.
We will not go into detail about all the possible options of each element, but simply stick to the basics.
In the next chapter, we will revise certain elements laid out here (as well as cover some new ones) and go more into more detail about how to use those elements.
Therefore, don’t panic if certain functionality is not described here—we will get there.
Flow A flow is the main component that you will be interacting with.
It is an XML document written by you and interpreted by Web Flow.
A flow defines the possible steps in your application and defines the following things for each step:
Which view should be rendered and the interaction between views.
Which actions are possible and whether to delegate execution to application controllers or execute expressions directly in your flow.
Each flow definition is an XML document and should therefore comply with XML syntax standards.
You start with the XML declaration, followed by the flow root element (see Listing 10-1)
This schema will also give you a short summary that covers what each (basic) element/attribute is good for.
Note  Depending on how familiar you are with XML schemas, you might know that the schema visualization only resembles the top-level elements of a flow.
Most of the elements have their own attributes, but these attributes are not listed here (you can see them when you drill down in the schema)
When we discuss the elements in this or the next chapter, we will list and explain the attributes of these elements.
Also, some of the elements can contain nested elements, but these nested elements cannot exist as top-level elements (and are therefore not listed here)
As we discuss a given element, we will also cover the different possibilities enabled by that element.
In Figure 10-6, the flow on the right is the top element.
The top-level section (beginning with start-state) contains the three attributes that can be used inside the flow root element.
In the lower section (starting with attribute), you can see the elements that can be used inside the flow definition.
Their order is important, and you should follow the order listed here.
Note  Only the five states are non-positional in the flow definition.
This is because they are connected via the special choice structure.
All other elements are positional and should appear in the order shown in Figure 10-6
The middle column (e.g., [0..*]) displays the multiplicity of the element.
It indicates how many times the element can exist in a single flow definition.
The number on the left is the minimum, the number (or asterisk for unlimited) is the maximum.
For example, [0..*] indicates that the element is optional and can appear an unlimited amount of times.
Typically, you can only have one element of the listed elements present within a choice.
This means that a state is optional; however, it also indicates that every element of the choice can appear an unlimited number of times.
Thus, there is no restriction on how many states you can define.
Furthermore, because of the choice, the states are non-positional (probably the main reason for introducing this as a choice)
If you look back at Listing 10-1, you will see that we declared Web Flow itself as the default namespace.
This means we don’t have to use prefixes for each element.
Each element or attribute is automatically validated against the schema coupled to the default namespace.
The schema location is used by IDEs to load the schema and validate the XML and to give command-line completion.
Notice that we are using the schema for Web Flow 2.0
For the remainder of the Web Flow coverage, we will omit the flow root element and its namespace declarations in the code listings.
We will only show this information if there is any relevance to it, such as when we cover attributes that belong to the flow root element.
Be aware that, even when the flow root element and its namespace declarations are not shown in a given listing, they are still at the beginning of every flow and are mandatory.
Now take a look at the flow definition in Listing 10-2
We would also like to point out that, when using STS, you have Web Flow support in your IDE.
Once you double-click the flow XML file, the content panel will open, typically showing the XML view.
At the bottom of this panel, you will notice tabs.
Next to the Source tab, you should also find flow and flow-graph tabs.
The flow tab gives a list-based overview of the elements in your flow (see Figure 10-7)
The flow tab, which provides an overview of the flow components.
The flow-graph tab graphically shows the elements and the different relations between them (see Figure 10-8)
You can also use the palette on the left to add new elements and combine them.
The flow-graph tab, which gives a graphical overview of the flow.
All of the information in this palette is directly reflected in the source, and vice versa.
If you add a component from the palette, the corresponding XML will be added to the source.
If you add an element directly in the XML and go back to the flow-graph (or graph), the new element will also appear there.
For now, it’s enough to understand that, when this flow is started, it will eventually enter the selectCategory view state.
This view state will render the selectCategory view (which will be resolved by the Tiles5 configuration) and use the form that is available under the orderForm key.
We use an on start action to instantiate the model and assign it to flow scope before we enter the view state.
We will discuss the evaluate and on start actions in the following sections.
This will bind the fields in a form during submission to the specified form.
Web Flow will take care of the parameter binding, as well as the conversion and form validation (as we will see later)
Note that the modelAttribute must already be present on one of the Web Flow scopes.
We introduced you to Tiles in Chapter 8, so we will assume that you already have a basic understanding about this templating framework.
If you have skipped ahead to read this chapter on Web Flow, but have no idea how Tiles works, then we suggest that you read the introduction to Tiles before proceeding with the rest of this chapter.
Note  The OrderController is just a Spring bean defined in the application context.
In our case by using annotations; applying the @Controller annotation, doing so the class will be picked up by classpath scanning and become a Spring bean.
Also notable are the possible transitions that can be triggered within the view state.
When the view is rendered, it is possible to execute a next or cancel transition.
The next transition will execute a method on the controller, and then forward to the next state (this could be view state or any of the other states that Web Flow supports, as we will see later on)
We will cover the end state in detail in the next chapter; for now, it is sufficient to know that transitioning to the end state terminates the flow.
The flow definition root element (flow) allows you to specify some extra attributes, which are optional.
It is fine to skip specifying them for a simple flow; however, these attributes might come in handy once you get a more complex flow layout or you want more customization (see Table 10-3)
This root element allows you to override the default start-state, inherit from another existing flow, and mark your flow as abstract.
We will cover the latter two cases in detail in Chapter 12 in the “Applying Inheritance” section.
An on-start is not a state, which means that Web Flow will execute whatever action is specified inside the on-start and then proceed with the first actual state specified by the flow.
You can override this behavior by specifying the name of another state, using the start-state attribute.
In that case, that given state will be executed first, no matter where this state appears in the flow definition.
Note that if an on-start is present, it is always executed! It does not matter if you specify a startstate, nor does it matter which state you specify as start-state.
The View State The <view-state> element is a basic element in each flow.
As we will see, there are four other *-state elements.
The view state is probably the most important of these elements, so we will describe this one first.
The view state models a view that is being rendered from the moment the view state is entered.
A view state can be entered as a starting point by starting a flow or by a transition event from another state within that flow.
The other states are decision state, action state, subflow state, and end state.
We left them out here on purpose, since they are not required to build a basic flow.
The user can then trigger a transition allowed within that view state to continue processing.
In Listing 10-2, there are two such transitions described: next and cancel.
Whenever the user triggers such action (by clicking a button or a link on the page) the flow resumes and executes the given action.
You use that attribute to refer to this view state from other states.
The ids must be unique over all states in the same flow definition.
The view attribute indicates which view this view-state will render.
The model attribute identifies the name of an object that is present on any of the Web Flow scopes, which will be used to bind the received parameters on.
These parameters are the request parameters part of the form submission.
Table 10-4 lists the attributes with descriptions and their uses.
This id must be unique over all states within the same flow definition.
It will identify the view state if you want to navigate to it from another state.
In this situation, the flow must be placed in same directory as the view.
A logical view name that is interpreted by the ViewResolver and mapped to a physical file.
It will, by default, bind all request parameters that are part of the request.
As explained before, you have to instantiate the model yourself (as we did using the on start), and make it available on one of the Web Flow scopes.
Web Flow will check them to find an attribute with the key you specified in the model attribute.
Although the documentation specifies that the default value is false (i.e., no PRG), in practice it seems to be the other way.
Whenever a view state is entered or an action is executed within the view state, a PRG occurs unless you specify redirect="false"
There are some other attributes listed in Figure 10-9 that we will not discuss at this time because they are outside the scope of this basic chapter.
They are also not required to build a basic flow.
For your convenience, if you are reading this for reference or you want to jump ahead, the parent, popup, and history attributes are discussed in Chapter 12’s “Inheritance,” “Reworking the Orders Overview,” and “Execution and Conversation Snapshots” sections, respectively.
The attribute element is common for each state, and it can also be applied on the flow root element.
This is an element you will probably never use, but we will cover it here for the sake of completeness.
The attribute element is used to supply metadata to tooling, for example.
Note  You have an element with the name “attribute” when an attribute is also part of the XML syntax, such as the id or view attribute.
All of this makes the name of this attribute name needlessly confusing!
Tooling that visualizes the flow can read these attribute elements and use their content to display additional information.
The type attribute is there to convert the value (which is otherwise treated as a String datatype) to a specific type, if required.
Please consult the Table of Contents or the Index to find explanations for the remaining elements, as they are scattered throughout the next several chapters.
State Transitions A transition literally means a state transition from the current state to the same or to a different state within the flow.
In some cases, the flow might execute an action before executing the actual transition.
You can see this in the selectCategory view state in Listing 10-2, where there are two transitions.
The transition is triggered by the literal defined in the on attribute.
You basically supply a request parameter with a specific naming convention where the on literal is nested.
You will see how to define this in your view when building your first pages in the upcoming “Selecting the Category” section.
When you specify a literal in the on attribute, it will create a matching event from that.
Whenever a request comes in to trigger a transition, it will match the event.
This is not really important yet, as you will specify a literal in your view and in the on attribute.
In addition to literals, you can also use expressions in both the on and to attributes.
The target state can be any of the five possible state types, and you reference them with the to attribute.
The value is the id of the other state you wish to transition to.
Remember that you can also transition to the same state (or to the same view state in our case)
Omitting the to attribute will yield the same effect, although it will not trigger a real transition.
In that case, the view state is not explicitly reentered.
This will become important when we discuss the on entry and on exit actions in the next chapter.
For now, it is safe to assume that both alternatives will yield the same result; however, not specifying the to attribute is the most logical thing to do here.
Notice that the cancel transition transitions to another state with the end id (i.e., the end state)
This is one of the four other special states, as we will see later on.
Table 10-5 lists the various attributes for the transition element.
Within a given state, you can only trigger transitions available in that state.
In the example (see Listing 10-2), you can only trigger the next or cancel transitions while in the selectCategories view state.
These transitions can use the to attribute on their turn to trigger other states within the same flow.
You can also specify expressions and a wildcard (*) as the value.
Specifying a wildcard has the same effect as omitting the on attribute.
The matching rule is that the first matching transition (based on the on attribute’s value) is executed.
In the case of a wildcard, putting the transition with the first in a given state means that it will always be executed, no matter what.
Remember that the literal is actually translated to an Event behind the scenes by Web Flow.
We will see this in detail in Chapter 11 in the “Form Validation Using the Application Controller” and “Working with Outcome Events” sections.
When omitted, the current state is re-executed, without actually exiting or entering the state.
If you don’t want this, you can do one of the following:
This might be handy for a “back” transition that goes to a previous state.
In that case, there won’t be any binding, nor will there be validation that might stop the user from going back.
When specifying a binder (see Chapter 12’s “Explicit Form Binding” section), only those elements specified are bound, giving you fine-grained control over the binding process.
Whenever you transition from one view state to another, you have the ability to go back.
By default, you can do this by using the browser’s Back button.
You can also disable the snapshotting feature on a global scale (see Chapter 12’s “Execution and Conversation Snapshots” section)
If you want to disable this feature’s fine-grained per view state, you can specify the history attribute with the preserve, discard, and invalidate values.
The default value is preserve, and it enables you to go back.
On the other hand, discard disables the ability to go back to the given view state (the view state where you define the transition with the history attribute), and invalidate completely disables the ability to go back to any previous view state your application has been through thus far.
The Evaluate Action The evaluate action enables your flow to interact with other components such as the Spring MVC controllers (or any other Java classes, as long as they are Spring beans)
The evaluate action takes an expression that is executed when the evaluation takes place.
The evaluate action must be the child of another element, and it cannot exist on its own.
It is executed as part of a certain action that is triggered within your flow.
In the example, we nested the evaluate action in a transition inside the view state and in the on start action.
As we will see, next to the transition and on start, you can use the evaluate action.
When the expression returns a value, you can use the result attribute to bind the return value to a variable in a given scope.
Attributes of the evaluate action are listed in Table 10-6
Basically, it allows you to specify a scope or an object within a given scope to bind the result to.
See the “Implicit Objects” section in Chapter 11 for the different possibilities.
When omitted, the result (if any) is not stored in any scope.
When storing a result in a scope, you are basically storing it in a map that has an Object value type.
Sometimes you want to explicitly trigger a conversion to another type.
In other scenarios, you would deduce from the field types that a conversion is required.
For example, suppose you want to bind a received request parameter (in String format) to a form where the target field has the Integer type.
It would be obvious that some conversion needs to be done first.
In this case, there is no such indication because a scope just accepts Object.
However, in your view, you could be expecting that the value is of a certain type other than the one returned by the method invoked by the expression.
This attribute will allow you to explicitly trigger a conversion to the desired target type before storing the result value in the specified scope.
This requires that there be a converter available able to do the conversion, whether it’s a default converter or a custom converter you write (as you will see in the “Type Conversion” section in Chapter 11)
Expressions After reading about the evaluate action and expressions, you will probably be thinking “expression”? Great.
But which expression language is that? Unified EL? OGNL? SpEL? Something else, maybe? Well, it turns out that Spring’s developers made it easy this time.
If you’ve used Spring before, you’re probably familiar with SpEL and understand that this makes the whole more consistent.
You can now use SpEL within Web Flow the same way you use it in your Spring applications.
If you are not familiar with SpEL, you can find a good overview of it in the Spring reference.9 Only a very basic understanding of this expression language is necessary for the Web Flow chapters, and we will.
We will quickly cover everything you need to know about SpEL to understand its usage in the Web Flow chapters.
In this case, the bean name is a key on any of the scopes available to Web Flow (we will discuss these in the “Different Web Flow Scopes” section in Chapter 11)
Web Flow will by default scan all available scopes to find a bean with a matching key.
If no match is found, the application context is tried next to resolve a bean with a matching bean identifier.
Note  The application context (typically) stores your controllers, services, repositories, and so forth.
These are types of objects that are stateless (and act as singletons)
Your real state, such as a form containing user data, is stored on any of the available scopes, whether the ones that Web Flow offers or the actual Servlet-provided scopes.
Besides accessing properties, you can also call methods and pass along parameters.
For example, take this expression in an evaluate action in Web Flow:
This will execute the someMethod—a method of someService that passes along someObject as a parameter.
Again, the expression parser will scan all scopes by default to find the service object and the parameter (including the application context)
You will also be able to use implicit objects to denote scopes or other special objects that are made directly available to you.
While these are not strictly related to the expression language, they can be considered as aliases that are always available.
In the earlier example in Listing 10-2, we called the initializeForm() method of the orderController:
When executing the expression, the orderController was found in the application context.
The result returned from this method is the fully initialized model that we will use throughout the flow.
In cases where you are creating a template expression or using expressions in attributes that are destined for both literals and expressions (such as the view attribute of the view state, for example), you must use the delimiters to denote where your expression part is.
Note  It’s possible you are a Web Flow 1 user, and you prefer OGNL (the default expression language for that version)
It’s also possible that you are upgrading from an earlier version of Web Flow 2, where Unified EL was the default expression language.
In Chapter 12, we will illustrate how you can change the default expression language to Unified EL or OGNL.
However, we encourage you to go with SpEL (the default) and only deviate from this option if there is a good reason to do so.
Configuration Now that you have seen what a basic flow and its main elements look like, it is time for some action.
The first thing we should do is configure our web application framework of choice (Spring MVC)
In addition to Spring MVC, Web Flow has special integration support for the following:
These options are not discussed here, but it’s important to inform you that Web Flow is not bound to Spring MVC only.
This is a good thing because the knowledge you will gather here could be useful for projects using one of the other web technologies.
Note  The pieces of configuration and sample code explained here can be found under the chapter10bookstore samples section.
In the beginning of this book, you will find extended information detailing how to import this project in the STS IDE or how to run it directly from the embedded web container.
To understand the configuration, it is not required to know the ins and outs of the application we are building—that’s why we discuss this setup first.
Here we focus first on the generic Spring MVC/Web Flow configuration.
Dependencies First, you should add Spring Web Flow to your build and deploy path.
When using Gradle (as in our samples) it suffices to declare dependencies to the following artifacts in the build.gradle:
The dependency is declared on project level (as opposed to the root, build.gradle)
The reasoning behind this is that the previous sample projects in the book do not use Web Flow.
Declaring the dependency in the root build.gradle file would implicitly mean that all these projects have an unnecessary Web Flow dependency.
By declaring the Web Flow dependency specifically in the build.gradle of the Web Flow samples, we limited this dependency by introducing it only when we were ready to tackle the topic of Web Flow.
The version variable is maintained in the build.gradle in the root of the /samples directory.
This is a clean way to manage the versions of your core libraries.
This works great for a monolithically structured project, where every subproject is supposed to use the same version of a given library.
This will provide all the dependencies (including transitive ones) required to get started using Web Flow.
Of course, you will need the Spring and Spring MVC dependencies as laid out earlier in this book.
Check the SpringSource Web Flow10 website to make sure there isn’t a newer version available when you start working with Web Flow in your application.
Web Flow Configuration Here we will start by explaining what you need for the Web Flow-specific configuration.
It consists of the components that are required to bootstrap Web Flow.
We will first describe what you need for Web Flow itself.
For example, we will cover how to configure the flow executor and flow registry.
The flow executor is the actual Web Flow engine that will run our flows, and the flow registry will look up and parse our flow definitions.
We will also have a look at the flow builder services that can be used to customize the configuration.
Finally, we need of a piece of separate configuration that will link the Web Flow configuration into the Spring MVC framework.
This piece of “glue” configuration will be described in the “Spring MVC Glue Configuration” section.
Core Configuration The core Web Flow configuration is simplified by making use of Spring’s so-called namespace configuration.
This means that you will use components in the Spring Web Flow namespace to configure Web Flow (see Listing 10-3)
The machinery behind it will create all the beans necessary to bootstrap it.
All of this is configured in a Spring XML configuration file.
The Spring configuration file looks standard; but in this case, we added an additional namespace that holds the Web Flow-specific configuration elements and attributes.
Also, the namespace has the webflow prefix; we will use this prefix to address elements in the Web Flow configuration namespace.
Note  At this time, there are no annotations for configuring Web Flow.
With a couple lines of XML, you can set up your Web Flow configuration.
The first component is the main entry point for the web application framework to drive the flow execution.
Optionally, you can specify the flow-registry attribute, which defaults to a bean with the id of flowRegistry.
This means that, if you stick to that bean naming convention, you won’t need to specify this attribute.
There are only two reasons why you would want to do this:
In other words, there is already a bean which has flowRegistry as its identification.
You are not using the namespaces configuration and instead created a custom flow registry bean, giving it a specific name.
We will go with the defaults in our sample code and not specify the flow-registry attribute.
We will discuss this in depth in Chapter 12’s “Web Flow Configuration Customizations” section.
Web Flow will automatically scan for flows and add them to the registry when it finds them.
In the sample, we have opted for the second option (see Listing 10-6)
Setting the base-path means that the registry will start to look for flows in /WEB-INF/view and all its subdirectories.
We have opted to put the flows together with our views.
However, you could change the value of base-path to another directory if you would like to store your flows separately.
The flow id (that’s the id you will use to start a flow) is the location of the flow within your web application, followed by the filename (but minus the .xml)
So a flow x.xml located in /WEB-INF/view would start like this: http://host:port/contextRoot/x.
Note  The last URL was not a mistake; there is no “y” missing at the end.
When a flow is not located in the root directory, Web Flow accumulates the subdirectories as part of the flow id and stops at the last subdirectory.
The name of the flow itself is in that case not part of the flow id.
While this might sound bizarre, Web Flow encourages you to create a unique subdirectory per flow.
You are encouraged to put the flow together with your other artifacts, such as your pages.
The option that allows you to store flows separately from your views will be discussed in Chapter 12’s “Web Flow Configuration Customizations” section.
Flow Builder Services With the flow builder services, you can further configure and customize the flow registry.
It is actually an attribute of the flow-registry, as you will see later in this chapter.
You only need to specify this when you want something other than the defaults.
Let’s look at the two attributes that are of importance at the moment (see Table 10-7)
The default implementation looks for views that are put alongside your flows and end with .jsp.
While we put our flows together with our views, and our views end with .jsp, we are using tiles to compose our views.
This resolver will look up the view definitions based on the literals you specified in your flow view states.
Development mode switches on hot-reloading of flow definition changes, including changes to dependent flow resources such as message bundles.
Basically, this means that the flow definitions are not cached, but reread from the file store when you access them.
So if you change something to the flow definition XML, it is sufficient to restart the flow in your browser, so you can immediately see the changes.
By enabling this feature, you avoid having to restart your web container each time you make changes to your flow definitions.
For production, you should change this to false because this could impose a (very small, but still present) performance penalty or unnecessary file access appearing when doing file-system monitoring.
You also could make this dynamic with a SpEL expression or by using Spring profiles.
After specifying the flow builder services, you can hook it up to the flow registry:
The flow builder services can be used to customize other things, as well.
For example, you can configure Web Flow to perform JSR 303 validation (AKA bean validation)
After performing the validation, you can configure custom type conversion and formatting.
These topics are discussed in Chapter 11’s “Type Conversion” and “Type Formatting” sections, respectively.
Finally, the flow builder services also allow you to switch the expression parser.
This is discussed in more detail in Chapter 12 in the “Web Flow Configuration Customizations” section.
We have set it up just as we did in the previous chapters.
However, this is nothing new compared to the previous chapters (it is explained in Chapter 6’s “Configuring Interceptors” section)
We will not discuss this class further because it is exactly the same as in the previous chapters.
Later in this chapter, we will configure Web Flow with the same Tiles view resolver that is defined for and used by Spring MVC.
The point is that we will still be able to use Spring MVC as-is, without added.
In that case, Spring MVC will works as it normally does, and it should have the means to resolve its views.
This mechanism is specially built, so that the Spring MVC DispatcherServlet remains your single entry point.
The distinction is made depending on the request, and the request is forwarded to either Web Flow or Spring MVC itself (which might then be a resource or even a call to your controller)
This FlowHandlerMapping will detect whether the URL points to an existing flow id.
You can see that the DispatcherServlet uses HandlerAdapter and HandlerMapping to send a request to a specific part—to either Web Flow or Spring MVC in our case.
It defines and configures the two beans with the following ids: flowHandlerAdapter and flowHandlerMapping.
This listing brings all these components together and effectively serves as the glue between Web Flow and Spring MVC.
This is because the two systems are separated from each other.
Once Web Flow is handling the request, it doesn’t know about interceptors added to Spring MVC handler mappings, and vice versa.
If you did not add these interceptors here, changing the language or showing random books would no longer work from the moment you started a flow.
In the preceding sections, we covered the different configuration details for configuring Web Flow.
We also investigated and explained how to integrate Web Flow with Spring MVC.
In the next section, we will focus on building something workable using Web Flow.
Building Your First Flow In this section and hereafter, we will build a small part of our bookstore sample application using Web Flow.
We already have seen some of the important elements that make up a flow.
Now we will use them to build an entire working flow.
To make you familiar with the basic building blocks required to assemble our first flow, we will build it step by step describing each part into detail.
The following sections will contain a lot of snippets, so you might want to peak to the complete flow as listed in the Overview section if you get lost in between.
This use case will allow a user to order books.
The first screen shows a dropdown list for selecting a category, while the next screen allows a user to select books that belong to that selected category.
One or more different books can be added to the list.
Next, the user can enter order details such as the delivery date.
The user is also able to cancel the process in each of the different stages.
The user selects the link to buy books from the navigation bar.
A user can select one or more different books and add them to the list of selected books.
The user can enter some order details, such as the date of delivery (page3)
On the left is the start of our flow with a single circle.
The start of a flow does not have a special element; it can be either of the following:
The state indicated by the start-state attribute of the flow root element.
When there is no <start-state> attribute, the first state of the flow is automatically executed when the flow is started.
In this case, the navigation is bidirectional, which means that you can go back and forth between these view states.
This is offered to you by Web Flow, and you do not have to configure anything special for it.
It will be offered by a Next/Previous button on the screen; however, you could also use your browser’s Forward/Back button.
You will see that the state of the previous step is retained and still visible in your browser, even when you go back from the last step to the first.
On the bottom right, the end of our flow is indicated with a double circle.
Once the end is reached, our flow will be terminated.
The end of a flow does have a special element: end state (which we cover in Chapter 11)
It is one of the five state types Web Flow understands.
We don’t perform any kind of authentication in this sample application.
But because we need to link orders to a user, every user is authenticated automatically when entering the web application.
We will not discuss this here because we are taking this part of the process out of your control for the moment.
We will leave the explanation for this to the next chapter.
After the order has been made, the user is sent back to the home page.
Note  The approach we take with the Spring Web Flow sample for selecting books and creating the order is somewhat different than the previously discussed Spring MVC approach.
We deliberately left out the shopping cart and transformed the book selection and order process to a more flow-based approach.
This better suits our needs when explaining the different Web Flow elements.
Creating the Home Page Before we proceed in building our flow, we first want to cover how a user gets into the application.
In other words, we want to go over what the user sees when she enters the bookstore URL.
It consists of the template with no content in the middle (the content area)
This page will allow the user to select an action from the navigation menu.
Let’s take a quick look at how this is implemented.
The goal of this controller is simply to render the home page, which is physically the main.jsp.
To access the application and show this home page, you simply have to point your browser to http://localhost:8080/chapter10-bookstore/
Thanks to the index.jsp, which is automatically picked up as the web application’s welcome file, the Welcome screen is shown.
This index.jsp will internally be forwarded to the index.htm request mapping on which the MainController is listening and trigger the view-rendering process.
Note that a welcome file must be a physical file.
It cannot be the name of a fictional view (such as our index.htm) that is resolved by Spring MVC.
To make this happen, we have an index.jsp file right under the webapp folder, as you can see in Listing 10-11
Tomcat (or tc Server) will be default place to look for the index.jsp welcome file.
Remember that index.jsp is outside our WEB-INF directory (in the STS Java view, it is under the /webapp directory), so it will be directly accessible by external clients.
This is unlike the JSPs of our other views, which are placed under WEB-INF/view and are not directly accessible by external clients.
Note  You can check the welcome file defaults by first going to your workspace server home directory.
The home directory can be found by double clicking the “Servers” project (while being in the Java or Java EE perspective) and then by double clicking on the server instance (which is named “VMware vFabric tc Server Developer Edition v2.6-config” by default)
The entries in this file are the defaults for each web application that will be deployed on this server instance.
At the end of the file, you will find the welcome-file-list, which lists all the files (and their extensions) that are recognized as welcome files by default.
Implementing the Create Order Flow To implement our flow according to the required use case, we will need three major elements:
An <on-start> element to initialize our model and selectable categories.
To add a book to the list of selected books.
In the upcoming sections, we will build the three pages (in the order as displayed in Figure 10-5) and the required flow components.
Let’s get started by building the page that lets users select the category.
Selecting the Category We need to begin by initializing our model and retrieving the selectable categories that we will have to present to the user.
We will use this model throughout the flow to gather the user’s input.
The categories are required for the first step of the flow, and these are displayed to the user in a dropdown list that the user can select from.
This is also the location where we will put the pages that we are going to create, along with the flow.
Earlier in this chapter, we covered the <on-start> element, which allows you to execute logic when the flow is initially starting.
This logic will execute before the flow enters any other state.
The action should appear before any other state, and it can appear only once in the flow.
This will be perfect for our initialization (see Listing 10-12)
The initialized OrderForm is then set to the flow scope.
We can specify more than one evaluate action in an on start, and these actions will be executed in order.
If one of the evaluate actions results in an exception, then the processing stops and no transition takes place.
To keep things simple, we used a map with a key type of Long (the surrogate key of each category record) and a value type of String (the name of the Category) as can be seen in Listing 10-14
Later on we will see how we can use Category Objects directly instead of transforming them to String’s first.
Note  We explicitly stored our categories separately from the OrderForm.
We could have also saved this on the form itself, but we kept it separate, so as not to cause bloat on the form.
Next, we are going to create our view state, as shown in Listing 10-15
The view state will use our orderForm (as indicated with the model attribute) that we initialized previously in the <on-start> element.
Web Flow will automatically bind every request parameter to the specified form.
As we will see in Chapter 11’s “Explicit Binding” section, this can be overridden.
Remember: We are keeping this sample as simple as possible; therefore, we left explicit binding, validation, and conversion out of the picture.
Our view will require some kind of control component that will trigger the next or cancel transition.
The next transition will bring us to the next view state.
However, before making the transition, we prepare the list of books that are available within the chosen category.
We do this by calling a method on the OrderController.
This method will use the selected category to load the books available for that category.
The result is a map with the same structure as the categories; it is also set to the flow scope (see Listing 10-17)
The flow execution key will allow Web Flow to load the state again where it was saved before returning the response (i.e., before pausing the flow)
The <form:select> element is a basic Spring MVC tag library for rendering a HTML select list.
It can work perfectly with a map; in that case, it will use the key as value for the HTML option element (which is the text that will be send as part of the form submission) and the value as the content of the HTML option (which is the text that will be shown in the list)
These are the control components that will drive the transition.
If you look at the name, you see that they end with the on value of our transitions and are prefixed with _eventId_
This is how Web Flow will identify which transition to execute.
The name of the buttons are sent along with the request when submitting the form.
As can be seen on the home page in Figure 10-10, our idea is to initiate our flow with a Buy books link.
We still need to configure this link in the navigation bar to start our flow.
To find the link, we have to open the header.jsp, which you can find in WEB-INF/templates/
A page consists of a header, content, and a footer panel.
The menu is rendered as part of the header.jsp (see Listing 10-19)
The URL created is simply appending "/createOrders" to the base URL.
As we saw in the “Core Configuration” section, the flows under the WEB-INF/view directory are addressable directly via the directory structure they reside in.
Note  You might wonder why we don’t embed <spring:url> inside the href attribute directly, instead of working with a variable.
We could have done this; while this notation is a bit more elaborate, it is also more readable.
Let’s just say it’s a matter of personal style and taste.
At this point you should be able to test the application.
On the home page, you can now click the Buy books link.
Doing so should display the view shown in Figure 10-12
Clicking the Next button will yield an error because we haven’t implemented the next view state yet.
However, clicking the Cancel button should bring us back to the home page.
For now, it is enough to know that the end state will simply end the flow execution and perform a last redirect to a view we configure.
That rounds out how to select a category, so let’s move onto selecting and adding books.
Selecting and Adding Books Next, we need to build a page where the user is presented with a list of books for the previously selected category.
The user should be able to add a selected book to an order list, and there should also be an input field to specify the number of books the user wants to add.
In our previous view state, before transitioning to the view state we are going to build here, we loaded the books on the flow scope under the selectableBooks key—so that part is already done.
What remains is for us to specify the view state and define all available transitions to handle the part of the use case where the user selects a book and adds it to the list.
In this section, we will continue by describing the functionality that we need to accomplish this.
Next, we will place the actual transition underneath, so you can see what it looks like.
Finally, we will give an overview of the entire view state.
Let’s begin by implementing something that takes us back to the previous page (see Listing 10-20)
The to attribute is the id of the previous view state.
So, when a _eventId_previous comes in via the request parameters, Web Flow will automatically take us back to the previous view state.
The previous view will then be shown, including its data.
We should be able to select a book from the available books list, and then add the book to our list of selected books that is stored on our form (see Listing 10-21)
This preceding snippet will invoke the method in Listing 10-22 on the OrderController.
We will use the OrderForm to retrieve the selected book id.
This was bound by Web Flow on the form when the form was submitted (i.e., when executing the add transition)
We retrieve the book and add it to the map of selected books with the specified amount.
Also, notice that this transition does not have a to attribute.
When left unspecified, the same view state is rendered again.
This is exactly what we want; after adding a book; that is, we want to stay on the same page and show the user that the new book was added to the list.
Once some books are added to the list, the user might want to start over and thus clear the currently selected books.
The user should also be able to advance to the final page (see Listing 10-27)
Finally, Listing 10-28 shows how our view state will look.
In Listing 10-28, you can see the Tiles definition that corresponds to the selectBooks view.
Next, we will create the page (see Listing 10-29), which will consist of three parts.
The first part allows you to select the book, enter the quantity, and add it to the list of selected books.
You invoke this functionality by clicking the Add and Reset buttons, which will call the add and reset transitions, respectively.
The second part of the page is the list itself; it shows the list of currently selected books and their quantity.
Finally, the third part of the page displays the buttons to drive the remaining transitions: previous, cancel, and next.
There are a few key things to note about the preceding listing, particularly the parts in bold type:
After implementing Listing 10-30, we restart the flow, select the category, and click the Next button.
Listing 10-30 shows the code to implement our view state.
The first transition is nothing new; it takes us back to the previous view state.
The second transition finalizes the order and transitions to the end state, which we will see in a moment.
The Account is nothing to worry about for now; just know that it was automatically set to the session scope when the user opened the web application.
Remember that, for this sample, we kept everything as simple as possible, so the user was logged in automatically (always with the same hardcoded user)
In the next chapter, we will implement the authentication ourselves, as a way of illustrating some new Web Flow concepts.
The Account identifies the user currently logged in and making the order.
The session scope is the ideal place to store information like authentication, which is really bound to the lifetime of the session.
Next, it will loop over the selected books and add each one of them to our order.
After the order is made, the flow transitions to the end state and all other states will be cleaned up.
We will discuss the end state in the next chapter in detail.
For now, it is enough to know that it will end our current flow and that it performs the entire cleanup (see Listing 10-33)
We used a bit of Spring JS (Spring JavaScript, based on DOJO) to render the date picker, as you can see on the view in Figure 10-14
The addDecoration decorates an existing HTML element—with id deliveryDate, in this case.
We specify the type of widget (date picker) and supply it with some attributes such as the format that it is required.
In the next chapter, we will also add matching server side validation.
We will also discuss some more JavaScript options in Chapter 12 when we talk about Ajax.
If you want to verify that the order has been made, you can click “Orders overview” link in the menu bar.
You will see that there now is a sixth order, the order that we made throughout this process.
Note  You will notice that clicking the “Order!” button without entering the (mandatory) delivery date will raise an ugly server side exception.
In this flow, we did not apply validations or any of those features.
The decoration (date picker) we applied on the field will indicate that it is mandatory; however, not filling in the delivery date won’t prevent the user from clicking the Submit button, and thus submitting the form without the delivery date.
In the upcoming chapters, we will examine how we can improve this, and show an appropriate validation message instead.
Overview In the previous sections we went through the different steps of building our first flow.
We introduced each part of the flow and also described the other elements which we needed, like the JSP page and the tiles configuration.
Before we conclude, you can find a complete overview of the flow we have build so far in Listing 10-35
Summary In this chapter, we started out with some theory about why and how Web Flow can ease your web application development.
We also addressed some of Web Flow’s more important features, such as its expanded scoping mechanism, automatic state saving, and how it can help protect the integrity of your web application state, using Post Redirect Get and request token synchronization.
Next, we learned how to configure Web Flow, including how to manage its specific configuration details.
We also learned how you how glue together Web Flow and Spring MVC.
We continued by touching on most of the Web Flow basics that you will need to get started implementing basic flows in your application.
Finally, we showed off some of Web Flow’s features with a live code example that builds a basic book order flow.
We are now ready to advance to the next chapter, where we will go deeper into some of the untouched features of Web Flow, using these features to transform our sample application into a real Web Flow application.
In the previous chapter on Spring Web Flow, we introduced you to Web Flow’s main features and what it can do for you.
We also covered what a basic Web Flow configuration looks like and how it can be integrated with Spring MVC.
We saw some basic elements that are part of almost every flow, such as the view state and the evaluate action.
And we ended by converting our Bookstore to a basic Web Flowenabled application.
In this chapter, we will continue to look at more features of Web Flow.
For example, we will see all the features required to turn the bookstore in a real-world application.
We will be starting from the bookstore as we left it in the previous chapter, which we will be refactoring as we go along.
The general approach of this chapter is a mix; we will introduce you to some new features first, explaining them in detail.
Next, we will see how these concepts can be applied by refactoring the existing application or using these features to modify the bookstore.
We have chosen this approach, so that the table of contents can continue to be referenced.
When working with Web Flow, you probably want to browse back to certain functionality and read about all its details.
If we were to mix everything together, this would become difficult.
We will tackle the sample in two stages, to make everything more digestible.
We will also take a closer look at scopes and how they work, and then introduce and define the implicit objects available for Web Flow expressions.
Flow Definition In a flow definition, we can have five states, two of which we have already seen: the view state and the end state.
The remaining states are the action state, decision state, and the subflow state.
We will go over these in more detail in this chapter.
However, in this section, we want to give a short introduction to subflows, since we will refer to them before covering them fully in the “Subflows” section.
For example, the structure and setup of a subflow is not too different from any other flow; it is defined in its own flow definition XML, and it has its own flow id.
Sometimes a given flow is started from another flow, rather than starting it at the top level by referring to it directly.
This process creates a parent/child relationship between the two flows.
As we will see later, this relationship implies that the two flows can share state.
It also serves as a modularization technique because it can help you build reusable components.
The user signals an event by submitting the contents of a form to the URL that contains the flow id as a path and the flow execution key as one of the parameters.
Other parameters can be values of input components, such as text fields, select boxes, check boxes, and so forth.
Web Flow will use the flow id and execution key from the submission to resume the flow execution, and it will parse the event from the submitted parameters.
Remember that, in our sample, the event is encapsulated in the name of the Submit button using this format: _eventId_event.
After parsing the event, Web Flow will use it to invoke the transition, which has a matching on attribute for the event that we submitted.
It will then be forwarded to the state indicated by the to attribute of the transition.
A transition takes the flow from one state to another state of that same flow.
Before you can go back to a view, you must either transition to another view state (possibly going through other states) or transition to an end state.
As we will see, an end state has also an option to specify a view.
This view is rendered after the flow execution has terminated.
Different Web Flow Scopes We already mentioned in the previous chapter that Web Flow adds a lot of different scopes into the picture (five to be exact): conversation, flow, view, flash, and request (see the “Fine-Grained Scoping” section in Chapter 10)
This is the case because Web Flow stores the state of these scopes between requests.
Also note that this is recursive; every object your object refers to should be serializable, as well.
If you do not want to retain certain objects, you can use the Java transient keyword on the field.
When the flow state is restored, these fields will resolve to null.
Next, we will explain each of the five scopes in detail, from the shortest life cycle to the longest.
While they are shown in the same figure, they should be interpreted sequentially.
First, HTTP request 1 enters and gets processed, and the response is returned.
Second, HTTP request 2 enters, and the cycle repeats for this request.
When the first request enters, request scope 1 is started.
It is possible that an event is triggered, and a transition is executed.
Note  We want to point out that, from now on, a curly brace indicates the scope available at that moment in a “scope figure.” The creation and cleanup of a certain scope is denoted by the curly brace itself; between the top and bottom of the brace, the scope is available to any execution trying to use it.
The request scope is tied at the level of a single request into the flow execution.
Each and every request coming into the flow execution will start with a new and empty request scope.
It is important to realize that the request scope is not linked to a flow execution by itself.
Consequently, a parent flow executing a subflow (or vice versa) always sees the same request scope.
You can use the request scope to store objects that are only required while processing the current request.
Objects that are cheap to create or load can also be put in the request scope because they can be recreated or reloaded every time they are needed.
For example, if you need to load a list of results, you could load them with an <on-render> action (as we will explain later on)
The <on-render> is executed right before the view is rendered.
The result could then be stored on the request scope for a very brief moment, until the view is rendered using that information and then cleared.
There is a great resemblance between the Servlet request scope and Web Flow request scope.
The major difference is that the latter scope is local to Web Flow components.
It is an internal artifact used within Web Flow, and it isn’t exposed to external components (e.g., Servlets)
Note  Including a request scope in Web Flow was a design decision to have an abstraction over the standard Servlet request scope.
The designers targeted Web Flow for other platforms, as well (which may not have the notion of a request scope as the Servlet specification does)
For you as a developer, there is no real difference apart from the fact that Web Flow’s request scope is easier to reach from, for example, expressions inside your flow.
Flash Scope You can think of the flash scope as a bigger request scope that survives two requests in a Post Redirect Get until the view finally gets rendered.
Attributes with flash scope are persisted until the view is rendered and then cleared.
Storing objects in the flash scope is particularly useful for objects that are required in the view, but are not needed anywhere else.
A good example of using flash scope is to store messages that are rendered on a view, like errors or warning messages.
While an action executes, they can be put on flash scope by your application controller or by validation logic in your flow.
The request scope is not sufficient because model validation occurs in the first request of the PRG.
As a result, when the view gets rendered, the messages put on request scope will be gone.
The flash scope provides an elegant solution for these kinds of use cases.
From the moment the view is rendered, the existing flash scope is cleared.
This implies that, if you refresh the view, the messages will be gone, which is typically what you want for things like error and warning messages.
Because flash scope is an extended request scope, it is also available to any subflow that is used.
For example, when a transition within a view state delegates to a subflow which then renders the view, the flash scope will also be available to the execution that happens within the subflow.
However, after the view has been rendered, any subsequent requests to that subflow will operate in their own flash scope.
View Scope The view scope gets allocated when a view state enters, and it is destroyed when the view state exits.
The view scope can only be referenced from within a view state.
In Figure 11-3, you can see that, for each new view state, a new view scope is available.
You could use view scope for storing data that is only required within the given view.
For example, when you have a data table with pagination, you could load the results and put them in view scope.
Using transitions within the view state (e.g., a next and previous transition), you could scroll through the list each time, showing a certain part of the result set.
From the moment the view state is exited (e.g., after selecting a result in the data table), the view scope is destroyed, and the resources are released.
Flow Scope The scope of the flow scope is a flow session.
You can see this in Figure 11-4, where the execution of the parent flow has a flow scope, as does the flow session of the subflow (a subflow runs in the same flow execution as the parent flow but in a different flow session)
This means that an attribute placed in a flow scope by a parent flow will not be accessible from the flow scope of a subflow.
You can use the flow scope to store objects that should be available for the entire flow session, but which are only for that session and not other flow sessions started in the same flow execution (i.e., subflows)
Objects in the flow scope are mostly related to the application and the functionality it implements (e.g., domain object instances manipulated by the flow)
Conversation Scope The conversation scope is scoped at the level of an entire conversation, or execution (see Figure 11-5)
The term “conversation” is a bit misleading, but that is merely an implementation detail (especially in Web Flow 2) that is not important in this discussion.
Although we are forced to use this term, you can think of conversation scope as a scope that maintains state over the entire flow execution.
We think that “execution scope” would have been a better naming.
Attributes in the conversation scope are available to every flow session contained within the conversation (or execution)
The conversation scope is therefore also available to all subflows.
Use the conversation scope if those objects should be available for every flow session (for that flow and/or its subflows), rather than for a single flow session.
If your flow does not use subflows, the lifespan of conversation and flow scopes can be considered equal.
Note that we are not saying that both scopes “become equal”; they remain two physically separated scopes, so setting something on flow scope will not become visible on conversation scope.
But in this case, they will be “logically” equal because they have the same lifespan, and the lifespan is normally the attribute that makes one flow different from another.
Because their lifespan is the same, one could argue that it would be equal either to choose flow or conversation scope.
However, by default it makes more sense to opt for flow scope and not conversation scope.
This is because subflows could be introduced later on (i.e., when your flow gets extended), and subflows will automatically be able to access the data on the conversation scope.
As we will see shortly when introducing subflows, the best practice is to think about which data the subflow needs and only expose the right amount of data.
In Figure 11-5, you can see that, for flow x, the conversation and flow scopes are equal because there is no subflow present.
You can also see that there is a new conversation scope (and flow scope) created for flow y.
Also, for flow y, there will be a different flow scope created for the subflow.
However, the conversation scope remains accessible for both the parent and the subflows.
As already explained, the flow scope visible for the subflow is a new one, and the subflow cannot access the flow scope of the parent flow.
Caution  Be careful when storing large objects in flow or conversation scope.
These scopes have relatively long life spans, which means that the data stored in them needs to be maintained for a long period of time.
As an alternative to storing large objects in the flow or conversation scope, consider reloading those objects for every request and storing them in request scope.
Implicit Objects Just as you have implicit objects in JSPs (scriptlets) and EL, you also have implicit objects defined by Web Flow.
An implicit object is a shortcut to certain functionality that is frequently used (e.g., the HTTP request parameters)
In EL, this implicit object is called param; in a Web Flow expression, you can use requestParameters.
In addition to data-related implicit objects, there are also references to key framework objects.
Table 11-1 outlines each implicit object that can be used in Web Flow expressions.
The function of each scope is explained in the preceding section.
It can be the event that triggered the state transition or a result Event from executing a method on an application controller.
Events are further discussed in the “Working with Outcome Events” section.
Or, you can check the sample in createOrders-flow in the authenticate view state, where we pass along the messageContext to the application controller.
For example, it exposes the current active flow definition and the current transition (if any)
Most of its remaining functionality is directly exposed via other implicit objects (e.g., messageContext, the different scopes, and so forth)
For example, it can indicate that a flow started, is active, has ended, and so forth.
When forwarding a user to another page (outside the flow and/or your application), you can pass this URL as a callback URL.
Later, the URL can be used for going back to a given flow and restoring the latest view state.
See the JavaDoc for more details on which properties you are able to call.
Enhancing the Bookstore In the previous sections, we covered general Web Flow terminology in some detail.
We needed to introduce these concepts prior to diving back into the code.
Now that we have covered them, we are going to look at specific Web Flow features.
We will do this by illustrating them with code and explaining them along the way.
In the previous chapter, we made our first pass at introducing a basic flow for ordering books.
We did this with some basic web flow components that illustrated how easy it is to transform a given use case using Web Flow.
Now we will continue adding functionality to and improving our sample application, illustrating and explaining various Web Flow features along the way.
For example, the sample application as we left it in the previous chapter is not much of an application, yet.
A lot of things are still missing, to name a few:
There is no validation: It should not be possible to make an order when there is no book selected.
The delivery date is also mandatory, and the site should trigger an exception when the user does not specify this date.
There is no conversion: We mapped a Category and Book in our form as a Long using the identifier for each of these objects.
It would be more elegant if we could map directly to a Category or Book from our domain.
In the following sections, we will address these and other shortcomings, gradually refactoring our sample application to show how you can use Web Flow to implement some real-world use cases.
We will start from the very beginning, by revising our first step in the flow: selecting the book category.
Selecting the Category To load our list of selectable categories, we used an on start action.
This action loaded our categories into flow scope before entering the view state to render the selected category view.
As we already explained in the “Different Web Flow Scopes” section, this is not the ideal place to store this information.
The selectable categories are only required in the scope of the selected category view.
Also, we mapped the category using its id in our form instead of mapping it as a domain object.
The next sections will show how we can change this.
On Start We will still use the on start to initialize our OrderForm.
Remember, the on start is executed automatically when the flow session starts.
Even if you have a specific <start-state> attribute defined in your top-level flow element, Web Flow will always execute the actions defined in on-start when starting the flow, executing each action listed sequentially.
Since we will not be loading our categories here, we deleted it, so that only the initialization of our form remains (see Listing 11-1)
From now on, we will use the normal data types and leave conversion and formatting to Web Flow and Spring MVC.
This changes our initialization of the OrderForm; and in Listing 11-2, you can see that we are now storing this information as a Date instead of a String.
On Render Now that we’ve removed the initialization of our categories (Category), we have to find another solution.
The solution lies in the use of an on render action and using the request scope.
It would be beneficial to load the categories right before our view gets rendered and remove them directly afterwards.
Every action specified in the on render is executed right before the view state renders.
Remember: When Web Flow uses PRG, the view state renders on the second request.
The first request executes our controller and selects the view to render.
When the second request comes in (the GET), our on render action executes.
We then load the categories and put them on the request scope (see Figure 11-1 in the “Request Scope” section)
Our view, which is rendered next, will be able to access the categories and render them (see Listing 11-3)
Basically, we moved the evaluate expression from the on start action to the on render action and chose requestScope instead of flowScope.
The existing version of the code for retrieving the categories selects all categories and puts them in a map using the id as the key and the name as the value (see Listing 11-4)
We will now make this code more natural by simply returning a List holding types of our domain entity Category (see Listing 11-5)
Later, we will look at how the conversion takes place.
In our page, we will no longer have a Map, but a list of Category objects.
We need to change the <form:select>, so that the name is displayed as a label and the id as a value.
We will still need the id (as the select value) to perform the conversion later on (see Listing 11-6)
Note  Instances of categories and books are the ideal candidates for caching.
However, instead of caching them on any of the Servlet or Web Flow scopes (which end up on the user’s session and would duplicate the values for each user), we cache them in the back-end, using the ORM’s 2nd level cache.
When executing queries on them, we also explicitly cache these queries.
The ORM is configured to use Ehcache as cache implementation.
This offloads redundant objects from the user’s session and keeps them cached in the back-end, usable for the entire application.
If you enable Hibernate (our JPA implementation) debugging, you will see that, after a server startup, categories are only fetched from the database once.
They won’t be fetched again until the next server restart or the cache expires.
Type Conversion Now we have a list of selectable categories, which are in fact domain entity objects.
At binding time, the id of category needs to be converted to a Category because that is the type we specified on our OrderForm object.
To enable type conversion, we have to go back to our Web Flow configuration.
Remember that the flow builder service allows us to customize certain Web Flow behavior.
We gave an introduction to the flow builder possibilities in the previous chapter under the “Web Flow Configuration” section.
We will now see how we can use the flow builder services to specify a custom conversion service.
The conversion service is a bit a pain to explain because we feel it is rather more complicated than it should be.
Fortunately, a lot of basic converters are already there, and you might not even notice that a conversion took place.
Until now, Web Flow has had its own type conversion mechanism.
Spring MVC uses a very similar, but incompatible, type-conversion system, so a custom converter written for Spring MVC should.
Fortunately, there is now an adapter that allows you to plug your Spring MVC-specific converters into Web Flow.
Note  Web Flow advises you to use the standard Spring MVC conversion mechanism and that you no longer write converters the “Web Flow way”
The latter is the one used solely by Web Flow, and it should be considered deprecated for writing new, customized converters.
In our case, we will have to write a converter that is able to convert from a String (representing a numerical value from the select list) to a Category object.
The default conversion service registers all default converters, and these are able to convert all primitive types, such as Integer, Long, and so on.
The conversion services also give you a hook to register your own converters or register another conversion service as a delegate conversion service.
The hook provided to register a delegate is used to pass along the core Spring MVC conversion service.
Whenever the conversion service is asked to convert a given type, it will look to see whether it can deal with the conversion itself (possibly using existing Web Flow converters)
If it cannot, it then checks the converters available in the Spring MVC supplied conversion service.
Next, we can pass on the reference for our conversionService to the flow builder services (see Listing 11-10)
This concludes the integration regarding conversion and formatting between Web Flow and Spring MVC.
The two sides are now joined and will act as one big conversion or formatting service.
We will use the Spring core service for adding custom converters, which will then be available to Web Flow.
The addFormatters method is called automatically by Spring, supplying the FormatterRegistry.
This is explained in detail in Chapter 5’s “Configuring Type Conversion” section.
Note  If you pay close attention, you will notice that we are adding a converter to a FormatterRegistry.
As you will see, formatting is a specialization of conversion.
As a reminder, conversion and formatting is a part of core Spring MVC and is explained in detail in Chapter 5 (see the “Converters” and “Formatters” sections)
By enabling the conversion service in Web Flow and coupling it to the Spring conversion service, we implicitly enable formatting via the Spring MVC conversion service.
Any formatter registered with the service will also be useable by Web Flow.
We will have to customize the formatting of our delivery and order date.
We don’t have to register a specific converter or formatter because date formatting is available by default.
Selecting Books and Delivery Options We have to repeat the refactorings we performed in the previous part for our selecting books view state.
In the previous chapter, we used an evaluate action in the next transition after transitioning to the selectBooks view state, as shown in Listing 11-14
We will remove the evaluate action just listed and replace it using the same on render mechanism (see Listing 11-15)
This makes the evaluate action in the on next transition of the previous selectCategory view state obsolete.
Likewise, we changed the select list, selectBooks.jsp, to render the title as item label and the id as item value because the objects stored for the selectable books will now be Book domain entities (see Listing 11-16)
Finally, we also need to register a converter for the Book domain entity.
This will be the exact same procedure as for the Category.
Next, we can continue with the specific refactorings for the select book and select delivery options of our application.
This involves adding validation, so a user is notified when submitting a form with invalid or missing data.
We will see that there are roughly three ways of performing validation: using the JSR 303 annotations, using validator methods in our form (or separate classes) that are recognized by Web Flow, and applying validation in our application controller itself.
Next, we can complete our flow builder services configuration, as shown in Listing 11-19
For now, we will just use the validation for the quantity field.
This is the field that a user can change when adding books to the order.
The default value is 1, but the user can also add multiple books to the order directly.
We could use bean validation for the other fields, as well.
However, there are two reasons why this would be troublesome:
First, the validation API is good at validating a single field, but we will also have to validate a combination of fields.
For example, later on we will have to check that the entered delivery date is after the order date.
The validation API has the group feature to validate fields in a group, but it is not possible to indicate a more complex relationship without writing a custom bean validator.
Unfortunately, this is not something the bean validation supports out of the box.
We will use one of the two other ways of validation (yet to be seen) to do this.
Second, the problem with this validation setup is that the entire form gets validated as a whole, yet we only use a part of it for each step or our flow.
Basically, this means that, when setting the Category on the first page, all of the other validation annotations would be triggered, as well.
If we were to put a @NotNull annotation above the Book instance field, then we would get an error that no Book is selected when we select a Category.
A solution could be to divide the form into multiple smaller forms.
But for now, we will validate the other fields in a different way.
Later, when the user can select the quantity in the select books page, the validator will trigger an error when the user specifies a value that is not allowed.
To define the dependency, we added it to the project’s root gradle file (build.gradle in the samples root directory):
Form Validation Using the Web Flow Validator Method and Classes The second way to perform validation is by implementing a method in the form of a "validateState" method in our model.
This type of validation is detected by Web Flow purely by following naming conventions.
The word “validate” is mandatory, while “state” is a placeholder that needs to be replaced by the id of state for which the validation should be applied to.
Web Flow will execute the validation on post back to the defined state.
So the validation is not executed the first time the view state is rendered, but when a postback is made (e.g., when a form is submitted)
In the example in Listing 11-21, the validation is triggered when we make a transition to the selectCategory state.
We check that the event that triggered the transition is the next event.
If the user were to click the cancel button, then we would not want to perform the validation.
A variation on this is to store the validation logic separately from your model in a validator class (see Listing 11-22)
To do so, you have to follow more naming conventions for classname and the.
In the case of an external validator, you would also get the model as a parameter to the validate method and, optionally, the Spring MVC Errors object.
The final requirement is that the bean should be registered as a Spring bean.
In an annotationdriven model like this one, you can simply add the @Component above the class definition and make sure the class will be picked up by the component scan.
Note  In the sample application, we have opted to store the validation together with the model, so you will not find an external OrderFormValidator.
But feel free to experiment and try to move validation logic from the OrderForm to a separate validator.
Form Validation Using the Application Controller The final validation method performs custom validation inside a controller method that is called by a Web Flow expression (see Listing 11-23)
The evaluate action for validating the delivery date is executed when a user clicks the finish button (triggering the finish transition) after entering the delivery options.
The invocation occurs before the invocation to create the actual order.
We pass along the form and messageContext (a Web Flow implicit object)
Inside this, we use the message context to add a custom message when the validation fails, as you can see in the preceding code snippet.
This is in contrast to other methods we have called previously when using an evaluate expression.
When executing an expression, the result (if it isn’t already an Event) is internally converted to an Event.
Also, these objects can optionally have objects as attributes associated with them.
When you do not need to trigger outcome conditions, there is no need to use an Event as a return value, and you can return the value as-is (or simply return void)
Web Flow will do the conversion to a successful Event for you.
However, in this case we need to differentiate between a validation success and a validation failure.
In the first case, we want to proceed with the order-creation process; in the second case, we want to render the select delivery options page again to show the error message and let the user try again.
Note that we could have attached a result with the successful Event, which could then be bound using the result attribute of the evaluate action.
We will discuss this later in this chapter’s “Working with Outcome Events” section.
Showing Validation Messages Finally, after adding validation messages with one of the three different approaches shown so far, we must still show them to the user.
To do this, we can use the Spring MVC standard <form:errors> tag to do one of two things.
First, we can render the messages for a specific path in our model.
Alternatively, we can render all messages by specifying the wildcard for the path attribute.
It is important to realize that messages generated by all validation methods can be shown in this way.
This will enable us to show the validation message in case the validation fails for that field.
The other two pages repeat the exact same process, so we won’t bore you by showing those, as well.
If we were to proceed without selecting a delivery date, the error message would be shown next to the field (see Figure 11-6)
The localization part of our custom error message comes from the default resource bundle included in our application.
To refresh our memory, let’s look at a snippet from the method that builds the error message:
The resource bundle has the code as the key and the translation (which you can see in Figure 11-6) as its value.
You can change the language dynamically by clicking the flags at the right end of the navigation bar.
In the case of bean validation messages, there is a standard resource bundle that is loaded by default.
You can override these messages in your own resource bundle.
The default resource bundle is part of the validation API’s implementation.
In our case, this is the RI (i.e., the Hibernate validator)
If we were to open the Hibernate validator JAR file, we would see the message bundles (see Figure 11-7)
Overview Before closing our first refactoring, we want to summarize the different things we have done so far.
This will give you a complete code overview of our flow and the involved OrderController and OrderForm.
We started out by loading our categories and books using the <on-render> action.
Next, we replaced the book and category references in our form with the real entity object.
In order for this to work, we had to create and register two custom converters.
Finally, we added validation to our flow, so that it is no longer possible to trigger application errors by not entering values for the mandatory fields.
We also showed you that there are three ways for you to implement validation.
Before going any further we would first like to introduce you to some other Web Flow features.
In this section we will cover how you use flow variables and access the different Web Flow scopes using the implicit objects.
A scope is treated as a java.util.Map, so you just pass along a key for reading values out of a scope, as well as a key plus value for setting something on a scope.
For example, here’s what you do if you want to read the value with the myKey key from the flow scope and pass this value to an application controller:
In addition to the <set> element, you can also set variables using the expression language in an evaluate action.
Listing 11-31 shows how to store the result returned from executing an application controller method on flow scope.
Flow Variables A flow may declare one or more instance variables.
These variables are allocated when the flow starts, and they are destroyed when the flow ends.
The name is the key under which the created instance will be available on flow scope, while the class attribute is the fully qualified class name of the class to be instantiated.
Web Flow creates an instance using the default (or parameterless) constructor of the class.
Note that Web Flow will create a Spring-managed bean from the created instance.
In doing so, Spring will fully initialize the instantiated class, applying all applicable BeanPostProcessors.
The instance will eventually be registered as a Spring bean with the application context.
This means that you can use for example @Autowired annotations in the class.
This also counts for referenced objects not marked as transient.
However, references to objects that hold no state (e.g., services, facades, DAOs, and so on) should be declared as transient.
Java’s transient keyword excludes these objects from the Java serialization process.
Such objects do not need to be serialized because they do not contain any state.
If these instances are autowired beans (using @Autowired), then Spring will make sure they are rewired when the flow resumes.
The <var> element is primarily used to create instances of classes before the flow starts, and these classes are used in the scope of that flow execution.
You can only use this element on top of the flow definition.
In comparison, the <set> element is better suited for setting or moving values between already existing instances.
For example, if you want put a given request parameter value on a search criteria object, you could use the <set> element.
In the name attribute, you would refer to the key that represents the search criteria object.
Accessing Scoped Variables from Views As we have seen, there is an implicit object available for each of the Web Flow scopes that you can use to reference the scope from within expressions inside your flow.
The Spring EL context is modified by Web Flow, so that these implicit objects are made available.
What Web Flow does is put every object from every Web Flow scope directly onto the Servlet request scope before the view is rendered.
You have to be careful with the names of the keys.
If you have a value with key x both on flow and conversation scope, only one of the two will be present in the Servlet request scope (one will be overwritten)
Normally, this would not present a problem because having the same key on different scopes does not make much sense.
We can obtain a reference to the RequestContext or ExternalContext object by injecting them using an expression.
For example, flowRequestContext and externalContext are both implicit objects, referring to the RequestContext and ExternalContext interfaces, respectively.
If we have an evaluate action, we can use an expression like this:
The someMethod method accepts the RequestContext as a parameter (see Listing 11-32)
There are also two thread-bound holder classes that give you instant access to the RequestContext and ExternalContext:
Controlling Action Execution We’ve already seen three ways of controlling the execution of Web Flow actions: on transition, on start, and on render.
However, there are other ways to execute these actions, all of which have some specifics that govern when they execute their contained actions.
These conditions are summed up with a detailed overview in the upcoming sections.
Each of these elements can also have three sub-elements; these are described in the “Controlling Action Execution: Sub-elements” section.
There can be only one <on-start> for an entire flow.
This action is useful for executing the overall initialization of the flow execution/session.
In our sample, we used it to initialize our form with some defaults.
If a flow throws an error before reaching the end of the flow, <on-end> is not executed.
There is no guarantee that the <on-end> will be executed.
For example, assume a given flow enters a certain view state and renders a view to the user’s browser.
At this point, the flow execution (i.e., the one living in the web container) is paused.
The user can now decide to trigger a new event that continues to converse with that flow execution.
However, the user can also decide to navigate to another page (or another flow), leaving the current flow execution as-is.
When the maximum number of concurrent executions is reached, Web Flow will start to clean up the oldest flow execution.
If our given flow execution is the oldest, it is cleaned up; but in that case, the <on-end> element will not be triggered.
It is only triggered when the flow execution ends normally (after hitting an end state)
This element is especially useful in a flow with multiple end states where certain logic needs to be executed when the flow ends.
Without this element, the logic needs to be repeated for each end state, but it can now be placed in a single on end.
This will ensure that the required logic is executed, no matter which of the different end states terminated the flow.
However, this is only true when the state is explicitly entered.
However, the <on-entry> will not be triggered in that case.
There must be an explicit transition to a state in order to execute the <on-entry>
The state to which the to attribute refers is of no importance; this holds true whether it is the same state where the transition is defined or another state altogether.
For example, in the case of a view state, if a transition returns to the same view state (explicitly specifying the to attribute), then the <on-entry> will be executed again.
However, it would not be executed when we trigger the add transition because it does not explicitly transition back to the selectBooks view state (it has no to in the transition)
The action specified by the <on-exit> is executed every time the state is exited.
In that case, we would exit the selectBooks view state to enter it again.
When dealing with large result sets, we can benefit from this behavior by loading them into request scope right before the view renders.
We already seen this in action in this chapter, when we covered the first phase of refactoring the sample application (see the “On Render” section earlier in this chapter)
Controlling Action Execution: Sub-elements Each of the previously described elements supports three sub-elements:
It accepts a (by default SpEL) expression and executes it.
Optionally, you can store the result on a scope with a certain key using the result attribute, and you can specify the result type if you require the result to be of a certain type (using the result-type attribute)
If so, a conversion is attempted; and if no converter is applicable, a conversion exception is thrown.
We discuss events further in the “Working with Outcome Events” section.
As explained in “Setting Variables and Accessing Scopes” section earlier in this chapter, the <set> element allows you to set something on a given scope.
You can specify a name and value, which are respectively the key under which the variable will be known and the value bound to it.
Optionally, you can require the result to be of a certain type.
If the value is not of the required type, a conversion is attempted; and if no converter is applicable, then a conversion exception is thrown.
It supports a fragments attribute that takes the id of a fragment to be rendered.
But what is a fragment? To make use of these features, you need Tiles.
When configuring Tiles, you define the parts that fill up your template.
A fragment refers to the name of such an attribute or definition.
It allows you to partially render a part of the page composition.
When a page consists of multiple parts (each identified by a tiles attribute), you can name the part in the fragment that you specifically want to re-render.
This allows for a partial page update in the browser.
For this to work, it requires some special configuration on both the server and client sides.
When doing a normal request, specifying the <render> action will have no effect.
Global Transitions As we have seen, a transition may take the user to another view, or it may simply execute an action and re-render the current view.
In the next chapter, we’ll also see how a transition may request the rendering of parts of a view called “fragments” when handling an Ajax event.
To be able to trigger them, you have to be in that given state.
In addition to transitions defined in a particular state, a flow can also have global transitions.
When an event occurs, if Web Flow cannot find any matching transitions in the current state of the flow, it will try to find a matching global transition.
Global transitions have to be defined at the end of the flow.
You may find that some transitions are duplicated in several view states.
With global transitions, you can now define them in one place.
After that, each state will be able to execute that transition as if it were directly part of the given state.
The most common example of this is a Cancel button that terminates the flow, but which might be present on each step of the flow.
Subflows Subflows give you an alternative way to structure your flows.
As it turns out, one of the strong points of Web Flow (which we haven’t really discussed until now) is its support for composition and modularity.
Composition allows you to combine different flow definitions to build a more complete definition.
To do this, you reuse existing definitions, which saves you code duplication.
In the next chapter, which is on advanced Web Flow, you will see this in practice using inheritance.
If you design for modularity, you will be able to treat certain parts of your flow as separate modules.
This also promotes reuse, as you will be able to refer to those modules from other parts in your application without having to duplicate code.
In this section, we will look at subflows, a Web Flow technique that will help you in accomplishing such reuse.
As is true for any object-oriented language, you need some kind of design.
The design will cost you a little extra effort, but this feature will be a (very) important aspect of your project.
For example, it will dictate how manageable your application will be in the near future.
Whereas in Java we could write everything in a single class or even in a single method, we all know that this would turn into an unworkable project in less than a day.
Therefore, we try to apply good design principles because we know we will benefit from doing so in the long run.
It will make our project easier to test and our code easier to read.
It will also improve the quality of our code and make it easier to extend without spending weeks of refactoring.
Flows don’t contain real Java code, but they do replace (or accommodate) your application controllers, which are an important part of the logic inside your flows.
A good design in your flows makes them easy to read, easy to refactor, and, above all, reusable.
Note  Web Flow 1 included a feature called inline flows, which is a flow that is inline with, or embedded inside, another top-level flow.
Such a flow does not need to be registered with Web Flow separately (you have to provide the flow id yourself inside the <inline-flow> flow element)
The best way to compare an inline flow is to a private Java nested class (or a private inner class, if you like)
If you must migrate such flows, the advised action is to simply move them to a top-level flow definition and register them with a flow id in the flow registry.
The flow id should be equal to the id attribute of the <inline-flow> element.
Or, you can use the flow definition update tool to do this for you.
A subflow is no different than a normal flow, which we’ve already covered.
As we will see in the next section when we continue refactoring our sample application, calling a subflow requires a special state and some consideration about passing along state between the parent flow and the subflow.
The flow that includes the subflow is referred to as the parent flow.
The subflow is sometimes also referred to as the child flow.
In short: Subflows enable you to move parts of a flow contained in one flow (flow-x) to another toplevel flow (flow-y)
Next, you can point from flow-x to flow-y using the <subflow-state> element in flowx; this enables you to execute the parts that you moved to flow-y.
This refactoring does not influence the behavior of your flow (or your application altogether), but it has an impact on your flow design.
When you have a piece of flow logic that is required in multiple flows, you can extract that logic, place it in another top-level flow, and then delegate to that flow as a subflow in the other flows.
When you have some logic in different classes that does the same thing, you extract it, put it in a separate class, and call that from within the classes you extracted the logic from.
You can apply the same pattern with flows; simply extract the common parts and put them in a separate flow.
When changes are required, you only need to make them once, instead of changing them separately in every flow.
As noted previously, it is important to understand that a subflow is no different than a normal flow.
In fact, you don’t create subflows per se; you just create a normal flow.
A subflow should be registered as a normal flow, and the same rules apply.
In Figure 11-8, both flow-x and flow-y are normal flows.
However, flow-y is also included as a subflow in flow-x.
So, from the point of flow-x, flow-y is considered a subflow.
Flow-x starts as a top-level flow and calls another flow (flow-y), which becomes its subflow.
When you include a subflow in your flow, that flow can itself delegate to a subflow and so forth.
There is no hard limit defined for how many levels of subflows can exist.
Note  As we have seen, a subflow is defined as a normal top-level flow in its own flow definition XML.
We speak about a flow being a subflow from the moment it is included in another flow.
However, because it is a normal flow, you can still start it like any other normal top-level flow.
However, in most cases you will design a flow specifically for use as a subflow; hence, starting it directly without the context of the parent flow would not make much sense.
Nevertheless, there exist scenarios where it might make sense for a given flow to be started as a top-level flow from one part in your application, but also to be included as a subflow in another part.
Further Enhancing the Bookstore We will continue our refactoring effort with the elements we have discussed in the previous sections.
So far, we have not added any security to our application.
In the previous chapter, we explained that, once you enter the application, you are automatically logged in.
However, we will now replace the login process with a traditional login page.
We will also require that the user be logged in prior to making an order.
And while we will dedicate a separate upcoming chapter to security (Chapter 13), in this section we’ll take a first look at security by creating our own home-grown security mechanism.
We will use this to illustrate several aspects of flows, including subflows and the remaining states that have not yet been covered.
It was required in the previous sample to be able to add orders to a user (you must be logged in to be able to add an order and view existing orders)
In this chapter’s sample, we’ve removed the listener because we will be implementing our own security mechanism.
The numbered steps in the diagram are described in Table 11-2
The revised flow from our book store application that we will refactor.
As we will see, the user has the option to log in via the login link in the navigation bar (using plain Spring MVC)
When authentication is successful, control is returned back to the createOrders-flow.
Creating the order has been implemented using an evaluate expression in the finish transition.
As we will see, a more elegant solution would be to use action states.
Implementing Authentication as a Subflow Our first action is to implement a flow that is able to capture the username and password from a page and verify its authenticity.
A page and form to capture the username and password; our login page.
An application controller method to verify the username and password and mark our user as authenticated.
A flow which will manage the navigation and act as glue between the login page and our application controller.
Perform the authentication by calling the appropriate method on the application controller.
If the authentication failed, we would remain inside the subflow, showing a message and offering the user another chance to enter the correct credentials.
Indicate that we want to go back to the previous page, in case the user decided not  to place the order at this time.
We will see in a minute how we can include this flow as a subflow.
This form will be used to capture the username and password submitted from the login page.
Next it will proceed by entering the view state, which eventually renders the login page.
When the authentication transition is executed, it will invoke the authenticate method on our.
We will discuss this method later on in this section.
Finally there are two end states to let the caller of the sublow differentiate between going back to the previous screen or continuing processing because authentication succeeded.
If authentication would fail, we remain inside the subflow, show a message that indicates that the user provided bad credentials and should try to login again after altering them.
The first thing to notice is the value of the form’s action attribute:
We refer to the authentication page from two places in our application.
The first reference occurs when clicking directly on the login link in the navigation bar.
In that case, we don’t start a flow, but navigate directly to the login page using plain Spring MVC.
There is also no need for a flow because, in this scenario, the authentication process only consists of a single page.
This is useful if the user wants to login directly from the main page.
Since there is no flow active, the else of our conditional operator is used for the form’s action attribute: when clicking the Login button (after filling in username and password), the form will submit to authenticate.htm.
Executing this application controller method will retrieve the submitted username and password bound to the AuthenticationForm and authenticate the user.
When the user wants to create an order, but is not yet authenticated, she is redirected to the login page first.
The second thing to notice in Listing 11-38 is that there are the two input fields (username and password) being bound to the authenticationForm.
Next, we declare the path within that form for each input text:
The first button starts the authentication process, while the second returns the user to the previous page.
When the login button is clicked, the form is simply submitted to the authentication method in case the page was loaded by Spring MVC.
The method executed is the one with the annotation, as seen in Listing 11-38:
If the previous button is clicked, then the last request mapping in Listing 11-40 is executed:
The distinction is made based on the presence of the _eventId_previous parameter.
If the authentication page was loaded by Web Flow, the eventId present in the name of the button will determine which transition to execute.
If the button with name _eventId_previous is clicked, then the previous transition will execute.
This method will be executed when the login button is clicked and the authenticate transition is executed.
This transition is the first method seen in Listing 11-40
The second method is a shared method that is used from the Spring MVC entry point as the Web Flow entry point.
As everything is set now, we can include our authentication flow as a subflow from our createOrders-flow.
Figure 11-10 shows the different attributes and elements that are possible for this element.
You’ll learn more about many of these elements in various places in this book.
The subflow state we declared for calling the authentication flow can be seen in Listing 11-41
The subflow attribute refers to the id of a registered flow.
As explained before, a subflow is a normal flow, so the id you specify there would be the id that you would use to launch a flow as a top-level flow within your application.
The transition on attribute of the <subflow-state> element should match one of the end state ids of the subflow.
This way, the subflow can tell the parent flow which state to transition to, depending on which end state was executed on the subflow.
However, if our subflow were to end with an end state with the authenticationOk id, then we would continue to the placeOrder state.
We still don’t have everything we need to be able wire everything together.
In our createOrdersflow, we need to decide whether we need to go to the subflow.
If our user was already authenticated, then there is no need to execute the subflow.
Decision State A decision state can contain any number of if elements that define an if-then-else structure.
The test attribute of the if element defines the condition, while the then and else attributes identify the target state.
When the flow enters a decision state, the first matching if is used to transition to the next state.
This means that all other if elements will not be processed.
The decision state can also delegate the criteria for the decision to Java application code using expressions.
You can see the different elements and attributes of the decision state (including their order) in Figure 11-11
In our sample, we will use a decision state in the createOrders-flow to check whether the user is authenticated.
If the user is not authenticated, then we will proceed to the authentication subflow, which will render the login screen.
If the user was previously authenticated, we can immediately proceed with creating the order.
Note  Remember that the authentication mechanism is a self-invented, session-based model.
There is usually no need to build such a model yourself.
However, we opted not to distract you by introducing Spring security because right now we want you to focus on the core Web Flow items being discussed in this chapter.
When authenticated, the model simply places a token on the session scope.
You can see the implementation of the decision state in Listing 11-42
If multiple if conditions are supplied, then they are evaluated one by one.
You can implement a chain of if conditions; however, be aware that any if condition that defines an else clause will, by definition, evaluate to true.
This means that none of the remaining if conditions will be evaluated.
For this reason, if you have multiple if elements, it only makes sense for the last if element to have an else.
If one of the previous ifs had an else, then the subsequent if elements would never be evaluated.
This makes sense if you think about it; if an if has also an else condition, either the then or the else is executed.
Hence, all if elements that are defined below an if condition are skipped.
Before we show you an overview of what we have done in this chapter, we want to perform one last refactoring—for the create order process.
This process is now embedded as an evaluate action of the finish transition.
We are going to replace this with an action state.
Action State An action state executes an action as its activity.
Action states are typically used to interact with back-end services, either directly or via controllers.
Action states execute automatically and do not pause the flow execution.
A view state pauses the flow execution (the view gets rendered, and the user spends time working with the view), but an action state signals events that leads to transitioning to another state.
In the example that follows, we transition to the end state when an order is successfully made.
We could also react to on “error” events and transition to an error page instead.
Note  There is no single rule for determining whether you need an action state.
You should probably be using an action state if there are multiple outcomes that you could react upon or in cases where processing is more complex (e.g., when executing multiple actions)
To refactor this, we simply move the evaluation expression to an <action-state> and adjust the transitions accordingly.
You can see this in the last method of Listing 11-40
The OrderForm was created in the beginning of the createOrder-flow in the on start element.
We don’t need to specify a scope per se because the expression language will look in all Web Flow scopes automatically (i.e., specifying orderForm without the implicit flowScope object would also be correct and yield the same result)
Working with Outcome Events As we have seen, we can use our evaluate action to invoke methods on application controllers.
When called from action states or decision states, these method return values can be used to drive state transitions.
Since transitions are triggered by events, a method return value must first be mapped to an Event object.
In this case, the action’s result event becomes the primary basis for the transition decision.
When combined with a controller or POJO action, this allows you to call a method in application code that returns a single value that can be used as the basis for a routing decision.
In our action state, the placeOrder() method returned an object of type Long.
Flow creating an event with the success id—hence, our transition of on="success"
If you however have a evaluate action nested in a transition instead, you can only decide whether the transition is allowed to continue or abort.
You can do this by returning a success or error event, either directly or by letting Web Flow map it for you.
If you do not return an explicit success or error event, then Web Flow will map your return value to an Event, as described in Table 11-3
In all other cases, the transition is aborted and the last view state is re-rendered.
Overview With all the previous refactorings applied, Listing 11-45 shows what our createOrders-flow now looks like.
Subflow Input/Output Mapping As we have seen in the “Different Web Flow Scopes” section, every flow session has its own flow scope.
We also illustrated that this is the case for subflows.
On scope level, subflows are no different than ordinary flows, and they work in their own flow session—hence, they have their own flow scope.
So, what should you do if you need to access data from the parent flow when within a subflow? Sure, you could put it on conversation scope, but that has some drawbacks.
A subflow is best seen is a black box with a specific input and output contract.
Putting everything on conversation scope merely to make data access easy violates encapsulation and might lead to brittle flow design.
A better option would be to bring the data over to the subflow’s flow scope—but only the data that the subflow is demanding.
Web Flow supplies some special functionality to define an input and output contract for subflows.
That way, you exactly know what data it takes as input and what data is gives back.
You can define the input contract of a flow by adding an input mapping to your flow.
Input mapping is responsible for mapping all input provided to the flow when it is launched into its flow scope.
You can also define the output contract via an output mapping.
The output mapping defines the values that are to be expected as a result of executing the flow, and they can be mapped back into to flow scope of the parent flow.
Before we continue, you should understand how Web Flow treats input and output attributes.
This map is standalone and will merely be created to form the transition between the attributes coming from the parent flow and going to the flow scope of the subflow.
When a flow starts, it gathers information to put into the input map.
This information might come from the URL or an input from a <subflow-state>
You can access the input map with the <input> element in the starting subflow.
Here flow-x exposes an attribute with name of varX to the subflow, flow-y.
It does that by specifying the input element in the subflow state.
This enables Web Flow to fetch the key, varX, from the flow scope of flow-x and then place the key/value on the input map.
When flow-y starts, it will look in the input map for a varX attribute and place it on the flow scope of flow-y.
In Figure 11-13, you also see that the input map is populated with values coming from the URL.
The reason for this behavior is that it allows you to easily use a flow as a standalone flow and as a subflow.
Note  The output mapping mirrors the input mapping, the same principles and rules apply.
One in the <subflow-state> of the parent flow and one in the subflow itself.
There is also an output map, which maps values from the subflow back to the parent flow (as you can see in Figure 11-13)
It enables custom mapping using a Java class rather than performing the mapping inside the flow.
This is pretty exotic; normally, the standard input and output elements should be sufficient to map whatever you need.
However, if you need some resource access while mapping data, this will help you accomplish that because you will have full control over the mapping process.
Creating the Order Process as a Subflow So far, we’ve created a subflow for performing the authentication.
Next, we will further refactor the createOrders-flow and extract the part that actually places the order into a subflow.
Remember that we previously refactored this to an action state in the createOrders-flow (see Listing 11-46)
In order for the action state to work in the subflow, we need to pass along our order form.
The order form is stored on flow scope of the parent flow; and, as we have already seen, the subflow will have its own flow scope.
Thus, we need to map the order form from the parent’s flow scope to the subflow’s flow scope.
The account is not required to be mapped because we put the account on the Servlet session scope.
This scope is reachable from our entire flow (and even beyond Web Flow such as in Servlets or JSPs because it is a JEE scope)
We will also need to send back the order id to the parent flow once the subflow completes.
First, we map the orderForm from the input map to the flow scope of the subflow.
We also declare the input to be mandatory and declare it to be of a specific type.
The type is just an extra check to ensure that the input is of the correct type.
When the input is not of the indicated type, a type conversion will be attempted.
In the end state, we use the output element to map the result (in this case, the id of the order) back to the parent flow.
If you have multiple end states and all of them output the same result back to the parent flow, then you can also remove the output element from each of the end states and put the output element below the latest end state.
This way, you don’t have to repeat the output element for each end state.
The output is then mapped, no matter which end state terminated the subflow.
Listing 11-48 shows how to declare a single output element that maps the declared variable to the parent flow when any of the end states terminate the subflow.
Finally, Listing 11-49 shows the subflow-state in our parent flow; this will declare which subflow to execute and is indicated by the subflow attribute.
The value is the id by which the flow we want to run as a subflow is mapped in Web Flow.
This is nothing new—we covered this previously in the “Implementing Authentication as a Subflow” section.
Inside the subflow state, we can see the input mapping.
This is the value we will be making available to the subflow.
The output mapping is the inverse of the input mapping; in other words, this is the value returned by the subflow that we will be binding to a variable within our parent flow.
For the output mapping, we chose the variable name, orderId, which will be put on flow scope by default.
The output value (the order id) will be used by our end state, which will use it to pass on the target URL that will be rendered when the flow ends (we will discuss the end state in the next section)
The transition is also nothing new—we covered this in the “Implementing Authentication as a Subflow” section.
When the subflow terminates, it will trigger this transition because the on attribute matches the end state id of the subflow and brings us to the end state of the parent flow.
Caution  You cannot specify a scope in either the input or output element.
By default, the values you refer to in the input element are resolved from flow scope, and values are put back on flow scope with the name you specify in the output element.
The fact is, flow scope is the only logical scope to use for input/output mapping because the conversation, flash, and request scopes are shared with the subflow.
Note that view scope is not shared, but it clears anyway, as soon as your flow leaves the view state.
The best way to understand this is that, in the <subflow-state> element, you define which keys from a given value/expression you want to map to the input map.
End State An end state terminates the active flow session.
Figure 11-14 shows the attributes and elements for this state.
Listing 11-50 shows an example of an end state terminating the active flow session.
If the terminated flow session is the root flow session of the ongoing flow execution, then the entire flow execution will end.
When the session is a subflow session, then processing will resume in the parent flow.
And it is not uncommon for a flow to have no end states, such as when you have a repetitive process like searching (where you typically have a Search Again button)
Having multiple end states is also common—one for each logical outcome of the flow.
As shown in the sample code, we have an end state in case the user wants to cancel the order flow.
If this happens, we redirect the user to the home page.
We also have an end state that redirects the user to the order overview page once an order has been successfully created.
Such a view can be used to confirm that flow processing ended successfully; this is typically called a confirmation view.
The view referenced by an end state will only be rendered when that end state terminates the entire flow execution.
If the end state ends a subflow session, view selection becomes the responsibility of the resuming parent flow.
In the “Subflows” section, we also saw that an end state can have an output element.
This allows the end state to map data back to the parent flow.
However, the end state is a bit of an exception.
When an end state is triggered, Web Flow will terminate the flow execution after handling the first request in the PRG idiom (the POST request)
It will also render and send back the view after processing the first request—however, it will not send a redirect, as it normally does.
If a normal redirect is issued, the second request in the PRG idiom (the GET) triggers a flow execution restart because the flow execution was already terminated after handling the first request (again, the POST)
This means that, if you refresh the page after hitting an end state, you will be restarting the flow.
To avoid this, it is better to let the end state redirect to a stable (possibly external) URL.
For an external redirect, outside of the application’s context, you could use the externalRedirect attribute.
In this case, there will be no more incoming requests to the flow execution because the newly rendered URL has nothing more to do with the flow.
Summary After finishing this chapter, you should have a solid understanding about most Web Flow features and how to apply them.
You should be able to start using Web Flow in your own applications, referring back to this chapter and Chapter 10 whenever you are in doubt or need to refresh your memory on the specifics of Web Flow’s behavior.
In this chapter, we showed how you can solve real-world use cases using Web Flow.
Along the way, you learned in detail how you can choose among the different types of validation.
This chapter also addressed subflows, which allow you to build more maintainable and reusable flows.
For example, we covered all of the different scopes, as well as how to use them.
We also reviewed all of the action states and covered how to use them in our use sample application.
You are now ready to proceed to the next and final Web Flow chapter, where you will explore some of the more advanced functionality that Web Flow has to offer.
In the couple previous chapters, we made you familiar with the Web Flow basics, such as how to configure Web Flow, glue it together with Spring MVC, and set up a basic flow.
We also explained the different elements, such as action states, model binding, validation, application controllers (and how to call them), expressions, and so forth.
Our approach for the previous chapters was to gradually introduce you to the concepts contained therein and to build on those concepts as the chapters went on.
In Chapter 10, we started with a basic high level view of Web Flow, introduced a simple use case, and then built that out as a sample application to illustrate the different aspects of using Web Flow.
In Chapter 11, we extended that by further refactoring and building out the sample application with new Web Flow functionality.
This chapter will continue to build on those topics covered previously; however the topics in this chapter are less coupled.
Every topic should be more or less seen as an individual topic that discusses its own Web Flow feature.
We will continue with the sample application as we left it in the previous chapter, and we are going to make modifications to support the features we discuss here.
A feature can be something completely new or an extension to something we saw in a previous chapter.
We intentionally divided the chapters this way to keep the previous chapter as digestible as possible, but also so that you can start in this chapter with the required Web Flow knowledge to jump right into a given feature.
After reading this final chapter on Web Flow, you should have a thorough understanding of nearly all the most important Web Flow features, including how and when to use them in practice.
Inheritance In the previous chapter, we introduced you to subflows, which will help you in structuring and reusing your flows.
But there is another Web Flow feature that can help you with this structure and reuse: inheritance.
In the previous chapter, we also saw there is a special attribute on the flow root element that you can use to declare flow inheritance (the parent attribute)
In addition to the flow, inheritance can also be applied to the five different states individually (i.e., the view, action, decision, subflow, and end states)
In the following sections, we will discuss each of these modularity features in detail.
And again, we will build these examples on top of the sample application constructed in the previous couple of chapters.
Flow Inheritance You can enable a flow to inherit elements defined by another flow or set of flows.
You declare the inheritance by using the parent attribute to mark each flow that has elements you want your flow to inherit from.
A common use case is for a parent flow to define global transitions and exception handlers.
The flow should be seen as merger between the parent and the current (child) flow.
Unlike with Java, you can inherit from multiple parent flows.
You simply separate each flow with a comma; the order is of no importance (see Listing 12-1)
Tip  Suppose you have several flows that share a lot of common functionality.
In that case, you can move the common functionality out of the individual flows and into a parent flow.
You can then let each of the individual flows inherit from that parent flow.
However, if you define it as such, the parent flow will be a normal flow like any other flow (it needs to have an id, be registered with Web Flow, and so forth)
This also means that you will be able to start the parent flow because it is a separate flow.
However, doing so doesn’t make sense in this case because the parent flow must always be combined with one of the child flows.
It is the child flows that should be started, not the parent flow they have in common.
Note that you can declare the parent flow to be abstract.
This will tell Web Flow to disallow starting flow executions (either top level or via subflows) for that flow.
However, if extend from such a flow, the child flow can be started normally as a top-level flow or subflow.
You can do this by setting the abstract attribute to true on the flow root element.
Web Flow will create a merged flow from the child flow and all its parent flows.
The rules for duplicate elements are split into mergeable and non-mergeable elements.
Mergeable elements will always attempt to merge together if the elements are similar.
Non-mergeable elements in a parent or child flow will always be retained intact in the resulting flow; they will not be modified as part of the merge process.
Mergeable elements are identified as mergeable when the following conditions are met:
Their key attributes match: If they don’t match, they fall into the non-mergeable category and are taken as-is in the resulting merged flow.
The key attribute is an element’s attribute that is identified by Web Flow as the one used for mergeability matches.
In other words, when the same element type exists in both the parent and child flows, and the value of this attribute matches, then the element is considered mergeable.
They are marked as merge always (see Table 12-1): In that case, the mergeable elements are always merged, no matter what.
In that case, there is no key attribute that should match first.
For example, Listing 12-2 shows an invented flow with a single view state that has two transitions.
Focusing on the inheritance aspect, it doesn’t matter which view the view state renders, nor is it important to which states each of the transitions transition.
The parent flow listed in Listing 12-3 cannot be started directly because it is declared to be abstract.
The child flow listed in Listing 12-4 can be started directly.
Because the child flow inherits from a parent flow, Web Flow will scan for mergeable elements.
It will find that, in both the parent and child flows, a view state with the id of someViewState exists.
It will now merge the view state, combining all elements inside.
This results in a merged flow (see Listing 12-5) that looks like the original flow.
This merged flow doesn’t exist physically; rather, it is generated in memory when Web Flow starts and scans your flow definitions.
In this case, the view state was a mergeable element because it had the same id, which is the key attribute for a view state on which Web Flow decides to merge the element.
If the id value were different, then Web Flow would have taken the element from the parent flow as-is and copied and pasted it into the merged flow.
In Table 12-1, you can see the different elements and their key attributes.
If there is an element in both the child and the parent flow that has the same key attribute, then the element will be marked for merging.
Otherwise, the element is taken completely as-is into the merged flow.
If an element has Always merged as a key attribute, it means that no specific attribute must match, and elements of the same type between parent and child are always merged.
As explained before, they become part of the merged flow asis, and they are copied and pasted as a whole from the parent flow(s) into the merged flow.
Attributes on elements that are not marked as key attributes in Table 12-1, and that are specified on the element in both the parent and the child flows, will be overwritten by the child flow.
For example, consider the view attribute of a <view-state> element.
So, every sub-element will be inherited from the parent; but in this case, the view attribute is defined both in the parent and child flows with a different value.
The resulting merged flow will navigate to view "b" when the flow is rendered.
The same goes for non-mergeable elements that are specified in both parent and child flows with the same identifiers: the child flow values take precedence.
If we were to remove the <var> element from the child flow, then there would be only one var element with the name of x left (the one in the parent flow)
In that case, the variable x will become an object of type ClassX.
Warning  Paths to external resources in the parent flow should be absolute.
Relative paths will break when the two flows are merged unless the parent and child flow are in the same directory.
Once merged, all relative paths in the parent flow will become relative to the child flow.
In our samples, this is not much of a problem because we are not dealing with resources directly.
Our views are literals, which match up with definition names in the Tiles configuration.
In such a case, you should make the path to the resource absolute by specifying the full path.
State Inheritance In addition to specifying a parent attribute on the flow element, you can also specify a parent attribute on the individual states.
This could be useful if you want more fine-grained control over which elements from the parent flow are actually inherited.
This only makes sense if you did not apply inheritance on the flow level; in other words, it makes sense only if you did not specify the parent attribute on the flow element, but instead specified it only on those states for which you want to have inheritance:
Unlike with flow inheritance, you can only inherit from a single state.
The parent state you’re inheriting from should be of the same type.
For example, a view state cannot inherit from an action state.
Basically, the same rules that apply for flow inheritance also apply here.
The only difference is that the granularity level is less coarse-grained because you can now indicate which elements need to be inherited.
The only notable difference is that the state is always merged with the indicated parent state.
With flow inheritance, it matters if the element has the same key attribute, so it can be merged or taken asis.
Since we are specifying the state directly here, it is always merged, no matter what.
You have to specify the flow in which the state you want to inherit from is defined.
Note  You might wonder what happens if there is a view state with the same name in both parent and child flows and there is state inheritance applied on them.
Meanwhile, the parent also has a view state of viewStateX.
In this case, every attribute and element of the viewStateX defined in the parent is merged with the viewStateX in the child.
If both the parent and the child provide the same attributes or elements with the same identifier, then the child version is the one that is retained.
Next, we will see how we can make some adjustments to this configuration that could be important for your application’s performance and/or how your flows are managed within your application.
We also saw that Web Flow uses SpEL by default, but it doesn’t have to be this way.
The second customization we are going to discuss explains how you can change the default expression language to something else.
We will illustrate how you define them in Listing 12-6 and then describe them in the next paragraph.
We entered these values in the code snippet to illustrate how to use these attributes, as well as to highlight their default values.
If we set this value to 0, then it will not be possible to go to a previous state within a flow execution.
In fact, your Back button will look like it doesn’t work.
A value of -1 means “unlimited”—you would probably never want to use this value because you want to keep the size of the user’s session within limits.
The max-executions attribute maps to how many concurrent flow executions can be active within a given session.
So, if we were to set max-executions to 2, then, after starting the third execution, Web Flow would simply clean up and remove the first started execution.
Note  These settings are always applicable for a user’s session, but not for the entire application.
So, if we set max-conversations to 5, that would mean that each user (and thus each session) could have a maximum of five conversations active at the same time (if a sixth conversation is started, the oldest is cleaned up and removed by Web Flow)
Caution  We are telling you right here and now that you should think about these defaults.
You probably want to tweak them to fit your needs, especially if you have lots of view states in your flows and you store lots of state in your flows—in such a case, these defaults would start to hog memory very fast (hence, you would probably want to bring these numbers down)
Also, most applications don’t need to be able to go back more than five states or more than one previous flow execution.
If you don’t need this state “save/restore” snapshot functionality at all, then set both values to 0 to disable it.
A feature we haven’t discussed yet is the expression-parser attribute.
This attribute will allow you to plug in another parser that supports other types of expression language.
By default, Web Flow uses SpEL as its expression language.
Depending on your background or preferences, you might want to switch the expression language to something else.
Setting OGNL as the default expression language could help you in upgrading Web Flow step-by-step.
As it turns out, switching the expression language is just a matter of configuring the correct class in the expression-parser attribute (see Listing 12-7)
Even if it doesn’t apply to you, you can quickly skim this section because it is very short and might be of help in the future.
That said, it does add some new stuff, refactor some quirks, and implement some internal optimizations.
This feature was simply removed in Web Flow 2, and there is no replacement.
When running Java6 or later, the XSLT processor that comes shipped by default as part of the JRE will be sufficient, so you won’t need any additional jar(s)
If you do encounter any problems, it is advised that you download Saxon (the home edition)
In that case, you just have to put the jar file (saxon9he.jar at the time of writing) in the same directory where you are putting the Spring core and Spring Web Flow jar files.
As described previously, you put the Spring core and Web Flow dependencies together with the flow from Listing 12-8 in a single directory; in this case, that directory is /tmp/convert.
If you do a directory listing, it should look like this:
The output is shown on the console and not stored in a file.
You can use your console tooling to pipe the output to a file, if desired.
In the preceding snippet, you can see that the <start-state> element has been moved to the toplevel flow element as an attribute.
Also, the <inline-flow> element is extracted as a separate flow with a warning that you should add it as a top-level flow.
Also, the conversion requires changes to other aspects, such as the flow execution listener API (these changes are covered in following sections)
You will still need to go through the flows and a portion of your code to check whether additional modifications are required.
However, this tool will at least put you on the right track.
Finally, depending on how many Web Flow 1 flows you have, and assuming your Web.
This way, you are at least relieved from having to change every expression in your flows.
Exception Handling There are three major ways in which you can deal with exception handling while using Web Flow.
In that case, we let the application controller handle the exception.
In the case of an error event, the flow will do something else (e.g., render the same view again, so that error messages are shown) instead of continuing, which would be the case if the event was a successful event.
Capturing exceptions in your application controller and steering the outcome using specific events is the preferred way of dealing with exceptions.
To some extent, this might be a matter of personal preference; however, when working with an application controller, this approach makes it more visible if the exception handling is also performed inside the method itself, rather than delegating it to the flow.
However, there are two other mechanisms you can use to handle exceptions, both of which involve handling the exceptions within the flow:
The On Exception Transition If you work with the on exception transition, you can specify the fully qualified exception class as the attribute’s value.
The transition will automatically be triggered if one of the other executions in that state triggers the exception or any of its subclasses.
You can only specify on or on-exception for a given transition, not both.
For example, in the authentication flow, you could have added an on exception transition like the one in Listing 12-11
In that case, the return value of the method is void.
If no exception occurred, then the execution of the application controller method completes normally, without a result value.
This would automatically be translated into a successful event by Web Flow, and the execution would continue as normal.
In this case, the to attribute transitions to the same view state and renders the same view.
This allows us to display the error messages added by the application controller’s authenticate method.
When an exception occurs in a flow execution, Spring Web Flow will first try the exception handlers attached to the current state of the flow.
If none handles the exception, the exception handlers attached to the flow itself will be tried.
If the exception is not handled by any of the available exception handlers, it will be rethrown.
You can attach any number of exception handlers to the flow or any of its states.
You can access the original thrown exception by calling the getCause method on it.
In this canHandle method, you can determine if you want the exception handler to be invoked for the type of exception.
If the canHandle method returns true for a given exception type, then the second method, handle, is called to let you handle the exception.
However, if you look at the return type of the handle method, you will see that there is more difficulty involved than just handling the exception and returning void.
Where an on exception transition just delegates navigation to Web Flow (i.e., upon a certain exception, it navigates to a given state), a custom exception handler is expected to drive the navigation itself, after dealing with the exception.
When an exception gets thrown at flow session startup (e.g., in an <on-start> element) the exception gets routed to the exception handler.
The exception handler must transition the flow to its start state after dealing with the exception.
The handler should not simply return—thereby leaving the flow with no current state set—because that would leave the flow execution in an undetermined state.
The former gives you more control over the exception-handling process, but it also confers more complexity.
The latter does everything for you, but you don’t have any programmatic control over the exceptionhandling process.
When using this support class, you can be sure that navigation is handled as it should be after handling the exception.
This class can be configured with a map of exceptions to handle and a matching target state that should be executed after dealing with the exception.
By default, this class also exposes the exception on flash scope.
You can override the handle method to perform custom exception handling.
In that case, it is advised that you call super.handle at the end of the method, so that the exception is still exposed on flash scope, and the transition to the target state is executed.
If a mapping exists, the exposeException() method is called, and finally, the flow will transition to the target state you indicated with that particular mapping.
An exception from the cause chain will also match with a mapping for one of its superclasses.
We have seen that Web Flow gives us three ways of dealing with exceptions:
We do so by catching the exception and adding the appropriate message to the Messagecontext.
Inside the flow by specifying the on exception attribute of a transition.
The question is this: when is it most appropriate to use each of these techniques? When working with application controllers in combination with your flow, the first approach is probably the most natural.
It gives you direct control over the exception-handling process, and it remains coupled to the code.
However, if you execute services or facades directly from within your flow (not using any application controller), then you can only react to exceptions using flow functionality.
In that case, using the second approach (i.e., using the on exception attribute) would be the preferred way to deal with application exceptions.
For example, assume you want to log whenever an exception arises.
Explicit Form Binding In Chapter 11, we saw that when a model is specified, the request parameters submitted with the form are bound to the model.
This happens automatically when you specify a model, and you don’t explicitly turn off binding for a given transition.
After binding, the model gets validated when it contains validation methods or a custom validator exists, as we have seen in the validation section of the preceding chapter.
If you want more control over the request parameters that get bound, you can specify a binder, as shown in Listing 12-14
For example, suppose that not every property on your model is used on your page.
You could have properties that are private to the application and are never rendered on the view (e.g., helper methods for exploiting the model)
Because Web Flow automatically tries to map every request parameter, a user could abuse this by submitting a value for these properties (by manipulating the request URL and parameters)
Chances are pretty small that this will be exploited because the user must to know the name of the property, and this property’s name is used nowhere in these pages.
But still, it could be a potential hole in your security.
If you have a model that contains “application private” properties that should never be populated with request parameters, then you can use a binder that explicitly lists only those properties that are allowed to be bound with incoming request parameters.
In the preceding code, we explicitly bound the username and password from the request parameters to the model.
We also marked them as required; when the value is absent, an error message will be added.
We will discuss how these messages are localized in a moment.
You can use this to point to a named converter.
This works with the older Spring Web Flow conversion mechanism, but it should no longer be used.
The Spring core conversion service does not support named converters.
Hence, using a named converter would mean that you need to explicitly register it with the Web Flow custom conversion service, but it cannot be used as such (via naming) in Spring MVC.
This will cause the right converter to be chosen automatically.
Finally, notice that we specified bind="false" on the previous transition.
The previous transition is triggered via a normal submit button in the form.
Without explicitly disabling binding, we can require that the username and password be filled in to go back.
Caution  You might recall from Chapter 11 that we had a Previous button in the sample application, as well.
In that example, we tackled this issue programmatically by checking the state in the model validation method:
In this case, the better solution is to indicate that binding="false"
If you rename a transition in your flow, the code in the model will break.
So, for simple cases, it is better to set the flow binding attribute to false.
Nevertheless, the programmatic solution might be convenient in some cases where certain validations need to be conditionally performed, depending on the state.
We marked both username and password as required, but how are they localized to an error message? In order for the required message to show up, we must declare the message keys.
Web Flow follows a predefined structure in trying to find the key that belongs to a field that is missing:
Another possibility is to use required and a place holder.
Finally, you need to declare a standard <form:errors> in your JSP with the path of the field to show the error for the different fields:
Note  In addition to the required error type, there are also others you can use, such as typeMismatch.
When an adequate type conversion cannot be executed, an error of this type is added.
You can define messages for these errors in the same manner as just discussed.
The server side supports selective partial rendering via the <render> element, on which one or more fragments can be specified that need to be rendered.
On the client side, there is a JavaScript library available that will automatically interpret the partial responses and execute the partial page refreshes.
The JavaScript part is based on the Dojo framework and is branded Spring JS (Spring JavaScript)
It is packaged as part of Web Flow, but as a separate artifact.
This means you have to put a separate dependency in your build system to obtain this dependency because it does not come directly with the main Web Flow dependency.
In our sample project, build.gradle, we explicitly defined this dependency (see Listing 12-15)
You will also get JS resources as a transient dependency.
The directory structure of the Spring JS resources, which shows a central web-resources folder.
Before we can use that AJAX functionality, we need to set up different elements.
This section will summarize those elements, providing an overview of what we will need to address for the sample application to support AJAX partial rendering:
We need to enable the special AJAX ViewResolver with the AJAX Tiles view.
This ViewResolver has special support built-in for detecting AJAX requests.
We need to rework a page, so that we can rerender a part of it via an AJAX call.
We also need to adjust the tiles-config.xml with the separate fragment that we will rerender.
We need to adjust the flow with the <render> element and specify the fragment to render.
Finally, we need to use the Spring JS in our page to start an AJAX request and let it partially refresh the part of that page that matches the fragment.
In the preceding example, we simply replace the existing view resolver with the Ajax decorated one.
When a non-AJAX view is detected, the behavior is the same as for a normal URL-based view resolver.
Preparing the View Now that we have configured Web Flow for AJAX, we will change our view by partially rerendering a part using an AJAX call (as opposed to triggering a complete page refresh)
In this section, we’ll see what modifications we have to make to support this.
We will also have to modify the Tiles configuration, but we’ll tackle that in a separate section to keep things separated and to make them easier to understand.
We will start in our selectBooks.jsp view, where there is a form that allows us to add books to the order.
Once the books are added, they are immediately shown in the table below the selected book.
This will be a good candidate for partial rendering, as seen this in Figure 12-2
Note  We should point out that we explicitly named the top-level <div> element with an id attribute.
In the following sections, we will see that it is used to identify the part of the page that should be replaced by the incoming AJAX response.
By inspecting the first element, Spring JS knows which piece of HTML to replace on the actual page.
In this case, it will look up the <div> with id selectedBooks and replace it with the version that came in via the AJAX response.
To this point, we are still just playing with Tiles, and we have not done anything special that is Web Flow AJAX related.
Thus far, this example could be a normal refactoring where we want to extract a part into a separate view (e.g., for readability, easier maintenance, or reuse)
Before Tiles will replace this with the real content, we must tell it about this new attribute.
We also explicitly gave the form an id attribute of selectBookForm; we will need this later when applying AJAX.
Configuring Tiles For the selectBooks view, we simply used the configuration shown in Listing 12-20
This snippet tells Tiles that it should render the full template, replacing the content of the Tiles placeholder with the selectBooks.jsp view.
What we want now is to extend this because selectBooks is also a template at this point.
Let’s begin by creating a new template that identifies selectBooks as a template.
This template will be included in the original selectBooks definition.
Finally, we need to link this template with the content attribute of the main template.
However, in that page, we’ve also included a Tiles placeholder.
The selectBooks page as it will be finally rendered, including all compositions.
Let’s summarize what we’ve done so far: these two Tiles definitions together form our new configuration.
Since the top-level definition we are rendering is still called selectBooks (we just changed its internal composition), nothing must be changed.
By the way, there is also a shorter notation for defining this composition that uses an inline form.
This will yield the same result, but is syntactically a bit more elegant.
We will illustrate this when we refactor the Tiles configuration in the “Flow Managed Persistence Context” section later in this chapter.
With this code in place, we can already test the refactored application.
It should yield the exact same results that it did before we changed the composition by moving the “show selected books” result table into a different view; in other words, the merged view that is being rendered should be same as the view rendered before.
Adjusting the Flow As discussed previously, we have to indicate which parts need to be rerendered explicitly.
This attribute will point to the Tiles attribute to render.
We can also specify multiple fragments by separating them with a comma, and we are also allowed to use expressions (that must evaluate to Tiles attribute names, just as their literal equivalents do)
If we take the createOrders-flow, we can add the render element in the add transition.
The render element only makes sense for transitions that rerender the same view, so we can mark the Tiles attribute, selectedBooks, for rendering.
Adding AJAX to the View with Spring JS and JQuery Finally, we need to physically invoke an asynchronous call from our browser.
Doing this will request a partial page update, causing that specific piece of our DOM to be updated.
Unfortunately, the XMLHttpRequest API (the browser API leveraging asynchronous support) is a bit problematic to use because of the nonstandard support for this feature over different browsers.
Fortunately, we have been blessed by some very good JavaScript frameworks that hide all those dirty details for us as application developers.
The first uses Spring JS, which we already have because we are depending on it.
The second relies on JQuery, which we will need to download a separate library for.
Let’s begin by demonstrating how to implement the client-side AJAX using Spring JS.
Using Spring JS In this example, we will use Spring JS to make an AJAX call when a user pushes the Add button (see Listing 12-24)
The Add button is a normal HTML submit button, and it will remain untouched.
A central concept in Spring JS is the notion of applying decorations to existing DOM nodes.
This technique is used to progressively enhance a web page so that it will still be functional in a browser that has JavaScript disabled or simply has problems with JavaScript itself.
The addDecoration method is used to apply these decorations, and we will use this method to add an Ajax decoration to the already existing submit button with the id of add.
In order to be able to use the AJAX libraries, we have to include references to them in our pages.
Because we are using templates, this is pretty easy; these references are simply added in the HTML head section of our template.
We can see this in the sample application when opening template.jsp (see Listing 12-25)
Listing 12-25: The extra JavaScript imports required to enable Ajax.
If you close such an element with the (normally syntax equivalent) “/>”, the scripts are not loaded.
This has nothing to do with Spring JS; rather, it is an HTML peculiarity.
Next, we have to decorate the button with the AJAX handler.
The JavaScript decoration, which will enable AJAX on the add button.
Several key things are worth noting about the preceding listing:
The elementId is the id of the HTML element to which the decoration should be applied.
In our case, it is the submit button with the id of add.
The event is the trigger event of the HTML element, which invokes the decoration.
The formId must match the form that contains all the information that is required to be submitted along with the Ajax request.
We added this id to the form element in Listing 12-19
The dojo.addOnLoad() method will make sure the decoration is added after all elements are loaded.
This method may not be required for this type of decoration, but it is considered a best practice to use it unless you have good reasons not to.
By the way, it does not matter where you place the <script> element.
We chose to put it at the bottom, but it could have appeared anywhere in the file.
The decoration will submit the form, causing all input to be transmitted to the server.
Because of the AJAX decoration, this happens in an asynchronous fashion.
It will take the name from the button as the event id to be triggered (which is also transmitted with the parameters)
Figure 12-4 shows what you’ll see if you inspect the request with Firebug.
Firebug’s capture of the request and showing of the request parameters.
When the flow resumes, it finds out that we wanted to execute the add transition, based upon the event id in the request parameters.
It also knows that there is a render element specified in the flow definition.
With this information, it has enough to continue selecting the view part that should be rendered.
Note  if you look carefully at Figure 12-4, you will see that there is an ajaxSource POST parameter listed in bold under the Parameters column (it is the second parameter)
This is noteworthy because there is no such component defined in our view.
It allows Web Flow to identify the request as an AJAX request.
The response received by the browser once Web Flow has finished executing the request is a partial response that contains data only from the showSelectBook view.
We can use Firebug to verify that this is indeed the case (see Figure 12-5)
The JavaScript that receives the partial view update will now try to match an element with the same type and id as in the update (that is why we explicitly named the id of the <div> element selectBooks)
It will then replace that content with the received update.
That’s it! If you now click the Add button, you’ll notice that the browser no longer performs an ordinary form submission or page refresh.
For example, in Safari you will no longer see the submit form progress bar in the browser’s status bar, which pops up when you click the add button.
Now the view update that occurs when pushing the add button will give a smoother impression because only the table containing the selected books is updated, not the entire page.
Using JQuery Instead of using Spring JS, the client part can also easily be replaced by other JavaScript libraries.
For example, you might be more familiar with JQuery (or ProtoType or another library)
These libraries will yield the same effect, as long as the mandatory extra request parameters _eventId_xxx and ajaxSource are present.
These parameters were automatically added by Spring JS, but they need to be added manually when using other JavaScript libraries.
For example, if you replace the Spring JS script with the JQuery script in Listing 12-27, you will see that this also works without any problem.
To create that script, we need to download the latest version of JQuery (version 1.7.1 at the time of writing) and add it to the HTML head section.
As you can see, the JQuery alternative requires more code.
We could probably make it a bit shorter, but Spring JS has the advantage of being optimized specifically for this job.
However, if you’re used to JQuery, you might find this to be a better alternative.
We start by adding a click event listener to the add button, which is our submit button for adding new books.
You can also see that, when we compose the request data in the data variable, we serialize the form for adding all input elements, and we manually add the parameters ajaxSource and _eventId_xxx.
Next, we assemble the request, and we identify the submit button and the form.
We serialize the form, and we manually append the required parameters.
These parameters are based on the name and id of the submit button.
The URL to submit to is taken from the form, as well.
With this URL, we can now perform the POST Ajax call, and the URL and parameters are the same as those sent out by the Spring JS.
As a response, we get the partially rendered view back from the server.
The only thing left to do is replace the entire target object with the HTML response content.
It must be said: when using JQuery, you should also take care that you handle errors that come back from the server.
When working with the Spring JS, you get automatic support for error detection: errors are nicely shown in a popup window.
Also, it is possible to show the rendered content directly in a popup window.
Flow Execution Listeners When executing a flow, Web Flow will go through different steps before it actually performs a transition or executes a method on your application controller.
For example, we have already seen that the flow execution is paused after the view has been rendered and sent back to the client.
Likewise, when a new request comes in for an existing flow execution, the flow execution needs to be resumed.
Pausing and resuming a flow execution are just two of the steps that Web Flow will be performing, but there are many more.
We say that these steps are part of the Web Flow lifecycle, which consists of the (noteworthy) steps that Web Flow goes through when executing a request.
You should evaluate whether the flow execution listener approach is sufficient to do the job you want to do.
This interface defines a lot of callback methods that will be invoked when certain things happen in the course of a flow execution life cycle.
Note  The flow execution listener is by no means using AOP or any byte-code manipulation.
It is a hook built into the Web Flow subsystem to give you callbacks for certain events during the flow execution.
Flow execution listeners are declared via the flow executor (see Listing 12-29)
The flow execution listener defined on top is called first; the listener immediately that one is called next; and so forth.
You can also specify the criteria attribute on the <webflow:listener> with a comma separated list of flow ids.
This will enable a given listener only for the given flows.
If you leave it empty, the listener is enabled for all flows.
This is the equivalent of specifying an asterisk (*), which is the default value for the criteria attribute if you don’t specify it.
Flow ids and the asterisks are the only allowed values for this attribute (see Listing 12-30)
Configuring the flow execution listener only for a specific flow id.
For example, you can get callbacks when resuming or pausing an execution, triggering events, executing actions, and so on.
Such callback methods become unpleasant when there are too many of them and they are badly documented.
They can also be unpleasant to use if you have too few of them, and you cannot use the listener to capture what you need.
In this subsection, you will find a complete explanation of each of the callbacks methods, so that you are prepared to make the right choice for a given job.
We don’t suggest trying to remembering all of these; it is better to quickly skim over them, so you know what the possibilities are.
When you need such functionality, you can return to this section and verify which callback suits your requirements best.
The thing to keep in mind is this: some execution.
You should always make sure you test properly and don’t assume that a given listener method does what you think it will do.
Note that we left out the return type for better readability, it is always void.
A flow execution listener method cannot return anything; if it changes something, it should do so with the parameters supplied to the callback method in question.
You can use these callbacks if you want to perform something upfront in the processing lifecycle that has an impact over the entire request execution.
Note that, when a new flow execution is started, the requestSubmitted callback is called before the flow execution is actually started (there will be no active flow yet at that time)
The equivalent is also true with requestProcessed: when a flow execution terminates (because it hits an end state), the flow will already be terminated when requestProcessed is invoked.
An exception may be thrown from this method to veto the creation of a new flow execution by throwing any kind of runtime exception.
In the case of launching a subflow, the flow execution has not yet been started, so the parent flow execution is still active.
The input parameter is the input map that will be passed to the spawning flow, as prepared by the subflow state <input> mapping or as provided externally.
A listener could veto the start of the newly starting flow execution session by throwing any kind of runtime exception.
This callback is useful if you want to do something every time a flow session has been started and initialized successfully.
The event could be an event signaled externally by the user or an event signaled internally (e.g., by an application controller)
This method is called prior to the transition actually taking place.
It is interesting to compare this method to eventSignaled; in this case, the transition is further along.
At this stage, you already know the source and (what will be) the target of the transition, whereas in eventSignaled, you simply know “something” is going to happen.
This method will be called after the transition matched, but before the state has been entered (e.g., no entry actions are executed at this point)
All entry logic of the given state has now been executed, and the state is fully initialized.
Note that it will not be called if the flow execution ends (i.e., it passes through an end state)
In that case, sessionEnding and sessionEnded will be called instead.
The resuming callback informs the listener that a paused flow execution has been restored and is going to resume.
At the point this callback method is invoked, the flow execution is still active.
Possible <on-entry> actions (e.g., those that appeared on the end state) have already executed.
If the flow is a subflow and has mapped out anything using the <output> mapping, it is also available via the output parameter.
This allows the listener to inspect or manipulate the output returned to the parent flow.
The outcome parameter matches the outcome reached by the ending session; this will be the id of the terminating <end-state>
When this method is invoked, the flow execution is no longer active.
If the flow in question was a subflow and it mapped data back to the parent, then the flow output map can no longer be manipulated at this point.
Also, if the parent flow has already been reactivated, but is not yet resuming.
The exceptionThrown callback method will be called whenever an exception occurs during the processing of a request in an active flow execution.
If there are flow exception handlers configured, they will be invoked after this method has been called.
Flow Managed Persistence Context With this section, we come to the last feature of Web Flow that we’ll be covering.
This feature allows you to extend a JPA persistence context into your presentation layer, while making it persistent for the duration of an entire flow execution.
While this is a simple feature when seen from the Web Flow side, fully understanding when or why to use it is a bit more complicated.
In this section, we will look in detail at what it actually can do for you, explaining and then illustrating how it works by using parts of the sample application.
All the other things we have seen in the Web Flow chapters are related to how we do something in the presentation layer.
However, this feature starts all the way back in the backend data access layer (DAL)
As you are aware from Chapter 1, we use an ORM to manage our persistence.
To be vendor neutral, we opted to use JPA as the ORM API.
In doing this, we could let the application run with other JPA providers, as well (e.g., EclipseLink)
We are using it outside a JEE managed context, which requires some manual intervention when it comes down to transaction management and other configuration.
Thanks to Spring, we can simulate a managed environment, so that there is in fact little difference from using JPA within a managed environment.
Note  While we are running in a managed environment (Tomcat), we actually mean a fully managed/compliant JEE application server with or without the EJB profile.
For example, Tomcat only implements a partial web profile of a JEE server, and it cannot be considered to be a managed environment from the JPA point of view.
In Tomcat, at least from the JPA point of view, your application would have to deal with the transaction management itself, and JPA would be configured as in a normal SE environment.
From Database to View Let’s begin by explaining how the data access is handled in the sample application to this point.
As explained in Chapter 1, we configured Spring to use JPA, and we use Hibernate as the ORM implementation.
Our application follows a typical, simple three-layered approach: we have a presentation layer, a business (logic) layer, and a data access layer.
Whenever our application controllers need something, they talk to a service.
The service uses the domain model and repositories to retrieve data from a relational database.
An entity is part of the domain model and reflects data backed by the database.
Such an entity is managed by JPA; or more precisely, by a persistence context.
One of the features an ORM may offer is lazy loading.
For example, when retrieving an Order, we could lazily load the Customer.
If we don’t need the Customer in our processing, no Customer data is loaded.
However, this feature only works when an entity is managed by the persistence context.
Normally, the persistence context is closed when the transaction ends.
This means our business transaction is committed (or rolled back), but the persistence context is kept open.
This also means that our entities remain managed, and we can still let them load data from our presentation layer (and thus, from within our views)
However, we should be careful not to perform changes or create operations in the presentation layer because there is no longer a spanning transaction when using the entities.
Each interaction will operate in its own transaction; this is unlike our business logic layer, where the entire service method call happens in one big transaction.
We simulate a method call originating from the presentation layer that goes into the business logic layer, starting a transaction on its way.
In the business logic layer, we are allowed to make modifications because all modifications we make are covered by the global transaction.
The transaction is ended when the result is returned back to the presentation layer, either committing or rolling back the transaction.
We can see that the entity is in a managed state in all layers.
Outside of the business logic layer, however, there is no more transaction.
This means that, if you put an entity on (for example) flow scope, it will become detached.
To explain this better, let’s assume we show an order on the user’s screen.
In order to do this, we load the Order entity from database using our service.
Potentially, we also show some information about the account of the user, which requires an extra query to be performed from within the view to retrieve the Account entity.
This is all good because everything is happening in the same request—our persistence context is still open, and our entity is still managed.
After the view is rendered, the flow session is paused and the view is sent to the browser.
Until now, that was just fine because our view was rendered, anyway.
However, suppose the order view allows the user to click an order that will show the details of the order (e.g., the products contained by the order)
In that case, after the user clicks the detail button, a new request comes in and the flow session is resumed.
While that is true, it will not reattach the entities that were detached when the previous request ended.
What this basically means is that, while the persistence context is extended into the presentation layer, it does not survive multiple requests.
Once a request has been processed (and the view has been rendered), the persistence context is closed.
When entities are stored on a given scope, they will be in a detached state when the next request comes in and tries to work with them.
Prolonging the Persistence Context Web Flow allows you to prolong the continuity of the persistence context over multiple requests.
As we explained in the previous section, the persistence context is opened when the request comes in, but is destroyed after rendering the view.
In the OEMIV pattern, the persistence context is not retained across multiple requests; in the FMPC pattern, the persistence context is stored for the next request in the flow session.
The good thing about this pattern is that we can just touch whatever we need in our presentation layer because we still have an active persistence context during the entire execution of our flow.
When using the FMPC pattern, we also no longer need to denote an explicit business transaction.
In our flow, there is only one place where we need a transaction, and that is in the last step: when we place the actual order.
In the intermediate steps, we just perform read access, which actually requires no transaction; or at most, a read-only transaction if we retrieve different types of entities, and we want to keep a certain amount of consistency.
In Figure 12-7, we can see how Web Flow will ensure that the persistence context is bound and unbound from flow scope before starting or resuming a flow session.
This will ensure that we are able to access the database from the different steps in our flow from the presentation layer, even on entities that are retrieved from flow scope.
Automatic binding and unbinding of the persistence context by Web Flow.
In this approach, the persistence context is opened when the flow session starts and remains open until the session ends.
The pattern should be used with read-only operations and ended in a single create/update transaction when the flow ends, as we will illustrate later on.
When you make a call that requires data (e.g., a lazy initialization of a collection or property), a separate transaction is spawned, and the data is retrieved.
This means that you don’t need any @Transactional annotation on the services.
If you need read consistency, you are allowed to do this; however, you are advised to make the transactions read-only.
Any modifications you might make are not flushed until the update transaction is executed at the end of the flow.
Let’s begin by enabling the prolonged persistence context on a per-flow basis.
We need to enable a special flow execution listener (see Listing 12-31)
The transaction manager is used to create a transaction when the flow ends.
At that moment, the entity manager is joined with the transaction, so that your modifications can be flushed to the database in an all-succeed or all-fail fashion.
The listener will also detect subflows, so that no transaction is executed when a subflow ends.
The create/update transaction is only executed when the top-level flow ends.
Next, we need to indicate which end state will trigger the commit (see Listing 12-33)
In Listing 12-34, you can see that we have put this in comments, so that it will not be loaded.
What is happening now is that, during our flow execution, our entities remain managed.
When the flow ends, we indicated that Web Flow should commit.
This means that it will start a transaction and let the EntityManager join that transaction, so it can flush the modification operations (i.e., creates, updates, and deletes) to the database.
This basically means that the createOrder method on our service does not require an @Transactional annotation anymore because the transaction is now managed by Web Flow.
Note When using disconnected transactions in the same flow (e.g., several read transactions in each step of the flow, followed by a modification transaction at the end), it is advised that we configure optimistic locking.
In our case, this is not that important because we are inserting new data.
However, this becomes very important if we want to update data that was previously read in a previous step of the flow (and thus belongs to a different transaction) because that data might be updated by the time we perform our modification transaction.
Without optimistic locking, we could end up overwriting the changes of other users without knowing it.
Reworking the Orders Overview The preceding section illustrated that we can use Web Flow to manage our transaction.
Finally, we want to illustrate that the persistence context is also available in our view for entities that are stored in a scope.
Normally this would not be possible because the persistence context would no longer available after a request ended.
The Orders Overview page shows the orders a customer made.
We will add an additional popup window that shows the details of the order.
In the domain model, we have an Order that has a list of zero or more OrderDetails.
At the moment, the orders overview is backed by a Spring MVC controller, and it is not governed by a flow.
In Listing 12-35, we will begin building a flow for the orders overview.
Note  In Listing 12-35, we are building a flow for something that is not really a “flow”; rather, it is just an overview page with a detail.
We created a flow purely in terms of the sample application, so we could demonstrate the flow-managed persistence context.
In a real-world app, this would probably not benefit from being modeled as a flow.
We also set the selected Order on flash scope using a <set> action.
The second view state renders the orderDetail view, but will only partially render it.
Because the popup attribute is set to true, this will, in conjunction with Spring’s client-side JavaScript, render the content in a popup window.
In Listing 12-36, you can see the orderDetail.jsp, which is just a fragment of a complete page because it will be rendered as a popup.
The Tiles configuration for this for is straightforward (see Listing 12-37)
It is important that this link be nested in a form.
We will also submit the index (which we retrieve from the JSTL supplied by a varStatus object) through a hidden field.
This will allow us to determine which order we want to see the details from (as we have seen in the flow, it uses the index request parameter to determine the selected Order object in the list)
We’ll conclude by decorating the link with an Ajax decoration.
Because we need both the link and the form— and because there are multiple versions of each—we use dojo to query all links where the id starts with orderDetailLink_
With this information, we can also compose the id of the anchor to bind to, as well as the form.
We also enable the popup functionality, so Spring JS knows to render the response inside a popup window.
Note To enable the form to be shown as a popup window, we enabled the popup attribute on the view state that renders the popup content.
The JavaScript that will decorate the button and trigger an AJAX request to display the order.
With the final modification in place, we can run the application and go to the Orders overview page.
We do this by clicking Orders overview in the navigation bar.
Figure 12-8 shows the orders for our customer with the user id of jd.
The new Orders overview page, which shows the orders and a link to view the details.
In the preceding code, the Order entity is stored on view scope.
The Book entities of the OrderDetails page (which we will need in the details view) are not yet initialized.
Finally, when a user clicks the View link, the details will open in a popup window (see Figure 12-9)
Clicking the view link brings up a popup window that shows an order’s details.
Web Flow placed the selected Order entity from view scope in flash scope.
Next, we instructed Web Flow to render our view state of orderDetail.
However, thanks to our flow-managed persistence context, the entities are still managed, and the extra data is loaded.
When enabled, it will silently load books in our persistence context, and we will not be performing an objective test.
Finally, we also have to mark the Book @ManyToOne association in the OrderDetail entity as lazy:
This is required because JPA (by default) loads many-to-one associations eagerly.
If we don’t explicitly tell JPA to load the association lazily, the Book entity will already be loaded when we load the.
The overview page indirectly loads the OrderDetail collection because it shows the number of books as part of the order.
This is accomplished by calling the size method on the Collection of OrderDetails; therefore, this association must be initialized.
This will implicitly trigger loading of the Book entity because it is eagerly fetched when the OrderDetail association is loaded.
After making the Book association explicitly lazy, we can click a view link to see the details.
As can be seen in Figure 12-9, we get an exception instead.
An exception is triggered when loading the book details if you are not using the flowmanaged persistence context.
Summary And that concludes the final chapter on Web Flow.
We have now covered all the noteworthy features that Web Flow has to offer and even shown you how to use them.
In this chapter, we took a more advanced and in-depth look at some of the functionality that was introduced in the previous couple of chapters.
For example, we showed you how to apply flow inheritance by implementing an extension on flow composition and modularity.
And then we dove still deeper into executing Web Flow actions.
For example, we discussed some powerful new features such as flow execution listeners, handling Ajax requests with Web Flow, and finally, the flow-managed persistence context.
As we all know, security is important for any application.
This is especially true for web applications, which are exposed to the Internet.
Exposure to outside threats is obvious, and dealing with it will be a major part of your effort to develop secure solutions.
However, the challenges that confront a developer are not only external threats.
Because security doesn’t add functionality, it is often underemphasized and sometimes even hard to justify in terms of time and resources.
It often ends up being forgotten or implemented badly under the pressure of tight deadlines and the demands for fulfilling all functional requirements.
Of course, it is a mistake to look at security in terms of “functionality.”
Security should be looked at from the same perspective as writing tests or refactoring code.
Testing doesn’t add direct value in terms of new functionality, but it does improve existing functionality and enable future additions or bug fixes to be made without destabilizing your project.
As a good developer, you refactor code on a daily basis, no matter how small the changes, to improve the application’s performance and stability.
Even though you may not be specifically asked for security, you should be aware of the threats to your application and make sure that what you deliver is as secure as possible.
On the other hand, do not forget that the entire “security” process is not entirely in your hands.
If you secure your application at application level, but the infrastructure team runs your app on a four-year-old web container without any patches applied, and a comparable operating system, you will probably get unwanted visitors no matter how secure your application is.
It is important for organizations to understand the importance of security and everything that affects it.
From the organization’s standpoint, the issue is not only a technical one.
With even the slightest anomaly that can be exploited, customers or other users may consider an application insecure.
Depending on the level of visibility your application enjoys, discovery of such anomaly (no matter how trivial) might trigger a storm of protest and give the organization bad publicity.
This might even be worse than the damage an attacker is able to do with the attack itself!
In this chapter we will show you how to fulfill your duties as an application developer and make your application as secure as possible on the application level.
We will do this by introducing you to Spring Security, which is a state-of-the-art, Spring 3.1-ready, security extension.
In this chapter we will show you how to secure your application in a couple of hours! We will start off from a basic security configuration that secures your app with a couple lines of XML.
Continuing from there, we will show how to use the database as storage for your users and credentials.
We will also investigate how you can integrate security with Spring Web Flow.
Finally, we’ll discuss the different options for applying authorization checks with Spring MVC in our JSP pages and application controllers.
Introducing Security Before we start talking about what Spring Security can do for you and how we are going to apply it to secure our application, we first need to provide some introduction to security.
It is important that we first set the context in which Spring Security will operate.
In the first part of this section, we will give an overview of application security, which is the type of security we are going to handle.
Next we will look at some general security principles and terminology that will be important for a good understanding of the remainder of the chapter.
Finally, we give a more detailed summary of the topics we will cover in this chapter, so you’ll know exactly what to expect.
To be complete as possible, we will touch on different aspects of Spring Security;
What Is Application Security? From a high-level view, application security is all about controlling access to your application’s functionality.
In our bookstore, for example, every user should be able to view the books we are selling.
But not every user should be able to create an order without fulfilling some conditions (such as creating an account and being logged in)
If we decided to further extend the bookstore with some CMS-like features, say editing or adding new books to the system, we would then want only a select set of users to be able to make modifications.
With application-level security you will be able to specify which resources in your application are restricted, and which are publicly available.
For the restricted resources you will be able to make further distinctions; a user who is able to access restricted functionality A would therefore not be allowed to access restricted functionality B.
Depending on your application’s context, this set of rules might vary from very complex to nonexistent.
In the first case you could be requiring detailed roles, complicated authentication mechanisms, and so on, while in the latter case you could be building a web site that has only read only content that is public for everyone, and so application security is probably not of your concern.
Note  As explained in the introduction to this chapter, security crosses many layers, and not just your application layer.
So that’s why the topic here is explicitly “application security.” No matter what level of application security your application demands, the environment surrounding your application needs to be secure.
You should not be afraid to ask your network or infrastructure team what they are doing to keep the environment secure where your application will reside.
An expression you probably are already familiar with summarize this very nicely: “your security is only as strong as its weakest point.”
General Security Principles We will start off covering some general security principles that will become important once you start securing your application:
Identification: Identifies a user based upon a certain identity; such as a username, token or certificate.
In case of a username it is as simple as checking the supplied password.
Authorization:  The process of identifying the functionality an authenticated user is allowed to use.
If you need to provide application security, you will first have to think about how to identify your users.
Identification will allow you to recognize a user who wants access to a protected resource.
It can also be a token, or even an x.509 certificate issued to a person or organization.
Next you will have to verify the identity that the user provides.
This process of verifying the identity is called authentication: checking the identification for its authenticity.
In the case of a username, authenticity might be verified by asking for a password and comparing the entry with the password stored for that user.
Finally, if a user’s identity is authenticated, the user is allowed access to the restricted zone of your application.
At that point you might want to make distinctions among your authenticated users.
In other words, you want to give certain privileges to authenticated users.
Before ordering something, a user must be authenticated, because you want to know who made which order, you need access to the delivery/contact addresses, or maybe to stored payment credentials like a credit card number.
However, it is clear that a normal customer who is authenticated as a user of your application should not be allowed to add or change products.
Allowing or disallowing an authenticated user certain functionality is called authorization.
Spring Security will especially concentrate on the authentication and authorization parts.
Also note that the method of authentication is in a certain way related to the type of identification your users will have to supply.
What We Will Cover Spring Security, (formerly known as Acegi Security), has become a very important piece in the puzzle if you want to secure your application.
Spring Security will especially help to secure your application by offering authentication and authorization schemes.
It will help you provide integration with many authentication systems, such as a simple database, directory services (offering an LDAP interface, for accessing, for example, open LDAP or Active Directory)
This chapter will cover how you can instruct Spring Security to take care of both the authentication and the authorization parts.
Note  Spring Security has generally seen a low intrusion level.
This allows us to add security in the more final stages of our application implementation.
Although some refactoring will be required, it will normally be very minimal.
This is one of the reasons we kept this chapter as last.
We will start by making you familiar with the basic security configuration.
We will configure Spring Security so that every request that goes into our application passes the security configuration.
We will see that this configuration is based on a filter mechanism through which a request has to pass before it is received by the requested resource.
We will also show you how easy it is to define which resources need to be protected and which can still be left publicly available (our login page, resources such as images, and so on)
For the authentication part we will be using username and password.
We will use a login form, which will include the typical username and password fields.
Besides creating the page (containing the login form) itself, we will see that we only need some XML configuration to let Spring Security handle.
By contrast, in the previous chapters we coded our own authentication mechanism.
To keep things simple, the authentication will at this point be backed by a basic in-memory data store.
Later we will see how can easily change this to a database store.
In applications using Web Flow, it’s likely that a lot of your application controller logic and view selection has been moved into flows.
We will see how we can plug Web Flow into the security mechanism so that your application is secure from top to bottom.
After we configure the authentication, we will see how we can further secure the login and order process.
Until we do that, all data is transmitted over plain HTTP.
We will see that adding transport security is just a matter of configuration.
Spring Security supports localization of exception messages, which are by default in the English language.
We will see what you should configure in order to support other locales.
We will also extend the security by implementing a role-based access model.
This will grant rights to your users that you can later use to check authorization when requiring access to a given resource.
Authorization with Spring Security can be applied programmatically, by means of code, or declaratively.
The declarative method will allow you to assert authorization using metadata in the form of annotations, expressions, or XML.
We will cover how Spring Security’s authorization can be applied in the following elements:
Views, to be able to show which component is visible or for a given user.
We will cover both declarative security (using annotations) and programmatic security and show in detail how to apply them both in your views, application controllers, and flows.
Finally we will introduce using the Spring Security Tag libraries in your JSP pages.
Note  For your information, Spring Security can also be applied in the same declarative way on your back-end (mostly on the services) as it is for your application controllers.
However, Spring Security in the back-end will not be covered in this chapter.
This application includes Spring MVC functionality, flows, application controllers, and a service layer.
In the current version, we have already applied a self-invented security mechanism.
A user can enter the site and browse books without any restriction.
Books can also be added to the shopping cart without restrictions.
A user who is not authenticated, however, cannot do a final checkout and cannot view his or her orders.
Before this is possible a user has to log in, by means of username and password.
To support this, we have a login form which takes the credentials and compares them to the information stored in our database.
As you will see, we can do all of this just by means of configuration using Spring Security instead of creating the security setup ourselves.
While our self-invented setup helped us to avoid some extra complexity at the time, and it apparently seems to do its job, there are still some serious flaws to be discovered if we look closer.
First, there is no security applied on controllers or flows.
For example, let’s go back to the previous example (Chapter 12) where we are still using our home-grown security implementation.
Without being authenticated, try to start the orders overview flow directly by typing this URL in your browser to open the page shown in Figure 13-1:
You can see that we are not logged in, as the Orders overview is not available in the navigation bar.
So even though this link is not available for an unauthenticated user, one can simply start it by copy/pasting the name of the flow in the browser’s address bar, and the page will load.
In this particular case no harm is done, and there is no even an exception being thrown.
We are in luck; the only thing that happens is an empty order page.
The service/repository will try to load the orders from account “null”, which results in an empty list, so nothing is shown.
If we had developed the repository with less care, we might have omitted the criteria “user” when it was null; in that case it would result in retrieving all orders for all customers!
It is clear that this is a serious vulnerability, so we have to make sure that our security is, well, real security and cannot be longer circumvented by simply typing the correct URL in the browser address bar.
Second, there is also no way to make a distinction among authenticated users, and thus there is no way to limit access.
Once a user is authenticated, he or she gets access to all restricted functionality, an approach that is in most cases too coarse-grained (most applications support different levels of authorization)
We brought this up just to show you that rolling out your own Security is not something to take lightly.
In our first attempt we will try to introduce you to the Spring Security basics and show you how easy it is to set up a basic security scheme that will already look very professional.
Make sure that no restricted functionality is accessible if the user is not authenticated, no matter what they try.
So the cheap URL trick will have no longer any effect.
Even a user who is authenticated will not be able to access pages or flows for which no explicit access rules are defined.
Use form-based authentication, which will show the user a login page on which credentials can be entered using a username and password field.
Redirect users to the login page automatically whenever they try to access a secured resource directly, and redirect them back to that resource after authentication was successful.
Use Spring Security to do the authentication part instead of writing this kind of code ourselves.
We will explain some of the Spring Security architecture and internals as we go along securing the application.
Later, in the following sections, we will extend this basic scheme and discuss more about authorization and how to apply it in our application.
We will extend the application by adding functionality to add categories and books, which will only be available to a selection of authenticated users.
Securing Our Bookstore To demonstrate the basic security scheme, we will apply it to our sample application.
In this first section, we will show you how to.
Configure Spring Security to act as a giant wrapper for our application, so that every request that comes in passes via Spring Security.
Enable auto-redirection when a secured resources is accessed without being authenticated, and then redirect them back once authenticated.
Adding the Right Dependencies Before you can use Spring Security you have to declare the correct set of dependencies.
Like Web Flow or Spring MVC, Spring Security is a module on which you must declare a specific dependency in order to use it.
This is convenient because your project can depend on the modules it actually needs; no more, no fewer.
This helps to keep your dependency tree clean, as no unused modules (which again have dependencies) are pulled into.
The modules we will be using (and the ones you will probably always use to secure a web application) are listed in Table 13-1
In the sample project, you will find these modules translated to dependency entries in the.
The value of this variable can be found in the root Gradle file.
Note  You’ve seen that Spring Security is divided into several modules.
The modules we are depending on, as can be seen in Listing 13-1, are only a subset of these, since we will not be using every functionality Spring Security has to offer.
In case you require other functionality (LDAP, for example) you have to include it as an extra module in your dependency list.
A list of these modules can be found in the Spring Security reference under the dependency section1
Here you will see each module listed together with its own dependencies.
The dependencies of the module itself are only there as information; they will be pulled in automatically by your build tool/dependency management system from the moment you add a dependency to one of the Spring Security modules.
The core concept is that it will capture every request coming in to our system and decide if the request can go through or not.
The mechanism to support this begins with a standard JEE Servlet filter.
This filter will serve as a hook to delegate the captured requests to Spring Security.
We can make use of the JEE dynamic servlet API to add this filter, as shown in Listing 13-2
The first argument of addFilter is the name we will be giving to the filter.
When we cover the Spring side in a moment, we will explain why this filter’s name is of importance.
The default (when supplying null) is to invoke it for all requests coming from “outside” the Servlet container.
You can also specify, for example, that the filter should be invoked when a resource is accessed by an internal include or forward statement.
Leaving this value as null is sufficient, since your resources are protected from the outside, and even when making includes or forwards you will be checking authorization on your pages using security tags (which we will cover later)
However, in some situations it can be desirable to go through the security filter chain again when performing such operations.
Note  There seems to be an issue with Tomcat (7.0.26 at the time of writing), where this flag seems to be interpreted the other way around.
So if you declare a Filter to be isMatchAfter equal to true, it will match before all other filters for the same URL pattern (or Servlet)
We have posted a message on the Apache Tomcat development mailing list2 for this.
Now that we have seen how all requests are captured by a filter, we will see how the requests end up in the Spring Security machinery.
That “somewhere” is the core of Spring Security and is configured in our Spring configuration.
This piece of configuration will configure the “Spring Main Security Configuration” as illustrated in Figure 13-2
To do this we first need to configure the Spring Security namespace that will contain all the artifacts we need to set up the main configuration (see Listing 13-3)
Note  You can also make the Spring Security namespace the default namespace.
Here we have chosen to use the default namespace for the core Spring beans functionality, which is the default in all our other Spring configuration files as well.
However, it would also work to switch them in this case, since this is a configuration file dedicated to Spring Security, where you will be using more of the Spring Security elements than from the bean namespace.
In that case, you could drop the “security” prefix, as all security elements will be accessible in the default namespace, without any prefix.
When there is a lot of security configuration, it can make your XML look less cluttered.
If you name the filter someFilter, it will look up the filter chain with bean ID someFilter, which results in no bean being found.
Before we continue we need to explain what the Spring Security filter chain is and what it will do for us.
The filter chain is the core component in capturing requests and dealing with what has to be done.
Almost everything in the main Spring Security configuration is handled by a filter in the filter chain.
You can plug in or remove filters at will, and every filter will have a specific job (see Figure 13-3)
In Listing 13-4, we implicitly configured an element that will send the user to the login.htm (specified by the login-page attribute) page if accessing a secured resource without being authenticated.
When the user logs in, the filter will automatically redirect the user back to the requested secured resource.
Or, the user might be redirected to main.htm, which renders the home page (defined by the default-target-url attribute) if there was no previously requested secure page but the user logged in directly via the login page.
In that case we also send a parameter, indicating that authentication was successful.
The main page in question will detect this and show a message that the authentication process succeeded.
This element will result in a filter being added to the filter chain to take care of this.
While you will be able to plug in your own custom filters, many existing filters are already at your disposal.
It is beyond the scope of this book to discuss them all, but in the Spring Security reference manual3 you will find more information about them.
For your convenience we have included the complete list here in Table 13-2
It will give you an idea of what is already available for you to use.
The bean alias will be important to refer to the filter if you defined such.
For example, if you add your own custom filters, you will be able to position them in the chain.
By explicitly referencing these filters you can position them before or after a specific filter.
For example, if you want to position myCustomFilter after the FORM_LOGIN_FILTER, you could define it as.
The namespace element or attribute is the configuration element that triggers the addition of the filter in the chain.
The filters are listed in the table in the order they would be in the chain if you define them.
As it turns out, we already configured a filter in Listing 13-4, by adding:
This filter will leverage the previously described functionality of redirecting the user to the login page or the index page.
As the name implies, it also covers other functionality, as we will discuss later.
This is again done by implicitly adding a filter to the filter chain.
We don’t declare a new filter, but instead use an existing one provided by Spring Security.
The filter will perform the authentication check if the resource you entered in the pattern matches with the resource requested.
At this point we have a mixture of flows and pages, the latter being controlled directly by a Spring MVC controller.
For each we will indicate whether it should be available publicly or privately (authenticated access only)
If a customer is not logged in, it would be impossible to retrieve the orders.
We again define if they should be available publicly or only after authentication.
In that case the application server will automatically look for a welcome file and will find index.jsp.
To organize the pages that require public or authenticated access, we are going to group them under.
Adding the intercept-url rules based on the request URIs we explicitly want to configure.
This means that you should specify the more specific rules first, followed by the more general rules.
If a resource matches a pattern, either directly or by wildcards specified in the pattern, the level of authentication specified by the access attribute will be required.
If that condition is met, access is granted; otherwise it is denied.
First we declared that index.jsp (our welcome) file is accessible for everyone.
Every URL beginning with /secured requires the user to be fully authenticated before access is granted.
URLs beginning with /public are able to be accessed by any one.
We will discuss the access attribute and where those values are coming from in a minute.
As you recall, our flows are placed together with our pages.
Because of this we do not need to specify extra rules, since access to anything under /secured will be captured by our /secured/** rule.
That is, you will have to put secured flows under flows/secured and public flows under flows/public.
If we request access to the /createOrders-flow we don’t need to be authenticated to get access.
If we try to access the /placeOrders-flow, however, we will need to be authenticated first.
If we are not authenticated, we are redirected to the login page.
After the login succeeds, Spring Security takes us back to the secured resources we asked for in the first place (/placeOrders-flow in this case)
You might also have noticed that we added an attribute in the <security:http> element called useexpressions with value true.
Before we can do that we have to explain a bit more about how Spring Security works.
Each voter will evaluate if access is granted, abstained, or denied.
This is indicated by the return value of the vote.
If the request resource matches any of the listed entries, either directly or by wildcard matching, the access attribute is checked to see what has to be done.
If the access attribute is permitAll, access is always granted.
If that is not the case, the user is redirected to the login page automatically.
After login, the user will be redirected back to the secured resource.
Finally, if the requested resource does not match any entry, access is denied by default by using the denyAll access attribute.
By default this will render the server’s default “403 access denied” page.
So accessing a random URL will bring up this page.
Even after the user has logged in, accessing a random URL will still trigger the “access denied” page, because there was no previous rule that explicitly granted access.
All resources that are not explicitly listed are now by default shielded from any user access.
Tip  When configuring access to resources, it is always wise to close up with a deny all rule.
If the access requirements for the requested resource aren’t listed, access is simply denied.
When the user accesses a resource other than the ones we listed, a “403 access denied” page will be shown on the user’s browser.
This makes sure that resources which are not explicitly configured cannot be accessed by accident.
We refactored all URL mapping in the pages accordingly to be prefixed with /public.
Overview of Expression Methods and Literals We still need to explain where the permitAll, fullyAuthenticated and denyAll come from.
These are all Spring EL expressions that are evaluated with a special Spring Security-aware context.
In a normal Spring EL environment, evaluating denyAll would trigger an exception.
However, in this scope, extra methods and properties are implicitly available for your expressions.
Optionally you can specify a range by supplying the netmask in the CIDR (Classless Inter- Domain Routing6) notation (ipaddress/mask)
You will see that in the super class there are additional methods not covered in Table 13-5
We didn’t include them, because they are aliases; for example, hasAuthority and hasAnyAuthority.
We also omitted the hasPermission methods, which are specifically for method-based security in combination with post- and pre filtering.
The methods in Table 13-6 can also be accessed as properties.
They provide access to a getter method that returns an Object, such as the principal.
Or they provide a shortcut for a getter method that returns a boolean (those properties start with is rather than get)
The result is exactly the same as the method syntax, but saves you the effort of typing the parentheses.
Remember that the expressions, whether you are using methods or properties, are Spring EL.
You will be able to use logical operators such as and, or etc.
Configuring Authentication When users are redirected to the login page, the application asks them to enter a username and password combination in order to proceed.
Spring Security will receive this information but needs to verify that the user exists and that the password supplied matches for that user.
In order to do this we need some kind of user store to hold the users (and passwords) that are able to access the application.
To keep things simple for now, we will use an in-memory data store, which we will fill with users and passwords entirely specified in the configuration.
Later we will see how to replace this with a database store.
Using this construct we don’t have to wire this authentication manager explicitly; it will be auto detected by Spring.
In order for the authentication manager to do its job, it needs a reference to an authentication provider.
This is the bridge to the store that contains the user details.
A user has a username (abbreviated name in this case), a password, and a comma-separated list of authorities.
What is important is that this code is not yet complete.
As you can see, we have a strange and long password.
A one way hash is a cryptographic function that takes plain text as input and generates another, weird-looking, string as output, called a hash (or digest)
The general idea is that the hash cannot (without taking decades of computing time) be reverseengineered to the original plain-text form.
In order to compare these passwords, one takes the password as entered by the user, hashes it with the hash function and then compares the output with the hash stored in the data store.
The only problem is that Spring now expects the user to enter the hash.
Because Spring does not know that what we stored is actually a hash, it thinks that this long string is the actual password that the user has to enter.
What is left to do is configure Spring to take the real plain-text password by the user, hash it using the selected hashing algorithm, and then compare the output hash with the hash value we supplied in the password field.
There is also a weird sub element, which we will discuss in a minute.
With this password encoder, Spring Security knows that our passwords are hashed, and that it should hash the user’s entered password first before comparing the value with the one in our data store.
Note  Why did we make things more complex by introducing a hashed password rather than a plain text one, when we are creating just the basic setup? We did this for a good reason.
A wise man once told us “in practice, a temporary solution is the equivalent of a production ready solution that will stay there forever.” Ask yourself; how many times have you developed something temporary that is still out there? Also, when working with Spring Security or Java, there is no good reason not to hash your passwords.
With the Apache Commons Codec,7 you can create a hash with a single line of code.
Never store plain-text passwords! Also, if someone performs an audit and sees that passwords are in plain text, you will be in trouble.
You might wonder, how did we generate the hash in the first place? We could have written a small Java tool which does that for us, using the Apache Commons Codec:
Or, we could have Googled an online site to do that.
There are also plenty of free tools out there that can generate any kind of hash.
Just one note, be careful using online generators, as you will be passing around real passwords.
For testing purposes this will do fine, but for real case scenarios, think about writing a tool yourself or downloading a well-known tool8 instead.
If you would verify this you’ll notice that the hashes don’t quite match.
In this case we are using a “salted hash” which is nothing more than the password suffixed with extra data that can be found when authenticating the user.
For example, it could be the first name of the user.
In this case we have chosen the easiest element; the username.
The goal of the salt is to make the digests more unique.
If two users use the same password, the same hash will be generated.
When using a salt, the hashes will differ, as they are calculated using another suffix (in this case their username)
Having the same hash doesn’t hurt, as they (practically) cannot be reverse engineered.
However, you are giving away a free hint: someone looking at the hashes might note that multiple users have the same hash, and thereby implicitly know that they also have the same password.
By adding the salt you are taking away that last hint, and you are also making the passwords longer.
The longer the password, the more resistant the hash will be against attacks.
We have now configured the password encoder with a type of hash.
Internally, we supplied it with a salt source that has a user-property with the value “username”
Let’s look in more detail at how Spring Security will handle this:
Finally, compare the result from the hash function with the one retrieved from the users data store.
Putting It All Together Before we can test our application, we still have to make some modifications to our pages.
In the previous application our pages were adapted for the custom authentication scheme that we created ourselves.
In particular, the login and landing page need some modifications to work together with Spring Security.
Spring Security will perform authentication, based on the username and password that we will supply.
We will do this by our login page, which has username and password fields.
But Spring needs to know about these items, so we are going see how to handle that.
We will also see how we can show error messages that the login might have produced.
Next we will make a small modification to our home page to indicate whether the authentication was successful.
Previously, if a user logged in using the login link, he or she could only infer that the login must have succeeded since there was no error.
We will enhance this a bit with a message saying that the authentication succeeded.
Finally, we will change the logout so it is handled by Spring Security as well.
We mention this option because it might be worth considering in your own Spring projects, although we will leave the values at their defaults for the duration of the chapter.
The request URL will be in the action of the HTML form.
Anyone inspecting your HTML source will know you are using Spring Security.
While “security through obscurity” might by itself give a false sense of security, if applied in a well-controlled and secured environment (as we are building here) it is considered a plus, since you are removing one more hint.
In this case, it is the version or software product you are using to secure your application.
As you can see, we have made sure the input fields for password and username have the requested name, so that the parameter will be picked up by Spring.
We are also submitting our form to the default Spring Security URL for authentication.
What you might also notice is that we added a section to display login errors:
The only thing we have to do is display it.
The message can be localized and can also be changed.
We will discuss this further in the “Localization” section of this chapter.
To detect that a new login failure occurred, we check for the presence of the parameter authenticationNok.
When Spring Security detects a login failure, it can direct to a specified URL.
On authentication failure we redirect back to the login page, but this time we append the parameter authenticationNok, which will make the message appear.
We are supplying a value 1 for the parameter, just to let it have a value so we can easily test if this parameter is present.
This rounds up the modifications to the login page; now we will move on to the home page.
Changing the Home Page When authentication is successful we redirect to the home page.
In this case we want to show a message that authentication was successful.
In order to do this, we will add a parameter to the URL specified in the default-target-url attribute (see Listing 13-11)
The code that displays the message is indicated in bold.
Adapting the home page to show the appropriate message when login was successful.
We only check for the authenticationOk parameter if the user is already authenticated.
If we then see that this parameter is present, we display a message so the user knows authentication was successful.
This authentication strategy ensures that the message is shown only once.
If the authenticated user were to return to the welcome page using the “home” link, or any other way, we have ensured that the message is not shown a second time.
We will discuss the Spring Security taglibs in detail later in the “Authorizing Access” section.
When the user clicks the logout link, it will direct to /logout, which will invoke the controller method logout, and call invalidate on the HTTP session.
Although this is not very complex, it should no longer be part of our application code.
After that we will configure Spring Security to take over the task.
In Table 13-2 earlier, we gave an overview of the possible filters; the LogoutFilter is one of them.
The logout-success-url attribute indicates the page to which Spring Security should redirect when the logout was successful.
The second attribute, logout-url, indicates the URL where the filter should listen.
Whenever a call is made to /logout, the LogoutFilter will be invoked and the user logged out.
The last attribute indicates whether the HTTP session should be invalidated as well.
Optionally you can also indicate to clear the entire HTTP session.
While it is not mandatory, it is in nearly all cases the safest to clear the session as well.
Invalidating the session is the default behavior if you don’t specify the invalidate-session attribute.
We specified it here explicitly so anyone reading our security configuration understands that the session is cleared for sure (not that we doubt the default value is working, but to give a clear indication, not everyone is aware of the defaults)
The logout link itself in our header.jsp remains unaltered, as you can see in Listing 13-14
The only thing missing is that this link should only appear when the user is actually logged in.
We will see how to handle this when we introduce the authorization tag.
Although we have included a lot of functionality, the configuration part is still pretty digestible, as you will see.
Together with the login and home page modification explained in the previous two sections, this secures our entire application.
We are now able to log in via a form login.
All our resources are now secured; some require authentication before a user can access them, and others are publicly accessible.
Resources that are not explicitly listed are denied access by default.
Going to the Database Up until now we have stored our user information in the configuration itself.
It would be better to adapt our configuration so that we can load the user’s account from the existing database tables.
As it turns out, this is a very easy step to take.
In our previous implementation this was loaded from the inmemory data store.
This is a very easy interface to implement, as it only has one method:
The goal of the UserDetailsService is to access the data store (database, directory server, or possibly a file) that contains the user information and possibly credentials.
Basically, the implementation should load the user information from wherever its configuration determines and convert that information to a UserDetails object.
As we will see later, a UserDetails object is the main object you will be using when asking for security information.
We use our CustomerService to load the Customer and pass it along to our custom UserDetails object.
There are getters for the username, password and our Customer object.
At the moment we return an empty list with for the GrantedAuthority property.
We will later see how this will fit into our application.
All the other methods are features for the UserDetails, such as account expiry and so on.
We won’t be using these features, so true is returned for all of them.
This means you will be able to access the Authentication Object anywhere in your web application by calling.
On the Authentication object, we are especially interested in the getPrincipal method.
In the previous section, we introduced you to the UserDetails, well this is what the getPrincipal returns, a UserDetails implementation.
Note  If you look at the API, you will see that getPrincipal returns Object.
So it can also return other types besides a UserDetails implementation.
In that case the return value from getPrincipal can be whatever type you want the principal to be.
Securing Our Flows, the Right Way The setup we’ve put in place until now still secures our flows as normal request mappings.
It only works for requests coming from outside to access a flow.
If a flow wants to start a subflow, the request is already behind the Security filters and will not be picked up (see Figure 13-4)
Securing flows as request URI using the filter chain is not enough.
What happens here is that no authentication is triggered when the request comes in to transition to placeOrder (as it is still for createOrders-flow)
When Web Flow makes the internal state transition to the sub-flow, it will actually execute without redirecting the user to the login page.
When you do so, your inter flow communication will also be secured.
In order to secure your flows, you can add the following element on top of your flow definitions:
You can use it to place the expressions you want to be valid before this flow can execute.
If you return to the “Configuring Which Resources to Secure” section, you will see that the following two flows required authentication:
The <secured> element also has a second attribute, called match.
For example, it is not possible to define an “or” or “and” relation.
Later on we will introduce the concept of roles, but you should know that you can allow or deny a flow to be executed depending on one or more roles being present.
With SpEL you would simply use the and operator if you only want the flow to execute when both roles are present, or the or operator if one suffices.
When not using SpEL you must use the match attribute, which will let you switch between any; if one of the roles requested are present, the flow will execute, or all; meaning that all of the roles in the attributes attribute must be present before the flow is executed.
However, the <secured> element in the flow could be used to perform finer-grained access control or authorization.
Roles will be discussed in the “Role-Based Access Control” section.
It is required in order for the <security> element we discussed previously to do anything.
It might well be that this problem is resolved by the time you read this; and if so then you can continue as.
If the issue10 has not been resolved, however, you have two options:
You would have to fall back to mainly using roles.
With this approach you will still be able to use SpEL.
For the sake of consistency we went with the second solution for the examples.
Next we configure the listener with the flow executor (see Listing 13-21)
If you come to a point where you need this, and it isn’t fixed, we suggest you read the issue (see the link in the footnote) and look at the source code at the same time.
This will be the best way to understand the fix we applied.
Transport Security At the moment we still have one major security hole in our security setup.
When our users log in they supply username and password credentials, which will be authenticated by Spring Security.
These credentials are, however, sent via the browser to the web server using HTTP, which is a plain-text protocol.
Anyone capturing data will be able to see the username and password in clear text.
To illustrate this we started up Wireshark11 and let it listen on the loopback adapter.
Next we performed a login in our application, and Figure 13-5 shows the results.
Network capture of an HTTP session showing plain credentials when logging in via the form.
To change this behavior we are going to switch to SSL (Secure Socket Layer, which is now called TLS, or Transport Layer Security, its successor, but for consistency we’ll call it SSL), whenever a user logs in.
Before we proceed, you must prepare your tomcat or tomcat STS instance to add an extra SSL connector.
It is beyond the scope of this book to go deeper into the internals of the SSL protocol or the PKI (Public Key Infrastructure), but for this to work you need to supply tomcat with a keystore, which contains a private/public key pair and a certificate for that public key.
Normally the certificate part is generated by a third-party Certificate Authority (CA)
Fortunately, you can self-sign such a certificate which is ideal for tests or closed production setups.
As a small intermezzo we wanted to share something about self-signed certificates, since there is sometimes a misunderstanding about them.
Using PKI with self-signed certificates has exactly the same encryption level as using an official CA signed certificate.
So your SSL will not be less safe; the encryption strength, the procedures, and everything that depends on them offers the exact same guarantees.
With a self-signed certificate your users will have to explicitly accept the certificate, and the browser will give them a warning that the identity cannot be verified.
How this is presented is browser dependent, but with Safari they will get the page as shown in Figure 13-6
In order to trust the certificate for the current session only, you can click “Continue”
If you want to trust the certificate for future sessions, you have to click “Show Certificate”
Doing so will present the dialog box shown in Figure 13-7
If you then check “always trust Bookstore when connecting to localhost” the certificate will be stored.
After you click Continue, the certificate will be trusted (for this session only or for future sessions depending if you clicked the checkbox in Figure 13-7) and you will be able to continue over SSL.
It is clear that this trusting is only a good idea for internal testing.
With a real CA signed certificate, the CA has asked the certificate holder for credentials before actually issuing the certificate.
For example, we would never get a server certificate for google.com from an authorized CA, since we cannot proof that we own the domain or have any authorization over it.
A client’s browser truststore (which contains a list of authorized root CAs) will also not trust our selfsigned certificate by default, since it cannot be verified by any of the known and trusted CAs.
Each party knows that your identity (you gave it personally on a USB stick, or emailed it from your personal account) is the one that is coupled to that certificate (the identity could be a person, server, domain, or whatever)
This way, you can easily save the costs of signing your public keys by a CA.
To generate a self-signed certificate we can use a Java tool called keytool.
Open a command line prompt and enter the following command (make sure the JDK is available on your path):
Enter tomcat as the password and again when prompted to re-enter it:
What is your first and last name? [Unknown]:  Bookstore What is the name of your organizational unit? [Unknown]:  Bookstore What is the name of your organization? [Unknown]:  Bookstore What is the name of your City or Locality? [Unknown]:  Brussels What is the name of your State or Province? [Unknown]:  Brussels What is the two-letter country code for this unit? [Unknown]:  BE Is CN=Bookstore, OU=Bookstore, O=Bookstore, L=Brussels, ST=Brussels, C=BE correct? [no]:  yes.
The prompt will return, and your selfsigned key is ready in the keystore.
Enter key password for <tomcat> (RETURN if same as keystore password):
Do not forget to clean the server in STS before starting.
After modifying anything in the server configuration you have to “clean” in order for the latest files to be copied over (right-click on the server instance in the server view and click Clean)
At this time verify that your server starts and that no errors are thrown.
If there is anything wrong with the configuration, Tomcat will show errors almost directly after starting up.
The final thing to do is to tell Spring Security which mappings we would like to use SSL for (see Listing 13-23)
The requires-channel will automatically change our protocol from HTTP to HTTPS (which is HTTP over SSL)
To illustrate this we are going to our home page (see Figure 13-8)
Next, we click the Login link in the navigation bar, which results in the page shown in Figure 13-9
After clicking on the Login navigation link, we automatically switch to HTTPS.
When we log in now, our credentials are transmitted securely.
If we take a look at the certificate, we will see the data we entered when generating it with keytool.
We will also see that there is no trust, as it is not generated by a trusted CA stored in our browser’s truststore.
It is not trusted by our browser, in this case Safari.
Note  When you run the sample application for the first time, going to the login page will automatically trigger the switch to SSL.
So you will first have to accept the self-signed certificate before your browser will proceed over SSL to the login page.
When we inspect what’s on the wire now, after configuring SSL, we will see that the initial request is a plain HTTP get to the login page.
Spring Security will, however, send a redirect (HTTP 302) back to the browser indicating a protocol change.
You can see that in the two highlighted lines in Figure 13-11
What follows next is no longer plain HTTP, but SSL.
The content of the packets are encrypted, and the password can no longer be intercepted by looking at the packets.
You have seen how we can switch from HTTP to HTTPS, just by altering the Spring Security configuration.
If your application is designed for Englishspeaking users, you don't need to do anything as by default since all Security messages are in English.
If you need to support other locales, you should know that all exception messages can be localized, including messages related to authentication failures and access being denied (authorization failures)
Exceptions and logging messages for developers or system deployers (including incorrect attributes, interface contract violations, using incorrect constructors, startup time validation, debug-level logging) are not localized and instead are hard-coded in English within Spring Security's code.
Spring Security relies on Spring's localization support to look up the appropriate message.
This listener will be called before any filter is invoked.
Role-Based Access Control Role-based access control (RBAC) is a beneficial access control model for organizations with many users and a high degree of diversity in the functions they are playing in their daily job.
Your role in RBAC is actually comparable with the role you would play in your organization; most likely that will have something to do with development.
The permissions are the rights that have been granted to someone with that role.
While this level of detail mostly makes sense only for larger organizations, its basic implementation is not very difficult.
As we will see, we can extend our domain model easily to support basic RBAC with a minimum of effort.
But to set the record straight, for something as simple our bookstore this is certainly overkill.
Even if it were to become a popular store, the diversity of users will be very low; they will all be doing pretty much the same things.
Hence we will not really benefit from an RBAC system.
But we will demonstrate it just to show what is possible with Spring Security.
The model we are going to support comes down to the relationships shown in Figure 13-12
A user (in our domain called “Account”) has one or more roles.
The roles we define will depend on what’s important for our application.
A role can be thought of as a globalization of a set of permissions.
In our bookstore a role might be “customer” or “administrator,” and a permission might be “create order” or “add books.” Permissions are normally finer-grained than roles.
We decided to load both roles and permissions in the Security context.
Checking on the role might be meaningful for a coarse-grained check.
For example; should this navigation link be shown? This probably depends on the fact that a given user possesses a given role.
However, going deeper, it could be that there are two different roles giving access to that same functionality.
But within the functionality, only certain operations are allowed, depending on specific permissions.
So here it would benefit us to check for the presence of a specific permission.
As we will see, with Spring Security we can easily check on both.
For example, suppose that a company has a page that shows various benefits an employee enjoys.
This could contain information about the medical plan, the meal vouchers, or group promotions.
Accessing this information is allowed for internal employees only; contractors and other types of outside employees don’t benefit from this and should be excluded from accessing this information.
For this reason we could opt to do a coarse-grained check on roles first.
This will prevent the contractors from even seeing a link to this information.
However, within the page itself we want to differentiate between normal employees, who can only read/query the information, and administrators, who will be able to modify the information.
As employees, we will only have the permission to read the extra benefits, while administrators (also being employees) will have the extra permission to modify the information as well.
This whole story is not so interesting for Spring Security.
It just wants to know a list of “strings” that you will use to check presence upon.
That this list contains roles, permissions, or aliens, doesn’t really matter.
The role and permission division is just for the people administrating the application, so that access can be dealt with flexibly, without having to change the code of the application.
Roles or permissions will be transformed to Spring Security GrantedAuthorities.
First is the familiar Account entity, which is shown in Listing 13-26
In bold you will see the many-to-many association it has with Order.
The Role entity, which has in turn a many-to-many association with Permission.
An Account has a number of roles, and each role has a number of permissions.
As we’ve stated: an Account can have multiple Roles and a Role can have multiple Permissions.
Finally we need to populate our security principal with these roles and permissions.
We will extend this now to load the list of granted authorities, as shown in Listing 13-29
First we check that the username is not null or blank.
Finally we will create a union of all the Roles that are linked to the Account, and all the Permissions linked to each Role and add them to a list of type GrantedAuthority.
The class just takes a String as constructor value and offers a getter for retrieving it later on.
You can see this here (we omitted the equals, hashCode and toString implementation for brevity):
In the next section we will see how you can limit access based upon these authorities.
Authorizing Access So far you have seen how we can secure our application by making all resources accessible for authenticated users only, unless specified otherwise.
We also showed how to configure Spring Security so it can authenticate the given credentials.
Our security setup is now almost ready, as all the bits and pieces are in place.
Or better said, we need to indicate which functionality the user is allowed to use based on the roles and permissions coupled to the user’s Account.
In the following sections we will see how we can control authorization in our pages.
We will see that Spring Security comes with its own tag library that offers special tags to disable or enable functionality directly in our JSP pages, based on the presence of certain roles or permissions.
Using Tag Libraries in Our Pages Spring Security comes with a dedicated tag library you can use to conditionally render certain page components.
The use case is always the same: determining whether a certain component or part of the page should be shown to the currently logged-in user based upon the set of authorities.
In order to use the tags, we have to declare the corresponding tag library in our pages.
In the following sections we will illustrate the most important tags and how you can use them.
The authorize Tag This tag is used to determine whether its contents should be evaluated or not, based on one or more authorization checks.
In our case we will use it in exactly the same way as the flow security attribute, or the access attribute of the intercept URL.
Using a SpEL expression we will verify if the current authenticated user has the given role in order to let the content be evaluated.
In the first code snippet we will only show the content when the authenticated user has the role ROLE_AUTHOR.
In the second snippet the content will only be shown if the authenticated user has the role PERM_ADD_BOOK.
This page will allow a user to add new books to the system, and new categories.
In order to use this functionality, the user must be authenticated and have the role ADMIN or AUTHOR.
However, for the two functions, adding new categories and books, two separate permissions are required.
Listing 13-30: Adding additional users to our initial data setup.
The author user is only able to add books to existing categories, but is not allowed to make new ones (only the admin user is)
Next, in Listing 13-31, we add a new link in our navigation menu, and apply the right security settings using the authorize tag.
Users from both roles should be able to manage books, but inside the page we will further restrict access based on their permissions.
Using the authorize tag in our navigation bar to display only the Manage Books link to.
It is clear that a normal customer (like our user jd) will not be able to see the Manage Books link at all.
Here we will further control authorization based on the specific permissions.
The first if block and the last JavaScript block are used to display a message whenever a Category or Book is added successfully.
This JavaScript code is the same as we used to show a message when the user.
In the latter case the user is redirected to the ordersOverview page and a message pops up up with the username and the order ID of the newly placed order.
In all cases the JavaScript will let the displayed message slowly disappear.
In our case the author will not be able to do this.
This “add category” section will not be shown to users with a role that does have the proper authorization; in our case the user author will not see this section.
The second authorize tag requires the permission to add books (PERM_ADD_BOOKS)
Both authors and admins will be able to do this.
To illustrate this, when we login with user “jd” the menu option to manage books will not even be shown, as you can see in Figure 13-13
Logging in with user “jd” does not display the Manage Books menu option.
When we log in as an author, the menu option Manage Books is shown.
When we click on it we will see that we only can add books, as shown in Figure 13-14
Logging in with user “author” displays the Manage Books menu option, but only allows us to.
Finally, when we login as admin, the Manage Books link is shown in the navigation bar as well, but now we are allowed to add categories and books, as can be seen in Figure 13-15
Logging in with user “admin” displays the Manage Book menu option and allows us to add.
Before we wrap up this section, there is one last thing we want to show.
In the earlier section “Logging Out,” we said that we still need to make an additional change.
The Logout button in the menu should only to be shown when the user has already logged in, and the Login button should be hidden (it should only be shown when the user is not authenticated yet)
Now that we have seen the authorize tag, this is just a matter of adding another one in the header.jsp.
In Listing 13-33 we show an excerpt from the header.jsp applying this tag around the Logout and Login menu links (shown in bold)
The first authorize tag in bold will only render its contents (the Login link) when we are not authenticated yet.
The second authorize tag in bold will only render its content (the Logout link) when we are authorized.
It can render any property of the object directly in the JSP.
This will display the username of the user currently logged in.
We have configured Spring Security to forward us to the home page when login was successful.
We also added a special parameter (authenticationOk) to indicate that.
The home page will display a message that the login was successful, including the username.
Here we use the var and scope attributes to bind the result (from the property indicated in the property attribute) with the given variable name (username) to the indicated scope (Servlet request scope)
You can see the result in Figure 13-16, where we logged in as user jd.
The JavaScript on the bottom is there to let the message slowly fade away as we have done elsewhere when showing notification messages.
Using Annotations in Our Code Securing your pages using the authorization tag is not sufficient, as we will see.
Hiding a link (which is the main task of the authorization tag) won’t do the trick if the user knows or guesses the direct link.
In that case the user still will get access (assuming you didn’t place a specific intercept-url for that page with proper authorization checks)
In this section we will see that you can also secure your application controller methods and backend services using annotations.
This way you are sure that if a user escapes the front-end security, the user will be blocked on the next level.
Applying security in your back-end services can also be useful if you have different frontend layers using the same back-end.
Until now we have seen three places where we can put specific authorization check points:
For a more fine grained approach, in the pages themselves using the authorize tag.
With our last example in mind, we added specific permission checks on the manageBooks.jsp page.
But what would happen if a user with the author role (who cannot add categories) were to simulate an http POST request adding a new category?
While the authorization tag on the page only hides a component, the controller listening for the request is still there.
So anyone who knows the correct URL and the request parameters can still invoke the controller directly.
Besides adding a intercept-url with fine grained authorization control (specifying roles and or permissions) for each of the pages, you can also use method-specific annotations as shown in Listing 13-36
Because the tag is commented out, the component to add categories is shown.
If you try to add one, you’ll get the famous “403 access denied” page.
Before Spring Security will process these annotations you need to enable method security.
Next we will also secure the addBooks method, as we did for the addCategory method, in Listing 13-38
To make the entire chain secure, you can also add these annotations on your service layer.
Once you do this there is no way that someone can bypass your security and invoke a function that is not allowed for the current principal.
To conclude, we want to say a few words about Security exceptions.
Normally your users should not run against such exceptions as part of normal navigation throughout your application.
We shielded all links in the pages using the authorization tag; so in other words, if a user does not have access to a certain link (or button) it will simply not be shown.
However, if a user starts to fiddle with the URLs, it might still be possible to access a forbidden URL.
In that case the user will hit the security annotations on your application controllers or back-end, and a 403 access denied message will be shown.
If you want customize this behavior, you have two options:
Its main purpose is to forward the user to a login page if not authenticated yet, or to a predefined error page if the current user lacks sufficient rights.
For your convenience this filter was already registered by using the Spring Security namespace configuration (<security:http>)
Summary Security in general is a very complex and broad domain.
However, we have shown you in this chapter that basic security for an average web application does not have to be complex.
On the contrary, we have shown with a small bit of XML and a filter configuration how you can make your pages secure, so that only those pages explicitly listed can be accessed.
Later we showed that customization using a custom UserDetailsService is also not very complex, but it allows you to adapt your user store to any existing database structure you might have.
Finally, we showed how to perform authorization based upon the permissions granted to a principal in your pages, your flows and controllers.
To conclude, we hope that you learned that with minimal effort your application can be secured.
With such a great tool as Spring Security available, there should no longer be a reason not to build in basic security in your applications.
This chapter was written to give you an overview of the possibilities and get you started quickly.
In that case we hope that this chapter has warmed you up to go and read more detailed material about Spring Security and what it can do to suit specific requirements.
In this appendix, we will discuss what it takes to get our application to run on a different environment than what we have been running it on so far.
Instead of running on any boring old Tomcat instance, we’ll run it in the cloud.
But before we get down to it, we’ll talk just a little bit about what the cloud means.
Cloud Computing You probably haven’t been able to avoid the onslaught of cloud computing in the specialized media.
But you may still not have an idea of what cloud computing entails.
We’ll try to give a short overview of what cloud computing is about.
It’s hard to give a single definition of what cloud computing is, as it tends to mean different things to different people.
Cloud Computing is a distributed computing m odel consisting of three ti ersinfrastructure, platform, and serv ices—that enables ubiquitous, conv enient, ondemand network access to a sh ared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services)
Consider Amazon S3,1 for example: Amazon allows you to store data on its servers using web-based APIs.
You pay Amazon for the bandwidth you use in uploading or downloading that data.
At no point in time do you ever need to have your own storage infrastructure.
There are several kinds of cloud service models in use:
Infrastructure as a service (IaaS): Delivers computing infrastructure as a service.
Examples of such infrastructure include virtual computers, storage, network infrastructure, and so forth.
Amazon and Rackspace are two of the best-known IaaS providers.
Platform as a service (PaaS): Offers services beyond the infrastructure.
The control over the actual infrastructure itself is mostly handed by the service provider.
Software as a service (SaaS): Provides the delivery of a full solution as a service, eliminating the need to install and run the application on the customer’s own computers and simplifying maintenance and support.
Contrast this with the traditional delivery model for software, where end users install software on every desktop, manage the upgrades themselves, and so on.
In this model, the user just visits a website and begins using the application online.
Cloud Foundry In this appendix, we’ll use Cloud Foundry as our PaaS of choice to deploy our bookstore application to.
But what is Cloud Foundry and why would we want to use it?
Initiated by VMware, with broad industry support, Cloud Foundry makes it faster and easier to build, test, deploy and scale applications.
Now what does this mean? It means that Cloud Foundry is not a proprietary, vendor-specific PaaS, but a truly open platform that is being developed by several individuals and organizations.
Ubuntu is also working on supporting Cloud Foundry under their Ubuntu Cloud4 banner.
It also means that we have to define some things more explicitly:
Cloud Foundry is the name of the open source project.
Cloudfoundry.com is a VMWare–hosted instance of Cloud Foundry that lets you deploy your application on VMWare–owned infrastructure.
In the course of this appendix, we don’t differentiate between Cloud Foundry the platform and CloudFoundry.com the hosted service.
Now that we’ve seen what Cloud Foundry is, why should we as Java/Spring developers care? Why should we use it over any other PaaS? One reason: The fact that Cloud Foundry is an open, multi-vendor platform is very nice because it helps us avoid the dangers of vendor-locking and the related costs.
Another reason: It also has multi-language support, including Ruby, Java, Scala, and NodeJs; and it offers many services, from relational stores such as MySQL and PostgreSQL, to queues like RabbitMQ, to NoSQL storage like MongoDB and Redis.
Another big advantage is that it integrates very nicely with Spring.
These things combined make Cloud Foundry a very interesting platform.
After reading and agreeing with the Terms of Service, you can click the Request Invite button.
Later (it can take a few hours or even a day), you’ll receive an e-mail with the credentials you need to actually deploy on CloudFoundry.com.
Deploying Our Application In this section, we are going to describe how we can deploy the sample application on Cloud Foundry.
We will describe each step in detail and also explain the modifications we must do to make everything work as expected.
If you want to perform the actions described here yourself, we will assume that you have read the initial chapter on how to set up your environment.
We are also assuming you have either STS or an Eclipse instance with the STS plug-in installed.
Installing the Cloud Foundry Plug-in Although Cloud Foundry offers several tools to get your application deployed, the fastest way to get started when you first dive in is to use the Eclipse plug-in.
The alternative is using the VMC commandline application, which is implemented as a Ruby gem.
An advanced user can’t escape using the VMC command-line; but for the scope of this appendix, we’ll use the Eclipse plug-in.
It is comparable to apt-get for Ubuntu or yum for Red Hat.
You can find more info on the VMC install at http://start.cloudfoundry.com/tools/vmc/installing-vmc.html.
You’ll get the normal plug-in installation windows that ask you to accept or reject the license agreement.
Click the Next and OK buttons until you get a dialog asking you to restart Eclipse, and then choose to restart it by clicking Restart now.
Now that we’ve installed the plug-in, we can proceed to the next step: deploying our application on Cloud Foundry.
It is an explicit goal to make Spring applications deployable without changing one line of configuration or code in most cases.
Unfortunately, this is not entirely true for our application because it will not get deployed without us making some changes.
The other driver for change is the way SSL is set up in Cloud Foundry, which has some impact on the way we configure Spring Security.
We also need to declare a DispatcherServlet by using the servlet tag, as shown in Listing A-2
We are creating two application contexts, splitting the back-end configuration (e.g., datasources, services, repositories, and so on) from the front-end configuration (e.g., Spring MVC, Spring Web Flow, the @Controllers, and so forth)
The DispatcherServlet will bootstrap its own context for the front end.
It will set this context as a parent context for its own application context.
The fact that we now have two application contexts instead of one doesn’t have a real impact on us.
We are also using two types of application context classes now.
The Cloud Foundry Spring config will do some magic, such as automatically replacing our datasource with the internal Cloud Foundry one, which we will discuss later.
Hopefully, this limitation will disappear in the future, so that we’ll be able to use any type of application context implementation we want.
Finally, we need to configure the filters, as shown in Listing A-3
Next, we’ll look at the changes needed for Spring Security.
Note  Chances are the changes just discussed will no longer be necessary by the time you’re reading this.
Tomcat 7 support is on the roadmap, and it might be implemented by the time you read this.
This also demonstrates one of the disadvantages of running on a PaaS: you don’t have control over the underlying infrastructure.
For example, what if you needed to run on Tomcat 7 right now?
Spring Security Configuration We are not yet done with our changes.
Cloud Foundry supports SSL, but there is a proxy standing in front of our application.
However, the connection between the proxy and the Cloud Foundry Tomcat instance running our application is plain HTTP.
Figure A-2 is a bit of a simplification, but it comes close enough to illustrating how things look from a developer’s point of view.
Before going to our application, the proxy adds some headers that are the result of dealing with the SSL connection.
It will tell us which cipher was used, as well as the client certificate if performing mutual (or two-way) SSL.
If we just use “normal” SSL without a client certificate, this last header will also be present, but it will have “no value” as its value.
This will yield false because the connection type between the proxy and the application is HTTP.
Spring Security will then send out a redirect to the browser, asking to switch over to SSL, which will result in an endless loop.
We will override the isSecure() method to also inspect the HTTP headers when considering whether a connection is secure.
If the original implementation decides a connection is not secure, then we’ll check for the presence of these specific SSL headers added by the Cloud Foundry proxy before we make a final decision.
What it will do first is call isSecure() from the superclass.
If the default behavior says our request is secure, then we leave everything untouched and return the value (true) as-is.
If both are present and have a non-empty value, we will consider the request as being a secured request (at least, we will assume that the user’s browser used SSL up until the Cloud Foundry proxy), and we will return true instead.
Overriding the isSecure() method might seem a bit of a drastic measure.
However, the Javadoc indicates that it should return true if the connection is considered secure.
It is not bound to a specific protocol, so one should never make the assumption that, when isSecure returns true, the protocol is HTTPS by definition.
It could also be any other protocol that gives “security” guarantees.
Also, given that this implementation is the least intrusive and is the least likely to break when upgrading Spring or Spring.
Cloud Foundry is also working on better SSL support in the near future, possibly allowing SSL going all the way up to our server.7
Now that we have all this in place, we should be able to deploy our application on Tomcat 6—and hence, on Cloud Foundry—so let’s now try to do just that.
Deploying Deploying to Cloud Foundry with the plug-in follows a process very similar to deploying to a Tomcat instance.
Follow these steps to create a server to deploy to:
Choose Cloud Foundry, which is found under the VMWare node.
Click Next and you’ll get a dialog requesting that you enter the account information that you used when signing up for Cloud Foundry (see Figure A-4)
If you haven’t done that yet, you can still click the CloudFoundry.com Signup button, which will take you to the website.
At this point, it doesn’t hurt to be a bit skeptical and click the Validate Account button.
It will check that you can connect to Cloud Foundry and that your credentials are OK.
Click Finish and the next dialog will ask you which applications you want to deploy.
This will take you to the Application Details dialog, which asks you what kind of app you’re deploying.
You get one more dialog asking you for an URL to deploy your application under (see Figure A-6)
You’ll need to pick another URL because appendixAbookstore will already be reserved.
You also can choose the amount of memory you want to give to your application by changing the value for Memory Reservation.
We kept the “Start application on deployment” check box selected, so the application will start deploying and booting.
You can also start the application later by manually clicking the Start button in the Cloud Foundry panel on the Applications tab.
After it finishes deploying, you can point your browser to the URL you configured earlier (http://appendixa-bookstore.cloudfoundry.com in our case, but http://the-name-you-justchose.cloudfoundry.com for yours), and see your app running on the cloud (see Figure A-7)!
Configuring the Services We may now have our application running, but there is still something missing: the application is still using its embedded H2 instance, so anytime we restart the app, the data will be gone again.
So let’s use one of the persistence options that Cloud Foundry offers us.
We are using JPA for persistence, so our choice will be limited to the relational databases, MySQL and PostgreSQL:
You’ll see the Overview panel where you can change your account details (see Figure A-8)
Click the Applications tab on the bottom, and you’ll see the actual applications you’ve deployed, as shown in Figure A-9
Click the Add Service button next to the Services panel.
Choose a MySQL database service and give it a name (see Figure A-10)
Click Finish, and you’ll be taken back to the Applications tab, where you’ll see that MySQL is now an available service.
Note that, at the moment of writing, there’s a bug in the plug-in that causes the Services panel not to show a service after just adding it.
Note  You can see the available services (and their version) using the vmc services command.
Now click the Update and Restart button, and then navigate to the application with your browser.
How Does It Work? You may wonder how it is possible that we’re able to save our data in a MySQL database, since we never did configure another datasource in our application.
In fact, all we did was tell Cloud Foundry that we wanted to use MySQL as an application service.
Remember how we had a choice of application type when deploying? We chose Spring and that enabled Cloud Foundry and Spring to do their magic.
What happens is that, during the deployment process, additional configuration is added to your web.xml that registers some extra Spring beans into your ApplicationContext.
This was exactly the reason why we needed to use XML config, as explained previously.
But what about the Hibernate dialect? Before we were using H2, and now we’re using MySQL—yet we didn’t have to tell Hibernate anything about this.
As it turns out, recent Hibernate versions have a handy feature that can detect the type of database from an actual connection, so there is no longer a need to explicitly configure the dialect to use.
Note  This has its disadvantages: if your database isn’t up or reachable up while your application is booting, Hibernate will fail at runtime.
One of the other, more explicit possibilities is to use the cloud configuration namespace.
Using that namespace, we could have configured a datasource in XML, as shown in Listing A-7
Setting the profile="cloud" attribute on the beans element means that the beans defined within the element will only be used if the “cloud” profile is active.
The cloud:datasource element is a “normal” datasource that represents the relational database application service that was bound to this application.
Combine this with the fact that Cloud Foundry automatically sets cloud as the active application profile, and we can have cloud-specific configuration using that profile.
This type of explicit configuration is even required if we want to use more than one cloud service of the same type (e.g., a MySQL and PostgreSQL service) at the same time.
Our application will not get touched in any way if we deploy using that type.
But CloudFoundry.com offers another solution, one that doesn’t require us to always connect to a remote system.
It’s called MicroCloud, and it is distributed as a virtual machine (a VMWare image) that we can run locally (such as on the free VMWare player)
On the same site, you can also find instructions on how to configure your MicroCloud.
Debugging with Cloud Foundry Things don’t always go as planned, and there will be times when you will need to debug your application.
While you can always debug your application when deploying on your own Tomcat instance, MicroCloud also supports connecting with a Java debugger.
To do so, you can start your application using the Debug button instead your Start button.
Once the application is started in debug mode, you can debug it just like any other application started locally.
If you want remote access to your services (e.g., you want to inspect the current data), Cloud Foundry provides the Caldecott gem that allows you to create a tunnel10 to them.
Now it’s only a matter of pointing your MySQL or JDBC client to that port to get to the data.
Summary This appendix covered Cloud Foundry and how you can deploy your application on it.
There are a few things that separate Cloud Foundry from competing PaaS providers: one is the open source nature of Cloud Foundry, and another is its excellent integration with the Spring framework.
While Cloud Foundry promises a seamless deployment model for most apps, which allows you to deploy your application as-is, you had to make some adjustments in the case of the bookstore application.
These adjustments were required mostly because you are using a newer Tomcat version than the one you currently get with Cloud Foundry.
Cloud Foundry is currently still in beta, so it is rapidly evolving, with new features and services still being added.
And while you may still run into some rough edges now and then, it is definitely worth keeping an eye on it to see how it evolves in the future.
All rights are reserved by the Publisher, whether the whole or part of  the material is concerned, specifically the rights of  translation, reprinting, reuse o f illustrations, recitation, broadcasti ng, reproduction on microf ilms or i n any other physical way , and transmission or i nformation storage and retrieval, electronic adaptation, computer sof tware, or by simi lar or d issimilar methodology now known or hereaf ter developed.
Exempted from this legal reservation are brief excerpts in connection with reviews or scholarly analysis or material supplied specifically for the purpose of being entered and executed on a computer system, for exclusive use by the purchaser of the work.
Duplication of this publication or parts thereof is permitted only under the provisions of the Copyright Law of the Publisher's location, in its current version, and permission for use must always be obtained from Springer.
Permissions for use may be obtained through RightsLink at the Copyright Clearance Center.
Violations are liable to prosecution under the respective Copyright Law.
Trademarked names, logos, an d images may app ear in this book.
Rather than us e a trademark s ymbol with every occurrence of a trademarked name, logo, or image we use the names, logos, and images only in an editorial fashion and to the benefit of the trademark owner, with no intention of infringement of the trademark.
The use in this  publication of  trade names, tr ademarks, service marks, and similar terms, ev en if th ey are not identified as such, is not to be ta ken as an expression of opinion as to whether or not they are subject to proprietary rights.
While the advice and information in this book are believed to be true and accurate at the date of  publication, neither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or o missions that may be made.
The publisher makes no warranty, express or implied, with respect to the material contained herein.
Apress and friends of ED book s may be purchased in bulk f or academic, corporate, or promo tional use.
Any source code or other supplementary materials referenced by the author i n this text is av ailable to re aders at www.apress.com.
I had been using J2EE and Struts heavily, and had struggled with many difficulties in effectively using those technologies while building Java enterprise applications.
While in general Spring did not try to reinvent the wheel by providing solutions competing  with existing parts of J2EE or other established frameworks (notably Hibernate), there was one important exception to this rule: web application development.
Spring shipped with its own web framework, Spring MVC, a fully functional web application framework that can serve as a direct alternative to something like Struts.
At the time, I saw further opportunity to enhance Spring-based web application development by adding a page flow component to Spring MVC called Spring Web Flow.
Spring MVC and Spring Web Flow are the prime subjects of this book.
The design of Spring MVC benefited from the lessons learned working with earlier frameworks.
Well-designed Spring MVC applications can grow and change while remaining manageable and maintainable.
Many found the initial learning curve when adopting Spring, and more specifically Spring MVC, too steep.
New frameworks such as Ruby on Rails popped up and focused on short term-productivity and making it very easy to get up-and-running.
You now have a framework offering the best of both worlds: easy to get started with while the fundamental principles underpinning it all pay dividends in the long term.
Since 2004, Spring MVC and Spring Web Flow have seen a steady and continued increase in popularity.
They are now mature and well established Java development frameworks.
If you build a Java web application on top of these frameworks, you can rest assured that you are building on a very solid foundation!
Of course, they help you in setting up a productive development environment and guide you while getting started developing with Spring MVC and Web Flow.
I really appreciate how they did not simply cover the technical details, but took the time to explain many of the underlying concepts, bringing a deeper understanding to you, the reader.
Furthermore, the book also covers other important topics such as enforcing security constraints and making sure your web applications are well tested.
After having read this book you should be well prepared to develop real-life web application based on Spring technologies.
I highly recommend this book for all those eager to learn about Spring MVC and Spring Web Flow, and I applaud the excellent job the authors have done in helping developers learn about these exciting Spring technologies.
He has developed and architected software, primarily in Java, for small and large companies.
He is an enthusiastic open source user and longtime fan, user and advocate of the Spring Framework.
When not working or answering questions on the Spring Framework Forums, he can be found in the water training for the triathlon or under the water diving or guiding other people around.
He holds a keen interest in system architecture and integration, data modeling, relational databases, security and networks.
Beginning his career with the Belgian federal government, Koen developed highly transactional Java-based applications with legacy integration.
Currently, he is employed by Hewlett-Packard and is a Java software consultant and technical lead for the Flemish government in Belgium.
Colin Yates is a J2EE principal architect who specializes in web-based development.
He has been a freelance consultant for the past three years and has worked in a number of environments, both structured and chaotic.
Since graduating with a software engineering degree in 1997, he has held a number of positions, including development lead, principal systems engineer, mentor, and professional trainer.
His principal skill set includes mentoring others, architecting complex problems into manageable solutions, and optimizing development processes.
Colin was first introduced to the Spring Framework in January 2003 by his mentors, Peter Den Haan and David Hewitt, and he has never looked back.
Seth Ladd is a software engineer and professional Spring Framework trainer and mentor specializing in object-oriented and testable web applications.
He started his own company building websites at age 17, but now enjoys having a real job.
He has architected and developed enterprise applications in Java and C for both the server and remotely connected embedded devices.
He enjoys speaking and teaching, and is a frequent presenter at local Java user groups and at corporate developer conferences.
Seth is very thankful for living and working in Kailua, Hawaii, with his wife.
He is able to work all the way up the stack, from heavy transactional code all the way to JavaScript-based front-ends.
Manuel Jordan Elera is an autodidactic developer and researcher who enjoys learning new technologies for his own experiments and creating new integrations.
In his little free time, he reads the Bible and composes music on his guitar.
Manuel is a Senior Member in the Spring Community Forums, where he is known as dr_pompeii.
Manuel is the Technical Reviewer for these books (All published by Apress):
Read and contact him through his blog at http://manueljordan.wordpress.com/ and follow him on his Twitter account, @dr_pompeii.
One thing I quickly learned during this endeavor is that writing a book is not something you do alone.
I would like to thank the whole team at Apress for their support; without you this book would have never seen the light of day.
I also learned that writing a book is harder than I ever expected.
I thank Manuel Jordan for introducing me to the people at Apress, which started this endeavor.
I owe a big thanks to Koen Serneels for helping me out writing this book and sitting it out all the way, you wrote more than you, initially, signed up for.
Another big thanks goes to Chris Nelson for keeping all of us focused and for his advice on the book; it was a pleasure working with you.
The same thanks go to the coordinating editors, Stephen Moles and Jennifer Blackwell, who in addition to the focus on quality tried to keep everything within the schedule (sorry for slipping past the initial date)
This book would never have seen the light without the comments and suggestions given by Manuel Jordan and Erwin Vervaet.
Although at times the comments drove me to desperation, without your comments and suggestions this book would never have become what it is now.
So thanks for the comments and suggestions and keeping a clear vision.
The appendix was written entirely by Christophe Vanfleteren, who took on this task with great dedication and determination.
He did an excellent job of making our application deploy on Cloud Foundry and writing down the steps it took.
Thanks also to my family and friends for the times they missed out on me, and to my divebuddies for all the dives and trips I missed in the last months.
Last but definitely not least I thank my wife, Djoke Deinum, for her endless support, love and dedication, despite the long evenings, sacrificed weekends and holidays to finish the book.
Without your support I probably long ago would have abandoned the endeavor.
I thank Erwin Vervaet for giving me the chance to coauthor this book and for being a great colleague and mentor over the last years.
With Erwin on your side there are no problems, only solutions.
Without you guys this project would never have reached this paper version; thank you all.
After all these months of hard work I realize that writing a book is even harder than writing good software.
In fact, writing a book is comparable to a software project without the luxury of automated testing.
Christophe Vanfleteren did an excellent job investigating Cloud Foundry and helping us out writing the appendix.
I had the pleasure to work together with Christophe before, and he is by far one of the most talented developers I have worked with in my career.
Special thanks to everyone who keeps Spring alive, by developing for it or by using it.
I have been using Spring since 2004, and to this day it still keeps me amazed.
I have used many frameworks, but Spring remains a top-notch framework with its superior code base, agility, liveness, good design and completeness.
It is my believe that Spring has many years to go and will be able to serve us on a daily basis to make our work easier, faster and help us create quality projects.
I thank my girlfriend, Sonja Korte, for bearing with me and forgiving me sacrificing our holidays and nearly all evenings and weekends over the last 4 months, and my family and friends for missing out on me.
Last but not least, I want to thank you for reading this book.
I'm also a reader of many IT books, so I know what is good and what isn't.
I really hope we have succeeded at bringing the good stuff into practice and offer you a top-quality book with exiting technology that will make your daily job easier.
Welcome to the first edition of Pro Spring MVC with Web Flow; the first Pro Spring book focused entirely on web development using the Spring Framework 3.1 ecosystem.
What This Book Will Teach You This book will teach you everything you need to know in order to get started building enterprise-quality web applications using version 3.1 of the Spring Framework.
Providing a web front end to a Spring based application.
Deploying to a local web server and to a remote cloud-based deployment platform.
After reading this book you will be familiar with the Spring MVC toolkit and capable of building your own web application from scratch or providing a new web interface to an existing application.
All too often trivial examples are used to demonstrate the power of a framework; it is only when you start using the framework in real situations that its limitations appear.
And because the real-world problems this book tackles are hard, sometimes the answers Spring MVC provides are not as easy as one would like.
This book will not shy away from highlighting those issues or providing pragmatic advice on how to do the right thing.
Who Is This Book For? This book is for those who are familiar with Spring and want to gain an in-depth understanding of Spring MVC.
While it is primarily aimed at those new to Spring MVC, there is information here that will take even expert MVCers by surprise!
The typical reader will be a web developer who has some understanding of the core Spring framework (after reading Pro Spring for example) and wants to investigate Spring MVC in more detail.
How to Read This Book This book will take the reader through the thought process of designing, implementing, and deploying a Java web application.
The order of the chapters follows the chronological order defined by the development lifecycle.
During these chapters we use a sample application to illustrate the topics discussed in the chapter.
Each chapter will address a real-world problem by introducing a new concept or capability which is then used to upgrade the sample application.
Note  There is a never-ending dilemma that authors face: should we show the answers first and then the questions, or show the questions and then the answers? The first approach risks overloading the reader, while the second approach can be frustrating and slow for those already familiar with the subject matter.
The authors believel that the pace of this book is sufficient for those unfamiliar with Spring MVC; more experienced readers may want to skip certain chapters.
The example in question is the site for a web-enabled bookstore.
A logged-in user can submit an order for one or more books.
Throughout the rest of this book, each chapter adds a new aspect to the sample application.
The simplest way of capturing this in the example was to have a new project for each chapter.
The Sample Code We need to explain a little about the coding and referencing style used throughout the book.
You’ll find that some of the code listings are complete and can be taken directly from the book to the development environment.
In others we omit some imports or methods that are mentioned in earlier listings; we’ve marked those with // Imports omitted or // Methods omitted.
Most include a reference to the code listing in which the methods or imports can be found.
This approach was needed for readability, as some code listings contain only a few new lines and others would span multiple pages.
How This Is Book Structured The book consists of a series of chapters, each explaining a part of the framework or how to use a certain technology.
The first four chapters are quite theoretical and are used to explain some of the more general concepts and how they apply or work within Spring MVC (the same goes for the start of the Spring Web Flow part of the book; Chapter 10 is also more or less theoretical)
After that introduction to the concepts behind Spring MVC, the remaining chapters follow a more practical and hands-on approach as we start to develop an application.
Chapter 1, “Configuring a Spring Development Environment.” This chapter presents the prerequisites for your development environment, which you can use to develop the sample application.
The structure and purpose of the sample application (an online bookstore) are also explained in this chapter.
Chapter 2, “Spring Framework Fundamentals,” provides a broad overview of the fundamental building blocks of the Spring framework.
It introduces the concepts of Dependency Injection (DI) and Inversion of Control (IoC)
This chapter is particularly recommended if you are unfamiliar with Spring.
Chapter 3, “Web Application Architecture.” In this chapter we take you on a slight detour to explain web application architecture.
We will explain the different layers that (generally) make a web application and we will explain the Model View Controller triad.
Chapter 4, “Spring MVC Architecture.” This chapter is the first "down and dirty" chapter dealing with Spring MVC.
It defines exactly what MVC is, how web applications are typically structured, or layered, and it dives into the powerhouse of the Spring MVC engine: the wonderful DispatcherServlet.
At the end we will have the start of the sample application.
Chapter 6, “Implementing Controllers – Advanced.” Every application requires the same behavior in a number of different places, as well as behavior that isn't really part of your core application but needs to be stuck in somewhere.
This chapter will introduce Aspect Oriented Programming (AOP) and how Spring MVC easily solves some common web problems.
We will also explore the internals of Spring MVC a bit more and explain how to extend the existing infrastructure and how to tailor it to our needs.
Chapter 7, “REST and AJAX.” Now that our bookstore is taking off, we want to add some nifty behavior to our application and we also want to expose our controllers as REST web services so that others might be able to integrate with us.
For this we are going to explore REST and AJAX and apply those techniques to our application.
In this chapter you will get to revisit the ViewResolver infrastructure and start to see the power of the MVC architecture shine through when you re-use the same infrastructure to provide different renditions of the same model.
Chapter 9, “Testing Spring MVC Applications.” Now that the craving to get something done has been somewhat satisfied and we’ve written some code, it is time to look at testing.
This chapter explains how to test Spring MVC applications but also crucially what to test.
This chapter will include a good discussion of different strategies for testing, including how to ensure you are testing only what you need to test.
You will also be given the chance to test-drive the HTML as well!
Chapter 10, “Spring Web Flow.” Up to now all of the page interactions have been pretty simple; each use-case was one or two pages.
Chapter 10 introduces Spring Web Flow— a companion partner to Spring MVC that provides some pretty nifty features for managing web conversations with clients.
Chapter 13, “Spring Security,” shows how to keep the scruffy hackers out of our web-application through the use of another well-established tool in the Spring toolbox, Spring Security.
Appendix A, “Cloud Foundry—Deploying to the Cloud.” In this appendix we explain the steps needed to deploy the application to the cloud, especially to Cloud Foundry, as that integrates seamlessly with our chosen development environment.
A Thousand-Mile View of the Spring Ecosystem So before going any further let's take the first peek at Spring MVC and where it fits into the existing Spring ecosystem.
The first piece of good news is that Spring MVC is Spring.
You configure Spring MVC using the existing powerful Spring container.
Beans defined in Spring MVC are just like any other beans.
As you can see— Spring MVC is powered by the rest of Spring!
Onward! Now that you have an idea about the style and purpose of this book let's waste no more time in getting you set up with a development environment.
Feel free to contact him if you have found a mistake, want to ask a question, or want to discuss anything else related to the book.
If you have suggestions, remarks, or questions, or have found something to be inaccurate, feel free to drop him a message.
